{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW08JFT0BUk1"
      },
      "source": [
        "# 컨볼루션 신경망(Convolution Neural Networks, CNN)\n",
        "\n",
        "- 완전 연결 네트워크의 문제점으로부터 시작\n",
        "\n",
        "  - 매개변수의 폭발적인 증가\n",
        "\n",
        "  - 공간 추론의 부족\n",
        "    - 픽셀 사이의 근접성 개념이 완전 연결 계층(Fully-Connected Layer)에서는 손실됨\n",
        "\n",
        "- 합성곱 계층은 입력 이미지가 커져도 튜닝해야 할 매개변수 개수에 영향을 주지 않음\n",
        "\n",
        "- 또한 그 어떠한 이미지에도 **그 차원 수와 상관없이** 적용될 수 있음\n",
        "\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://miro.medium.com/max/4308/1*1TI1aGBZ4dybR6__DI9dzA.png\">\n",
        "  \n",
        "  <center>[LeNet-5 구조]</center>\n",
        "\n",
        "  <sub>[이미지 출처] https://medium.com/@pechyonkin/key-deep-learning-architectures-lenet-5-6fc3c59e6f4</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORxbya83GHwc"
      },
      "source": [
        "## 컨볼루션 연산 (Convolution Operation)\n",
        "\n",
        "- 필터(filter) 연산\n",
        "  - 입력 데이터에 필터를 통한 어떠한 연산을 진행\n",
        "  \n",
        "  - **필터에 대응하는 원소끼리 곱하고, 그 합을 구함**\n",
        "\n",
        "  - 연산이 완료된 결과 데이터를 **특징 맵(feature map)**이라 부름\n",
        "\n",
        "- 필터(filter)\n",
        "  - 커널(kernel)이라고도 칭함\n",
        "  \n",
        "  - 흔히 사진 어플에서 사용하는 '이미지 필터'와 비슷한 개념\n",
        "\n",
        "  - 필터의 사이즈는 \"거의 항상 홀수\"\n",
        "    - 짝수이면 패딩이 비대칭이 되어버림\n",
        "  \n",
        "    - 왼쪽, 오른쪽을 다르게 주어야함\n",
        "  \n",
        "    - 중심위치가 존재, 즉 구별된 하나의 픽셀(중심 픽셀)이 존재\n",
        "\n",
        "  - 필터의 학습 파라미터 개수는 입력 데이터의 크기와 상관없이 일정  \n",
        "    따라서, 과적합을 방지할 수 있음\n",
        "\n",
        "  <br>\n",
        "\n",
        "  <br>\n",
        "\n",
        "- 연산 시각화\n",
        "  <img src=\"https://www.researchgate.net/profile/Ihab_S_Mohamed/publication/324165524/figure/fig3/AS:611103423860736@1522709818959/An-example-of-convolution-operation-in-2D-2.png\" width=\"500\">\n",
        "\n",
        "  <sub>[이미지 출처] https://www.researchgate.net/figure/An-example-of-convolution-operation-in-2D-2_fig3_324165524</sub>\n",
        "\n",
        "\n",
        "- 일반적으로, 합성곱 연산을 한 후의 데이터 사이즈는  \n",
        "  ### $\\quad (n-f+1) \\times (n-f+1)$\n",
        "    $n$: 입력 데이터의 크기  \n",
        "    $f$: 필터(커널)의 크기\n",
        "\n",
        "  <br>\n",
        "  \n",
        "  <img src=\"https://miro.medium.com/max/1400/1*Fw-ehcNBR9byHtho-Rxbtw.gif\" width=\"400\">\n",
        "\n",
        "  위 예에서 입력 데이터 크기($n$)는 5, 필터의 크기($k$)는 3이므로  \n",
        "  출력 데이터의 크기는 $(5 - 3 + 1) = 3$\n",
        "\n",
        "  <br>\n",
        "\n",
        "  <sub>[이미지 출처] https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-60rJIUG49O"
      },
      "source": [
        "## Convolution vs Cross Correlation (참고)\n",
        "\n",
        "- 실제로 머신러닝 분야에서 '합성곱'이라는 용어를 일반적으로 사용하고는 있지만  \n",
        "  여기서 말하는 합성곱 연산은 '수학적 용어'로는 **교차 상관 관계(cross-correlation)**이라고 볼 수 있음\n",
        "\n",
        "- 수학적으로 합성곱 연산은 필터를 '뒤집어서' 연산을 진행\n",
        "\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Comparison_convolution_correlation.svg/400px-Comparison_convolution_correlation.svg.png\">\n",
        "\n",
        "  <sub>[이미지 출처] https://en.wikipedia.org/wiki/Convolution</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-ekDsJwN2Y-"
      },
      "source": [
        "## 패딩(padding)과 스트라이드(stride)\n",
        "- 필터(커널) 사이즈과 함께 **입력 이미지와 출력 이미지의 사이즈를 결정**하기 위해 사용\n",
        "\n",
        "- 사용자가 결정할 수 있음\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNisiLu2TY9z"
      },
      "source": [
        "\n",
        "### 패딩\n",
        "- 입력 데이터의 주변을 특정 값으로 채우는 기법\n",
        "  - 주로 0으로 많이 채움\n",
        "\n",
        "<br>\n",
        "\n",
        "- 출력 데이터의 크기\n",
        "  ### $\\quad (n+2p-f+1) \\times (n+2p-f+1)$\n",
        "  <br>\n",
        "\n",
        "  위 그림에서, 입력 데이터의 크기($n$)는 5, 필터의 크기($f$)는 4, 패딩값($p$)은 2이므로    \n",
        "  출력 데이터의 크기는 ($5 + 2\\times 2 - 4 + 1) = 6$\n",
        "\n",
        "<br>\n",
        "\n",
        "### 'valid' 와 'same'\n",
        "- 'valid'\n",
        "  - 패딩을 주지 않음\n",
        "  - padding=0\n",
        "    - 0으로 채워진 테두리가 아니라 패딩을 주지 않는다는 뜻!\n",
        "\n",
        "- 'same'\n",
        "  - 패딩을 주어 입력 이미지의 크기와 연산 후의 이미지 크기를 같게!\n",
        "\n",
        "  - 만약, 필터(커널)의 크기가 $k$ 이면,  \n",
        "    패딩의 크기는 $p = \\frac{k-1}{2}$ (단, <u>stride=1)</u>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlZ7zG6ON85J"
      },
      "source": [
        "\n",
        "\n",
        "### 스트라이드\n",
        "- 필터를 적용하는 간격을 의미"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPcsND-0OCNm"
      },
      "source": [
        "## 출력 데이터의 크기\n",
        "\n",
        "## $\\qquad OH = \\frac{H + 2P - FH}{S} + 1 $\n",
        "## $\\qquad OW = \\frac{W + 2P - FW}{S} + 1 $\n",
        "\n",
        "- 입력 크기 : $(H, W)$\n",
        "\n",
        "- 필터 크기 : $(FH, FW)$\n",
        "\n",
        "- 출력 크기 : $(OH, OW)$\n",
        "\n",
        "- 패딩, 스트라이드 : $P, S$\n",
        "\n",
        "- (주의)\n",
        "  - 위 식의 값에서 $\\frac{H + 2P - FH}{S}$ 또는 $\\frac{W + 2P - FW}{S}$가 정수로 나누어 떨어지는 값이어야 한다.  \n",
        "  - 만약, 정수로 나누어 떨어지지 않으면  \n",
        "    패딩, 스트라이드값을 조정하여 정수로 나누어 떨어지게 해야!\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUeddu9eJ6fG"
      },
      "source": [
        "## 텐서플로우/케라스 메소드\n",
        "- 이미지 합성곱의 경우 기본적으로 저차원 API의 `tf.nn.conv2d()`를 사용\n",
        "  - `input` : 형상이 $(B, \\ H, \\ W, \\ D)$인 입력 이미지 배치\n",
        "\n",
        "  - `filter` : $N$개의 필터가 쌓여 형상이 $(k_H, \\ k_W, \\ D, \\ N)$ 인 텐서\n",
        "\n",
        "  - `strides` : 보폭을 나타내는 4개의 정수 리스트.  \n",
        "    $\\qquad \\qquad [1, \\ S_H, \\ S_W, \\ 1]$ 을 사용\n",
        "\n",
        "  - `padding` : 패딩을 나타내는 4x2개의 정수 리스트나 사전 정의된 패딩 중 무엇을 사용할지 정의  \n",
        "    \"VALID\" or \"SAME\" 문자열 사용\n",
        "\n",
        "  - `name` : 해당 연산을 식별하는 이름\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "1-KCMignLPKb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "k, D, N = 3, 3, 16\n",
        "input_data = torch.randn(size=(N, D, 32, 32))\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, n_kernels=32, kernel_size=(3, 3), strides=1, padding=0):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        \n",
        "        self.n_kernels = n_kernels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        \n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=input_data.size(1),\n",
        "            out_channels=self.n_kernels,\n",
        "            kernel_size=self.kernel_size,\n",
        "            stride=self.strides,\n",
        "            padding=self.padding\n",
        "        )\n",
        "        nn.init.kaiming_normal_(self.conv.weight, mode='fan_out', nonlinearity='relu')\n",
        "        nn.init.zeros_(self.conv.bias) # type: ignore\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = F.relu(self.conv(x))\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([16, 32, 30, 30])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = SimpleCNN(n_kernels=32, kernel_size=(3, 3), strides=1, padding=0)\n",
        "\n",
        "output_data = model(input_data)\n",
        "\n",
        "output_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x4UoMbF8jJ9"
      },
      "source": [
        "## 풀링(Pooling)\n",
        "\n",
        "- 필터(커널) 사이즈 내에서 특정 값을 추출하는 과정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDiaO3XF8oC_"
      },
      "source": [
        "### 맥스 풀링(Max Pooling)\n",
        "- 가장 많이 사용되는 방법\n",
        "\n",
        "- 출력 데이터의 사이즈 계산은 컨볼루션 연산과 동일\n",
        "## $\\quad OH = \\frac{H + 2P - FH}{S} + 1 $\n",
        "## $\\quad OW = \\frac{W + 2P - FW}{S} + 1 $\n",
        "\n",
        "- 일반적으로 stride=2, kernel_size=2 를 통해  \n",
        "  **특징맵의 크기를 <u>절반으로 줄이는 역할</u>**\n",
        "\n",
        "- 모델이 물체의 주요한 특징을 학습할 수 있도록 해주며,  \n",
        "  컨볼루션 신경망이 이동 불변성 특성을 가지게 해줌\n",
        "  - 예를 들어, 아래의 그림에서 초록색 사각형 안에 있는  \n",
        "    2와 8의 위치를 바꾼다해도 맥스 풀링 연산은 8을 추출\n",
        "\n",
        "- 모델의 파라미터 개수를 줄여주고, 연산 속도를 빠르게 해줌\n",
        "\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://cs231n.github.io/assets/cnn/maxpool.jpeg\" width=\"600\">\n",
        "\n",
        "  <sub>[이미지 출처] https://cs231n.github.io/convolutional-networks/</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4czHpHrW8qyb"
      },
      "source": [
        "### 평균 풀링(Avg Pooling)\n",
        "\n",
        "- 필터 내의 있는 픽셀값의 평균을 구하는 과정\n",
        "\n",
        "- 과거에 많이 사용, 요즘은 잘 사용되지 않는다.\n",
        "\n",
        "- 맥스풀링과 마찬가지로 stride=2, kernel_size=2 를 통해  \n",
        "  특징 맵의 사이즈를 줄이는 역할\n",
        "\n",
        "  <img src=\"https://www.researchgate.net/profile/Juan_Pedro_Dominguez-Morales/publication/329885401/figure/fig21/AS:707709083062277@1545742402308/Average-pooling-example.png\" width=\"600\">\n",
        "\n",
        "  <sub>[이미지 출처] https://www.researchgate.net/figure/Average-pooling-example_fig21_329885401</sub>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "NL27tG0uQDAt"
      },
      "outputs": [],
      "source": [
        "k, D, N = 3, 3, 16\n",
        "input_data = torch.randn(size=(N, D, 32, 32))\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_kernels, kernel_size, pool_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.n_kernels = n_kernels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.k_strides = 1\n",
        "        self.k_padding = 0\n",
        "        \n",
        "        self.pool_size = (2, 2)\n",
        "        \n",
        "        self.p_strides = 2\n",
        "        self.p_padding = 0\n",
        "        \n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=input_data.size(1),\n",
        "            out_channels=n_kernels,\n",
        "            kernel_size=self.kernel_size,\n",
        "            stride=self.k_strides,\n",
        "            padding=self.k_padding\n",
        "        )\n",
        "        nn.init.kaiming_normal_(self.conv.weight, mode='fan_out', nonlinearity='relu')\n",
        "        nn.init.zeros_(self.conv.bias) # type: ignore\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv(x))\n",
        "        x = F.max_pool2d(x, kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "qWw49mAzQOJa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([16, 32, 15, 15])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Net(n_kernels=32, kernel_size=(3, 3), pool_size=(2, 2))\n",
        "\n",
        "output_data = model(input_data)\n",
        "\n",
        "output_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmhhig5YQViL"
      },
      "source": [
        "## 완전 연결 계층(Fully-Connected Layer)\n",
        "\n",
        "- 입력으로 받은 텐서를 1차원으로 평면화(flatten) 함\n",
        "\n",
        "- 밀집 계층(Dense Layer)라고도 함\n",
        "\n",
        "- 일반적으로 분류기로서 **네트워크의 마지막 계층에서 사용**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "JQ_ZMUwMQ9Zx"
      },
      "outputs": [],
      "source": [
        "N, D = 16, 32\n",
        "input_data = torch.randn(size=(N, D))\n",
        "\n",
        "class FullyConnectedLayer(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.fc = nn.Linear(\n",
        "            in_features=self.input_size,\n",
        "            out_features=self.output_size\n",
        "        )\n",
        "        nn.init.kaiming_normal_(self.fc.weight, mode='fan_out', nonlinearity='relu')\n",
        "        nn.init.zeros_(self.fc.bias)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        z = self.fc(x)\n",
        "        z = F.relu(z)\n",
        "\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "kUHf1gnFQSLL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([16, 10])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = FullyConnectedLayer(input_data.size(1), 10)\n",
        "\n",
        "output_data = model(input_data)\n",
        "\n",
        "output_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQDl4bYMSBgr"
      },
      "source": [
        "## 유효 수용 영역(ERF, Effective Receptive Field)\n",
        "\n",
        "- 입력 이미지에서 거리가 먼 요소를 상호 참조하여 결합하여 네트워크 능력에 영향을 줌\n",
        "\n",
        "- 입력 이미지의 영역을 정의해 주어진 계층을 위한 뉴런의 활성화에 영향을 미침\n",
        "\n",
        "- 한 계층의 필터 크기나 윈도우 크기로 불리기 때문에 RF(receptive field, 수용 영역)이라는 용어를 흔히 볼 수 있음\n",
        "\n",
        "  <img src=\"https://wiki.math.uwaterloo.ca/statwiki/images/8/8c/understanding_ERF_fig0.png\">\n",
        "\n",
        "  <sub>[이미지 출처] https://wiki.math.uwaterloo.ca/statwiki/index.php?title=Understanding_the_Effective_Receptive_Field_in_Deep_Convolutional_Neural_Networks</sub>\n",
        "\n",
        "<br>\n",
        "\n",
        "- RF의 중앙에 위치한 픽셀은 주변에 있는 픽셀보다 더 높은 가중치를 가짐\n",
        "  - 중앙부에 위치한 픽셀은 여러 개의 계층을 전파한 값\n",
        "\n",
        "  - 중앙부에 있는 픽셀은 주변에 위치한 픽셀보다 더 많은 정보를 가짐\n",
        "\n",
        "- 가우시안 분포를 따름\n",
        "\n",
        "  <img src=\"https://www.researchgate.net/publication/316950618/figure/fig4/AS:495826810007552@1495225731123/The-receptive-field-of-each-convolution-layer-with-a-3-3-kernel-The-green-area-marks.png\">\n",
        "\n",
        "  <sub>[이미지 출처] https://www.researchgate.net/figure/The-receptive-field-of-each-convolution-layer-with-a-3-3-kernel-The-green-area-marks_fig4_316950618</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziTX7TwxVDIK"
      },
      "source": [
        "## CNN 구현\n",
        "\n",
        "### LeNet-5\n",
        "\n",
        "\n",
        "  <img src=\"https://miro.medium.com/max/4308/1*1TI1aGBZ4dybR6__DI9dzA.png\">\n",
        "  \n",
        "  <center>[LeNet-5 구조]</center>\n",
        "\n",
        "  <sub>[이미지 출처] https://medium.com/@pechyonkin/key-deep-learning-architectures-lenet-5-6fc3c59e6f4</sub>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "OmHHY6NoRC6P"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "vzO3O0sucnsA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LeNet5(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (out): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.n_classes = n_classes\n",
        "        \n",
        "        # Layers\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=6,\n",
        "            kernel_size=(5, 5),\n",
        "            stride=1,\n",
        "            padding=0\n",
        "        )\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=6,\n",
        "            out_channels=16,\n",
        "            kernel_size=(5, 5),\n",
        "            stride=1,\n",
        "            padding=0\n",
        "        )\n",
        "        self.fc1 = nn.Linear(in_features=16*4*4, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.out = nn.Linear(in_features=84, out_features=self.n_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = F.max_pool2d(self.conv1(x), kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
        "        x = F.max_pool2d(self.conv2(x), kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x\n",
        "        \n",
        "    @staticmethod\n",
        "    def init_params(m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = LeNet5(n_classes=10).to(device)\n",
        "model.apply(LeNet5.init_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "MzpZgJdteQCA"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and pre-process data\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "train_data = MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
        "\n",
        "def calc_mean_std(loader: DataLoader):\n",
        "    sum, sq_sum, n_batches = 0, 0, 0\n",
        "    \n",
        "    for data, _ in loader:\n",
        "        sum += torch.mean(data, dim=[0, 2, 3])\n",
        "        sq_sum += torch.mean(torch.square(data), dim=[0, 2, 3])\n",
        "        n_batches +=1\n",
        "    \n",
        "    mean = sum / n_batches\n",
        "    std = (sq_sum / n_batches - mean ** 2) ** .5 # V(X) = (E(X^2) - m^2)\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "mean, std = calc_mean_std(train_loader)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((mean, ), (std, ))\n",
        "])\n",
        "train_data = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_preprocessed_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_preprocessed_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "_fYNdTcwdd9R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 0.557654636337402\n",
            "Epoch: 2, Loss: 0.13484441306679806\n",
            "Epoch: 3, Loss: 0.08652228806564148\n",
            "Epoch: 4, Loss: 0.06544912608062968\n",
            "Epoch: 5, Loss: 0.04937011444980794\n",
            "Epoch: 6, Loss: 0.03950584412532601\n",
            "Epoch: 7, Loss: 0.031849166804409405\n",
            "Epoch: 8, Loss: 0.02582009834574258\n",
            "Epoch: 9, Loss: 0.022043122213452736\n",
            "Epoch: 10, Loss: 0.01992389608689762\n",
            "Epoch: 11, Loss: 0.01564681690602385\n",
            "Epoch: 12, Loss: 0.01325382659994462\n",
            "Epoch: 13, Loss: 0.013788178145013591\n",
            "Epoch: 14, Loss: 0.012152602786118996\n",
            "Epoch: 15, Loss: 0.009027431737086637\n",
            "Epoch: 16, Loss: 0.010531126717947661\n",
            "Epoch: 17, Loss: 0.011664751093547315\n",
            "Epoch: 18, Loss: 0.015532196492719603\n",
            "Epoch: 19, Loss: 0.009587820614948174\n",
            "Epoch: 20, Loss: 0.005657295747957331\n",
            "Epoch: 21, Loss: 0.005274079769337054\n",
            "Epoch: 22, Loss: 0.007630581128227703\n",
            "Epoch: 23, Loss: 0.005413186255231886\n",
            "Epoch: 24, Loss: 0.0074952933670422855\n",
            "Epoch: 25, Loss: 0.011542059531022964\n",
            "Epoch: 26, Loss: 0.007396229544401843\n",
            "Epoch: 27, Loss: 0.005621461904585421\n",
            "Epoch: 28, Loss: 0.007541273915813555\n",
            "Epoch: 29, Loss: 0.004057106185606012\n",
            "Epoch: 30, Loss: 0.004201425754798309\n",
            "Epoch: 31, Loss: 0.003946126377733426\n",
            "Epoch: 32, Loss: 0.005375784021197568\n",
            "Epoch: 33, Loss: 0.008200786552225373\n",
            "Epoch: 34, Loss: 0.007978743826893054\n",
            "Epoch: 35, Loss: 0.00582246194377497\n",
            "Epoch: 36, Loss: 0.008190991869567834\n",
            "Epoch: 37, Loss: 0.007090601515200762\n",
            "Epoch: 38, Loss: 0.0050809131342480504\n",
            "Epoch: 39, Loss: 0.004505578222663044\n",
            "Epoch: 40, Loss: 0.0028640817652326113\n",
            "Epoch: 41, Loss: 0.0014736496122361828\n",
            "Epoch: 42, Loss: 0.0006502724833663183\n",
            "Epoch: 43, Loss: 0.008504581593218818\n",
            "Epoch: 44, Loss: 0.009621889338914696\n",
            "Epoch: 45, Loss: 0.00605396846103565\n",
            "Epoch: 46, Loss: 0.004181055584187339\n",
            "Epoch: 47, Loss: 0.0021789967431028886\n",
            "Epoch: 48, Loss: 0.0035209312564579995\n",
            "Epoch: 49, Loss: 0.003076638948250741\n",
            "Epoch: 50, Loss: 0.0030653269246342578\n"
          ]
        }
      ],
      "source": [
        "epochs = 50\n",
        "lr = 1e-3\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    running_loss = .0\n",
        "    \n",
        "    for idx, data in enumerate(train_preprocessed_loader):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(inputs)\n",
        "        pred_vals, pred_indices = torch.max(outputs, dim=1)\n",
        "        loss = criterion(outputs, labels) # backpropagation 과정은 tensor 형태가 필요\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if idx == len(train_preprocessed_loader) - 1:\n",
        "            print(f'Epoch: {epoch + 1}, Loss: {running_loss / len(train_preprocessed_loader)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "rsHzPXwAdL0y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set\n",
            "Loss: 0.00033505, Accuracy: 98.75%\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    t_loss = 0\n",
        "    \n",
        "    for data in test_preprocessed_loader:\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(inputs)\n",
        "        pred_vals, pred_indices = torch.max(outputs, dim=1)\n",
        "        t_loss += criterion(outputs, labels).item()\n",
        "        correct += pred_indices.eq(labels).sum().item()\n",
        "    \n",
        "    t_loss /= len(test_preprocessed_loader.dataset)\n",
        "    acc = correct / len(test_preprocessed_loader.dataset) * 100\n",
        "    print(\"Test Set\")    \n",
        "    print(f\"Loss: {t_loss:.8f}, Accuracy: {acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeMPNQRYoBW6"
      },
      "source": [
        "# Visual Geometry Group Net(VGGNet)\n",
        "\n",
        "- 2014년 ILSVRC 분류 과제에서 2등을 차지했지만, 이 후의 수많은 연구에 영향을 미침\n",
        "\n",
        "- 특징\n",
        "\n",
        "  - 활성화 함수로 `ReLU` 사용, Dropout 적용\n",
        "\n",
        "  - 합성곱과 풀링 계층으로 구성된 블록과 분류를 위한 완전 연결계층으로 결합된 전형적인 구조\n",
        "\n",
        "  - 인위적으로 데이터셋을 늘림\n",
        "    \n",
        "    - 이미지 변환, 좌우 반전 등의 변환을 시도\n",
        "\n",
        "  - 몇 개의 합성곱 계층과 최대-풀링 계층이 따르는 5개의 블록과,  \n",
        "    3개의 완전연결계층(학습 시, 드롭아웃 사용)으로 구성\n",
        "\n",
        "  - 모든 합성곱과 최대-풀링 계층에 `padding='SAME'` 적용\n",
        "\n",
        "  - 합성곱 계층에는 `stride=1`, 활성화 함수로 `ReLU` 사용\n",
        "\n",
        "  - 특징 맵 깊이를 증가시킴\n",
        "\n",
        "  - 척도 변경을 통한 데이터 보강(Data Augmentation)\n",
        "\n",
        "\n",
        "\n",
        "- 기여\n",
        "\n",
        "  - 3x3 커널을 갖는 두 합성곱 계층을 쌓은 스택이 5x5 커널을 갖는 하나의 합성곱 계층과 동일한 수용영역(ERF)을 가짐\n",
        "\n",
        "  - 11x11 사이즈의 필터 크기를 가지는 AlexNet과 비교하여,  \n",
        "    더 작은 합성곱 계층을 더 많이 포함해 더 큰 ERF를 얻음\n",
        "\n",
        "  - 이와 같이 합성곱 계층의 개수가 많아지면,  \n",
        "    **매개변수 개수를 줄이고, 비선형성을 증가시킴**\n",
        "\n",
        "\n",
        "- VGG-19 아키텍쳐\n",
        "\n",
        "  - VGG-16에 3개의 합성곱 계층을 추가\n",
        "\n",
        "  <br>   \n",
        "\n",
        "  <img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16.png\">\n",
        "  <center>VGG-16 아키텍쳐</center>\n",
        "\n",
        "  <sub>[이미지 출처] https://neurohive.io/en/popular-networks/vgg16/ </sub>\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "- (참고) ILSVRC의 주요 분류 metric 중 하나는 `top-5`\n",
        "  \n",
        "  - 상위 5개 예측 안에 정확한 클래스가 포함되면 제대로 예측한 것으로 간주\n",
        "\n",
        "  - 일반적인 `top-k` metric의 특정 케이스\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ea52RHRWjSAs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "m1mnnxcilbdr"
      },
      "outputs": [],
      "source": [
        "def create_train_test_dirs(source_dir, test_size=.2):\n",
        "    \"\"\"\n",
        "    폴더 구조를 변경하는 함수\n",
        "    \"\"\"\n",
        "    path = os.path.join(os.getcwd(), 'data', source_dir)\n",
        "    translate = {\"cane\": \"dog\", \"cavallo\": \"horse\", \"elefante\": \"elephant\", \"farfalla\": \"butterfly\", \"gallina\": \"chicken\", \"gatto\": \"cat\", \"mucca\": \"cow\", \"pecora\": \"sheep\", \"ragno\": \"spider\", \"scoiattolo\": \"squirrel\"}\n",
        "    classes = [dir for dir in os.listdir(path) if os.path.isdir(os.path.join(path, dir))]\n",
        "\n",
        "    for cls in classes:\n",
        "        new_cls = translate.get(cls, cls)\n",
        "        data_splits = ['train', 'test']\n",
        "        \n",
        "        for split in data_splits:\n",
        "            os.makedirs(os.path.join(path, split, new_cls), exist_ok=True)\n",
        "        \n",
        "        files = [f for f in os.listdir(os.path.join(path, cls)) if os.path.isfile(os.path.join(path, cls, f))]\n",
        "        train_files, test_files = train_test_split(files, test_size=test_size, random_state=42)\n",
        "\n",
        "        for split, files in zip(data_splits, (train_files, test_files)):\n",
        "            for f in files:\n",
        "                src_f_path = os.path.join(path, cls, f)\n",
        "                dst_f_path = os.path.join(path, split, new_cls, f)\n",
        "                \n",
        "                if os.path.exists(dst_f_path):\n",
        "                    os.remove(dst_f_path)\n",
        "                \n",
        "                shutil.move(src_f_path, dst_f_path)\n",
        "        \n",
        "        os.rmdir(os.path.join(path, cls))\n",
        "\n",
        "source_dir = 'animals-10'\n",
        "\n",
        "create_train_test_dirs(source_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "fmQm2hVmUtD4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3890, 973)"
            ]
          },
          "execution_count": 189,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def cnt_imgs(source_dir, animal):\n",
        "    \"\"\"\n",
        "    제대로 분류 되었는지 확인하는 함수\n",
        "    \"\"\"\n",
        "    train_path = os.path.join(os.getcwd(), 'data', source_dir, 'train', animal)\n",
        "    test_path = os.path.join(os.getcwd(), 'data', source_dir, 'test', animal)\n",
        "\n",
        "    train_cnt = len([f for f in os.listdir(train_path) if os.path.isfile(os.path.join(train_path, f))])\n",
        "    test_cnt = len([f for f in os.listdir(test_path) if os.path.isfile(os.path.join(test_path, f))])\n",
        "    \n",
        "    return train_cnt, test_cnt\n",
        "\n",
        "train_cnt, test_cnt = cnt_imgs(source_dir, 'dog')\n",
        "\n",
        "train_cnt, test_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class VGGNet16(nn.Module):\n",
        "    \"\"\"\n",
        "    output의 차원은 데이터 특성상 10개로 설정\n",
        "    \"\"\"\n",
        "    def __init__(self, n_classes=10):\n",
        "        super().__init__()\n",
        "        self.n_classes = n_classes\n",
        "        \n",
        "        # Layers\n",
        "        self.conv1_1 = nn.Conv2d(\n",
        "            in_channels=3,\n",
        "            out_channels=64,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1)\n",
        "        )\n",
        "        self.conv1_2 = nn.Conv2d(\n",
        "            in_channels=64,\n",
        "            out_channels=64,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1)\n",
        "        )\n",
        "        \n",
        "        self.conv2_1 = nn.Conv2d(\n",
        "            in_channels=64,\n",
        "            out_channels=128,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1)\n",
        "        )\n",
        "        self.conv2_2 = nn.Conv2d(\n",
        "            in_channels=128,\n",
        "            out_channels=128,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1)\n",
        "        )\n",
        "        \n",
        "        self.conv3_1 = nn.Conv2d(\n",
        "            in_channels=128,\n",
        "            out_channels=256,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1)\n",
        "        )\n",
        "        self.conv3_2 = nn.Conv2d(\n",
        "            in_channels=256,\n",
        "            out_channels=256,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1)\n",
        "        )\n",
        "        self.conv3_3 = nn.Conv2d(\n",
        "            in_channels=256,\n",
        "            out_channels=256,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1)\n",
        "        )\n",
        "        \n",
        "        self.conv4_1 = nn.Conv2d(\n",
        "            in_channels=256,\n",
        "            out_channels=512,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1)\n",
        "        )\n",
        "        self.conv4_2 = nn.Conv2d(\n",
        "            in_channels=512,\n",
        "            out_channels=512,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1)\n",
        "        )\n",
        "        self.conv4_3 = nn.Conv2d(\n",
        "            in_channels=512,\n",
        "            out_channels=512,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1)\n",
        "        )\n",
        "        \n",
        "        self.conv5_1 = nn.Conv2d(\n",
        "            in_channels=512,\n",
        "            out_channels=512,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1)\n",
        "        )\n",
        "        self.conv5_2 = nn.Conv2d(\n",
        "            in_channels=512,\n",
        "            out_channels=512,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1)\n",
        "        )\n",
        "        self.conv5_3 = nn.Conv2d(\n",
        "            in_channels=512,\n",
        "            out_channels=512,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1)\n",
        "        )\n",
        "    \n",
        "        self.fc1 = nn.Linear(512 * 7 * 7, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "\n",
        "        self.out = nn.Linear(4096, self.n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1_1(x))\n",
        "        x = F.relu(self.conv1_2(x))\n",
        "        x = F.max_pool2d(x, kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
        "\n",
        "        x = F.relu(self.conv2_1(x))\n",
        "        x = F.relu(self.conv2_2(x))\n",
        "        x = F.max_pool2d(x, kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
        "    \n",
        "        x = F.relu(self.conv3_1(x))\n",
        "        x = F.relu(self.conv3_2(x))\n",
        "        x = F.relu(self.conv3_3(x))\n",
        "        x = F.max_pool2d(x, kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
        "        \n",
        "        x = F.relu(self.conv4_1(x))\n",
        "        x = F.relu(self.conv4_2(x))\n",
        "        x = F.relu(self.conv4_3(x))\n",
        "        x = F.max_pool2d(x, kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
        "        \n",
        "        x = F.relu(self.conv5_1(x))\n",
        "        x = F.relu(self.conv5_2(x))\n",
        "        x = F.relu(self.conv5_3(x))\n",
        "        x = F.max_pool2d(x, kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
        "\n",
        "        x = x.view(-1, self.n_flat_features(x))\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.out(x)\n",
        "        \n",
        "        return x\n",
        "        \n",
        "    def n_flat_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        n_features = 1\n",
        "        \n",
        "        for s in size:\n",
        "            n_features *= s\n",
        "        \n",
        "        return n_features\n",
        "    \n",
        "    @staticmethod\n",
        "    def init_params(m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "transform_temp = transforms.Compose([\n",
        "    transforms.RandomResizedCrop((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(root='./data/animals-10/train', transform=transform_temp)\n",
        "loader = DataLoader(dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.5084, 0.4803, 0.3970]) tensor([0.2634, 0.2589, 0.2705])\n"
          ]
        }
      ],
      "source": [
        "def calc_mean_std(loader: DataLoader):\n",
        "    sum, sq_sum, n_batches = 0, 0, 0\n",
        "    \n",
        "    for data, _ in loader:\n",
        "        sum += torch.mean(data, dim=[0, 2, 3])\n",
        "        sq_sum += torch.mean(data ** 2, dim=[0, 2, 3])\n",
        "        n_batches += 1\n",
        "    \n",
        "    mean = sum / n_batches\n",
        "    std = ((sq_sum / n_batches) - mean ** 2) ** .5\n",
        "    \n",
        "    return mean, std\n",
        "\n",
        "mean, std = calc_mean_std(loader)\n",
        "print(mean, std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(root=os.path.join(os.getcwd(), 'data', 'animals-10', 'train'), transform=transform)\n",
        "test_data = datasets.ImageFolder(root=os.path.join(os.getcwd(), 'data', 'animals-10', 'test'), transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = VGGNet16().to('cuda')\n",
        "model.apply(VGGNet16.init_params)\n",
        "\n",
        "epochs = 50\n",
        "lr = 1e-3\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model: nn.Module, train_loader: DataLoader, criterion: nn.modules.loss._Loss, optimizer: optim.Optimizer, scheduler: optim.lr_scheduler.StepLR, epochs: int):\n",
        "    model.train()\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        for idx, (inputs, labels) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            print(f'Epoch: {epoch + 1}, Step: {idx + 1}/{len(train_loader)}, Loss: {running_loss / (idx + 1):.6f}, Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "        scheduler.step()\n",
        "                \n",
        "def test(model: nn.Module, test_loader: DataLoader, criterion: nn.modules.loss._Loss):\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        t_loss = 0\n",
        "        correct = 0\n",
        "        \n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "            outputs = model(inputs)\n",
        "            pred_vals, pred_indices = torch.max(outputs, dim=1)\n",
        "            \n",
        "            t_loss += criterion(outputs, labels).item()\n",
        "            correct += pred_indices.eq(labels).sum().item()\n",
        "        \n",
        "        t_loss /= len(test_loader)\n",
        "        acc = correct / len(test_loader.dataset)\n",
        "    \n",
        "    print('Test')\n",
        "    print(f'Loss: {t_loss:.6f}, Accuracy: {acc * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Step: 1/655, Loss: 3.737157, Accuracy: 0.00%\n",
            "Epoch: 1, Step: 2/655, Loss: 2279.057055, Accuracy: 6.25%\n",
            "Epoch: 1, Step: 3/655, Loss: 1523.593024, Accuracy: 6.25%\n",
            "Epoch: 1, Step: 4/655, Loss: 1143.249146, Accuracy: 14.06%\n",
            "Epoch: 1, Step: 5/655, Loss: 915.063270, Accuracy: 14.38%\n",
            "Epoch: 1, Step: 6/655, Loss: 762.930701, Accuracy: 15.10%\n",
            "Epoch: 1, Step: 7/655, Loss: 654.275023, Accuracy: 15.18%\n",
            "Epoch: 1, Step: 8/655, Loss: 572.770497, Accuracy: 15.62%\n",
            "Epoch: 1, Step: 9/655, Loss: 509.377783, Accuracy: 15.97%\n",
            "Epoch: 1, Step: 10/655, Loss: 458.681549, Accuracy: 15.31%\n",
            "Epoch: 1, Step: 11/655, Loss: 417.187945, Accuracy: 15.62%\n",
            "Epoch: 1, Step: 12/655, Loss: 382.611864, Accuracy: 16.15%\n",
            "Epoch: 1, Step: 13/655, Loss: 353.353108, Accuracy: 16.11%\n",
            "Epoch: 1, Step: 14/655, Loss: 328.277294, Accuracy: 15.40%\n",
            "Epoch: 1, Step: 15/655, Loss: 306.542490, Accuracy: 15.21%\n",
            "Epoch: 1, Step: 16/655, Loss: 287.525944, Accuracy: 15.23%\n",
            "Epoch: 1, Step: 17/655, Loss: 270.743092, Accuracy: 14.89%\n",
            "Epoch: 1, Step: 18/655, Loss: 255.825310, Accuracy: 15.10%\n",
            "Epoch: 1, Step: 19/655, Loss: 242.484714, Accuracy: 14.97%\n",
            "Epoch: 1, Step: 20/655, Loss: 230.473437, Accuracy: 15.47%\n",
            "Epoch: 1, Step: 21/655, Loss: 219.607875, Accuracy: 15.33%\n",
            "Epoch: 1, Step: 22/655, Loss: 209.725683, Accuracy: 15.62%\n",
            "Epoch: 1, Step: 23/655, Loss: 200.705308, Accuracy: 15.62%\n",
            "Epoch: 1, Step: 24/655, Loss: 192.434810, Accuracy: 15.62%\n",
            "Epoch: 1, Step: 25/655, Loss: 184.824613, Accuracy: 15.75%\n",
            "Epoch: 1, Step: 26/655, Loss: 177.800199, Accuracy: 15.62%\n",
            "Epoch: 1, Step: 27/655, Loss: 171.302053, Accuracy: 15.51%\n",
            "Epoch: 1, Step: 28/655, Loss: 165.262196, Accuracy: 15.51%\n",
            "Epoch: 1, Step: 29/655, Loss: 159.638985, Accuracy: 16.06%\n",
            "Epoch: 1, Step: 30/655, Loss: 154.391530, Accuracy: 16.04%\n",
            "Epoch: 1, Step: 31/655, Loss: 149.483026, Accuracy: 15.93%\n",
            "Epoch: 1, Step: 32/655, Loss: 144.886280, Accuracy: 15.62%\n",
            "Epoch: 1, Step: 33/655, Loss: 140.564711, Accuracy: 15.81%\n",
            "Epoch: 1, Step: 34/655, Loss: 136.497062, Accuracy: 15.72%\n",
            "Epoch: 1, Step: 35/655, Loss: 132.660816, Accuracy: 15.98%\n",
            "Epoch: 1, Step: 36/655, Loss: 129.037063, Accuracy: 16.15%\n",
            "Epoch: 1, Step: 37/655, Loss: 125.609053, Accuracy: 16.30%\n",
            "Epoch: 1, Step: 38/655, Loss: 122.363798, Accuracy: 16.28%\n",
            "Epoch: 1, Step: 39/655, Loss: 119.282402, Accuracy: 16.27%\n",
            "Epoch: 1, Step: 40/655, Loss: 116.355796, Accuracy: 16.25%\n",
            "Epoch: 1, Step: 41/655, Loss: 113.568945, Accuracy: 16.62%\n",
            "Epoch: 1, Step: 42/655, Loss: 110.916054, Accuracy: 16.52%\n",
            "Epoch: 1, Step: 43/655, Loss: 108.387195, Accuracy: 16.57%\n",
            "Epoch: 1, Step: 44/655, Loss: 105.976230, Accuracy: 16.41%\n",
            "Epoch: 1, Step: 45/655, Loss: 103.671715, Accuracy: 16.32%\n",
            "Epoch: 1, Step: 46/655, Loss: 101.466830, Accuracy: 16.44%\n",
            "Epoch: 1, Step: 47/655, Loss: 99.355717, Accuracy: 16.49%\n",
            "Epoch: 1, Step: 48/655, Loss: 97.330565, Accuracy: 16.60%\n",
            "Epoch: 1, Step: 49/655, Loss: 95.388275, Accuracy: 16.84%\n",
            "Epoch: 1, Step: 50/655, Loss: 93.523975, Accuracy: 16.75%\n",
            "Epoch: 1, Step: 51/655, Loss: 91.733757, Accuracy: 16.79%\n",
            "Epoch: 1, Step: 52/655, Loss: 90.014572, Accuracy: 16.77%\n",
            "Epoch: 1, Step: 53/655, Loss: 88.357474, Accuracy: 16.98%\n",
            "Epoch: 1, Step: 54/655, Loss: 86.761748, Accuracy: 17.13%\n",
            "Epoch: 1, Step: 55/655, Loss: 85.223543, Accuracy: 17.27%\n",
            "Epoch: 1, Step: 56/655, Loss: 83.740469, Accuracy: 17.41%\n",
            "Epoch: 1, Step: 57/655, Loss: 82.309549, Accuracy: 17.54%\n",
            "Epoch: 1, Step: 58/655, Loss: 80.928137, Accuracy: 17.83%\n",
            "Epoch: 1, Step: 59/655, Loss: 79.592962, Accuracy: 17.85%\n",
            "Epoch: 1, Step: 60/655, Loss: 78.302438, Accuracy: 17.92%\n",
            "Epoch: 1, Step: 61/655, Loss: 77.054499, Accuracy: 17.88%\n",
            "Epoch: 1, Step: 62/655, Loss: 75.846239, Accuracy: 17.84%\n",
            "Epoch: 1, Step: 63/655, Loss: 74.677574, Accuracy: 17.86%\n",
            "Epoch: 1, Step: 64/655, Loss: 73.544948, Accuracy: 17.72%\n",
            "Epoch: 1, Step: 65/655, Loss: 72.446624, Accuracy: 17.93%\n",
            "Epoch: 1, Step: 66/655, Loss: 71.382808, Accuracy: 17.90%\n",
            "Epoch: 1, Step: 67/655, Loss: 70.349332, Accuracy: 17.82%\n",
            "Epoch: 1, Step: 68/655, Loss: 69.347376, Accuracy: 17.92%\n",
            "Epoch: 1, Step: 69/655, Loss: 68.373571, Accuracy: 17.98%\n",
            "Epoch: 1, Step: 70/655, Loss: 67.427682, Accuracy: 17.95%\n",
            "Epoch: 1, Step: 71/655, Loss: 66.509595, Accuracy: 17.91%\n",
            "Epoch: 1, Step: 72/655, Loss: 65.619663, Accuracy: 17.71%\n",
            "Epoch: 1, Step: 73/655, Loss: 64.749200, Accuracy: 17.77%\n",
            "Epoch: 1, Step: 74/655, Loss: 63.904202, Accuracy: 17.69%\n",
            "Epoch: 1, Step: 75/655, Loss: 63.083531, Accuracy: 17.46%\n",
            "Epoch: 1, Step: 76/655, Loss: 62.284366, Accuracy: 17.48%\n",
            "Epoch: 1, Step: 77/655, Loss: 61.504459, Accuracy: 17.49%\n",
            "Epoch: 1, Step: 78/655, Loss: 60.744250, Accuracy: 17.51%\n",
            "Epoch: 1, Step: 79/655, Loss: 60.004783, Accuracy: 17.37%\n",
            "Epoch: 1, Step: 80/655, Loss: 59.283368, Accuracy: 17.30%\n",
            "Epoch: 1, Step: 81/655, Loss: 58.578524, Accuracy: 17.36%\n",
            "Epoch: 1, Step: 82/655, Loss: 57.890509, Accuracy: 17.30%\n",
            "Epoch: 1, Step: 83/655, Loss: 57.219873, Accuracy: 17.51%\n",
            "Epoch: 1, Step: 84/655, Loss: 56.565763, Accuracy: 17.49%\n",
            "Epoch: 1, Step: 85/655, Loss: 55.926443, Accuracy: 17.50%\n",
            "Epoch: 1, Step: 86/655, Loss: 55.301640, Accuracy: 17.41%\n",
            "Epoch: 1, Step: 87/655, Loss: 54.690714, Accuracy: 17.56%\n",
            "Epoch: 1, Step: 88/655, Loss: 54.094286, Accuracy: 17.72%\n",
            "Epoch: 1, Step: 89/655, Loss: 53.512405, Accuracy: 17.66%\n",
            "Epoch: 1, Step: 90/655, Loss: 52.941889, Accuracy: 17.67%\n",
            "Epoch: 1, Step: 91/655, Loss: 52.384500, Accuracy: 17.72%\n",
            "Epoch: 1, Step: 92/655, Loss: 51.839438, Accuracy: 17.70%\n",
            "Epoch: 1, Step: 93/655, Loss: 51.307439, Accuracy: 17.57%\n",
            "Epoch: 1, Step: 94/655, Loss: 50.785307, Accuracy: 17.65%\n",
            "Epoch: 1, Step: 95/655, Loss: 50.273986, Accuracy: 17.70%\n",
            "Epoch: 1, Step: 96/655, Loss: 49.773544, Accuracy: 17.74%\n",
            "Epoch: 1, Step: 97/655, Loss: 49.282551, Accuracy: 17.75%\n",
            "Epoch: 1, Step: 98/655, Loss: 48.802662, Accuracy: 17.73%\n",
            "Epoch: 1, Step: 99/655, Loss: 48.331233, Accuracy: 17.71%\n",
            "Epoch: 1, Step: 100/655, Loss: 47.869965, Accuracy: 17.69%\n",
            "Epoch: 1, Step: 101/655, Loss: 47.417090, Accuracy: 17.70%\n",
            "Epoch: 1, Step: 102/655, Loss: 46.973990, Accuracy: 17.71%\n",
            "Epoch: 1, Step: 103/655, Loss: 46.539227, Accuracy: 17.69%\n",
            "Epoch: 1, Step: 104/655, Loss: 46.112339, Accuracy: 17.76%\n",
            "Epoch: 1, Step: 105/655, Loss: 45.695139, Accuracy: 17.77%\n",
            "Epoch: 1, Step: 106/655, Loss: 45.285288, Accuracy: 17.72%\n",
            "Epoch: 1, Step: 107/655, Loss: 44.883148, Accuracy: 17.73%\n",
            "Epoch: 1, Step: 108/655, Loss: 44.487342, Accuracy: 17.82%\n",
            "Epoch: 1, Step: 109/655, Loss: 44.098608, Accuracy: 17.95%\n",
            "Epoch: 1, Step: 110/655, Loss: 43.717978, Accuracy: 18.04%\n",
            "Epoch: 1, Step: 111/655, Loss: 43.343498, Accuracy: 18.05%\n",
            "Epoch: 1, Step: 112/655, Loss: 42.976635, Accuracy: 18.05%\n",
            "Epoch: 1, Step: 113/655, Loss: 42.616035, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 114/655, Loss: 42.261535, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 115/655, Loss: 41.914553, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 116/655, Loss: 41.572205, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 117/655, Loss: 41.235684, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 118/655, Loss: 40.904850, Accuracy: 18.25%\n",
            "Epoch: 1, Step: 119/655, Loss: 40.579509, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 120/655, Loss: 40.260305, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 121/655, Loss: 39.944763, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 122/655, Loss: 39.634121, Accuracy: 18.29%\n",
            "Epoch: 1, Step: 123/655, Loss: 39.330729, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 124/655, Loss: 39.031450, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 125/655, Loss: 38.736359, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 126/655, Loss: 38.445304, Accuracy: 18.28%\n",
            "Epoch: 1, Step: 127/655, Loss: 38.159803, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 128/655, Loss: 37.879565, Accuracy: 18.29%\n",
            "Epoch: 1, Step: 129/655, Loss: 37.604149, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 130/655, Loss: 37.332064, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 131/655, Loss: 37.063934, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 132/655, Loss: 36.800474, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 133/655, Loss: 36.540232, Accuracy: 18.07%\n",
            "Epoch: 1, Step: 134/655, Loss: 36.283718, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 135/655, Loss: 36.030354, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 136/655, Loss: 35.781892, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 137/655, Loss: 35.536727, Accuracy: 18.27%\n",
            "Epoch: 1, Step: 138/655, Loss: 35.295014, Accuracy: 18.27%\n",
            "Epoch: 1, Step: 139/655, Loss: 35.057356, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 140/655, Loss: 34.822984, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 141/655, Loss: 34.592099, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 142/655, Loss: 34.363841, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 143/655, Loss: 34.138849, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 144/655, Loss: 33.916831, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 145/655, Loss: 33.697974, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 146/655, Loss: 33.482453, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 147/655, Loss: 33.270753, Accuracy: 18.09%\n",
            "Epoch: 1, Step: 148/655, Loss: 33.060965, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 149/655, Loss: 32.854234, Accuracy: 18.06%\n",
            "Epoch: 1, Step: 150/655, Loss: 32.649755, Accuracy: 18.00%\n",
            "Epoch: 1, Step: 151/655, Loss: 32.447183, Accuracy: 18.09%\n",
            "Epoch: 1, Step: 152/655, Loss: 32.247741, Accuracy: 18.07%\n",
            "Epoch: 1, Step: 153/655, Loss: 32.051208, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 154/655, Loss: 31.856470, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 155/655, Loss: 31.665255, Accuracy: 18.25%\n",
            "Epoch: 1, Step: 156/655, Loss: 31.476259, Accuracy: 18.25%\n",
            "Epoch: 1, Step: 157/655, Loss: 31.290612, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 158/655, Loss: 31.106792, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 159/655, Loss: 30.925184, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 160/655, Loss: 30.745486, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 161/655, Loss: 30.568040, Accuracy: 18.30%\n",
            "Epoch: 1, Step: 162/655, Loss: 30.392891, Accuracy: 18.31%\n",
            "Epoch: 1, Step: 163/655, Loss: 30.218846, Accuracy: 18.37%\n",
            "Epoch: 1, Step: 164/655, Loss: 30.048161, Accuracy: 18.37%\n",
            "Epoch: 1, Step: 165/655, Loss: 29.879777, Accuracy: 18.33%\n",
            "Epoch: 1, Step: 166/655, Loss: 29.713116, Accuracy: 18.37%\n",
            "Epoch: 1, Step: 167/655, Loss: 29.548653, Accuracy: 18.34%\n",
            "Epoch: 1, Step: 168/655, Loss: 29.385145, Accuracy: 18.40%\n",
            "Epoch: 1, Step: 169/655, Loss: 29.224076, Accuracy: 18.38%\n",
            "Epoch: 1, Step: 170/655, Loss: 29.065205, Accuracy: 18.36%\n",
            "Epoch: 1, Step: 171/655, Loss: 28.908181, Accuracy: 18.33%\n",
            "Epoch: 1, Step: 172/655, Loss: 28.752122, Accuracy: 18.39%\n",
            "Epoch: 1, Step: 173/655, Loss: 28.599043, Accuracy: 18.37%\n",
            "Epoch: 1, Step: 174/655, Loss: 28.446666, Accuracy: 18.37%\n",
            "Epoch: 1, Step: 175/655, Loss: 28.296037, Accuracy: 18.38%\n",
            "Epoch: 1, Step: 176/655, Loss: 28.147104, Accuracy: 18.43%\n",
            "Epoch: 1, Step: 177/655, Loss: 28.000281, Accuracy: 18.50%\n",
            "Epoch: 1, Step: 178/655, Loss: 27.856119, Accuracy: 18.42%\n",
            "Epoch: 1, Step: 179/655, Loss: 27.713706, Accuracy: 18.40%\n",
            "Epoch: 1, Step: 180/655, Loss: 27.571998, Accuracy: 18.40%\n",
            "Epoch: 1, Step: 181/655, Loss: 27.431328, Accuracy: 18.40%\n",
            "Epoch: 1, Step: 182/655, Loss: 27.293102, Accuracy: 18.34%\n",
            "Epoch: 1, Step: 183/655, Loss: 27.156187, Accuracy: 18.34%\n",
            "Epoch: 1, Step: 184/655, Loss: 27.020678, Accuracy: 18.31%\n",
            "Epoch: 1, Step: 185/655, Loss: 26.887200, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 186/655, Loss: 26.754435, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 187/655, Loss: 26.623844, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 188/655, Loss: 26.494121, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 189/655, Loss: 26.366160, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 190/655, Loss: 26.239483, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 191/655, Loss: 26.113245, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 192/655, Loss: 25.989053, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 193/655, Loss: 25.865495, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 194/655, Loss: 25.743553, Accuracy: 18.25%\n",
            "Epoch: 1, Step: 195/655, Loss: 25.622783, Accuracy: 18.29%\n",
            "Epoch: 1, Step: 196/655, Loss: 25.503795, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 197/655, Loss: 25.385073, Accuracy: 18.27%\n",
            "Epoch: 1, Step: 198/655, Loss: 25.268825, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 199/655, Loss: 25.153384, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 200/655, Loss: 25.038294, Accuracy: 18.27%\n",
            "Epoch: 1, Step: 201/655, Loss: 24.924510, Accuracy: 18.28%\n",
            "Epoch: 1, Step: 202/655, Loss: 24.812107, Accuracy: 18.29%\n",
            "Epoch: 1, Step: 203/655, Loss: 24.700355, Accuracy: 18.30%\n",
            "Epoch: 1, Step: 204/655, Loss: 24.590301, Accuracy: 18.31%\n",
            "Epoch: 1, Step: 205/655, Loss: 24.481051, Accuracy: 18.29%\n",
            "Epoch: 1, Step: 206/655, Loss: 24.372930, Accuracy: 18.34%\n",
            "Epoch: 1, Step: 207/655, Loss: 24.265973, Accuracy: 18.28%\n",
            "Epoch: 1, Step: 208/655, Loss: 24.160014, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 209/655, Loss: 24.054791, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 210/655, Loss: 23.951608, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 211/655, Loss: 23.848695, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 212/655, Loss: 23.747318, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 213/655, Loss: 23.645914, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 214/655, Loss: 23.546121, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 215/655, Loss: 23.446854, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 216/655, Loss: 23.348330, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 217/655, Loss: 23.250973, Accuracy: 18.07%\n",
            "Epoch: 1, Step: 218/655, Loss: 23.153818, Accuracy: 18.09%\n",
            "Epoch: 1, Step: 219/655, Loss: 23.058584, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 220/655, Loss: 22.963958, Accuracy: 18.04%\n",
            "Epoch: 1, Step: 221/655, Loss: 22.870944, Accuracy: 18.04%\n",
            "Epoch: 1, Step: 222/655, Loss: 22.778116, Accuracy: 18.05%\n",
            "Epoch: 1, Step: 223/655, Loss: 22.685491, Accuracy: 18.04%\n",
            "Epoch: 1, Step: 224/655, Loss: 22.593832, Accuracy: 18.05%\n",
            "Epoch: 1, Step: 225/655, Loss: 22.503420, Accuracy: 18.03%\n",
            "Epoch: 1, Step: 226/655, Loss: 22.413957, Accuracy: 18.00%\n",
            "Epoch: 1, Step: 227/655, Loss: 22.324799, Accuracy: 18.01%\n",
            "Epoch: 1, Step: 228/655, Loss: 22.236561, Accuracy: 18.01%\n",
            "Epoch: 1, Step: 229/655, Loss: 22.149099, Accuracy: 18.03%\n",
            "Epoch: 1, Step: 230/655, Loss: 22.062658, Accuracy: 17.98%\n",
            "Epoch: 1, Step: 231/655, Loss: 21.977065, Accuracy: 17.95%\n",
            "Epoch: 1, Step: 232/655, Loss: 21.891595, Accuracy: 17.98%\n",
            "Epoch: 1, Step: 233/655, Loss: 21.807027, Accuracy: 17.93%\n",
            "Epoch: 1, Step: 234/655, Loss: 21.723168, Accuracy: 17.96%\n",
            "Epoch: 1, Step: 235/655, Loss: 21.640479, Accuracy: 17.91%\n",
            "Epoch: 1, Step: 236/655, Loss: 21.558227, Accuracy: 17.92%\n",
            "Epoch: 1, Step: 237/655, Loss: 21.476546, Accuracy: 17.93%\n",
            "Epoch: 1, Step: 238/655, Loss: 21.395312, Accuracy: 17.98%\n",
            "Epoch: 1, Step: 239/655, Loss: 21.315139, Accuracy: 17.95%\n",
            "Epoch: 1, Step: 240/655, Loss: 21.235041, Accuracy: 18.01%\n",
            "Epoch: 1, Step: 241/655, Loss: 21.156132, Accuracy: 18.01%\n",
            "Epoch: 1, Step: 242/655, Loss: 21.077663, Accuracy: 18.01%\n",
            "Epoch: 1, Step: 243/655, Loss: 21.000861, Accuracy: 17.95%\n",
            "Epoch: 1, Step: 244/655, Loss: 20.924219, Accuracy: 17.90%\n",
            "Epoch: 1, Step: 245/655, Loss: 20.847687, Accuracy: 17.93%\n",
            "Epoch: 1, Step: 246/655, Loss: 20.771906, Accuracy: 17.94%\n",
            "Epoch: 1, Step: 247/655, Loss: 20.696552, Accuracy: 17.99%\n",
            "Epoch: 1, Step: 248/655, Loss: 20.622038, Accuracy: 18.01%\n",
            "Epoch: 1, Step: 249/655, Loss: 20.547717, Accuracy: 18.00%\n",
            "Epoch: 1, Step: 250/655, Loss: 20.474514, Accuracy: 17.98%\n",
            "Epoch: 1, Step: 251/655, Loss: 20.401453, Accuracy: 18.02%\n",
            "Epoch: 1, Step: 252/655, Loss: 20.329460, Accuracy: 18.01%\n",
            "Epoch: 1, Step: 253/655, Loss: 20.257440, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 254/655, Loss: 20.186373, Accuracy: 18.09%\n",
            "Epoch: 1, Step: 255/655, Loss: 20.116378, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 256/655, Loss: 20.046830, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 257/655, Loss: 19.977355, Accuracy: 18.07%\n",
            "Epoch: 1, Step: 258/655, Loss: 19.908898, Accuracy: 18.05%\n",
            "Epoch: 1, Step: 259/655, Loss: 19.840651, Accuracy: 18.03%\n",
            "Epoch: 1, Step: 260/655, Loss: 19.772767, Accuracy: 18.05%\n",
            "Epoch: 1, Step: 261/655, Loss: 19.705716, Accuracy: 18.06%\n",
            "Epoch: 1, Step: 262/655, Loss: 19.638910, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 263/655, Loss: 19.573032, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 264/655, Loss: 19.507141, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 265/655, Loss: 19.441537, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 266/655, Loss: 19.376613, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 267/655, Loss: 19.312214, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 268/655, Loss: 19.248552, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 269/655, Loss: 19.185047, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 270/655, Loss: 19.122235, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 271/655, Loss: 19.059325, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 272/655, Loss: 18.997726, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 273/655, Loss: 18.936534, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 274/655, Loss: 18.875618, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 275/655, Loss: 18.814966, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 276/655, Loss: 18.754682, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 277/655, Loss: 18.694840, Accuracy: 18.25%\n",
            "Epoch: 1, Step: 278/655, Loss: 18.635376, Accuracy: 18.28%\n",
            "Epoch: 1, Step: 279/655, Loss: 18.576557, Accuracy: 18.25%\n",
            "Epoch: 1, Step: 280/655, Loss: 18.518307, Accuracy: 18.25%\n",
            "Epoch: 1, Step: 281/655, Loss: 18.460628, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 282/655, Loss: 18.403290, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 283/655, Loss: 18.345957, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 284/655, Loss: 18.289189, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 285/655, Loss: 18.232901, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 286/655, Loss: 18.177098, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 287/655, Loss: 18.121722, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 288/655, Loss: 18.066633, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 289/655, Loss: 18.012294, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 290/655, Loss: 17.957576, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 291/655, Loss: 17.903568, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 292/655, Loss: 17.850028, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 293/655, Loss: 17.796473, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 294/655, Loss: 17.743394, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 295/655, Loss: 17.690191, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 296/655, Loss: 17.638197, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 297/655, Loss: 17.586277, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 298/655, Loss: 17.534259, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 299/655, Loss: 17.483107, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 300/655, Loss: 17.432166, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 301/655, Loss: 17.382198, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 302/655, Loss: 17.332301, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 303/655, Loss: 17.282613, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 304/655, Loss: 17.233034, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 305/655, Loss: 17.183680, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 306/655, Loss: 17.134321, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 307/655, Loss: 17.085681, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 308/655, Loss: 17.037520, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 309/655, Loss: 16.989187, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 310/655, Loss: 16.941698, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 311/655, Loss: 16.894445, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 312/655, Loss: 16.847174, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 313/655, Loss: 16.800611, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 314/655, Loss: 16.754079, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 315/655, Loss: 16.708246, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 316/655, Loss: 16.662253, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 317/655, Loss: 16.616757, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 318/655, Loss: 16.571551, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 319/655, Loss: 16.526672, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 320/655, Loss: 16.482057, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 321/655, Loss: 16.437500, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 322/655, Loss: 16.393304, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 323/655, Loss: 16.349219, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 324/655, Loss: 16.305598, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 325/655, Loss: 16.262247, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 326/655, Loss: 16.218873, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 327/655, Loss: 16.176522, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 328/655, Loss: 16.134020, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 329/655, Loss: 16.091851, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 330/655, Loss: 16.050144, Accuracy: 18.06%\n",
            "Epoch: 1, Step: 331/655, Loss: 16.008381, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 332/655, Loss: 15.966487, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 333/655, Loss: 15.925260, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 334/655, Loss: 15.884079, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 335/655, Loss: 15.843391, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 336/655, Loss: 15.803201, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 337/655, Loss: 15.762919, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 338/655, Loss: 15.722558, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 339/655, Loss: 15.682756, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 340/655, Loss: 15.643269, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 341/655, Loss: 15.603970, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 342/655, Loss: 15.564865, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 343/655, Loss: 15.525715, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 344/655, Loss: 15.487105, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 345/655, Loss: 15.448362, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 346/655, Loss: 15.409879, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 347/655, Loss: 15.372125, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 348/655, Loss: 15.334524, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 349/655, Loss: 15.296817, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 350/655, Loss: 15.259649, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 351/655, Loss: 15.222258, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 352/655, Loss: 15.185008, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 353/655, Loss: 15.148157, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 354/655, Loss: 15.111773, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 355/655, Loss: 15.075194, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 356/655, Loss: 15.039105, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 357/655, Loss: 15.003257, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 358/655, Loss: 14.967433, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 359/655, Loss: 14.931964, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 360/655, Loss: 14.896841, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 361/655, Loss: 14.861792, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 362/655, Loss: 14.827035, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 363/655, Loss: 14.792918, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 364/655, Loss: 14.758258, Accuracy: 18.07%\n",
            "Epoch: 1, Step: 365/655, Loss: 14.723662, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 366/655, Loss: 14.689598, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 367/655, Loss: 14.655384, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 368/655, Loss: 14.621748, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 369/655, Loss: 14.588052, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 370/655, Loss: 14.554371, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 371/655, Loss: 14.520952, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 372/655, Loss: 14.487778, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 373/655, Loss: 14.454445, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 374/655, Loss: 14.422132, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 375/655, Loss: 14.389558, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 376/655, Loss: 14.357374, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 377/655, Loss: 14.325232, Accuracy: 18.06%\n",
            "Epoch: 1, Step: 378/655, Loss: 14.293077, Accuracy: 18.07%\n",
            "Epoch: 1, Step: 379/655, Loss: 14.261469, Accuracy: 18.06%\n",
            "Epoch: 1, Step: 380/655, Loss: 14.229223, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 381/655, Loss: 14.197692, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 382/655, Loss: 14.166639, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 383/655, Loss: 14.135426, Accuracy: 18.09%\n",
            "Epoch: 1, Step: 384/655, Loss: 14.104847, Accuracy: 18.05%\n",
            "Epoch: 1, Step: 385/655, Loss: 14.073964, Accuracy: 18.04%\n",
            "Epoch: 1, Step: 386/655, Loss: 14.042938, Accuracy: 18.07%\n",
            "Epoch: 1, Step: 387/655, Loss: 14.012562, Accuracy: 18.06%\n",
            "Epoch: 1, Step: 388/655, Loss: 13.982283, Accuracy: 18.04%\n",
            "Epoch: 1, Step: 389/655, Loss: 13.952188, Accuracy: 18.03%\n",
            "Epoch: 1, Step: 390/655, Loss: 13.921681, Accuracy: 18.05%\n",
            "Epoch: 1, Step: 391/655, Loss: 13.891540, Accuracy: 18.04%\n",
            "Epoch: 1, Step: 392/655, Loss: 13.861763, Accuracy: 18.03%\n",
            "Epoch: 1, Step: 393/655, Loss: 13.831913, Accuracy: 18.06%\n",
            "Epoch: 1, Step: 394/655, Loss: 13.802352, Accuracy: 18.07%\n",
            "Epoch: 1, Step: 395/655, Loss: 13.772754, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 396/655, Loss: 13.743542, Accuracy: 18.09%\n",
            "Epoch: 1, Step: 397/655, Loss: 13.714292, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 398/655, Loss: 13.685103, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 399/655, Loss: 13.656276, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 400/655, Loss: 13.627773, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 401/655, Loss: 13.599060, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 402/655, Loss: 13.570646, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 403/655, Loss: 13.542150, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 404/655, Loss: 13.513955, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 405/655, Loss: 13.485931, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 406/655, Loss: 13.457912, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 407/655, Loss: 13.430455, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 408/655, Loss: 13.402870, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 409/655, Loss: 13.376143, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 410/655, Loss: 13.349149, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 411/655, Loss: 13.322264, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 412/655, Loss: 13.295218, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 413/655, Loss: 13.268355, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 414/655, Loss: 13.241220, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 415/655, Loss: 13.214623, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 416/655, Loss: 13.188177, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 417/655, Loss: 13.161628, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 418/655, Loss: 13.135538, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 419/655, Loss: 13.109567, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 420/655, Loss: 13.083894, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 421/655, Loss: 13.058183, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 422/655, Loss: 13.032437, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 423/655, Loss: 13.006536, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 424/655, Loss: 12.981158, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 425/655, Loss: 12.955597, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 426/655, Loss: 12.930444, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 427/655, Loss: 12.905180, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 428/655, Loss: 12.880008, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 429/655, Loss: 12.855079, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 430/655, Loss: 12.830469, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 431/655, Loss: 12.805636, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 432/655, Loss: 12.781215, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 433/655, Loss: 12.757071, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 434/655, Loss: 12.732936, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 435/655, Loss: 12.708615, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 436/655, Loss: 12.684528, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 437/655, Loss: 12.660374, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 438/655, Loss: 12.636758, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 439/655, Loss: 12.613102, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 440/655, Loss: 12.589404, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 441/655, Loss: 12.565890, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 442/655, Loss: 12.542412, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 443/655, Loss: 12.519426, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 444/655, Loss: 12.496187, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 445/655, Loss: 12.473227, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 446/655, Loss: 12.450437, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 447/655, Loss: 12.427733, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 448/655, Loss: 12.404889, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 449/655, Loss: 12.382383, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 450/655, Loss: 12.359467, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 451/655, Loss: 12.336902, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 452/655, Loss: 12.314548, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 453/655, Loss: 12.292534, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 454/655, Loss: 12.270321, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 455/655, Loss: 12.248019, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 456/655, Loss: 12.225876, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 457/655, Loss: 12.204100, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 458/655, Loss: 12.182024, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 459/655, Loss: 12.160247, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 460/655, Loss: 12.138553, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 461/655, Loss: 12.117284, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 462/655, Loss: 12.095698, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 463/655, Loss: 12.074342, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 464/655, Loss: 12.053222, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 465/655, Loss: 12.031902, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 466/655, Loss: 12.010803, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 467/655, Loss: 11.989673, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 468/655, Loss: 11.968949, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 469/655, Loss: 11.948315, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 470/655, Loss: 11.927831, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 471/655, Loss: 11.907213, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 472/655, Loss: 11.886927, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 473/655, Loss: 11.866388, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 474/655, Loss: 11.846108, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 475/655, Loss: 11.825880, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 476/655, Loss: 11.805891, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 477/655, Loss: 11.785622, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 478/655, Loss: 11.765651, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 479/655, Loss: 11.745627, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 480/655, Loss: 11.725886, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 481/655, Loss: 11.706004, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 482/655, Loss: 11.686383, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 483/655, Loss: 11.666674, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 484/655, Loss: 11.647268, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 485/655, Loss: 11.627784, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 486/655, Loss: 11.608249, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 487/655, Loss: 11.588780, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 488/655, Loss: 11.569600, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 489/655, Loss: 11.550372, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 490/655, Loss: 11.531457, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 491/655, Loss: 11.512469, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 492/655, Loss: 11.493590, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 493/655, Loss: 11.474675, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 494/655, Loss: 11.455654, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 495/655, Loss: 11.437292, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 496/655, Loss: 11.418438, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 497/655, Loss: 11.399838, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 498/655, Loss: 11.381456, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 499/655, Loss: 11.363078, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 500/655, Loss: 11.345050, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 501/655, Loss: 11.326740, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 502/655, Loss: 11.308863, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 503/655, Loss: 11.290822, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 504/655, Loss: 11.272800, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 505/655, Loss: 11.254752, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 506/655, Loss: 11.236926, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 507/655, Loss: 11.219245, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 508/655, Loss: 11.201390, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 509/655, Loss: 11.183594, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 510/655, Loss: 11.165744, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 511/655, Loss: 11.148440, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 512/655, Loss: 11.131120, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 513/655, Loss: 11.113807, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 514/655, Loss: 11.096168, Accuracy: 18.15%\n",
            "Epoch: 1, Step: 515/655, Loss: 11.078946, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 516/655, Loss: 11.061586, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 517/655, Loss: 11.044723, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 518/655, Loss: 11.027809, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 519/655, Loss: 11.010745, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 520/655, Loss: 10.993810, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 521/655, Loss: 10.977041, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 522/655, Loss: 10.960508, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 523/655, Loss: 10.943716, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 524/655, Loss: 10.927024, Accuracy: 18.10%\n",
            "Epoch: 1, Step: 525/655, Loss: 10.910593, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 526/655, Loss: 10.893954, Accuracy: 18.08%\n",
            "Epoch: 1, Step: 527/655, Loss: 10.877264, Accuracy: 18.09%\n",
            "Epoch: 1, Step: 528/655, Loss: 10.860967, Accuracy: 18.09%\n",
            "Epoch: 1, Step: 529/655, Loss: 10.844474, Accuracy: 18.09%\n",
            "Epoch: 1, Step: 530/655, Loss: 10.828088, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 531/655, Loss: 10.811668, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 532/655, Loss: 10.795498, Accuracy: 18.11%\n",
            "Epoch: 1, Step: 533/655, Loss: 10.779204, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 534/655, Loss: 10.763186, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 535/655, Loss: 10.747234, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 536/655, Loss: 10.731297, Accuracy: 18.12%\n",
            "Epoch: 1, Step: 537/655, Loss: 10.715524, Accuracy: 18.13%\n",
            "Epoch: 1, Step: 538/655, Loss: 10.699687, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 539/655, Loss: 10.683996, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 540/655, Loss: 10.668190, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 541/655, Loss: 10.652207, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 542/655, Loss: 10.636648, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 543/655, Loss: 10.621033, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 544/655, Loss: 10.605687, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 545/655, Loss: 10.590239, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 546/655, Loss: 10.574853, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 547/655, Loss: 10.559549, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 548/655, Loss: 10.544355, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 549/655, Loss: 10.529163, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 550/655, Loss: 10.513911, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 551/655, Loss: 10.498847, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 552/655, Loss: 10.483879, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 553/655, Loss: 10.468872, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 554/655, Loss: 10.453961, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 555/655, Loss: 10.439097, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 556/655, Loss: 10.424375, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 557/655, Loss: 10.409081, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 558/655, Loss: 10.394264, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 559/655, Loss: 10.379659, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 560/655, Loss: 10.364837, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 561/655, Loss: 10.350360, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 562/655, Loss: 10.335613, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 563/655, Loss: 10.321492, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 564/655, Loss: 10.307277, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 565/655, Loss: 10.292865, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 566/655, Loss: 10.278642, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 567/655, Loss: 10.264167, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 568/655, Loss: 10.249841, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 569/655, Loss: 10.235792, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 570/655, Loss: 10.221947, Accuracy: 18.25%\n",
            "Epoch: 1, Step: 571/655, Loss: 10.208025, Accuracy: 18.25%\n",
            "Epoch: 1, Step: 572/655, Loss: 10.194319, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 573/655, Loss: 10.180310, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 574/655, Loss: 10.166714, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 575/655, Loss: 10.153041, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 576/655, Loss: 10.139241, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 577/655, Loss: 10.125545, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 578/655, Loss: 10.112014, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 579/655, Loss: 10.098330, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 580/655, Loss: 10.084832, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 581/655, Loss: 10.071316, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 582/655, Loss: 10.057785, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 583/655, Loss: 10.044307, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 584/655, Loss: 10.030886, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 585/655, Loss: 10.017597, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 586/655, Loss: 10.004086, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 587/655, Loss: 9.990751, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 588/655, Loss: 9.977471, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 589/655, Loss: 9.964358, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 590/655, Loss: 9.951229, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 591/655, Loss: 9.938194, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 592/655, Loss: 9.925071, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 593/655, Loss: 9.912312, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 594/655, Loss: 9.899346, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 595/655, Loss: 9.886410, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 596/655, Loss: 9.873696, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 597/655, Loss: 9.860769, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 598/655, Loss: 9.847983, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 599/655, Loss: 9.835203, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 600/655, Loss: 9.822490, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 601/655, Loss: 9.809951, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 602/655, Loss: 9.797297, Accuracy: 18.14%\n",
            "Epoch: 1, Step: 603/655, Loss: 9.784665, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 604/655, Loss: 9.772057, Accuracy: 18.16%\n",
            "Epoch: 1, Step: 605/655, Loss: 9.759440, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 606/655, Loss: 9.746947, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 607/655, Loss: 9.734438, Accuracy: 18.20%\n",
            "Epoch: 1, Step: 608/655, Loss: 9.722105, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 609/655, Loss: 9.709705, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 610/655, Loss: 9.697353, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 611/655, Loss: 9.685008, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 612/655, Loss: 9.672869, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 613/655, Loss: 9.660577, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 614/655, Loss: 9.648508, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 615/655, Loss: 9.636634, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 616/655, Loss: 9.624277, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 617/655, Loss: 9.612329, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 618/655, Loss: 9.600321, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 619/655, Loss: 9.588413, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 620/655, Loss: 9.576239, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 621/655, Loss: 9.564097, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 622/655, Loss: 9.552041, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 623/655, Loss: 9.540342, Accuracy: 18.25%\n",
            "Epoch: 1, Step: 624/655, Loss: 9.528625, Accuracy: 18.25%\n",
            "Epoch: 1, Step: 625/655, Loss: 9.517106, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 626/655, Loss: 9.505494, Accuracy: 18.25%\n",
            "Epoch: 1, Step: 627/655, Loss: 9.493795, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 628/655, Loss: 9.481991, Accuracy: 18.27%\n",
            "Epoch: 1, Step: 629/655, Loss: 9.470354, Accuracy: 18.29%\n",
            "Epoch: 1, Step: 630/655, Loss: 9.458542, Accuracy: 18.29%\n",
            "Epoch: 1, Step: 631/655, Loss: 9.447171, Accuracy: 18.30%\n",
            "Epoch: 1, Step: 632/655, Loss: 9.435741, Accuracy: 18.30%\n",
            "Epoch: 1, Step: 633/655, Loss: 9.424472, Accuracy: 18.28%\n",
            "Epoch: 1, Step: 634/655, Loss: 9.413034, Accuracy: 18.28%\n",
            "Epoch: 1, Step: 635/655, Loss: 9.401914, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 636/655, Loss: 9.390658, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 637/655, Loss: 9.379286, Accuracy: 18.26%\n",
            "Epoch: 1, Step: 638/655, Loss: 9.368106, Accuracy: 18.25%\n",
            "Epoch: 1, Step: 639/655, Loss: 9.357055, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 640/655, Loss: 9.345804, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 641/655, Loss: 9.334585, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 642/655, Loss: 9.323558, Accuracy: 18.23%\n",
            "Epoch: 1, Step: 643/655, Loss: 9.312470, Accuracy: 18.24%\n",
            "Epoch: 1, Step: 644/655, Loss: 9.301556, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 645/655, Loss: 9.290568, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 646/655, Loss: 9.279298, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 647/655, Loss: 9.268373, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 648/655, Loss: 9.257451, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 649/655, Loss: 9.246736, Accuracy: 18.22%\n",
            "Epoch: 1, Step: 650/655, Loss: 9.235977, Accuracy: 18.21%\n",
            "Epoch: 1, Step: 651/655, Loss: 9.225296, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 652/655, Loss: 9.214595, Accuracy: 18.19%\n",
            "Epoch: 1, Step: 653/655, Loss: 9.204032, Accuracy: 18.18%\n",
            "Epoch: 1, Step: 654/655, Loss: 9.193367, Accuracy: 18.17%\n",
            "Epoch: 1, Step: 655/655, Loss: 9.182934, Accuracy: 18.17%\n",
            "Epoch: 2, Step: 1/655, Loss: 2.305083, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 2/655, Loss: 2.301845, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 3/655, Loss: 2.269729, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 4/655, Loss: 2.268726, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 5/655, Loss: 2.255483, Accuracy: 20.00%\n",
            "Epoch: 2, Step: 6/655, Loss: 2.256551, Accuracy: 20.31%\n",
            "Epoch: 2, Step: 7/655, Loss: 2.252286, Accuracy: 20.54%\n",
            "Epoch: 2, Step: 8/655, Loss: 2.253920, Accuracy: 20.31%\n",
            "Epoch: 2, Step: 9/655, Loss: 2.251454, Accuracy: 19.79%\n",
            "Epoch: 2, Step: 10/655, Loss: 2.248141, Accuracy: 19.38%\n",
            "Epoch: 2, Step: 11/655, Loss: 2.255020, Accuracy: 18.18%\n",
            "Epoch: 2, Step: 12/655, Loss: 2.247922, Accuracy: 19.27%\n",
            "Epoch: 2, Step: 13/655, Loss: 2.242992, Accuracy: 19.23%\n",
            "Epoch: 2, Step: 14/655, Loss: 2.244166, Accuracy: 19.64%\n",
            "Epoch: 2, Step: 15/655, Loss: 2.240507, Accuracy: 19.58%\n",
            "Epoch: 2, Step: 16/655, Loss: 2.238128, Accuracy: 19.73%\n",
            "Epoch: 2, Step: 17/655, Loss: 2.238975, Accuracy: 19.12%\n",
            "Epoch: 2, Step: 18/655, Loss: 2.236809, Accuracy: 19.27%\n",
            "Epoch: 2, Step: 19/655, Loss: 2.235805, Accuracy: 19.74%\n",
            "Epoch: 2, Step: 20/655, Loss: 2.234477, Accuracy: 19.69%\n",
            "Epoch: 2, Step: 21/655, Loss: 2.234959, Accuracy: 19.49%\n",
            "Epoch: 2, Step: 22/655, Loss: 2.233944, Accuracy: 19.03%\n",
            "Epoch: 2, Step: 23/655, Loss: 2.235537, Accuracy: 19.02%\n",
            "Epoch: 2, Step: 24/655, Loss: 2.236378, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 25/655, Loss: 2.238604, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 26/655, Loss: 2.231466, Accuracy: 19.83%\n",
            "Epoch: 2, Step: 27/655, Loss: 2.227920, Accuracy: 19.68%\n",
            "Epoch: 2, Step: 28/655, Loss: 2.225745, Accuracy: 19.42%\n",
            "Epoch: 2, Step: 29/655, Loss: 2.222444, Accuracy: 19.40%\n",
            "Epoch: 2, Step: 30/655, Loss: 2.224680, Accuracy: 19.38%\n",
            "Epoch: 2, Step: 31/655, Loss: 2.222351, Accuracy: 19.56%\n",
            "Epoch: 2, Step: 32/655, Loss: 2.222694, Accuracy: 19.53%\n",
            "Epoch: 2, Step: 33/655, Loss: 2.222388, Accuracy: 19.51%\n",
            "Epoch: 2, Step: 34/655, Loss: 2.219927, Accuracy: 19.30%\n",
            "Epoch: 2, Step: 35/655, Loss: 2.219815, Accuracy: 19.38%\n",
            "Epoch: 2, Step: 36/655, Loss: 2.213300, Accuracy: 19.88%\n",
            "Epoch: 2, Step: 37/655, Loss: 2.210669, Accuracy: 20.02%\n",
            "Epoch: 2, Step: 38/655, Loss: 2.214199, Accuracy: 19.90%\n",
            "Epoch: 2, Step: 39/655, Loss: 2.213961, Accuracy: 19.71%\n",
            "Epoch: 2, Step: 40/655, Loss: 2.212969, Accuracy: 19.84%\n",
            "Epoch: 2, Step: 41/655, Loss: 2.209891, Accuracy: 19.97%\n",
            "Epoch: 2, Step: 42/655, Loss: 2.211057, Accuracy: 19.87%\n",
            "Epoch: 2, Step: 43/655, Loss: 2.207615, Accuracy: 20.35%\n",
            "Epoch: 2, Step: 44/655, Loss: 2.211874, Accuracy: 20.17%\n",
            "Epoch: 2, Step: 45/655, Loss: 2.211318, Accuracy: 20.21%\n",
            "Epoch: 2, Step: 46/655, Loss: 2.208400, Accuracy: 20.45%\n",
            "Epoch: 2, Step: 47/655, Loss: 2.208624, Accuracy: 20.28%\n",
            "Epoch: 2, Step: 48/655, Loss: 2.209308, Accuracy: 20.25%\n",
            "Epoch: 2, Step: 49/655, Loss: 2.206976, Accuracy: 20.28%\n",
            "Epoch: 2, Step: 50/655, Loss: 2.203189, Accuracy: 20.44%\n",
            "Epoch: 2, Step: 51/655, Loss: 2.202874, Accuracy: 20.34%\n",
            "Epoch: 2, Step: 52/655, Loss: 2.200113, Accuracy: 20.55%\n",
            "Epoch: 2, Step: 53/655, Loss: 2.200087, Accuracy: 20.58%\n",
            "Epoch: 2, Step: 54/655, Loss: 2.198341, Accuracy: 20.54%\n",
            "Epoch: 2, Step: 55/655, Loss: 2.199073, Accuracy: 20.40%\n",
            "Epoch: 2, Step: 56/655, Loss: 2.200940, Accuracy: 20.31%\n",
            "Epoch: 2, Step: 57/655, Loss: 2.200552, Accuracy: 20.34%\n",
            "Epoch: 2, Step: 58/655, Loss: 2.201119, Accuracy: 20.37%\n",
            "Epoch: 2, Step: 59/655, Loss: 2.199377, Accuracy: 20.66%\n",
            "Epoch: 2, Step: 60/655, Loss: 2.201146, Accuracy: 20.62%\n",
            "Epoch: 2, Step: 61/655, Loss: 2.201051, Accuracy: 20.59%\n",
            "Epoch: 2, Step: 62/655, Loss: 2.200758, Accuracy: 20.67%\n",
            "Epoch: 2, Step: 63/655, Loss: 2.201770, Accuracy: 20.49%\n",
            "Epoch: 2, Step: 64/655, Loss: 2.200771, Accuracy: 20.61%\n",
            "Epoch: 2, Step: 65/655, Loss: 2.201837, Accuracy: 20.43%\n",
            "Epoch: 2, Step: 66/655, Loss: 2.202312, Accuracy: 20.41%\n",
            "Epoch: 2, Step: 67/655, Loss: 2.202237, Accuracy: 20.52%\n",
            "Epoch: 2, Step: 68/655, Loss: 2.202962, Accuracy: 20.50%\n",
            "Epoch: 2, Step: 69/655, Loss: 2.203256, Accuracy: 20.38%\n",
            "Epoch: 2, Step: 70/655, Loss: 2.203739, Accuracy: 20.22%\n",
            "Epoch: 2, Step: 71/655, Loss: 2.204252, Accuracy: 20.16%\n",
            "Epoch: 2, Step: 72/655, Loss: 2.204851, Accuracy: 20.10%\n",
            "Epoch: 2, Step: 73/655, Loss: 2.204136, Accuracy: 20.12%\n",
            "Epoch: 2, Step: 74/655, Loss: 2.205068, Accuracy: 20.02%\n",
            "Epoch: 2, Step: 75/655, Loss: 2.204920, Accuracy: 19.96%\n",
            "Epoch: 2, Step: 76/655, Loss: 2.203174, Accuracy: 20.07%\n",
            "Epoch: 2, Step: 77/655, Loss: 2.205440, Accuracy: 19.85%\n",
            "Epoch: 2, Step: 78/655, Loss: 2.206400, Accuracy: 19.71%\n",
            "Epoch: 2, Step: 79/655, Loss: 2.207679, Accuracy: 19.50%\n",
            "Epoch: 2, Step: 80/655, Loss: 2.207811, Accuracy: 19.49%\n",
            "Epoch: 2, Step: 81/655, Loss: 2.207998, Accuracy: 19.41%\n",
            "Epoch: 2, Step: 82/655, Loss: 2.208714, Accuracy: 19.32%\n",
            "Epoch: 2, Step: 83/655, Loss: 2.208301, Accuracy: 19.31%\n",
            "Epoch: 2, Step: 84/655, Loss: 2.208774, Accuracy: 19.31%\n",
            "Epoch: 2, Step: 85/655, Loss: 2.208481, Accuracy: 19.34%\n",
            "Epoch: 2, Step: 86/655, Loss: 2.207923, Accuracy: 19.30%\n",
            "Epoch: 2, Step: 87/655, Loss: 2.207431, Accuracy: 19.32%\n",
            "Epoch: 2, Step: 88/655, Loss: 2.207516, Accuracy: 19.42%\n",
            "Epoch: 2, Step: 89/655, Loss: 2.208005, Accuracy: 19.38%\n",
            "Epoch: 2, Step: 90/655, Loss: 2.207101, Accuracy: 19.55%\n",
            "Epoch: 2, Step: 91/655, Loss: 2.207417, Accuracy: 19.57%\n",
            "Epoch: 2, Step: 92/655, Loss: 2.209087, Accuracy: 19.50%\n",
            "Epoch: 2, Step: 93/655, Loss: 2.208844, Accuracy: 19.52%\n",
            "Epoch: 2, Step: 94/655, Loss: 2.207903, Accuracy: 19.55%\n",
            "Epoch: 2, Step: 95/655, Loss: 2.208369, Accuracy: 19.47%\n",
            "Epoch: 2, Step: 96/655, Loss: 2.208533, Accuracy: 19.50%\n",
            "Epoch: 2, Step: 97/655, Loss: 2.210083, Accuracy: 19.49%\n",
            "Epoch: 2, Step: 98/655, Loss: 2.209547, Accuracy: 19.42%\n",
            "Epoch: 2, Step: 99/655, Loss: 2.211003, Accuracy: 19.38%\n",
            "Epoch: 2, Step: 100/655, Loss: 2.210873, Accuracy: 19.38%\n",
            "Epoch: 2, Step: 101/655, Loss: 2.210922, Accuracy: 19.31%\n",
            "Epoch: 2, Step: 102/655, Loss: 2.210831, Accuracy: 19.27%\n",
            "Epoch: 2, Step: 103/655, Loss: 2.211339, Accuracy: 19.24%\n",
            "Epoch: 2, Step: 104/655, Loss: 2.209838, Accuracy: 19.32%\n",
            "Epoch: 2, Step: 105/655, Loss: 2.209878, Accuracy: 19.29%\n",
            "Epoch: 2, Step: 106/655, Loss: 2.210238, Accuracy: 19.34%\n",
            "Epoch: 2, Step: 107/655, Loss: 2.211188, Accuracy: 19.28%\n",
            "Epoch: 2, Step: 108/655, Loss: 2.211484, Accuracy: 19.24%\n",
            "Epoch: 2, Step: 109/655, Loss: 2.211111, Accuracy: 19.32%\n",
            "Epoch: 2, Step: 110/655, Loss: 2.210407, Accuracy: 19.23%\n",
            "Epoch: 2, Step: 111/655, Loss: 2.209980, Accuracy: 19.17%\n",
            "Epoch: 2, Step: 112/655, Loss: 2.210190, Accuracy: 19.20%\n",
            "Epoch: 2, Step: 113/655, Loss: 2.209995, Accuracy: 19.28%\n",
            "Epoch: 2, Step: 114/655, Loss: 2.209528, Accuracy: 19.27%\n",
            "Epoch: 2, Step: 115/655, Loss: 2.208897, Accuracy: 19.35%\n",
            "Epoch: 2, Step: 116/655, Loss: 2.208297, Accuracy: 19.40%\n",
            "Epoch: 2, Step: 117/655, Loss: 2.207784, Accuracy: 19.39%\n",
            "Epoch: 2, Step: 118/655, Loss: 2.206752, Accuracy: 19.41%\n",
            "Epoch: 2, Step: 119/655, Loss: 2.206320, Accuracy: 19.54%\n",
            "Epoch: 2, Step: 120/655, Loss: 2.207673, Accuracy: 19.45%\n",
            "Epoch: 2, Step: 121/655, Loss: 2.207954, Accuracy: 19.47%\n",
            "Epoch: 2, Step: 122/655, Loss: 2.207515, Accuracy: 19.49%\n",
            "Epoch: 2, Step: 123/655, Loss: 2.207496, Accuracy: 19.46%\n",
            "Epoch: 2, Step: 124/655, Loss: 2.207888, Accuracy: 19.46%\n",
            "Epoch: 2, Step: 125/655, Loss: 2.207679, Accuracy: 19.48%\n",
            "Epoch: 2, Step: 126/655, Loss: 2.206752, Accuracy: 19.49%\n",
            "Epoch: 2, Step: 127/655, Loss: 2.206104, Accuracy: 19.56%\n",
            "Epoch: 2, Step: 128/655, Loss: 2.205792, Accuracy: 19.51%\n",
            "Epoch: 2, Step: 129/655, Loss: 2.205586, Accuracy: 19.50%\n",
            "Epoch: 2, Step: 130/655, Loss: 2.205174, Accuracy: 19.50%\n",
            "Epoch: 2, Step: 131/655, Loss: 2.205726, Accuracy: 19.42%\n",
            "Epoch: 2, Step: 132/655, Loss: 2.204889, Accuracy: 19.44%\n",
            "Epoch: 2, Step: 133/655, Loss: 2.204263, Accuracy: 19.45%\n",
            "Epoch: 2, Step: 134/655, Loss: 2.204525, Accuracy: 19.43%\n",
            "Epoch: 2, Step: 135/655, Loss: 2.204391, Accuracy: 19.47%\n",
            "Epoch: 2, Step: 136/655, Loss: 2.203648, Accuracy: 19.49%\n",
            "Epoch: 2, Step: 137/655, Loss: 2.203712, Accuracy: 19.50%\n",
            "Epoch: 2, Step: 138/655, Loss: 2.204161, Accuracy: 19.50%\n",
            "Epoch: 2, Step: 139/655, Loss: 2.204815, Accuracy: 19.47%\n",
            "Epoch: 2, Step: 140/655, Loss: 2.205804, Accuracy: 19.46%\n",
            "Epoch: 2, Step: 141/655, Loss: 2.206396, Accuracy: 19.41%\n",
            "Epoch: 2, Step: 142/655, Loss: 2.206588, Accuracy: 19.43%\n",
            "Epoch: 2, Step: 143/655, Loss: 2.206774, Accuracy: 19.38%\n",
            "Epoch: 2, Step: 144/655, Loss: 2.206981, Accuracy: 19.42%\n",
            "Epoch: 2, Step: 145/655, Loss: 2.207762, Accuracy: 19.40%\n",
            "Epoch: 2, Step: 146/655, Loss: 2.207607, Accuracy: 19.41%\n",
            "Epoch: 2, Step: 147/655, Loss: 2.207597, Accuracy: 19.37%\n",
            "Epoch: 2, Step: 148/655, Loss: 2.207854, Accuracy: 19.36%\n",
            "Epoch: 2, Step: 149/655, Loss: 2.207763, Accuracy: 19.36%\n",
            "Epoch: 2, Step: 150/655, Loss: 2.206955, Accuracy: 19.40%\n",
            "Epoch: 2, Step: 151/655, Loss: 2.207506, Accuracy: 19.33%\n",
            "Epoch: 2, Step: 152/655, Loss: 2.207569, Accuracy: 19.35%\n",
            "Epoch: 2, Step: 153/655, Loss: 2.207697, Accuracy: 19.38%\n",
            "Epoch: 2, Step: 154/655, Loss: 2.207248, Accuracy: 19.42%\n",
            "Epoch: 2, Step: 155/655, Loss: 2.207462, Accuracy: 19.35%\n",
            "Epoch: 2, Step: 156/655, Loss: 2.207548, Accuracy: 19.33%\n",
            "Epoch: 2, Step: 157/655, Loss: 2.206944, Accuracy: 19.37%\n",
            "Epoch: 2, Step: 158/655, Loss: 2.206915, Accuracy: 19.38%\n",
            "Epoch: 2, Step: 159/655, Loss: 2.206255, Accuracy: 19.46%\n",
            "Epoch: 2, Step: 160/655, Loss: 2.206035, Accuracy: 19.53%\n",
            "Epoch: 2, Step: 161/655, Loss: 2.206182, Accuracy: 19.51%\n",
            "Epoch: 2, Step: 162/655, Loss: 2.206443, Accuracy: 19.46%\n",
            "Epoch: 2, Step: 163/655, Loss: 2.206512, Accuracy: 19.46%\n",
            "Epoch: 2, Step: 164/655, Loss: 2.207053, Accuracy: 19.40%\n",
            "Epoch: 2, Step: 165/655, Loss: 2.206761, Accuracy: 19.41%\n",
            "Epoch: 2, Step: 166/655, Loss: 2.206805, Accuracy: 19.47%\n",
            "Epoch: 2, Step: 167/655, Loss: 2.206304, Accuracy: 19.50%\n",
            "Epoch: 2, Step: 168/655, Loss: 2.205911, Accuracy: 19.53%\n",
            "Epoch: 2, Step: 169/655, Loss: 2.206361, Accuracy: 19.51%\n",
            "Epoch: 2, Step: 170/655, Loss: 2.206747, Accuracy: 19.47%\n",
            "Epoch: 2, Step: 171/655, Loss: 2.207477, Accuracy: 19.41%\n",
            "Epoch: 2, Step: 172/655, Loss: 2.207434, Accuracy: 19.37%\n",
            "Epoch: 2, Step: 173/655, Loss: 2.206916, Accuracy: 19.42%\n",
            "Epoch: 2, Step: 174/655, Loss: 2.206614, Accuracy: 19.43%\n",
            "Epoch: 2, Step: 175/655, Loss: 2.206709, Accuracy: 19.45%\n",
            "Epoch: 2, Step: 176/655, Loss: 2.207194, Accuracy: 19.39%\n",
            "Epoch: 2, Step: 177/655, Loss: 2.206536, Accuracy: 19.47%\n",
            "Epoch: 2, Step: 178/655, Loss: 2.205961, Accuracy: 19.49%\n",
            "Epoch: 2, Step: 179/655, Loss: 2.205993, Accuracy: 19.45%\n",
            "Epoch: 2, Step: 180/655, Loss: 2.206689, Accuracy: 19.39%\n",
            "Epoch: 2, Step: 181/655, Loss: 2.206174, Accuracy: 19.42%\n",
            "Epoch: 2, Step: 182/655, Loss: 2.205960, Accuracy: 19.42%\n",
            "Epoch: 2, Step: 183/655, Loss: 2.205947, Accuracy: 19.43%\n",
            "Epoch: 2, Step: 184/655, Loss: 2.206744, Accuracy: 19.43%\n",
            "Epoch: 2, Step: 185/655, Loss: 2.206932, Accuracy: 19.41%\n",
            "Epoch: 2, Step: 186/655, Loss: 2.206515, Accuracy: 19.39%\n",
            "Epoch: 2, Step: 187/655, Loss: 2.206033, Accuracy: 19.33%\n",
            "Epoch: 2, Step: 188/655, Loss: 2.206905, Accuracy: 19.28%\n",
            "Epoch: 2, Step: 189/655, Loss: 2.206321, Accuracy: 19.30%\n",
            "Epoch: 2, Step: 190/655, Loss: 2.206449, Accuracy: 19.31%\n",
            "Epoch: 2, Step: 191/655, Loss: 2.206589, Accuracy: 19.27%\n",
            "Epoch: 2, Step: 192/655, Loss: 2.206955, Accuracy: 19.24%\n",
            "Epoch: 2, Step: 193/655, Loss: 2.208011, Accuracy: 19.15%\n",
            "Epoch: 2, Step: 194/655, Loss: 2.207483, Accuracy: 19.22%\n",
            "Epoch: 2, Step: 195/655, Loss: 2.206748, Accuracy: 19.25%\n",
            "Epoch: 2, Step: 196/655, Loss: 2.206866, Accuracy: 19.24%\n",
            "Epoch: 2, Step: 197/655, Loss: 2.207023, Accuracy: 19.23%\n",
            "Epoch: 2, Step: 198/655, Loss: 2.206880, Accuracy: 19.26%\n",
            "Epoch: 2, Step: 199/655, Loss: 2.207167, Accuracy: 19.25%\n",
            "Epoch: 2, Step: 200/655, Loss: 2.206653, Accuracy: 19.30%\n",
            "Epoch: 2, Step: 201/655, Loss: 2.206781, Accuracy: 19.26%\n",
            "Epoch: 2, Step: 202/655, Loss: 2.206635, Accuracy: 19.21%\n",
            "Epoch: 2, Step: 203/655, Loss: 2.207087, Accuracy: 19.18%\n",
            "Epoch: 2, Step: 204/655, Loss: 2.207172, Accuracy: 19.19%\n",
            "Epoch: 2, Step: 205/655, Loss: 2.207450, Accuracy: 19.19%\n",
            "Epoch: 2, Step: 206/655, Loss: 2.207880, Accuracy: 19.14%\n",
            "Epoch: 2, Step: 207/655, Loss: 2.207337, Accuracy: 19.25%\n",
            "Epoch: 2, Step: 208/655, Loss: 2.207015, Accuracy: 19.25%\n",
            "Epoch: 2, Step: 209/655, Loss: 2.206967, Accuracy: 19.23%\n",
            "Epoch: 2, Step: 210/655, Loss: 2.207337, Accuracy: 19.17%\n",
            "Epoch: 2, Step: 211/655, Loss: 2.206896, Accuracy: 19.15%\n",
            "Epoch: 2, Step: 212/655, Loss: 2.207305, Accuracy: 19.06%\n",
            "Epoch: 2, Step: 213/655, Loss: 2.207487, Accuracy: 19.07%\n",
            "Epoch: 2, Step: 214/655, Loss: 2.207823, Accuracy: 19.04%\n",
            "Epoch: 2, Step: 215/655, Loss: 2.207985, Accuracy: 19.04%\n",
            "Epoch: 2, Step: 216/655, Loss: 2.207720, Accuracy: 19.07%\n",
            "Epoch: 2, Step: 217/655, Loss: 2.208113, Accuracy: 19.02%\n",
            "Epoch: 2, Step: 218/655, Loss: 2.207542, Accuracy: 19.07%\n",
            "Epoch: 2, Step: 219/655, Loss: 2.207946, Accuracy: 19.02%\n",
            "Epoch: 2, Step: 220/655, Loss: 2.208047, Accuracy: 19.02%\n",
            "Epoch: 2, Step: 221/655, Loss: 2.208102, Accuracy: 19.02%\n",
            "Epoch: 2, Step: 222/655, Loss: 2.208115, Accuracy: 19.06%\n",
            "Epoch: 2, Step: 223/655, Loss: 2.207442, Accuracy: 19.06%\n",
            "Epoch: 2, Step: 224/655, Loss: 2.207288, Accuracy: 19.08%\n",
            "Epoch: 2, Step: 225/655, Loss: 2.207137, Accuracy: 19.08%\n",
            "Epoch: 2, Step: 226/655, Loss: 2.207169, Accuracy: 19.07%\n",
            "Epoch: 2, Step: 227/655, Loss: 2.207368, Accuracy: 19.07%\n",
            "Epoch: 2, Step: 228/655, Loss: 2.207200, Accuracy: 19.09%\n",
            "Epoch: 2, Step: 229/655, Loss: 2.207259, Accuracy: 19.12%\n",
            "Epoch: 2, Step: 230/655, Loss: 2.206713, Accuracy: 19.17%\n",
            "Epoch: 2, Step: 231/655, Loss: 2.207073, Accuracy: 19.12%\n",
            "Epoch: 2, Step: 232/655, Loss: 2.207303, Accuracy: 19.13%\n",
            "Epoch: 2, Step: 233/655, Loss: 2.207214, Accuracy: 19.14%\n",
            "Epoch: 2, Step: 234/655, Loss: 2.207179, Accuracy: 19.14%\n",
            "Epoch: 2, Step: 235/655, Loss: 2.207120, Accuracy: 19.19%\n",
            "Epoch: 2, Step: 236/655, Loss: 2.207699, Accuracy: 19.17%\n",
            "Epoch: 2, Step: 237/655, Loss: 2.207929, Accuracy: 19.19%\n",
            "Epoch: 2, Step: 238/655, Loss: 2.208035, Accuracy: 19.14%\n",
            "Epoch: 2, Step: 239/655, Loss: 2.208350, Accuracy: 19.13%\n",
            "Epoch: 2, Step: 240/655, Loss: 2.208167, Accuracy: 19.11%\n",
            "Epoch: 2, Step: 241/655, Loss: 2.208034, Accuracy: 19.13%\n",
            "Epoch: 2, Step: 242/655, Loss: 2.208616, Accuracy: 19.10%\n",
            "Epoch: 2, Step: 243/655, Loss: 2.208985, Accuracy: 19.07%\n",
            "Epoch: 2, Step: 244/655, Loss: 2.208948, Accuracy: 19.10%\n",
            "Epoch: 2, Step: 245/655, Loss: 2.208700, Accuracy: 19.12%\n",
            "Epoch: 2, Step: 246/655, Loss: 2.208898, Accuracy: 19.13%\n",
            "Epoch: 2, Step: 247/655, Loss: 2.208765, Accuracy: 19.15%\n",
            "Epoch: 2, Step: 248/655, Loss: 2.208781, Accuracy: 19.15%\n",
            "Epoch: 2, Step: 249/655, Loss: 2.208461, Accuracy: 19.23%\n",
            "Epoch: 2, Step: 250/655, Loss: 2.208632, Accuracy: 19.20%\n",
            "Epoch: 2, Step: 251/655, Loss: 2.208882, Accuracy: 19.19%\n",
            "Epoch: 2, Step: 252/655, Loss: 2.209314, Accuracy: 19.16%\n",
            "Epoch: 2, Step: 253/655, Loss: 2.209521, Accuracy: 19.11%\n",
            "Epoch: 2, Step: 254/655, Loss: 2.209137, Accuracy: 19.14%\n",
            "Epoch: 2, Step: 255/655, Loss: 2.209058, Accuracy: 19.13%\n",
            "Epoch: 2, Step: 256/655, Loss: 2.209818, Accuracy: 19.09%\n",
            "Epoch: 2, Step: 257/655, Loss: 2.210325, Accuracy: 19.07%\n",
            "Epoch: 2, Step: 258/655, Loss: 2.210685, Accuracy: 19.04%\n",
            "Epoch: 2, Step: 259/655, Loss: 2.210929, Accuracy: 19.02%\n",
            "Epoch: 2, Step: 260/655, Loss: 2.210997, Accuracy: 18.99%\n",
            "Epoch: 2, Step: 261/655, Loss: 2.211516, Accuracy: 18.97%\n",
            "Epoch: 2, Step: 262/655, Loss: 2.211647, Accuracy: 18.95%\n",
            "Epoch: 2, Step: 263/655, Loss: 2.211741, Accuracy: 18.96%\n",
            "Epoch: 2, Step: 264/655, Loss: 2.211725, Accuracy: 18.96%\n",
            "Epoch: 2, Step: 265/655, Loss: 2.211436, Accuracy: 19.00%\n",
            "Epoch: 2, Step: 266/655, Loss: 2.211494, Accuracy: 18.97%\n",
            "Epoch: 2, Step: 267/655, Loss: 2.211160, Accuracy: 18.96%\n",
            "Epoch: 2, Step: 268/655, Loss: 2.211271, Accuracy: 18.91%\n",
            "Epoch: 2, Step: 269/655, Loss: 2.211662, Accuracy: 18.90%\n",
            "Epoch: 2, Step: 270/655, Loss: 2.211468, Accuracy: 18.90%\n",
            "Epoch: 2, Step: 271/655, Loss: 2.211738, Accuracy: 18.87%\n",
            "Epoch: 2, Step: 272/655, Loss: 2.212225, Accuracy: 18.86%\n",
            "Epoch: 2, Step: 273/655, Loss: 2.212090, Accuracy: 18.86%\n",
            "Epoch: 2, Step: 274/655, Loss: 2.212252, Accuracy: 18.86%\n",
            "Epoch: 2, Step: 275/655, Loss: 2.212330, Accuracy: 18.86%\n",
            "Epoch: 2, Step: 276/655, Loss: 2.212394, Accuracy: 18.84%\n",
            "Epoch: 2, Step: 277/655, Loss: 2.212205, Accuracy: 18.84%\n",
            "Epoch: 2, Step: 278/655, Loss: 2.212134, Accuracy: 18.83%\n",
            "Epoch: 2, Step: 279/655, Loss: 2.212079, Accuracy: 18.88%\n",
            "Epoch: 2, Step: 280/655, Loss: 2.212058, Accuracy: 18.90%\n",
            "Epoch: 2, Step: 281/655, Loss: 2.211890, Accuracy: 18.91%\n",
            "Epoch: 2, Step: 282/655, Loss: 2.211873, Accuracy: 18.93%\n",
            "Epoch: 2, Step: 283/655, Loss: 2.211715, Accuracy: 18.95%\n",
            "Epoch: 2, Step: 284/655, Loss: 2.212028, Accuracy: 18.94%\n",
            "Epoch: 2, Step: 285/655, Loss: 2.211872, Accuracy: 18.94%\n",
            "Epoch: 2, Step: 286/655, Loss: 2.211657, Accuracy: 18.96%\n",
            "Epoch: 2, Step: 287/655, Loss: 2.211842, Accuracy: 18.97%\n",
            "Epoch: 2, Step: 288/655, Loss: 2.211536, Accuracy: 18.98%\n",
            "Epoch: 2, Step: 289/655, Loss: 2.211269, Accuracy: 18.97%\n",
            "Epoch: 2, Step: 290/655, Loss: 2.210938, Accuracy: 18.98%\n",
            "Epoch: 2, Step: 291/655, Loss: 2.210663, Accuracy: 19.02%\n",
            "Epoch: 2, Step: 292/655, Loss: 2.210601, Accuracy: 19.04%\n",
            "Epoch: 2, Step: 293/655, Loss: 2.210737, Accuracy: 19.00%\n",
            "Epoch: 2, Step: 294/655, Loss: 2.210593, Accuracy: 18.99%\n",
            "Epoch: 2, Step: 295/655, Loss: 2.211098, Accuracy: 18.96%\n",
            "Epoch: 2, Step: 296/655, Loss: 2.210802, Accuracy: 18.97%\n",
            "Epoch: 2, Step: 297/655, Loss: 2.210391, Accuracy: 19.00%\n",
            "Epoch: 2, Step: 298/655, Loss: 2.210425, Accuracy: 19.02%\n",
            "Epoch: 2, Step: 299/655, Loss: 2.210508, Accuracy: 19.01%\n",
            "Epoch: 2, Step: 300/655, Loss: 2.210827, Accuracy: 18.97%\n",
            "Epoch: 2, Step: 301/655, Loss: 2.211462, Accuracy: 18.92%\n",
            "Epoch: 2, Step: 302/655, Loss: 2.211557, Accuracy: 18.94%\n",
            "Epoch: 2, Step: 303/655, Loss: 2.211743, Accuracy: 18.94%\n",
            "Epoch: 2, Step: 304/655, Loss: 2.211776, Accuracy: 18.94%\n",
            "Epoch: 2, Step: 305/655, Loss: 2.211653, Accuracy: 18.92%\n",
            "Epoch: 2, Step: 306/655, Loss: 2.211215, Accuracy: 18.95%\n",
            "Epoch: 2, Step: 307/655, Loss: 2.211067, Accuracy: 18.98%\n",
            "Epoch: 2, Step: 308/655, Loss: 2.210878, Accuracy: 19.02%\n",
            "Epoch: 2, Step: 309/655, Loss: 2.210800, Accuracy: 19.01%\n",
            "Epoch: 2, Step: 310/655, Loss: 2.210804, Accuracy: 19.01%\n",
            "Epoch: 2, Step: 311/655, Loss: 2.210686, Accuracy: 19.00%\n",
            "Epoch: 2, Step: 312/655, Loss: 2.210978, Accuracy: 18.99%\n",
            "Epoch: 2, Step: 313/655, Loss: 2.210905, Accuracy: 18.99%\n",
            "Epoch: 2, Step: 314/655, Loss: 2.211107, Accuracy: 18.97%\n",
            "Epoch: 2, Step: 315/655, Loss: 2.211409, Accuracy: 18.97%\n",
            "Epoch: 2, Step: 316/655, Loss: 2.211343, Accuracy: 18.96%\n",
            "Epoch: 2, Step: 317/655, Loss: 2.211294, Accuracy: 18.96%\n",
            "Epoch: 2, Step: 318/655, Loss: 2.211598, Accuracy: 18.95%\n",
            "Epoch: 2, Step: 319/655, Loss: 2.211150, Accuracy: 18.96%\n",
            "Epoch: 2, Step: 320/655, Loss: 2.211512, Accuracy: 18.94%\n",
            "Epoch: 2, Step: 321/655, Loss: 2.211274, Accuracy: 18.94%\n",
            "Epoch: 2, Step: 322/655, Loss: 2.211342, Accuracy: 18.93%\n",
            "Epoch: 2, Step: 323/655, Loss: 2.211506, Accuracy: 18.90%\n",
            "Epoch: 2, Step: 324/655, Loss: 2.212046, Accuracy: 18.89%\n",
            "Epoch: 2, Step: 325/655, Loss: 2.212201, Accuracy: 18.87%\n",
            "Epoch: 2, Step: 326/655, Loss: 2.212269, Accuracy: 18.87%\n",
            "Epoch: 2, Step: 327/655, Loss: 2.212123, Accuracy: 18.86%\n",
            "Epoch: 2, Step: 328/655, Loss: 2.212130, Accuracy: 18.88%\n",
            "Epoch: 2, Step: 329/655, Loss: 2.211822, Accuracy: 18.88%\n",
            "Epoch: 2, Step: 330/655, Loss: 2.211409, Accuracy: 18.91%\n",
            "Epoch: 2, Step: 331/655, Loss: 2.211471, Accuracy: 18.91%\n",
            "Epoch: 2, Step: 332/655, Loss: 2.211542, Accuracy: 18.92%\n",
            "Epoch: 2, Step: 333/655, Loss: 2.211516, Accuracy: 18.93%\n",
            "Epoch: 2, Step: 334/655, Loss: 2.211327, Accuracy: 18.94%\n",
            "Epoch: 2, Step: 335/655, Loss: 2.211601, Accuracy: 18.95%\n",
            "Epoch: 2, Step: 336/655, Loss: 2.211418, Accuracy: 18.94%\n",
            "Epoch: 2, Step: 337/655, Loss: 2.211570, Accuracy: 18.92%\n",
            "Epoch: 2, Step: 338/655, Loss: 2.211319, Accuracy: 18.96%\n",
            "Epoch: 2, Step: 339/655, Loss: 2.211668, Accuracy: 18.94%\n",
            "Epoch: 2, Step: 340/655, Loss: 2.211670, Accuracy: 18.93%\n",
            "Epoch: 2, Step: 341/655, Loss: 2.211867, Accuracy: 18.91%\n",
            "Epoch: 2, Step: 342/655, Loss: 2.211931, Accuracy: 18.91%\n",
            "Epoch: 2, Step: 343/655, Loss: 2.212202, Accuracy: 18.88%\n",
            "Epoch: 2, Step: 344/655, Loss: 2.212292, Accuracy: 18.88%\n",
            "Epoch: 2, Step: 345/655, Loss: 2.211849, Accuracy: 18.87%\n",
            "Epoch: 2, Step: 346/655, Loss: 2.211650, Accuracy: 18.88%\n",
            "Epoch: 2, Step: 347/655, Loss: 2.211427, Accuracy: 18.89%\n",
            "Epoch: 2, Step: 348/655, Loss: 2.211143, Accuracy: 18.89%\n",
            "Epoch: 2, Step: 349/655, Loss: 2.210814, Accuracy: 18.93%\n",
            "Epoch: 2, Step: 350/655, Loss: 2.210725, Accuracy: 18.92%\n",
            "Epoch: 2, Step: 351/655, Loss: 2.211168, Accuracy: 18.89%\n",
            "Epoch: 2, Step: 352/655, Loss: 2.211126, Accuracy: 18.91%\n",
            "Epoch: 2, Step: 353/655, Loss: 2.210773, Accuracy: 18.92%\n",
            "Epoch: 2, Step: 354/655, Loss: 2.210621, Accuracy: 18.89%\n",
            "Epoch: 2, Step: 355/655, Loss: 2.211000, Accuracy: 18.89%\n",
            "Epoch: 2, Step: 356/655, Loss: 2.210834, Accuracy: 18.92%\n",
            "Epoch: 2, Step: 357/655, Loss: 2.210546, Accuracy: 18.95%\n",
            "Epoch: 2, Step: 358/655, Loss: 2.210783, Accuracy: 18.95%\n",
            "Epoch: 2, Step: 359/655, Loss: 2.210938, Accuracy: 18.92%\n",
            "Epoch: 2, Step: 360/655, Loss: 2.211155, Accuracy: 18.93%\n",
            "Epoch: 2, Step: 361/655, Loss: 2.211084, Accuracy: 18.94%\n",
            "Epoch: 2, Step: 362/655, Loss: 2.211146, Accuracy: 18.94%\n",
            "Epoch: 2, Step: 363/655, Loss: 2.211104, Accuracy: 18.97%\n",
            "Epoch: 2, Step: 364/655, Loss: 2.211480, Accuracy: 18.95%\n",
            "Epoch: 2, Step: 365/655, Loss: 2.211461, Accuracy: 18.93%\n",
            "Epoch: 2, Step: 366/655, Loss: 2.211529, Accuracy: 18.93%\n",
            "Epoch: 2, Step: 367/655, Loss: 2.211545, Accuracy: 18.92%\n",
            "Epoch: 2, Step: 368/655, Loss: 2.211432, Accuracy: 18.91%\n",
            "Epoch: 2, Step: 369/655, Loss: 2.211364, Accuracy: 18.89%\n",
            "Epoch: 2, Step: 370/655, Loss: 2.211333, Accuracy: 18.89%\n",
            "Epoch: 2, Step: 371/655, Loss: 2.211025, Accuracy: 18.86%\n",
            "Epoch: 2, Step: 372/655, Loss: 2.211144, Accuracy: 18.87%\n",
            "Epoch: 2, Step: 373/655, Loss: 2.211154, Accuracy: 18.85%\n",
            "Epoch: 2, Step: 374/655, Loss: 2.211097, Accuracy: 18.83%\n",
            "Epoch: 2, Step: 375/655, Loss: 2.211328, Accuracy: 18.82%\n",
            "Epoch: 2, Step: 376/655, Loss: 2.211583, Accuracy: 18.80%\n",
            "Epoch: 2, Step: 377/655, Loss: 2.211367, Accuracy: 18.81%\n",
            "Epoch: 2, Step: 378/655, Loss: 2.211266, Accuracy: 18.80%\n",
            "Epoch: 2, Step: 379/655, Loss: 2.211123, Accuracy: 18.81%\n",
            "Epoch: 2, Step: 380/655, Loss: 2.210988, Accuracy: 18.79%\n",
            "Epoch: 2, Step: 381/655, Loss: 2.211107, Accuracy: 18.79%\n",
            "Epoch: 2, Step: 382/655, Loss: 2.210932, Accuracy: 18.77%\n",
            "Epoch: 2, Step: 383/655, Loss: 2.210967, Accuracy: 18.77%\n",
            "Epoch: 2, Step: 384/655, Loss: 2.210478, Accuracy: 18.80%\n",
            "Epoch: 2, Step: 385/655, Loss: 2.210245, Accuracy: 18.85%\n",
            "Epoch: 2, Step: 386/655, Loss: 2.209914, Accuracy: 18.84%\n",
            "Epoch: 2, Step: 387/655, Loss: 2.209783, Accuracy: 18.84%\n",
            "Epoch: 2, Step: 388/655, Loss: 2.210165, Accuracy: 18.81%\n",
            "Epoch: 2, Step: 389/655, Loss: 2.209894, Accuracy: 18.80%\n",
            "Epoch: 2, Step: 390/655, Loss: 2.210014, Accuracy: 18.78%\n",
            "Epoch: 2, Step: 391/655, Loss: 2.209877, Accuracy: 18.80%\n",
            "Epoch: 2, Step: 392/655, Loss: 2.209974, Accuracy: 18.77%\n",
            "Epoch: 2, Step: 393/655, Loss: 2.210370, Accuracy: 18.77%\n",
            "Epoch: 2, Step: 394/655, Loss: 2.210834, Accuracy: 18.76%\n",
            "Epoch: 2, Step: 395/655, Loss: 2.210850, Accuracy: 18.76%\n",
            "Epoch: 2, Step: 396/655, Loss: 2.210934, Accuracy: 18.77%\n",
            "Epoch: 2, Step: 397/655, Loss: 2.211050, Accuracy: 18.77%\n",
            "Epoch: 2, Step: 398/655, Loss: 2.210784, Accuracy: 18.81%\n",
            "Epoch: 2, Step: 399/655, Loss: 2.210869, Accuracy: 18.80%\n",
            "Epoch: 2, Step: 400/655, Loss: 2.211027, Accuracy: 18.82%\n",
            "Epoch: 2, Step: 401/655, Loss: 2.210933, Accuracy: 18.82%\n",
            "Epoch: 2, Step: 402/655, Loss: 2.211173, Accuracy: 18.80%\n",
            "Epoch: 2, Step: 403/655, Loss: 2.211137, Accuracy: 18.79%\n",
            "Epoch: 2, Step: 404/655, Loss: 2.211339, Accuracy: 18.76%\n",
            "Epoch: 2, Step: 405/655, Loss: 2.210986, Accuracy: 18.76%\n",
            "Epoch: 2, Step: 406/655, Loss: 2.210924, Accuracy: 18.78%\n",
            "Epoch: 2, Step: 407/655, Loss: 2.210572, Accuracy: 18.79%\n",
            "Epoch: 2, Step: 408/655, Loss: 2.210316, Accuracy: 18.80%\n",
            "Epoch: 2, Step: 409/655, Loss: 2.210379, Accuracy: 18.78%\n",
            "Epoch: 2, Step: 410/655, Loss: 2.210290, Accuracy: 18.80%\n",
            "Epoch: 2, Step: 411/655, Loss: 2.210231, Accuracy: 18.80%\n",
            "Epoch: 2, Step: 412/655, Loss: 2.210397, Accuracy: 18.80%\n",
            "Epoch: 2, Step: 413/655, Loss: 2.210713, Accuracy: 18.80%\n",
            "Epoch: 2, Step: 414/655, Loss: 2.210862, Accuracy: 18.79%\n",
            "Epoch: 2, Step: 415/655, Loss: 2.210926, Accuracy: 18.79%\n",
            "Epoch: 2, Step: 416/655, Loss: 2.211010, Accuracy: 18.77%\n",
            "Epoch: 2, Step: 417/655, Loss: 2.211062, Accuracy: 18.76%\n",
            "Epoch: 2, Step: 418/655, Loss: 2.211082, Accuracy: 18.76%\n",
            "Epoch: 2, Step: 419/655, Loss: 2.211191, Accuracy: 18.73%\n",
            "Epoch: 2, Step: 420/655, Loss: 2.211066, Accuracy: 18.74%\n",
            "Epoch: 2, Step: 421/655, Loss: 2.210906, Accuracy: 18.74%\n",
            "Epoch: 2, Step: 422/655, Loss: 2.211052, Accuracy: 18.74%\n",
            "Epoch: 2, Step: 423/655, Loss: 2.211400, Accuracy: 18.70%\n",
            "Epoch: 2, Step: 424/655, Loss: 2.211514, Accuracy: 18.69%\n",
            "Epoch: 2, Step: 425/655, Loss: 2.211422, Accuracy: 18.68%\n",
            "Epoch: 2, Step: 426/655, Loss: 2.211580, Accuracy: 18.70%\n",
            "Epoch: 2, Step: 427/655, Loss: 2.211653, Accuracy: 18.71%\n",
            "Epoch: 2, Step: 428/655, Loss: 2.211676, Accuracy: 18.71%\n",
            "Epoch: 2, Step: 429/655, Loss: 2.211748, Accuracy: 18.70%\n",
            "Epoch: 2, Step: 430/655, Loss: 2.211800, Accuracy: 18.68%\n",
            "Epoch: 2, Step: 431/655, Loss: 2.211696, Accuracy: 18.68%\n",
            "Epoch: 2, Step: 432/655, Loss: 2.211777, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 433/655, Loss: 2.211717, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 434/655, Loss: 2.211706, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 435/655, Loss: 2.211858, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 436/655, Loss: 2.211601, Accuracy: 18.69%\n",
            "Epoch: 2, Step: 437/655, Loss: 2.211532, Accuracy: 18.69%\n",
            "Epoch: 2, Step: 438/655, Loss: 2.211940, Accuracy: 18.69%\n",
            "Epoch: 2, Step: 439/655, Loss: 2.211911, Accuracy: 18.69%\n",
            "Epoch: 2, Step: 440/655, Loss: 2.211727, Accuracy: 18.69%\n",
            "Epoch: 2, Step: 441/655, Loss: 2.211972, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 442/655, Loss: 2.212001, Accuracy: 18.68%\n",
            "Epoch: 2, Step: 443/655, Loss: 2.212074, Accuracy: 18.67%\n",
            "Epoch: 2, Step: 444/655, Loss: 2.212427, Accuracy: 18.65%\n",
            "Epoch: 2, Step: 445/655, Loss: 2.212586, Accuracy: 18.65%\n",
            "Epoch: 2, Step: 446/655, Loss: 2.212423, Accuracy: 18.69%\n",
            "Epoch: 2, Step: 447/655, Loss: 2.212503, Accuracy: 18.68%\n",
            "Epoch: 2, Step: 448/655, Loss: 2.212591, Accuracy: 18.68%\n",
            "Epoch: 2, Step: 449/655, Loss: 2.212635, Accuracy: 18.69%\n",
            "Epoch: 2, Step: 450/655, Loss: 2.212440, Accuracy: 18.70%\n",
            "Epoch: 2, Step: 451/655, Loss: 2.212486, Accuracy: 18.69%\n",
            "Epoch: 2, Step: 452/655, Loss: 2.212865, Accuracy: 18.67%\n",
            "Epoch: 2, Step: 453/655, Loss: 2.212670, Accuracy: 18.69%\n",
            "Epoch: 2, Step: 454/655, Loss: 2.212846, Accuracy: 18.67%\n",
            "Epoch: 2, Step: 455/655, Loss: 2.212953, Accuracy: 18.67%\n",
            "Epoch: 2, Step: 456/655, Loss: 2.212883, Accuracy: 18.65%\n",
            "Epoch: 2, Step: 457/655, Loss: 2.213049, Accuracy: 18.64%\n",
            "Epoch: 2, Step: 458/655, Loss: 2.212791, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 459/655, Loss: 2.212950, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 460/655, Loss: 2.212996, Accuracy: 18.65%\n",
            "Epoch: 2, Step: 461/655, Loss: 2.213093, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 462/655, Loss: 2.213190, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 463/655, Loss: 2.213236, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 464/655, Loss: 2.213260, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 465/655, Loss: 2.213227, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 466/655, Loss: 2.213261, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 467/655, Loss: 2.213361, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 468/655, Loss: 2.213508, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 469/655, Loss: 2.213643, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 470/655, Loss: 2.213688, Accuracy: 18.59%\n",
            "Epoch: 2, Step: 471/655, Loss: 2.213381, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 472/655, Loss: 2.213410, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 473/655, Loss: 2.213257, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 474/655, Loss: 2.213074, Accuracy: 18.59%\n",
            "Epoch: 2, Step: 475/655, Loss: 2.212984, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 476/655, Loss: 2.212854, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 477/655, Loss: 2.212857, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 478/655, Loss: 2.212778, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 479/655, Loss: 2.212631, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 480/655, Loss: 2.212771, Accuracy: 18.59%\n",
            "Epoch: 2, Step: 481/655, Loss: 2.212767, Accuracy: 18.56%\n",
            "Epoch: 2, Step: 482/655, Loss: 2.212725, Accuracy: 18.56%\n",
            "Epoch: 2, Step: 483/655, Loss: 2.212789, Accuracy: 18.55%\n",
            "Epoch: 2, Step: 484/655, Loss: 2.212424, Accuracy: 18.57%\n",
            "Epoch: 2, Step: 485/655, Loss: 2.212401, Accuracy: 18.56%\n",
            "Epoch: 2, Step: 486/655, Loss: 2.212379, Accuracy: 18.57%\n",
            "Epoch: 2, Step: 487/655, Loss: 2.212645, Accuracy: 18.55%\n",
            "Epoch: 2, Step: 488/655, Loss: 2.212607, Accuracy: 18.56%\n",
            "Epoch: 2, Step: 489/655, Loss: 2.212672, Accuracy: 18.56%\n",
            "Epoch: 2, Step: 490/655, Loss: 2.212502, Accuracy: 18.58%\n",
            "Epoch: 2, Step: 491/655, Loss: 2.212224, Accuracy: 18.59%\n",
            "Epoch: 2, Step: 492/655, Loss: 2.212025, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 493/655, Loss: 2.212011, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 494/655, Loss: 2.212308, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 495/655, Loss: 2.212166, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 496/655, Loss: 2.212440, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 497/655, Loss: 2.212305, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 498/655, Loss: 2.212087, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 499/655, Loss: 2.211805, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 500/655, Loss: 2.211879, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 501/655, Loss: 2.211772, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 502/655, Loss: 2.211892, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 503/655, Loss: 2.211803, Accuracy: 18.59%\n",
            "Epoch: 2, Step: 504/655, Loss: 2.212029, Accuracy: 18.56%\n",
            "Epoch: 2, Step: 505/655, Loss: 2.212051, Accuracy: 18.56%\n",
            "Epoch: 2, Step: 506/655, Loss: 2.212023, Accuracy: 18.54%\n",
            "Epoch: 2, Step: 507/655, Loss: 2.211904, Accuracy: 18.54%\n",
            "Epoch: 2, Step: 508/655, Loss: 2.211818, Accuracy: 18.53%\n",
            "Epoch: 2, Step: 509/655, Loss: 2.211875, Accuracy: 18.54%\n",
            "Epoch: 2, Step: 510/655, Loss: 2.211571, Accuracy: 18.55%\n",
            "Epoch: 2, Step: 511/655, Loss: 2.211501, Accuracy: 18.55%\n",
            "Epoch: 2, Step: 512/655, Loss: 2.211481, Accuracy: 18.57%\n",
            "Epoch: 2, Step: 513/655, Loss: 2.211211, Accuracy: 18.59%\n",
            "Epoch: 2, Step: 514/655, Loss: 2.211239, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 515/655, Loss: 2.211335, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 516/655, Loss: 2.211664, Accuracy: 18.58%\n",
            "Epoch: 2, Step: 517/655, Loss: 2.211686, Accuracy: 18.57%\n",
            "Epoch: 2, Step: 518/655, Loss: 2.211316, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 519/655, Loss: 2.211374, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 520/655, Loss: 2.211550, Accuracy: 18.59%\n",
            "Epoch: 2, Step: 521/655, Loss: 2.211672, Accuracy: 18.58%\n",
            "Epoch: 2, Step: 522/655, Loss: 2.211819, Accuracy: 18.55%\n",
            "Epoch: 2, Step: 523/655, Loss: 2.211897, Accuracy: 18.56%\n",
            "Epoch: 2, Step: 524/655, Loss: 2.211974, Accuracy: 18.58%\n",
            "Epoch: 2, Step: 525/655, Loss: 2.211920, Accuracy: 18.58%\n",
            "Epoch: 2, Step: 526/655, Loss: 2.212100, Accuracy: 18.55%\n",
            "Epoch: 2, Step: 527/655, Loss: 2.212115, Accuracy: 18.54%\n",
            "Epoch: 2, Step: 528/655, Loss: 2.212278, Accuracy: 18.55%\n",
            "Epoch: 2, Step: 529/655, Loss: 2.211856, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 530/655, Loss: 2.211558, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 531/655, Loss: 2.211444, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 532/655, Loss: 2.211580, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 533/655, Loss: 2.211529, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 534/655, Loss: 2.211319, Accuracy: 18.64%\n",
            "Epoch: 2, Step: 535/655, Loss: 2.211284, Accuracy: 18.64%\n",
            "Epoch: 2, Step: 536/655, Loss: 2.211122, Accuracy: 18.64%\n",
            "Epoch: 2, Step: 537/655, Loss: 2.210764, Accuracy: 18.65%\n",
            "Epoch: 2, Step: 538/655, Loss: 2.211046, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 539/655, Loss: 2.210849, Accuracy: 18.65%\n",
            "Epoch: 2, Step: 540/655, Loss: 2.210931, Accuracy: 18.65%\n",
            "Epoch: 2, Step: 541/655, Loss: 2.211300, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 542/655, Loss: 2.211392, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 543/655, Loss: 2.211233, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 544/655, Loss: 2.211022, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 545/655, Loss: 2.210944, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 546/655, Loss: 2.211192, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 547/655, Loss: 2.211232, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 548/655, Loss: 2.211291, Accuracy: 18.59%\n",
            "Epoch: 2, Step: 549/655, Loss: 2.211572, Accuracy: 18.57%\n",
            "Epoch: 2, Step: 550/655, Loss: 2.211622, Accuracy: 18.56%\n",
            "Epoch: 2, Step: 551/655, Loss: 2.211854, Accuracy: 18.56%\n",
            "Epoch: 2, Step: 552/655, Loss: 2.211824, Accuracy: 18.56%\n",
            "Epoch: 2, Step: 553/655, Loss: 2.211681, Accuracy: 18.59%\n",
            "Epoch: 2, Step: 554/655, Loss: 2.211543, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 555/655, Loss: 2.211354, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 556/655, Loss: 2.211048, Accuracy: 18.64%\n",
            "Epoch: 2, Step: 557/655, Loss: 2.211114, Accuracy: 18.64%\n",
            "Epoch: 2, Step: 558/655, Loss: 2.211102, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 559/655, Loss: 2.211073, Accuracy: 18.64%\n",
            "Epoch: 2, Step: 560/655, Loss: 2.211364, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 561/655, Loss: 2.211551, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 562/655, Loss: 2.211533, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 563/655, Loss: 2.211405, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 564/655, Loss: 2.211309, Accuracy: 18.64%\n",
            "Epoch: 2, Step: 565/655, Loss: 2.211244, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 566/655, Loss: 2.211320, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 567/655, Loss: 2.211128, Accuracy: 18.65%\n",
            "Epoch: 2, Step: 568/655, Loss: 2.211221, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 569/655, Loss: 2.211156, Accuracy: 18.65%\n",
            "Epoch: 2, Step: 570/655, Loss: 2.210896, Accuracy: 18.65%\n",
            "Epoch: 2, Step: 571/655, Loss: 2.210852, Accuracy: 18.67%\n",
            "Epoch: 2, Step: 572/655, Loss: 2.210863, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 573/655, Loss: 2.211081, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 574/655, Loss: 2.211234, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 575/655, Loss: 2.211242, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 576/655, Loss: 2.211141, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 577/655, Loss: 2.211412, Accuracy: 18.59%\n",
            "Epoch: 2, Step: 578/655, Loss: 2.211350, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 579/655, Loss: 2.211290, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 580/655, Loss: 2.211298, Accuracy: 18.58%\n",
            "Epoch: 2, Step: 581/655, Loss: 2.211130, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 582/655, Loss: 2.210869, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 583/655, Loss: 2.210899, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 584/655, Loss: 2.210970, Accuracy: 18.59%\n",
            "Epoch: 2, Step: 585/655, Loss: 2.211061, Accuracy: 18.59%\n",
            "Epoch: 2, Step: 586/655, Loss: 2.210860, Accuracy: 18.58%\n",
            "Epoch: 2, Step: 587/655, Loss: 2.210933, Accuracy: 18.59%\n",
            "Epoch: 2, Step: 588/655, Loss: 2.210755, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 589/655, Loss: 2.210730, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 590/655, Loss: 2.210703, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 591/655, Loss: 2.210528, Accuracy: 18.64%\n",
            "Epoch: 2, Step: 592/655, Loss: 2.210521, Accuracy: 18.64%\n",
            "Epoch: 2, Step: 593/655, Loss: 2.210498, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 594/655, Loss: 2.210671, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 595/655, Loss: 2.210657, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 596/655, Loss: 2.210809, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 597/655, Loss: 2.210599, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 598/655, Loss: 2.210338, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 599/655, Loss: 2.210248, Accuracy: 18.67%\n",
            "Epoch: 2, Step: 600/655, Loss: 2.210188, Accuracy: 18.67%\n",
            "Epoch: 2, Step: 601/655, Loss: 2.210108, Accuracy: 18.67%\n",
            "Epoch: 2, Step: 602/655, Loss: 2.210111, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 603/655, Loss: 2.210256, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 604/655, Loss: 2.210086, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 605/655, Loss: 2.209935, Accuracy: 18.64%\n",
            "Epoch: 2, Step: 606/655, Loss: 2.210045, Accuracy: 18.64%\n",
            "Epoch: 2, Step: 607/655, Loss: 2.209943, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 608/655, Loss: 2.209893, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 609/655, Loss: 2.209771, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 610/655, Loss: 2.209835, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 611/655, Loss: 2.209795, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 612/655, Loss: 2.210160, Accuracy: 18.63%\n",
            "Epoch: 2, Step: 613/655, Loss: 2.210139, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 614/655, Loss: 2.210293, Accuracy: 18.60%\n",
            "Epoch: 2, Step: 615/655, Loss: 2.210235, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 616/655, Loss: 2.210129, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 617/655, Loss: 2.210139, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 618/655, Loss: 2.210109, Accuracy: 18.61%\n",
            "Epoch: 2, Step: 619/655, Loss: 2.209902, Accuracy: 18.62%\n",
            "Epoch: 2, Step: 620/655, Loss: 2.209609, Accuracy: 18.64%\n",
            "Epoch: 2, Step: 621/655, Loss: 2.209775, Accuracy: 18.64%\n",
            "Epoch: 2, Step: 622/655, Loss: 2.209958, Accuracy: 18.65%\n",
            "Epoch: 2, Step: 623/655, Loss: 2.209892, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 624/655, Loss: 2.209999, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 625/655, Loss: 2.209986, Accuracy: 18.65%\n",
            "Epoch: 2, Step: 626/655, Loss: 2.209881, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 627/655, Loss: 2.210040, Accuracy: 18.66%\n",
            "Epoch: 2, Step: 628/655, Loss: 2.209782, Accuracy: 18.67%\n",
            "Epoch: 2, Step: 629/655, Loss: 2.209793, Accuracy: 18.69%\n",
            "Epoch: 2, Step: 630/655, Loss: 2.209557, Accuracy: 18.70%\n",
            "Epoch: 2, Step: 631/655, Loss: 2.209320, Accuracy: 18.74%\n",
            "Epoch: 2, Step: 632/655, Loss: 2.209195, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 633/655, Loss: 2.209368, Accuracy: 18.74%\n",
            "Epoch: 2, Step: 634/655, Loss: 2.209386, Accuracy: 18.73%\n",
            "Epoch: 2, Step: 635/655, Loss: 2.209435, Accuracy: 18.74%\n",
            "Epoch: 2, Step: 636/655, Loss: 2.209436, Accuracy: 18.73%\n",
            "Epoch: 2, Step: 637/655, Loss: 2.209280, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 638/655, Loss: 2.209131, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 639/655, Loss: 2.209311, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 640/655, Loss: 2.209205, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 641/655, Loss: 2.209201, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 642/655, Loss: 2.209482, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 643/655, Loss: 2.209433, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 644/655, Loss: 2.209465, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 645/655, Loss: 2.209555, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 646/655, Loss: 2.209654, Accuracy: 18.75%\n",
            "Epoch: 2, Step: 647/655, Loss: 2.209621, Accuracy: 18.74%\n",
            "Epoch: 2, Step: 648/655, Loss: 2.209788, Accuracy: 18.72%\n",
            "Epoch: 2, Step: 649/655, Loss: 2.209630, Accuracy: 18.74%\n",
            "Epoch: 2, Step: 650/655, Loss: 2.209668, Accuracy: 18.74%\n",
            "Epoch: 2, Step: 651/655, Loss: 2.209623, Accuracy: 18.73%\n",
            "Epoch: 2, Step: 652/655, Loss: 2.209660, Accuracy: 18.73%\n",
            "Epoch: 2, Step: 653/655, Loss: 2.209554, Accuracy: 18.74%\n",
            "Epoch: 2, Step: 654/655, Loss: 2.209531, Accuracy: 18.74%\n",
            "Epoch: 2, Step: 655/655, Loss: 2.209610, Accuracy: 18.74%\n",
            "Epoch: 3, Step: 1/655, Loss: 2.262947, Accuracy: 21.88%\n",
            "Epoch: 3, Step: 2/655, Loss: 2.236675, Accuracy: 17.19%\n",
            "Epoch: 3, Step: 3/655, Loss: 2.213676, Accuracy: 19.79%\n",
            "Epoch: 3, Step: 4/655, Loss: 2.201823, Accuracy: 22.66%\n",
            "Epoch: 3, Step: 5/655, Loss: 2.224040, Accuracy: 20.62%\n",
            "Epoch: 3, Step: 6/655, Loss: 2.219662, Accuracy: 20.31%\n",
            "Epoch: 3, Step: 7/655, Loss: 2.233658, Accuracy: 18.30%\n",
            "Epoch: 3, Step: 8/655, Loss: 2.232549, Accuracy: 17.97%\n",
            "Epoch: 3, Step: 9/655, Loss: 2.248914, Accuracy: 16.67%\n",
            "Epoch: 3, Step: 10/655, Loss: 2.254213, Accuracy: 16.25%\n",
            "Epoch: 3, Step: 11/655, Loss: 2.258946, Accuracy: 16.48%\n",
            "Epoch: 3, Step: 12/655, Loss: 2.250657, Accuracy: 17.19%\n",
            "Epoch: 3, Step: 13/655, Loss: 2.242425, Accuracy: 17.79%\n",
            "Epoch: 3, Step: 14/655, Loss: 2.236800, Accuracy: 17.86%\n",
            "Epoch: 3, Step: 15/655, Loss: 2.240450, Accuracy: 17.50%\n",
            "Epoch: 3, Step: 16/655, Loss: 2.242068, Accuracy: 16.80%\n",
            "Epoch: 3, Step: 17/655, Loss: 2.240105, Accuracy: 17.10%\n",
            "Epoch: 3, Step: 18/655, Loss: 2.244624, Accuracy: 17.19%\n",
            "Epoch: 3, Step: 19/655, Loss: 2.239544, Accuracy: 17.11%\n",
            "Epoch: 3, Step: 20/655, Loss: 2.238487, Accuracy: 17.03%\n",
            "Epoch: 3, Step: 21/655, Loss: 2.235426, Accuracy: 17.26%\n",
            "Epoch: 3, Step: 22/655, Loss: 2.234409, Accuracy: 17.47%\n",
            "Epoch: 3, Step: 23/655, Loss: 2.234469, Accuracy: 16.85%\n",
            "Epoch: 3, Step: 24/655, Loss: 2.234788, Accuracy: 16.80%\n",
            "Epoch: 3, Step: 25/655, Loss: 2.230670, Accuracy: 17.25%\n",
            "Epoch: 3, Step: 26/655, Loss: 2.228674, Accuracy: 17.19%\n",
            "Epoch: 3, Step: 27/655, Loss: 2.230512, Accuracy: 17.36%\n",
            "Epoch: 3, Step: 28/655, Loss: 2.229775, Accuracy: 17.63%\n",
            "Epoch: 3, Step: 29/655, Loss: 2.230492, Accuracy: 17.67%\n",
            "Epoch: 3, Step: 30/655, Loss: 2.224521, Accuracy: 18.23%\n",
            "Epoch: 3, Step: 31/655, Loss: 2.223315, Accuracy: 18.35%\n",
            "Epoch: 3, Step: 32/655, Loss: 2.225749, Accuracy: 18.16%\n",
            "Epoch: 3, Step: 33/655, Loss: 2.223482, Accuracy: 18.18%\n",
            "Epoch: 3, Step: 34/655, Loss: 2.226512, Accuracy: 17.92%\n",
            "Epoch: 3, Step: 35/655, Loss: 2.225110, Accuracy: 17.95%\n",
            "Epoch: 3, Step: 36/655, Loss: 2.224450, Accuracy: 17.97%\n",
            "Epoch: 3, Step: 37/655, Loss: 2.226335, Accuracy: 17.74%\n",
            "Epoch: 3, Step: 38/655, Loss: 2.227085, Accuracy: 17.85%\n",
            "Epoch: 3, Step: 39/655, Loss: 2.227228, Accuracy: 17.79%\n",
            "Epoch: 3, Step: 40/655, Loss: 2.224626, Accuracy: 17.73%\n",
            "Epoch: 3, Step: 41/655, Loss: 2.222499, Accuracy: 17.91%\n",
            "Epoch: 3, Step: 42/655, Loss: 2.220574, Accuracy: 17.93%\n",
            "Epoch: 3, Step: 43/655, Loss: 2.222406, Accuracy: 17.95%\n",
            "Epoch: 3, Step: 44/655, Loss: 2.221539, Accuracy: 17.83%\n",
            "Epoch: 3, Step: 45/655, Loss: 2.223051, Accuracy: 17.85%\n",
            "Epoch: 3, Step: 46/655, Loss: 2.221615, Accuracy: 17.80%\n",
            "Epoch: 3, Step: 47/655, Loss: 2.221004, Accuracy: 17.55%\n",
            "Epoch: 3, Step: 48/655, Loss: 2.220898, Accuracy: 17.51%\n",
            "Epoch: 3, Step: 49/655, Loss: 2.219022, Accuracy: 17.60%\n",
            "Epoch: 3, Step: 50/655, Loss: 2.218475, Accuracy: 17.56%\n",
            "Epoch: 3, Step: 51/655, Loss: 2.215323, Accuracy: 17.71%\n",
            "Epoch: 3, Step: 52/655, Loss: 2.213469, Accuracy: 17.79%\n",
            "Epoch: 3, Step: 53/655, Loss: 2.212747, Accuracy: 17.63%\n",
            "Epoch: 3, Step: 54/655, Loss: 2.210338, Accuracy: 17.77%\n",
            "Epoch: 3, Step: 55/655, Loss: 2.210681, Accuracy: 17.67%\n",
            "Epoch: 3, Step: 56/655, Loss: 2.208523, Accuracy: 17.86%\n",
            "Epoch: 3, Step: 57/655, Loss: 2.210519, Accuracy: 17.82%\n",
            "Epoch: 3, Step: 58/655, Loss: 2.208405, Accuracy: 18.00%\n",
            "Epoch: 3, Step: 59/655, Loss: 2.207564, Accuracy: 17.90%\n",
            "Epoch: 3, Step: 60/655, Loss: 2.206970, Accuracy: 18.02%\n",
            "Epoch: 3, Step: 61/655, Loss: 2.207601, Accuracy: 17.93%\n",
            "Epoch: 3, Step: 62/655, Loss: 2.208016, Accuracy: 17.94%\n",
            "Epoch: 3, Step: 63/655, Loss: 2.207588, Accuracy: 18.01%\n",
            "Epoch: 3, Step: 64/655, Loss: 2.206449, Accuracy: 18.12%\n",
            "Epoch: 3, Step: 65/655, Loss: 2.205799, Accuracy: 18.27%\n",
            "Epoch: 3, Step: 66/655, Loss: 2.205515, Accuracy: 18.13%\n",
            "Epoch: 3, Step: 67/655, Loss: 2.204876, Accuracy: 18.24%\n",
            "Epoch: 3, Step: 68/655, Loss: 2.203468, Accuracy: 18.24%\n",
            "Epoch: 3, Step: 69/655, Loss: 2.204426, Accuracy: 18.21%\n",
            "Epoch: 3, Step: 70/655, Loss: 2.203204, Accuracy: 18.21%\n",
            "Epoch: 3, Step: 71/655, Loss: 2.202060, Accuracy: 18.31%\n",
            "Epoch: 3, Step: 72/655, Loss: 2.200804, Accuracy: 18.32%\n",
            "Epoch: 3, Step: 73/655, Loss: 2.199841, Accuracy: 18.32%\n",
            "Epoch: 3, Step: 74/655, Loss: 2.200695, Accuracy: 18.24%\n",
            "Epoch: 3, Step: 75/655, Loss: 2.198991, Accuracy: 18.42%\n",
            "Epoch: 3, Step: 76/655, Loss: 2.198669, Accuracy: 18.38%\n",
            "Epoch: 3, Step: 77/655, Loss: 2.199304, Accuracy: 18.30%\n",
            "Epoch: 3, Step: 78/655, Loss: 2.199964, Accuracy: 18.35%\n",
            "Epoch: 3, Step: 79/655, Loss: 2.200458, Accuracy: 18.31%\n",
            "Epoch: 3, Step: 80/655, Loss: 2.199166, Accuracy: 18.32%\n",
            "Epoch: 3, Step: 81/655, Loss: 2.199643, Accuracy: 18.40%\n",
            "Epoch: 3, Step: 82/655, Loss: 2.199433, Accuracy: 18.45%\n",
            "Epoch: 3, Step: 83/655, Loss: 2.200993, Accuracy: 18.34%\n",
            "Epoch: 3, Step: 84/655, Loss: 2.200055, Accuracy: 18.38%\n",
            "Epoch: 3, Step: 85/655, Loss: 2.198170, Accuracy: 18.53%\n",
            "Epoch: 3, Step: 86/655, Loss: 2.197812, Accuracy: 18.60%\n",
            "Epoch: 3, Step: 87/655, Loss: 2.196693, Accuracy: 18.61%\n",
            "Epoch: 3, Step: 88/655, Loss: 2.194755, Accuracy: 18.64%\n",
            "Epoch: 3, Step: 89/655, Loss: 2.196255, Accuracy: 18.61%\n",
            "Epoch: 3, Step: 90/655, Loss: 2.195393, Accuracy: 18.61%\n",
            "Epoch: 3, Step: 91/655, Loss: 2.194646, Accuracy: 18.65%\n",
            "Epoch: 3, Step: 92/655, Loss: 2.193730, Accuracy: 18.58%\n",
            "Epoch: 3, Step: 93/655, Loss: 2.192724, Accuracy: 18.65%\n",
            "Epoch: 3, Step: 94/655, Loss: 2.192613, Accuracy: 18.65%\n",
            "Epoch: 3, Step: 95/655, Loss: 2.192242, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 96/655, Loss: 2.192553, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 97/655, Loss: 2.194035, Accuracy: 18.65%\n",
            "Epoch: 3, Step: 98/655, Loss: 2.195016, Accuracy: 18.65%\n",
            "Epoch: 3, Step: 99/655, Loss: 2.195213, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 100/655, Loss: 2.194689, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 101/655, Loss: 2.196417, Accuracy: 18.63%\n",
            "Epoch: 3, Step: 102/655, Loss: 2.196114, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 103/655, Loss: 2.195987, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 104/655, Loss: 2.196831, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 105/655, Loss: 2.196746, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 106/655, Loss: 2.196804, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 107/655, Loss: 2.197499, Accuracy: 18.81%\n",
            "Epoch: 3, Step: 108/655, Loss: 2.197593, Accuracy: 18.92%\n",
            "Epoch: 3, Step: 109/655, Loss: 2.196898, Accuracy: 19.01%\n",
            "Epoch: 3, Step: 110/655, Loss: 2.197324, Accuracy: 18.92%\n",
            "Epoch: 3, Step: 111/655, Loss: 2.196961, Accuracy: 19.00%\n",
            "Epoch: 3, Step: 112/655, Loss: 2.198551, Accuracy: 18.92%\n",
            "Epoch: 3, Step: 113/655, Loss: 2.199621, Accuracy: 18.81%\n",
            "Epoch: 3, Step: 114/655, Loss: 2.199535, Accuracy: 18.80%\n",
            "Epoch: 3, Step: 115/655, Loss: 2.198941, Accuracy: 18.89%\n",
            "Epoch: 3, Step: 116/655, Loss: 2.200041, Accuracy: 18.83%\n",
            "Epoch: 3, Step: 117/655, Loss: 2.199073, Accuracy: 18.94%\n",
            "Epoch: 3, Step: 118/655, Loss: 2.199919, Accuracy: 18.88%\n",
            "Epoch: 3, Step: 119/655, Loss: 2.200126, Accuracy: 18.91%\n",
            "Epoch: 3, Step: 120/655, Loss: 2.200088, Accuracy: 18.93%\n",
            "Epoch: 3, Step: 121/655, Loss: 2.200260, Accuracy: 18.93%\n",
            "Epoch: 3, Step: 122/655, Loss: 2.200222, Accuracy: 18.85%\n",
            "Epoch: 3, Step: 123/655, Loss: 2.200299, Accuracy: 18.83%\n",
            "Epoch: 3, Step: 124/655, Loss: 2.200449, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 125/655, Loss: 2.200286, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 126/655, Loss: 2.200550, Accuracy: 18.68%\n",
            "Epoch: 3, Step: 127/655, Loss: 2.199958, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 128/655, Loss: 2.199921, Accuracy: 18.82%\n",
            "Epoch: 3, Step: 129/655, Loss: 2.199737, Accuracy: 18.82%\n",
            "Epoch: 3, Step: 130/655, Loss: 2.199773, Accuracy: 18.80%\n",
            "Epoch: 3, Step: 131/655, Loss: 2.199400, Accuracy: 18.85%\n",
            "Epoch: 3, Step: 132/655, Loss: 2.198784, Accuracy: 18.89%\n",
            "Epoch: 3, Step: 133/655, Loss: 2.198724, Accuracy: 18.91%\n",
            "Epoch: 3, Step: 134/655, Loss: 2.198127, Accuracy: 18.96%\n",
            "Epoch: 3, Step: 135/655, Loss: 2.197351, Accuracy: 18.98%\n",
            "Epoch: 3, Step: 136/655, Loss: 2.197627, Accuracy: 19.05%\n",
            "Epoch: 3, Step: 137/655, Loss: 2.197914, Accuracy: 19.02%\n",
            "Epoch: 3, Step: 138/655, Loss: 2.198423, Accuracy: 19.00%\n",
            "Epoch: 3, Step: 139/655, Loss: 2.197705, Accuracy: 19.04%\n",
            "Epoch: 3, Step: 140/655, Loss: 2.197841, Accuracy: 19.06%\n",
            "Epoch: 3, Step: 141/655, Loss: 2.198857, Accuracy: 19.02%\n",
            "Epoch: 3, Step: 142/655, Loss: 2.198573, Accuracy: 18.97%\n",
            "Epoch: 3, Step: 143/655, Loss: 2.197868, Accuracy: 18.99%\n",
            "Epoch: 3, Step: 144/655, Loss: 2.197667, Accuracy: 18.97%\n",
            "Epoch: 3, Step: 145/655, Loss: 2.197541, Accuracy: 18.94%\n",
            "Epoch: 3, Step: 146/655, Loss: 2.197295, Accuracy: 18.99%\n",
            "Epoch: 3, Step: 147/655, Loss: 2.197846, Accuracy: 18.96%\n",
            "Epoch: 3, Step: 148/655, Loss: 2.198112, Accuracy: 18.94%\n",
            "Epoch: 3, Step: 149/655, Loss: 2.198286, Accuracy: 18.94%\n",
            "Epoch: 3, Step: 150/655, Loss: 2.198784, Accuracy: 18.92%\n",
            "Epoch: 3, Step: 151/655, Loss: 2.198309, Accuracy: 18.98%\n",
            "Epoch: 3, Step: 152/655, Loss: 2.199656, Accuracy: 18.87%\n",
            "Epoch: 3, Step: 153/655, Loss: 2.199545, Accuracy: 18.83%\n",
            "Epoch: 3, Step: 154/655, Loss: 2.200024, Accuracy: 18.79%\n",
            "Epoch: 3, Step: 155/655, Loss: 2.199996, Accuracy: 18.77%\n",
            "Epoch: 3, Step: 156/655, Loss: 2.199959, Accuracy: 18.77%\n",
            "Epoch: 3, Step: 157/655, Loss: 2.200215, Accuracy: 18.77%\n",
            "Epoch: 3, Step: 158/655, Loss: 2.199968, Accuracy: 18.79%\n",
            "Epoch: 3, Step: 159/655, Loss: 2.199827, Accuracy: 18.81%\n",
            "Epoch: 3, Step: 160/655, Loss: 2.200196, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 161/655, Loss: 2.200968, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 162/655, Loss: 2.201511, Accuracy: 18.77%\n",
            "Epoch: 3, Step: 163/655, Loss: 2.201147, Accuracy: 18.81%\n",
            "Epoch: 3, Step: 164/655, Loss: 2.201550, Accuracy: 18.83%\n",
            "Epoch: 3, Step: 165/655, Loss: 2.201261, Accuracy: 18.86%\n",
            "Epoch: 3, Step: 166/655, Loss: 2.201689, Accuracy: 18.84%\n",
            "Epoch: 3, Step: 167/655, Loss: 2.201824, Accuracy: 18.88%\n",
            "Epoch: 3, Step: 168/655, Loss: 2.201530, Accuracy: 18.94%\n",
            "Epoch: 3, Step: 169/655, Loss: 2.201582, Accuracy: 18.95%\n",
            "Epoch: 3, Step: 170/655, Loss: 2.201089, Accuracy: 18.99%\n",
            "Epoch: 3, Step: 171/655, Loss: 2.200515, Accuracy: 19.01%\n",
            "Epoch: 3, Step: 172/655, Loss: 2.200873, Accuracy: 19.00%\n",
            "Epoch: 3, Step: 173/655, Loss: 2.201617, Accuracy: 18.91%\n",
            "Epoch: 3, Step: 174/655, Loss: 2.202111, Accuracy: 18.86%\n",
            "Epoch: 3, Step: 175/655, Loss: 2.202568, Accuracy: 18.84%\n",
            "Epoch: 3, Step: 176/655, Loss: 2.203281, Accuracy: 18.77%\n",
            "Epoch: 3, Step: 177/655, Loss: 2.203463, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 178/655, Loss: 2.203628, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 179/655, Loss: 2.203989, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 180/655, Loss: 2.203634, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 181/655, Loss: 2.204356, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 182/655, Loss: 2.204120, Accuracy: 18.77%\n",
            "Epoch: 3, Step: 183/655, Loss: 2.204178, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 184/655, Loss: 2.203813, Accuracy: 18.77%\n",
            "Epoch: 3, Step: 185/655, Loss: 2.203792, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 186/655, Loss: 2.203533, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 187/655, Loss: 2.203483, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 188/655, Loss: 2.202826, Accuracy: 18.77%\n",
            "Epoch: 3, Step: 189/655, Loss: 2.203304, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 190/655, Loss: 2.203562, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 191/655, Loss: 2.204214, Accuracy: 18.65%\n",
            "Epoch: 3, Step: 192/655, Loss: 2.204253, Accuracy: 18.62%\n",
            "Epoch: 3, Step: 193/655, Loss: 2.204374, Accuracy: 18.57%\n",
            "Epoch: 3, Step: 194/655, Loss: 2.204433, Accuracy: 18.54%\n",
            "Epoch: 3, Step: 195/655, Loss: 2.204015, Accuracy: 18.54%\n",
            "Epoch: 3, Step: 196/655, Loss: 2.203635, Accuracy: 18.61%\n",
            "Epoch: 3, Step: 197/655, Loss: 2.204153, Accuracy: 18.56%\n",
            "Epoch: 3, Step: 198/655, Loss: 2.204107, Accuracy: 18.58%\n",
            "Epoch: 3, Step: 199/655, Loss: 2.203979, Accuracy: 18.59%\n",
            "Epoch: 3, Step: 200/655, Loss: 2.203645, Accuracy: 18.59%\n",
            "Epoch: 3, Step: 201/655, Loss: 2.203336, Accuracy: 18.63%\n",
            "Epoch: 3, Step: 202/655, Loss: 2.202845, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 203/655, Loss: 2.202900, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 204/655, Loss: 2.202921, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 205/655, Loss: 2.203233, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 206/655, Loss: 2.203203, Accuracy: 18.63%\n",
            "Epoch: 3, Step: 207/655, Loss: 2.202933, Accuracy: 18.61%\n",
            "Epoch: 3, Step: 208/655, Loss: 2.202349, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 209/655, Loss: 2.202468, Accuracy: 18.60%\n",
            "Epoch: 3, Step: 210/655, Loss: 2.202391, Accuracy: 18.63%\n",
            "Epoch: 3, Step: 211/655, Loss: 2.202052, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 212/655, Loss: 2.201809, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 213/655, Loss: 2.201408, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 214/655, Loss: 2.201236, Accuracy: 18.68%\n",
            "Epoch: 3, Step: 215/655, Loss: 2.201562, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 216/655, Loss: 2.201849, Accuracy: 18.63%\n",
            "Epoch: 3, Step: 217/655, Loss: 2.201655, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 218/655, Loss: 2.202255, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 219/655, Loss: 2.203116, Accuracy: 18.64%\n",
            "Epoch: 3, Step: 220/655, Loss: 2.203650, Accuracy: 18.61%\n",
            "Epoch: 3, Step: 221/655, Loss: 2.203794, Accuracy: 18.59%\n",
            "Epoch: 3, Step: 222/655, Loss: 2.202925, Accuracy: 18.58%\n",
            "Epoch: 3, Step: 223/655, Loss: 2.203448, Accuracy: 18.55%\n",
            "Epoch: 3, Step: 224/655, Loss: 2.203419, Accuracy: 18.57%\n",
            "Epoch: 3, Step: 225/655, Loss: 2.203040, Accuracy: 18.57%\n",
            "Epoch: 3, Step: 226/655, Loss: 2.203003, Accuracy: 18.60%\n",
            "Epoch: 3, Step: 227/655, Loss: 2.203038, Accuracy: 18.61%\n",
            "Epoch: 3, Step: 228/655, Loss: 2.202881, Accuracy: 18.64%\n",
            "Epoch: 3, Step: 229/655, Loss: 2.203102, Accuracy: 18.64%\n",
            "Epoch: 3, Step: 230/655, Loss: 2.203069, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 231/655, Loss: 2.203212, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 232/655, Loss: 2.203396, Accuracy: 18.63%\n",
            "Epoch: 3, Step: 233/655, Loss: 2.203723, Accuracy: 18.64%\n",
            "Epoch: 3, Step: 234/655, Loss: 2.203939, Accuracy: 18.64%\n",
            "Epoch: 3, Step: 235/655, Loss: 2.203627, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 236/655, Loss: 2.203764, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 237/655, Loss: 2.203528, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 238/655, Loss: 2.203940, Accuracy: 18.64%\n",
            "Epoch: 3, Step: 239/655, Loss: 2.203329, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 240/655, Loss: 2.202929, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 241/655, Loss: 2.203281, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 242/655, Loss: 2.203370, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 243/655, Loss: 2.203309, Accuracy: 18.74%\n",
            "Epoch: 3, Step: 244/655, Loss: 2.203717, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 245/655, Loss: 2.203843, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 246/655, Loss: 2.203973, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 247/655, Loss: 2.204236, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 248/655, Loss: 2.204019, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 249/655, Loss: 2.204216, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 250/655, Loss: 2.204054, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 251/655, Loss: 2.204136, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 252/655, Loss: 2.204319, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 253/655, Loss: 2.204124, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 254/655, Loss: 2.204191, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 255/655, Loss: 2.203743, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 256/655, Loss: 2.203973, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 257/655, Loss: 2.203977, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 258/655, Loss: 2.204364, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 259/655, Loss: 2.204550, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 260/655, Loss: 2.204579, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 261/655, Loss: 2.204890, Accuracy: 18.64%\n",
            "Epoch: 3, Step: 262/655, Loss: 2.204930, Accuracy: 18.62%\n",
            "Epoch: 3, Step: 263/655, Loss: 2.205003, Accuracy: 18.63%\n",
            "Epoch: 3, Step: 264/655, Loss: 2.205568, Accuracy: 18.62%\n",
            "Epoch: 3, Step: 265/655, Loss: 2.205187, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 266/655, Loss: 2.205176, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 267/655, Loss: 2.204601, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 268/655, Loss: 2.204761, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 269/655, Loss: 2.204547, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 270/655, Loss: 2.204417, Accuracy: 18.76%\n",
            "Epoch: 3, Step: 271/655, Loss: 2.204512, Accuracy: 18.76%\n",
            "Epoch: 3, Step: 272/655, Loss: 2.204289, Accuracy: 18.74%\n",
            "Epoch: 3, Step: 273/655, Loss: 2.204469, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 274/655, Loss: 2.204748, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 275/655, Loss: 2.204170, Accuracy: 18.74%\n",
            "Epoch: 3, Step: 276/655, Loss: 2.204426, Accuracy: 18.74%\n",
            "Epoch: 3, Step: 277/655, Loss: 2.204598, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 278/655, Loss: 2.204237, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 279/655, Loss: 2.204062, Accuracy: 18.74%\n",
            "Epoch: 3, Step: 280/655, Loss: 2.204096, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 281/655, Loss: 2.204233, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 282/655, Loss: 2.204292, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 283/655, Loss: 2.204842, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 284/655, Loss: 2.204856, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 285/655, Loss: 2.204773, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 286/655, Loss: 2.205237, Accuracy: 18.64%\n",
            "Epoch: 3, Step: 287/655, Loss: 2.205465, Accuracy: 18.63%\n",
            "Epoch: 3, Step: 288/655, Loss: 2.205600, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 289/655, Loss: 2.205631, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 290/655, Loss: 2.205544, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 291/655, Loss: 2.205498, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 292/655, Loss: 2.205370, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 293/655, Loss: 2.205620, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 294/655, Loss: 2.205334, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 295/655, Loss: 2.204866, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 296/655, Loss: 2.205230, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 297/655, Loss: 2.205265, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 298/655, Loss: 2.205682, Accuracy: 18.68%\n",
            "Epoch: 3, Step: 299/655, Loss: 2.205504, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 300/655, Loss: 2.205740, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 301/655, Loss: 2.205821, Accuracy: 18.68%\n",
            "Epoch: 3, Step: 302/655, Loss: 2.205816, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 303/655, Loss: 2.206077, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 304/655, Loss: 2.206009, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 305/655, Loss: 2.205884, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 306/655, Loss: 2.205503, Accuracy: 18.64%\n",
            "Epoch: 3, Step: 307/655, Loss: 2.205261, Accuracy: 18.65%\n",
            "Epoch: 3, Step: 308/655, Loss: 2.205160, Accuracy: 18.64%\n",
            "Epoch: 3, Step: 309/655, Loss: 2.205569, Accuracy: 18.61%\n",
            "Epoch: 3, Step: 310/655, Loss: 2.205121, Accuracy: 18.65%\n",
            "Epoch: 3, Step: 311/655, Loss: 2.205314, Accuracy: 18.63%\n",
            "Epoch: 3, Step: 312/655, Loss: 2.205344, Accuracy: 18.62%\n",
            "Epoch: 3, Step: 313/655, Loss: 2.205556, Accuracy: 18.60%\n",
            "Epoch: 3, Step: 314/655, Loss: 2.205664, Accuracy: 18.61%\n",
            "Epoch: 3, Step: 315/655, Loss: 2.205512, Accuracy: 18.65%\n",
            "Epoch: 3, Step: 316/655, Loss: 2.205451, Accuracy: 18.63%\n",
            "Epoch: 3, Step: 317/655, Loss: 2.205756, Accuracy: 18.59%\n",
            "Epoch: 3, Step: 318/655, Loss: 2.206186, Accuracy: 18.56%\n",
            "Epoch: 3, Step: 319/655, Loss: 2.206087, Accuracy: 18.60%\n",
            "Epoch: 3, Step: 320/655, Loss: 2.206104, Accuracy: 18.61%\n",
            "Epoch: 3, Step: 321/655, Loss: 2.206012, Accuracy: 18.62%\n",
            "Epoch: 3, Step: 322/655, Loss: 2.205746, Accuracy: 18.62%\n",
            "Epoch: 3, Step: 323/655, Loss: 2.205512, Accuracy: 18.63%\n",
            "Epoch: 3, Step: 324/655, Loss: 2.205285, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 325/655, Loss: 2.205190, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 326/655, Loss: 2.205399, Accuracy: 18.68%\n",
            "Epoch: 3, Step: 327/655, Loss: 2.205272, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 328/655, Loss: 2.205599, Accuracy: 18.68%\n",
            "Epoch: 3, Step: 329/655, Loss: 2.205335, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 330/655, Loss: 2.205265, Accuracy: 18.74%\n",
            "Epoch: 3, Step: 331/655, Loss: 2.205288, Accuracy: 18.74%\n",
            "Epoch: 3, Step: 332/655, Loss: 2.205104, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 333/655, Loss: 2.205046, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 334/655, Loss: 2.204649, Accuracy: 18.76%\n",
            "Epoch: 3, Step: 335/655, Loss: 2.204350, Accuracy: 18.79%\n",
            "Epoch: 3, Step: 336/655, Loss: 2.204413, Accuracy: 18.79%\n",
            "Epoch: 3, Step: 337/655, Loss: 2.204363, Accuracy: 18.78%\n",
            "Epoch: 3, Step: 338/655, Loss: 2.204729, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 339/655, Loss: 2.204356, Accuracy: 18.78%\n",
            "Epoch: 3, Step: 340/655, Loss: 2.204294, Accuracy: 18.78%\n",
            "Epoch: 3, Step: 341/655, Loss: 2.204339, Accuracy: 18.81%\n",
            "Epoch: 3, Step: 342/655, Loss: 2.204316, Accuracy: 18.82%\n",
            "Epoch: 3, Step: 343/655, Loss: 2.204374, Accuracy: 18.82%\n",
            "Epoch: 3, Step: 344/655, Loss: 2.203947, Accuracy: 18.85%\n",
            "Epoch: 3, Step: 345/655, Loss: 2.203783, Accuracy: 18.82%\n",
            "Epoch: 3, Step: 346/655, Loss: 2.203818, Accuracy: 18.83%\n",
            "Epoch: 3, Step: 347/655, Loss: 2.203865, Accuracy: 18.84%\n",
            "Epoch: 3, Step: 348/655, Loss: 2.204515, Accuracy: 18.81%\n",
            "Epoch: 3, Step: 349/655, Loss: 2.204146, Accuracy: 18.82%\n",
            "Epoch: 3, Step: 350/655, Loss: 2.204084, Accuracy: 18.81%\n",
            "Epoch: 3, Step: 351/655, Loss: 2.203938, Accuracy: 18.81%\n",
            "Epoch: 3, Step: 352/655, Loss: 2.204240, Accuracy: 18.81%\n",
            "Epoch: 3, Step: 353/655, Loss: 2.204178, Accuracy: 18.83%\n",
            "Epoch: 3, Step: 354/655, Loss: 2.204121, Accuracy: 18.85%\n",
            "Epoch: 3, Step: 355/655, Loss: 2.204311, Accuracy: 18.86%\n",
            "Epoch: 3, Step: 356/655, Loss: 2.204353, Accuracy: 18.86%\n",
            "Epoch: 3, Step: 357/655, Loss: 2.204714, Accuracy: 18.83%\n",
            "Epoch: 3, Step: 358/655, Loss: 2.204717, Accuracy: 18.83%\n",
            "Epoch: 3, Step: 359/655, Loss: 2.204984, Accuracy: 18.84%\n",
            "Epoch: 3, Step: 360/655, Loss: 2.205285, Accuracy: 18.81%\n",
            "Epoch: 3, Step: 361/655, Loss: 2.205605, Accuracy: 18.81%\n",
            "Epoch: 3, Step: 362/655, Loss: 2.205213, Accuracy: 18.84%\n",
            "Epoch: 3, Step: 363/655, Loss: 2.205011, Accuracy: 18.90%\n",
            "Epoch: 3, Step: 364/655, Loss: 2.204822, Accuracy: 18.96%\n",
            "Epoch: 3, Step: 365/655, Loss: 2.204296, Accuracy: 19.00%\n",
            "Epoch: 3, Step: 366/655, Loss: 2.204266, Accuracy: 19.00%\n",
            "Epoch: 3, Step: 367/655, Loss: 2.204135, Accuracy: 18.97%\n",
            "Epoch: 3, Step: 368/655, Loss: 2.204227, Accuracy: 18.95%\n",
            "Epoch: 3, Step: 369/655, Loss: 2.204383, Accuracy: 18.95%\n",
            "Epoch: 3, Step: 370/655, Loss: 2.204273, Accuracy: 18.95%\n",
            "Epoch: 3, Step: 371/655, Loss: 2.204302, Accuracy: 18.96%\n",
            "Epoch: 3, Step: 372/655, Loss: 2.204418, Accuracy: 18.96%\n",
            "Epoch: 3, Step: 373/655, Loss: 2.203983, Accuracy: 18.98%\n",
            "Epoch: 3, Step: 374/655, Loss: 2.204398, Accuracy: 18.98%\n",
            "Epoch: 3, Step: 375/655, Loss: 2.204416, Accuracy: 18.95%\n",
            "Epoch: 3, Step: 376/655, Loss: 2.204706, Accuracy: 18.95%\n",
            "Epoch: 3, Step: 377/655, Loss: 2.204788, Accuracy: 18.93%\n",
            "Epoch: 3, Step: 378/655, Loss: 2.205015, Accuracy: 18.91%\n",
            "Epoch: 3, Step: 379/655, Loss: 2.205016, Accuracy: 18.92%\n",
            "Epoch: 3, Step: 380/655, Loss: 2.205188, Accuracy: 18.92%\n",
            "Epoch: 3, Step: 381/655, Loss: 2.205183, Accuracy: 18.91%\n",
            "Epoch: 3, Step: 382/655, Loss: 2.205397, Accuracy: 18.89%\n",
            "Epoch: 3, Step: 383/655, Loss: 2.205658, Accuracy: 18.88%\n",
            "Epoch: 3, Step: 384/655, Loss: 2.205979, Accuracy: 18.85%\n",
            "Epoch: 3, Step: 385/655, Loss: 2.206194, Accuracy: 18.81%\n",
            "Epoch: 3, Step: 386/655, Loss: 2.205862, Accuracy: 18.82%\n",
            "Epoch: 3, Step: 387/655, Loss: 2.205743, Accuracy: 18.82%\n",
            "Epoch: 3, Step: 388/655, Loss: 2.205558, Accuracy: 18.84%\n",
            "Epoch: 3, Step: 389/655, Loss: 2.205633, Accuracy: 18.84%\n",
            "Epoch: 3, Step: 390/655, Loss: 2.205882, Accuracy: 18.84%\n",
            "Epoch: 3, Step: 391/655, Loss: 2.205780, Accuracy: 18.84%\n",
            "Epoch: 3, Step: 392/655, Loss: 2.205655, Accuracy: 18.85%\n",
            "Epoch: 3, Step: 393/655, Loss: 2.205630, Accuracy: 18.85%\n",
            "Epoch: 3, Step: 394/655, Loss: 2.205985, Accuracy: 18.82%\n",
            "Epoch: 3, Step: 395/655, Loss: 2.205853, Accuracy: 18.84%\n",
            "Epoch: 3, Step: 396/655, Loss: 2.205909, Accuracy: 18.84%\n",
            "Epoch: 3, Step: 397/655, Loss: 2.205984, Accuracy: 18.83%\n",
            "Epoch: 3, Step: 398/655, Loss: 2.206259, Accuracy: 18.80%\n",
            "Epoch: 3, Step: 399/655, Loss: 2.206446, Accuracy: 18.79%\n",
            "Epoch: 3, Step: 400/655, Loss: 2.206453, Accuracy: 18.78%\n",
            "Epoch: 3, Step: 401/655, Loss: 2.206152, Accuracy: 18.80%\n",
            "Epoch: 3, Step: 402/655, Loss: 2.206110, Accuracy: 18.80%\n",
            "Epoch: 3, Step: 403/655, Loss: 2.206160, Accuracy: 18.78%\n",
            "Epoch: 3, Step: 404/655, Loss: 2.205954, Accuracy: 18.80%\n",
            "Epoch: 3, Step: 405/655, Loss: 2.206097, Accuracy: 18.77%\n",
            "Epoch: 3, Step: 406/655, Loss: 2.206118, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 407/655, Loss: 2.206044, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 408/655, Loss: 2.205907, Accuracy: 18.74%\n",
            "Epoch: 3, Step: 409/655, Loss: 2.205972, Accuracy: 18.74%\n",
            "Epoch: 3, Step: 410/655, Loss: 2.206188, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 411/655, Loss: 2.206431, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 412/655, Loss: 2.206247, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 413/655, Loss: 2.206105, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 414/655, Loss: 2.205808, Accuracy: 18.74%\n",
            "Epoch: 3, Step: 415/655, Loss: 2.205650, Accuracy: 18.74%\n",
            "Epoch: 3, Step: 416/655, Loss: 2.205439, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 417/655, Loss: 2.205486, Accuracy: 18.74%\n",
            "Epoch: 3, Step: 418/655, Loss: 2.205451, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 419/655, Loss: 2.205549, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 420/655, Loss: 2.205953, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 421/655, Loss: 2.205894, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 422/655, Loss: 2.205931, Accuracy: 18.68%\n",
            "Epoch: 3, Step: 423/655, Loss: 2.205903, Accuracy: 18.68%\n",
            "Epoch: 3, Step: 424/655, Loss: 2.206121, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 425/655, Loss: 2.206010, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 426/655, Loss: 2.205919, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 427/655, Loss: 2.206068, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 428/655, Loss: 2.205882, Accuracy: 18.68%\n",
            "Epoch: 3, Step: 429/655, Loss: 2.205700, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 430/655, Loss: 2.205852, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 431/655, Loss: 2.205740, Accuracy: 18.68%\n",
            "Epoch: 3, Step: 432/655, Loss: 2.205582, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 433/655, Loss: 2.205484, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 434/655, Loss: 2.205536, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 435/655, Loss: 2.205781, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 436/655, Loss: 2.205669, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 437/655, Loss: 2.205685, Accuracy: 18.68%\n",
            "Epoch: 3, Step: 438/655, Loss: 2.205618, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 439/655, Loss: 2.205678, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 440/655, Loss: 2.205442, Accuracy: 18.77%\n",
            "Epoch: 3, Step: 441/655, Loss: 2.205442, Accuracy: 18.77%\n",
            "Epoch: 3, Step: 442/655, Loss: 2.205676, Accuracy: 18.76%\n",
            "Epoch: 3, Step: 443/655, Loss: 2.205714, Accuracy: 18.75%\n",
            "Epoch: 3, Step: 444/655, Loss: 2.206494, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 445/655, Loss: 2.206506, Accuracy: 18.74%\n",
            "Epoch: 3, Step: 446/655, Loss: 2.206596, Accuracy: 18.73%\n",
            "Epoch: 3, Step: 447/655, Loss: 2.206465, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 448/655, Loss: 2.206416, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 449/655, Loss: 2.206480, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 450/655, Loss: 2.206800, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 451/655, Loss: 2.206717, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 452/655, Loss: 2.206735, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 453/655, Loss: 2.206472, Accuracy: 18.68%\n",
            "Epoch: 3, Step: 454/655, Loss: 2.206391, Accuracy: 18.68%\n",
            "Epoch: 3, Step: 455/655, Loss: 2.206035, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 456/655, Loss: 2.205750, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 457/655, Loss: 2.205696, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 458/655, Loss: 2.205495, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 459/655, Loss: 2.205486, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 460/655, Loss: 2.205361, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 461/655, Loss: 2.205361, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 462/655, Loss: 2.205470, Accuracy: 18.68%\n",
            "Epoch: 3, Step: 463/655, Loss: 2.205487, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 464/655, Loss: 2.205662, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 465/655, Loss: 2.205523, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 466/655, Loss: 2.205301, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 467/655, Loss: 2.205502, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 468/655, Loss: 2.205573, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 469/655, Loss: 2.205865, Accuracy: 18.68%\n",
            "Epoch: 3, Step: 470/655, Loss: 2.205857, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 471/655, Loss: 2.205988, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 472/655, Loss: 2.205967, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 473/655, Loss: 2.206168, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 474/655, Loss: 2.206073, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 475/655, Loss: 2.206050, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 476/655, Loss: 2.205839, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 477/655, Loss: 2.205847, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 478/655, Loss: 2.205818, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 479/655, Loss: 2.205997, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 480/655, Loss: 2.205993, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 481/655, Loss: 2.206178, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 482/655, Loss: 2.206432, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 483/655, Loss: 2.206447, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 484/655, Loss: 2.206352, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 485/655, Loss: 2.206546, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 486/655, Loss: 2.206716, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 487/655, Loss: 2.206811, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 488/655, Loss: 2.206727, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 489/655, Loss: 2.207052, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 490/655, Loss: 2.207159, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 491/655, Loss: 2.207168, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 492/655, Loss: 2.207036, Accuracy: 18.71%\n",
            "Epoch: 3, Step: 493/655, Loss: 2.206939, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 494/655, Loss: 2.207372, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 495/655, Loss: 2.207260, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 496/655, Loss: 2.207286, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 497/655, Loss: 2.206965, Accuracy: 18.70%\n",
            "Epoch: 3, Step: 498/655, Loss: 2.206886, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 499/655, Loss: 2.206849, Accuracy: 18.72%\n",
            "Epoch: 3, Step: 500/655, Loss: 2.206899, Accuracy: 18.69%\n",
            "Epoch: 3, Step: 501/655, Loss: 2.207037, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 502/655, Loss: 2.207176, Accuracy: 18.67%\n",
            "Epoch: 3, Step: 503/655, Loss: 2.207277, Accuracy: 18.65%\n",
            "Epoch: 3, Step: 504/655, Loss: 2.207175, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 505/655, Loss: 2.207145, Accuracy: 18.65%\n",
            "Epoch: 3, Step: 506/655, Loss: 2.207137, Accuracy: 18.65%\n",
            "Epoch: 3, Step: 507/655, Loss: 2.207304, Accuracy: 18.64%\n",
            "Epoch: 3, Step: 508/655, Loss: 2.207243, Accuracy: 18.64%\n",
            "Epoch: 3, Step: 509/655, Loss: 2.207333, Accuracy: 18.63%\n",
            "Epoch: 3, Step: 510/655, Loss: 2.207437, Accuracy: 18.64%\n",
            "Epoch: 3, Step: 511/655, Loss: 2.207526, Accuracy: 18.65%\n",
            "Epoch: 3, Step: 512/655, Loss: 2.207716, Accuracy: 18.64%\n",
            "Epoch: 3, Step: 513/655, Loss: 2.207751, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 514/655, Loss: 2.208067, Accuracy: 18.66%\n",
            "Epoch: 3, Step: 515/655, Loss: 2.208179, Accuracy: 18.65%\n",
            "Epoch: 3, Step: 516/655, Loss: 2.208353, Accuracy: 18.63%\n",
            "Epoch: 3, Step: 517/655, Loss: 2.208441, Accuracy: 18.63%\n",
            "Epoch: 3, Step: 518/655, Loss: 2.208700, Accuracy: 18.61%\n",
            "Epoch: 3, Step: 519/655, Loss: 2.208620, Accuracy: 18.62%\n",
            "Epoch: 3, Step: 520/655, Loss: 2.208472, Accuracy: 18.62%\n",
            "Epoch: 3, Step: 521/655, Loss: 2.208321, Accuracy: 18.62%\n",
            "Epoch: 3, Step: 522/655, Loss: 2.208497, Accuracy: 18.59%\n",
            "Epoch: 3, Step: 523/655, Loss: 2.208641, Accuracy: 18.58%\n",
            "Epoch: 3, Step: 524/655, Loss: 2.208441, Accuracy: 18.57%\n",
            "Epoch: 3, Step: 525/655, Loss: 2.208465, Accuracy: 18.57%\n",
            "Epoch: 3, Step: 526/655, Loss: 2.208298, Accuracy: 18.60%\n",
            "Epoch: 3, Step: 527/655, Loss: 2.208348, Accuracy: 18.60%\n",
            "Epoch: 3, Step: 528/655, Loss: 2.208492, Accuracy: 18.60%\n",
            "Epoch: 3, Step: 529/655, Loss: 2.208358, Accuracy: 18.60%\n",
            "Epoch: 3, Step: 530/655, Loss: 2.208331, Accuracy: 18.60%\n",
            "Epoch: 3, Step: 531/655, Loss: 2.208168, Accuracy: 18.60%\n",
            "Epoch: 3, Step: 532/655, Loss: 2.208288, Accuracy: 18.58%\n",
            "Epoch: 3, Step: 533/655, Loss: 2.208205, Accuracy: 18.57%\n",
            "Epoch: 3, Step: 534/655, Loss: 2.208210, Accuracy: 18.57%\n",
            "Epoch: 3, Step: 535/655, Loss: 2.208258, Accuracy: 18.56%\n",
            "Epoch: 3, Step: 536/655, Loss: 2.208331, Accuracy: 18.56%\n",
            "Epoch: 3, Step: 537/655, Loss: 2.208419, Accuracy: 18.56%\n",
            "Epoch: 3, Step: 538/655, Loss: 2.208381, Accuracy: 18.56%\n",
            "Epoch: 3, Step: 539/655, Loss: 2.208534, Accuracy: 18.54%\n",
            "Epoch: 3, Step: 540/655, Loss: 2.208725, Accuracy: 18.52%\n",
            "Epoch: 3, Step: 541/655, Loss: 2.208416, Accuracy: 18.54%\n",
            "Epoch: 3, Step: 542/655, Loss: 2.208454, Accuracy: 18.54%\n",
            "Epoch: 3, Step: 543/655, Loss: 2.208290, Accuracy: 18.56%\n",
            "Epoch: 3, Step: 544/655, Loss: 2.208305, Accuracy: 18.55%\n",
            "Epoch: 3, Step: 545/655, Loss: 2.208269, Accuracy: 18.56%\n",
            "Epoch: 3, Step: 546/655, Loss: 2.208626, Accuracy: 18.53%\n",
            "Epoch: 3, Step: 547/655, Loss: 2.208693, Accuracy: 18.52%\n",
            "Epoch: 3, Step: 548/655, Loss: 2.208803, Accuracy: 18.53%\n",
            "Epoch: 3, Step: 549/655, Loss: 2.208753, Accuracy: 18.53%\n",
            "Epoch: 3, Step: 550/655, Loss: 2.208793, Accuracy: 18.53%\n",
            "Epoch: 3, Step: 551/655, Loss: 2.208940, Accuracy: 18.52%\n",
            "Epoch: 3, Step: 552/655, Loss: 2.208981, Accuracy: 18.51%\n",
            "Epoch: 3, Step: 553/655, Loss: 2.208829, Accuracy: 18.50%\n",
            "Epoch: 3, Step: 554/655, Loss: 2.208960, Accuracy: 18.50%\n",
            "Epoch: 3, Step: 555/655, Loss: 2.208930, Accuracy: 18.51%\n",
            "Epoch: 3, Step: 556/655, Loss: 2.208977, Accuracy: 18.50%\n",
            "Epoch: 3, Step: 557/655, Loss: 2.208794, Accuracy: 18.51%\n",
            "Epoch: 3, Step: 558/655, Loss: 2.208938, Accuracy: 18.50%\n",
            "Epoch: 3, Step: 559/655, Loss: 2.208956, Accuracy: 18.49%\n",
            "Epoch: 3, Step: 560/655, Loss: 2.209104, Accuracy: 18.49%\n",
            "Epoch: 3, Step: 561/655, Loss: 2.209057, Accuracy: 18.49%\n",
            "Epoch: 3, Step: 562/655, Loss: 2.209144, Accuracy: 18.49%\n",
            "Epoch: 3, Step: 563/655, Loss: 2.209214, Accuracy: 18.47%\n",
            "Epoch: 3, Step: 564/655, Loss: 2.209367, Accuracy: 18.46%\n",
            "Epoch: 3, Step: 565/655, Loss: 2.209390, Accuracy: 18.46%\n",
            "Epoch: 3, Step: 566/655, Loss: 2.209404, Accuracy: 18.44%\n",
            "Epoch: 3, Step: 567/655, Loss: 2.209447, Accuracy: 18.45%\n",
            "Epoch: 3, Step: 568/655, Loss: 2.209494, Accuracy: 18.46%\n",
            "Epoch: 3, Step: 569/655, Loss: 2.209446, Accuracy: 18.46%\n",
            "Epoch: 3, Step: 570/655, Loss: 2.209551, Accuracy: 18.45%\n",
            "Epoch: 3, Step: 571/655, Loss: 2.209561, Accuracy: 18.47%\n",
            "Epoch: 3, Step: 572/655, Loss: 2.209687, Accuracy: 18.48%\n",
            "Epoch: 3, Step: 573/655, Loss: 2.209760, Accuracy: 18.46%\n",
            "Epoch: 3, Step: 574/655, Loss: 2.209683, Accuracy: 18.46%\n",
            "Epoch: 3, Step: 575/655, Loss: 2.209499, Accuracy: 18.47%\n",
            "Epoch: 3, Step: 576/655, Loss: 2.209552, Accuracy: 18.48%\n",
            "Epoch: 3, Step: 577/655, Loss: 2.209526, Accuracy: 18.48%\n",
            "Epoch: 3, Step: 578/655, Loss: 2.209402, Accuracy: 18.50%\n",
            "Epoch: 3, Step: 579/655, Loss: 2.209203, Accuracy: 18.50%\n",
            "Epoch: 3, Step: 580/655, Loss: 2.209165, Accuracy: 18.50%\n",
            "Epoch: 3, Step: 581/655, Loss: 2.209071, Accuracy: 18.50%\n",
            "Epoch: 3, Step: 582/655, Loss: 2.209241, Accuracy: 18.49%\n",
            "Epoch: 3, Step: 583/655, Loss: 2.209314, Accuracy: 18.49%\n",
            "Epoch: 3, Step: 584/655, Loss: 2.209370, Accuracy: 18.48%\n",
            "Epoch: 3, Step: 585/655, Loss: 2.209308, Accuracy: 18.49%\n",
            "Epoch: 3, Step: 586/655, Loss: 2.209411, Accuracy: 18.49%\n",
            "Epoch: 3, Step: 587/655, Loss: 2.209475, Accuracy: 18.48%\n",
            "Epoch: 3, Step: 588/655, Loss: 2.209713, Accuracy: 18.46%\n",
            "Epoch: 3, Step: 589/655, Loss: 2.209625, Accuracy: 18.48%\n",
            "Epoch: 3, Step: 590/655, Loss: 2.209766, Accuracy: 18.48%\n",
            "Epoch: 3, Step: 591/655, Loss: 2.209525, Accuracy: 18.50%\n",
            "Epoch: 3, Step: 592/655, Loss: 2.209621, Accuracy: 18.49%\n",
            "Epoch: 3, Step: 593/655, Loss: 2.209748, Accuracy: 18.48%\n",
            "Epoch: 3, Step: 594/655, Loss: 2.209824, Accuracy: 18.47%\n",
            "Epoch: 3, Step: 595/655, Loss: 2.209896, Accuracy: 18.46%\n",
            "Epoch: 3, Step: 596/655, Loss: 2.209891, Accuracy: 18.45%\n",
            "Epoch: 3, Step: 597/655, Loss: 2.209804, Accuracy: 18.45%\n",
            "Epoch: 3, Step: 598/655, Loss: 2.209547, Accuracy: 18.45%\n",
            "Epoch: 3, Step: 599/655, Loss: 2.209580, Accuracy: 18.44%\n",
            "Epoch: 3, Step: 600/655, Loss: 2.209401, Accuracy: 18.46%\n",
            "Epoch: 3, Step: 601/655, Loss: 2.209517, Accuracy: 18.46%\n",
            "Epoch: 3, Step: 602/655, Loss: 2.209416, Accuracy: 18.47%\n",
            "Epoch: 3, Step: 603/655, Loss: 2.209384, Accuracy: 18.46%\n",
            "Epoch: 3, Step: 604/655, Loss: 2.209309, Accuracy: 18.44%\n",
            "Epoch: 3, Step: 605/655, Loss: 2.209144, Accuracy: 18.45%\n",
            "Epoch: 3, Step: 606/655, Loss: 2.208878, Accuracy: 18.46%\n",
            "Epoch: 3, Step: 607/655, Loss: 2.208824, Accuracy: 18.47%\n",
            "Epoch: 3, Step: 608/655, Loss: 2.208841, Accuracy: 18.46%\n",
            "Epoch: 3, Step: 609/655, Loss: 2.208997, Accuracy: 18.44%\n",
            "Epoch: 3, Step: 610/655, Loss: 2.208996, Accuracy: 18.42%\n",
            "Epoch: 3, Step: 611/655, Loss: 2.209223, Accuracy: 18.42%\n",
            "Epoch: 3, Step: 612/655, Loss: 2.209130, Accuracy: 18.43%\n",
            "Epoch: 3, Step: 613/655, Loss: 2.209155, Accuracy: 18.43%\n",
            "Epoch: 3, Step: 614/655, Loss: 2.209308, Accuracy: 18.41%\n",
            "Epoch: 3, Step: 615/655, Loss: 2.209355, Accuracy: 18.41%\n",
            "Epoch: 3, Step: 616/655, Loss: 2.209237, Accuracy: 18.43%\n",
            "Epoch: 3, Step: 617/655, Loss: 2.209462, Accuracy: 18.43%\n",
            "Epoch: 3, Step: 618/655, Loss: 2.209499, Accuracy: 18.43%\n",
            "Epoch: 3, Step: 619/655, Loss: 2.209440, Accuracy: 18.42%\n",
            "Epoch: 3, Step: 620/655, Loss: 2.209379, Accuracy: 18.40%\n",
            "Epoch: 3, Step: 621/655, Loss: 2.209251, Accuracy: 18.42%\n",
            "Epoch: 3, Step: 622/655, Loss: 2.209489, Accuracy: 18.40%\n",
            "Epoch: 3, Step: 623/655, Loss: 2.209547, Accuracy: 18.39%\n",
            "Epoch: 3, Step: 624/655, Loss: 2.209505, Accuracy: 18.40%\n",
            "Epoch: 3, Step: 625/655, Loss: 2.209446, Accuracy: 18.41%\n",
            "Epoch: 3, Step: 626/655, Loss: 2.209484, Accuracy: 18.40%\n",
            "Epoch: 3, Step: 627/655, Loss: 2.209640, Accuracy: 18.40%\n",
            "Epoch: 3, Step: 628/655, Loss: 2.209782, Accuracy: 18.41%\n",
            "Epoch: 3, Step: 629/655, Loss: 2.209830, Accuracy: 18.42%\n",
            "Epoch: 3, Step: 630/655, Loss: 2.209850, Accuracy: 18.42%\n",
            "Epoch: 3, Step: 631/655, Loss: 2.209699, Accuracy: 18.42%\n",
            "Epoch: 3, Step: 632/655, Loss: 2.209518, Accuracy: 18.42%\n",
            "Epoch: 3, Step: 633/655, Loss: 2.209493, Accuracy: 18.41%\n",
            "Epoch: 3, Step: 634/655, Loss: 2.209432, Accuracy: 18.43%\n",
            "Epoch: 3, Step: 635/655, Loss: 2.209362, Accuracy: 18.44%\n",
            "Epoch: 3, Step: 636/655, Loss: 2.209273, Accuracy: 18.43%\n",
            "Epoch: 3, Step: 637/655, Loss: 2.209262, Accuracy: 18.42%\n",
            "Epoch: 3, Step: 638/655, Loss: 2.209290, Accuracy: 18.42%\n",
            "Epoch: 3, Step: 639/655, Loss: 2.209063, Accuracy: 18.44%\n",
            "Epoch: 3, Step: 640/655, Loss: 2.209011, Accuracy: 18.42%\n",
            "Epoch: 3, Step: 641/655, Loss: 2.209220, Accuracy: 18.41%\n",
            "Epoch: 3, Step: 642/655, Loss: 2.209329, Accuracy: 18.40%\n",
            "Epoch: 3, Step: 643/655, Loss: 2.209479, Accuracy: 18.40%\n",
            "Epoch: 3, Step: 644/655, Loss: 2.209579, Accuracy: 18.40%\n",
            "Epoch: 3, Step: 645/655, Loss: 2.209440, Accuracy: 18.40%\n",
            "Epoch: 3, Step: 646/655, Loss: 2.209533, Accuracy: 18.38%\n",
            "Epoch: 3, Step: 647/655, Loss: 2.209677, Accuracy: 18.37%\n",
            "Epoch: 3, Step: 648/655, Loss: 2.209441, Accuracy: 18.38%\n",
            "Epoch: 3, Step: 649/655, Loss: 2.209560, Accuracy: 18.37%\n",
            "Epoch: 3, Step: 650/655, Loss: 2.209446, Accuracy: 18.38%\n",
            "Epoch: 3, Step: 651/655, Loss: 2.209419, Accuracy: 18.38%\n",
            "Epoch: 3, Step: 652/655, Loss: 2.209311, Accuracy: 18.39%\n",
            "Epoch: 3, Step: 653/655, Loss: 2.209328, Accuracy: 18.37%\n",
            "Epoch: 3, Step: 654/655, Loss: 2.209203, Accuracy: 18.36%\n",
            "Epoch: 3, Step: 655/655, Loss: 2.209335, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 1/655, Loss: 2.171281, Accuracy: 18.75%\n",
            "Epoch: 4, Step: 2/655, Loss: 2.131316, Accuracy: 20.31%\n",
            "Epoch: 4, Step: 3/655, Loss: 2.136323, Accuracy: 20.83%\n",
            "Epoch: 4, Step: 4/655, Loss: 2.164899, Accuracy: 21.09%\n",
            "Epoch: 4, Step: 5/655, Loss: 2.178042, Accuracy: 18.75%\n",
            "Epoch: 4, Step: 6/655, Loss: 2.192657, Accuracy: 18.75%\n",
            "Epoch: 4, Step: 7/655, Loss: 2.201076, Accuracy: 18.30%\n",
            "Epoch: 4, Step: 8/655, Loss: 2.200393, Accuracy: 17.97%\n",
            "Epoch: 4, Step: 9/655, Loss: 2.208422, Accuracy: 17.36%\n",
            "Epoch: 4, Step: 10/655, Loss: 2.215230, Accuracy: 17.81%\n",
            "Epoch: 4, Step: 11/655, Loss: 2.203708, Accuracy: 18.18%\n",
            "Epoch: 4, Step: 12/655, Loss: 2.211271, Accuracy: 17.71%\n",
            "Epoch: 4, Step: 13/655, Loss: 2.226581, Accuracy: 16.35%\n",
            "Epoch: 4, Step: 14/655, Loss: 2.223341, Accuracy: 16.29%\n",
            "Epoch: 4, Step: 15/655, Loss: 2.227567, Accuracy: 16.46%\n",
            "Epoch: 4, Step: 16/655, Loss: 2.216337, Accuracy: 17.38%\n",
            "Epoch: 4, Step: 17/655, Loss: 2.219316, Accuracy: 16.91%\n",
            "Epoch: 4, Step: 18/655, Loss: 2.214127, Accuracy: 17.19%\n",
            "Epoch: 4, Step: 19/655, Loss: 2.215148, Accuracy: 17.11%\n",
            "Epoch: 4, Step: 20/655, Loss: 2.212197, Accuracy: 17.66%\n",
            "Epoch: 4, Step: 21/655, Loss: 2.210727, Accuracy: 17.26%\n",
            "Epoch: 4, Step: 22/655, Loss: 2.210598, Accuracy: 17.61%\n",
            "Epoch: 4, Step: 23/655, Loss: 2.213215, Accuracy: 17.66%\n",
            "Epoch: 4, Step: 24/655, Loss: 2.213870, Accuracy: 17.45%\n",
            "Epoch: 4, Step: 25/655, Loss: 2.214098, Accuracy: 17.25%\n",
            "Epoch: 4, Step: 26/655, Loss: 2.216978, Accuracy: 17.07%\n",
            "Epoch: 4, Step: 27/655, Loss: 2.220127, Accuracy: 16.78%\n",
            "Epoch: 4, Step: 28/655, Loss: 2.222463, Accuracy: 17.19%\n",
            "Epoch: 4, Step: 29/655, Loss: 2.220841, Accuracy: 17.46%\n",
            "Epoch: 4, Step: 30/655, Loss: 2.217068, Accuracy: 17.71%\n",
            "Epoch: 4, Step: 31/655, Loss: 2.216998, Accuracy: 17.34%\n",
            "Epoch: 4, Step: 32/655, Loss: 2.214407, Accuracy: 17.58%\n",
            "Epoch: 4, Step: 33/655, Loss: 2.214819, Accuracy: 17.42%\n",
            "Epoch: 4, Step: 34/655, Loss: 2.214472, Accuracy: 17.56%\n",
            "Epoch: 4, Step: 35/655, Loss: 2.211332, Accuracy: 17.86%\n",
            "Epoch: 4, Step: 36/655, Loss: 2.208997, Accuracy: 18.23%\n",
            "Epoch: 4, Step: 37/655, Loss: 2.210781, Accuracy: 18.24%\n",
            "Epoch: 4, Step: 38/655, Loss: 2.210737, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 39/655, Loss: 2.213524, Accuracy: 18.27%\n",
            "Epoch: 4, Step: 40/655, Loss: 2.212351, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 41/655, Loss: 2.210711, Accuracy: 18.22%\n",
            "Epoch: 4, Step: 42/655, Loss: 2.209996, Accuracy: 18.23%\n",
            "Epoch: 4, Step: 43/655, Loss: 2.213737, Accuracy: 18.10%\n",
            "Epoch: 4, Step: 44/655, Loss: 2.212514, Accuracy: 18.25%\n",
            "Epoch: 4, Step: 45/655, Loss: 2.212514, Accuracy: 18.12%\n",
            "Epoch: 4, Step: 46/655, Loss: 2.212143, Accuracy: 18.21%\n",
            "Epoch: 4, Step: 47/655, Loss: 2.211605, Accuracy: 18.35%\n",
            "Epoch: 4, Step: 48/655, Loss: 2.214292, Accuracy: 18.16%\n",
            "Epoch: 4, Step: 49/655, Loss: 2.215779, Accuracy: 17.98%\n",
            "Epoch: 4, Step: 50/655, Loss: 2.217184, Accuracy: 18.00%\n",
            "Epoch: 4, Step: 51/655, Loss: 2.218633, Accuracy: 18.01%\n",
            "Epoch: 4, Step: 52/655, Loss: 2.218230, Accuracy: 17.97%\n",
            "Epoch: 4, Step: 53/655, Loss: 2.217479, Accuracy: 18.16%\n",
            "Epoch: 4, Step: 54/655, Loss: 2.216780, Accuracy: 18.17%\n",
            "Epoch: 4, Step: 55/655, Loss: 2.215411, Accuracy: 18.18%\n",
            "Epoch: 4, Step: 56/655, Loss: 2.214314, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 57/655, Loss: 2.212880, Accuracy: 18.37%\n",
            "Epoch: 4, Step: 58/655, Loss: 2.215606, Accuracy: 18.27%\n",
            "Epoch: 4, Step: 59/655, Loss: 2.217405, Accuracy: 18.22%\n",
            "Epoch: 4, Step: 60/655, Loss: 2.217172, Accuracy: 18.18%\n",
            "Epoch: 4, Step: 61/655, Loss: 2.215807, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 62/655, Loss: 2.216918, Accuracy: 18.30%\n",
            "Epoch: 4, Step: 63/655, Loss: 2.216039, Accuracy: 18.25%\n",
            "Epoch: 4, Step: 64/655, Loss: 2.216363, Accuracy: 18.21%\n",
            "Epoch: 4, Step: 65/655, Loss: 2.217039, Accuracy: 18.22%\n",
            "Epoch: 4, Step: 66/655, Loss: 2.217653, Accuracy: 18.28%\n",
            "Epoch: 4, Step: 67/655, Loss: 2.217318, Accuracy: 18.24%\n",
            "Epoch: 4, Step: 68/655, Loss: 2.218389, Accuracy: 18.15%\n",
            "Epoch: 4, Step: 69/655, Loss: 2.219350, Accuracy: 18.07%\n",
            "Epoch: 4, Step: 70/655, Loss: 2.218213, Accuracy: 18.08%\n",
            "Epoch: 4, Step: 71/655, Loss: 2.217269, Accuracy: 18.09%\n",
            "Epoch: 4, Step: 72/655, Loss: 2.217407, Accuracy: 17.97%\n",
            "Epoch: 4, Step: 73/655, Loss: 2.216106, Accuracy: 17.89%\n",
            "Epoch: 4, Step: 74/655, Loss: 2.216619, Accuracy: 17.95%\n",
            "Epoch: 4, Step: 75/655, Loss: 2.214878, Accuracy: 17.92%\n",
            "Epoch: 4, Step: 76/655, Loss: 2.214631, Accuracy: 17.85%\n",
            "Epoch: 4, Step: 77/655, Loss: 2.214676, Accuracy: 17.94%\n",
            "Epoch: 4, Step: 78/655, Loss: 2.213728, Accuracy: 18.03%\n",
            "Epoch: 4, Step: 79/655, Loss: 2.213420, Accuracy: 18.00%\n",
            "Epoch: 4, Step: 80/655, Loss: 2.211802, Accuracy: 18.09%\n",
            "Epoch: 4, Step: 81/655, Loss: 2.211803, Accuracy: 18.17%\n",
            "Epoch: 4, Step: 82/655, Loss: 2.211803, Accuracy: 18.18%\n",
            "Epoch: 4, Step: 83/655, Loss: 2.210181, Accuracy: 18.30%\n",
            "Epoch: 4, Step: 84/655, Loss: 2.210049, Accuracy: 18.30%\n",
            "Epoch: 4, Step: 85/655, Loss: 2.209907, Accuracy: 18.27%\n",
            "Epoch: 4, Step: 86/655, Loss: 2.208294, Accuracy: 18.42%\n",
            "Epoch: 4, Step: 87/655, Loss: 2.210055, Accuracy: 18.39%\n",
            "Epoch: 4, Step: 88/655, Loss: 2.210784, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 89/655, Loss: 2.211716, Accuracy: 18.22%\n",
            "Epoch: 4, Step: 90/655, Loss: 2.210949, Accuracy: 18.26%\n",
            "Epoch: 4, Step: 91/655, Loss: 2.211632, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 92/655, Loss: 2.210362, Accuracy: 18.27%\n",
            "Epoch: 4, Step: 93/655, Loss: 2.209333, Accuracy: 18.28%\n",
            "Epoch: 4, Step: 94/655, Loss: 2.209194, Accuracy: 18.18%\n",
            "Epoch: 4, Step: 95/655, Loss: 2.209851, Accuracy: 18.16%\n",
            "Epoch: 4, Step: 96/655, Loss: 2.209799, Accuracy: 18.13%\n",
            "Epoch: 4, Step: 97/655, Loss: 2.209760, Accuracy: 18.17%\n",
            "Epoch: 4, Step: 98/655, Loss: 2.209488, Accuracy: 18.08%\n",
            "Epoch: 4, Step: 99/655, Loss: 2.209573, Accuracy: 18.06%\n",
            "Epoch: 4, Step: 100/655, Loss: 2.209913, Accuracy: 18.00%\n",
            "Epoch: 4, Step: 101/655, Loss: 2.211285, Accuracy: 17.98%\n",
            "Epoch: 4, Step: 102/655, Loss: 2.211857, Accuracy: 17.92%\n",
            "Epoch: 4, Step: 103/655, Loss: 2.212133, Accuracy: 17.99%\n",
            "Epoch: 4, Step: 104/655, Loss: 2.212344, Accuracy: 17.97%\n",
            "Epoch: 4, Step: 105/655, Loss: 2.212520, Accuracy: 17.95%\n",
            "Epoch: 4, Step: 106/655, Loss: 2.212191, Accuracy: 17.92%\n",
            "Epoch: 4, Step: 107/655, Loss: 2.212031, Accuracy: 17.93%\n",
            "Epoch: 4, Step: 108/655, Loss: 2.213103, Accuracy: 17.91%\n",
            "Epoch: 4, Step: 109/655, Loss: 2.212398, Accuracy: 18.00%\n",
            "Epoch: 4, Step: 110/655, Loss: 2.212595, Accuracy: 17.95%\n",
            "Epoch: 4, Step: 111/655, Loss: 2.213463, Accuracy: 17.91%\n",
            "Epoch: 4, Step: 112/655, Loss: 2.213501, Accuracy: 17.94%\n",
            "Epoch: 4, Step: 113/655, Loss: 2.212918, Accuracy: 17.95%\n",
            "Epoch: 4, Step: 114/655, Loss: 2.213841, Accuracy: 17.90%\n",
            "Epoch: 4, Step: 115/655, Loss: 2.213748, Accuracy: 17.88%\n",
            "Epoch: 4, Step: 116/655, Loss: 2.213416, Accuracy: 17.91%\n",
            "Epoch: 4, Step: 117/655, Loss: 2.213624, Accuracy: 17.87%\n",
            "Epoch: 4, Step: 118/655, Loss: 2.213891, Accuracy: 17.90%\n",
            "Epoch: 4, Step: 119/655, Loss: 2.213474, Accuracy: 17.83%\n",
            "Epoch: 4, Step: 120/655, Loss: 2.213566, Accuracy: 17.81%\n",
            "Epoch: 4, Step: 121/655, Loss: 2.212977, Accuracy: 17.95%\n",
            "Epoch: 4, Step: 122/655, Loss: 2.212957, Accuracy: 17.93%\n",
            "Epoch: 4, Step: 123/655, Loss: 2.212348, Accuracy: 18.04%\n",
            "Epoch: 4, Step: 124/655, Loss: 2.212383, Accuracy: 18.04%\n",
            "Epoch: 4, Step: 125/655, Loss: 2.211497, Accuracy: 18.10%\n",
            "Epoch: 4, Step: 126/655, Loss: 2.211617, Accuracy: 18.08%\n",
            "Epoch: 4, Step: 127/655, Loss: 2.212136, Accuracy: 18.09%\n",
            "Epoch: 4, Step: 128/655, Loss: 2.212360, Accuracy: 18.02%\n",
            "Epoch: 4, Step: 129/655, Loss: 2.211826, Accuracy: 18.00%\n",
            "Epoch: 4, Step: 130/655, Loss: 2.211470, Accuracy: 18.05%\n",
            "Epoch: 4, Step: 131/655, Loss: 2.210467, Accuracy: 18.03%\n",
            "Epoch: 4, Step: 132/655, Loss: 2.210672, Accuracy: 18.09%\n",
            "Epoch: 4, Step: 133/655, Loss: 2.210132, Accuracy: 18.16%\n",
            "Epoch: 4, Step: 134/655, Loss: 2.210900, Accuracy: 18.19%\n",
            "Epoch: 4, Step: 135/655, Loss: 2.210670, Accuracy: 18.22%\n",
            "Epoch: 4, Step: 136/655, Loss: 2.210364, Accuracy: 18.20%\n",
            "Epoch: 4, Step: 137/655, Loss: 2.209862, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 138/655, Loss: 2.209786, Accuracy: 18.27%\n",
            "Epoch: 4, Step: 139/655, Loss: 2.209462, Accuracy: 18.26%\n",
            "Epoch: 4, Step: 140/655, Loss: 2.210107, Accuracy: 18.30%\n",
            "Epoch: 4, Step: 141/655, Loss: 2.210790, Accuracy: 18.24%\n",
            "Epoch: 4, Step: 142/655, Loss: 2.210342, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 143/655, Loss: 2.210465, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 144/655, Loss: 2.210257, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 145/655, Loss: 2.210408, Accuracy: 18.38%\n",
            "Epoch: 4, Step: 146/655, Loss: 2.209874, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 147/655, Loss: 2.210747, Accuracy: 18.41%\n",
            "Epoch: 4, Step: 148/655, Loss: 2.211187, Accuracy: 18.35%\n",
            "Epoch: 4, Step: 149/655, Loss: 2.212148, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 150/655, Loss: 2.211776, Accuracy: 18.35%\n",
            "Epoch: 4, Step: 151/655, Loss: 2.210885, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 152/655, Loss: 2.211348, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 153/655, Loss: 2.210914, Accuracy: 18.50%\n",
            "Epoch: 4, Step: 154/655, Loss: 2.210695, Accuracy: 18.53%\n",
            "Epoch: 4, Step: 155/655, Loss: 2.209476, Accuracy: 18.61%\n",
            "Epoch: 4, Step: 156/655, Loss: 2.209320, Accuracy: 18.59%\n",
            "Epoch: 4, Step: 157/655, Loss: 2.208304, Accuracy: 18.63%\n",
            "Epoch: 4, Step: 158/655, Loss: 2.208539, Accuracy: 18.57%\n",
            "Epoch: 4, Step: 159/655, Loss: 2.208554, Accuracy: 18.59%\n",
            "Epoch: 4, Step: 160/655, Loss: 2.208654, Accuracy: 18.57%\n",
            "Epoch: 4, Step: 161/655, Loss: 2.209303, Accuracy: 18.50%\n",
            "Epoch: 4, Step: 162/655, Loss: 2.208800, Accuracy: 18.50%\n",
            "Epoch: 4, Step: 163/655, Loss: 2.209615, Accuracy: 18.48%\n",
            "Epoch: 4, Step: 164/655, Loss: 2.209611, Accuracy: 18.52%\n",
            "Epoch: 4, Step: 165/655, Loss: 2.209361, Accuracy: 18.52%\n",
            "Epoch: 4, Step: 166/655, Loss: 2.209484, Accuracy: 18.49%\n",
            "Epoch: 4, Step: 167/655, Loss: 2.210715, Accuracy: 18.39%\n",
            "Epoch: 4, Step: 168/655, Loss: 2.210097, Accuracy: 18.38%\n",
            "Epoch: 4, Step: 169/655, Loss: 2.210156, Accuracy: 18.38%\n",
            "Epoch: 4, Step: 170/655, Loss: 2.210180, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 171/655, Loss: 2.208759, Accuracy: 18.35%\n",
            "Epoch: 4, Step: 172/655, Loss: 2.209755, Accuracy: 18.37%\n",
            "Epoch: 4, Step: 173/655, Loss: 2.209717, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 174/655, Loss: 2.209435, Accuracy: 18.48%\n",
            "Epoch: 4, Step: 175/655, Loss: 2.210295, Accuracy: 18.41%\n",
            "Epoch: 4, Step: 176/655, Loss: 2.211001, Accuracy: 18.38%\n",
            "Epoch: 4, Step: 177/655, Loss: 2.211083, Accuracy: 18.40%\n",
            "Epoch: 4, Step: 178/655, Loss: 2.210455, Accuracy: 18.43%\n",
            "Epoch: 4, Step: 179/655, Loss: 2.209714, Accuracy: 18.47%\n",
            "Epoch: 4, Step: 180/655, Loss: 2.209248, Accuracy: 18.51%\n",
            "Epoch: 4, Step: 181/655, Loss: 2.208571, Accuracy: 18.63%\n",
            "Epoch: 4, Step: 182/655, Loss: 2.208815, Accuracy: 18.61%\n",
            "Epoch: 4, Step: 183/655, Loss: 2.208657, Accuracy: 18.61%\n",
            "Epoch: 4, Step: 184/655, Loss: 2.209016, Accuracy: 18.63%\n",
            "Epoch: 4, Step: 185/655, Loss: 2.208649, Accuracy: 18.61%\n",
            "Epoch: 4, Step: 186/655, Loss: 2.208306, Accuracy: 18.65%\n",
            "Epoch: 4, Step: 187/655, Loss: 2.207519, Accuracy: 18.70%\n",
            "Epoch: 4, Step: 188/655, Loss: 2.206986, Accuracy: 18.70%\n",
            "Epoch: 4, Step: 189/655, Loss: 2.207000, Accuracy: 18.72%\n",
            "Epoch: 4, Step: 190/655, Loss: 2.206535, Accuracy: 18.80%\n",
            "Epoch: 4, Step: 191/655, Loss: 2.205686, Accuracy: 18.91%\n",
            "Epoch: 4, Step: 192/655, Loss: 2.205094, Accuracy: 18.95%\n",
            "Epoch: 4, Step: 193/655, Loss: 2.205732, Accuracy: 18.91%\n",
            "Epoch: 4, Step: 194/655, Loss: 2.205668, Accuracy: 18.94%\n",
            "Epoch: 4, Step: 195/655, Loss: 2.205290, Accuracy: 18.91%\n",
            "Epoch: 4, Step: 196/655, Loss: 2.205109, Accuracy: 18.91%\n",
            "Epoch: 4, Step: 197/655, Loss: 2.205084, Accuracy: 18.88%\n",
            "Epoch: 4, Step: 198/655, Loss: 2.205639, Accuracy: 18.83%\n",
            "Epoch: 4, Step: 199/655, Loss: 2.205858, Accuracy: 18.84%\n",
            "Epoch: 4, Step: 200/655, Loss: 2.206398, Accuracy: 18.83%\n",
            "Epoch: 4, Step: 201/655, Loss: 2.206463, Accuracy: 18.81%\n",
            "Epoch: 4, Step: 202/655, Loss: 2.206584, Accuracy: 18.78%\n",
            "Epoch: 4, Step: 203/655, Loss: 2.206822, Accuracy: 18.73%\n",
            "Epoch: 4, Step: 204/655, Loss: 2.206641, Accuracy: 18.73%\n",
            "Epoch: 4, Step: 205/655, Loss: 2.206260, Accuracy: 18.77%\n",
            "Epoch: 4, Step: 206/655, Loss: 2.206018, Accuracy: 18.75%\n",
            "Epoch: 4, Step: 207/655, Loss: 2.206903, Accuracy: 18.70%\n",
            "Epoch: 4, Step: 208/655, Loss: 2.207194, Accuracy: 18.70%\n",
            "Epoch: 4, Step: 209/655, Loss: 2.207203, Accuracy: 18.72%\n",
            "Epoch: 4, Step: 210/655, Loss: 2.207819, Accuracy: 18.68%\n",
            "Epoch: 4, Step: 211/655, Loss: 2.207766, Accuracy: 18.69%\n",
            "Epoch: 4, Step: 212/655, Loss: 2.208241, Accuracy: 18.66%\n",
            "Epoch: 4, Step: 213/655, Loss: 2.208186, Accuracy: 18.68%\n",
            "Epoch: 4, Step: 214/655, Loss: 2.207751, Accuracy: 18.66%\n",
            "Epoch: 4, Step: 215/655, Loss: 2.208360, Accuracy: 18.66%\n",
            "Epoch: 4, Step: 216/655, Loss: 2.208331, Accuracy: 18.66%\n",
            "Epoch: 4, Step: 217/655, Loss: 2.208575, Accuracy: 18.65%\n",
            "Epoch: 4, Step: 218/655, Loss: 2.208529, Accuracy: 18.66%\n",
            "Epoch: 4, Step: 219/655, Loss: 2.208105, Accuracy: 18.68%\n",
            "Epoch: 4, Step: 220/655, Loss: 2.207929, Accuracy: 18.69%\n",
            "Epoch: 4, Step: 221/655, Loss: 2.207890, Accuracy: 18.71%\n",
            "Epoch: 4, Step: 222/655, Loss: 2.207181, Accuracy: 18.76%\n",
            "Epoch: 4, Step: 223/655, Loss: 2.207673, Accuracy: 18.72%\n",
            "Epoch: 4, Step: 224/655, Loss: 2.207626, Accuracy: 18.76%\n",
            "Epoch: 4, Step: 225/655, Loss: 2.207806, Accuracy: 18.78%\n",
            "Epoch: 4, Step: 226/655, Loss: 2.208062, Accuracy: 18.72%\n",
            "Epoch: 4, Step: 227/655, Loss: 2.207727, Accuracy: 18.75%\n",
            "Epoch: 4, Step: 228/655, Loss: 2.207826, Accuracy: 18.78%\n",
            "Epoch: 4, Step: 229/655, Loss: 2.208368, Accuracy: 18.79%\n",
            "Epoch: 4, Step: 230/655, Loss: 2.209046, Accuracy: 18.80%\n",
            "Epoch: 4, Step: 231/655, Loss: 2.209223, Accuracy: 18.80%\n",
            "Epoch: 4, Step: 232/655, Loss: 2.208866, Accuracy: 18.82%\n",
            "Epoch: 4, Step: 233/655, Loss: 2.208567, Accuracy: 18.83%\n",
            "Epoch: 4, Step: 234/655, Loss: 2.208384, Accuracy: 18.86%\n",
            "Epoch: 4, Step: 235/655, Loss: 2.208530, Accuracy: 18.82%\n",
            "Epoch: 4, Step: 236/655, Loss: 2.208682, Accuracy: 18.84%\n",
            "Epoch: 4, Step: 237/655, Loss: 2.209129, Accuracy: 18.83%\n",
            "Epoch: 4, Step: 238/655, Loss: 2.209059, Accuracy: 18.84%\n",
            "Epoch: 4, Step: 239/655, Loss: 2.208942, Accuracy: 18.84%\n",
            "Epoch: 4, Step: 240/655, Loss: 2.208845, Accuracy: 18.87%\n",
            "Epoch: 4, Step: 241/655, Loss: 2.209050, Accuracy: 18.85%\n",
            "Epoch: 4, Step: 242/655, Loss: 2.208899, Accuracy: 18.87%\n",
            "Epoch: 4, Step: 243/655, Loss: 2.208874, Accuracy: 18.83%\n",
            "Epoch: 4, Step: 244/655, Loss: 2.209091, Accuracy: 18.78%\n",
            "Epoch: 4, Step: 245/655, Loss: 2.209082, Accuracy: 18.75%\n",
            "Epoch: 4, Step: 246/655, Loss: 2.209535, Accuracy: 18.75%\n",
            "Epoch: 4, Step: 247/655, Loss: 2.209736, Accuracy: 18.72%\n",
            "Epoch: 4, Step: 248/655, Loss: 2.209831, Accuracy: 18.74%\n",
            "Epoch: 4, Step: 249/655, Loss: 2.209795, Accuracy: 18.72%\n",
            "Epoch: 4, Step: 250/655, Loss: 2.209725, Accuracy: 18.70%\n",
            "Epoch: 4, Step: 251/655, Loss: 2.209829, Accuracy: 18.70%\n",
            "Epoch: 4, Step: 252/655, Loss: 2.210049, Accuracy: 18.68%\n",
            "Epoch: 4, Step: 253/655, Loss: 2.210114, Accuracy: 18.70%\n",
            "Epoch: 4, Step: 254/655, Loss: 2.210343, Accuracy: 18.65%\n",
            "Epoch: 4, Step: 255/655, Loss: 2.210338, Accuracy: 18.65%\n",
            "Epoch: 4, Step: 256/655, Loss: 2.210717, Accuracy: 18.63%\n",
            "Epoch: 4, Step: 257/655, Loss: 2.210635, Accuracy: 18.63%\n",
            "Epoch: 4, Step: 258/655, Loss: 2.210658, Accuracy: 18.59%\n",
            "Epoch: 4, Step: 259/655, Loss: 2.211001, Accuracy: 18.56%\n",
            "Epoch: 4, Step: 260/655, Loss: 2.210275, Accuracy: 18.59%\n",
            "Epoch: 4, Step: 261/655, Loss: 2.210540, Accuracy: 18.56%\n",
            "Epoch: 4, Step: 262/655, Loss: 2.210244, Accuracy: 18.59%\n",
            "Epoch: 4, Step: 263/655, Loss: 2.210440, Accuracy: 18.58%\n",
            "Epoch: 4, Step: 264/655, Loss: 2.210106, Accuracy: 18.60%\n",
            "Epoch: 4, Step: 265/655, Loss: 2.210162, Accuracy: 18.62%\n",
            "Epoch: 4, Step: 266/655, Loss: 2.209955, Accuracy: 18.66%\n",
            "Epoch: 4, Step: 267/655, Loss: 2.210116, Accuracy: 18.67%\n",
            "Epoch: 4, Step: 268/655, Loss: 2.209743, Accuracy: 18.68%\n",
            "Epoch: 4, Step: 269/655, Loss: 2.210061, Accuracy: 18.66%\n",
            "Epoch: 4, Step: 270/655, Loss: 2.210386, Accuracy: 18.62%\n",
            "Epoch: 4, Step: 271/655, Loss: 2.210110, Accuracy: 18.63%\n",
            "Epoch: 4, Step: 272/655, Loss: 2.210190, Accuracy: 18.62%\n",
            "Epoch: 4, Step: 273/655, Loss: 2.210296, Accuracy: 18.61%\n",
            "Epoch: 4, Step: 274/655, Loss: 2.209775, Accuracy: 18.64%\n",
            "Epoch: 4, Step: 275/655, Loss: 2.209410, Accuracy: 18.66%\n",
            "Epoch: 4, Step: 276/655, Loss: 2.209446, Accuracy: 18.65%\n",
            "Epoch: 4, Step: 277/655, Loss: 2.209893, Accuracy: 18.63%\n",
            "Epoch: 4, Step: 278/655, Loss: 2.209615, Accuracy: 18.65%\n",
            "Epoch: 4, Step: 279/655, Loss: 2.209612, Accuracy: 18.64%\n",
            "Epoch: 4, Step: 280/655, Loss: 2.209752, Accuracy: 18.63%\n",
            "Epoch: 4, Step: 281/655, Loss: 2.210072, Accuracy: 18.62%\n",
            "Epoch: 4, Step: 282/655, Loss: 2.210402, Accuracy: 18.61%\n",
            "Epoch: 4, Step: 283/655, Loss: 2.210417, Accuracy: 18.61%\n",
            "Epoch: 4, Step: 284/655, Loss: 2.210584, Accuracy: 18.58%\n",
            "Epoch: 4, Step: 285/655, Loss: 2.210617, Accuracy: 18.55%\n",
            "Epoch: 4, Step: 286/655, Loss: 2.210795, Accuracy: 18.53%\n",
            "Epoch: 4, Step: 287/655, Loss: 2.210909, Accuracy: 18.53%\n",
            "Epoch: 4, Step: 288/655, Loss: 2.210692, Accuracy: 18.57%\n",
            "Epoch: 4, Step: 289/655, Loss: 2.210566, Accuracy: 18.61%\n",
            "Epoch: 4, Step: 290/655, Loss: 2.210935, Accuracy: 18.56%\n",
            "Epoch: 4, Step: 291/655, Loss: 2.211348, Accuracy: 18.55%\n",
            "Epoch: 4, Step: 292/655, Loss: 2.212117, Accuracy: 18.53%\n",
            "Epoch: 4, Step: 293/655, Loss: 2.212202, Accuracy: 18.49%\n",
            "Epoch: 4, Step: 294/655, Loss: 2.212612, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 295/655, Loss: 2.213375, Accuracy: 18.42%\n",
            "Epoch: 4, Step: 296/655, Loss: 2.213609, Accuracy: 18.41%\n",
            "Epoch: 4, Step: 297/655, Loss: 2.213996, Accuracy: 18.40%\n",
            "Epoch: 4, Step: 298/655, Loss: 2.213626, Accuracy: 18.40%\n",
            "Epoch: 4, Step: 299/655, Loss: 2.213785, Accuracy: 18.39%\n",
            "Epoch: 4, Step: 300/655, Loss: 2.213848, Accuracy: 18.39%\n",
            "Epoch: 4, Step: 301/655, Loss: 2.214293, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 302/655, Loss: 2.214159, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 303/655, Loss: 2.214157, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 304/655, Loss: 2.214288, Accuracy: 18.35%\n",
            "Epoch: 4, Step: 305/655, Loss: 2.214346, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 306/655, Loss: 2.214206, Accuracy: 18.35%\n",
            "Epoch: 4, Step: 307/655, Loss: 2.214427, Accuracy: 18.35%\n",
            "Epoch: 4, Step: 308/655, Loss: 2.214411, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 309/655, Loss: 2.214410, Accuracy: 18.37%\n",
            "Epoch: 4, Step: 310/655, Loss: 2.214421, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 311/655, Loss: 2.214158, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 312/655, Loss: 2.214400, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 313/655, Loss: 2.214224, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 314/655, Loss: 2.214261, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 315/655, Loss: 2.213734, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 316/655, Loss: 2.213945, Accuracy: 18.25%\n",
            "Epoch: 4, Step: 317/655, Loss: 2.213713, Accuracy: 18.27%\n",
            "Epoch: 4, Step: 318/655, Loss: 2.213578, Accuracy: 18.26%\n",
            "Epoch: 4, Step: 319/655, Loss: 2.213699, Accuracy: 18.24%\n",
            "Epoch: 4, Step: 320/655, Loss: 2.213651, Accuracy: 18.22%\n",
            "Epoch: 4, Step: 321/655, Loss: 2.213212, Accuracy: 18.25%\n",
            "Epoch: 4, Step: 322/655, Loss: 2.213268, Accuracy: 18.26%\n",
            "Epoch: 4, Step: 323/655, Loss: 2.213278, Accuracy: 18.22%\n",
            "Epoch: 4, Step: 324/655, Loss: 2.213192, Accuracy: 18.22%\n",
            "Epoch: 4, Step: 325/655, Loss: 2.213222, Accuracy: 18.21%\n",
            "Epoch: 4, Step: 326/655, Loss: 2.213031, Accuracy: 18.24%\n",
            "Epoch: 4, Step: 327/655, Loss: 2.213076, Accuracy: 18.21%\n",
            "Epoch: 4, Step: 328/655, Loss: 2.212951, Accuracy: 18.21%\n",
            "Epoch: 4, Step: 329/655, Loss: 2.212707, Accuracy: 18.22%\n",
            "Epoch: 4, Step: 330/655, Loss: 2.212506, Accuracy: 18.25%\n",
            "Epoch: 4, Step: 331/655, Loss: 2.212398, Accuracy: 18.27%\n",
            "Epoch: 4, Step: 332/655, Loss: 2.212341, Accuracy: 18.27%\n",
            "Epoch: 4, Step: 333/655, Loss: 2.212407, Accuracy: 18.27%\n",
            "Epoch: 4, Step: 334/655, Loss: 2.212327, Accuracy: 18.25%\n",
            "Epoch: 4, Step: 335/655, Loss: 2.212330, Accuracy: 18.25%\n",
            "Epoch: 4, Step: 336/655, Loss: 2.212097, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 337/655, Loss: 2.211796, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 338/655, Loss: 2.211549, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 339/655, Loss: 2.211596, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 340/655, Loss: 2.211503, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 341/655, Loss: 2.211648, Accuracy: 18.28%\n",
            "Epoch: 4, Step: 342/655, Loss: 2.211568, Accuracy: 18.27%\n",
            "Epoch: 4, Step: 343/655, Loss: 2.211501, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 344/655, Loss: 2.211737, Accuracy: 18.28%\n",
            "Epoch: 4, Step: 345/655, Loss: 2.211937, Accuracy: 18.24%\n",
            "Epoch: 4, Step: 346/655, Loss: 2.212189, Accuracy: 18.24%\n",
            "Epoch: 4, Step: 347/655, Loss: 2.212142, Accuracy: 18.22%\n",
            "Epoch: 4, Step: 348/655, Loss: 2.212328, Accuracy: 18.22%\n",
            "Epoch: 4, Step: 349/655, Loss: 2.212593, Accuracy: 18.19%\n",
            "Epoch: 4, Step: 350/655, Loss: 2.212425, Accuracy: 18.19%\n",
            "Epoch: 4, Step: 351/655, Loss: 2.212100, Accuracy: 18.20%\n",
            "Epoch: 4, Step: 352/655, Loss: 2.212097, Accuracy: 18.18%\n",
            "Epoch: 4, Step: 353/655, Loss: 2.212131, Accuracy: 18.19%\n",
            "Epoch: 4, Step: 354/655, Loss: 2.212094, Accuracy: 18.19%\n",
            "Epoch: 4, Step: 355/655, Loss: 2.211979, Accuracy: 18.21%\n",
            "Epoch: 4, Step: 356/655, Loss: 2.211894, Accuracy: 18.20%\n",
            "Epoch: 4, Step: 357/655, Loss: 2.212284, Accuracy: 18.21%\n",
            "Epoch: 4, Step: 358/655, Loss: 2.212333, Accuracy: 18.23%\n",
            "Epoch: 4, Step: 359/655, Loss: 2.212382, Accuracy: 18.26%\n",
            "Epoch: 4, Step: 360/655, Loss: 2.212694, Accuracy: 18.26%\n",
            "Epoch: 4, Step: 361/655, Loss: 2.212866, Accuracy: 18.27%\n",
            "Epoch: 4, Step: 362/655, Loss: 2.212689, Accuracy: 18.27%\n",
            "Epoch: 4, Step: 363/655, Loss: 2.213130, Accuracy: 18.26%\n",
            "Epoch: 4, Step: 364/655, Loss: 2.213078, Accuracy: 18.28%\n",
            "Epoch: 4, Step: 365/655, Loss: 2.212763, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 366/655, Loss: 2.212856, Accuracy: 18.33%\n",
            "Epoch: 4, Step: 367/655, Loss: 2.212707, Accuracy: 18.33%\n",
            "Epoch: 4, Step: 368/655, Loss: 2.212721, Accuracy: 18.33%\n",
            "Epoch: 4, Step: 369/655, Loss: 2.212590, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 370/655, Loss: 2.212370, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 371/655, Loss: 2.212540, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 372/655, Loss: 2.212448, Accuracy: 18.33%\n",
            "Epoch: 4, Step: 373/655, Loss: 2.212428, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 374/655, Loss: 2.212349, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 375/655, Loss: 2.212351, Accuracy: 18.33%\n",
            "Epoch: 4, Step: 376/655, Loss: 2.212367, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 377/655, Loss: 2.212783, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 378/655, Loss: 2.212701, Accuracy: 18.35%\n",
            "Epoch: 4, Step: 379/655, Loss: 2.212438, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 380/655, Loss: 2.212385, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 381/655, Loss: 2.211752, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 382/655, Loss: 2.211592, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 383/655, Loss: 2.211522, Accuracy: 18.33%\n",
            "Epoch: 4, Step: 384/655, Loss: 2.211271, Accuracy: 18.35%\n",
            "Epoch: 4, Step: 385/655, Loss: 2.210924, Accuracy: 18.38%\n",
            "Epoch: 4, Step: 386/655, Loss: 2.210929, Accuracy: 18.38%\n",
            "Epoch: 4, Step: 387/655, Loss: 2.210896, Accuracy: 18.40%\n",
            "Epoch: 4, Step: 388/655, Loss: 2.210915, Accuracy: 18.40%\n",
            "Epoch: 4, Step: 389/655, Loss: 2.210822, Accuracy: 18.38%\n",
            "Epoch: 4, Step: 390/655, Loss: 2.211078, Accuracy: 18.39%\n",
            "Epoch: 4, Step: 391/655, Loss: 2.211011, Accuracy: 18.40%\n",
            "Epoch: 4, Step: 392/655, Loss: 2.211090, Accuracy: 18.39%\n",
            "Epoch: 4, Step: 393/655, Loss: 2.210787, Accuracy: 18.40%\n",
            "Epoch: 4, Step: 394/655, Loss: 2.210539, Accuracy: 18.42%\n",
            "Epoch: 4, Step: 395/655, Loss: 2.210678, Accuracy: 18.41%\n",
            "Epoch: 4, Step: 396/655, Loss: 2.210725, Accuracy: 18.37%\n",
            "Epoch: 4, Step: 397/655, Loss: 2.210748, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 398/655, Loss: 2.210769, Accuracy: 18.37%\n",
            "Epoch: 4, Step: 399/655, Loss: 2.210523, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 400/655, Loss: 2.210659, Accuracy: 18.38%\n",
            "Epoch: 4, Step: 401/655, Loss: 2.210729, Accuracy: 18.40%\n",
            "Epoch: 4, Step: 402/655, Loss: 2.210600, Accuracy: 18.39%\n",
            "Epoch: 4, Step: 403/655, Loss: 2.210940, Accuracy: 18.39%\n",
            "Epoch: 4, Step: 404/655, Loss: 2.211128, Accuracy: 18.37%\n",
            "Epoch: 4, Step: 405/655, Loss: 2.211087, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 406/655, Loss: 2.210998, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 407/655, Loss: 2.211189, Accuracy: 18.33%\n",
            "Epoch: 4, Step: 408/655, Loss: 2.211326, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 409/655, Loss: 2.211281, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 410/655, Loss: 2.211126, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 411/655, Loss: 2.211280, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 412/655, Loss: 2.211269, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 413/655, Loss: 2.211425, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 414/655, Loss: 2.211375, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 415/655, Loss: 2.211377, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 416/655, Loss: 2.211101, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 417/655, Loss: 2.210763, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 418/655, Loss: 2.210643, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 419/655, Loss: 2.210558, Accuracy: 18.28%\n",
            "Epoch: 4, Step: 420/655, Loss: 2.210506, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 421/655, Loss: 2.210537, Accuracy: 18.27%\n",
            "Epoch: 4, Step: 422/655, Loss: 2.210447, Accuracy: 18.28%\n",
            "Epoch: 4, Step: 423/655, Loss: 2.210239, Accuracy: 18.28%\n",
            "Epoch: 4, Step: 424/655, Loss: 2.210234, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 425/655, Loss: 2.210076, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 426/655, Loss: 2.209824, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 427/655, Loss: 2.209823, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 428/655, Loss: 2.209984, Accuracy: 18.28%\n",
            "Epoch: 4, Step: 429/655, Loss: 2.209869, Accuracy: 18.28%\n",
            "Epoch: 4, Step: 430/655, Loss: 2.209714, Accuracy: 18.30%\n",
            "Epoch: 4, Step: 431/655, Loss: 2.209769, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 432/655, Loss: 2.209988, Accuracy: 18.26%\n",
            "Epoch: 4, Step: 433/655, Loss: 2.210014, Accuracy: 18.24%\n",
            "Epoch: 4, Step: 434/655, Loss: 2.209915, Accuracy: 18.25%\n",
            "Epoch: 4, Step: 435/655, Loss: 2.210259, Accuracy: 18.24%\n",
            "Epoch: 4, Step: 436/655, Loss: 2.210357, Accuracy: 18.23%\n",
            "Epoch: 4, Step: 437/655, Loss: 2.210433, Accuracy: 18.21%\n",
            "Epoch: 4, Step: 438/655, Loss: 2.210340, Accuracy: 18.20%\n",
            "Epoch: 4, Step: 439/655, Loss: 2.210541, Accuracy: 18.20%\n",
            "Epoch: 4, Step: 440/655, Loss: 2.210629, Accuracy: 18.19%\n",
            "Epoch: 4, Step: 441/655, Loss: 2.210900, Accuracy: 18.18%\n",
            "Epoch: 4, Step: 442/655, Loss: 2.211223, Accuracy: 18.13%\n",
            "Epoch: 4, Step: 443/655, Loss: 2.210855, Accuracy: 18.16%\n",
            "Epoch: 4, Step: 444/655, Loss: 2.211213, Accuracy: 18.14%\n",
            "Epoch: 4, Step: 445/655, Loss: 2.211437, Accuracy: 18.12%\n",
            "Epoch: 4, Step: 446/655, Loss: 2.211456, Accuracy: 18.11%\n",
            "Epoch: 4, Step: 447/655, Loss: 2.211477, Accuracy: 18.11%\n",
            "Epoch: 4, Step: 448/655, Loss: 2.211538, Accuracy: 18.11%\n",
            "Epoch: 4, Step: 449/655, Loss: 2.211665, Accuracy: 18.12%\n",
            "Epoch: 4, Step: 450/655, Loss: 2.211543, Accuracy: 18.11%\n",
            "Epoch: 4, Step: 451/655, Loss: 2.211301, Accuracy: 18.12%\n",
            "Epoch: 4, Step: 452/655, Loss: 2.211227, Accuracy: 18.14%\n",
            "Epoch: 4, Step: 453/655, Loss: 2.211480, Accuracy: 18.13%\n",
            "Epoch: 4, Step: 454/655, Loss: 2.211226, Accuracy: 18.12%\n",
            "Epoch: 4, Step: 455/655, Loss: 2.210866, Accuracy: 18.15%\n",
            "Epoch: 4, Step: 456/655, Loss: 2.210789, Accuracy: 18.13%\n",
            "Epoch: 4, Step: 457/655, Loss: 2.210640, Accuracy: 18.16%\n",
            "Epoch: 4, Step: 458/655, Loss: 2.210494, Accuracy: 18.19%\n",
            "Epoch: 4, Step: 459/655, Loss: 2.210341, Accuracy: 18.21%\n",
            "Epoch: 4, Step: 460/655, Loss: 2.210265, Accuracy: 18.21%\n",
            "Epoch: 4, Step: 461/655, Loss: 2.210286, Accuracy: 18.22%\n",
            "Epoch: 4, Step: 462/655, Loss: 2.210048, Accuracy: 18.23%\n",
            "Epoch: 4, Step: 463/655, Loss: 2.210209, Accuracy: 18.23%\n",
            "Epoch: 4, Step: 464/655, Loss: 2.210140, Accuracy: 18.24%\n",
            "Epoch: 4, Step: 465/655, Loss: 2.210380, Accuracy: 18.22%\n",
            "Epoch: 4, Step: 466/655, Loss: 2.210347, Accuracy: 18.23%\n",
            "Epoch: 4, Step: 467/655, Loss: 2.210425, Accuracy: 18.23%\n",
            "Epoch: 4, Step: 468/655, Loss: 2.210291, Accuracy: 18.24%\n",
            "Epoch: 4, Step: 469/655, Loss: 2.210260, Accuracy: 18.26%\n",
            "Epoch: 4, Step: 470/655, Loss: 2.209902, Accuracy: 18.28%\n",
            "Epoch: 4, Step: 471/655, Loss: 2.209787, Accuracy: 18.27%\n",
            "Epoch: 4, Step: 472/655, Loss: 2.209452, Accuracy: 18.26%\n",
            "Epoch: 4, Step: 473/655, Loss: 2.209727, Accuracy: 18.24%\n",
            "Epoch: 4, Step: 474/655, Loss: 2.209785, Accuracy: 18.24%\n",
            "Epoch: 4, Step: 475/655, Loss: 2.209817, Accuracy: 18.24%\n",
            "Epoch: 4, Step: 476/655, Loss: 2.210036, Accuracy: 18.22%\n",
            "Epoch: 4, Step: 477/655, Loss: 2.209729, Accuracy: 18.26%\n",
            "Epoch: 4, Step: 478/655, Loss: 2.209814, Accuracy: 18.25%\n",
            "Epoch: 4, Step: 479/655, Loss: 2.210075, Accuracy: 18.24%\n",
            "Epoch: 4, Step: 480/655, Loss: 2.209985, Accuracy: 18.25%\n",
            "Epoch: 4, Step: 481/655, Loss: 2.209899, Accuracy: 18.25%\n",
            "Epoch: 4, Step: 482/655, Loss: 2.209375, Accuracy: 18.28%\n",
            "Epoch: 4, Step: 483/655, Loss: 2.209652, Accuracy: 18.26%\n",
            "Epoch: 4, Step: 484/655, Loss: 2.209282, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 485/655, Loss: 2.209300, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 486/655, Loss: 2.209602, Accuracy: 18.28%\n",
            "Epoch: 4, Step: 487/655, Loss: 2.209455, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 488/655, Loss: 2.209199, Accuracy: 18.28%\n",
            "Epoch: 4, Step: 489/655, Loss: 2.209478, Accuracy: 18.26%\n",
            "Epoch: 4, Step: 490/655, Loss: 2.209432, Accuracy: 18.27%\n",
            "Epoch: 4, Step: 491/655, Loss: 2.209262, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 492/655, Loss: 2.209115, Accuracy: 18.30%\n",
            "Epoch: 4, Step: 493/655, Loss: 2.208893, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 494/655, Loss: 2.208870, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 495/655, Loss: 2.208916, Accuracy: 18.35%\n",
            "Epoch: 4, Step: 496/655, Loss: 2.208968, Accuracy: 18.33%\n",
            "Epoch: 4, Step: 497/655, Loss: 2.208962, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 498/655, Loss: 2.208945, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 499/655, Loss: 2.208855, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 500/655, Loss: 2.208919, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 501/655, Loss: 2.208904, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 502/655, Loss: 2.208842, Accuracy: 18.35%\n",
            "Epoch: 4, Step: 503/655, Loss: 2.208791, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 504/655, Loss: 2.208856, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 505/655, Loss: 2.209142, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 506/655, Loss: 2.209203, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 507/655, Loss: 2.209130, Accuracy: 18.35%\n",
            "Epoch: 4, Step: 508/655, Loss: 2.209120, Accuracy: 18.33%\n",
            "Epoch: 4, Step: 509/655, Loss: 2.208937, Accuracy: 18.33%\n",
            "Epoch: 4, Step: 510/655, Loss: 2.209038, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 511/655, Loss: 2.209142, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 512/655, Loss: 2.209192, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 513/655, Loss: 2.209258, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 514/655, Loss: 2.209482, Accuracy: 18.29%\n",
            "Epoch: 4, Step: 515/655, Loss: 2.209397, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 516/655, Loss: 2.209233, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 517/655, Loss: 2.209208, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 518/655, Loss: 2.209010, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 519/655, Loss: 2.209256, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 520/655, Loss: 2.209113, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 521/655, Loss: 2.209009, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 522/655, Loss: 2.209187, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 523/655, Loss: 2.208997, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 524/655, Loss: 2.209258, Accuracy: 18.31%\n",
            "Epoch: 4, Step: 525/655, Loss: 2.209170, Accuracy: 18.32%\n",
            "Epoch: 4, Step: 526/655, Loss: 2.209092, Accuracy: 18.34%\n",
            "Epoch: 4, Step: 527/655, Loss: 2.208998, Accuracy: 18.33%\n",
            "Epoch: 4, Step: 528/655, Loss: 2.209051, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 529/655, Loss: 2.208954, Accuracy: 18.37%\n",
            "Epoch: 4, Step: 530/655, Loss: 2.209127, Accuracy: 18.37%\n",
            "Epoch: 4, Step: 531/655, Loss: 2.208829, Accuracy: 18.39%\n",
            "Epoch: 4, Step: 532/655, Loss: 2.208823, Accuracy: 18.39%\n",
            "Epoch: 4, Step: 533/655, Loss: 2.208885, Accuracy: 18.37%\n",
            "Epoch: 4, Step: 534/655, Loss: 2.209110, Accuracy: 18.38%\n",
            "Epoch: 4, Step: 535/655, Loss: 2.209252, Accuracy: 18.38%\n",
            "Epoch: 4, Step: 536/655, Loss: 2.209303, Accuracy: 18.38%\n",
            "Epoch: 4, Step: 537/655, Loss: 2.209297, Accuracy: 18.38%\n",
            "Epoch: 4, Step: 538/655, Loss: 2.209421, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 539/655, Loss: 2.209323, Accuracy: 18.38%\n",
            "Epoch: 4, Step: 540/655, Loss: 2.209299, Accuracy: 18.37%\n",
            "Epoch: 4, Step: 541/655, Loss: 2.209306, Accuracy: 18.37%\n",
            "Epoch: 4, Step: 542/655, Loss: 2.209483, Accuracy: 18.36%\n",
            "Epoch: 4, Step: 543/655, Loss: 2.209513, Accuracy: 18.37%\n",
            "Epoch: 4, Step: 544/655, Loss: 2.209448, Accuracy: 18.37%\n",
            "Epoch: 4, Step: 545/655, Loss: 2.209474, Accuracy: 18.38%\n",
            "Epoch: 4, Step: 546/655, Loss: 2.209289, Accuracy: 18.40%\n",
            "Epoch: 4, Step: 547/655, Loss: 2.209018, Accuracy: 18.42%\n",
            "Epoch: 4, Step: 548/655, Loss: 2.209127, Accuracy: 18.43%\n",
            "Epoch: 4, Step: 549/655, Loss: 2.209179, Accuracy: 18.42%\n",
            "Epoch: 4, Step: 550/655, Loss: 2.209038, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 551/655, Loss: 2.209028, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 552/655, Loss: 2.209085, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 553/655, Loss: 2.208606, Accuracy: 18.47%\n",
            "Epoch: 4, Step: 554/655, Loss: 2.208508, Accuracy: 18.47%\n",
            "Epoch: 4, Step: 555/655, Loss: 2.208536, Accuracy: 18.47%\n",
            "Epoch: 4, Step: 556/655, Loss: 2.208668, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 557/655, Loss: 2.208610, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 558/655, Loss: 2.208707, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 559/655, Loss: 2.208893, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 560/655, Loss: 2.208866, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 561/655, Loss: 2.209044, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 562/655, Loss: 2.209015, Accuracy: 18.43%\n",
            "Epoch: 4, Step: 563/655, Loss: 2.208855, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 564/655, Loss: 2.208826, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 565/655, Loss: 2.208604, Accuracy: 18.47%\n",
            "Epoch: 4, Step: 566/655, Loss: 2.208426, Accuracy: 18.47%\n",
            "Epoch: 4, Step: 567/655, Loss: 2.208176, Accuracy: 18.47%\n",
            "Epoch: 4, Step: 568/655, Loss: 2.207855, Accuracy: 18.48%\n",
            "Epoch: 4, Step: 569/655, Loss: 2.207924, Accuracy: 18.48%\n",
            "Epoch: 4, Step: 570/655, Loss: 2.207903, Accuracy: 18.48%\n",
            "Epoch: 4, Step: 571/655, Loss: 2.207894, Accuracy: 18.48%\n",
            "Epoch: 4, Step: 572/655, Loss: 2.207973, Accuracy: 18.48%\n",
            "Epoch: 4, Step: 573/655, Loss: 2.208164, Accuracy: 18.47%\n",
            "Epoch: 4, Step: 574/655, Loss: 2.208129, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 575/655, Loss: 2.208265, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 576/655, Loss: 2.208747, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 577/655, Loss: 2.208389, Accuracy: 18.48%\n",
            "Epoch: 4, Step: 578/655, Loss: 2.208403, Accuracy: 18.47%\n",
            "Epoch: 4, Step: 579/655, Loss: 2.208316, Accuracy: 18.48%\n",
            "Epoch: 4, Step: 580/655, Loss: 2.208337, Accuracy: 18.49%\n",
            "Epoch: 4, Step: 581/655, Loss: 2.208214, Accuracy: 18.49%\n",
            "Epoch: 4, Step: 582/655, Loss: 2.208284, Accuracy: 18.48%\n",
            "Epoch: 4, Step: 583/655, Loss: 2.208071, Accuracy: 18.49%\n",
            "Epoch: 4, Step: 584/655, Loss: 2.208248, Accuracy: 18.48%\n",
            "Epoch: 4, Step: 585/655, Loss: 2.208513, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 586/655, Loss: 2.208614, Accuracy: 18.47%\n",
            "Epoch: 4, Step: 587/655, Loss: 2.208889, Accuracy: 18.47%\n",
            "Epoch: 4, Step: 588/655, Loss: 2.208868, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 589/655, Loss: 2.208949, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 590/655, Loss: 2.209008, Accuracy: 18.47%\n",
            "Epoch: 4, Step: 591/655, Loss: 2.208863, Accuracy: 18.48%\n",
            "Epoch: 4, Step: 592/655, Loss: 2.208844, Accuracy: 18.48%\n",
            "Epoch: 4, Step: 593/655, Loss: 2.208901, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 594/655, Loss: 2.208945, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 595/655, Loss: 2.209097, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 596/655, Loss: 2.209206, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 597/655, Loss: 2.209125, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 598/655, Loss: 2.209103, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 599/655, Loss: 2.209082, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 600/655, Loss: 2.209095, Accuracy: 18.43%\n",
            "Epoch: 4, Step: 601/655, Loss: 2.209224, Accuracy: 18.43%\n",
            "Epoch: 4, Step: 602/655, Loss: 2.209306, Accuracy: 18.42%\n",
            "Epoch: 4, Step: 603/655, Loss: 2.209383, Accuracy: 18.40%\n",
            "Epoch: 4, Step: 604/655, Loss: 2.209282, Accuracy: 18.40%\n",
            "Epoch: 4, Step: 605/655, Loss: 2.209253, Accuracy: 18.40%\n",
            "Epoch: 4, Step: 606/655, Loss: 2.209121, Accuracy: 18.39%\n",
            "Epoch: 4, Step: 607/655, Loss: 2.209108, Accuracy: 18.39%\n",
            "Epoch: 4, Step: 608/655, Loss: 2.208964, Accuracy: 18.41%\n",
            "Epoch: 4, Step: 609/655, Loss: 2.208896, Accuracy: 18.43%\n",
            "Epoch: 4, Step: 610/655, Loss: 2.208998, Accuracy: 18.43%\n",
            "Epoch: 4, Step: 611/655, Loss: 2.209171, Accuracy: 18.42%\n",
            "Epoch: 4, Step: 612/655, Loss: 2.209254, Accuracy: 18.41%\n",
            "Epoch: 4, Step: 613/655, Loss: 2.209232, Accuracy: 18.43%\n",
            "Epoch: 4, Step: 614/655, Loss: 2.209324, Accuracy: 18.42%\n",
            "Epoch: 4, Step: 615/655, Loss: 2.209246, Accuracy: 18.43%\n",
            "Epoch: 4, Step: 616/655, Loss: 2.209279, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 617/655, Loss: 2.209285, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 618/655, Loss: 2.209028, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 619/655, Loss: 2.208814, Accuracy: 18.48%\n",
            "Epoch: 4, Step: 620/655, Loss: 2.208980, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 621/655, Loss: 2.208861, Accuracy: 18.47%\n",
            "Epoch: 4, Step: 622/655, Loss: 2.208931, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 623/655, Loss: 2.208942, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 624/655, Loss: 2.208783, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 625/655, Loss: 2.208815, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 626/655, Loss: 2.208974, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 627/655, Loss: 2.208850, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 628/655, Loss: 2.208791, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 629/655, Loss: 2.208858, Accuracy: 18.43%\n",
            "Epoch: 4, Step: 630/655, Loss: 2.208858, Accuracy: 18.43%\n",
            "Epoch: 4, Step: 631/655, Loss: 2.208935, Accuracy: 18.43%\n",
            "Epoch: 4, Step: 632/655, Loss: 2.208886, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 633/655, Loss: 2.208877, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 634/655, Loss: 2.208720, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 635/655, Loss: 2.209100, Accuracy: 18.43%\n",
            "Epoch: 4, Step: 636/655, Loss: 2.209081, Accuracy: 18.43%\n",
            "Epoch: 4, Step: 637/655, Loss: 2.208995, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 638/655, Loss: 2.209115, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 639/655, Loss: 2.209066, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 640/655, Loss: 2.208965, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 641/655, Loss: 2.208960, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 642/655, Loss: 2.208804, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 643/655, Loss: 2.208961, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 644/655, Loss: 2.208884, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 645/655, Loss: 2.208993, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 646/655, Loss: 2.208889, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 647/655, Loss: 2.208800, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 648/655, Loss: 2.208724, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 649/655, Loss: 2.208788, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 650/655, Loss: 2.208597, Accuracy: 18.47%\n",
            "Epoch: 4, Step: 651/655, Loss: 2.208580, Accuracy: 18.47%\n",
            "Epoch: 4, Step: 652/655, Loss: 2.208615, Accuracy: 18.46%\n",
            "Epoch: 4, Step: 653/655, Loss: 2.208590, Accuracy: 18.45%\n",
            "Epoch: 4, Step: 654/655, Loss: 2.208561, Accuracy: 18.44%\n",
            "Epoch: 4, Step: 655/655, Loss: 2.208672, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 1/655, Loss: 2.289099, Accuracy: 12.50%\n",
            "Epoch: 5, Step: 2/655, Loss: 2.191247, Accuracy: 20.31%\n",
            "Epoch: 5, Step: 3/655, Loss: 2.210948, Accuracy: 19.79%\n",
            "Epoch: 5, Step: 4/655, Loss: 2.250133, Accuracy: 17.19%\n",
            "Epoch: 5, Step: 5/655, Loss: 2.228331, Accuracy: 20.62%\n",
            "Epoch: 5, Step: 6/655, Loss: 2.209425, Accuracy: 21.35%\n",
            "Epoch: 5, Step: 7/655, Loss: 2.225248, Accuracy: 20.09%\n",
            "Epoch: 5, Step: 8/655, Loss: 2.212346, Accuracy: 20.31%\n",
            "Epoch: 5, Step: 9/655, Loss: 2.200942, Accuracy: 19.79%\n",
            "Epoch: 5, Step: 10/655, Loss: 2.187710, Accuracy: 20.00%\n",
            "Epoch: 5, Step: 11/655, Loss: 2.181045, Accuracy: 20.17%\n",
            "Epoch: 5, Step: 12/655, Loss: 2.178358, Accuracy: 21.09%\n",
            "Epoch: 5, Step: 13/655, Loss: 2.199042, Accuracy: 20.43%\n",
            "Epoch: 5, Step: 14/655, Loss: 2.197795, Accuracy: 19.42%\n",
            "Epoch: 5, Step: 15/655, Loss: 2.206628, Accuracy: 18.75%\n",
            "Epoch: 5, Step: 16/655, Loss: 2.201384, Accuracy: 19.14%\n",
            "Epoch: 5, Step: 17/655, Loss: 2.206698, Accuracy: 18.75%\n",
            "Epoch: 5, Step: 18/655, Loss: 2.208481, Accuracy: 18.06%\n",
            "Epoch: 5, Step: 19/655, Loss: 2.204751, Accuracy: 18.09%\n",
            "Epoch: 5, Step: 20/655, Loss: 2.204256, Accuracy: 18.12%\n",
            "Epoch: 5, Step: 21/655, Loss: 2.206942, Accuracy: 18.30%\n",
            "Epoch: 5, Step: 22/655, Loss: 2.207508, Accuracy: 18.47%\n",
            "Epoch: 5, Step: 23/655, Loss: 2.206954, Accuracy: 18.48%\n",
            "Epoch: 5, Step: 24/655, Loss: 2.200664, Accuracy: 18.62%\n",
            "Epoch: 5, Step: 25/655, Loss: 2.195949, Accuracy: 18.12%\n",
            "Epoch: 5, Step: 26/655, Loss: 2.194919, Accuracy: 18.39%\n",
            "Epoch: 5, Step: 27/655, Loss: 2.199933, Accuracy: 18.29%\n",
            "Epoch: 5, Step: 28/655, Loss: 2.203919, Accuracy: 18.19%\n",
            "Epoch: 5, Step: 29/655, Loss: 2.201996, Accuracy: 18.10%\n",
            "Epoch: 5, Step: 30/655, Loss: 2.202775, Accuracy: 17.81%\n",
            "Epoch: 5, Step: 31/655, Loss: 2.203102, Accuracy: 17.84%\n",
            "Epoch: 5, Step: 32/655, Loss: 2.207306, Accuracy: 17.38%\n",
            "Epoch: 5, Step: 33/655, Loss: 2.208684, Accuracy: 17.33%\n",
            "Epoch: 5, Step: 34/655, Loss: 2.208048, Accuracy: 17.46%\n",
            "Epoch: 5, Step: 35/655, Loss: 2.210278, Accuracy: 17.50%\n",
            "Epoch: 5, Step: 36/655, Loss: 2.208860, Accuracy: 17.97%\n",
            "Epoch: 5, Step: 37/655, Loss: 2.210816, Accuracy: 17.74%\n",
            "Epoch: 5, Step: 38/655, Loss: 2.212049, Accuracy: 17.60%\n",
            "Epoch: 5, Step: 39/655, Loss: 2.211439, Accuracy: 17.31%\n",
            "Epoch: 5, Step: 40/655, Loss: 2.212125, Accuracy: 17.34%\n",
            "Epoch: 5, Step: 41/655, Loss: 2.212488, Accuracy: 17.23%\n",
            "Epoch: 5, Step: 42/655, Loss: 2.209490, Accuracy: 17.49%\n",
            "Epoch: 5, Step: 43/655, Loss: 2.209163, Accuracy: 17.37%\n",
            "Epoch: 5, Step: 44/655, Loss: 2.209416, Accuracy: 17.54%\n",
            "Epoch: 5, Step: 45/655, Loss: 2.209689, Accuracy: 17.57%\n",
            "Epoch: 5, Step: 46/655, Loss: 2.207654, Accuracy: 17.87%\n",
            "Epoch: 5, Step: 47/655, Loss: 2.208056, Accuracy: 17.95%\n",
            "Epoch: 5, Step: 48/655, Loss: 2.211584, Accuracy: 17.77%\n",
            "Epoch: 5, Step: 49/655, Loss: 2.211511, Accuracy: 17.79%\n",
            "Epoch: 5, Step: 50/655, Loss: 2.212435, Accuracy: 17.69%\n",
            "Epoch: 5, Step: 51/655, Loss: 2.211591, Accuracy: 17.71%\n",
            "Epoch: 5, Step: 52/655, Loss: 2.212956, Accuracy: 17.49%\n",
            "Epoch: 5, Step: 53/655, Loss: 2.211667, Accuracy: 17.39%\n",
            "Epoch: 5, Step: 54/655, Loss: 2.212114, Accuracy: 17.36%\n",
            "Epoch: 5, Step: 55/655, Loss: 2.211075, Accuracy: 17.50%\n",
            "Epoch: 5, Step: 56/655, Loss: 2.211002, Accuracy: 17.35%\n",
            "Epoch: 5, Step: 57/655, Loss: 2.211176, Accuracy: 17.54%\n",
            "Epoch: 5, Step: 58/655, Loss: 2.212248, Accuracy: 17.62%\n",
            "Epoch: 5, Step: 59/655, Loss: 2.210275, Accuracy: 17.53%\n",
            "Epoch: 5, Step: 60/655, Loss: 2.210562, Accuracy: 17.40%\n",
            "Epoch: 5, Step: 61/655, Loss: 2.209704, Accuracy: 17.42%\n",
            "Epoch: 5, Step: 62/655, Loss: 2.209454, Accuracy: 17.49%\n",
            "Epoch: 5, Step: 63/655, Loss: 2.211239, Accuracy: 17.36%\n",
            "Epoch: 5, Step: 64/655, Loss: 2.209648, Accuracy: 17.48%\n",
            "Epoch: 5, Step: 65/655, Loss: 2.210467, Accuracy: 17.45%\n",
            "Epoch: 5, Step: 66/655, Loss: 2.210148, Accuracy: 17.47%\n",
            "Epoch: 5, Step: 67/655, Loss: 2.209148, Accuracy: 17.44%\n",
            "Epoch: 5, Step: 68/655, Loss: 2.206633, Accuracy: 17.69%\n",
            "Epoch: 5, Step: 69/655, Loss: 2.206391, Accuracy: 17.75%\n",
            "Epoch: 5, Step: 70/655, Loss: 2.205879, Accuracy: 17.68%\n",
            "Epoch: 5, Step: 71/655, Loss: 2.204790, Accuracy: 17.74%\n",
            "Epoch: 5, Step: 72/655, Loss: 2.204809, Accuracy: 17.71%\n",
            "Epoch: 5, Step: 73/655, Loss: 2.205491, Accuracy: 17.64%\n",
            "Epoch: 5, Step: 74/655, Loss: 2.206213, Accuracy: 17.61%\n",
            "Epoch: 5, Step: 75/655, Loss: 2.204999, Accuracy: 17.75%\n",
            "Epoch: 5, Step: 76/655, Loss: 2.206495, Accuracy: 17.68%\n",
            "Epoch: 5, Step: 77/655, Loss: 2.208195, Accuracy: 17.53%\n",
            "Epoch: 5, Step: 78/655, Loss: 2.206669, Accuracy: 17.63%\n",
            "Epoch: 5, Step: 79/655, Loss: 2.207145, Accuracy: 17.60%\n",
            "Epoch: 5, Step: 80/655, Loss: 2.206346, Accuracy: 17.70%\n",
            "Epoch: 5, Step: 81/655, Loss: 2.205123, Accuracy: 17.71%\n",
            "Epoch: 5, Step: 82/655, Loss: 2.202858, Accuracy: 17.91%\n",
            "Epoch: 5, Step: 83/655, Loss: 2.202429, Accuracy: 18.00%\n",
            "Epoch: 5, Step: 84/655, Loss: 2.202618, Accuracy: 18.12%\n",
            "Epoch: 5, Step: 85/655, Loss: 2.203811, Accuracy: 18.16%\n",
            "Epoch: 5, Step: 86/655, Loss: 2.202875, Accuracy: 18.13%\n",
            "Epoch: 5, Step: 87/655, Loss: 2.203445, Accuracy: 18.03%\n",
            "Epoch: 5, Step: 88/655, Loss: 2.202635, Accuracy: 18.08%\n",
            "Epoch: 5, Step: 89/655, Loss: 2.201776, Accuracy: 18.19%\n",
            "Epoch: 5, Step: 90/655, Loss: 2.201626, Accuracy: 18.26%\n",
            "Epoch: 5, Step: 91/655, Loss: 2.202381, Accuracy: 18.13%\n",
            "Epoch: 5, Step: 92/655, Loss: 2.202352, Accuracy: 18.07%\n",
            "Epoch: 5, Step: 93/655, Loss: 2.203129, Accuracy: 18.08%\n",
            "Epoch: 5, Step: 94/655, Loss: 2.203697, Accuracy: 18.12%\n",
            "Epoch: 5, Step: 95/655, Loss: 2.203733, Accuracy: 18.12%\n",
            "Epoch: 5, Step: 96/655, Loss: 2.203515, Accuracy: 18.07%\n",
            "Epoch: 5, Step: 97/655, Loss: 2.204297, Accuracy: 17.98%\n",
            "Epoch: 5, Step: 98/655, Loss: 2.204850, Accuracy: 17.98%\n",
            "Epoch: 5, Step: 99/655, Loss: 2.205562, Accuracy: 17.96%\n",
            "Epoch: 5, Step: 100/655, Loss: 2.204870, Accuracy: 17.81%\n",
            "Epoch: 5, Step: 101/655, Loss: 2.205524, Accuracy: 17.82%\n",
            "Epoch: 5, Step: 102/655, Loss: 2.205701, Accuracy: 17.77%\n",
            "Epoch: 5, Step: 103/655, Loss: 2.205544, Accuracy: 17.87%\n",
            "Epoch: 5, Step: 104/655, Loss: 2.206689, Accuracy: 17.82%\n",
            "Epoch: 5, Step: 105/655, Loss: 2.206369, Accuracy: 17.86%\n",
            "Epoch: 5, Step: 106/655, Loss: 2.208191, Accuracy: 17.81%\n",
            "Epoch: 5, Step: 107/655, Loss: 2.208760, Accuracy: 17.73%\n",
            "Epoch: 5, Step: 108/655, Loss: 2.207303, Accuracy: 17.68%\n",
            "Epoch: 5, Step: 109/655, Loss: 2.208728, Accuracy: 17.66%\n",
            "Epoch: 5, Step: 110/655, Loss: 2.207595, Accuracy: 17.70%\n",
            "Epoch: 5, Step: 111/655, Loss: 2.206589, Accuracy: 17.68%\n",
            "Epoch: 5, Step: 112/655, Loss: 2.206767, Accuracy: 17.69%\n",
            "Epoch: 5, Step: 113/655, Loss: 2.206628, Accuracy: 17.81%\n",
            "Epoch: 5, Step: 114/655, Loss: 2.206884, Accuracy: 17.85%\n",
            "Epoch: 5, Step: 115/655, Loss: 2.205856, Accuracy: 17.83%\n",
            "Epoch: 5, Step: 116/655, Loss: 2.205393, Accuracy: 17.89%\n",
            "Epoch: 5, Step: 117/655, Loss: 2.204714, Accuracy: 17.95%\n",
            "Epoch: 5, Step: 118/655, Loss: 2.204020, Accuracy: 18.01%\n",
            "Epoch: 5, Step: 119/655, Loss: 2.204601, Accuracy: 17.96%\n",
            "Epoch: 5, Step: 120/655, Loss: 2.204090, Accuracy: 18.10%\n",
            "Epoch: 5, Step: 121/655, Loss: 2.203874, Accuracy: 18.05%\n",
            "Epoch: 5, Step: 122/655, Loss: 2.203385, Accuracy: 18.16%\n",
            "Epoch: 5, Step: 123/655, Loss: 2.204102, Accuracy: 18.14%\n",
            "Epoch: 5, Step: 124/655, Loss: 2.204826, Accuracy: 18.12%\n",
            "Epoch: 5, Step: 125/655, Loss: 2.205255, Accuracy: 18.15%\n",
            "Epoch: 5, Step: 126/655, Loss: 2.205126, Accuracy: 18.18%\n",
            "Epoch: 5, Step: 127/655, Loss: 2.205662, Accuracy: 18.11%\n",
            "Epoch: 5, Step: 128/655, Loss: 2.206481, Accuracy: 18.04%\n",
            "Epoch: 5, Step: 129/655, Loss: 2.205965, Accuracy: 18.05%\n",
            "Epoch: 5, Step: 130/655, Loss: 2.207019, Accuracy: 18.03%\n",
            "Epoch: 5, Step: 131/655, Loss: 2.206761, Accuracy: 17.99%\n",
            "Epoch: 5, Step: 132/655, Loss: 2.206587, Accuracy: 18.06%\n",
            "Epoch: 5, Step: 133/655, Loss: 2.206272, Accuracy: 18.02%\n",
            "Epoch: 5, Step: 134/655, Loss: 2.206168, Accuracy: 18.03%\n",
            "Epoch: 5, Step: 135/655, Loss: 2.206054, Accuracy: 18.03%\n",
            "Epoch: 5, Step: 136/655, Loss: 2.206859, Accuracy: 18.06%\n",
            "Epoch: 5, Step: 137/655, Loss: 2.207624, Accuracy: 18.04%\n",
            "Epoch: 5, Step: 138/655, Loss: 2.207977, Accuracy: 18.03%\n",
            "Epoch: 5, Step: 139/655, Loss: 2.208785, Accuracy: 18.01%\n",
            "Epoch: 5, Step: 140/655, Loss: 2.208177, Accuracy: 18.06%\n",
            "Epoch: 5, Step: 141/655, Loss: 2.208957, Accuracy: 17.97%\n",
            "Epoch: 5, Step: 142/655, Loss: 2.209134, Accuracy: 17.98%\n",
            "Epoch: 5, Step: 143/655, Loss: 2.209073, Accuracy: 17.96%\n",
            "Epoch: 5, Step: 144/655, Loss: 2.209665, Accuracy: 17.95%\n",
            "Epoch: 5, Step: 145/655, Loss: 2.208972, Accuracy: 17.95%\n",
            "Epoch: 5, Step: 146/655, Loss: 2.209419, Accuracy: 17.94%\n",
            "Epoch: 5, Step: 147/655, Loss: 2.209477, Accuracy: 17.90%\n",
            "Epoch: 5, Step: 148/655, Loss: 2.209260, Accuracy: 17.91%\n",
            "Epoch: 5, Step: 149/655, Loss: 2.208825, Accuracy: 17.89%\n",
            "Epoch: 5, Step: 150/655, Loss: 2.208956, Accuracy: 17.90%\n",
            "Epoch: 5, Step: 151/655, Loss: 2.209550, Accuracy: 17.88%\n",
            "Epoch: 5, Step: 152/655, Loss: 2.209894, Accuracy: 17.85%\n",
            "Epoch: 5, Step: 153/655, Loss: 2.210168, Accuracy: 17.79%\n",
            "Epoch: 5, Step: 154/655, Loss: 2.210625, Accuracy: 17.74%\n",
            "Epoch: 5, Step: 155/655, Loss: 2.211123, Accuracy: 17.74%\n",
            "Epoch: 5, Step: 156/655, Loss: 2.211450, Accuracy: 17.73%\n",
            "Epoch: 5, Step: 157/655, Loss: 2.211757, Accuracy: 17.73%\n",
            "Epoch: 5, Step: 158/655, Loss: 2.211455, Accuracy: 17.78%\n",
            "Epoch: 5, Step: 159/655, Loss: 2.211276, Accuracy: 17.81%\n",
            "Epoch: 5, Step: 160/655, Loss: 2.210888, Accuracy: 17.89%\n",
            "Epoch: 5, Step: 161/655, Loss: 2.210403, Accuracy: 17.93%\n",
            "Epoch: 5, Step: 162/655, Loss: 2.210816, Accuracy: 17.92%\n",
            "Epoch: 5, Step: 163/655, Loss: 2.210846, Accuracy: 17.89%\n",
            "Epoch: 5, Step: 164/655, Loss: 2.210655, Accuracy: 17.85%\n",
            "Epoch: 5, Step: 165/655, Loss: 2.210952, Accuracy: 17.90%\n",
            "Epoch: 5, Step: 166/655, Loss: 2.210670, Accuracy: 17.90%\n",
            "Epoch: 5, Step: 167/655, Loss: 2.210545, Accuracy: 17.91%\n",
            "Epoch: 5, Step: 168/655, Loss: 2.210539, Accuracy: 17.93%\n",
            "Epoch: 5, Step: 169/655, Loss: 2.210120, Accuracy: 17.92%\n",
            "Epoch: 5, Step: 170/655, Loss: 2.210615, Accuracy: 17.90%\n",
            "Epoch: 5, Step: 171/655, Loss: 2.210852, Accuracy: 17.96%\n",
            "Epoch: 5, Step: 172/655, Loss: 2.210323, Accuracy: 17.97%\n",
            "Epoch: 5, Step: 173/655, Loss: 2.210208, Accuracy: 18.01%\n",
            "Epoch: 5, Step: 174/655, Loss: 2.210669, Accuracy: 17.96%\n",
            "Epoch: 5, Step: 175/655, Loss: 2.210717, Accuracy: 18.02%\n",
            "Epoch: 5, Step: 176/655, Loss: 2.211154, Accuracy: 18.00%\n",
            "Epoch: 5, Step: 177/655, Loss: 2.210374, Accuracy: 18.03%\n",
            "Epoch: 5, Step: 178/655, Loss: 2.209699, Accuracy: 18.07%\n",
            "Epoch: 5, Step: 179/655, Loss: 2.209371, Accuracy: 18.07%\n",
            "Epoch: 5, Step: 180/655, Loss: 2.208812, Accuracy: 18.09%\n",
            "Epoch: 5, Step: 181/655, Loss: 2.209124, Accuracy: 18.06%\n",
            "Epoch: 5, Step: 182/655, Loss: 2.209541, Accuracy: 18.03%\n",
            "Epoch: 5, Step: 183/655, Loss: 2.209360, Accuracy: 18.02%\n",
            "Epoch: 5, Step: 184/655, Loss: 2.209740, Accuracy: 17.97%\n",
            "Epoch: 5, Step: 185/655, Loss: 2.209603, Accuracy: 17.99%\n",
            "Epoch: 5, Step: 186/655, Loss: 2.209785, Accuracy: 18.01%\n",
            "Epoch: 5, Step: 187/655, Loss: 2.209996, Accuracy: 18.03%\n",
            "Epoch: 5, Step: 188/655, Loss: 2.209356, Accuracy: 18.09%\n",
            "Epoch: 5, Step: 189/655, Loss: 2.208257, Accuracy: 18.09%\n",
            "Epoch: 5, Step: 190/655, Loss: 2.208112, Accuracy: 18.08%\n",
            "Epoch: 5, Step: 191/655, Loss: 2.208950, Accuracy: 18.05%\n",
            "Epoch: 5, Step: 192/655, Loss: 2.208540, Accuracy: 18.08%\n",
            "Epoch: 5, Step: 193/655, Loss: 2.208919, Accuracy: 18.02%\n",
            "Epoch: 5, Step: 194/655, Loss: 2.208728, Accuracy: 18.06%\n",
            "Epoch: 5, Step: 195/655, Loss: 2.208690, Accuracy: 18.04%\n",
            "Epoch: 5, Step: 196/655, Loss: 2.208211, Accuracy: 18.02%\n",
            "Epoch: 5, Step: 197/655, Loss: 2.208267, Accuracy: 18.02%\n",
            "Epoch: 5, Step: 198/655, Loss: 2.207778, Accuracy: 18.02%\n",
            "Epoch: 5, Step: 199/655, Loss: 2.207758, Accuracy: 18.09%\n",
            "Epoch: 5, Step: 200/655, Loss: 2.207716, Accuracy: 18.09%\n",
            "Epoch: 5, Step: 201/655, Loss: 2.208115, Accuracy: 18.03%\n",
            "Epoch: 5, Step: 202/655, Loss: 2.207960, Accuracy: 18.04%\n",
            "Epoch: 5, Step: 203/655, Loss: 2.207586, Accuracy: 18.03%\n",
            "Epoch: 5, Step: 204/655, Loss: 2.208207, Accuracy: 18.01%\n",
            "Epoch: 5, Step: 205/655, Loss: 2.208193, Accuracy: 18.02%\n",
            "Epoch: 5, Step: 206/655, Loss: 2.208181, Accuracy: 18.02%\n",
            "Epoch: 5, Step: 207/655, Loss: 2.208179, Accuracy: 17.98%\n",
            "Epoch: 5, Step: 208/655, Loss: 2.207914, Accuracy: 18.03%\n",
            "Epoch: 5, Step: 209/655, Loss: 2.207887, Accuracy: 18.06%\n",
            "Epoch: 5, Step: 210/655, Loss: 2.207157, Accuracy: 18.14%\n",
            "Epoch: 5, Step: 211/655, Loss: 2.207440, Accuracy: 18.11%\n",
            "Epoch: 5, Step: 212/655, Loss: 2.207568, Accuracy: 18.09%\n",
            "Epoch: 5, Step: 213/655, Loss: 2.208369, Accuracy: 18.06%\n",
            "Epoch: 5, Step: 214/655, Loss: 2.208365, Accuracy: 18.06%\n",
            "Epoch: 5, Step: 215/655, Loss: 2.208692, Accuracy: 18.02%\n",
            "Epoch: 5, Step: 216/655, Loss: 2.209192, Accuracy: 18.01%\n",
            "Epoch: 5, Step: 217/655, Loss: 2.209364, Accuracy: 17.99%\n",
            "Epoch: 5, Step: 218/655, Loss: 2.209180, Accuracy: 17.99%\n",
            "Epoch: 5, Step: 219/655, Loss: 2.209166, Accuracy: 17.98%\n",
            "Epoch: 5, Step: 220/655, Loss: 2.208700, Accuracy: 18.00%\n",
            "Epoch: 5, Step: 221/655, Loss: 2.208349, Accuracy: 17.99%\n",
            "Epoch: 5, Step: 222/655, Loss: 2.208760, Accuracy: 17.96%\n",
            "Epoch: 5, Step: 223/655, Loss: 2.209113, Accuracy: 17.94%\n",
            "Epoch: 5, Step: 224/655, Loss: 2.208621, Accuracy: 17.98%\n",
            "Epoch: 5, Step: 225/655, Loss: 2.208913, Accuracy: 17.99%\n",
            "Epoch: 5, Step: 226/655, Loss: 2.208893, Accuracy: 17.99%\n",
            "Epoch: 5, Step: 227/655, Loss: 2.209227, Accuracy: 18.02%\n",
            "Epoch: 5, Step: 228/655, Loss: 2.209196, Accuracy: 18.00%\n",
            "Epoch: 5, Step: 229/655, Loss: 2.208602, Accuracy: 18.04%\n",
            "Epoch: 5, Step: 230/655, Loss: 2.208727, Accuracy: 18.04%\n",
            "Epoch: 5, Step: 231/655, Loss: 2.208003, Accuracy: 18.05%\n",
            "Epoch: 5, Step: 232/655, Loss: 2.207932, Accuracy: 18.05%\n",
            "Epoch: 5, Step: 233/655, Loss: 2.207740, Accuracy: 18.11%\n",
            "Epoch: 5, Step: 234/655, Loss: 2.207779, Accuracy: 18.11%\n",
            "Epoch: 5, Step: 235/655, Loss: 2.207680, Accuracy: 18.10%\n",
            "Epoch: 5, Step: 236/655, Loss: 2.207850, Accuracy: 18.07%\n",
            "Epoch: 5, Step: 237/655, Loss: 2.207757, Accuracy: 18.12%\n",
            "Epoch: 5, Step: 238/655, Loss: 2.207647, Accuracy: 18.12%\n",
            "Epoch: 5, Step: 239/655, Loss: 2.207231, Accuracy: 18.19%\n",
            "Epoch: 5, Step: 240/655, Loss: 2.207342, Accuracy: 18.18%\n",
            "Epoch: 5, Step: 241/655, Loss: 2.207120, Accuracy: 18.19%\n",
            "Epoch: 5, Step: 242/655, Loss: 2.207491, Accuracy: 18.16%\n",
            "Epoch: 5, Step: 243/655, Loss: 2.207529, Accuracy: 18.16%\n",
            "Epoch: 5, Step: 244/655, Loss: 2.207975, Accuracy: 18.11%\n",
            "Epoch: 5, Step: 245/655, Loss: 2.208173, Accuracy: 18.10%\n",
            "Epoch: 5, Step: 246/655, Loss: 2.207657, Accuracy: 18.17%\n",
            "Epoch: 5, Step: 247/655, Loss: 2.207472, Accuracy: 18.18%\n",
            "Epoch: 5, Step: 248/655, Loss: 2.207435, Accuracy: 18.20%\n",
            "Epoch: 5, Step: 249/655, Loss: 2.207286, Accuracy: 18.17%\n",
            "Epoch: 5, Step: 250/655, Loss: 2.206941, Accuracy: 18.18%\n",
            "Epoch: 5, Step: 251/655, Loss: 2.207070, Accuracy: 18.16%\n",
            "Epoch: 5, Step: 252/655, Loss: 2.206751, Accuracy: 18.18%\n",
            "Epoch: 5, Step: 253/655, Loss: 2.206779, Accuracy: 18.19%\n",
            "Epoch: 5, Step: 254/655, Loss: 2.206659, Accuracy: 18.23%\n",
            "Epoch: 5, Step: 255/655, Loss: 2.206964, Accuracy: 18.24%\n",
            "Epoch: 5, Step: 256/655, Loss: 2.206924, Accuracy: 18.21%\n",
            "Epoch: 5, Step: 257/655, Loss: 2.207080, Accuracy: 18.18%\n",
            "Epoch: 5, Step: 258/655, Loss: 2.206888, Accuracy: 18.19%\n",
            "Epoch: 5, Step: 259/655, Loss: 2.206952, Accuracy: 18.16%\n",
            "Epoch: 5, Step: 260/655, Loss: 2.207351, Accuracy: 18.12%\n",
            "Epoch: 5, Step: 261/655, Loss: 2.207110, Accuracy: 18.14%\n",
            "Epoch: 5, Step: 262/655, Loss: 2.207336, Accuracy: 18.11%\n",
            "Epoch: 5, Step: 263/655, Loss: 2.207062, Accuracy: 18.13%\n",
            "Epoch: 5, Step: 264/655, Loss: 2.207417, Accuracy: 18.10%\n",
            "Epoch: 5, Step: 265/655, Loss: 2.207242, Accuracy: 18.12%\n",
            "Epoch: 5, Step: 266/655, Loss: 2.206851, Accuracy: 18.10%\n",
            "Epoch: 5, Step: 267/655, Loss: 2.207009, Accuracy: 18.11%\n",
            "Epoch: 5, Step: 268/655, Loss: 2.206931, Accuracy: 18.12%\n",
            "Epoch: 5, Step: 269/655, Loss: 2.206800, Accuracy: 18.15%\n",
            "Epoch: 5, Step: 270/655, Loss: 2.206543, Accuracy: 18.18%\n",
            "Epoch: 5, Step: 271/655, Loss: 2.206449, Accuracy: 18.21%\n",
            "Epoch: 5, Step: 272/655, Loss: 2.206364, Accuracy: 18.21%\n",
            "Epoch: 5, Step: 273/655, Loss: 2.206735, Accuracy: 18.21%\n",
            "Epoch: 5, Step: 274/655, Loss: 2.206854, Accuracy: 18.21%\n",
            "Epoch: 5, Step: 275/655, Loss: 2.207392, Accuracy: 18.22%\n",
            "Epoch: 5, Step: 276/655, Loss: 2.207531, Accuracy: 18.25%\n",
            "Epoch: 5, Step: 277/655, Loss: 2.207507, Accuracy: 18.24%\n",
            "Epoch: 5, Step: 278/655, Loss: 2.207371, Accuracy: 18.27%\n",
            "Epoch: 5, Step: 279/655, Loss: 2.206637, Accuracy: 18.30%\n",
            "Epoch: 5, Step: 280/655, Loss: 2.206535, Accuracy: 18.29%\n",
            "Epoch: 5, Step: 281/655, Loss: 2.206387, Accuracy: 18.33%\n",
            "Epoch: 5, Step: 282/655, Loss: 2.206350, Accuracy: 18.34%\n",
            "Epoch: 5, Step: 283/655, Loss: 2.206210, Accuracy: 18.37%\n",
            "Epoch: 5, Step: 284/655, Loss: 2.206643, Accuracy: 18.34%\n",
            "Epoch: 5, Step: 285/655, Loss: 2.206485, Accuracy: 18.38%\n",
            "Epoch: 5, Step: 286/655, Loss: 2.206492, Accuracy: 18.37%\n",
            "Epoch: 5, Step: 287/655, Loss: 2.206715, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 288/655, Loss: 2.206740, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 289/655, Loss: 2.206675, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 290/655, Loss: 2.206727, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 291/655, Loss: 2.206621, Accuracy: 18.47%\n",
            "Epoch: 5, Step: 292/655, Loss: 2.206993, Accuracy: 18.47%\n",
            "Epoch: 5, Step: 293/655, Loss: 2.207443, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 294/655, Loss: 2.207543, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 295/655, Loss: 2.207043, Accuracy: 18.46%\n",
            "Epoch: 5, Step: 296/655, Loss: 2.207133, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 297/655, Loss: 2.206971, Accuracy: 18.47%\n",
            "Epoch: 5, Step: 298/655, Loss: 2.206933, Accuracy: 18.48%\n",
            "Epoch: 5, Step: 299/655, Loss: 2.207268, Accuracy: 18.47%\n",
            "Epoch: 5, Step: 300/655, Loss: 2.207624, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 301/655, Loss: 2.207554, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 302/655, Loss: 2.207647, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 303/655, Loss: 2.207310, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 304/655, Loss: 2.207337, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 305/655, Loss: 2.207372, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 306/655, Loss: 2.207248, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 307/655, Loss: 2.207433, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 308/655, Loss: 2.207121, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 309/655, Loss: 2.206948, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 310/655, Loss: 2.207174, Accuracy: 18.46%\n",
            "Epoch: 5, Step: 311/655, Loss: 2.207193, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 312/655, Loss: 2.207349, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 313/655, Loss: 2.207215, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 314/655, Loss: 2.207273, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 315/655, Loss: 2.207347, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 316/655, Loss: 2.207467, Accuracy: 18.39%\n",
            "Epoch: 5, Step: 317/655, Loss: 2.207487, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 318/655, Loss: 2.207557, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 319/655, Loss: 2.207861, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 320/655, Loss: 2.208095, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 321/655, Loss: 2.207842, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 322/655, Loss: 2.207999, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 323/655, Loss: 2.208139, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 324/655, Loss: 2.208208, Accuracy: 18.46%\n",
            "Epoch: 5, Step: 325/655, Loss: 2.208289, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 326/655, Loss: 2.208375, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 327/655, Loss: 2.208394, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 328/655, Loss: 2.208318, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 329/655, Loss: 2.208000, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 330/655, Loss: 2.207928, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 331/655, Loss: 2.208465, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 332/655, Loss: 2.208218, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 333/655, Loss: 2.207693, Accuracy: 18.46%\n",
            "Epoch: 5, Step: 334/655, Loss: 2.207655, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 335/655, Loss: 2.207524, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 336/655, Loss: 2.207404, Accuracy: 18.46%\n",
            "Epoch: 5, Step: 337/655, Loss: 2.207453, Accuracy: 18.48%\n",
            "Epoch: 5, Step: 338/655, Loss: 2.207626, Accuracy: 18.49%\n",
            "Epoch: 5, Step: 339/655, Loss: 2.207499, Accuracy: 18.49%\n",
            "Epoch: 5, Step: 340/655, Loss: 2.207566, Accuracy: 18.49%\n",
            "Epoch: 5, Step: 341/655, Loss: 2.207679, Accuracy: 18.49%\n",
            "Epoch: 5, Step: 342/655, Loss: 2.207889, Accuracy: 18.49%\n",
            "Epoch: 5, Step: 343/655, Loss: 2.208162, Accuracy: 18.49%\n",
            "Epoch: 5, Step: 344/655, Loss: 2.208361, Accuracy: 18.47%\n",
            "Epoch: 5, Step: 345/655, Loss: 2.208669, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 346/655, Loss: 2.208684, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 347/655, Loss: 2.209262, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 348/655, Loss: 2.208934, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 349/655, Loss: 2.208907, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 350/655, Loss: 2.208807, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 351/655, Loss: 2.208539, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 352/655, Loss: 2.208439, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 353/655, Loss: 2.208885, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 354/655, Loss: 2.208740, Accuracy: 18.46%\n",
            "Epoch: 5, Step: 355/655, Loss: 2.209225, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 356/655, Loss: 2.209229, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 357/655, Loss: 2.209190, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 358/655, Loss: 2.209167, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 359/655, Loss: 2.208809, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 360/655, Loss: 2.209077, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 361/655, Loss: 2.208707, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 362/655, Loss: 2.208929, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 363/655, Loss: 2.209132, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 364/655, Loss: 2.209146, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 365/655, Loss: 2.209334, Accuracy: 18.39%\n",
            "Epoch: 5, Step: 366/655, Loss: 2.209432, Accuracy: 18.38%\n",
            "Epoch: 5, Step: 367/655, Loss: 2.209187, Accuracy: 18.38%\n",
            "Epoch: 5, Step: 368/655, Loss: 2.209433, Accuracy: 18.36%\n",
            "Epoch: 5, Step: 369/655, Loss: 2.209372, Accuracy: 18.35%\n",
            "Epoch: 5, Step: 370/655, Loss: 2.209569, Accuracy: 18.36%\n",
            "Epoch: 5, Step: 371/655, Loss: 2.209336, Accuracy: 18.38%\n",
            "Epoch: 5, Step: 372/655, Loss: 2.209596, Accuracy: 18.37%\n",
            "Epoch: 5, Step: 373/655, Loss: 2.209623, Accuracy: 18.38%\n",
            "Epoch: 5, Step: 374/655, Loss: 2.209664, Accuracy: 18.37%\n",
            "Epoch: 5, Step: 375/655, Loss: 2.209652, Accuracy: 18.37%\n",
            "Epoch: 5, Step: 376/655, Loss: 2.209558, Accuracy: 18.39%\n",
            "Epoch: 5, Step: 377/655, Loss: 2.209429, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 378/655, Loss: 2.209448, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 379/655, Loss: 2.209585, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 380/655, Loss: 2.209704, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 381/655, Loss: 2.209758, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 382/655, Loss: 2.209780, Accuracy: 18.48%\n",
            "Epoch: 5, Step: 383/655, Loss: 2.209871, Accuracy: 18.48%\n",
            "Epoch: 5, Step: 384/655, Loss: 2.209717, Accuracy: 18.48%\n",
            "Epoch: 5, Step: 385/655, Loss: 2.209830, Accuracy: 18.46%\n",
            "Epoch: 5, Step: 386/655, Loss: 2.209856, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 387/655, Loss: 2.210063, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 388/655, Loss: 2.210055, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 389/655, Loss: 2.210195, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 390/655, Loss: 2.210204, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 391/655, Loss: 2.210329, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 392/655, Loss: 2.210285, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 393/655, Loss: 2.210455, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 394/655, Loss: 2.210629, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 395/655, Loss: 2.210673, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 396/655, Loss: 2.210674, Accuracy: 18.39%\n",
            "Epoch: 5, Step: 397/655, Loss: 2.210640, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 398/655, Loss: 2.210542, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 399/655, Loss: 2.210731, Accuracy: 18.39%\n",
            "Epoch: 5, Step: 400/655, Loss: 2.210861, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 401/655, Loss: 2.210667, Accuracy: 18.39%\n",
            "Epoch: 5, Step: 402/655, Loss: 2.210238, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 403/655, Loss: 2.210302, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 404/655, Loss: 2.210284, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 405/655, Loss: 2.210238, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 406/655, Loss: 2.210399, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 407/655, Loss: 2.210436, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 408/655, Loss: 2.210468, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 409/655, Loss: 2.210069, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 410/655, Loss: 2.210250, Accuracy: 18.39%\n",
            "Epoch: 5, Step: 411/655, Loss: 2.210192, Accuracy: 18.39%\n",
            "Epoch: 5, Step: 412/655, Loss: 2.210338, Accuracy: 18.39%\n",
            "Epoch: 5, Step: 413/655, Loss: 2.210506, Accuracy: 18.38%\n",
            "Epoch: 5, Step: 414/655, Loss: 2.210451, Accuracy: 18.38%\n",
            "Epoch: 5, Step: 415/655, Loss: 2.210080, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 416/655, Loss: 2.210204, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 417/655, Loss: 2.210157, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 418/655, Loss: 2.210374, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 419/655, Loss: 2.210386, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 420/655, Loss: 2.210315, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 421/655, Loss: 2.210313, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 422/655, Loss: 2.210280, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 423/655, Loss: 2.210660, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 424/655, Loss: 2.210353, Accuracy: 18.41%\n",
            "Epoch: 5, Step: 425/655, Loss: 2.210453, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 426/655, Loss: 2.210373, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 427/655, Loss: 2.210302, Accuracy: 18.40%\n",
            "Epoch: 5, Step: 428/655, Loss: 2.210240, Accuracy: 18.39%\n",
            "Epoch: 5, Step: 429/655, Loss: 2.210208, Accuracy: 18.42%\n",
            "Epoch: 5, Step: 430/655, Loss: 2.210265, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 431/655, Loss: 2.210172, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 432/655, Loss: 2.210201, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 433/655, Loss: 2.210285, Accuracy: 18.43%\n",
            "Epoch: 5, Step: 434/655, Loss: 2.210132, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 435/655, Loss: 2.210136, Accuracy: 18.46%\n",
            "Epoch: 5, Step: 436/655, Loss: 2.210116, Accuracy: 18.48%\n",
            "Epoch: 5, Step: 437/655, Loss: 2.210044, Accuracy: 18.48%\n",
            "Epoch: 5, Step: 438/655, Loss: 2.209623, Accuracy: 18.54%\n",
            "Epoch: 5, Step: 439/655, Loss: 2.209807, Accuracy: 18.52%\n",
            "Epoch: 5, Step: 440/655, Loss: 2.210303, Accuracy: 18.49%\n",
            "Epoch: 5, Step: 441/655, Loss: 2.210402, Accuracy: 18.49%\n",
            "Epoch: 5, Step: 442/655, Loss: 2.210337, Accuracy: 18.50%\n",
            "Epoch: 5, Step: 443/655, Loss: 2.210414, Accuracy: 18.48%\n",
            "Epoch: 5, Step: 444/655, Loss: 2.210150, Accuracy: 18.52%\n",
            "Epoch: 5, Step: 445/655, Loss: 2.209931, Accuracy: 18.53%\n",
            "Epoch: 5, Step: 446/655, Loss: 2.209872, Accuracy: 18.53%\n",
            "Epoch: 5, Step: 447/655, Loss: 2.209986, Accuracy: 18.54%\n",
            "Epoch: 5, Step: 448/655, Loss: 2.209833, Accuracy: 18.55%\n",
            "Epoch: 5, Step: 449/655, Loss: 2.209770, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 450/655, Loss: 2.209860, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 451/655, Loss: 2.209863, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 452/655, Loss: 2.210057, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 453/655, Loss: 2.210134, Accuracy: 18.57%\n",
            "Epoch: 5, Step: 454/655, Loss: 2.210239, Accuracy: 18.56%\n",
            "Epoch: 5, Step: 455/655, Loss: 2.210360, Accuracy: 18.54%\n",
            "Epoch: 5, Step: 456/655, Loss: 2.210212, Accuracy: 18.55%\n",
            "Epoch: 5, Step: 457/655, Loss: 2.209984, Accuracy: 18.57%\n",
            "Epoch: 5, Step: 458/655, Loss: 2.209719, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 459/655, Loss: 2.209684, Accuracy: 18.57%\n",
            "Epoch: 5, Step: 460/655, Loss: 2.209796, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 461/655, Loss: 2.209821, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 462/655, Loss: 2.209927, Accuracy: 18.56%\n",
            "Epoch: 5, Step: 463/655, Loss: 2.209911, Accuracy: 18.56%\n",
            "Epoch: 5, Step: 464/655, Loss: 2.209631, Accuracy: 18.60%\n",
            "Epoch: 5, Step: 465/655, Loss: 2.209601, Accuracy: 18.61%\n",
            "Epoch: 5, Step: 466/655, Loss: 2.209519, Accuracy: 18.61%\n",
            "Epoch: 5, Step: 467/655, Loss: 2.209475, Accuracy: 18.60%\n",
            "Epoch: 5, Step: 468/655, Loss: 2.209563, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 469/655, Loss: 2.209305, Accuracy: 18.60%\n",
            "Epoch: 5, Step: 470/655, Loss: 2.209327, Accuracy: 18.62%\n",
            "Epoch: 5, Step: 471/655, Loss: 2.209534, Accuracy: 18.64%\n",
            "Epoch: 5, Step: 472/655, Loss: 2.209529, Accuracy: 18.64%\n",
            "Epoch: 5, Step: 473/655, Loss: 2.209777, Accuracy: 18.62%\n",
            "Epoch: 5, Step: 474/655, Loss: 2.209821, Accuracy: 18.62%\n",
            "Epoch: 5, Step: 475/655, Loss: 2.209828, Accuracy: 18.64%\n",
            "Epoch: 5, Step: 476/655, Loss: 2.209962, Accuracy: 18.64%\n",
            "Epoch: 5, Step: 477/655, Loss: 2.210054, Accuracy: 18.63%\n",
            "Epoch: 5, Step: 478/655, Loss: 2.209861, Accuracy: 18.63%\n",
            "Epoch: 5, Step: 479/655, Loss: 2.210099, Accuracy: 18.61%\n",
            "Epoch: 5, Step: 480/655, Loss: 2.210035, Accuracy: 18.61%\n",
            "Epoch: 5, Step: 481/655, Loss: 2.210130, Accuracy: 18.61%\n",
            "Epoch: 5, Step: 482/655, Loss: 2.210221, Accuracy: 18.61%\n",
            "Epoch: 5, Step: 483/655, Loss: 2.210431, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 484/655, Loss: 2.210416, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 485/655, Loss: 2.210450, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 486/655, Loss: 2.210704, Accuracy: 18.60%\n",
            "Epoch: 5, Step: 487/655, Loss: 2.210579, Accuracy: 18.63%\n",
            "Epoch: 5, Step: 488/655, Loss: 2.210433, Accuracy: 18.62%\n",
            "Epoch: 5, Step: 489/655, Loss: 2.210247, Accuracy: 18.62%\n",
            "Epoch: 5, Step: 490/655, Loss: 2.210472, Accuracy: 18.61%\n",
            "Epoch: 5, Step: 491/655, Loss: 2.210565, Accuracy: 18.62%\n",
            "Epoch: 5, Step: 492/655, Loss: 2.210723, Accuracy: 18.60%\n",
            "Epoch: 5, Step: 493/655, Loss: 2.210796, Accuracy: 18.60%\n",
            "Epoch: 5, Step: 494/655, Loss: 2.210703, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 495/655, Loss: 2.210761, Accuracy: 18.57%\n",
            "Epoch: 5, Step: 496/655, Loss: 2.210929, Accuracy: 18.55%\n",
            "Epoch: 5, Step: 497/655, Loss: 2.210984, Accuracy: 18.57%\n",
            "Epoch: 5, Step: 498/655, Loss: 2.210911, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 499/655, Loss: 2.210781, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 500/655, Loss: 2.210582, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 501/655, Loss: 2.210702, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 502/655, Loss: 2.210695, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 503/655, Loss: 2.210633, Accuracy: 18.56%\n",
            "Epoch: 5, Step: 504/655, Loss: 2.210675, Accuracy: 18.55%\n",
            "Epoch: 5, Step: 505/655, Loss: 2.210579, Accuracy: 18.56%\n",
            "Epoch: 5, Step: 506/655, Loss: 2.210636, Accuracy: 18.57%\n",
            "Epoch: 5, Step: 507/655, Loss: 2.210500, Accuracy: 18.56%\n",
            "Epoch: 5, Step: 508/655, Loss: 2.210272, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 509/655, Loss: 2.210405, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 510/655, Loss: 2.210254, Accuracy: 18.60%\n",
            "Epoch: 5, Step: 511/655, Loss: 2.210340, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 512/655, Loss: 2.210067, Accuracy: 18.60%\n",
            "Epoch: 5, Step: 513/655, Loss: 2.210409, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 514/655, Loss: 2.210589, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 515/655, Loss: 2.210512, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 516/655, Loss: 2.210534, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 517/655, Loss: 2.210601, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 518/655, Loss: 2.210487, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 519/655, Loss: 2.210458, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 520/655, Loss: 2.210351, Accuracy: 18.60%\n",
            "Epoch: 5, Step: 521/655, Loss: 2.210116, Accuracy: 18.62%\n",
            "Epoch: 5, Step: 522/655, Loss: 2.210382, Accuracy: 18.61%\n",
            "Epoch: 5, Step: 523/655, Loss: 2.210242, Accuracy: 18.64%\n",
            "Epoch: 5, Step: 524/655, Loss: 2.210378, Accuracy: 18.64%\n",
            "Epoch: 5, Step: 525/655, Loss: 2.210243, Accuracy: 18.65%\n",
            "Epoch: 5, Step: 526/655, Loss: 2.210019, Accuracy: 18.65%\n",
            "Epoch: 5, Step: 527/655, Loss: 2.210032, Accuracy: 18.64%\n",
            "Epoch: 5, Step: 528/655, Loss: 2.209937, Accuracy: 18.65%\n",
            "Epoch: 5, Step: 529/655, Loss: 2.210117, Accuracy: 18.63%\n",
            "Epoch: 5, Step: 530/655, Loss: 2.210192, Accuracy: 18.63%\n",
            "Epoch: 5, Step: 531/655, Loss: 2.210309, Accuracy: 18.63%\n",
            "Epoch: 5, Step: 532/655, Loss: 2.210047, Accuracy: 18.64%\n",
            "Epoch: 5, Step: 533/655, Loss: 2.210052, Accuracy: 18.62%\n",
            "Epoch: 5, Step: 534/655, Loss: 2.210158, Accuracy: 18.62%\n",
            "Epoch: 5, Step: 535/655, Loss: 2.209892, Accuracy: 18.61%\n",
            "Epoch: 5, Step: 536/655, Loss: 2.209868, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 537/655, Loss: 2.209810, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 538/655, Loss: 2.209906, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 539/655, Loss: 2.209898, Accuracy: 18.56%\n",
            "Epoch: 5, Step: 540/655, Loss: 2.209633, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 541/655, Loss: 2.209510, Accuracy: 18.61%\n",
            "Epoch: 5, Step: 542/655, Loss: 2.209356, Accuracy: 18.60%\n",
            "Epoch: 5, Step: 543/655, Loss: 2.209410, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 544/655, Loss: 2.209253, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 545/655, Loss: 2.209215, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 546/655, Loss: 2.208927, Accuracy: 18.60%\n",
            "Epoch: 5, Step: 547/655, Loss: 2.209158, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 548/655, Loss: 2.209210, Accuracy: 18.57%\n",
            "Epoch: 5, Step: 549/655, Loss: 2.208935, Accuracy: 18.57%\n",
            "Epoch: 5, Step: 550/655, Loss: 2.208841, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 551/655, Loss: 2.208854, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 552/655, Loss: 2.209088, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 553/655, Loss: 2.209105, Accuracy: 18.57%\n",
            "Epoch: 5, Step: 554/655, Loss: 2.209032, Accuracy: 18.56%\n",
            "Epoch: 5, Step: 555/655, Loss: 2.209073, Accuracy: 18.55%\n",
            "Epoch: 5, Step: 556/655, Loss: 2.209165, Accuracy: 18.56%\n",
            "Epoch: 5, Step: 557/655, Loss: 2.209266, Accuracy: 18.54%\n",
            "Epoch: 5, Step: 558/655, Loss: 2.209243, Accuracy: 18.54%\n",
            "Epoch: 5, Step: 559/655, Loss: 2.209224, Accuracy: 18.54%\n",
            "Epoch: 5, Step: 560/655, Loss: 2.209354, Accuracy: 18.52%\n",
            "Epoch: 5, Step: 561/655, Loss: 2.209413, Accuracy: 18.49%\n",
            "Epoch: 5, Step: 562/655, Loss: 2.209539, Accuracy: 18.49%\n",
            "Epoch: 5, Step: 563/655, Loss: 2.209399, Accuracy: 18.47%\n",
            "Epoch: 5, Step: 564/655, Loss: 2.209238, Accuracy: 18.48%\n",
            "Epoch: 5, Step: 565/655, Loss: 2.209315, Accuracy: 18.48%\n",
            "Epoch: 5, Step: 566/655, Loss: 2.209464, Accuracy: 18.47%\n",
            "Epoch: 5, Step: 567/655, Loss: 2.209461, Accuracy: 18.47%\n",
            "Epoch: 5, Step: 568/655, Loss: 2.209606, Accuracy: 18.49%\n",
            "Epoch: 5, Step: 569/655, Loss: 2.209446, Accuracy: 18.49%\n",
            "Epoch: 5, Step: 570/655, Loss: 2.209597, Accuracy: 18.47%\n",
            "Epoch: 5, Step: 571/655, Loss: 2.209519, Accuracy: 18.47%\n",
            "Epoch: 5, Step: 572/655, Loss: 2.209488, Accuracy: 18.46%\n",
            "Epoch: 5, Step: 573/655, Loss: 2.209374, Accuracy: 18.48%\n",
            "Epoch: 5, Step: 574/655, Loss: 2.209147, Accuracy: 18.49%\n",
            "Epoch: 5, Step: 575/655, Loss: 2.209127, Accuracy: 18.48%\n",
            "Epoch: 5, Step: 576/655, Loss: 2.209448, Accuracy: 18.47%\n",
            "Epoch: 5, Step: 577/655, Loss: 2.209575, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 578/655, Loss: 2.209844, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 579/655, Loss: 2.209841, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 580/655, Loss: 2.209649, Accuracy: 18.44%\n",
            "Epoch: 5, Step: 581/655, Loss: 2.209560, Accuracy: 18.45%\n",
            "Epoch: 5, Step: 582/655, Loss: 2.209492, Accuracy: 18.47%\n",
            "Epoch: 5, Step: 583/655, Loss: 2.209449, Accuracy: 18.48%\n",
            "Epoch: 5, Step: 584/655, Loss: 2.209335, Accuracy: 18.52%\n",
            "Epoch: 5, Step: 585/655, Loss: 2.209590, Accuracy: 18.50%\n",
            "Epoch: 5, Step: 586/655, Loss: 2.209504, Accuracy: 18.50%\n",
            "Epoch: 5, Step: 587/655, Loss: 2.209558, Accuracy: 18.51%\n",
            "Epoch: 5, Step: 588/655, Loss: 2.209336, Accuracy: 18.51%\n",
            "Epoch: 5, Step: 589/655, Loss: 2.209474, Accuracy: 18.51%\n",
            "Epoch: 5, Step: 590/655, Loss: 2.209295, Accuracy: 18.50%\n",
            "Epoch: 5, Step: 591/655, Loss: 2.209342, Accuracy: 18.48%\n",
            "Epoch: 5, Step: 592/655, Loss: 2.209109, Accuracy: 18.51%\n",
            "Epoch: 5, Step: 593/655, Loss: 2.209127, Accuracy: 18.54%\n",
            "Epoch: 5, Step: 594/655, Loss: 2.209098, Accuracy: 18.54%\n",
            "Epoch: 5, Step: 595/655, Loss: 2.208996, Accuracy: 18.55%\n",
            "Epoch: 5, Step: 596/655, Loss: 2.209092, Accuracy: 18.56%\n",
            "Epoch: 5, Step: 597/655, Loss: 2.209107, Accuracy: 18.55%\n",
            "Epoch: 5, Step: 598/655, Loss: 2.209261, Accuracy: 18.56%\n",
            "Epoch: 5, Step: 599/655, Loss: 2.209274, Accuracy: 18.56%\n",
            "Epoch: 5, Step: 600/655, Loss: 2.209109, Accuracy: 18.58%\n",
            "Epoch: 5, Step: 601/655, Loss: 2.209057, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 602/655, Loss: 2.208953, Accuracy: 18.59%\n",
            "Epoch: 5, Step: 603/655, Loss: 2.209033, Accuracy: 18.60%\n",
            "Epoch: 5, Step: 604/655, Loss: 2.209006, Accuracy: 18.62%\n",
            "Epoch: 5, Step: 605/655, Loss: 2.209230, Accuracy: 18.61%\n",
            "Epoch: 5, Step: 606/655, Loss: 2.209083, Accuracy: 18.61%\n",
            "Epoch: 5, Step: 607/655, Loss: 2.208961, Accuracy: 18.62%\n",
            "Epoch: 5, Step: 608/655, Loss: 2.208834, Accuracy: 18.63%\n",
            "Epoch: 5, Step: 609/655, Loss: 2.208769, Accuracy: 18.65%\n",
            "Epoch: 5, Step: 610/655, Loss: 2.208691, Accuracy: 18.66%\n",
            "Epoch: 5, Step: 611/655, Loss: 2.208609, Accuracy: 18.64%\n",
            "Epoch: 5, Step: 612/655, Loss: 2.208409, Accuracy: 18.63%\n",
            "Epoch: 5, Step: 613/655, Loss: 2.208313, Accuracy: 18.64%\n",
            "Epoch: 5, Step: 614/655, Loss: 2.208255, Accuracy: 18.67%\n",
            "Epoch: 5, Step: 615/655, Loss: 2.208290, Accuracy: 18.66%\n",
            "Epoch: 5, Step: 616/655, Loss: 2.208320, Accuracy: 18.66%\n",
            "Epoch: 5, Step: 617/655, Loss: 2.208182, Accuracy: 18.68%\n",
            "Epoch: 5, Step: 618/655, Loss: 2.208182, Accuracy: 18.67%\n",
            "Epoch: 5, Step: 619/655, Loss: 2.208111, Accuracy: 18.67%\n",
            "Epoch: 5, Step: 620/655, Loss: 2.208117, Accuracy: 18.68%\n",
            "Epoch: 5, Step: 621/655, Loss: 2.208103, Accuracy: 18.68%\n",
            "Epoch: 5, Step: 622/655, Loss: 2.208242, Accuracy: 18.67%\n",
            "Epoch: 5, Step: 623/655, Loss: 2.208440, Accuracy: 18.67%\n",
            "Epoch: 5, Step: 624/655, Loss: 2.208421, Accuracy: 18.66%\n",
            "Epoch: 5, Step: 625/655, Loss: 2.208360, Accuracy: 18.68%\n",
            "Epoch: 5, Step: 626/655, Loss: 2.208202, Accuracy: 18.70%\n",
            "Epoch: 5, Step: 627/655, Loss: 2.208313, Accuracy: 18.69%\n",
            "Epoch: 5, Step: 628/655, Loss: 2.208477, Accuracy: 18.67%\n",
            "Epoch: 5, Step: 629/655, Loss: 2.208432, Accuracy: 18.69%\n",
            "Epoch: 5, Step: 630/655, Loss: 2.208502, Accuracy: 18.69%\n",
            "Epoch: 5, Step: 631/655, Loss: 2.208614, Accuracy: 18.68%\n",
            "Epoch: 5, Step: 632/655, Loss: 2.208615, Accuracy: 18.68%\n",
            "Epoch: 5, Step: 633/655, Loss: 2.208669, Accuracy: 18.67%\n",
            "Epoch: 5, Step: 634/655, Loss: 2.208749, Accuracy: 18.67%\n",
            "Epoch: 5, Step: 635/655, Loss: 2.208585, Accuracy: 18.67%\n",
            "Epoch: 5, Step: 636/655, Loss: 2.208570, Accuracy: 18.67%\n",
            "Epoch: 5, Step: 637/655, Loss: 2.208681, Accuracy: 18.67%\n",
            "Epoch: 5, Step: 638/655, Loss: 2.208629, Accuracy: 18.69%\n",
            "Epoch: 5, Step: 639/655, Loss: 2.208434, Accuracy: 18.71%\n",
            "Epoch: 5, Step: 640/655, Loss: 2.208349, Accuracy: 18.72%\n",
            "Epoch: 5, Step: 641/655, Loss: 2.208509, Accuracy: 18.71%\n",
            "Epoch: 5, Step: 642/655, Loss: 2.208473, Accuracy: 18.71%\n",
            "Epoch: 5, Step: 643/655, Loss: 2.208387, Accuracy: 18.71%\n",
            "Epoch: 5, Step: 644/655, Loss: 2.208361, Accuracy: 18.72%\n",
            "Epoch: 5, Step: 645/655, Loss: 2.208404, Accuracy: 18.71%\n",
            "Epoch: 5, Step: 646/655, Loss: 2.208323, Accuracy: 18.70%\n",
            "Epoch: 5, Step: 647/655, Loss: 2.208238, Accuracy: 18.70%\n",
            "Epoch: 5, Step: 648/655, Loss: 2.208406, Accuracy: 18.70%\n",
            "Epoch: 5, Step: 649/655, Loss: 2.208384, Accuracy: 18.70%\n",
            "Epoch: 5, Step: 650/655, Loss: 2.208286, Accuracy: 18.70%\n",
            "Epoch: 5, Step: 651/655, Loss: 2.208182, Accuracy: 18.71%\n",
            "Epoch: 5, Step: 652/655, Loss: 2.208295, Accuracy: 18.70%\n",
            "Epoch: 5, Step: 653/655, Loss: 2.208220, Accuracy: 18.69%\n",
            "Epoch: 5, Step: 654/655, Loss: 2.208155, Accuracy: 18.69%\n",
            "Epoch: 5, Step: 655/655, Loss: 2.208237, Accuracy: 18.68%\n",
            "Epoch: 6, Step: 1/655, Loss: 2.289963, Accuracy: 18.75%\n",
            "Epoch: 6, Step: 2/655, Loss: 2.260484, Accuracy: 21.88%\n",
            "Epoch: 6, Step: 3/655, Loss: 2.251529, Accuracy: 16.67%\n",
            "Epoch: 6, Step: 4/655, Loss: 2.243090, Accuracy: 20.31%\n",
            "Epoch: 6, Step: 5/655, Loss: 2.232903, Accuracy: 20.00%\n",
            "Epoch: 6, Step: 6/655, Loss: 2.238532, Accuracy: 19.27%\n",
            "Epoch: 6, Step: 7/655, Loss: 2.226448, Accuracy: 19.64%\n",
            "Epoch: 6, Step: 8/655, Loss: 2.208591, Accuracy: 19.92%\n",
            "Epoch: 6, Step: 9/655, Loss: 2.205638, Accuracy: 20.14%\n",
            "Epoch: 6, Step: 10/655, Loss: 2.218458, Accuracy: 19.38%\n",
            "Epoch: 6, Step: 11/655, Loss: 2.210734, Accuracy: 19.60%\n",
            "Epoch: 6, Step: 12/655, Loss: 2.200599, Accuracy: 19.27%\n",
            "Epoch: 6, Step: 13/655, Loss: 2.205768, Accuracy: 19.23%\n",
            "Epoch: 6, Step: 14/655, Loss: 2.206851, Accuracy: 19.20%\n",
            "Epoch: 6, Step: 15/655, Loss: 2.208631, Accuracy: 19.17%\n",
            "Epoch: 6, Step: 16/655, Loss: 2.200694, Accuracy: 20.12%\n",
            "Epoch: 6, Step: 17/655, Loss: 2.189566, Accuracy: 20.96%\n",
            "Epoch: 6, Step: 18/655, Loss: 2.188788, Accuracy: 20.66%\n",
            "Epoch: 6, Step: 19/655, Loss: 2.186774, Accuracy: 20.56%\n",
            "Epoch: 6, Step: 20/655, Loss: 2.190078, Accuracy: 20.00%\n",
            "Epoch: 6, Step: 21/655, Loss: 2.189600, Accuracy: 19.94%\n",
            "Epoch: 6, Step: 22/655, Loss: 2.195580, Accuracy: 19.74%\n",
            "Epoch: 6, Step: 23/655, Loss: 2.198548, Accuracy: 19.43%\n",
            "Epoch: 6, Step: 24/655, Loss: 2.200540, Accuracy: 19.40%\n",
            "Epoch: 6, Step: 25/655, Loss: 2.195787, Accuracy: 19.62%\n",
            "Epoch: 6, Step: 26/655, Loss: 2.194461, Accuracy: 20.07%\n",
            "Epoch: 6, Step: 27/655, Loss: 2.198437, Accuracy: 19.91%\n",
            "Epoch: 6, Step: 28/655, Loss: 2.197897, Accuracy: 19.98%\n",
            "Epoch: 6, Step: 29/655, Loss: 2.194433, Accuracy: 19.83%\n",
            "Epoch: 6, Step: 30/655, Loss: 2.193216, Accuracy: 20.00%\n",
            "Epoch: 6, Step: 31/655, Loss: 2.198180, Accuracy: 19.76%\n",
            "Epoch: 6, Step: 32/655, Loss: 2.194275, Accuracy: 19.92%\n",
            "Epoch: 6, Step: 33/655, Loss: 2.192842, Accuracy: 19.98%\n",
            "Epoch: 6, Step: 34/655, Loss: 2.192748, Accuracy: 19.67%\n",
            "Epoch: 6, Step: 35/655, Loss: 2.194399, Accuracy: 19.64%\n",
            "Epoch: 6, Step: 36/655, Loss: 2.198559, Accuracy: 19.36%\n",
            "Epoch: 6, Step: 37/655, Loss: 2.194425, Accuracy: 19.85%\n",
            "Epoch: 6, Step: 38/655, Loss: 2.195288, Accuracy: 19.49%\n",
            "Epoch: 6, Step: 39/655, Loss: 2.194578, Accuracy: 19.55%\n",
            "Epoch: 6, Step: 40/655, Loss: 2.193957, Accuracy: 19.77%\n",
            "Epoch: 6, Step: 41/655, Loss: 2.193442, Accuracy: 19.89%\n",
            "Epoch: 6, Step: 42/655, Loss: 2.194514, Accuracy: 19.94%\n",
            "Epoch: 6, Step: 43/655, Loss: 2.192099, Accuracy: 19.84%\n",
            "Epoch: 6, Step: 44/655, Loss: 2.186808, Accuracy: 20.10%\n",
            "Epoch: 6, Step: 45/655, Loss: 2.185285, Accuracy: 20.21%\n",
            "Epoch: 6, Step: 46/655, Loss: 2.186605, Accuracy: 20.24%\n",
            "Epoch: 6, Step: 47/655, Loss: 2.186170, Accuracy: 20.08%\n",
            "Epoch: 6, Step: 48/655, Loss: 2.183730, Accuracy: 20.25%\n",
            "Epoch: 6, Step: 49/655, Loss: 2.185067, Accuracy: 20.09%\n",
            "Epoch: 6, Step: 50/655, Loss: 2.185672, Accuracy: 20.12%\n",
            "Epoch: 6, Step: 51/655, Loss: 2.185692, Accuracy: 20.22%\n",
            "Epoch: 6, Step: 52/655, Loss: 2.186981, Accuracy: 20.13%\n",
            "Epoch: 6, Step: 53/655, Loss: 2.188688, Accuracy: 19.87%\n",
            "Epoch: 6, Step: 54/655, Loss: 2.186144, Accuracy: 20.02%\n",
            "Epoch: 6, Step: 55/655, Loss: 2.187338, Accuracy: 19.89%\n",
            "Epoch: 6, Step: 56/655, Loss: 2.189242, Accuracy: 19.75%\n",
            "Epoch: 6, Step: 57/655, Loss: 2.187892, Accuracy: 19.68%\n",
            "Epoch: 6, Step: 58/655, Loss: 2.187831, Accuracy: 19.77%\n",
            "Epoch: 6, Step: 59/655, Loss: 2.192401, Accuracy: 19.70%\n",
            "Epoch: 6, Step: 60/655, Loss: 2.190485, Accuracy: 19.69%\n",
            "Epoch: 6, Step: 61/655, Loss: 2.192139, Accuracy: 19.47%\n",
            "Epoch: 6, Step: 62/655, Loss: 2.191150, Accuracy: 19.61%\n",
            "Epoch: 6, Step: 63/655, Loss: 2.192398, Accuracy: 19.64%\n",
            "Epoch: 6, Step: 64/655, Loss: 2.190072, Accuracy: 19.78%\n",
            "Epoch: 6, Step: 65/655, Loss: 2.190363, Accuracy: 19.86%\n",
            "Epoch: 6, Step: 66/655, Loss: 2.191669, Accuracy: 19.84%\n",
            "Epoch: 6, Step: 67/655, Loss: 2.191193, Accuracy: 20.01%\n",
            "Epoch: 6, Step: 68/655, Loss: 2.191627, Accuracy: 20.08%\n",
            "Epoch: 6, Step: 69/655, Loss: 2.190762, Accuracy: 20.06%\n",
            "Epoch: 6, Step: 70/655, Loss: 2.190140, Accuracy: 20.00%\n",
            "Epoch: 6, Step: 71/655, Loss: 2.190274, Accuracy: 19.98%\n",
            "Epoch: 6, Step: 72/655, Loss: 2.190167, Accuracy: 20.05%\n",
            "Epoch: 6, Step: 73/655, Loss: 2.191552, Accuracy: 19.99%\n",
            "Epoch: 6, Step: 74/655, Loss: 2.191932, Accuracy: 19.89%\n",
            "Epoch: 6, Step: 75/655, Loss: 2.190022, Accuracy: 20.00%\n",
            "Epoch: 6, Step: 76/655, Loss: 2.191908, Accuracy: 19.90%\n",
            "Epoch: 6, Step: 77/655, Loss: 2.192941, Accuracy: 19.85%\n",
            "Epoch: 6, Step: 78/655, Loss: 2.193230, Accuracy: 19.87%\n",
            "Epoch: 6, Step: 79/655, Loss: 2.193632, Accuracy: 19.90%\n",
            "Epoch: 6, Step: 80/655, Loss: 2.193049, Accuracy: 19.88%\n",
            "Epoch: 6, Step: 81/655, Loss: 2.192555, Accuracy: 19.91%\n",
            "Epoch: 6, Step: 82/655, Loss: 2.193742, Accuracy: 19.89%\n",
            "Epoch: 6, Step: 83/655, Loss: 2.192738, Accuracy: 19.99%\n",
            "Epoch: 6, Step: 84/655, Loss: 2.192508, Accuracy: 19.90%\n",
            "Epoch: 6, Step: 85/655, Loss: 2.193988, Accuracy: 19.78%\n",
            "Epoch: 6, Step: 86/655, Loss: 2.193257, Accuracy: 19.84%\n",
            "Epoch: 6, Step: 87/655, Loss: 2.194564, Accuracy: 19.76%\n",
            "Epoch: 6, Step: 88/655, Loss: 2.193704, Accuracy: 19.85%\n",
            "Epoch: 6, Step: 89/655, Loss: 2.193104, Accuracy: 19.87%\n",
            "Epoch: 6, Step: 90/655, Loss: 2.192872, Accuracy: 19.93%\n",
            "Epoch: 6, Step: 91/655, Loss: 2.193464, Accuracy: 19.88%\n",
            "Epoch: 6, Step: 92/655, Loss: 2.195159, Accuracy: 19.87%\n",
            "Epoch: 6, Step: 93/655, Loss: 2.195114, Accuracy: 19.89%\n",
            "Epoch: 6, Step: 94/655, Loss: 2.193801, Accuracy: 19.91%\n",
            "Epoch: 6, Step: 95/655, Loss: 2.195727, Accuracy: 19.84%\n",
            "Epoch: 6, Step: 96/655, Loss: 2.197552, Accuracy: 19.73%\n",
            "Epoch: 6, Step: 97/655, Loss: 2.196786, Accuracy: 19.78%\n",
            "Epoch: 6, Step: 98/655, Loss: 2.196963, Accuracy: 19.80%\n",
            "Epoch: 6, Step: 99/655, Loss: 2.197416, Accuracy: 19.79%\n",
            "Epoch: 6, Step: 100/655, Loss: 2.197861, Accuracy: 19.75%\n",
            "Epoch: 6, Step: 101/655, Loss: 2.198413, Accuracy: 19.59%\n",
            "Epoch: 6, Step: 102/655, Loss: 2.198818, Accuracy: 19.61%\n",
            "Epoch: 6, Step: 103/655, Loss: 2.198781, Accuracy: 19.63%\n",
            "Epoch: 6, Step: 104/655, Loss: 2.199178, Accuracy: 19.71%\n",
            "Epoch: 6, Step: 105/655, Loss: 2.199535, Accuracy: 19.70%\n",
            "Epoch: 6, Step: 106/655, Loss: 2.198995, Accuracy: 19.63%\n",
            "Epoch: 6, Step: 107/655, Loss: 2.200039, Accuracy: 19.54%\n",
            "Epoch: 6, Step: 108/655, Loss: 2.200158, Accuracy: 19.50%\n",
            "Epoch: 6, Step: 109/655, Loss: 2.199699, Accuracy: 19.47%\n",
            "Epoch: 6, Step: 110/655, Loss: 2.199339, Accuracy: 19.46%\n",
            "Epoch: 6, Step: 111/655, Loss: 2.199132, Accuracy: 19.43%\n",
            "Epoch: 6, Step: 112/655, Loss: 2.200089, Accuracy: 19.42%\n",
            "Epoch: 6, Step: 113/655, Loss: 2.199551, Accuracy: 19.44%\n",
            "Epoch: 6, Step: 114/655, Loss: 2.200111, Accuracy: 19.44%\n",
            "Epoch: 6, Step: 115/655, Loss: 2.200149, Accuracy: 19.43%\n",
            "Epoch: 6, Step: 116/655, Loss: 2.199513, Accuracy: 19.45%\n",
            "Epoch: 6, Step: 117/655, Loss: 2.199281, Accuracy: 19.44%\n",
            "Epoch: 6, Step: 118/655, Loss: 2.198646, Accuracy: 19.47%\n",
            "Epoch: 6, Step: 119/655, Loss: 2.199156, Accuracy: 19.43%\n",
            "Epoch: 6, Step: 120/655, Loss: 2.199478, Accuracy: 19.38%\n",
            "Epoch: 6, Step: 121/655, Loss: 2.199615, Accuracy: 19.34%\n",
            "Epoch: 6, Step: 122/655, Loss: 2.199059, Accuracy: 19.49%\n",
            "Epoch: 6, Step: 123/655, Loss: 2.199325, Accuracy: 19.46%\n",
            "Epoch: 6, Step: 124/655, Loss: 2.199638, Accuracy: 19.41%\n",
            "Epoch: 6, Step: 125/655, Loss: 2.199192, Accuracy: 19.40%\n",
            "Epoch: 6, Step: 126/655, Loss: 2.198683, Accuracy: 19.42%\n",
            "Epoch: 6, Step: 127/655, Loss: 2.198102, Accuracy: 19.46%\n",
            "Epoch: 6, Step: 128/655, Loss: 2.197715, Accuracy: 19.43%\n",
            "Epoch: 6, Step: 129/655, Loss: 2.197665, Accuracy: 19.43%\n",
            "Epoch: 6, Step: 130/655, Loss: 2.198791, Accuracy: 19.40%\n",
            "Epoch: 6, Step: 131/655, Loss: 2.198757, Accuracy: 19.37%\n",
            "Epoch: 6, Step: 132/655, Loss: 2.197736, Accuracy: 19.39%\n",
            "Epoch: 6, Step: 133/655, Loss: 2.197488, Accuracy: 19.45%\n",
            "Epoch: 6, Step: 134/655, Loss: 2.198433, Accuracy: 19.40%\n",
            "Epoch: 6, Step: 135/655, Loss: 2.199541, Accuracy: 19.33%\n",
            "Epoch: 6, Step: 136/655, Loss: 2.200721, Accuracy: 19.30%\n",
            "Epoch: 6, Step: 137/655, Loss: 2.200834, Accuracy: 19.30%\n",
            "Epoch: 6, Step: 138/655, Loss: 2.200863, Accuracy: 19.29%\n",
            "Epoch: 6, Step: 139/655, Loss: 2.201229, Accuracy: 19.29%\n",
            "Epoch: 6, Step: 140/655, Loss: 2.201302, Accuracy: 19.35%\n",
            "Epoch: 6, Step: 141/655, Loss: 2.202112, Accuracy: 19.33%\n",
            "Epoch: 6, Step: 142/655, Loss: 2.202578, Accuracy: 19.41%\n",
            "Epoch: 6, Step: 143/655, Loss: 2.202475, Accuracy: 19.38%\n",
            "Epoch: 6, Step: 144/655, Loss: 2.202936, Accuracy: 19.31%\n",
            "Epoch: 6, Step: 145/655, Loss: 2.202855, Accuracy: 19.27%\n",
            "Epoch: 6, Step: 146/655, Loss: 2.203326, Accuracy: 19.20%\n",
            "Epoch: 6, Step: 147/655, Loss: 2.203895, Accuracy: 19.22%\n",
            "Epoch: 6, Step: 148/655, Loss: 2.203856, Accuracy: 19.21%\n",
            "Epoch: 6, Step: 149/655, Loss: 2.203593, Accuracy: 19.19%\n",
            "Epoch: 6, Step: 150/655, Loss: 2.203511, Accuracy: 19.23%\n",
            "Epoch: 6, Step: 151/655, Loss: 2.203649, Accuracy: 19.23%\n",
            "Epoch: 6, Step: 152/655, Loss: 2.204250, Accuracy: 19.20%\n",
            "Epoch: 6, Step: 153/655, Loss: 2.204234, Accuracy: 19.24%\n",
            "Epoch: 6, Step: 154/655, Loss: 2.203233, Accuracy: 19.32%\n",
            "Epoch: 6, Step: 155/655, Loss: 2.202770, Accuracy: 19.25%\n",
            "Epoch: 6, Step: 156/655, Loss: 2.203162, Accuracy: 19.27%\n",
            "Epoch: 6, Step: 157/655, Loss: 2.201877, Accuracy: 19.27%\n",
            "Epoch: 6, Step: 158/655, Loss: 2.201768, Accuracy: 19.24%\n",
            "Epoch: 6, Step: 159/655, Loss: 2.202185, Accuracy: 19.26%\n",
            "Epoch: 6, Step: 160/655, Loss: 2.201744, Accuracy: 19.24%\n",
            "Epoch: 6, Step: 161/655, Loss: 2.202131, Accuracy: 19.22%\n",
            "Epoch: 6, Step: 162/655, Loss: 2.201921, Accuracy: 19.21%\n",
            "Epoch: 6, Step: 163/655, Loss: 2.202237, Accuracy: 19.21%\n",
            "Epoch: 6, Step: 164/655, Loss: 2.202886, Accuracy: 19.17%\n",
            "Epoch: 6, Step: 165/655, Loss: 2.203189, Accuracy: 19.11%\n",
            "Epoch: 6, Step: 166/655, Loss: 2.203268, Accuracy: 19.16%\n",
            "Epoch: 6, Step: 167/655, Loss: 2.202415, Accuracy: 19.22%\n",
            "Epoch: 6, Step: 168/655, Loss: 2.202303, Accuracy: 19.27%\n",
            "Epoch: 6, Step: 169/655, Loss: 2.202409, Accuracy: 19.29%\n",
            "Epoch: 6, Step: 170/655, Loss: 2.202768, Accuracy: 19.28%\n",
            "Epoch: 6, Step: 171/655, Loss: 2.202405, Accuracy: 19.33%\n",
            "Epoch: 6, Step: 172/655, Loss: 2.202017, Accuracy: 19.40%\n",
            "Epoch: 6, Step: 173/655, Loss: 2.202254, Accuracy: 19.42%\n",
            "Epoch: 6, Step: 174/655, Loss: 2.202366, Accuracy: 19.41%\n",
            "Epoch: 6, Step: 175/655, Loss: 2.202537, Accuracy: 19.36%\n",
            "Epoch: 6, Step: 176/655, Loss: 2.202228, Accuracy: 19.41%\n",
            "Epoch: 6, Step: 177/655, Loss: 2.202121, Accuracy: 19.40%\n",
            "Epoch: 6, Step: 178/655, Loss: 2.202190, Accuracy: 19.40%\n",
            "Epoch: 6, Step: 179/655, Loss: 2.202340, Accuracy: 19.40%\n",
            "Epoch: 6, Step: 180/655, Loss: 2.201897, Accuracy: 19.36%\n",
            "Epoch: 6, Step: 181/655, Loss: 2.201754, Accuracy: 19.35%\n",
            "Epoch: 6, Step: 182/655, Loss: 2.202194, Accuracy: 19.32%\n",
            "Epoch: 6, Step: 183/655, Loss: 2.202459, Accuracy: 19.30%\n",
            "Epoch: 6, Step: 184/655, Loss: 2.202393, Accuracy: 19.29%\n",
            "Epoch: 6, Step: 185/655, Loss: 2.202577, Accuracy: 19.29%\n",
            "Epoch: 6, Step: 186/655, Loss: 2.202405, Accuracy: 19.24%\n",
            "Epoch: 6, Step: 187/655, Loss: 2.202467, Accuracy: 19.25%\n",
            "Epoch: 6, Step: 188/655, Loss: 2.202662, Accuracy: 19.25%\n",
            "Epoch: 6, Step: 189/655, Loss: 2.202198, Accuracy: 19.36%\n",
            "Epoch: 6, Step: 190/655, Loss: 2.202113, Accuracy: 19.31%\n",
            "Epoch: 6, Step: 191/655, Loss: 2.201999, Accuracy: 19.29%\n",
            "Epoch: 6, Step: 192/655, Loss: 2.202123, Accuracy: 19.29%\n",
            "Epoch: 6, Step: 193/655, Loss: 2.202809, Accuracy: 19.22%\n",
            "Epoch: 6, Step: 194/655, Loss: 2.203020, Accuracy: 19.23%\n",
            "Epoch: 6, Step: 195/655, Loss: 2.202775, Accuracy: 19.23%\n",
            "Epoch: 6, Step: 196/655, Loss: 2.203586, Accuracy: 19.18%\n",
            "Epoch: 6, Step: 197/655, Loss: 2.203457, Accuracy: 19.13%\n",
            "Epoch: 6, Step: 198/655, Loss: 2.203173, Accuracy: 19.16%\n",
            "Epoch: 6, Step: 199/655, Loss: 2.203330, Accuracy: 19.13%\n",
            "Epoch: 6, Step: 200/655, Loss: 2.203101, Accuracy: 19.14%\n",
            "Epoch: 6, Step: 201/655, Loss: 2.202436, Accuracy: 19.19%\n",
            "Epoch: 6, Step: 202/655, Loss: 2.201895, Accuracy: 19.25%\n",
            "Epoch: 6, Step: 203/655, Loss: 2.201511, Accuracy: 19.26%\n",
            "Epoch: 6, Step: 204/655, Loss: 2.201855, Accuracy: 19.24%\n",
            "Epoch: 6, Step: 205/655, Loss: 2.202082, Accuracy: 19.18%\n",
            "Epoch: 6, Step: 206/655, Loss: 2.202131, Accuracy: 19.21%\n",
            "Epoch: 6, Step: 207/655, Loss: 2.202908, Accuracy: 19.13%\n",
            "Epoch: 6, Step: 208/655, Loss: 2.202768, Accuracy: 19.11%\n",
            "Epoch: 6, Step: 209/655, Loss: 2.203399, Accuracy: 19.08%\n",
            "Epoch: 6, Step: 210/655, Loss: 2.203442, Accuracy: 19.08%\n",
            "Epoch: 6, Step: 211/655, Loss: 2.203947, Accuracy: 19.08%\n",
            "Epoch: 6, Step: 212/655, Loss: 2.203360, Accuracy: 19.07%\n",
            "Epoch: 6, Step: 213/655, Loss: 2.203343, Accuracy: 19.07%\n",
            "Epoch: 6, Step: 214/655, Loss: 2.202702, Accuracy: 19.14%\n",
            "Epoch: 6, Step: 215/655, Loss: 2.202446, Accuracy: 19.16%\n",
            "Epoch: 6, Step: 216/655, Loss: 2.202529, Accuracy: 19.18%\n",
            "Epoch: 6, Step: 217/655, Loss: 2.203065, Accuracy: 19.15%\n",
            "Epoch: 6, Step: 218/655, Loss: 2.202993, Accuracy: 19.17%\n",
            "Epoch: 6, Step: 219/655, Loss: 2.202722, Accuracy: 19.15%\n",
            "Epoch: 6, Step: 220/655, Loss: 2.203179, Accuracy: 19.15%\n",
            "Epoch: 6, Step: 221/655, Loss: 2.203342, Accuracy: 19.10%\n",
            "Epoch: 6, Step: 222/655, Loss: 2.203126, Accuracy: 19.12%\n",
            "Epoch: 6, Step: 223/655, Loss: 2.203046, Accuracy: 19.09%\n",
            "Epoch: 6, Step: 224/655, Loss: 2.202618, Accuracy: 19.10%\n",
            "Epoch: 6, Step: 225/655, Loss: 2.202494, Accuracy: 19.11%\n",
            "Epoch: 6, Step: 226/655, Loss: 2.202765, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 227/655, Loss: 2.203439, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 228/655, Loss: 2.204609, Accuracy: 18.97%\n",
            "Epoch: 6, Step: 229/655, Loss: 2.204394, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 230/655, Loss: 2.204546, Accuracy: 18.98%\n",
            "Epoch: 6, Step: 231/655, Loss: 2.204966, Accuracy: 18.98%\n",
            "Epoch: 6, Step: 232/655, Loss: 2.204706, Accuracy: 18.97%\n",
            "Epoch: 6, Step: 233/655, Loss: 2.205203, Accuracy: 18.91%\n",
            "Epoch: 6, Step: 234/655, Loss: 2.205330, Accuracy: 18.98%\n",
            "Epoch: 6, Step: 235/655, Loss: 2.204331, Accuracy: 19.04%\n",
            "Epoch: 6, Step: 236/655, Loss: 2.204432, Accuracy: 19.04%\n",
            "Epoch: 6, Step: 237/655, Loss: 2.204851, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 238/655, Loss: 2.205041, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 239/655, Loss: 2.205368, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 240/655, Loss: 2.205272, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 241/655, Loss: 2.205238, Accuracy: 19.02%\n",
            "Epoch: 6, Step: 242/655, Loss: 2.204731, Accuracy: 19.10%\n",
            "Epoch: 6, Step: 243/655, Loss: 2.204481, Accuracy: 19.10%\n",
            "Epoch: 6, Step: 244/655, Loss: 2.204068, Accuracy: 19.12%\n",
            "Epoch: 6, Step: 245/655, Loss: 2.203950, Accuracy: 19.15%\n",
            "Epoch: 6, Step: 246/655, Loss: 2.203860, Accuracy: 19.13%\n",
            "Epoch: 6, Step: 247/655, Loss: 2.203841, Accuracy: 19.13%\n",
            "Epoch: 6, Step: 248/655, Loss: 2.204115, Accuracy: 19.12%\n",
            "Epoch: 6, Step: 249/655, Loss: 2.203642, Accuracy: 19.14%\n",
            "Epoch: 6, Step: 250/655, Loss: 2.204290, Accuracy: 19.09%\n",
            "Epoch: 6, Step: 251/655, Loss: 2.204100, Accuracy: 19.09%\n",
            "Epoch: 6, Step: 252/655, Loss: 2.204317, Accuracy: 19.08%\n",
            "Epoch: 6, Step: 253/655, Loss: 2.204365, Accuracy: 19.08%\n",
            "Epoch: 6, Step: 254/655, Loss: 2.204390, Accuracy: 19.07%\n",
            "Epoch: 6, Step: 255/655, Loss: 2.204752, Accuracy: 19.06%\n",
            "Epoch: 6, Step: 256/655, Loss: 2.204480, Accuracy: 19.06%\n",
            "Epoch: 6, Step: 257/655, Loss: 2.204527, Accuracy: 19.07%\n",
            "Epoch: 6, Step: 258/655, Loss: 2.205035, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 259/655, Loss: 2.205181, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 260/655, Loss: 2.205307, Accuracy: 19.06%\n",
            "Epoch: 6, Step: 261/655, Loss: 2.205096, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 262/655, Loss: 2.205301, Accuracy: 19.02%\n",
            "Epoch: 6, Step: 263/655, Loss: 2.205401, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 264/655, Loss: 2.205118, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 265/655, Loss: 2.205528, Accuracy: 18.96%\n",
            "Epoch: 6, Step: 266/655, Loss: 2.205170, Accuracy: 18.96%\n",
            "Epoch: 6, Step: 267/655, Loss: 2.205118, Accuracy: 18.94%\n",
            "Epoch: 6, Step: 268/655, Loss: 2.205243, Accuracy: 18.92%\n",
            "Epoch: 6, Step: 269/655, Loss: 2.205747, Accuracy: 18.92%\n",
            "Epoch: 6, Step: 270/655, Loss: 2.205571, Accuracy: 18.91%\n",
            "Epoch: 6, Step: 271/655, Loss: 2.205796, Accuracy: 18.92%\n",
            "Epoch: 6, Step: 272/655, Loss: 2.205405, Accuracy: 18.96%\n",
            "Epoch: 6, Step: 273/655, Loss: 2.205381, Accuracy: 18.98%\n",
            "Epoch: 6, Step: 274/655, Loss: 2.204963, Accuracy: 19.04%\n",
            "Epoch: 6, Step: 275/655, Loss: 2.205110, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 276/655, Loss: 2.204939, Accuracy: 18.98%\n",
            "Epoch: 6, Step: 277/655, Loss: 2.205115, Accuracy: 18.95%\n",
            "Epoch: 6, Step: 278/655, Loss: 2.205187, Accuracy: 18.94%\n",
            "Epoch: 6, Step: 279/655, Loss: 2.204806, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 280/655, Loss: 2.204500, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 281/655, Loss: 2.204812, Accuracy: 18.95%\n",
            "Epoch: 6, Step: 282/655, Loss: 2.205050, Accuracy: 18.96%\n",
            "Epoch: 6, Step: 283/655, Loss: 2.205152, Accuracy: 18.97%\n",
            "Epoch: 6, Step: 284/655, Loss: 2.204822, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 285/655, Loss: 2.205084, Accuracy: 18.98%\n",
            "Epoch: 6, Step: 286/655, Loss: 2.204979, Accuracy: 18.96%\n",
            "Epoch: 6, Step: 287/655, Loss: 2.204740, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 288/655, Loss: 2.204712, Accuracy: 19.02%\n",
            "Epoch: 6, Step: 289/655, Loss: 2.204479, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 290/655, Loss: 2.204638, Accuracy: 19.04%\n",
            "Epoch: 6, Step: 291/655, Loss: 2.204648, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 292/655, Loss: 2.204723, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 293/655, Loss: 2.204695, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 294/655, Loss: 2.204818, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 295/655, Loss: 2.204955, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 296/655, Loss: 2.204804, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 297/655, Loss: 2.204969, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 298/655, Loss: 2.204669, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 299/655, Loss: 2.204724, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 300/655, Loss: 2.204846, Accuracy: 19.02%\n",
            "Epoch: 6, Step: 301/655, Loss: 2.205078, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 302/655, Loss: 2.204966, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 303/655, Loss: 2.205329, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 304/655, Loss: 2.205751, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 305/655, Loss: 2.205749, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 306/655, Loss: 2.205827, Accuracy: 19.04%\n",
            "Epoch: 6, Step: 307/655, Loss: 2.205664, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 308/655, Loss: 2.205471, Accuracy: 19.04%\n",
            "Epoch: 6, Step: 309/655, Loss: 2.205585, Accuracy: 19.04%\n",
            "Epoch: 6, Step: 310/655, Loss: 2.205395, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 311/655, Loss: 2.205398, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 312/655, Loss: 2.205258, Accuracy: 19.04%\n",
            "Epoch: 6, Step: 313/655, Loss: 2.205292, Accuracy: 19.06%\n",
            "Epoch: 6, Step: 314/655, Loss: 2.205490, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 315/655, Loss: 2.205279, Accuracy: 19.04%\n",
            "Epoch: 6, Step: 316/655, Loss: 2.204702, Accuracy: 19.08%\n",
            "Epoch: 6, Step: 317/655, Loss: 2.205261, Accuracy: 19.07%\n",
            "Epoch: 6, Step: 318/655, Loss: 2.205218, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 319/655, Loss: 2.205187, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 320/655, Loss: 2.205618, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 321/655, Loss: 2.205338, Accuracy: 19.06%\n",
            "Epoch: 6, Step: 322/655, Loss: 2.205103, Accuracy: 19.07%\n",
            "Epoch: 6, Step: 323/655, Loss: 2.204985, Accuracy: 19.07%\n",
            "Epoch: 6, Step: 324/655, Loss: 2.204779, Accuracy: 19.09%\n",
            "Epoch: 6, Step: 325/655, Loss: 2.204856, Accuracy: 19.12%\n",
            "Epoch: 6, Step: 326/655, Loss: 2.205042, Accuracy: 19.08%\n",
            "Epoch: 6, Step: 327/655, Loss: 2.205015, Accuracy: 19.06%\n",
            "Epoch: 6, Step: 328/655, Loss: 2.205197, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 329/655, Loss: 2.205429, Accuracy: 19.04%\n",
            "Epoch: 6, Step: 330/655, Loss: 2.205364, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 331/655, Loss: 2.205419, Accuracy: 19.02%\n",
            "Epoch: 6, Step: 332/655, Loss: 2.205424, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 333/655, Loss: 2.205538, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 334/655, Loss: 2.205555, Accuracy: 18.97%\n",
            "Epoch: 6, Step: 335/655, Loss: 2.206021, Accuracy: 18.93%\n",
            "Epoch: 6, Step: 336/655, Loss: 2.205935, Accuracy: 18.94%\n",
            "Epoch: 6, Step: 337/655, Loss: 2.205827, Accuracy: 18.92%\n",
            "Epoch: 6, Step: 338/655, Loss: 2.205881, Accuracy: 18.92%\n",
            "Epoch: 6, Step: 339/655, Loss: 2.205590, Accuracy: 18.93%\n",
            "Epoch: 6, Step: 340/655, Loss: 2.205334, Accuracy: 18.92%\n",
            "Epoch: 6, Step: 341/655, Loss: 2.205398, Accuracy: 18.94%\n",
            "Epoch: 6, Step: 342/655, Loss: 2.205024, Accuracy: 18.97%\n",
            "Epoch: 6, Step: 343/655, Loss: 2.204775, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 344/655, Loss: 2.204905, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 345/655, Loss: 2.204829, Accuracy: 19.02%\n",
            "Epoch: 6, Step: 346/655, Loss: 2.205122, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 347/655, Loss: 2.205131, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 348/655, Loss: 2.205152, Accuracy: 19.02%\n",
            "Epoch: 6, Step: 349/655, Loss: 2.205087, Accuracy: 19.02%\n",
            "Epoch: 6, Step: 350/655, Loss: 2.205328, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 351/655, Loss: 2.205028, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 352/655, Loss: 2.204685, Accuracy: 19.04%\n",
            "Epoch: 6, Step: 353/655, Loss: 2.204982, Accuracy: 19.02%\n",
            "Epoch: 6, Step: 354/655, Loss: 2.205020, Accuracy: 19.02%\n",
            "Epoch: 6, Step: 355/655, Loss: 2.205057, Accuracy: 19.02%\n",
            "Epoch: 6, Step: 356/655, Loss: 2.204842, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 357/655, Loss: 2.204833, Accuracy: 19.07%\n",
            "Epoch: 6, Step: 358/655, Loss: 2.205049, Accuracy: 19.06%\n",
            "Epoch: 6, Step: 359/655, Loss: 2.205331, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 360/655, Loss: 2.205319, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 361/655, Loss: 2.205175, Accuracy: 19.04%\n",
            "Epoch: 6, Step: 362/655, Loss: 2.205261, Accuracy: 19.04%\n",
            "Epoch: 6, Step: 363/655, Loss: 2.205161, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 364/655, Loss: 2.205059, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 365/655, Loss: 2.204994, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 366/655, Loss: 2.204971, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 367/655, Loss: 2.205250, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 368/655, Loss: 2.205257, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 369/655, Loss: 2.205615, Accuracy: 18.96%\n",
            "Epoch: 6, Step: 370/655, Loss: 2.206163, Accuracy: 18.94%\n",
            "Epoch: 6, Step: 371/655, Loss: 2.206484, Accuracy: 18.92%\n",
            "Epoch: 6, Step: 372/655, Loss: 2.206518, Accuracy: 18.91%\n",
            "Epoch: 6, Step: 373/655, Loss: 2.206638, Accuracy: 18.89%\n",
            "Epoch: 6, Step: 374/655, Loss: 2.206814, Accuracy: 18.89%\n",
            "Epoch: 6, Step: 375/655, Loss: 2.206776, Accuracy: 18.91%\n",
            "Epoch: 6, Step: 376/655, Loss: 2.206759, Accuracy: 18.92%\n",
            "Epoch: 6, Step: 377/655, Loss: 2.206678, Accuracy: 18.94%\n",
            "Epoch: 6, Step: 378/655, Loss: 2.206254, Accuracy: 18.96%\n",
            "Epoch: 6, Step: 379/655, Loss: 2.206576, Accuracy: 18.94%\n",
            "Epoch: 6, Step: 380/655, Loss: 2.206337, Accuracy: 18.91%\n",
            "Epoch: 6, Step: 381/655, Loss: 2.206107, Accuracy: 18.94%\n",
            "Epoch: 6, Step: 382/655, Loss: 2.206007, Accuracy: 18.97%\n",
            "Epoch: 6, Step: 383/655, Loss: 2.206018, Accuracy: 18.97%\n",
            "Epoch: 6, Step: 384/655, Loss: 2.205866, Accuracy: 18.97%\n",
            "Epoch: 6, Step: 385/655, Loss: 2.205808, Accuracy: 18.98%\n",
            "Epoch: 6, Step: 386/655, Loss: 2.205791, Accuracy: 18.98%\n",
            "Epoch: 6, Step: 387/655, Loss: 2.205659, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 388/655, Loss: 2.205522, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 389/655, Loss: 2.205447, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 390/655, Loss: 2.205885, Accuracy: 18.97%\n",
            "Epoch: 6, Step: 391/655, Loss: 2.205831, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 392/655, Loss: 2.206105, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 393/655, Loss: 2.206369, Accuracy: 18.96%\n",
            "Epoch: 6, Step: 394/655, Loss: 2.206020, Accuracy: 19.04%\n",
            "Epoch: 6, Step: 395/655, Loss: 2.205999, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 396/655, Loss: 2.205834, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 397/655, Loss: 2.205847, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 398/655, Loss: 2.205639, Accuracy: 19.02%\n",
            "Epoch: 6, Step: 399/655, Loss: 2.205428, Accuracy: 19.02%\n",
            "Epoch: 6, Step: 400/655, Loss: 2.205553, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 401/655, Loss: 2.205588, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 402/655, Loss: 2.205363, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 403/655, Loss: 2.205179, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 404/655, Loss: 2.205127, Accuracy: 19.07%\n",
            "Epoch: 6, Step: 405/655, Loss: 2.205140, Accuracy: 19.09%\n",
            "Epoch: 6, Step: 406/655, Loss: 2.205381, Accuracy: 19.07%\n",
            "Epoch: 6, Step: 407/655, Loss: 2.205618, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 408/655, Loss: 2.205137, Accuracy: 19.08%\n",
            "Epoch: 6, Step: 409/655, Loss: 2.205129, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 410/655, Loss: 2.204834, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 411/655, Loss: 2.204606, Accuracy: 19.05%\n",
            "Epoch: 6, Step: 412/655, Loss: 2.204857, Accuracy: 19.04%\n",
            "Epoch: 6, Step: 413/655, Loss: 2.204776, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 414/655, Loss: 2.205009, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 415/655, Loss: 2.205136, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 416/655, Loss: 2.205293, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 417/655, Loss: 2.205167, Accuracy: 19.03%\n",
            "Epoch: 6, Step: 418/655, Loss: 2.205313, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 419/655, Loss: 2.205398, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 420/655, Loss: 2.205388, Accuracy: 19.02%\n",
            "Epoch: 6, Step: 421/655, Loss: 2.205171, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 422/655, Loss: 2.205410, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 423/655, Loss: 2.205652, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 424/655, Loss: 2.205438, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 425/655, Loss: 2.205600, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 426/655, Loss: 2.205708, Accuracy: 18.97%\n",
            "Epoch: 6, Step: 427/655, Loss: 2.205950, Accuracy: 18.97%\n",
            "Epoch: 6, Step: 428/655, Loss: 2.205970, Accuracy: 18.97%\n",
            "Epoch: 6, Step: 429/655, Loss: 2.205726, Accuracy: 18.96%\n",
            "Epoch: 6, Step: 430/655, Loss: 2.205596, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 431/655, Loss: 2.206028, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 432/655, Loss: 2.205909, Accuracy: 18.98%\n",
            "Epoch: 6, Step: 433/655, Loss: 2.205701, Accuracy: 18.97%\n",
            "Epoch: 6, Step: 434/655, Loss: 2.205368, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 435/655, Loss: 2.205320, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 436/655, Loss: 2.205496, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 437/655, Loss: 2.205794, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 438/655, Loss: 2.205781, Accuracy: 18.97%\n",
            "Epoch: 6, Step: 439/655, Loss: 2.205955, Accuracy: 18.95%\n",
            "Epoch: 6, Step: 440/655, Loss: 2.205864, Accuracy: 18.96%\n",
            "Epoch: 6, Step: 441/655, Loss: 2.205941, Accuracy: 18.96%\n",
            "Epoch: 6, Step: 442/655, Loss: 2.205780, Accuracy: 18.98%\n",
            "Epoch: 6, Step: 443/655, Loss: 2.205597, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 444/655, Loss: 2.205596, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 445/655, Loss: 2.205444, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 446/655, Loss: 2.205545, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 447/655, Loss: 2.205468, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 448/655, Loss: 2.205321, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 449/655, Loss: 2.205790, Accuracy: 18.98%\n",
            "Epoch: 6, Step: 450/655, Loss: 2.205881, Accuracy: 18.97%\n",
            "Epoch: 6, Step: 451/655, Loss: 2.205535, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 452/655, Loss: 2.205423, Accuracy: 19.01%\n",
            "Epoch: 6, Step: 453/655, Loss: 2.205352, Accuracy: 18.98%\n",
            "Epoch: 6, Step: 454/655, Loss: 2.205425, Accuracy: 18.98%\n",
            "Epoch: 6, Step: 455/655, Loss: 2.205436, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 456/655, Loss: 2.205614, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 457/655, Loss: 2.205797, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 458/655, Loss: 2.205672, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 459/655, Loss: 2.205713, Accuracy: 19.00%\n",
            "Epoch: 6, Step: 460/655, Loss: 2.205861, Accuracy: 18.99%\n",
            "Epoch: 6, Step: 461/655, Loss: 2.206058, Accuracy: 18.96%\n",
            "Epoch: 6, Step: 462/655, Loss: 2.206210, Accuracy: 18.93%\n",
            "Epoch: 6, Step: 463/655, Loss: 2.206131, Accuracy: 18.94%\n",
            "Epoch: 6, Step: 464/655, Loss: 2.206080, Accuracy: 18.95%\n",
            "Epoch: 6, Step: 465/655, Loss: 2.206181, Accuracy: 18.95%\n",
            "Epoch: 6, Step: 466/655, Loss: 2.206030, Accuracy: 18.94%\n",
            "Epoch: 6, Step: 467/655, Loss: 2.205961, Accuracy: 18.94%\n",
            "Epoch: 6, Step: 468/655, Loss: 2.205708, Accuracy: 18.95%\n",
            "Epoch: 6, Step: 469/655, Loss: 2.205796, Accuracy: 18.94%\n",
            "Epoch: 6, Step: 470/655, Loss: 2.205861, Accuracy: 18.94%\n",
            "Epoch: 6, Step: 471/655, Loss: 2.206058, Accuracy: 18.94%\n",
            "Epoch: 6, Step: 472/655, Loss: 2.206073, Accuracy: 18.95%\n",
            "Epoch: 6, Step: 473/655, Loss: 2.206343, Accuracy: 18.93%\n",
            "Epoch: 6, Step: 474/655, Loss: 2.206369, Accuracy: 18.93%\n",
            "Epoch: 6, Step: 475/655, Loss: 2.206620, Accuracy: 18.89%\n",
            "Epoch: 6, Step: 476/655, Loss: 2.206737, Accuracy: 18.87%\n",
            "Epoch: 6, Step: 477/655, Loss: 2.206795, Accuracy: 18.87%\n",
            "Epoch: 6, Step: 478/655, Loss: 2.206860, Accuracy: 18.85%\n",
            "Epoch: 6, Step: 479/655, Loss: 2.206625, Accuracy: 18.87%\n",
            "Epoch: 6, Step: 480/655, Loss: 2.207091, Accuracy: 18.83%\n",
            "Epoch: 6, Step: 481/655, Loss: 2.207468, Accuracy: 18.81%\n",
            "Epoch: 6, Step: 482/655, Loss: 2.207127, Accuracy: 18.83%\n",
            "Epoch: 6, Step: 483/655, Loss: 2.207010, Accuracy: 18.81%\n",
            "Epoch: 6, Step: 484/655, Loss: 2.206965, Accuracy: 18.81%\n",
            "Epoch: 6, Step: 485/655, Loss: 2.207153, Accuracy: 18.81%\n",
            "Epoch: 6, Step: 486/655, Loss: 2.207253, Accuracy: 18.80%\n",
            "Epoch: 6, Step: 487/655, Loss: 2.207180, Accuracy: 18.82%\n",
            "Epoch: 6, Step: 488/655, Loss: 2.207072, Accuracy: 18.83%\n",
            "Epoch: 6, Step: 489/655, Loss: 2.207392, Accuracy: 18.80%\n",
            "Epoch: 6, Step: 490/655, Loss: 2.207394, Accuracy: 18.84%\n",
            "Epoch: 6, Step: 491/655, Loss: 2.207552, Accuracy: 18.84%\n",
            "Epoch: 6, Step: 492/655, Loss: 2.207433, Accuracy: 18.85%\n",
            "Epoch: 6, Step: 493/655, Loss: 2.207384, Accuracy: 18.86%\n",
            "Epoch: 6, Step: 494/655, Loss: 2.207631, Accuracy: 18.84%\n",
            "Epoch: 6, Step: 495/655, Loss: 2.207848, Accuracy: 18.83%\n",
            "Epoch: 6, Step: 496/655, Loss: 2.208115, Accuracy: 18.81%\n",
            "Epoch: 6, Step: 497/655, Loss: 2.207897, Accuracy: 18.81%\n",
            "Epoch: 6, Step: 498/655, Loss: 2.208047, Accuracy: 18.80%\n",
            "Epoch: 6, Step: 499/655, Loss: 2.207888, Accuracy: 18.78%\n",
            "Epoch: 6, Step: 500/655, Loss: 2.207774, Accuracy: 18.78%\n",
            "Epoch: 6, Step: 501/655, Loss: 2.207539, Accuracy: 18.78%\n",
            "Epoch: 6, Step: 502/655, Loss: 2.207793, Accuracy: 18.76%\n",
            "Epoch: 6, Step: 503/655, Loss: 2.207776, Accuracy: 18.77%\n",
            "Epoch: 6, Step: 504/655, Loss: 2.207629, Accuracy: 18.77%\n",
            "Epoch: 6, Step: 505/655, Loss: 2.207811, Accuracy: 18.77%\n",
            "Epoch: 6, Step: 506/655, Loss: 2.207872, Accuracy: 18.78%\n",
            "Epoch: 6, Step: 507/655, Loss: 2.208029, Accuracy: 18.76%\n",
            "Epoch: 6, Step: 508/655, Loss: 2.208103, Accuracy: 18.74%\n",
            "Epoch: 6, Step: 509/655, Loss: 2.208095, Accuracy: 18.74%\n",
            "Epoch: 6, Step: 510/655, Loss: 2.208099, Accuracy: 18.74%\n",
            "Epoch: 6, Step: 511/655, Loss: 2.208210, Accuracy: 18.74%\n",
            "Epoch: 6, Step: 512/655, Loss: 2.208030, Accuracy: 18.72%\n",
            "Epoch: 6, Step: 513/655, Loss: 2.208147, Accuracy: 18.71%\n",
            "Epoch: 6, Step: 514/655, Loss: 2.208044, Accuracy: 18.70%\n",
            "Epoch: 6, Step: 515/655, Loss: 2.207842, Accuracy: 18.71%\n",
            "Epoch: 6, Step: 516/655, Loss: 2.207799, Accuracy: 18.69%\n",
            "Epoch: 6, Step: 517/655, Loss: 2.207938, Accuracy: 18.70%\n",
            "Epoch: 6, Step: 518/655, Loss: 2.208076, Accuracy: 18.70%\n",
            "Epoch: 6, Step: 519/655, Loss: 2.207882, Accuracy: 18.69%\n",
            "Epoch: 6, Step: 520/655, Loss: 2.208035, Accuracy: 18.66%\n",
            "Epoch: 6, Step: 521/655, Loss: 2.207919, Accuracy: 18.67%\n",
            "Epoch: 6, Step: 522/655, Loss: 2.207975, Accuracy: 18.66%\n",
            "Epoch: 6, Step: 523/655, Loss: 2.207719, Accuracy: 18.67%\n",
            "Epoch: 6, Step: 524/655, Loss: 2.207668, Accuracy: 18.67%\n",
            "Epoch: 6, Step: 525/655, Loss: 2.207743, Accuracy: 18.68%\n",
            "Epoch: 6, Step: 526/655, Loss: 2.207728, Accuracy: 18.70%\n",
            "Epoch: 6, Step: 527/655, Loss: 2.207707, Accuracy: 18.70%\n",
            "Epoch: 6, Step: 528/655, Loss: 2.207797, Accuracy: 18.69%\n",
            "Epoch: 6, Step: 529/655, Loss: 2.207689, Accuracy: 18.69%\n",
            "Epoch: 6, Step: 530/655, Loss: 2.207686, Accuracy: 18.69%\n",
            "Epoch: 6, Step: 531/655, Loss: 2.207753, Accuracy: 18.69%\n",
            "Epoch: 6, Step: 532/655, Loss: 2.207961, Accuracy: 18.68%\n",
            "Epoch: 6, Step: 533/655, Loss: 2.207988, Accuracy: 18.69%\n",
            "Epoch: 6, Step: 534/655, Loss: 2.207851, Accuracy: 18.70%\n",
            "Epoch: 6, Step: 535/655, Loss: 2.207930, Accuracy: 18.70%\n",
            "Epoch: 6, Step: 536/655, Loss: 2.207784, Accuracy: 18.69%\n",
            "Epoch: 6, Step: 537/655, Loss: 2.207903, Accuracy: 18.67%\n",
            "Epoch: 6, Step: 538/655, Loss: 2.207846, Accuracy: 18.66%\n",
            "Epoch: 6, Step: 539/655, Loss: 2.207819, Accuracy: 18.65%\n",
            "Epoch: 6, Step: 540/655, Loss: 2.208115, Accuracy: 18.63%\n",
            "Epoch: 6, Step: 541/655, Loss: 2.208368, Accuracy: 18.63%\n",
            "Epoch: 6, Step: 542/655, Loss: 2.208423, Accuracy: 18.63%\n",
            "Epoch: 6, Step: 543/655, Loss: 2.208361, Accuracy: 18.63%\n",
            "Epoch: 6, Step: 544/655, Loss: 2.208179, Accuracy: 18.66%\n",
            "Epoch: 6, Step: 545/655, Loss: 2.207960, Accuracy: 18.67%\n",
            "Epoch: 6, Step: 546/655, Loss: 2.207904, Accuracy: 18.68%\n",
            "Epoch: 6, Step: 547/655, Loss: 2.207872, Accuracy: 18.67%\n",
            "Epoch: 6, Step: 548/655, Loss: 2.207992, Accuracy: 18.66%\n",
            "Epoch: 6, Step: 549/655, Loss: 2.208107, Accuracy: 18.64%\n",
            "Epoch: 6, Step: 550/655, Loss: 2.207999, Accuracy: 18.64%\n",
            "Epoch: 6, Step: 551/655, Loss: 2.208046, Accuracy: 18.63%\n",
            "Epoch: 6, Step: 552/655, Loss: 2.207974, Accuracy: 18.63%\n",
            "Epoch: 6, Step: 553/655, Loss: 2.208143, Accuracy: 18.61%\n",
            "Epoch: 6, Step: 554/655, Loss: 2.208076, Accuracy: 18.62%\n",
            "Epoch: 6, Step: 555/655, Loss: 2.208008, Accuracy: 18.62%\n",
            "Epoch: 6, Step: 556/655, Loss: 2.207899, Accuracy: 18.63%\n",
            "Epoch: 6, Step: 557/655, Loss: 2.208006, Accuracy: 18.62%\n",
            "Epoch: 6, Step: 558/655, Loss: 2.208108, Accuracy: 18.62%\n",
            "Epoch: 6, Step: 559/655, Loss: 2.208003, Accuracy: 18.62%\n",
            "Epoch: 6, Step: 560/655, Loss: 2.207958, Accuracy: 18.63%\n",
            "Epoch: 6, Step: 561/655, Loss: 2.207999, Accuracy: 18.62%\n",
            "Epoch: 6, Step: 562/655, Loss: 2.208038, Accuracy: 18.61%\n",
            "Epoch: 6, Step: 563/655, Loss: 2.207843, Accuracy: 18.61%\n",
            "Epoch: 6, Step: 564/655, Loss: 2.207730, Accuracy: 18.62%\n",
            "Epoch: 6, Step: 565/655, Loss: 2.207609, Accuracy: 18.62%\n",
            "Epoch: 6, Step: 566/655, Loss: 2.207678, Accuracy: 18.61%\n",
            "Epoch: 6, Step: 567/655, Loss: 2.207662, Accuracy: 18.62%\n",
            "Epoch: 6, Step: 568/655, Loss: 2.207648, Accuracy: 18.62%\n",
            "Epoch: 6, Step: 569/655, Loss: 2.207631, Accuracy: 18.60%\n",
            "Epoch: 6, Step: 570/655, Loss: 2.207316, Accuracy: 18.63%\n",
            "Epoch: 6, Step: 571/655, Loss: 2.207400, Accuracy: 18.63%\n",
            "Epoch: 6, Step: 572/655, Loss: 2.207513, Accuracy: 18.60%\n",
            "Epoch: 6, Step: 573/655, Loss: 2.207355, Accuracy: 18.61%\n",
            "Epoch: 6, Step: 574/655, Loss: 2.207559, Accuracy: 18.59%\n",
            "Epoch: 6, Step: 575/655, Loss: 2.207722, Accuracy: 18.58%\n",
            "Epoch: 6, Step: 576/655, Loss: 2.207924, Accuracy: 18.57%\n",
            "Epoch: 6, Step: 577/655, Loss: 2.207730, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 578/655, Loss: 2.207830, Accuracy: 18.53%\n",
            "Epoch: 6, Step: 579/655, Loss: 2.207734, Accuracy: 18.52%\n",
            "Epoch: 6, Step: 580/655, Loss: 2.207574, Accuracy: 18.53%\n",
            "Epoch: 6, Step: 581/655, Loss: 2.207551, Accuracy: 18.53%\n",
            "Epoch: 6, Step: 582/655, Loss: 2.207632, Accuracy: 18.53%\n",
            "Epoch: 6, Step: 583/655, Loss: 2.207740, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 584/655, Loss: 2.207850, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 585/655, Loss: 2.208020, Accuracy: 18.53%\n",
            "Epoch: 6, Step: 586/655, Loss: 2.207976, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 587/655, Loss: 2.207956, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 588/655, Loss: 2.207717, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 589/655, Loss: 2.207851, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 590/655, Loss: 2.207880, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 591/655, Loss: 2.207928, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 592/655, Loss: 2.207856, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 593/655, Loss: 2.207769, Accuracy: 18.56%\n",
            "Epoch: 6, Step: 594/655, Loss: 2.207710, Accuracy: 18.56%\n",
            "Epoch: 6, Step: 595/655, Loss: 2.207597, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 596/655, Loss: 2.207497, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 597/655, Loss: 2.207593, Accuracy: 18.52%\n",
            "Epoch: 6, Step: 598/655, Loss: 2.207446, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 599/655, Loss: 2.207461, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 600/655, Loss: 2.207374, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 601/655, Loss: 2.207479, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 602/655, Loss: 2.207526, Accuracy: 18.56%\n",
            "Epoch: 6, Step: 603/655, Loss: 2.207358, Accuracy: 18.57%\n",
            "Epoch: 6, Step: 604/655, Loss: 2.207311, Accuracy: 18.56%\n",
            "Epoch: 6, Step: 605/655, Loss: 2.207185, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 606/655, Loss: 2.207187, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 607/655, Loss: 2.207136, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 608/655, Loss: 2.207187, Accuracy: 18.52%\n",
            "Epoch: 6, Step: 609/655, Loss: 2.207206, Accuracy: 18.53%\n",
            "Epoch: 6, Step: 610/655, Loss: 2.207138, Accuracy: 18.52%\n",
            "Epoch: 6, Step: 611/655, Loss: 2.207261, Accuracy: 18.52%\n",
            "Epoch: 6, Step: 612/655, Loss: 2.207318, Accuracy: 18.52%\n",
            "Epoch: 6, Step: 613/655, Loss: 2.207428, Accuracy: 18.52%\n",
            "Epoch: 6, Step: 614/655, Loss: 2.207485, Accuracy: 18.50%\n",
            "Epoch: 6, Step: 615/655, Loss: 2.207445, Accuracy: 18.51%\n",
            "Epoch: 6, Step: 616/655, Loss: 2.207066, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 617/655, Loss: 2.207264, Accuracy: 18.53%\n",
            "Epoch: 6, Step: 618/655, Loss: 2.207488, Accuracy: 18.53%\n",
            "Epoch: 6, Step: 619/655, Loss: 2.207774, Accuracy: 18.52%\n",
            "Epoch: 6, Step: 620/655, Loss: 2.207748, Accuracy: 18.51%\n",
            "Epoch: 6, Step: 621/655, Loss: 2.207651, Accuracy: 18.53%\n",
            "Epoch: 6, Step: 622/655, Loss: 2.207526, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 623/655, Loss: 2.207516, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 624/655, Loss: 2.207533, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 625/655, Loss: 2.207549, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 626/655, Loss: 2.207679, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 627/655, Loss: 2.207586, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 628/655, Loss: 2.207478, Accuracy: 18.56%\n",
            "Epoch: 6, Step: 629/655, Loss: 2.207545, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 630/655, Loss: 2.207538, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 631/655, Loss: 2.207822, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 632/655, Loss: 2.207706, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 633/655, Loss: 2.207738, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 634/655, Loss: 2.207559, Accuracy: 18.56%\n",
            "Epoch: 6, Step: 635/655, Loss: 2.207727, Accuracy: 18.56%\n",
            "Epoch: 6, Step: 636/655, Loss: 2.207610, Accuracy: 18.56%\n",
            "Epoch: 6, Step: 637/655, Loss: 2.207593, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 638/655, Loss: 2.207707, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 639/655, Loss: 2.207878, Accuracy: 18.53%\n",
            "Epoch: 6, Step: 640/655, Loss: 2.208016, Accuracy: 18.53%\n",
            "Epoch: 6, Step: 641/655, Loss: 2.208188, Accuracy: 18.53%\n",
            "Epoch: 6, Step: 642/655, Loss: 2.208052, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 643/655, Loss: 2.208045, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 644/655, Loss: 2.207933, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 645/655, Loss: 2.208006, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 646/655, Loss: 2.207969, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 647/655, Loss: 2.207844, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 648/655, Loss: 2.207882, Accuracy: 18.55%\n",
            "Epoch: 6, Step: 649/655, Loss: 2.208096, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 650/655, Loss: 2.208148, Accuracy: 18.52%\n",
            "Epoch: 6, Step: 651/655, Loss: 2.208066, Accuracy: 18.53%\n",
            "Epoch: 6, Step: 652/655, Loss: 2.207986, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 653/655, Loss: 2.208119, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 654/655, Loss: 2.208371, Accuracy: 18.54%\n",
            "Epoch: 6, Step: 655/655, Loss: 2.208223, Accuracy: 18.55%\n",
            "Epoch: 7, Step: 1/655, Loss: 2.230933, Accuracy: 21.88%\n",
            "Epoch: 7, Step: 2/655, Loss: 2.234640, Accuracy: 23.44%\n",
            "Epoch: 7, Step: 3/655, Loss: 2.186299, Accuracy: 26.04%\n",
            "Epoch: 7, Step: 4/655, Loss: 2.197208, Accuracy: 23.44%\n",
            "Epoch: 7, Step: 5/655, Loss: 2.208244, Accuracy: 21.88%\n",
            "Epoch: 7, Step: 6/655, Loss: 2.224702, Accuracy: 20.31%\n",
            "Epoch: 7, Step: 7/655, Loss: 2.217859, Accuracy: 20.09%\n",
            "Epoch: 7, Step: 8/655, Loss: 2.217828, Accuracy: 19.53%\n",
            "Epoch: 7, Step: 9/655, Loss: 2.214571, Accuracy: 19.44%\n",
            "Epoch: 7, Step: 10/655, Loss: 2.217121, Accuracy: 18.12%\n",
            "Epoch: 7, Step: 11/655, Loss: 2.216646, Accuracy: 17.61%\n",
            "Epoch: 7, Step: 12/655, Loss: 2.208633, Accuracy: 17.97%\n",
            "Epoch: 7, Step: 13/655, Loss: 2.214732, Accuracy: 17.55%\n",
            "Epoch: 7, Step: 14/655, Loss: 2.216384, Accuracy: 17.63%\n",
            "Epoch: 7, Step: 15/655, Loss: 2.219306, Accuracy: 17.50%\n",
            "Epoch: 7, Step: 16/655, Loss: 2.216601, Accuracy: 17.77%\n",
            "Epoch: 7, Step: 17/655, Loss: 2.211399, Accuracy: 18.01%\n",
            "Epoch: 7, Step: 18/655, Loss: 2.213096, Accuracy: 18.23%\n",
            "Epoch: 7, Step: 19/655, Loss: 2.213777, Accuracy: 18.09%\n",
            "Epoch: 7, Step: 20/655, Loss: 2.213272, Accuracy: 18.28%\n",
            "Epoch: 7, Step: 21/655, Loss: 2.214397, Accuracy: 18.30%\n",
            "Epoch: 7, Step: 22/655, Loss: 2.211780, Accuracy: 18.04%\n",
            "Epoch: 7, Step: 23/655, Loss: 2.214163, Accuracy: 17.80%\n",
            "Epoch: 7, Step: 24/655, Loss: 2.210773, Accuracy: 18.23%\n",
            "Epoch: 7, Step: 25/655, Loss: 2.205092, Accuracy: 18.62%\n",
            "Epoch: 7, Step: 26/655, Loss: 2.208350, Accuracy: 18.39%\n",
            "Epoch: 7, Step: 27/655, Loss: 2.210332, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 28/655, Loss: 2.213022, Accuracy: 18.30%\n",
            "Epoch: 7, Step: 29/655, Loss: 2.209653, Accuracy: 18.64%\n",
            "Epoch: 7, Step: 30/655, Loss: 2.214230, Accuracy: 18.54%\n",
            "Epoch: 7, Step: 31/655, Loss: 2.212438, Accuracy: 18.65%\n",
            "Epoch: 7, Step: 32/655, Loss: 2.214968, Accuracy: 18.55%\n",
            "Epoch: 7, Step: 33/655, Loss: 2.211864, Accuracy: 18.75%\n",
            "Epoch: 7, Step: 34/655, Loss: 2.212067, Accuracy: 18.75%\n",
            "Epoch: 7, Step: 35/655, Loss: 2.211898, Accuracy: 18.57%\n",
            "Epoch: 7, Step: 36/655, Loss: 2.211774, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 37/655, Loss: 2.213528, Accuracy: 18.33%\n",
            "Epoch: 7, Step: 38/655, Loss: 2.214965, Accuracy: 18.59%\n",
            "Epoch: 7, Step: 39/655, Loss: 2.217929, Accuracy: 18.27%\n",
            "Epoch: 7, Step: 40/655, Loss: 2.217046, Accuracy: 18.05%\n",
            "Epoch: 7, Step: 41/655, Loss: 2.216142, Accuracy: 18.06%\n",
            "Epoch: 7, Step: 42/655, Loss: 2.213755, Accuracy: 18.15%\n",
            "Epoch: 7, Step: 43/655, Loss: 2.214542, Accuracy: 18.10%\n",
            "Epoch: 7, Step: 44/655, Loss: 2.212513, Accuracy: 18.39%\n",
            "Epoch: 7, Step: 45/655, Loss: 2.210622, Accuracy: 18.33%\n",
            "Epoch: 7, Step: 46/655, Loss: 2.212426, Accuracy: 18.21%\n",
            "Epoch: 7, Step: 47/655, Loss: 2.212998, Accuracy: 18.35%\n",
            "Epoch: 7, Step: 48/655, Loss: 2.214267, Accuracy: 18.23%\n",
            "Epoch: 7, Step: 49/655, Loss: 2.211967, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 50/655, Loss: 2.210126, Accuracy: 18.56%\n",
            "Epoch: 7, Step: 51/655, Loss: 2.210433, Accuracy: 18.63%\n",
            "Epoch: 7, Step: 52/655, Loss: 2.208485, Accuracy: 18.45%\n",
            "Epoch: 7, Step: 53/655, Loss: 2.207355, Accuracy: 18.51%\n",
            "Epoch: 7, Step: 54/655, Loss: 2.208378, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 55/655, Loss: 2.212215, Accuracy: 18.24%\n",
            "Epoch: 7, Step: 56/655, Loss: 2.210590, Accuracy: 18.36%\n",
            "Epoch: 7, Step: 57/655, Loss: 2.206947, Accuracy: 18.59%\n",
            "Epoch: 7, Step: 58/655, Loss: 2.210033, Accuracy: 18.53%\n",
            "Epoch: 7, Step: 59/655, Loss: 2.209184, Accuracy: 18.54%\n",
            "Epoch: 7, Step: 60/655, Loss: 2.207579, Accuracy: 18.59%\n",
            "Epoch: 7, Step: 61/655, Loss: 2.206201, Accuracy: 18.75%\n",
            "Epoch: 7, Step: 62/655, Loss: 2.203846, Accuracy: 18.95%\n",
            "Epoch: 7, Step: 63/655, Loss: 2.203294, Accuracy: 18.80%\n",
            "Epoch: 7, Step: 64/655, Loss: 2.201469, Accuracy: 18.80%\n",
            "Epoch: 7, Step: 65/655, Loss: 2.202253, Accuracy: 18.70%\n",
            "Epoch: 7, Step: 66/655, Loss: 2.202032, Accuracy: 18.70%\n",
            "Epoch: 7, Step: 67/655, Loss: 2.202329, Accuracy: 18.75%\n",
            "Epoch: 7, Step: 68/655, Loss: 2.201494, Accuracy: 18.75%\n",
            "Epoch: 7, Step: 69/655, Loss: 2.201810, Accuracy: 18.75%\n",
            "Epoch: 7, Step: 70/655, Loss: 2.201517, Accuracy: 18.79%\n",
            "Epoch: 7, Step: 71/655, Loss: 2.201952, Accuracy: 18.66%\n",
            "Epoch: 7, Step: 72/655, Loss: 2.200466, Accuracy: 18.79%\n",
            "Epoch: 7, Step: 73/655, Loss: 2.200218, Accuracy: 18.84%\n",
            "Epoch: 7, Step: 74/655, Loss: 2.199306, Accuracy: 18.88%\n",
            "Epoch: 7, Step: 75/655, Loss: 2.200306, Accuracy: 18.75%\n",
            "Epoch: 7, Step: 76/655, Loss: 2.200863, Accuracy: 18.75%\n",
            "Epoch: 7, Step: 77/655, Loss: 2.199999, Accuracy: 18.83%\n",
            "Epoch: 7, Step: 78/655, Loss: 2.199740, Accuracy: 18.95%\n",
            "Epoch: 7, Step: 79/655, Loss: 2.198510, Accuracy: 18.95%\n",
            "Epoch: 7, Step: 80/655, Loss: 2.199341, Accuracy: 18.91%\n",
            "Epoch: 7, Step: 81/655, Loss: 2.198529, Accuracy: 18.90%\n",
            "Epoch: 7, Step: 82/655, Loss: 2.199833, Accuracy: 18.86%\n",
            "Epoch: 7, Step: 83/655, Loss: 2.201255, Accuracy: 18.71%\n",
            "Epoch: 7, Step: 84/655, Loss: 2.200719, Accuracy: 18.71%\n",
            "Epoch: 7, Step: 85/655, Loss: 2.201104, Accuracy: 18.68%\n",
            "Epoch: 7, Step: 86/655, Loss: 2.201124, Accuracy: 18.57%\n",
            "Epoch: 7, Step: 87/655, Loss: 2.201113, Accuracy: 18.53%\n",
            "Epoch: 7, Step: 88/655, Loss: 2.200989, Accuracy: 18.61%\n",
            "Epoch: 7, Step: 89/655, Loss: 2.200847, Accuracy: 18.71%\n",
            "Epoch: 7, Step: 90/655, Loss: 2.200790, Accuracy: 18.82%\n",
            "Epoch: 7, Step: 91/655, Loss: 2.202191, Accuracy: 18.78%\n",
            "Epoch: 7, Step: 92/655, Loss: 2.201907, Accuracy: 18.82%\n",
            "Epoch: 7, Step: 93/655, Loss: 2.202179, Accuracy: 18.75%\n",
            "Epoch: 7, Step: 94/655, Loss: 2.203947, Accuracy: 18.75%\n",
            "Epoch: 7, Step: 95/655, Loss: 2.202341, Accuracy: 18.85%\n",
            "Epoch: 7, Step: 96/655, Loss: 2.202531, Accuracy: 18.91%\n",
            "Epoch: 7, Step: 97/655, Loss: 2.201666, Accuracy: 18.94%\n",
            "Epoch: 7, Step: 98/655, Loss: 2.201389, Accuracy: 19.10%\n",
            "Epoch: 7, Step: 99/655, Loss: 2.200889, Accuracy: 19.19%\n",
            "Epoch: 7, Step: 100/655, Loss: 2.200625, Accuracy: 19.09%\n",
            "Epoch: 7, Step: 101/655, Loss: 2.200250, Accuracy: 19.12%\n",
            "Epoch: 7, Step: 102/655, Loss: 2.200416, Accuracy: 19.12%\n",
            "Epoch: 7, Step: 103/655, Loss: 2.199258, Accuracy: 19.17%\n",
            "Epoch: 7, Step: 104/655, Loss: 2.200691, Accuracy: 19.08%\n",
            "Epoch: 7, Step: 105/655, Loss: 2.200666, Accuracy: 19.08%\n",
            "Epoch: 7, Step: 106/655, Loss: 2.200398, Accuracy: 19.10%\n",
            "Epoch: 7, Step: 107/655, Loss: 2.199083, Accuracy: 19.22%\n",
            "Epoch: 7, Step: 108/655, Loss: 2.200011, Accuracy: 19.21%\n",
            "Epoch: 7, Step: 109/655, Loss: 2.200409, Accuracy: 19.21%\n",
            "Epoch: 7, Step: 110/655, Loss: 2.200185, Accuracy: 19.18%\n",
            "Epoch: 7, Step: 111/655, Loss: 2.200329, Accuracy: 19.20%\n",
            "Epoch: 7, Step: 112/655, Loss: 2.200166, Accuracy: 19.17%\n",
            "Epoch: 7, Step: 113/655, Loss: 2.200297, Accuracy: 19.08%\n",
            "Epoch: 7, Step: 114/655, Loss: 2.200567, Accuracy: 19.11%\n",
            "Epoch: 7, Step: 115/655, Loss: 2.201484, Accuracy: 19.05%\n",
            "Epoch: 7, Step: 116/655, Loss: 2.200986, Accuracy: 19.07%\n",
            "Epoch: 7, Step: 117/655, Loss: 2.202450, Accuracy: 19.07%\n",
            "Epoch: 7, Step: 118/655, Loss: 2.203176, Accuracy: 19.07%\n",
            "Epoch: 7, Step: 119/655, Loss: 2.202820, Accuracy: 19.12%\n",
            "Epoch: 7, Step: 120/655, Loss: 2.203324, Accuracy: 19.04%\n",
            "Epoch: 7, Step: 121/655, Loss: 2.202451, Accuracy: 19.14%\n",
            "Epoch: 7, Step: 122/655, Loss: 2.203152, Accuracy: 19.16%\n",
            "Epoch: 7, Step: 123/655, Loss: 2.202273, Accuracy: 19.26%\n",
            "Epoch: 7, Step: 124/655, Loss: 2.201892, Accuracy: 19.18%\n",
            "Epoch: 7, Step: 125/655, Loss: 2.201849, Accuracy: 19.18%\n",
            "Epoch: 7, Step: 126/655, Loss: 2.202053, Accuracy: 19.20%\n",
            "Epoch: 7, Step: 127/655, Loss: 2.202042, Accuracy: 19.27%\n",
            "Epoch: 7, Step: 128/655, Loss: 2.200999, Accuracy: 19.31%\n",
            "Epoch: 7, Step: 129/655, Loss: 2.201324, Accuracy: 19.28%\n",
            "Epoch: 7, Step: 130/655, Loss: 2.201160, Accuracy: 19.30%\n",
            "Epoch: 7, Step: 131/655, Loss: 2.200889, Accuracy: 19.35%\n",
            "Epoch: 7, Step: 132/655, Loss: 2.201181, Accuracy: 19.37%\n",
            "Epoch: 7, Step: 133/655, Loss: 2.200733, Accuracy: 19.48%\n",
            "Epoch: 7, Step: 134/655, Loss: 2.201010, Accuracy: 19.50%\n",
            "Epoch: 7, Step: 135/655, Loss: 2.201210, Accuracy: 19.56%\n",
            "Epoch: 7, Step: 136/655, Loss: 2.202139, Accuracy: 19.53%\n",
            "Epoch: 7, Step: 137/655, Loss: 2.202666, Accuracy: 19.46%\n",
            "Epoch: 7, Step: 138/655, Loss: 2.202087, Accuracy: 19.47%\n",
            "Epoch: 7, Step: 139/655, Loss: 2.201004, Accuracy: 19.56%\n",
            "Epoch: 7, Step: 140/655, Loss: 2.201364, Accuracy: 19.58%\n",
            "Epoch: 7, Step: 141/655, Loss: 2.201203, Accuracy: 19.53%\n",
            "Epoch: 7, Step: 142/655, Loss: 2.201274, Accuracy: 19.50%\n",
            "Epoch: 7, Step: 143/655, Loss: 2.201212, Accuracy: 19.49%\n",
            "Epoch: 7, Step: 144/655, Loss: 2.201457, Accuracy: 19.51%\n",
            "Epoch: 7, Step: 145/655, Loss: 2.201450, Accuracy: 19.46%\n",
            "Epoch: 7, Step: 146/655, Loss: 2.201454, Accuracy: 19.37%\n",
            "Epoch: 7, Step: 147/655, Loss: 2.200586, Accuracy: 19.41%\n",
            "Epoch: 7, Step: 148/655, Loss: 2.200657, Accuracy: 19.36%\n",
            "Epoch: 7, Step: 149/655, Loss: 2.201202, Accuracy: 19.25%\n",
            "Epoch: 7, Step: 150/655, Loss: 2.200562, Accuracy: 19.29%\n",
            "Epoch: 7, Step: 151/655, Loss: 2.201134, Accuracy: 19.27%\n",
            "Epoch: 7, Step: 152/655, Loss: 2.201736, Accuracy: 19.22%\n",
            "Epoch: 7, Step: 153/655, Loss: 2.202144, Accuracy: 19.22%\n",
            "Epoch: 7, Step: 154/655, Loss: 2.201590, Accuracy: 19.26%\n",
            "Epoch: 7, Step: 155/655, Loss: 2.202404, Accuracy: 19.25%\n",
            "Epoch: 7, Step: 156/655, Loss: 2.201814, Accuracy: 19.29%\n",
            "Epoch: 7, Step: 157/655, Loss: 2.201268, Accuracy: 19.29%\n",
            "Epoch: 7, Step: 158/655, Loss: 2.200966, Accuracy: 19.30%\n",
            "Epoch: 7, Step: 159/655, Loss: 2.201227, Accuracy: 19.30%\n",
            "Epoch: 7, Step: 160/655, Loss: 2.201466, Accuracy: 19.26%\n",
            "Epoch: 7, Step: 161/655, Loss: 2.201065, Accuracy: 19.27%\n",
            "Epoch: 7, Step: 162/655, Loss: 2.200980, Accuracy: 19.29%\n",
            "Epoch: 7, Step: 163/655, Loss: 2.200897, Accuracy: 19.25%\n",
            "Epoch: 7, Step: 164/655, Loss: 2.201457, Accuracy: 19.17%\n",
            "Epoch: 7, Step: 165/655, Loss: 2.201255, Accuracy: 19.20%\n",
            "Epoch: 7, Step: 166/655, Loss: 2.201081, Accuracy: 19.22%\n",
            "Epoch: 7, Step: 167/655, Loss: 2.200824, Accuracy: 19.20%\n",
            "Epoch: 7, Step: 168/655, Loss: 2.200264, Accuracy: 19.25%\n",
            "Epoch: 7, Step: 169/655, Loss: 2.200493, Accuracy: 19.21%\n",
            "Epoch: 7, Step: 170/655, Loss: 2.200504, Accuracy: 19.15%\n",
            "Epoch: 7, Step: 171/655, Loss: 2.201746, Accuracy: 19.13%\n",
            "Epoch: 7, Step: 172/655, Loss: 2.202172, Accuracy: 19.10%\n",
            "Epoch: 7, Step: 173/655, Loss: 2.202653, Accuracy: 19.08%\n",
            "Epoch: 7, Step: 174/655, Loss: 2.201633, Accuracy: 19.13%\n",
            "Epoch: 7, Step: 175/655, Loss: 2.202104, Accuracy: 19.14%\n",
            "Epoch: 7, Step: 176/655, Loss: 2.202316, Accuracy: 19.12%\n",
            "Epoch: 7, Step: 177/655, Loss: 2.202121, Accuracy: 19.14%\n",
            "Epoch: 7, Step: 178/655, Loss: 2.201612, Accuracy: 19.21%\n",
            "Epoch: 7, Step: 179/655, Loss: 2.201566, Accuracy: 19.22%\n",
            "Epoch: 7, Step: 180/655, Loss: 2.201382, Accuracy: 19.20%\n",
            "Epoch: 7, Step: 181/655, Loss: 2.201144, Accuracy: 19.23%\n",
            "Epoch: 7, Step: 182/655, Loss: 2.201164, Accuracy: 19.27%\n",
            "Epoch: 7, Step: 183/655, Loss: 2.201666, Accuracy: 19.21%\n",
            "Epoch: 7, Step: 184/655, Loss: 2.201530, Accuracy: 19.23%\n",
            "Epoch: 7, Step: 185/655, Loss: 2.201109, Accuracy: 19.29%\n",
            "Epoch: 7, Step: 186/655, Loss: 2.201664, Accuracy: 19.25%\n",
            "Epoch: 7, Step: 187/655, Loss: 2.201703, Accuracy: 19.25%\n",
            "Epoch: 7, Step: 188/655, Loss: 2.201988, Accuracy: 19.22%\n",
            "Epoch: 7, Step: 189/655, Loss: 2.201727, Accuracy: 19.26%\n",
            "Epoch: 7, Step: 190/655, Loss: 2.201891, Accuracy: 19.28%\n",
            "Epoch: 7, Step: 191/655, Loss: 2.201720, Accuracy: 19.27%\n",
            "Epoch: 7, Step: 192/655, Loss: 2.201575, Accuracy: 19.25%\n",
            "Epoch: 7, Step: 193/655, Loss: 2.201525, Accuracy: 19.27%\n",
            "Epoch: 7, Step: 194/655, Loss: 2.201448, Accuracy: 19.28%\n",
            "Epoch: 7, Step: 195/655, Loss: 2.201249, Accuracy: 19.31%\n",
            "Epoch: 7, Step: 196/655, Loss: 2.201944, Accuracy: 19.26%\n",
            "Epoch: 7, Step: 197/655, Loss: 2.202147, Accuracy: 19.24%\n",
            "Epoch: 7, Step: 198/655, Loss: 2.202446, Accuracy: 19.21%\n",
            "Epoch: 7, Step: 199/655, Loss: 2.202350, Accuracy: 19.17%\n",
            "Epoch: 7, Step: 200/655, Loss: 2.201427, Accuracy: 19.19%\n",
            "Epoch: 7, Step: 201/655, Loss: 2.201724, Accuracy: 19.17%\n",
            "Epoch: 7, Step: 202/655, Loss: 2.201298, Accuracy: 19.20%\n",
            "Epoch: 7, Step: 203/655, Loss: 2.201690, Accuracy: 19.18%\n",
            "Epoch: 7, Step: 204/655, Loss: 2.202213, Accuracy: 19.09%\n",
            "Epoch: 7, Step: 205/655, Loss: 2.201702, Accuracy: 19.12%\n",
            "Epoch: 7, Step: 206/655, Loss: 2.201706, Accuracy: 19.11%\n",
            "Epoch: 7, Step: 207/655, Loss: 2.201885, Accuracy: 19.10%\n",
            "Epoch: 7, Step: 208/655, Loss: 2.201693, Accuracy: 19.07%\n",
            "Epoch: 7, Step: 209/655, Loss: 2.201579, Accuracy: 19.02%\n",
            "Epoch: 7, Step: 210/655, Loss: 2.201882, Accuracy: 18.99%\n",
            "Epoch: 7, Step: 211/655, Loss: 2.201956, Accuracy: 19.03%\n",
            "Epoch: 7, Step: 212/655, Loss: 2.202049, Accuracy: 19.00%\n",
            "Epoch: 7, Step: 213/655, Loss: 2.201751, Accuracy: 19.01%\n",
            "Epoch: 7, Step: 214/655, Loss: 2.201410, Accuracy: 19.07%\n",
            "Epoch: 7, Step: 215/655, Loss: 2.201880, Accuracy: 19.07%\n",
            "Epoch: 7, Step: 216/655, Loss: 2.201873, Accuracy: 19.04%\n",
            "Epoch: 7, Step: 217/655, Loss: 2.201898, Accuracy: 19.02%\n",
            "Epoch: 7, Step: 218/655, Loss: 2.201705, Accuracy: 19.01%\n",
            "Epoch: 7, Step: 219/655, Loss: 2.202158, Accuracy: 18.96%\n",
            "Epoch: 7, Step: 220/655, Loss: 2.201806, Accuracy: 18.95%\n",
            "Epoch: 7, Step: 221/655, Loss: 2.202266, Accuracy: 18.96%\n",
            "Epoch: 7, Step: 222/655, Loss: 2.202017, Accuracy: 18.95%\n",
            "Epoch: 7, Step: 223/655, Loss: 2.201651, Accuracy: 18.95%\n",
            "Epoch: 7, Step: 224/655, Loss: 2.201613, Accuracy: 18.95%\n",
            "Epoch: 7, Step: 225/655, Loss: 2.201490, Accuracy: 18.90%\n",
            "Epoch: 7, Step: 226/655, Loss: 2.201938, Accuracy: 18.87%\n",
            "Epoch: 7, Step: 227/655, Loss: 2.202544, Accuracy: 18.85%\n",
            "Epoch: 7, Step: 228/655, Loss: 2.202579, Accuracy: 18.86%\n",
            "Epoch: 7, Step: 229/655, Loss: 2.202312, Accuracy: 18.80%\n",
            "Epoch: 7, Step: 230/655, Loss: 2.202367, Accuracy: 18.79%\n",
            "Epoch: 7, Step: 231/655, Loss: 2.202405, Accuracy: 18.80%\n",
            "Epoch: 7, Step: 232/655, Loss: 2.202740, Accuracy: 18.82%\n",
            "Epoch: 7, Step: 233/655, Loss: 2.203024, Accuracy: 18.78%\n",
            "Epoch: 7, Step: 234/655, Loss: 2.203110, Accuracy: 18.78%\n",
            "Epoch: 7, Step: 235/655, Loss: 2.203110, Accuracy: 18.79%\n",
            "Epoch: 7, Step: 236/655, Loss: 2.202780, Accuracy: 18.83%\n",
            "Epoch: 7, Step: 237/655, Loss: 2.203666, Accuracy: 18.75%\n",
            "Epoch: 7, Step: 238/655, Loss: 2.204082, Accuracy: 18.75%\n",
            "Epoch: 7, Step: 239/655, Loss: 2.203897, Accuracy: 18.80%\n",
            "Epoch: 7, Step: 240/655, Loss: 2.203854, Accuracy: 18.80%\n",
            "Epoch: 7, Step: 241/655, Loss: 2.204386, Accuracy: 18.76%\n",
            "Epoch: 7, Step: 242/655, Loss: 2.204148, Accuracy: 18.75%\n",
            "Epoch: 7, Step: 243/655, Loss: 2.204813, Accuracy: 18.71%\n",
            "Epoch: 7, Step: 244/655, Loss: 2.204723, Accuracy: 18.71%\n",
            "Epoch: 7, Step: 245/655, Loss: 2.204299, Accuracy: 18.74%\n",
            "Epoch: 7, Step: 246/655, Loss: 2.204649, Accuracy: 18.71%\n",
            "Epoch: 7, Step: 247/655, Loss: 2.204600, Accuracy: 18.71%\n",
            "Epoch: 7, Step: 248/655, Loss: 2.204330, Accuracy: 18.69%\n",
            "Epoch: 7, Step: 249/655, Loss: 2.204544, Accuracy: 18.67%\n",
            "Epoch: 7, Step: 250/655, Loss: 2.204568, Accuracy: 18.69%\n",
            "Epoch: 7, Step: 251/655, Loss: 2.204693, Accuracy: 18.70%\n",
            "Epoch: 7, Step: 252/655, Loss: 2.204895, Accuracy: 18.66%\n",
            "Epoch: 7, Step: 253/655, Loss: 2.205274, Accuracy: 18.64%\n",
            "Epoch: 7, Step: 254/655, Loss: 2.205567, Accuracy: 18.65%\n",
            "Epoch: 7, Step: 255/655, Loss: 2.205877, Accuracy: 18.68%\n",
            "Epoch: 7, Step: 256/655, Loss: 2.205351, Accuracy: 18.65%\n",
            "Epoch: 7, Step: 257/655, Loss: 2.205928, Accuracy: 18.62%\n",
            "Epoch: 7, Step: 258/655, Loss: 2.205706, Accuracy: 18.62%\n",
            "Epoch: 7, Step: 259/655, Loss: 2.205856, Accuracy: 18.65%\n",
            "Epoch: 7, Step: 260/655, Loss: 2.205637, Accuracy: 18.67%\n",
            "Epoch: 7, Step: 261/655, Loss: 2.205584, Accuracy: 18.68%\n",
            "Epoch: 7, Step: 262/655, Loss: 2.205657, Accuracy: 18.73%\n",
            "Epoch: 7, Step: 263/655, Loss: 2.205643, Accuracy: 18.75%\n",
            "Epoch: 7, Step: 264/655, Loss: 2.205726, Accuracy: 18.74%\n",
            "Epoch: 7, Step: 265/655, Loss: 2.205252, Accuracy: 18.77%\n",
            "Epoch: 7, Step: 266/655, Loss: 2.205437, Accuracy: 18.76%\n",
            "Epoch: 7, Step: 267/655, Loss: 2.205336, Accuracy: 18.79%\n",
            "Epoch: 7, Step: 268/655, Loss: 2.204878, Accuracy: 18.83%\n",
            "Epoch: 7, Step: 269/655, Loss: 2.205077, Accuracy: 18.81%\n",
            "Epoch: 7, Step: 270/655, Loss: 2.204878, Accuracy: 18.81%\n",
            "Epoch: 7, Step: 271/655, Loss: 2.204679, Accuracy: 18.81%\n",
            "Epoch: 7, Step: 272/655, Loss: 2.204670, Accuracy: 18.82%\n",
            "Epoch: 7, Step: 273/655, Loss: 2.205666, Accuracy: 18.77%\n",
            "Epoch: 7, Step: 274/655, Loss: 2.205590, Accuracy: 18.80%\n",
            "Epoch: 7, Step: 275/655, Loss: 2.205328, Accuracy: 18.81%\n",
            "Epoch: 7, Step: 276/655, Loss: 2.205784, Accuracy: 18.80%\n",
            "Epoch: 7, Step: 277/655, Loss: 2.205549, Accuracy: 18.80%\n",
            "Epoch: 7, Step: 278/655, Loss: 2.205124, Accuracy: 18.85%\n",
            "Epoch: 7, Step: 279/655, Loss: 2.204637, Accuracy: 18.86%\n",
            "Epoch: 7, Step: 280/655, Loss: 2.204804, Accuracy: 18.85%\n",
            "Epoch: 7, Step: 281/655, Loss: 2.205067, Accuracy: 18.82%\n",
            "Epoch: 7, Step: 282/655, Loss: 2.204858, Accuracy: 18.83%\n",
            "Epoch: 7, Step: 283/655, Loss: 2.204858, Accuracy: 18.83%\n",
            "Epoch: 7, Step: 284/655, Loss: 2.205232, Accuracy: 18.83%\n",
            "Epoch: 7, Step: 285/655, Loss: 2.205099, Accuracy: 18.82%\n",
            "Epoch: 7, Step: 286/655, Loss: 2.204939, Accuracy: 18.83%\n",
            "Epoch: 7, Step: 287/655, Loss: 2.205441, Accuracy: 18.76%\n",
            "Epoch: 7, Step: 288/655, Loss: 2.205481, Accuracy: 18.77%\n",
            "Epoch: 7, Step: 289/655, Loss: 2.205300, Accuracy: 18.77%\n",
            "Epoch: 7, Step: 290/655, Loss: 2.205243, Accuracy: 18.77%\n",
            "Epoch: 7, Step: 291/655, Loss: 2.205462, Accuracy: 18.74%\n",
            "Epoch: 7, Step: 292/655, Loss: 2.205253, Accuracy: 18.74%\n",
            "Epoch: 7, Step: 293/655, Loss: 2.205448, Accuracy: 18.73%\n",
            "Epoch: 7, Step: 294/655, Loss: 2.205609, Accuracy: 18.72%\n",
            "Epoch: 7, Step: 295/655, Loss: 2.205871, Accuracy: 18.69%\n",
            "Epoch: 7, Step: 296/655, Loss: 2.205595, Accuracy: 18.71%\n",
            "Epoch: 7, Step: 297/655, Loss: 2.205732, Accuracy: 18.72%\n",
            "Epoch: 7, Step: 298/655, Loss: 2.205731, Accuracy: 18.72%\n",
            "Epoch: 7, Step: 299/655, Loss: 2.205887, Accuracy: 18.70%\n",
            "Epoch: 7, Step: 300/655, Loss: 2.205697, Accuracy: 18.67%\n",
            "Epoch: 7, Step: 301/655, Loss: 2.205621, Accuracy: 18.66%\n",
            "Epoch: 7, Step: 302/655, Loss: 2.206289, Accuracy: 18.65%\n",
            "Epoch: 7, Step: 303/655, Loss: 2.206418, Accuracy: 18.64%\n",
            "Epoch: 7, Step: 304/655, Loss: 2.206549, Accuracy: 18.60%\n",
            "Epoch: 7, Step: 305/655, Loss: 2.206898, Accuracy: 18.59%\n",
            "Epoch: 7, Step: 306/655, Loss: 2.206765, Accuracy: 18.60%\n",
            "Epoch: 7, Step: 307/655, Loss: 2.207128, Accuracy: 18.60%\n",
            "Epoch: 7, Step: 308/655, Loss: 2.207389, Accuracy: 18.59%\n",
            "Epoch: 7, Step: 309/655, Loss: 2.207412, Accuracy: 18.62%\n",
            "Epoch: 7, Step: 310/655, Loss: 2.207637, Accuracy: 18.63%\n",
            "Epoch: 7, Step: 311/655, Loss: 2.207711, Accuracy: 18.62%\n",
            "Epoch: 7, Step: 312/655, Loss: 2.208042, Accuracy: 18.61%\n",
            "Epoch: 7, Step: 313/655, Loss: 2.208034, Accuracy: 18.62%\n",
            "Epoch: 7, Step: 314/655, Loss: 2.207949, Accuracy: 18.65%\n",
            "Epoch: 7, Step: 315/655, Loss: 2.208099, Accuracy: 18.61%\n",
            "Epoch: 7, Step: 316/655, Loss: 2.207711, Accuracy: 18.63%\n",
            "Epoch: 7, Step: 317/655, Loss: 2.207799, Accuracy: 18.62%\n",
            "Epoch: 7, Step: 318/655, Loss: 2.207928, Accuracy: 18.61%\n",
            "Epoch: 7, Step: 319/655, Loss: 2.207928, Accuracy: 18.62%\n",
            "Epoch: 7, Step: 320/655, Loss: 2.207849, Accuracy: 18.63%\n",
            "Epoch: 7, Step: 321/655, Loss: 2.207770, Accuracy: 18.62%\n",
            "Epoch: 7, Step: 322/655, Loss: 2.208008, Accuracy: 18.61%\n",
            "Epoch: 7, Step: 323/655, Loss: 2.207986, Accuracy: 18.59%\n",
            "Epoch: 7, Step: 324/655, Loss: 2.208071, Accuracy: 18.61%\n",
            "Epoch: 7, Step: 325/655, Loss: 2.207849, Accuracy: 18.61%\n",
            "Epoch: 7, Step: 326/655, Loss: 2.207933, Accuracy: 18.62%\n",
            "Epoch: 7, Step: 327/655, Loss: 2.207527, Accuracy: 18.67%\n",
            "Epoch: 7, Step: 328/655, Loss: 2.207320, Accuracy: 18.68%\n",
            "Epoch: 7, Step: 329/655, Loss: 2.207361, Accuracy: 18.66%\n",
            "Epoch: 7, Step: 330/655, Loss: 2.207412, Accuracy: 18.66%\n",
            "Epoch: 7, Step: 331/655, Loss: 2.207374, Accuracy: 18.62%\n",
            "Epoch: 7, Step: 332/655, Loss: 2.207812, Accuracy: 18.59%\n",
            "Epoch: 7, Step: 333/655, Loss: 2.207438, Accuracy: 18.55%\n",
            "Epoch: 7, Step: 334/655, Loss: 2.207555, Accuracy: 18.54%\n",
            "Epoch: 7, Step: 335/655, Loss: 2.207545, Accuracy: 18.54%\n",
            "Epoch: 7, Step: 336/655, Loss: 2.207316, Accuracy: 18.60%\n",
            "Epoch: 7, Step: 337/655, Loss: 2.207398, Accuracy: 18.59%\n",
            "Epoch: 7, Step: 338/655, Loss: 2.207254, Accuracy: 18.60%\n",
            "Epoch: 7, Step: 339/655, Loss: 2.207622, Accuracy: 18.59%\n",
            "Epoch: 7, Step: 340/655, Loss: 2.207877, Accuracy: 18.58%\n",
            "Epoch: 7, Step: 341/655, Loss: 2.208095, Accuracy: 18.58%\n",
            "Epoch: 7, Step: 342/655, Loss: 2.208099, Accuracy: 18.55%\n",
            "Epoch: 7, Step: 343/655, Loss: 2.208108, Accuracy: 18.53%\n",
            "Epoch: 7, Step: 344/655, Loss: 2.208332, Accuracy: 18.50%\n",
            "Epoch: 7, Step: 345/655, Loss: 2.208021, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 346/655, Loss: 2.207890, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 347/655, Loss: 2.207913, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 348/655, Loss: 2.207979, Accuracy: 18.52%\n",
            "Epoch: 7, Step: 349/655, Loss: 2.207821, Accuracy: 18.54%\n",
            "Epoch: 7, Step: 350/655, Loss: 2.207927, Accuracy: 18.54%\n",
            "Epoch: 7, Step: 351/655, Loss: 2.207981, Accuracy: 18.53%\n",
            "Epoch: 7, Step: 352/655, Loss: 2.207880, Accuracy: 18.53%\n",
            "Epoch: 7, Step: 353/655, Loss: 2.208124, Accuracy: 18.52%\n",
            "Epoch: 7, Step: 354/655, Loss: 2.207840, Accuracy: 18.54%\n",
            "Epoch: 7, Step: 355/655, Loss: 2.207779, Accuracy: 18.51%\n",
            "Epoch: 7, Step: 356/655, Loss: 2.207488, Accuracy: 18.51%\n",
            "Epoch: 7, Step: 357/655, Loss: 2.207369, Accuracy: 18.50%\n",
            "Epoch: 7, Step: 358/655, Loss: 2.207176, Accuracy: 18.51%\n",
            "Epoch: 7, Step: 359/655, Loss: 2.207211, Accuracy: 18.54%\n",
            "Epoch: 7, Step: 360/655, Loss: 2.206920, Accuracy: 18.57%\n",
            "Epoch: 7, Step: 361/655, Loss: 2.206841, Accuracy: 18.59%\n",
            "Epoch: 7, Step: 362/655, Loss: 2.207259, Accuracy: 18.60%\n",
            "Epoch: 7, Step: 363/655, Loss: 2.206936, Accuracy: 18.63%\n",
            "Epoch: 7, Step: 364/655, Loss: 2.206841, Accuracy: 18.62%\n",
            "Epoch: 7, Step: 365/655, Loss: 2.206545, Accuracy: 18.63%\n",
            "Epoch: 7, Step: 366/655, Loss: 2.206470, Accuracy: 18.64%\n",
            "Epoch: 7, Step: 367/655, Loss: 2.206709, Accuracy: 18.62%\n",
            "Epoch: 7, Step: 368/655, Loss: 2.206875, Accuracy: 18.58%\n",
            "Epoch: 7, Step: 369/655, Loss: 2.206592, Accuracy: 18.58%\n",
            "Epoch: 7, Step: 370/655, Loss: 2.206590, Accuracy: 18.57%\n",
            "Epoch: 7, Step: 371/655, Loss: 2.206565, Accuracy: 18.54%\n",
            "Epoch: 7, Step: 372/655, Loss: 2.206984, Accuracy: 18.51%\n",
            "Epoch: 7, Step: 373/655, Loss: 2.206854, Accuracy: 18.52%\n",
            "Epoch: 7, Step: 374/655, Loss: 2.207065, Accuracy: 18.51%\n",
            "Epoch: 7, Step: 375/655, Loss: 2.207296, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 376/655, Loss: 2.207788, Accuracy: 18.45%\n",
            "Epoch: 7, Step: 377/655, Loss: 2.207891, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 378/655, Loss: 2.207723, Accuracy: 18.43%\n",
            "Epoch: 7, Step: 379/655, Loss: 2.207947, Accuracy: 18.43%\n",
            "Epoch: 7, Step: 380/655, Loss: 2.207894, Accuracy: 18.45%\n",
            "Epoch: 7, Step: 381/655, Loss: 2.207847, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 382/655, Loss: 2.208006, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 383/655, Loss: 2.208136, Accuracy: 18.46%\n",
            "Epoch: 7, Step: 384/655, Loss: 2.207986, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 385/655, Loss: 2.208109, Accuracy: 18.45%\n",
            "Epoch: 7, Step: 386/655, Loss: 2.208030, Accuracy: 18.45%\n",
            "Epoch: 7, Step: 387/655, Loss: 2.208088, Accuracy: 18.43%\n",
            "Epoch: 7, Step: 388/655, Loss: 2.208246, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 389/655, Loss: 2.208370, Accuracy: 18.38%\n",
            "Epoch: 7, Step: 390/655, Loss: 2.208318, Accuracy: 18.36%\n",
            "Epoch: 7, Step: 391/655, Loss: 2.208710, Accuracy: 18.33%\n",
            "Epoch: 7, Step: 392/655, Loss: 2.208893, Accuracy: 18.34%\n",
            "Epoch: 7, Step: 393/655, Loss: 2.209079, Accuracy: 18.35%\n",
            "Epoch: 7, Step: 394/655, Loss: 2.209047, Accuracy: 18.35%\n",
            "Epoch: 7, Step: 395/655, Loss: 2.208942, Accuracy: 18.37%\n",
            "Epoch: 7, Step: 396/655, Loss: 2.208669, Accuracy: 18.39%\n",
            "Epoch: 7, Step: 397/655, Loss: 2.208554, Accuracy: 18.41%\n",
            "Epoch: 7, Step: 398/655, Loss: 2.208750, Accuracy: 18.39%\n",
            "Epoch: 7, Step: 399/655, Loss: 2.209033, Accuracy: 18.39%\n",
            "Epoch: 7, Step: 400/655, Loss: 2.209146, Accuracy: 18.39%\n",
            "Epoch: 7, Step: 401/655, Loss: 2.209336, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 402/655, Loss: 2.209631, Accuracy: 18.38%\n",
            "Epoch: 7, Step: 403/655, Loss: 2.209834, Accuracy: 18.39%\n",
            "Epoch: 7, Step: 404/655, Loss: 2.209858, Accuracy: 18.37%\n",
            "Epoch: 7, Step: 405/655, Loss: 2.209932, Accuracy: 18.36%\n",
            "Epoch: 7, Step: 406/655, Loss: 2.209928, Accuracy: 18.37%\n",
            "Epoch: 7, Step: 407/655, Loss: 2.209862, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 408/655, Loss: 2.209982, Accuracy: 18.41%\n",
            "Epoch: 7, Step: 409/655, Loss: 2.210161, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 410/655, Loss: 2.210112, Accuracy: 18.41%\n",
            "Epoch: 7, Step: 411/655, Loss: 2.210051, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 412/655, Loss: 2.209985, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 413/655, Loss: 2.209884, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 414/655, Loss: 2.209878, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 415/655, Loss: 2.209721, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 416/655, Loss: 2.209729, Accuracy: 18.38%\n",
            "Epoch: 7, Step: 417/655, Loss: 2.209633, Accuracy: 18.41%\n",
            "Epoch: 7, Step: 418/655, Loss: 2.209622, Accuracy: 18.41%\n",
            "Epoch: 7, Step: 419/655, Loss: 2.209695, Accuracy: 18.41%\n",
            "Epoch: 7, Step: 420/655, Loss: 2.209855, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 421/655, Loss: 2.209905, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 422/655, Loss: 2.210110, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 423/655, Loss: 2.210079, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 424/655, Loss: 2.210011, Accuracy: 18.43%\n",
            "Epoch: 7, Step: 425/655, Loss: 2.210105, Accuracy: 18.43%\n",
            "Epoch: 7, Step: 426/655, Loss: 2.210159, Accuracy: 18.41%\n",
            "Epoch: 7, Step: 427/655, Loss: 2.209848, Accuracy: 18.41%\n",
            "Epoch: 7, Step: 428/655, Loss: 2.209978, Accuracy: 18.39%\n",
            "Epoch: 7, Step: 429/655, Loss: 2.209759, Accuracy: 18.38%\n",
            "Epoch: 7, Step: 430/655, Loss: 2.209922, Accuracy: 18.39%\n",
            "Epoch: 7, Step: 431/655, Loss: 2.209655, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 432/655, Loss: 2.209770, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 433/655, Loss: 2.209712, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 434/655, Loss: 2.209773, Accuracy: 18.43%\n",
            "Epoch: 7, Step: 435/655, Loss: 2.209752, Accuracy: 18.44%\n",
            "Epoch: 7, Step: 436/655, Loss: 2.209767, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 437/655, Loss: 2.209412, Accuracy: 18.46%\n",
            "Epoch: 7, Step: 438/655, Loss: 2.209410, Accuracy: 18.46%\n",
            "Epoch: 7, Step: 439/655, Loss: 2.209319, Accuracy: 18.46%\n",
            "Epoch: 7, Step: 440/655, Loss: 2.209716, Accuracy: 18.43%\n",
            "Epoch: 7, Step: 441/655, Loss: 2.209765, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 442/655, Loss: 2.209617, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 443/655, Loss: 2.209813, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 444/655, Loss: 2.209616, Accuracy: 18.43%\n",
            "Epoch: 7, Step: 445/655, Loss: 2.209346, Accuracy: 18.43%\n",
            "Epoch: 7, Step: 446/655, Loss: 2.209343, Accuracy: 18.44%\n",
            "Epoch: 7, Step: 447/655, Loss: 2.209408, Accuracy: 18.44%\n",
            "Epoch: 7, Step: 448/655, Loss: 2.209613, Accuracy: 18.44%\n",
            "Epoch: 7, Step: 449/655, Loss: 2.209312, Accuracy: 18.44%\n",
            "Epoch: 7, Step: 450/655, Loss: 2.209091, Accuracy: 18.44%\n",
            "Epoch: 7, Step: 451/655, Loss: 2.209266, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 452/655, Loss: 2.209424, Accuracy: 18.43%\n",
            "Epoch: 7, Step: 453/655, Loss: 2.209635, Accuracy: 18.41%\n",
            "Epoch: 7, Step: 454/655, Loss: 2.209393, Accuracy: 18.45%\n",
            "Epoch: 7, Step: 455/655, Loss: 2.209312, Accuracy: 18.43%\n",
            "Epoch: 7, Step: 456/655, Loss: 2.209405, Accuracy: 18.45%\n",
            "Epoch: 7, Step: 457/655, Loss: 2.209439, Accuracy: 18.44%\n",
            "Epoch: 7, Step: 458/655, Loss: 2.209722, Accuracy: 18.44%\n",
            "Epoch: 7, Step: 459/655, Loss: 2.209675, Accuracy: 18.46%\n",
            "Epoch: 7, Step: 460/655, Loss: 2.209474, Accuracy: 18.46%\n",
            "Epoch: 7, Step: 461/655, Loss: 2.209553, Accuracy: 18.43%\n",
            "Epoch: 7, Step: 462/655, Loss: 2.209477, Accuracy: 18.44%\n",
            "Epoch: 7, Step: 463/655, Loss: 2.209464, Accuracy: 18.45%\n",
            "Epoch: 7, Step: 464/655, Loss: 2.209427, Accuracy: 18.46%\n",
            "Epoch: 7, Step: 465/655, Loss: 2.209131, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 466/655, Loss: 2.208992, Accuracy: 18.50%\n",
            "Epoch: 7, Step: 467/655, Loss: 2.208917, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 468/655, Loss: 2.209285, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 469/655, Loss: 2.209320, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 470/655, Loss: 2.209522, Accuracy: 18.46%\n",
            "Epoch: 7, Step: 471/655, Loss: 2.209519, Accuracy: 18.46%\n",
            "Epoch: 7, Step: 472/655, Loss: 2.209383, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 473/655, Loss: 2.209491, Accuracy: 18.46%\n",
            "Epoch: 7, Step: 474/655, Loss: 2.209538, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 475/655, Loss: 2.209464, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 476/655, Loss: 2.209476, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 477/655, Loss: 2.209508, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 478/655, Loss: 2.209523, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 479/655, Loss: 2.209568, Accuracy: 18.46%\n",
            "Epoch: 7, Step: 480/655, Loss: 2.209568, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 481/655, Loss: 2.209440, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 482/655, Loss: 2.209608, Accuracy: 18.46%\n",
            "Epoch: 7, Step: 483/655, Loss: 2.209755, Accuracy: 18.45%\n",
            "Epoch: 7, Step: 484/655, Loss: 2.209640, Accuracy: 18.44%\n",
            "Epoch: 7, Step: 485/655, Loss: 2.209820, Accuracy: 18.43%\n",
            "Epoch: 7, Step: 486/655, Loss: 2.210010, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 487/655, Loss: 2.209995, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 488/655, Loss: 2.210088, Accuracy: 18.39%\n",
            "Epoch: 7, Step: 489/655, Loss: 2.210068, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 490/655, Loss: 2.210243, Accuracy: 18.37%\n",
            "Epoch: 7, Step: 491/655, Loss: 2.210009, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 492/655, Loss: 2.210002, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 493/655, Loss: 2.210039, Accuracy: 18.39%\n",
            "Epoch: 7, Step: 494/655, Loss: 2.210052, Accuracy: 18.38%\n",
            "Epoch: 7, Step: 495/655, Loss: 2.209946, Accuracy: 18.38%\n",
            "Epoch: 7, Step: 496/655, Loss: 2.209888, Accuracy: 18.38%\n",
            "Epoch: 7, Step: 497/655, Loss: 2.210205, Accuracy: 18.37%\n",
            "Epoch: 7, Step: 498/655, Loss: 2.210354, Accuracy: 18.35%\n",
            "Epoch: 7, Step: 499/655, Loss: 2.210022, Accuracy: 18.37%\n",
            "Epoch: 7, Step: 500/655, Loss: 2.209927, Accuracy: 18.36%\n",
            "Epoch: 7, Step: 501/655, Loss: 2.209696, Accuracy: 18.38%\n",
            "Epoch: 7, Step: 502/655, Loss: 2.209908, Accuracy: 18.38%\n",
            "Epoch: 7, Step: 503/655, Loss: 2.209986, Accuracy: 18.35%\n",
            "Epoch: 7, Step: 504/655, Loss: 2.210012, Accuracy: 18.35%\n",
            "Epoch: 7, Step: 505/655, Loss: 2.210027, Accuracy: 18.34%\n",
            "Epoch: 7, Step: 506/655, Loss: 2.210062, Accuracy: 18.33%\n",
            "Epoch: 7, Step: 507/655, Loss: 2.210175, Accuracy: 18.32%\n",
            "Epoch: 7, Step: 508/655, Loss: 2.210201, Accuracy: 18.33%\n",
            "Epoch: 7, Step: 509/655, Loss: 2.210052, Accuracy: 18.34%\n",
            "Epoch: 7, Step: 510/655, Loss: 2.210013, Accuracy: 18.35%\n",
            "Epoch: 7, Step: 511/655, Loss: 2.209979, Accuracy: 18.34%\n",
            "Epoch: 7, Step: 512/655, Loss: 2.209737, Accuracy: 18.36%\n",
            "Epoch: 7, Step: 513/655, Loss: 2.209691, Accuracy: 18.36%\n",
            "Epoch: 7, Step: 514/655, Loss: 2.209506, Accuracy: 18.37%\n",
            "Epoch: 7, Step: 515/655, Loss: 2.209638, Accuracy: 18.37%\n",
            "Epoch: 7, Step: 516/655, Loss: 2.209635, Accuracy: 18.37%\n",
            "Epoch: 7, Step: 517/655, Loss: 2.209656, Accuracy: 18.38%\n",
            "Epoch: 7, Step: 518/655, Loss: 2.209701, Accuracy: 18.36%\n",
            "Epoch: 7, Step: 519/655, Loss: 2.209562, Accuracy: 18.38%\n",
            "Epoch: 7, Step: 520/655, Loss: 2.209854, Accuracy: 18.37%\n",
            "Epoch: 7, Step: 521/655, Loss: 2.209959, Accuracy: 18.37%\n",
            "Epoch: 7, Step: 522/655, Loss: 2.209788, Accuracy: 18.36%\n",
            "Epoch: 7, Step: 523/655, Loss: 2.209678, Accuracy: 18.37%\n",
            "Epoch: 7, Step: 524/655, Loss: 2.209712, Accuracy: 18.39%\n",
            "Epoch: 7, Step: 525/655, Loss: 2.209434, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 526/655, Loss: 2.209786, Accuracy: 18.39%\n",
            "Epoch: 7, Step: 527/655, Loss: 2.209986, Accuracy: 18.38%\n",
            "Epoch: 7, Step: 528/655, Loss: 2.209633, Accuracy: 18.41%\n",
            "Epoch: 7, Step: 529/655, Loss: 2.209536, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 530/655, Loss: 2.209412, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 531/655, Loss: 2.209539, Accuracy: 18.41%\n",
            "Epoch: 7, Step: 532/655, Loss: 2.209634, Accuracy: 18.39%\n",
            "Epoch: 7, Step: 533/655, Loss: 2.209530, Accuracy: 18.40%\n",
            "Epoch: 7, Step: 534/655, Loss: 2.209581, Accuracy: 18.39%\n",
            "Epoch: 7, Step: 535/655, Loss: 2.209385, Accuracy: 18.41%\n",
            "Epoch: 7, Step: 536/655, Loss: 2.209438, Accuracy: 18.41%\n",
            "Epoch: 7, Step: 537/655, Loss: 2.209335, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 538/655, Loss: 2.209241, Accuracy: 18.42%\n",
            "Epoch: 7, Step: 539/655, Loss: 2.209066, Accuracy: 18.44%\n",
            "Epoch: 7, Step: 540/655, Loss: 2.209046, Accuracy: 18.44%\n",
            "Epoch: 7, Step: 541/655, Loss: 2.208928, Accuracy: 18.46%\n",
            "Epoch: 7, Step: 542/655, Loss: 2.208734, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 543/655, Loss: 2.208783, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 544/655, Loss: 2.208920, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 545/655, Loss: 2.209034, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 546/655, Loss: 2.208861, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 547/655, Loss: 2.208801, Accuracy: 18.46%\n",
            "Epoch: 7, Step: 548/655, Loss: 2.208719, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 549/655, Loss: 2.208864, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 550/655, Loss: 2.208864, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 551/655, Loss: 2.208715, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 552/655, Loss: 2.208838, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 553/655, Loss: 2.208797, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 554/655, Loss: 2.208915, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 555/655, Loss: 2.209079, Accuracy: 18.45%\n",
            "Epoch: 7, Step: 556/655, Loss: 2.209056, Accuracy: 18.46%\n",
            "Epoch: 7, Step: 557/655, Loss: 2.209018, Accuracy: 18.44%\n",
            "Epoch: 7, Step: 558/655, Loss: 2.209017, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 559/655, Loss: 2.208865, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 560/655, Loss: 2.208742, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 561/655, Loss: 2.208589, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 562/655, Loss: 2.208648, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 563/655, Loss: 2.208964, Accuracy: 18.45%\n",
            "Epoch: 7, Step: 564/655, Loss: 2.209096, Accuracy: 18.45%\n",
            "Epoch: 7, Step: 565/655, Loss: 2.208927, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 566/655, Loss: 2.208895, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 567/655, Loss: 2.208900, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 568/655, Loss: 2.208817, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 569/655, Loss: 2.208464, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 570/655, Loss: 2.208414, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 571/655, Loss: 2.208391, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 572/655, Loss: 2.208623, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 573/655, Loss: 2.208762, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 574/655, Loss: 2.209107, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 575/655, Loss: 2.209304, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 576/655, Loss: 2.209350, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 577/655, Loss: 2.209262, Accuracy: 18.51%\n",
            "Epoch: 7, Step: 578/655, Loss: 2.209445, Accuracy: 18.50%\n",
            "Epoch: 7, Step: 579/655, Loss: 2.209502, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 580/655, Loss: 2.209264, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 581/655, Loss: 2.209323, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 582/655, Loss: 2.209294, Accuracy: 18.50%\n",
            "Epoch: 7, Step: 583/655, Loss: 2.209436, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 584/655, Loss: 2.209125, Accuracy: 18.51%\n",
            "Epoch: 7, Step: 585/655, Loss: 2.209180, Accuracy: 18.50%\n",
            "Epoch: 7, Step: 586/655, Loss: 2.209317, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 587/655, Loss: 2.209495, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 588/655, Loss: 2.209444, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 589/655, Loss: 2.209609, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 590/655, Loss: 2.209699, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 591/655, Loss: 2.209549, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 592/655, Loss: 2.209477, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 593/655, Loss: 2.209407, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 594/655, Loss: 2.209250, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 595/655, Loss: 2.209338, Accuracy: 18.47%\n",
            "Epoch: 7, Step: 596/655, Loss: 2.209253, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 597/655, Loss: 2.209306, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 598/655, Loss: 2.209156, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 599/655, Loss: 2.209082, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 600/655, Loss: 2.208778, Accuracy: 18.51%\n",
            "Epoch: 7, Step: 601/655, Loss: 2.208785, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 602/655, Loss: 2.208572, Accuracy: 18.50%\n",
            "Epoch: 7, Step: 603/655, Loss: 2.208731, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 604/655, Loss: 2.208796, Accuracy: 18.50%\n",
            "Epoch: 7, Step: 605/655, Loss: 2.208581, Accuracy: 18.50%\n",
            "Epoch: 7, Step: 606/655, Loss: 2.208532, Accuracy: 18.50%\n",
            "Epoch: 7, Step: 607/655, Loss: 2.208622, Accuracy: 18.49%\n",
            "Epoch: 7, Step: 608/655, Loss: 2.208720, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 609/655, Loss: 2.208586, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 610/655, Loss: 2.208627, Accuracy: 18.48%\n",
            "Epoch: 7, Step: 611/655, Loss: 2.208429, Accuracy: 18.50%\n",
            "Epoch: 7, Step: 612/655, Loss: 2.208517, Accuracy: 18.50%\n",
            "Epoch: 7, Step: 613/655, Loss: 2.208649, Accuracy: 18.51%\n",
            "Epoch: 7, Step: 614/655, Loss: 2.208685, Accuracy: 18.51%\n",
            "Epoch: 7, Step: 615/655, Loss: 2.208657, Accuracy: 18.52%\n",
            "Epoch: 7, Step: 616/655, Loss: 2.208714, Accuracy: 18.53%\n",
            "Epoch: 7, Step: 617/655, Loss: 2.208621, Accuracy: 18.52%\n",
            "Epoch: 7, Step: 618/655, Loss: 2.208679, Accuracy: 18.52%\n",
            "Epoch: 7, Step: 619/655, Loss: 2.208495, Accuracy: 18.52%\n",
            "Epoch: 7, Step: 620/655, Loss: 2.208702, Accuracy: 18.52%\n",
            "Epoch: 7, Step: 621/655, Loss: 2.208606, Accuracy: 18.54%\n",
            "Epoch: 7, Step: 622/655, Loss: 2.208755, Accuracy: 18.55%\n",
            "Epoch: 7, Step: 623/655, Loss: 2.208646, Accuracy: 18.55%\n",
            "Epoch: 7, Step: 624/655, Loss: 2.208671, Accuracy: 18.54%\n",
            "Epoch: 7, Step: 625/655, Loss: 2.208681, Accuracy: 18.56%\n",
            "Epoch: 7, Step: 626/655, Loss: 2.208506, Accuracy: 18.58%\n",
            "Epoch: 7, Step: 627/655, Loss: 2.208388, Accuracy: 18.58%\n",
            "Epoch: 7, Step: 628/655, Loss: 2.208347, Accuracy: 18.58%\n",
            "Epoch: 7, Step: 629/655, Loss: 2.208227, Accuracy: 18.58%\n",
            "Epoch: 7, Step: 630/655, Loss: 2.208313, Accuracy: 18.58%\n",
            "Epoch: 7, Step: 631/655, Loss: 2.208374, Accuracy: 18.56%\n",
            "Epoch: 7, Step: 632/655, Loss: 2.208305, Accuracy: 18.56%\n",
            "Epoch: 7, Step: 633/655, Loss: 2.208095, Accuracy: 18.56%\n",
            "Epoch: 7, Step: 634/655, Loss: 2.208130, Accuracy: 18.57%\n",
            "Epoch: 7, Step: 635/655, Loss: 2.208039, Accuracy: 18.57%\n",
            "Epoch: 7, Step: 636/655, Loss: 2.207976, Accuracy: 18.57%\n",
            "Epoch: 7, Step: 637/655, Loss: 2.208218, Accuracy: 18.57%\n",
            "Epoch: 7, Step: 638/655, Loss: 2.207993, Accuracy: 18.58%\n",
            "Epoch: 7, Step: 639/655, Loss: 2.208079, Accuracy: 18.56%\n",
            "Epoch: 7, Step: 640/655, Loss: 2.208082, Accuracy: 18.56%\n",
            "Epoch: 7, Step: 641/655, Loss: 2.208321, Accuracy: 18.55%\n",
            "Epoch: 7, Step: 642/655, Loss: 2.208326, Accuracy: 18.56%\n",
            "Epoch: 7, Step: 643/655, Loss: 2.208427, Accuracy: 18.54%\n",
            "Epoch: 7, Step: 644/655, Loss: 2.208475, Accuracy: 18.54%\n",
            "Epoch: 7, Step: 645/655, Loss: 2.208312, Accuracy: 18.55%\n",
            "Epoch: 7, Step: 646/655, Loss: 2.208316, Accuracy: 18.56%\n",
            "Epoch: 7, Step: 647/655, Loss: 2.208335, Accuracy: 18.58%\n",
            "Epoch: 7, Step: 648/655, Loss: 2.208465, Accuracy: 18.57%\n",
            "Epoch: 7, Step: 649/655, Loss: 2.208338, Accuracy: 18.56%\n",
            "Epoch: 7, Step: 650/655, Loss: 2.208262, Accuracy: 18.57%\n",
            "Epoch: 7, Step: 651/655, Loss: 2.208448, Accuracy: 18.57%\n",
            "Epoch: 7, Step: 652/655, Loss: 2.208288, Accuracy: 18.55%\n",
            "Epoch: 7, Step: 653/655, Loss: 2.208307, Accuracy: 18.56%\n",
            "Epoch: 7, Step: 654/655, Loss: 2.208142, Accuracy: 18.57%\n",
            "Epoch: 7, Step: 655/655, Loss: 2.208103, Accuracy: 18.57%\n",
            "Epoch: 8, Step: 1/655, Loss: 2.229965, Accuracy: 12.50%\n",
            "Epoch: 8, Step: 2/655, Loss: 2.260129, Accuracy: 12.50%\n",
            "Epoch: 8, Step: 3/655, Loss: 2.252047, Accuracy: 13.54%\n",
            "Epoch: 8, Step: 4/655, Loss: 2.199919, Accuracy: 16.41%\n",
            "Epoch: 8, Step: 5/655, Loss: 2.214602, Accuracy: 16.25%\n",
            "Epoch: 8, Step: 6/655, Loss: 2.205245, Accuracy: 16.67%\n",
            "Epoch: 8, Step: 7/655, Loss: 2.212783, Accuracy: 16.07%\n",
            "Epoch: 8, Step: 8/655, Loss: 2.209437, Accuracy: 16.41%\n",
            "Epoch: 8, Step: 9/655, Loss: 2.214241, Accuracy: 16.67%\n",
            "Epoch: 8, Step: 10/655, Loss: 2.226585, Accuracy: 16.25%\n",
            "Epoch: 8, Step: 11/655, Loss: 2.216500, Accuracy: 16.19%\n",
            "Epoch: 8, Step: 12/655, Loss: 2.219913, Accuracy: 15.89%\n",
            "Epoch: 8, Step: 13/655, Loss: 2.220647, Accuracy: 16.11%\n",
            "Epoch: 8, Step: 14/655, Loss: 2.210911, Accuracy: 16.52%\n",
            "Epoch: 8, Step: 15/655, Loss: 2.208720, Accuracy: 17.08%\n",
            "Epoch: 8, Step: 16/655, Loss: 2.207446, Accuracy: 16.99%\n",
            "Epoch: 8, Step: 17/655, Loss: 2.205535, Accuracy: 16.54%\n",
            "Epoch: 8, Step: 18/655, Loss: 2.206712, Accuracy: 16.67%\n",
            "Epoch: 8, Step: 19/655, Loss: 2.201315, Accuracy: 17.11%\n",
            "Epoch: 8, Step: 20/655, Loss: 2.200371, Accuracy: 17.66%\n",
            "Epoch: 8, Step: 21/655, Loss: 2.198192, Accuracy: 17.56%\n",
            "Epoch: 8, Step: 22/655, Loss: 2.195370, Accuracy: 17.33%\n",
            "Epoch: 8, Step: 23/655, Loss: 2.190902, Accuracy: 17.66%\n",
            "Epoch: 8, Step: 24/655, Loss: 2.189071, Accuracy: 18.10%\n",
            "Epoch: 8, Step: 25/655, Loss: 2.189459, Accuracy: 17.75%\n",
            "Epoch: 8, Step: 26/655, Loss: 2.187155, Accuracy: 18.03%\n",
            "Epoch: 8, Step: 27/655, Loss: 2.190223, Accuracy: 17.94%\n",
            "Epoch: 8, Step: 28/655, Loss: 2.191552, Accuracy: 17.86%\n",
            "Epoch: 8, Step: 29/655, Loss: 2.193569, Accuracy: 18.00%\n",
            "Epoch: 8, Step: 30/655, Loss: 2.194434, Accuracy: 18.12%\n",
            "Epoch: 8, Step: 31/655, Loss: 2.196211, Accuracy: 17.94%\n",
            "Epoch: 8, Step: 32/655, Loss: 2.197330, Accuracy: 17.77%\n",
            "Epoch: 8, Step: 33/655, Loss: 2.196232, Accuracy: 17.99%\n",
            "Epoch: 8, Step: 34/655, Loss: 2.195770, Accuracy: 18.11%\n",
            "Epoch: 8, Step: 35/655, Loss: 2.194906, Accuracy: 18.04%\n",
            "Epoch: 8, Step: 36/655, Loss: 2.195276, Accuracy: 17.88%\n",
            "Epoch: 8, Step: 37/655, Loss: 2.195607, Accuracy: 17.82%\n",
            "Epoch: 8, Step: 38/655, Loss: 2.198466, Accuracy: 17.76%\n",
            "Epoch: 8, Step: 39/655, Loss: 2.199362, Accuracy: 17.63%\n",
            "Epoch: 8, Step: 40/655, Loss: 2.202408, Accuracy: 17.50%\n",
            "Epoch: 8, Step: 41/655, Loss: 2.203999, Accuracy: 17.45%\n",
            "Epoch: 8, Step: 42/655, Loss: 2.206326, Accuracy: 17.49%\n",
            "Epoch: 8, Step: 43/655, Loss: 2.208926, Accuracy: 17.37%\n",
            "Epoch: 8, Step: 44/655, Loss: 2.206867, Accuracy: 17.33%\n",
            "Epoch: 8, Step: 45/655, Loss: 2.202859, Accuracy: 17.64%\n",
            "Epoch: 8, Step: 46/655, Loss: 2.202737, Accuracy: 17.66%\n",
            "Epoch: 8, Step: 47/655, Loss: 2.202536, Accuracy: 17.55%\n",
            "Epoch: 8, Step: 48/655, Loss: 2.203742, Accuracy: 17.51%\n",
            "Epoch: 8, Step: 49/655, Loss: 2.205573, Accuracy: 17.41%\n",
            "Epoch: 8, Step: 50/655, Loss: 2.208341, Accuracy: 17.19%\n",
            "Epoch: 8, Step: 51/655, Loss: 2.208807, Accuracy: 17.03%\n",
            "Epoch: 8, Step: 52/655, Loss: 2.210166, Accuracy: 17.19%\n",
            "Epoch: 8, Step: 53/655, Loss: 2.210077, Accuracy: 17.22%\n",
            "Epoch: 8, Step: 54/655, Loss: 2.208662, Accuracy: 17.30%\n",
            "Epoch: 8, Step: 55/655, Loss: 2.208500, Accuracy: 17.39%\n",
            "Epoch: 8, Step: 56/655, Loss: 2.207635, Accuracy: 17.30%\n",
            "Epoch: 8, Step: 57/655, Loss: 2.209098, Accuracy: 17.21%\n",
            "Epoch: 8, Step: 58/655, Loss: 2.210168, Accuracy: 17.13%\n",
            "Epoch: 8, Step: 59/655, Loss: 2.209849, Accuracy: 17.11%\n",
            "Epoch: 8, Step: 60/655, Loss: 2.210881, Accuracy: 17.19%\n",
            "Epoch: 8, Step: 61/655, Loss: 2.209867, Accuracy: 17.16%\n",
            "Epoch: 8, Step: 62/655, Loss: 2.209987, Accuracy: 17.34%\n",
            "Epoch: 8, Step: 63/655, Loss: 2.209463, Accuracy: 17.46%\n",
            "Epoch: 8, Step: 64/655, Loss: 2.209290, Accuracy: 17.38%\n",
            "Epoch: 8, Step: 65/655, Loss: 2.205333, Accuracy: 17.55%\n",
            "Epoch: 8, Step: 66/655, Loss: 2.206264, Accuracy: 17.57%\n",
            "Epoch: 8, Step: 67/655, Loss: 2.205731, Accuracy: 17.44%\n",
            "Epoch: 8, Step: 68/655, Loss: 2.206340, Accuracy: 17.42%\n",
            "Epoch: 8, Step: 69/655, Loss: 2.207141, Accuracy: 17.30%\n",
            "Epoch: 8, Step: 70/655, Loss: 2.205773, Accuracy: 17.23%\n",
            "Epoch: 8, Step: 71/655, Loss: 2.204492, Accuracy: 17.17%\n",
            "Epoch: 8, Step: 72/655, Loss: 2.204547, Accuracy: 17.06%\n",
            "Epoch: 8, Step: 73/655, Loss: 2.203229, Accuracy: 17.21%\n",
            "Epoch: 8, Step: 74/655, Loss: 2.204613, Accuracy: 17.19%\n",
            "Epoch: 8, Step: 75/655, Loss: 2.204289, Accuracy: 17.29%\n",
            "Epoch: 8, Step: 76/655, Loss: 2.204279, Accuracy: 17.23%\n",
            "Epoch: 8, Step: 77/655, Loss: 2.204457, Accuracy: 17.29%\n",
            "Epoch: 8, Step: 78/655, Loss: 2.203806, Accuracy: 17.27%\n",
            "Epoch: 8, Step: 79/655, Loss: 2.203100, Accuracy: 17.25%\n",
            "Epoch: 8, Step: 80/655, Loss: 2.203615, Accuracy: 17.30%\n",
            "Epoch: 8, Step: 81/655, Loss: 2.202511, Accuracy: 17.32%\n",
            "Epoch: 8, Step: 82/655, Loss: 2.201407, Accuracy: 17.38%\n",
            "Epoch: 8, Step: 83/655, Loss: 2.202637, Accuracy: 17.32%\n",
            "Epoch: 8, Step: 84/655, Loss: 2.204123, Accuracy: 17.22%\n",
            "Epoch: 8, Step: 85/655, Loss: 2.203573, Accuracy: 17.35%\n",
            "Epoch: 8, Step: 86/655, Loss: 2.202208, Accuracy: 17.41%\n",
            "Epoch: 8, Step: 87/655, Loss: 2.202490, Accuracy: 17.42%\n",
            "Epoch: 8, Step: 88/655, Loss: 2.202717, Accuracy: 17.37%\n",
            "Epoch: 8, Step: 89/655, Loss: 2.202456, Accuracy: 17.45%\n",
            "Epoch: 8, Step: 90/655, Loss: 2.203612, Accuracy: 17.29%\n",
            "Epoch: 8, Step: 91/655, Loss: 2.204968, Accuracy: 17.27%\n",
            "Epoch: 8, Step: 92/655, Loss: 2.205380, Accuracy: 17.22%\n",
            "Epoch: 8, Step: 93/655, Loss: 2.204584, Accuracy: 17.37%\n",
            "Epoch: 8, Step: 94/655, Loss: 2.203989, Accuracy: 17.45%\n",
            "Epoch: 8, Step: 95/655, Loss: 2.203654, Accuracy: 17.50%\n",
            "Epoch: 8, Step: 96/655, Loss: 2.203788, Accuracy: 17.48%\n",
            "Epoch: 8, Step: 97/655, Loss: 2.205233, Accuracy: 17.36%\n",
            "Epoch: 8, Step: 98/655, Loss: 2.205420, Accuracy: 17.41%\n",
            "Epoch: 8, Step: 99/655, Loss: 2.203475, Accuracy: 17.49%\n",
            "Epoch: 8, Step: 100/655, Loss: 2.203447, Accuracy: 17.56%\n",
            "Epoch: 8, Step: 101/655, Loss: 2.202590, Accuracy: 17.64%\n",
            "Epoch: 8, Step: 102/655, Loss: 2.202735, Accuracy: 17.52%\n",
            "Epoch: 8, Step: 103/655, Loss: 2.202961, Accuracy: 17.45%\n",
            "Epoch: 8, Step: 104/655, Loss: 2.202503, Accuracy: 17.46%\n",
            "Epoch: 8, Step: 105/655, Loss: 2.203392, Accuracy: 17.50%\n",
            "Epoch: 8, Step: 106/655, Loss: 2.204515, Accuracy: 17.48%\n",
            "Epoch: 8, Step: 107/655, Loss: 2.204588, Accuracy: 17.49%\n",
            "Epoch: 8, Step: 108/655, Loss: 2.204790, Accuracy: 17.45%\n",
            "Epoch: 8, Step: 109/655, Loss: 2.205896, Accuracy: 17.37%\n",
            "Epoch: 8, Step: 110/655, Loss: 2.206367, Accuracy: 17.36%\n",
            "Epoch: 8, Step: 111/655, Loss: 2.205342, Accuracy: 17.48%\n",
            "Epoch: 8, Step: 112/655, Loss: 2.204268, Accuracy: 17.52%\n",
            "Epoch: 8, Step: 113/655, Loss: 2.204610, Accuracy: 17.51%\n",
            "Epoch: 8, Step: 114/655, Loss: 2.204456, Accuracy: 17.52%\n",
            "Epoch: 8, Step: 115/655, Loss: 2.204308, Accuracy: 17.53%\n",
            "Epoch: 8, Step: 116/655, Loss: 2.203609, Accuracy: 17.51%\n",
            "Epoch: 8, Step: 117/655, Loss: 2.202819, Accuracy: 17.47%\n",
            "Epoch: 8, Step: 118/655, Loss: 2.202396, Accuracy: 17.45%\n",
            "Epoch: 8, Step: 119/655, Loss: 2.203072, Accuracy: 17.33%\n",
            "Epoch: 8, Step: 120/655, Loss: 2.202194, Accuracy: 17.34%\n",
            "Epoch: 8, Step: 121/655, Loss: 2.201886, Accuracy: 17.41%\n",
            "Epoch: 8, Step: 122/655, Loss: 2.202078, Accuracy: 17.39%\n",
            "Epoch: 8, Step: 123/655, Loss: 2.201516, Accuracy: 17.45%\n",
            "Epoch: 8, Step: 124/655, Loss: 2.202921, Accuracy: 17.41%\n",
            "Epoch: 8, Step: 125/655, Loss: 2.203200, Accuracy: 17.45%\n",
            "Epoch: 8, Step: 126/655, Loss: 2.202264, Accuracy: 17.51%\n",
            "Epoch: 8, Step: 127/655, Loss: 2.202727, Accuracy: 17.57%\n",
            "Epoch: 8, Step: 128/655, Loss: 2.203105, Accuracy: 17.60%\n",
            "Epoch: 8, Step: 129/655, Loss: 2.204127, Accuracy: 17.54%\n",
            "Epoch: 8, Step: 130/655, Loss: 2.203673, Accuracy: 17.57%\n",
            "Epoch: 8, Step: 131/655, Loss: 2.204575, Accuracy: 17.51%\n",
            "Epoch: 8, Step: 132/655, Loss: 2.204356, Accuracy: 17.47%\n",
            "Epoch: 8, Step: 133/655, Loss: 2.204193, Accuracy: 17.53%\n",
            "Epoch: 8, Step: 134/655, Loss: 2.203655, Accuracy: 17.51%\n",
            "Epoch: 8, Step: 135/655, Loss: 2.203573, Accuracy: 17.62%\n",
            "Epoch: 8, Step: 136/655, Loss: 2.203193, Accuracy: 17.65%\n",
            "Epoch: 8, Step: 137/655, Loss: 2.203575, Accuracy: 17.61%\n",
            "Epoch: 8, Step: 138/655, Loss: 2.204251, Accuracy: 17.62%\n",
            "Epoch: 8, Step: 139/655, Loss: 2.204023, Accuracy: 17.72%\n",
            "Epoch: 8, Step: 140/655, Loss: 2.204208, Accuracy: 17.70%\n",
            "Epoch: 8, Step: 141/655, Loss: 2.204456, Accuracy: 17.80%\n",
            "Epoch: 8, Step: 142/655, Loss: 2.204251, Accuracy: 17.85%\n",
            "Epoch: 8, Step: 143/655, Loss: 2.204364, Accuracy: 17.83%\n",
            "Epoch: 8, Step: 144/655, Loss: 2.203351, Accuracy: 17.90%\n",
            "Epoch: 8, Step: 145/655, Loss: 2.203378, Accuracy: 17.93%\n",
            "Epoch: 8, Step: 146/655, Loss: 2.203703, Accuracy: 17.87%\n",
            "Epoch: 8, Step: 147/655, Loss: 2.203163, Accuracy: 17.94%\n",
            "Epoch: 8, Step: 148/655, Loss: 2.203257, Accuracy: 17.93%\n",
            "Epoch: 8, Step: 149/655, Loss: 2.203181, Accuracy: 18.02%\n",
            "Epoch: 8, Step: 150/655, Loss: 2.203365, Accuracy: 18.00%\n",
            "Epoch: 8, Step: 151/655, Loss: 2.202903, Accuracy: 18.00%\n",
            "Epoch: 8, Step: 152/655, Loss: 2.202836, Accuracy: 18.13%\n",
            "Epoch: 8, Step: 153/655, Loss: 2.203017, Accuracy: 18.10%\n",
            "Epoch: 8, Step: 154/655, Loss: 2.203794, Accuracy: 18.04%\n",
            "Epoch: 8, Step: 155/655, Loss: 2.203633, Accuracy: 18.06%\n",
            "Epoch: 8, Step: 156/655, Loss: 2.203494, Accuracy: 18.13%\n",
            "Epoch: 8, Step: 157/655, Loss: 2.204116, Accuracy: 18.07%\n",
            "Epoch: 8, Step: 158/655, Loss: 2.204832, Accuracy: 18.08%\n",
            "Epoch: 8, Step: 159/655, Loss: 2.204865, Accuracy: 18.08%\n",
            "Epoch: 8, Step: 160/655, Loss: 2.204429, Accuracy: 18.05%\n",
            "Epoch: 8, Step: 161/655, Loss: 2.204436, Accuracy: 18.01%\n",
            "Epoch: 8, Step: 162/655, Loss: 2.204421, Accuracy: 18.02%\n",
            "Epoch: 8, Step: 163/655, Loss: 2.203687, Accuracy: 18.08%\n",
            "Epoch: 8, Step: 164/655, Loss: 2.204363, Accuracy: 18.08%\n",
            "Epoch: 8, Step: 165/655, Loss: 2.204476, Accuracy: 18.12%\n",
            "Epoch: 8, Step: 166/655, Loss: 2.204299, Accuracy: 18.13%\n",
            "Epoch: 8, Step: 167/655, Loss: 2.204282, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 168/655, Loss: 2.204319, Accuracy: 18.17%\n",
            "Epoch: 8, Step: 169/655, Loss: 2.204148, Accuracy: 18.25%\n",
            "Epoch: 8, Step: 170/655, Loss: 2.204703, Accuracy: 18.24%\n",
            "Epoch: 8, Step: 171/655, Loss: 2.205387, Accuracy: 18.24%\n",
            "Epoch: 8, Step: 172/655, Loss: 2.205117, Accuracy: 18.24%\n",
            "Epoch: 8, Step: 173/655, Loss: 2.205036, Accuracy: 18.19%\n",
            "Epoch: 8, Step: 174/655, Loss: 2.205295, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 175/655, Loss: 2.204802, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 176/655, Loss: 2.204473, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 177/655, Loss: 2.204686, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 178/655, Loss: 2.204860, Accuracy: 18.26%\n",
            "Epoch: 8, Step: 179/655, Loss: 2.205383, Accuracy: 18.23%\n",
            "Epoch: 8, Step: 180/655, Loss: 2.204641, Accuracy: 18.26%\n",
            "Epoch: 8, Step: 181/655, Loss: 2.204528, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 182/655, Loss: 2.203963, Accuracy: 18.34%\n",
            "Epoch: 8, Step: 183/655, Loss: 2.204409, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 184/655, Loss: 2.204211, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 185/655, Loss: 2.203393, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 186/655, Loss: 2.203348, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 187/655, Loss: 2.203129, Accuracy: 18.33%\n",
            "Epoch: 8, Step: 188/655, Loss: 2.203693, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 189/655, Loss: 2.203568, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 190/655, Loss: 2.204054, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 191/655, Loss: 2.204647, Accuracy: 18.24%\n",
            "Epoch: 8, Step: 192/655, Loss: 2.204653, Accuracy: 18.23%\n",
            "Epoch: 8, Step: 193/655, Loss: 2.205405, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 194/655, Loss: 2.205350, Accuracy: 18.14%\n",
            "Epoch: 8, Step: 195/655, Loss: 2.205999, Accuracy: 18.06%\n",
            "Epoch: 8, Step: 196/655, Loss: 2.206400, Accuracy: 18.02%\n",
            "Epoch: 8, Step: 197/655, Loss: 2.206048, Accuracy: 18.02%\n",
            "Epoch: 8, Step: 198/655, Loss: 2.206176, Accuracy: 17.99%\n",
            "Epoch: 8, Step: 199/655, Loss: 2.206376, Accuracy: 17.95%\n",
            "Epoch: 8, Step: 200/655, Loss: 2.206803, Accuracy: 17.92%\n",
            "Epoch: 8, Step: 201/655, Loss: 2.206835, Accuracy: 17.89%\n",
            "Epoch: 8, Step: 202/655, Loss: 2.206529, Accuracy: 17.88%\n",
            "Epoch: 8, Step: 203/655, Loss: 2.206754, Accuracy: 17.87%\n",
            "Epoch: 8, Step: 204/655, Loss: 2.206260, Accuracy: 17.86%\n",
            "Epoch: 8, Step: 205/655, Loss: 2.206395, Accuracy: 17.91%\n",
            "Epoch: 8, Step: 206/655, Loss: 2.206509, Accuracy: 17.93%\n",
            "Epoch: 8, Step: 207/655, Loss: 2.206662, Accuracy: 17.93%\n",
            "Epoch: 8, Step: 208/655, Loss: 2.206553, Accuracy: 17.98%\n",
            "Epoch: 8, Step: 209/655, Loss: 2.205930, Accuracy: 17.99%\n",
            "Epoch: 8, Step: 210/655, Loss: 2.206776, Accuracy: 17.93%\n",
            "Epoch: 8, Step: 211/655, Loss: 2.207304, Accuracy: 17.91%\n",
            "Epoch: 8, Step: 212/655, Loss: 2.206969, Accuracy: 17.87%\n",
            "Epoch: 8, Step: 213/655, Loss: 2.207368, Accuracy: 17.87%\n",
            "Epoch: 8, Step: 214/655, Loss: 2.206942, Accuracy: 17.93%\n",
            "Epoch: 8, Step: 215/655, Loss: 2.207102, Accuracy: 17.95%\n",
            "Epoch: 8, Step: 216/655, Loss: 2.206855, Accuracy: 17.97%\n",
            "Epoch: 8, Step: 217/655, Loss: 2.206805, Accuracy: 17.99%\n",
            "Epoch: 8, Step: 218/655, Loss: 2.206488, Accuracy: 17.96%\n",
            "Epoch: 8, Step: 219/655, Loss: 2.206506, Accuracy: 17.91%\n",
            "Epoch: 8, Step: 220/655, Loss: 2.206157, Accuracy: 17.95%\n",
            "Epoch: 8, Step: 221/655, Loss: 2.205884, Accuracy: 17.93%\n",
            "Epoch: 8, Step: 222/655, Loss: 2.205955, Accuracy: 17.96%\n",
            "Epoch: 8, Step: 223/655, Loss: 2.206040, Accuracy: 17.95%\n",
            "Epoch: 8, Step: 224/655, Loss: 2.206203, Accuracy: 17.94%\n",
            "Epoch: 8, Step: 225/655, Loss: 2.206379, Accuracy: 17.94%\n",
            "Epoch: 8, Step: 226/655, Loss: 2.206016, Accuracy: 18.02%\n",
            "Epoch: 8, Step: 227/655, Loss: 2.206111, Accuracy: 18.03%\n",
            "Epoch: 8, Step: 228/655, Loss: 2.206581, Accuracy: 18.05%\n",
            "Epoch: 8, Step: 229/655, Loss: 2.206821, Accuracy: 18.07%\n",
            "Epoch: 8, Step: 230/655, Loss: 2.206169, Accuracy: 18.11%\n",
            "Epoch: 8, Step: 231/655, Loss: 2.205908, Accuracy: 18.10%\n",
            "Epoch: 8, Step: 232/655, Loss: 2.206358, Accuracy: 18.08%\n",
            "Epoch: 8, Step: 233/655, Loss: 2.206388, Accuracy: 18.11%\n",
            "Epoch: 8, Step: 234/655, Loss: 2.206054, Accuracy: 18.10%\n",
            "Epoch: 8, Step: 235/655, Loss: 2.206211, Accuracy: 18.07%\n",
            "Epoch: 8, Step: 236/655, Loss: 2.206198, Accuracy: 18.06%\n",
            "Epoch: 8, Step: 237/655, Loss: 2.206514, Accuracy: 18.04%\n",
            "Epoch: 8, Step: 238/655, Loss: 2.206574, Accuracy: 18.05%\n",
            "Epoch: 8, Step: 239/655, Loss: 2.206617, Accuracy: 18.06%\n",
            "Epoch: 8, Step: 240/655, Loss: 2.206612, Accuracy: 18.03%\n",
            "Epoch: 8, Step: 241/655, Loss: 2.206738, Accuracy: 18.02%\n",
            "Epoch: 8, Step: 242/655, Loss: 2.206516, Accuracy: 18.03%\n",
            "Epoch: 8, Step: 243/655, Loss: 2.205966, Accuracy: 18.06%\n",
            "Epoch: 8, Step: 244/655, Loss: 2.206497, Accuracy: 18.02%\n",
            "Epoch: 8, Step: 245/655, Loss: 2.206368, Accuracy: 18.04%\n",
            "Epoch: 8, Step: 246/655, Loss: 2.206042, Accuracy: 18.04%\n",
            "Epoch: 8, Step: 247/655, Loss: 2.206238, Accuracy: 18.02%\n",
            "Epoch: 8, Step: 248/655, Loss: 2.205863, Accuracy: 18.02%\n",
            "Epoch: 8, Step: 249/655, Loss: 2.205816, Accuracy: 18.02%\n",
            "Epoch: 8, Step: 250/655, Loss: 2.205475, Accuracy: 18.04%\n",
            "Epoch: 8, Step: 251/655, Loss: 2.205615, Accuracy: 18.00%\n",
            "Epoch: 8, Step: 252/655, Loss: 2.205545, Accuracy: 18.01%\n",
            "Epoch: 8, Step: 253/655, Loss: 2.205217, Accuracy: 18.01%\n",
            "Epoch: 8, Step: 254/655, Loss: 2.204910, Accuracy: 18.02%\n",
            "Epoch: 8, Step: 255/655, Loss: 2.204733, Accuracy: 18.01%\n",
            "Epoch: 8, Step: 256/655, Loss: 2.204667, Accuracy: 18.03%\n",
            "Epoch: 8, Step: 257/655, Loss: 2.204816, Accuracy: 18.04%\n",
            "Epoch: 8, Step: 258/655, Loss: 2.205162, Accuracy: 18.05%\n",
            "Epoch: 8, Step: 259/655, Loss: 2.205466, Accuracy: 18.05%\n",
            "Epoch: 8, Step: 260/655, Loss: 2.205055, Accuracy: 18.04%\n",
            "Epoch: 8, Step: 261/655, Loss: 2.205310, Accuracy: 18.00%\n",
            "Epoch: 8, Step: 262/655, Loss: 2.205059, Accuracy: 18.02%\n",
            "Epoch: 8, Step: 263/655, Loss: 2.205361, Accuracy: 18.01%\n",
            "Epoch: 8, Step: 264/655, Loss: 2.205247, Accuracy: 18.00%\n",
            "Epoch: 8, Step: 265/655, Loss: 2.205270, Accuracy: 17.97%\n",
            "Epoch: 8, Step: 266/655, Loss: 2.205282, Accuracy: 17.99%\n",
            "Epoch: 8, Step: 267/655, Loss: 2.204814, Accuracy: 18.02%\n",
            "Epoch: 8, Step: 268/655, Loss: 2.204477, Accuracy: 18.00%\n",
            "Epoch: 8, Step: 269/655, Loss: 2.204601, Accuracy: 18.01%\n",
            "Epoch: 8, Step: 270/655, Loss: 2.204225, Accuracy: 18.04%\n",
            "Epoch: 8, Step: 271/655, Loss: 2.204241, Accuracy: 18.06%\n",
            "Epoch: 8, Step: 272/655, Loss: 2.204751, Accuracy: 18.03%\n",
            "Epoch: 8, Step: 273/655, Loss: 2.205073, Accuracy: 18.03%\n",
            "Epoch: 8, Step: 274/655, Loss: 2.204941, Accuracy: 18.05%\n",
            "Epoch: 8, Step: 275/655, Loss: 2.204955, Accuracy: 18.07%\n",
            "Epoch: 8, Step: 276/655, Loss: 2.205142, Accuracy: 18.04%\n",
            "Epoch: 8, Step: 277/655, Loss: 2.204610, Accuracy: 18.07%\n",
            "Epoch: 8, Step: 278/655, Loss: 2.204824, Accuracy: 18.04%\n",
            "Epoch: 8, Step: 279/655, Loss: 2.204896, Accuracy: 18.03%\n",
            "Epoch: 8, Step: 280/655, Loss: 2.205181, Accuracy: 18.05%\n",
            "Epoch: 8, Step: 281/655, Loss: 2.205640, Accuracy: 18.04%\n",
            "Epoch: 8, Step: 282/655, Loss: 2.205833, Accuracy: 18.04%\n",
            "Epoch: 8, Step: 283/655, Loss: 2.205837, Accuracy: 18.03%\n",
            "Epoch: 8, Step: 284/655, Loss: 2.205826, Accuracy: 18.05%\n",
            "Epoch: 8, Step: 285/655, Loss: 2.206154, Accuracy: 18.05%\n",
            "Epoch: 8, Step: 286/655, Loss: 2.205759, Accuracy: 18.09%\n",
            "Epoch: 8, Step: 287/655, Loss: 2.205676, Accuracy: 18.10%\n",
            "Epoch: 8, Step: 288/655, Loss: 2.205664, Accuracy: 18.10%\n",
            "Epoch: 8, Step: 289/655, Loss: 2.205545, Accuracy: 18.11%\n",
            "Epoch: 8, Step: 290/655, Loss: 2.205943, Accuracy: 18.11%\n",
            "Epoch: 8, Step: 291/655, Loss: 2.206089, Accuracy: 18.08%\n",
            "Epoch: 8, Step: 292/655, Loss: 2.205868, Accuracy: 18.13%\n",
            "Epoch: 8, Step: 293/655, Loss: 2.205771, Accuracy: 18.13%\n",
            "Epoch: 8, Step: 294/655, Loss: 2.205960, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 295/655, Loss: 2.205967, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 296/655, Loss: 2.206221, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 297/655, Loss: 2.205941, Accuracy: 18.16%\n",
            "Epoch: 8, Step: 298/655, Loss: 2.206165, Accuracy: 18.16%\n",
            "Epoch: 8, Step: 299/655, Loss: 2.206273, Accuracy: 18.16%\n",
            "Epoch: 8, Step: 300/655, Loss: 2.206116, Accuracy: 18.20%\n",
            "Epoch: 8, Step: 301/655, Loss: 2.206004, Accuracy: 18.22%\n",
            "Epoch: 8, Step: 302/655, Loss: 2.206106, Accuracy: 18.21%\n",
            "Epoch: 8, Step: 303/655, Loss: 2.205623, Accuracy: 18.22%\n",
            "Epoch: 8, Step: 304/655, Loss: 2.205455, Accuracy: 18.22%\n",
            "Epoch: 8, Step: 305/655, Loss: 2.205603, Accuracy: 18.21%\n",
            "Epoch: 8, Step: 306/655, Loss: 2.205746, Accuracy: 18.21%\n",
            "Epoch: 8, Step: 307/655, Loss: 2.205652, Accuracy: 18.22%\n",
            "Epoch: 8, Step: 308/655, Loss: 2.205824, Accuracy: 18.20%\n",
            "Epoch: 8, Step: 309/655, Loss: 2.205569, Accuracy: 18.24%\n",
            "Epoch: 8, Step: 310/655, Loss: 2.205604, Accuracy: 18.24%\n",
            "Epoch: 8, Step: 311/655, Loss: 2.205160, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 312/655, Loss: 2.205312, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 313/655, Loss: 2.205376, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 314/655, Loss: 2.205198, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 315/655, Loss: 2.205284, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 316/655, Loss: 2.205273, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 317/655, Loss: 2.205304, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 318/655, Loss: 2.205160, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 319/655, Loss: 2.205249, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 320/655, Loss: 2.205037, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 321/655, Loss: 2.204808, Accuracy: 18.33%\n",
            "Epoch: 8, Step: 322/655, Loss: 2.205073, Accuracy: 18.34%\n",
            "Epoch: 8, Step: 323/655, Loss: 2.204873, Accuracy: 18.37%\n",
            "Epoch: 8, Step: 324/655, Loss: 2.205147, Accuracy: 18.36%\n",
            "Epoch: 8, Step: 325/655, Loss: 2.205188, Accuracy: 18.38%\n",
            "Epoch: 8, Step: 326/655, Loss: 2.205149, Accuracy: 18.37%\n",
            "Epoch: 8, Step: 327/655, Loss: 2.205113, Accuracy: 18.36%\n",
            "Epoch: 8, Step: 328/655, Loss: 2.205430, Accuracy: 18.36%\n",
            "Epoch: 8, Step: 329/655, Loss: 2.205514, Accuracy: 18.35%\n",
            "Epoch: 8, Step: 330/655, Loss: 2.205589, Accuracy: 18.34%\n",
            "Epoch: 8, Step: 331/655, Loss: 2.205406, Accuracy: 18.36%\n",
            "Epoch: 8, Step: 332/655, Loss: 2.205164, Accuracy: 18.38%\n",
            "Epoch: 8, Step: 333/655, Loss: 2.205329, Accuracy: 18.37%\n",
            "Epoch: 8, Step: 334/655, Loss: 2.205594, Accuracy: 18.33%\n",
            "Epoch: 8, Step: 335/655, Loss: 2.205344, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 336/655, Loss: 2.205461, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 337/655, Loss: 2.205126, Accuracy: 18.33%\n",
            "Epoch: 8, Step: 338/655, Loss: 2.205185, Accuracy: 18.37%\n",
            "Epoch: 8, Step: 339/655, Loss: 2.204951, Accuracy: 18.40%\n",
            "Epoch: 8, Step: 340/655, Loss: 2.205029, Accuracy: 18.37%\n",
            "Epoch: 8, Step: 341/655, Loss: 2.204945, Accuracy: 18.38%\n",
            "Epoch: 8, Step: 342/655, Loss: 2.205270, Accuracy: 18.38%\n",
            "Epoch: 8, Step: 343/655, Loss: 2.205427, Accuracy: 18.37%\n",
            "Epoch: 8, Step: 344/655, Loss: 2.205773, Accuracy: 18.35%\n",
            "Epoch: 8, Step: 345/655, Loss: 2.205672, Accuracy: 18.38%\n",
            "Epoch: 8, Step: 346/655, Loss: 2.205469, Accuracy: 18.37%\n",
            "Epoch: 8, Step: 347/655, Loss: 2.205416, Accuracy: 18.37%\n",
            "Epoch: 8, Step: 348/655, Loss: 2.205251, Accuracy: 18.39%\n",
            "Epoch: 8, Step: 349/655, Loss: 2.205041, Accuracy: 18.40%\n",
            "Epoch: 8, Step: 350/655, Loss: 2.205527, Accuracy: 18.38%\n",
            "Epoch: 8, Step: 351/655, Loss: 2.205582, Accuracy: 18.38%\n",
            "Epoch: 8, Step: 352/655, Loss: 2.205729, Accuracy: 18.37%\n",
            "Epoch: 8, Step: 353/655, Loss: 2.205587, Accuracy: 18.37%\n",
            "Epoch: 8, Step: 354/655, Loss: 2.206043, Accuracy: 18.34%\n",
            "Epoch: 8, Step: 355/655, Loss: 2.205859, Accuracy: 18.33%\n",
            "Epoch: 8, Step: 356/655, Loss: 2.205844, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 357/655, Loss: 2.205784, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 358/655, Loss: 2.206225, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 359/655, Loss: 2.205871, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 360/655, Loss: 2.205453, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 361/655, Loss: 2.205308, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 362/655, Loss: 2.205620, Accuracy: 18.25%\n",
            "Epoch: 8, Step: 363/655, Loss: 2.205313, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 364/655, Loss: 2.205419, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 365/655, Loss: 2.205609, Accuracy: 18.25%\n",
            "Epoch: 8, Step: 366/655, Loss: 2.205827, Accuracy: 18.25%\n",
            "Epoch: 8, Step: 367/655, Loss: 2.205369, Accuracy: 18.26%\n",
            "Epoch: 8, Step: 368/655, Loss: 2.205396, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 369/655, Loss: 2.205169, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 370/655, Loss: 2.204948, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 371/655, Loss: 2.204747, Accuracy: 18.33%\n",
            "Epoch: 8, Step: 372/655, Loss: 2.204788, Accuracy: 18.34%\n",
            "Epoch: 8, Step: 373/655, Loss: 2.204896, Accuracy: 18.34%\n",
            "Epoch: 8, Step: 374/655, Loss: 2.204968, Accuracy: 18.33%\n",
            "Epoch: 8, Step: 375/655, Loss: 2.205307, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 376/655, Loss: 2.205344, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 377/655, Loss: 2.205359, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 378/655, Loss: 2.205365, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 379/655, Loss: 2.205367, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 380/655, Loss: 2.205423, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 381/655, Loss: 2.205037, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 382/655, Loss: 2.205139, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 383/655, Loss: 2.205075, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 384/655, Loss: 2.204960, Accuracy: 18.33%\n",
            "Epoch: 8, Step: 385/655, Loss: 2.204698, Accuracy: 18.33%\n",
            "Epoch: 8, Step: 386/655, Loss: 2.204784, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 387/655, Loss: 2.204919, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 388/655, Loss: 2.204994, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 389/655, Loss: 2.205239, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 390/655, Loss: 2.205320, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 391/655, Loss: 2.205653, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 392/655, Loss: 2.206138, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 393/655, Loss: 2.206320, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 394/655, Loss: 2.206512, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 395/655, Loss: 2.206575, Accuracy: 18.24%\n",
            "Epoch: 8, Step: 396/655, Loss: 2.206180, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 397/655, Loss: 2.205786, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 398/655, Loss: 2.206036, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 399/655, Loss: 2.206235, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 400/655, Loss: 2.206217, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 401/655, Loss: 2.206315, Accuracy: 18.25%\n",
            "Epoch: 8, Step: 402/655, Loss: 2.206112, Accuracy: 18.25%\n",
            "Epoch: 8, Step: 403/655, Loss: 2.206210, Accuracy: 18.25%\n",
            "Epoch: 8, Step: 404/655, Loss: 2.205989, Accuracy: 18.25%\n",
            "Epoch: 8, Step: 405/655, Loss: 2.205795, Accuracy: 18.26%\n",
            "Epoch: 8, Step: 406/655, Loss: 2.205666, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 407/655, Loss: 2.205658, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 408/655, Loss: 2.205958, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 409/655, Loss: 2.205946, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 410/655, Loss: 2.206026, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 411/655, Loss: 2.205647, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 412/655, Loss: 2.205702, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 413/655, Loss: 2.205654, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 414/655, Loss: 2.205690, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 415/655, Loss: 2.205352, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 416/655, Loss: 2.205142, Accuracy: 18.26%\n",
            "Epoch: 8, Step: 417/655, Loss: 2.205060, Accuracy: 18.26%\n",
            "Epoch: 8, Step: 418/655, Loss: 2.205165, Accuracy: 18.25%\n",
            "Epoch: 8, Step: 419/655, Loss: 2.205597, Accuracy: 18.24%\n",
            "Epoch: 8, Step: 420/655, Loss: 2.205815, Accuracy: 18.24%\n",
            "Epoch: 8, Step: 421/655, Loss: 2.205997, Accuracy: 18.22%\n",
            "Epoch: 8, Step: 422/655, Loss: 2.205969, Accuracy: 18.20%\n",
            "Epoch: 8, Step: 423/655, Loss: 2.205925, Accuracy: 18.23%\n",
            "Epoch: 8, Step: 424/655, Loss: 2.205949, Accuracy: 18.24%\n",
            "Epoch: 8, Step: 425/655, Loss: 2.205903, Accuracy: 18.23%\n",
            "Epoch: 8, Step: 426/655, Loss: 2.205661, Accuracy: 18.26%\n",
            "Epoch: 8, Step: 427/655, Loss: 2.205402, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 428/655, Loss: 2.205422, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 429/655, Loss: 2.205117, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 430/655, Loss: 2.204603, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 431/655, Loss: 2.204685, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 432/655, Loss: 2.204480, Accuracy: 18.34%\n",
            "Epoch: 8, Step: 433/655, Loss: 2.204201, Accuracy: 18.34%\n",
            "Epoch: 8, Step: 434/655, Loss: 2.204351, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 435/655, Loss: 2.204686, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 436/655, Loss: 2.204856, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 437/655, Loss: 2.205332, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 438/655, Loss: 2.205273, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 439/655, Loss: 2.205309, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 440/655, Loss: 2.205344, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 441/655, Loss: 2.205146, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 442/655, Loss: 2.204871, Accuracy: 18.34%\n",
            "Epoch: 8, Step: 443/655, Loss: 2.204752, Accuracy: 18.36%\n",
            "Epoch: 8, Step: 444/655, Loss: 2.204943, Accuracy: 18.33%\n",
            "Epoch: 8, Step: 445/655, Loss: 2.204907, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 446/655, Loss: 2.205081, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 447/655, Loss: 2.205081, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 448/655, Loss: 2.205617, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 449/655, Loss: 2.205843, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 450/655, Loss: 2.205967, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 451/655, Loss: 2.205884, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 452/655, Loss: 2.206124, Accuracy: 18.26%\n",
            "Epoch: 8, Step: 453/655, Loss: 2.206205, Accuracy: 18.25%\n",
            "Epoch: 8, Step: 454/655, Loss: 2.206156, Accuracy: 18.25%\n",
            "Epoch: 8, Step: 455/655, Loss: 2.206269, Accuracy: 18.25%\n",
            "Epoch: 8, Step: 456/655, Loss: 2.206388, Accuracy: 18.26%\n",
            "Epoch: 8, Step: 457/655, Loss: 2.206272, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 458/655, Loss: 2.206102, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 459/655, Loss: 2.205911, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 460/655, Loss: 2.205987, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 461/655, Loss: 2.206070, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 462/655, Loss: 2.206128, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 463/655, Loss: 2.206352, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 464/655, Loss: 2.206215, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 465/655, Loss: 2.205806, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 466/655, Loss: 2.206215, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 467/655, Loss: 2.206062, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 468/655, Loss: 2.205870, Accuracy: 18.33%\n",
            "Epoch: 8, Step: 469/655, Loss: 2.205970, Accuracy: 18.34%\n",
            "Epoch: 8, Step: 470/655, Loss: 2.205763, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 471/655, Loss: 2.205660, Accuracy: 18.33%\n",
            "Epoch: 8, Step: 472/655, Loss: 2.205799, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 473/655, Loss: 2.206060, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 474/655, Loss: 2.205957, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 475/655, Loss: 2.206028, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 476/655, Loss: 2.205916, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 477/655, Loss: 2.206071, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 478/655, Loss: 2.205945, Accuracy: 18.35%\n",
            "Epoch: 8, Step: 479/655, Loss: 2.205781, Accuracy: 18.37%\n",
            "Epoch: 8, Step: 480/655, Loss: 2.205468, Accuracy: 18.39%\n",
            "Epoch: 8, Step: 481/655, Loss: 2.205682, Accuracy: 18.36%\n",
            "Epoch: 8, Step: 482/655, Loss: 2.205985, Accuracy: 18.34%\n",
            "Epoch: 8, Step: 483/655, Loss: 2.206072, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 484/655, Loss: 2.206105, Accuracy: 18.34%\n",
            "Epoch: 8, Step: 485/655, Loss: 2.206116, Accuracy: 18.34%\n",
            "Epoch: 8, Step: 486/655, Loss: 2.206130, Accuracy: 18.33%\n",
            "Epoch: 8, Step: 487/655, Loss: 2.206124, Accuracy: 18.33%\n",
            "Epoch: 8, Step: 488/655, Loss: 2.206259, Accuracy: 18.33%\n",
            "Epoch: 8, Step: 489/655, Loss: 2.206275, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 490/655, Loss: 2.206385, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 491/655, Loss: 2.206304, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 492/655, Loss: 2.206591, Accuracy: 18.32%\n",
            "Epoch: 8, Step: 493/655, Loss: 2.206606, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 494/655, Loss: 2.206541, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 495/655, Loss: 2.206305, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 496/655, Loss: 2.206538, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 497/655, Loss: 2.206625, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 498/655, Loss: 2.206849, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 499/655, Loss: 2.206816, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 500/655, Loss: 2.206851, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 501/655, Loss: 2.206948, Accuracy: 18.26%\n",
            "Epoch: 8, Step: 502/655, Loss: 2.206868, Accuracy: 18.25%\n",
            "Epoch: 8, Step: 503/655, Loss: 2.206984, Accuracy: 18.23%\n",
            "Epoch: 8, Step: 504/655, Loss: 2.206891, Accuracy: 18.24%\n",
            "Epoch: 8, Step: 505/655, Loss: 2.206564, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 506/655, Loss: 2.206546, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 507/655, Loss: 2.206615, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 508/655, Loss: 2.206555, Accuracy: 18.26%\n",
            "Epoch: 8, Step: 509/655, Loss: 2.206537, Accuracy: 18.26%\n",
            "Epoch: 8, Step: 510/655, Loss: 2.206294, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 511/655, Loss: 2.206165, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 512/655, Loss: 2.206090, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 513/655, Loss: 2.206084, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 514/655, Loss: 2.206222, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 515/655, Loss: 2.206048, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 516/655, Loss: 2.205950, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 517/655, Loss: 2.205927, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 518/655, Loss: 2.205771, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 519/655, Loss: 2.205814, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 520/655, Loss: 2.206003, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 521/655, Loss: 2.205715, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 522/655, Loss: 2.206016, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 523/655, Loss: 2.205902, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 524/655, Loss: 2.205957, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 525/655, Loss: 2.205977, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 526/655, Loss: 2.206026, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 527/655, Loss: 2.205853, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 528/655, Loss: 2.205909, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 529/655, Loss: 2.206091, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 530/655, Loss: 2.206010, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 531/655, Loss: 2.205872, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 532/655, Loss: 2.206148, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 533/655, Loss: 2.206244, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 534/655, Loss: 2.206210, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 535/655, Loss: 2.206202, Accuracy: 18.31%\n",
            "Epoch: 8, Step: 536/655, Loss: 2.206371, Accuracy: 18.30%\n",
            "Epoch: 8, Step: 537/655, Loss: 2.206441, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 538/655, Loss: 2.206528, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 539/655, Loss: 2.206634, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 540/655, Loss: 2.206790, Accuracy: 18.27%\n",
            "Epoch: 8, Step: 541/655, Loss: 2.206839, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 542/655, Loss: 2.206866, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 543/655, Loss: 2.206671, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 544/655, Loss: 2.206568, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 545/655, Loss: 2.206638, Accuracy: 18.29%\n",
            "Epoch: 8, Step: 546/655, Loss: 2.206742, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 547/655, Loss: 2.206851, Accuracy: 18.28%\n",
            "Epoch: 8, Step: 548/655, Loss: 2.206885, Accuracy: 18.26%\n",
            "Epoch: 8, Step: 549/655, Loss: 2.206964, Accuracy: 18.24%\n",
            "Epoch: 8, Step: 550/655, Loss: 2.207040, Accuracy: 18.24%\n",
            "Epoch: 8, Step: 551/655, Loss: 2.207288, Accuracy: 18.23%\n",
            "Epoch: 8, Step: 552/655, Loss: 2.207323, Accuracy: 18.21%\n",
            "Epoch: 8, Step: 553/655, Loss: 2.207197, Accuracy: 18.22%\n",
            "Epoch: 8, Step: 554/655, Loss: 2.207329, Accuracy: 18.20%\n",
            "Epoch: 8, Step: 555/655, Loss: 2.207434, Accuracy: 18.20%\n",
            "Epoch: 8, Step: 556/655, Loss: 2.207322, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 557/655, Loss: 2.207176, Accuracy: 18.21%\n",
            "Epoch: 8, Step: 558/655, Loss: 2.207216, Accuracy: 18.20%\n",
            "Epoch: 8, Step: 559/655, Loss: 2.207140, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 560/655, Loss: 2.207371, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 561/655, Loss: 2.207561, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 562/655, Loss: 2.207571, Accuracy: 18.17%\n",
            "Epoch: 8, Step: 563/655, Loss: 2.207563, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 564/655, Loss: 2.207398, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 565/655, Loss: 2.207319, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 566/655, Loss: 2.207181, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 567/655, Loss: 2.207065, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 568/655, Loss: 2.207129, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 569/655, Loss: 2.207239, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 570/655, Loss: 2.207089, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 571/655, Loss: 2.207048, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 572/655, Loss: 2.207010, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 573/655, Loss: 2.207049, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 574/655, Loss: 2.207229, Accuracy: 18.19%\n",
            "Epoch: 8, Step: 575/655, Loss: 2.207395, Accuracy: 18.19%\n",
            "Epoch: 8, Step: 576/655, Loss: 2.207638, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 577/655, Loss: 2.207722, Accuracy: 18.17%\n",
            "Epoch: 8, Step: 578/655, Loss: 2.207471, Accuracy: 18.19%\n",
            "Epoch: 8, Step: 579/655, Loss: 2.207724, Accuracy: 18.17%\n",
            "Epoch: 8, Step: 580/655, Loss: 2.207799, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 581/655, Loss: 2.207649, Accuracy: 18.19%\n",
            "Epoch: 8, Step: 582/655, Loss: 2.207650, Accuracy: 18.19%\n",
            "Epoch: 8, Step: 583/655, Loss: 2.207738, Accuracy: 18.19%\n",
            "Epoch: 8, Step: 584/655, Loss: 2.207718, Accuracy: 18.19%\n",
            "Epoch: 8, Step: 585/655, Loss: 2.207636, Accuracy: 18.19%\n",
            "Epoch: 8, Step: 586/655, Loss: 2.207701, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 587/655, Loss: 2.207708, Accuracy: 18.20%\n",
            "Epoch: 8, Step: 588/655, Loss: 2.207712, Accuracy: 18.20%\n",
            "Epoch: 8, Step: 589/655, Loss: 2.207714, Accuracy: 18.20%\n",
            "Epoch: 8, Step: 590/655, Loss: 2.207776, Accuracy: 18.21%\n",
            "Epoch: 8, Step: 591/655, Loss: 2.207832, Accuracy: 18.21%\n",
            "Epoch: 8, Step: 592/655, Loss: 2.207849, Accuracy: 18.20%\n",
            "Epoch: 8, Step: 593/655, Loss: 2.207827, Accuracy: 18.20%\n",
            "Epoch: 8, Step: 594/655, Loss: 2.207680, Accuracy: 18.21%\n",
            "Epoch: 8, Step: 595/655, Loss: 2.207765, Accuracy: 18.20%\n",
            "Epoch: 8, Step: 596/655, Loss: 2.208003, Accuracy: 18.20%\n",
            "Epoch: 8, Step: 597/655, Loss: 2.207978, Accuracy: 18.19%\n",
            "Epoch: 8, Step: 598/655, Loss: 2.208091, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 599/655, Loss: 2.208012, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 600/655, Loss: 2.207835, Accuracy: 18.19%\n",
            "Epoch: 8, Step: 601/655, Loss: 2.207980, Accuracy: 18.17%\n",
            "Epoch: 8, Step: 602/655, Loss: 2.208113, Accuracy: 18.16%\n",
            "Epoch: 8, Step: 603/655, Loss: 2.208075, Accuracy: 18.17%\n",
            "Epoch: 8, Step: 604/655, Loss: 2.208219, Accuracy: 18.16%\n",
            "Epoch: 8, Step: 605/655, Loss: 2.208171, Accuracy: 18.16%\n",
            "Epoch: 8, Step: 606/655, Loss: 2.208222, Accuracy: 18.14%\n",
            "Epoch: 8, Step: 607/655, Loss: 2.208221, Accuracy: 18.14%\n",
            "Epoch: 8, Step: 608/655, Loss: 2.208065, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 609/655, Loss: 2.208045, Accuracy: 18.13%\n",
            "Epoch: 8, Step: 610/655, Loss: 2.207939, Accuracy: 18.14%\n",
            "Epoch: 8, Step: 611/655, Loss: 2.207893, Accuracy: 18.13%\n",
            "Epoch: 8, Step: 612/655, Loss: 2.207841, Accuracy: 18.14%\n",
            "Epoch: 8, Step: 613/655, Loss: 2.207804, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 614/655, Loss: 2.207960, Accuracy: 18.14%\n",
            "Epoch: 8, Step: 615/655, Loss: 2.207887, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 616/655, Loss: 2.207969, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 617/655, Loss: 2.207915, Accuracy: 18.17%\n",
            "Epoch: 8, Step: 618/655, Loss: 2.207866, Accuracy: 18.17%\n",
            "Epoch: 8, Step: 619/655, Loss: 2.207886, Accuracy: 18.16%\n",
            "Epoch: 8, Step: 620/655, Loss: 2.207853, Accuracy: 18.16%\n",
            "Epoch: 8, Step: 621/655, Loss: 2.208023, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 622/655, Loss: 2.208058, Accuracy: 18.16%\n",
            "Epoch: 8, Step: 623/655, Loss: 2.208029, Accuracy: 18.16%\n",
            "Epoch: 8, Step: 624/655, Loss: 2.208301, Accuracy: 18.14%\n",
            "Epoch: 8, Step: 625/655, Loss: 2.208320, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 626/655, Loss: 2.208482, Accuracy: 18.13%\n",
            "Epoch: 8, Step: 627/655, Loss: 2.208247, Accuracy: 18.16%\n",
            "Epoch: 8, Step: 628/655, Loss: 2.208359, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 629/655, Loss: 2.208384, Accuracy: 18.14%\n",
            "Epoch: 8, Step: 630/655, Loss: 2.208206, Accuracy: 18.14%\n",
            "Epoch: 8, Step: 631/655, Loss: 2.208239, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 632/655, Loss: 2.208354, Accuracy: 18.14%\n",
            "Epoch: 8, Step: 633/655, Loss: 2.208307, Accuracy: 18.16%\n",
            "Epoch: 8, Step: 634/655, Loss: 2.208319, Accuracy: 18.16%\n",
            "Epoch: 8, Step: 635/655, Loss: 2.208406, Accuracy: 18.16%\n",
            "Epoch: 8, Step: 636/655, Loss: 2.208301, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 637/655, Loss: 2.208195, Accuracy: 18.16%\n",
            "Epoch: 8, Step: 638/655, Loss: 2.208363, Accuracy: 18.14%\n",
            "Epoch: 8, Step: 639/655, Loss: 2.208254, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 640/655, Loss: 2.208432, Accuracy: 18.15%\n",
            "Epoch: 8, Step: 641/655, Loss: 2.208360, Accuracy: 18.17%\n",
            "Epoch: 8, Step: 642/655, Loss: 2.208326, Accuracy: 18.20%\n",
            "Epoch: 8, Step: 643/655, Loss: 2.208382, Accuracy: 18.19%\n",
            "Epoch: 8, Step: 644/655, Loss: 2.208234, Accuracy: 18.19%\n",
            "Epoch: 8, Step: 645/655, Loss: 2.208282, Accuracy: 18.19%\n",
            "Epoch: 8, Step: 646/655, Loss: 2.208229, Accuracy: 18.19%\n",
            "Epoch: 8, Step: 647/655, Loss: 2.208337, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 648/655, Loss: 2.208301, Accuracy: 18.17%\n",
            "Epoch: 8, Step: 649/655, Loss: 2.208226, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 650/655, Loss: 2.208226, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 651/655, Loss: 2.208294, Accuracy: 18.17%\n",
            "Epoch: 8, Step: 652/655, Loss: 2.208328, Accuracy: 18.17%\n",
            "Epoch: 8, Step: 653/655, Loss: 2.208188, Accuracy: 18.17%\n",
            "Epoch: 8, Step: 654/655, Loss: 2.208198, Accuracy: 18.18%\n",
            "Epoch: 8, Step: 655/655, Loss: 2.208195, Accuracy: 18.18%\n",
            "Epoch: 9, Step: 1/655, Loss: 2.237740, Accuracy: 15.62%\n",
            "Epoch: 9, Step: 2/655, Loss: 2.242024, Accuracy: 17.19%\n",
            "Epoch: 9, Step: 3/655, Loss: 2.223251, Accuracy: 16.67%\n",
            "Epoch: 9, Step: 4/655, Loss: 2.220603, Accuracy: 17.97%\n",
            "Epoch: 9, Step: 5/655, Loss: 2.229461, Accuracy: 16.25%\n",
            "Epoch: 9, Step: 6/655, Loss: 2.225511, Accuracy: 17.19%\n",
            "Epoch: 9, Step: 7/655, Loss: 2.213359, Accuracy: 17.86%\n",
            "Epoch: 9, Step: 8/655, Loss: 2.195668, Accuracy: 17.97%\n",
            "Epoch: 9, Step: 9/655, Loss: 2.175469, Accuracy: 18.06%\n",
            "Epoch: 9, Step: 10/655, Loss: 2.194555, Accuracy: 16.88%\n",
            "Epoch: 9, Step: 11/655, Loss: 2.210144, Accuracy: 16.19%\n",
            "Epoch: 9, Step: 12/655, Loss: 2.212851, Accuracy: 16.41%\n",
            "Epoch: 9, Step: 13/655, Loss: 2.210023, Accuracy: 17.55%\n",
            "Epoch: 9, Step: 14/655, Loss: 2.206053, Accuracy: 17.86%\n",
            "Epoch: 9, Step: 15/655, Loss: 2.203618, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 16/655, Loss: 2.205741, Accuracy: 17.77%\n",
            "Epoch: 9, Step: 17/655, Loss: 2.209192, Accuracy: 18.20%\n",
            "Epoch: 9, Step: 18/655, Loss: 2.214140, Accuracy: 17.71%\n",
            "Epoch: 9, Step: 19/655, Loss: 2.219215, Accuracy: 17.60%\n",
            "Epoch: 9, Step: 20/655, Loss: 2.216557, Accuracy: 17.34%\n",
            "Epoch: 9, Step: 21/655, Loss: 2.215389, Accuracy: 17.56%\n",
            "Epoch: 9, Step: 22/655, Loss: 2.217882, Accuracy: 17.19%\n",
            "Epoch: 9, Step: 23/655, Loss: 2.216092, Accuracy: 17.66%\n",
            "Epoch: 9, Step: 24/655, Loss: 2.214472, Accuracy: 17.97%\n",
            "Epoch: 9, Step: 25/655, Loss: 2.209096, Accuracy: 18.00%\n",
            "Epoch: 9, Step: 26/655, Loss: 2.206007, Accuracy: 18.27%\n",
            "Epoch: 9, Step: 27/655, Loss: 2.201904, Accuracy: 18.06%\n",
            "Epoch: 9, Step: 28/655, Loss: 2.199875, Accuracy: 18.19%\n",
            "Epoch: 9, Step: 29/655, Loss: 2.200162, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 30/655, Loss: 2.202754, Accuracy: 18.12%\n",
            "Epoch: 9, Step: 31/655, Loss: 2.205312, Accuracy: 18.15%\n",
            "Epoch: 9, Step: 32/655, Loss: 2.208570, Accuracy: 18.16%\n",
            "Epoch: 9, Step: 33/655, Loss: 2.208534, Accuracy: 17.99%\n",
            "Epoch: 9, Step: 34/655, Loss: 2.204561, Accuracy: 18.47%\n",
            "Epoch: 9, Step: 35/655, Loss: 2.205467, Accuracy: 18.75%\n",
            "Epoch: 9, Step: 36/655, Loss: 2.207582, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 37/655, Loss: 2.208809, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 38/655, Loss: 2.210909, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 39/655, Loss: 2.207845, Accuracy: 18.59%\n",
            "Epoch: 9, Step: 40/655, Loss: 2.208285, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 41/655, Loss: 2.207307, Accuracy: 18.06%\n",
            "Epoch: 9, Step: 42/655, Loss: 2.205976, Accuracy: 17.93%\n",
            "Epoch: 9, Step: 43/655, Loss: 2.207449, Accuracy: 17.81%\n",
            "Epoch: 9, Step: 44/655, Loss: 2.205553, Accuracy: 18.04%\n",
            "Epoch: 9, Step: 45/655, Loss: 2.204319, Accuracy: 17.99%\n",
            "Epoch: 9, Step: 46/655, Loss: 2.206671, Accuracy: 17.93%\n",
            "Epoch: 9, Step: 47/655, Loss: 2.206358, Accuracy: 18.09%\n",
            "Epoch: 9, Step: 48/655, Loss: 2.208708, Accuracy: 17.84%\n",
            "Epoch: 9, Step: 49/655, Loss: 2.209089, Accuracy: 18.05%\n",
            "Epoch: 9, Step: 50/655, Loss: 2.209282, Accuracy: 18.00%\n",
            "Epoch: 9, Step: 51/655, Loss: 2.208791, Accuracy: 17.95%\n",
            "Epoch: 9, Step: 52/655, Loss: 2.206732, Accuracy: 18.15%\n",
            "Epoch: 9, Step: 53/655, Loss: 2.207502, Accuracy: 18.22%\n",
            "Epoch: 9, Step: 54/655, Loss: 2.208618, Accuracy: 18.11%\n",
            "Epoch: 9, Step: 55/655, Loss: 2.207321, Accuracy: 18.07%\n",
            "Epoch: 9, Step: 56/655, Loss: 2.206385, Accuracy: 18.08%\n",
            "Epoch: 9, Step: 57/655, Loss: 2.208156, Accuracy: 17.93%\n",
            "Epoch: 9, Step: 58/655, Loss: 2.206930, Accuracy: 18.16%\n",
            "Epoch: 9, Step: 59/655, Loss: 2.206651, Accuracy: 18.06%\n",
            "Epoch: 9, Step: 60/655, Loss: 2.208115, Accuracy: 18.18%\n",
            "Epoch: 9, Step: 61/655, Loss: 2.208482, Accuracy: 18.08%\n",
            "Epoch: 9, Step: 62/655, Loss: 2.208826, Accuracy: 18.09%\n",
            "Epoch: 9, Step: 63/655, Loss: 2.206027, Accuracy: 18.20%\n",
            "Epoch: 9, Step: 64/655, Loss: 2.206140, Accuracy: 18.12%\n",
            "Epoch: 9, Step: 65/655, Loss: 2.204089, Accuracy: 18.22%\n",
            "Epoch: 9, Step: 66/655, Loss: 2.203382, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 67/655, Loss: 2.203576, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 68/655, Loss: 2.203872, Accuracy: 18.57%\n",
            "Epoch: 9, Step: 69/655, Loss: 2.205408, Accuracy: 18.48%\n",
            "Epoch: 9, Step: 70/655, Loss: 2.205506, Accuracy: 18.48%\n",
            "Epoch: 9, Step: 71/655, Loss: 2.205891, Accuracy: 18.53%\n",
            "Epoch: 9, Step: 72/655, Loss: 2.205840, Accuracy: 18.62%\n",
            "Epoch: 9, Step: 73/655, Loss: 2.204421, Accuracy: 18.62%\n",
            "Epoch: 9, Step: 74/655, Loss: 2.203917, Accuracy: 18.54%\n",
            "Epoch: 9, Step: 75/655, Loss: 2.206087, Accuracy: 18.50%\n",
            "Epoch: 9, Step: 76/655, Loss: 2.206860, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 77/655, Loss: 2.205378, Accuracy: 18.63%\n",
            "Epoch: 9, Step: 78/655, Loss: 2.206317, Accuracy: 18.47%\n",
            "Epoch: 9, Step: 79/655, Loss: 2.206958, Accuracy: 18.39%\n",
            "Epoch: 9, Step: 80/655, Loss: 2.205939, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 81/655, Loss: 2.206275, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 82/655, Loss: 2.205743, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 83/655, Loss: 2.207947, Accuracy: 18.30%\n",
            "Epoch: 9, Step: 84/655, Loss: 2.207327, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 85/655, Loss: 2.207489, Accuracy: 18.49%\n",
            "Epoch: 9, Step: 86/655, Loss: 2.207507, Accuracy: 18.53%\n",
            "Epoch: 9, Step: 87/655, Loss: 2.207682, Accuracy: 18.50%\n",
            "Epoch: 9, Step: 88/655, Loss: 2.208805, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 89/655, Loss: 2.209824, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 90/655, Loss: 2.208319, Accuracy: 18.51%\n",
            "Epoch: 9, Step: 91/655, Loss: 2.208379, Accuracy: 18.48%\n",
            "Epoch: 9, Step: 92/655, Loss: 2.207928, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 93/655, Loss: 2.207103, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 94/655, Loss: 2.207651, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 95/655, Loss: 2.209106, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 96/655, Loss: 2.208766, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 97/655, Loss: 2.209975, Accuracy: 18.17%\n",
            "Epoch: 9, Step: 98/655, Loss: 2.210039, Accuracy: 18.27%\n",
            "Epoch: 9, Step: 99/655, Loss: 2.209906, Accuracy: 18.21%\n",
            "Epoch: 9, Step: 100/655, Loss: 2.209809, Accuracy: 18.25%\n",
            "Epoch: 9, Step: 101/655, Loss: 2.211544, Accuracy: 18.13%\n",
            "Epoch: 9, Step: 102/655, Loss: 2.212029, Accuracy: 18.05%\n",
            "Epoch: 9, Step: 103/655, Loss: 2.212766, Accuracy: 17.96%\n",
            "Epoch: 9, Step: 104/655, Loss: 2.212814, Accuracy: 17.94%\n",
            "Epoch: 9, Step: 105/655, Loss: 2.212470, Accuracy: 17.89%\n",
            "Epoch: 9, Step: 106/655, Loss: 2.213095, Accuracy: 17.81%\n",
            "Epoch: 9, Step: 107/655, Loss: 2.212110, Accuracy: 17.90%\n",
            "Epoch: 9, Step: 108/655, Loss: 2.210844, Accuracy: 17.97%\n",
            "Epoch: 9, Step: 109/655, Loss: 2.211406, Accuracy: 17.95%\n",
            "Epoch: 9, Step: 110/655, Loss: 2.211962, Accuracy: 17.95%\n",
            "Epoch: 9, Step: 111/655, Loss: 2.210644, Accuracy: 17.96%\n",
            "Epoch: 9, Step: 112/655, Loss: 2.210513, Accuracy: 17.86%\n",
            "Epoch: 9, Step: 113/655, Loss: 2.210659, Accuracy: 17.81%\n",
            "Epoch: 9, Step: 114/655, Loss: 2.211077, Accuracy: 17.76%\n",
            "Epoch: 9, Step: 115/655, Loss: 2.211844, Accuracy: 17.69%\n",
            "Epoch: 9, Step: 116/655, Loss: 2.211848, Accuracy: 17.70%\n",
            "Epoch: 9, Step: 117/655, Loss: 2.212559, Accuracy: 17.65%\n",
            "Epoch: 9, Step: 118/655, Loss: 2.211002, Accuracy: 17.72%\n",
            "Epoch: 9, Step: 119/655, Loss: 2.211523, Accuracy: 17.62%\n",
            "Epoch: 9, Step: 120/655, Loss: 2.210700, Accuracy: 17.63%\n",
            "Epoch: 9, Step: 121/655, Loss: 2.210894, Accuracy: 17.61%\n",
            "Epoch: 9, Step: 122/655, Loss: 2.210025, Accuracy: 17.75%\n",
            "Epoch: 9, Step: 123/655, Loss: 2.209640, Accuracy: 17.89%\n",
            "Epoch: 9, Step: 124/655, Loss: 2.210958, Accuracy: 17.84%\n",
            "Epoch: 9, Step: 125/655, Loss: 2.211229, Accuracy: 17.77%\n",
            "Epoch: 9, Step: 126/655, Loss: 2.210602, Accuracy: 17.73%\n",
            "Epoch: 9, Step: 127/655, Loss: 2.210195, Accuracy: 17.77%\n",
            "Epoch: 9, Step: 128/655, Loss: 2.209987, Accuracy: 17.80%\n",
            "Epoch: 9, Step: 129/655, Loss: 2.210150, Accuracy: 17.76%\n",
            "Epoch: 9, Step: 130/655, Loss: 2.209723, Accuracy: 17.76%\n",
            "Epoch: 9, Step: 131/655, Loss: 2.210651, Accuracy: 17.75%\n",
            "Epoch: 9, Step: 132/655, Loss: 2.210918, Accuracy: 17.76%\n",
            "Epoch: 9, Step: 133/655, Loss: 2.211111, Accuracy: 17.79%\n",
            "Epoch: 9, Step: 134/655, Loss: 2.211043, Accuracy: 17.75%\n",
            "Epoch: 9, Step: 135/655, Loss: 2.211084, Accuracy: 17.73%\n",
            "Epoch: 9, Step: 136/655, Loss: 2.211362, Accuracy: 17.72%\n",
            "Epoch: 9, Step: 137/655, Loss: 2.211276, Accuracy: 17.72%\n",
            "Epoch: 9, Step: 138/655, Loss: 2.211228, Accuracy: 17.75%\n",
            "Epoch: 9, Step: 139/655, Loss: 2.211706, Accuracy: 17.74%\n",
            "Epoch: 9, Step: 140/655, Loss: 2.211392, Accuracy: 17.72%\n",
            "Epoch: 9, Step: 141/655, Loss: 2.211939, Accuracy: 17.71%\n",
            "Epoch: 9, Step: 142/655, Loss: 2.212721, Accuracy: 17.69%\n",
            "Epoch: 9, Step: 143/655, Loss: 2.212874, Accuracy: 17.68%\n",
            "Epoch: 9, Step: 144/655, Loss: 2.212894, Accuracy: 17.66%\n",
            "Epoch: 9, Step: 145/655, Loss: 2.213140, Accuracy: 17.61%\n",
            "Epoch: 9, Step: 146/655, Loss: 2.213017, Accuracy: 17.59%\n",
            "Epoch: 9, Step: 147/655, Loss: 2.212871, Accuracy: 17.64%\n",
            "Epoch: 9, Step: 148/655, Loss: 2.212998, Accuracy: 17.69%\n",
            "Epoch: 9, Step: 149/655, Loss: 2.213447, Accuracy: 17.70%\n",
            "Epoch: 9, Step: 150/655, Loss: 2.213818, Accuracy: 17.71%\n",
            "Epoch: 9, Step: 151/655, Loss: 2.213273, Accuracy: 17.78%\n",
            "Epoch: 9, Step: 152/655, Loss: 2.213075, Accuracy: 17.80%\n",
            "Epoch: 9, Step: 153/655, Loss: 2.214160, Accuracy: 17.71%\n",
            "Epoch: 9, Step: 154/655, Loss: 2.214452, Accuracy: 17.65%\n",
            "Epoch: 9, Step: 155/655, Loss: 2.214023, Accuracy: 17.62%\n",
            "Epoch: 9, Step: 156/655, Loss: 2.213691, Accuracy: 17.69%\n",
            "Epoch: 9, Step: 157/655, Loss: 2.213042, Accuracy: 17.75%\n",
            "Epoch: 9, Step: 158/655, Loss: 2.212771, Accuracy: 17.76%\n",
            "Epoch: 9, Step: 159/655, Loss: 2.212548, Accuracy: 17.75%\n",
            "Epoch: 9, Step: 160/655, Loss: 2.212403, Accuracy: 17.79%\n",
            "Epoch: 9, Step: 161/655, Loss: 2.212143, Accuracy: 17.80%\n",
            "Epoch: 9, Step: 162/655, Loss: 2.211255, Accuracy: 17.84%\n",
            "Epoch: 9, Step: 163/655, Loss: 2.210338, Accuracy: 17.91%\n",
            "Epoch: 9, Step: 164/655, Loss: 2.210666, Accuracy: 17.89%\n",
            "Epoch: 9, Step: 165/655, Loss: 2.211281, Accuracy: 17.84%\n",
            "Epoch: 9, Step: 166/655, Loss: 2.211211, Accuracy: 17.88%\n",
            "Epoch: 9, Step: 167/655, Loss: 2.211201, Accuracy: 17.83%\n",
            "Epoch: 9, Step: 168/655, Loss: 2.210684, Accuracy: 17.88%\n",
            "Epoch: 9, Step: 169/655, Loss: 2.210605, Accuracy: 17.86%\n",
            "Epoch: 9, Step: 170/655, Loss: 2.210728, Accuracy: 17.87%\n",
            "Epoch: 9, Step: 171/655, Loss: 2.210404, Accuracy: 17.91%\n",
            "Epoch: 9, Step: 172/655, Loss: 2.210887, Accuracy: 17.88%\n",
            "Epoch: 9, Step: 173/655, Loss: 2.211114, Accuracy: 17.90%\n",
            "Epoch: 9, Step: 174/655, Loss: 2.212212, Accuracy: 17.87%\n",
            "Epoch: 9, Step: 175/655, Loss: 2.212069, Accuracy: 17.88%\n",
            "Epoch: 9, Step: 176/655, Loss: 2.212668, Accuracy: 17.86%\n",
            "Epoch: 9, Step: 177/655, Loss: 2.212549, Accuracy: 17.88%\n",
            "Epoch: 9, Step: 178/655, Loss: 2.212512, Accuracy: 17.89%\n",
            "Epoch: 9, Step: 179/655, Loss: 2.212984, Accuracy: 17.84%\n",
            "Epoch: 9, Step: 180/655, Loss: 2.213124, Accuracy: 17.86%\n",
            "Epoch: 9, Step: 181/655, Loss: 2.213095, Accuracy: 17.80%\n",
            "Epoch: 9, Step: 182/655, Loss: 2.212915, Accuracy: 17.84%\n",
            "Epoch: 9, Step: 183/655, Loss: 2.212711, Accuracy: 17.86%\n",
            "Epoch: 9, Step: 184/655, Loss: 2.212430, Accuracy: 17.88%\n",
            "Epoch: 9, Step: 185/655, Loss: 2.212709, Accuracy: 17.85%\n",
            "Epoch: 9, Step: 186/655, Loss: 2.212884, Accuracy: 17.86%\n",
            "Epoch: 9, Step: 187/655, Loss: 2.212224, Accuracy: 17.90%\n",
            "Epoch: 9, Step: 188/655, Loss: 2.211884, Accuracy: 17.90%\n",
            "Epoch: 9, Step: 189/655, Loss: 2.212090, Accuracy: 17.82%\n",
            "Epoch: 9, Step: 190/655, Loss: 2.212140, Accuracy: 17.83%\n",
            "Epoch: 9, Step: 191/655, Loss: 2.212725, Accuracy: 17.85%\n",
            "Epoch: 9, Step: 192/655, Loss: 2.212343, Accuracy: 17.85%\n",
            "Epoch: 9, Step: 193/655, Loss: 2.212533, Accuracy: 17.88%\n",
            "Epoch: 9, Step: 194/655, Loss: 2.212516, Accuracy: 17.88%\n",
            "Epoch: 9, Step: 195/655, Loss: 2.211673, Accuracy: 17.93%\n",
            "Epoch: 9, Step: 196/655, Loss: 2.211550, Accuracy: 17.98%\n",
            "Epoch: 9, Step: 197/655, Loss: 2.211854, Accuracy: 17.97%\n",
            "Epoch: 9, Step: 198/655, Loss: 2.212312, Accuracy: 17.96%\n",
            "Epoch: 9, Step: 199/655, Loss: 2.211913, Accuracy: 18.00%\n",
            "Epoch: 9, Step: 200/655, Loss: 2.211382, Accuracy: 18.02%\n",
            "Epoch: 9, Step: 201/655, Loss: 2.211387, Accuracy: 17.99%\n",
            "Epoch: 9, Step: 202/655, Loss: 2.211374, Accuracy: 17.99%\n",
            "Epoch: 9, Step: 203/655, Loss: 2.211320, Accuracy: 18.01%\n",
            "Epoch: 9, Step: 204/655, Loss: 2.211458, Accuracy: 18.00%\n",
            "Epoch: 9, Step: 205/655, Loss: 2.211604, Accuracy: 18.00%\n",
            "Epoch: 9, Step: 206/655, Loss: 2.212095, Accuracy: 18.01%\n",
            "Epoch: 9, Step: 207/655, Loss: 2.212660, Accuracy: 18.04%\n",
            "Epoch: 9, Step: 208/655, Loss: 2.212363, Accuracy: 18.06%\n",
            "Epoch: 9, Step: 209/655, Loss: 2.212301, Accuracy: 18.05%\n",
            "Epoch: 9, Step: 210/655, Loss: 2.212327, Accuracy: 18.10%\n",
            "Epoch: 9, Step: 211/655, Loss: 2.211531, Accuracy: 18.14%\n",
            "Epoch: 9, Step: 212/655, Loss: 2.211676, Accuracy: 18.15%\n",
            "Epoch: 9, Step: 213/655, Loss: 2.211274, Accuracy: 18.16%\n",
            "Epoch: 9, Step: 214/655, Loss: 2.211176, Accuracy: 18.17%\n",
            "Epoch: 9, Step: 215/655, Loss: 2.211561, Accuracy: 18.17%\n",
            "Epoch: 9, Step: 216/655, Loss: 2.211627, Accuracy: 18.16%\n",
            "Epoch: 9, Step: 217/655, Loss: 2.212164, Accuracy: 18.16%\n",
            "Epoch: 9, Step: 218/655, Loss: 2.211942, Accuracy: 18.15%\n",
            "Epoch: 9, Step: 219/655, Loss: 2.211526, Accuracy: 18.19%\n",
            "Epoch: 9, Step: 220/655, Loss: 2.211689, Accuracy: 18.20%\n",
            "Epoch: 9, Step: 221/655, Loss: 2.211806, Accuracy: 18.20%\n",
            "Epoch: 9, Step: 222/655, Loss: 2.211576, Accuracy: 18.22%\n",
            "Epoch: 9, Step: 223/655, Loss: 2.211628, Accuracy: 18.23%\n",
            "Epoch: 9, Step: 224/655, Loss: 2.211604, Accuracy: 18.23%\n",
            "Epoch: 9, Step: 225/655, Loss: 2.211735, Accuracy: 18.19%\n",
            "Epoch: 9, Step: 226/655, Loss: 2.211458, Accuracy: 18.22%\n",
            "Epoch: 9, Step: 227/655, Loss: 2.212037, Accuracy: 18.19%\n",
            "Epoch: 9, Step: 228/655, Loss: 2.211662, Accuracy: 18.22%\n",
            "Epoch: 9, Step: 229/655, Loss: 2.211290, Accuracy: 18.30%\n",
            "Epoch: 9, Step: 230/655, Loss: 2.211495, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 231/655, Loss: 2.211198, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 232/655, Loss: 2.211541, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 233/655, Loss: 2.211440, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 234/655, Loss: 2.211360, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 235/655, Loss: 2.211739, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 236/655, Loss: 2.212185, Accuracy: 18.31%\n",
            "Epoch: 9, Step: 237/655, Loss: 2.211762, Accuracy: 18.31%\n",
            "Epoch: 9, Step: 238/655, Loss: 2.212540, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 239/655, Loss: 2.212244, Accuracy: 18.25%\n",
            "Epoch: 9, Step: 240/655, Loss: 2.213132, Accuracy: 18.18%\n",
            "Epoch: 9, Step: 241/655, Loss: 2.212810, Accuracy: 18.17%\n",
            "Epoch: 9, Step: 242/655, Loss: 2.212418, Accuracy: 18.13%\n",
            "Epoch: 9, Step: 243/655, Loss: 2.212662, Accuracy: 18.13%\n",
            "Epoch: 9, Step: 244/655, Loss: 2.213006, Accuracy: 18.14%\n",
            "Epoch: 9, Step: 245/655, Loss: 2.213381, Accuracy: 18.09%\n",
            "Epoch: 9, Step: 246/655, Loss: 2.213591, Accuracy: 18.08%\n",
            "Epoch: 9, Step: 247/655, Loss: 2.213263, Accuracy: 18.08%\n",
            "Epoch: 9, Step: 248/655, Loss: 2.213157, Accuracy: 18.08%\n",
            "Epoch: 9, Step: 249/655, Loss: 2.213744, Accuracy: 18.05%\n",
            "Epoch: 9, Step: 250/655, Loss: 2.213216, Accuracy: 18.06%\n",
            "Epoch: 9, Step: 251/655, Loss: 2.212937, Accuracy: 18.05%\n",
            "Epoch: 9, Step: 252/655, Loss: 2.212567, Accuracy: 18.08%\n",
            "Epoch: 9, Step: 253/655, Loss: 2.212112, Accuracy: 18.08%\n",
            "Epoch: 9, Step: 254/655, Loss: 2.212034, Accuracy: 18.04%\n",
            "Epoch: 9, Step: 255/655, Loss: 2.212200, Accuracy: 17.99%\n",
            "Epoch: 9, Step: 256/655, Loss: 2.212576, Accuracy: 17.98%\n",
            "Epoch: 9, Step: 257/655, Loss: 2.212493, Accuracy: 18.00%\n",
            "Epoch: 9, Step: 258/655, Loss: 2.212945, Accuracy: 18.02%\n",
            "Epoch: 9, Step: 259/655, Loss: 2.212728, Accuracy: 18.04%\n",
            "Epoch: 9, Step: 260/655, Loss: 2.212609, Accuracy: 18.04%\n",
            "Epoch: 9, Step: 261/655, Loss: 2.212346, Accuracy: 18.07%\n",
            "Epoch: 9, Step: 262/655, Loss: 2.212709, Accuracy: 18.09%\n",
            "Epoch: 9, Step: 263/655, Loss: 2.212733, Accuracy: 18.08%\n",
            "Epoch: 9, Step: 264/655, Loss: 2.212999, Accuracy: 18.08%\n",
            "Epoch: 9, Step: 265/655, Loss: 2.212365, Accuracy: 18.14%\n",
            "Epoch: 9, Step: 266/655, Loss: 2.211543, Accuracy: 18.21%\n",
            "Epoch: 9, Step: 267/655, Loss: 2.211819, Accuracy: 18.22%\n",
            "Epoch: 9, Step: 268/655, Loss: 2.211797, Accuracy: 18.19%\n",
            "Epoch: 9, Step: 269/655, Loss: 2.211548, Accuracy: 18.25%\n",
            "Epoch: 9, Step: 270/655, Loss: 2.211805, Accuracy: 18.22%\n",
            "Epoch: 9, Step: 271/655, Loss: 2.212207, Accuracy: 18.21%\n",
            "Epoch: 9, Step: 272/655, Loss: 2.212086, Accuracy: 18.20%\n",
            "Epoch: 9, Step: 273/655, Loss: 2.212005, Accuracy: 18.18%\n",
            "Epoch: 9, Step: 274/655, Loss: 2.211826, Accuracy: 18.17%\n",
            "Epoch: 9, Step: 275/655, Loss: 2.211509, Accuracy: 18.19%\n",
            "Epoch: 9, Step: 276/655, Loss: 2.211786, Accuracy: 18.18%\n",
            "Epoch: 9, Step: 277/655, Loss: 2.211652, Accuracy: 18.21%\n",
            "Epoch: 9, Step: 278/655, Loss: 2.211507, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 279/655, Loss: 2.211486, Accuracy: 18.27%\n",
            "Epoch: 9, Step: 280/655, Loss: 2.211587, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 281/655, Loss: 2.211400, Accuracy: 18.27%\n",
            "Epoch: 9, Step: 282/655, Loss: 2.211330, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 283/655, Loss: 2.211406, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 284/655, Loss: 2.211634, Accuracy: 18.23%\n",
            "Epoch: 9, Step: 285/655, Loss: 2.211261, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 286/655, Loss: 2.211455, Accuracy: 18.27%\n",
            "Epoch: 9, Step: 287/655, Loss: 2.211833, Accuracy: 18.24%\n",
            "Epoch: 9, Step: 288/655, Loss: 2.211717, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 289/655, Loss: 2.211639, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 290/655, Loss: 2.212128, Accuracy: 18.24%\n",
            "Epoch: 9, Step: 291/655, Loss: 2.211425, Accuracy: 18.30%\n",
            "Epoch: 9, Step: 292/655, Loss: 2.211244, Accuracy: 18.28%\n",
            "Epoch: 9, Step: 293/655, Loss: 2.211239, Accuracy: 18.29%\n",
            "Epoch: 9, Step: 294/655, Loss: 2.211466, Accuracy: 18.29%\n",
            "Epoch: 9, Step: 295/655, Loss: 2.211194, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 296/655, Loss: 2.211266, Accuracy: 18.29%\n",
            "Epoch: 9, Step: 297/655, Loss: 2.211535, Accuracy: 18.27%\n",
            "Epoch: 9, Step: 298/655, Loss: 2.211466, Accuracy: 18.27%\n",
            "Epoch: 9, Step: 299/655, Loss: 2.211213, Accuracy: 18.27%\n",
            "Epoch: 9, Step: 300/655, Loss: 2.211450, Accuracy: 18.24%\n",
            "Epoch: 9, Step: 301/655, Loss: 2.211451, Accuracy: 18.24%\n",
            "Epoch: 9, Step: 302/655, Loss: 2.211116, Accuracy: 18.22%\n",
            "Epoch: 9, Step: 303/655, Loss: 2.211388, Accuracy: 18.21%\n",
            "Epoch: 9, Step: 304/655, Loss: 2.210951, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 305/655, Loss: 2.211033, Accuracy: 18.23%\n",
            "Epoch: 9, Step: 306/655, Loss: 2.211245, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 307/655, Loss: 2.211305, Accuracy: 18.27%\n",
            "Epoch: 9, Step: 308/655, Loss: 2.211274, Accuracy: 18.24%\n",
            "Epoch: 9, Step: 309/655, Loss: 2.210963, Accuracy: 18.25%\n",
            "Epoch: 9, Step: 310/655, Loss: 2.210475, Accuracy: 18.25%\n",
            "Epoch: 9, Step: 311/655, Loss: 2.210359, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 312/655, Loss: 2.209801, Accuracy: 18.29%\n",
            "Epoch: 9, Step: 313/655, Loss: 2.209732, Accuracy: 18.28%\n",
            "Epoch: 9, Step: 314/655, Loss: 2.209613, Accuracy: 18.30%\n",
            "Epoch: 9, Step: 315/655, Loss: 2.209579, Accuracy: 18.31%\n",
            "Epoch: 9, Step: 316/655, Loss: 2.209930, Accuracy: 18.30%\n",
            "Epoch: 9, Step: 317/655, Loss: 2.210008, Accuracy: 18.28%\n",
            "Epoch: 9, Step: 318/655, Loss: 2.210271, Accuracy: 18.28%\n",
            "Epoch: 9, Step: 319/655, Loss: 2.210151, Accuracy: 18.27%\n",
            "Epoch: 9, Step: 320/655, Loss: 2.210278, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 321/655, Loss: 2.210015, Accuracy: 18.24%\n",
            "Epoch: 9, Step: 322/655, Loss: 2.210291, Accuracy: 18.24%\n",
            "Epoch: 9, Step: 323/655, Loss: 2.209938, Accuracy: 18.25%\n",
            "Epoch: 9, Step: 324/655, Loss: 2.209910, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 325/655, Loss: 2.209554, Accuracy: 18.28%\n",
            "Epoch: 9, Step: 326/655, Loss: 2.209732, Accuracy: 18.29%\n",
            "Epoch: 9, Step: 327/655, Loss: 2.210079, Accuracy: 18.31%\n",
            "Epoch: 9, Step: 328/655, Loss: 2.209808, Accuracy: 18.28%\n",
            "Epoch: 9, Step: 329/655, Loss: 2.209926, Accuracy: 18.29%\n",
            "Epoch: 9, Step: 330/655, Loss: 2.209379, Accuracy: 18.32%\n",
            "Epoch: 9, Step: 331/655, Loss: 2.209269, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 332/655, Loss: 2.209477, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 333/655, Loss: 2.209739, Accuracy: 18.30%\n",
            "Epoch: 9, Step: 334/655, Loss: 2.209792, Accuracy: 18.32%\n",
            "Epoch: 9, Step: 335/655, Loss: 2.210097, Accuracy: 18.30%\n",
            "Epoch: 9, Step: 336/655, Loss: 2.210267, Accuracy: 18.27%\n",
            "Epoch: 9, Step: 337/655, Loss: 2.210442, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 338/655, Loss: 2.210431, Accuracy: 18.27%\n",
            "Epoch: 9, Step: 339/655, Loss: 2.210783, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 340/655, Loss: 2.211055, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 341/655, Loss: 2.211433, Accuracy: 18.24%\n",
            "Epoch: 9, Step: 342/655, Loss: 2.211852, Accuracy: 18.23%\n",
            "Epoch: 9, Step: 343/655, Loss: 2.212034, Accuracy: 18.22%\n",
            "Epoch: 9, Step: 344/655, Loss: 2.211835, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 345/655, Loss: 2.212261, Accuracy: 18.24%\n",
            "Epoch: 9, Step: 346/655, Loss: 2.212124, Accuracy: 18.24%\n",
            "Epoch: 9, Step: 347/655, Loss: 2.212300, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 348/655, Loss: 2.212091, Accuracy: 18.28%\n",
            "Epoch: 9, Step: 349/655, Loss: 2.211537, Accuracy: 18.29%\n",
            "Epoch: 9, Step: 350/655, Loss: 2.211190, Accuracy: 18.32%\n",
            "Epoch: 9, Step: 351/655, Loss: 2.210953, Accuracy: 18.31%\n",
            "Epoch: 9, Step: 352/655, Loss: 2.211075, Accuracy: 18.30%\n",
            "Epoch: 9, Step: 353/655, Loss: 2.210805, Accuracy: 18.32%\n",
            "Epoch: 9, Step: 354/655, Loss: 2.210680, Accuracy: 18.32%\n",
            "Epoch: 9, Step: 355/655, Loss: 2.210051, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 356/655, Loss: 2.210054, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 357/655, Loss: 2.209951, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 358/655, Loss: 2.210068, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 359/655, Loss: 2.210387, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 360/655, Loss: 2.210718, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 361/655, Loss: 2.210498, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 362/655, Loss: 2.210704, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 363/655, Loss: 2.210526, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 364/655, Loss: 2.210568, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 365/655, Loss: 2.210440, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 366/655, Loss: 2.210279, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 367/655, Loss: 2.210485, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 368/655, Loss: 2.210684, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 369/655, Loss: 2.210645, Accuracy: 18.29%\n",
            "Epoch: 9, Step: 370/655, Loss: 2.210290, Accuracy: 18.31%\n",
            "Epoch: 9, Step: 371/655, Loss: 2.210031, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 372/655, Loss: 2.209921, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 373/655, Loss: 2.210265, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 374/655, Loss: 2.210023, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 375/655, Loss: 2.210147, Accuracy: 18.32%\n",
            "Epoch: 9, Step: 376/655, Loss: 2.210017, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 377/655, Loss: 2.209718, Accuracy: 18.39%\n",
            "Epoch: 9, Step: 378/655, Loss: 2.209323, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 379/655, Loss: 2.209314, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 380/655, Loss: 2.209278, Accuracy: 18.39%\n",
            "Epoch: 9, Step: 381/655, Loss: 2.209339, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 382/655, Loss: 2.209415, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 383/655, Loss: 2.209372, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 384/655, Loss: 2.209277, Accuracy: 18.39%\n",
            "Epoch: 9, Step: 385/655, Loss: 2.209225, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 386/655, Loss: 2.209371, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 387/655, Loss: 2.208992, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 388/655, Loss: 2.209022, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 389/655, Loss: 2.209362, Accuracy: 18.39%\n",
            "Epoch: 9, Step: 390/655, Loss: 2.209511, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 391/655, Loss: 2.209237, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 392/655, Loss: 2.209030, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 393/655, Loss: 2.209000, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 394/655, Loss: 2.209071, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 395/655, Loss: 2.209027, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 396/655, Loss: 2.209305, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 397/655, Loss: 2.209206, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 398/655, Loss: 2.208815, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 399/655, Loss: 2.208843, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 400/655, Loss: 2.209145, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 401/655, Loss: 2.209204, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 402/655, Loss: 2.209226, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 403/655, Loss: 2.209526, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 404/655, Loss: 2.209503, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 405/655, Loss: 2.209376, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 406/655, Loss: 2.209496, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 407/655, Loss: 2.209859, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 408/655, Loss: 2.209763, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 409/655, Loss: 2.209998, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 410/655, Loss: 2.210128, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 411/655, Loss: 2.209782, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 412/655, Loss: 2.209890, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 413/655, Loss: 2.210036, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 414/655, Loss: 2.210095, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 415/655, Loss: 2.210046, Accuracy: 18.31%\n",
            "Epoch: 9, Step: 416/655, Loss: 2.210175, Accuracy: 18.32%\n",
            "Epoch: 9, Step: 417/655, Loss: 2.209968, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 418/655, Loss: 2.209967, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 419/655, Loss: 2.209901, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 420/655, Loss: 2.209832, Accuracy: 18.39%\n",
            "Epoch: 9, Step: 421/655, Loss: 2.209797, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 422/655, Loss: 2.209652, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 423/655, Loss: 2.209616, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 424/655, Loss: 2.209630, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 425/655, Loss: 2.209861, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 426/655, Loss: 2.209826, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 427/655, Loss: 2.210130, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 428/655, Loss: 2.210395, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 429/655, Loss: 2.210304, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 430/655, Loss: 2.210340, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 431/655, Loss: 2.210125, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 432/655, Loss: 2.209922, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 433/655, Loss: 2.209869, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 434/655, Loss: 2.209970, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 435/655, Loss: 2.209728, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 436/655, Loss: 2.209804, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 437/655, Loss: 2.209765, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 438/655, Loss: 2.209426, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 439/655, Loss: 2.209124, Accuracy: 18.47%\n",
            "Epoch: 9, Step: 440/655, Loss: 2.209394, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 441/655, Loss: 2.209278, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 442/655, Loss: 2.209318, Accuracy: 18.47%\n",
            "Epoch: 9, Step: 443/655, Loss: 2.209530, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 444/655, Loss: 2.209262, Accuracy: 18.48%\n",
            "Epoch: 9, Step: 445/655, Loss: 2.209622, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 446/655, Loss: 2.209599, Accuracy: 18.46%\n",
            "Epoch: 9, Step: 447/655, Loss: 2.209875, Accuracy: 18.46%\n",
            "Epoch: 9, Step: 448/655, Loss: 2.210024, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 449/655, Loss: 2.210030, Accuracy: 18.46%\n",
            "Epoch: 9, Step: 450/655, Loss: 2.209908, Accuracy: 18.47%\n",
            "Epoch: 9, Step: 451/655, Loss: 2.209898, Accuracy: 18.46%\n",
            "Epoch: 9, Step: 452/655, Loss: 2.209959, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 453/655, Loss: 2.210033, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 454/655, Loss: 2.209793, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 455/655, Loss: 2.210074, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 456/655, Loss: 2.209763, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 457/655, Loss: 2.209923, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 458/655, Loss: 2.209897, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 459/655, Loss: 2.210015, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 460/655, Loss: 2.210155, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 461/655, Loss: 2.210080, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 462/655, Loss: 2.209941, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 463/655, Loss: 2.209876, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 464/655, Loss: 2.209421, Accuracy: 18.46%\n",
            "Epoch: 9, Step: 465/655, Loss: 2.209538, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 466/655, Loss: 2.209725, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 467/655, Loss: 2.209675, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 468/655, Loss: 2.210029, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 469/655, Loss: 2.209895, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 470/655, Loss: 2.209777, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 471/655, Loss: 2.209744, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 472/655, Loss: 2.209744, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 473/655, Loss: 2.209875, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 474/655, Loss: 2.209752, Accuracy: 18.39%\n",
            "Epoch: 9, Step: 475/655, Loss: 2.209761, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 476/655, Loss: 2.209925, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 477/655, Loss: 2.209770, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 478/655, Loss: 2.209863, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 479/655, Loss: 2.209876, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 480/655, Loss: 2.209795, Accuracy: 18.39%\n",
            "Epoch: 9, Step: 481/655, Loss: 2.209885, Accuracy: 18.39%\n",
            "Epoch: 9, Step: 482/655, Loss: 2.209671, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 483/655, Loss: 2.209596, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 484/655, Loss: 2.209741, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 485/655, Loss: 2.209779, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 486/655, Loss: 2.209889, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 487/655, Loss: 2.209921, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 488/655, Loss: 2.209835, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 489/655, Loss: 2.209896, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 490/655, Loss: 2.210396, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 491/655, Loss: 2.210440, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 492/655, Loss: 2.210322, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 493/655, Loss: 2.210078, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 494/655, Loss: 2.210177, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 495/655, Loss: 2.210288, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 496/655, Loss: 2.210584, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 497/655, Loss: 2.210448, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 498/655, Loss: 2.210383, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 499/655, Loss: 2.210284, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 500/655, Loss: 2.210096, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 501/655, Loss: 2.209915, Accuracy: 18.39%\n",
            "Epoch: 9, Step: 502/655, Loss: 2.209916, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 503/655, Loss: 2.209834, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 504/655, Loss: 2.209730, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 505/655, Loss: 2.209645, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 506/655, Loss: 2.209481, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 507/655, Loss: 2.209480, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 508/655, Loss: 2.209325, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 509/655, Loss: 2.209255, Accuracy: 18.46%\n",
            "Epoch: 9, Step: 510/655, Loss: 2.209203, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 511/655, Loss: 2.209036, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 512/655, Loss: 2.208997, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 513/655, Loss: 2.208811, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 514/655, Loss: 2.208729, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 515/655, Loss: 2.208626, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 516/655, Loss: 2.208526, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 517/655, Loss: 2.208710, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 518/655, Loss: 2.208506, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 519/655, Loss: 2.208599, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 520/655, Loss: 2.208587, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 521/655, Loss: 2.208760, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 522/655, Loss: 2.208624, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 523/655, Loss: 2.208407, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 524/655, Loss: 2.208264, Accuracy: 18.46%\n",
            "Epoch: 9, Step: 525/655, Loss: 2.208248, Accuracy: 18.47%\n",
            "Epoch: 9, Step: 526/655, Loss: 2.208186, Accuracy: 18.48%\n",
            "Epoch: 9, Step: 527/655, Loss: 2.208248, Accuracy: 18.46%\n",
            "Epoch: 9, Step: 528/655, Loss: 2.208120, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 529/655, Loss: 2.208084, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 530/655, Loss: 2.208368, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 531/655, Loss: 2.208142, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 532/655, Loss: 2.208202, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 533/655, Loss: 2.208141, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 534/655, Loss: 2.208311, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 535/655, Loss: 2.208090, Accuracy: 18.46%\n",
            "Epoch: 9, Step: 536/655, Loss: 2.207987, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 537/655, Loss: 2.207857, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 538/655, Loss: 2.207616, Accuracy: 18.46%\n",
            "Epoch: 9, Step: 539/655, Loss: 2.207589, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 540/655, Loss: 2.207774, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 541/655, Loss: 2.207737, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 542/655, Loss: 2.207635, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 543/655, Loss: 2.207768, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 544/655, Loss: 2.207579, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 545/655, Loss: 2.207656, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 546/655, Loss: 2.207406, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 547/655, Loss: 2.207624, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 548/655, Loss: 2.207617, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 549/655, Loss: 2.207592, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 550/655, Loss: 2.207337, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 551/655, Loss: 2.207411, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 552/655, Loss: 2.207443, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 553/655, Loss: 2.207250, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 554/655, Loss: 2.207124, Accuracy: 18.45%\n",
            "Epoch: 9, Step: 555/655, Loss: 2.207244, Accuracy: 18.43%\n",
            "Epoch: 9, Step: 556/655, Loss: 2.207399, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 557/655, Loss: 2.207369, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 558/655, Loss: 2.207523, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 559/655, Loss: 2.207486, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 560/655, Loss: 2.207461, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 561/655, Loss: 2.207339, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 562/655, Loss: 2.207450, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 563/655, Loss: 2.207504, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 564/655, Loss: 2.207515, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 565/655, Loss: 2.207594, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 566/655, Loss: 2.207466, Accuracy: 18.44%\n",
            "Epoch: 9, Step: 567/655, Loss: 2.207674, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 568/655, Loss: 2.207727, Accuracy: 18.42%\n",
            "Epoch: 9, Step: 569/655, Loss: 2.207842, Accuracy: 18.41%\n",
            "Epoch: 9, Step: 570/655, Loss: 2.207717, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 571/655, Loss: 2.207852, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 572/655, Loss: 2.207862, Accuracy: 18.39%\n",
            "Epoch: 9, Step: 573/655, Loss: 2.207692, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 574/655, Loss: 2.207625, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 575/655, Loss: 2.207558, Accuracy: 18.40%\n",
            "Epoch: 9, Step: 576/655, Loss: 2.207995, Accuracy: 18.39%\n",
            "Epoch: 9, Step: 577/655, Loss: 2.208039, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 578/655, Loss: 2.207886, Accuracy: 18.38%\n",
            "Epoch: 9, Step: 579/655, Loss: 2.207916, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 580/655, Loss: 2.208058, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 581/655, Loss: 2.207888, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 582/655, Loss: 2.207785, Accuracy: 18.37%\n",
            "Epoch: 9, Step: 583/655, Loss: 2.207959, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 584/655, Loss: 2.208067, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 585/655, Loss: 2.208132, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 586/655, Loss: 2.208184, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 587/655, Loss: 2.208049, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 588/655, Loss: 2.208033, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 589/655, Loss: 2.207963, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 590/655, Loss: 2.207881, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 591/655, Loss: 2.207750, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 592/655, Loss: 2.207949, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 593/655, Loss: 2.207854, Accuracy: 18.36%\n",
            "Epoch: 9, Step: 594/655, Loss: 2.208123, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 595/655, Loss: 2.208132, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 596/655, Loss: 2.208144, Accuracy: 18.35%\n",
            "Epoch: 9, Step: 597/655, Loss: 2.208122, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 598/655, Loss: 2.208057, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 599/655, Loss: 2.207916, Accuracy: 18.34%\n",
            "Epoch: 9, Step: 600/655, Loss: 2.207992, Accuracy: 18.33%\n",
            "Epoch: 9, Step: 601/655, Loss: 2.208239, Accuracy: 18.31%\n",
            "Epoch: 9, Step: 602/655, Loss: 2.208496, Accuracy: 18.29%\n",
            "Epoch: 9, Step: 603/655, Loss: 2.208594, Accuracy: 18.29%\n",
            "Epoch: 9, Step: 604/655, Loss: 2.208616, Accuracy: 18.28%\n",
            "Epoch: 9, Step: 605/655, Loss: 2.208524, Accuracy: 18.27%\n",
            "Epoch: 9, Step: 606/655, Loss: 2.208637, Accuracy: 18.24%\n",
            "Epoch: 9, Step: 607/655, Loss: 2.208587, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 608/655, Loss: 2.208648, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 609/655, Loss: 2.208874, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 610/655, Loss: 2.208859, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 611/655, Loss: 2.209011, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 612/655, Loss: 2.208972, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 613/655, Loss: 2.208921, Accuracy: 18.27%\n",
            "Epoch: 9, Step: 614/655, Loss: 2.209032, Accuracy: 18.25%\n",
            "Epoch: 9, Step: 615/655, Loss: 2.209015, Accuracy: 18.26%\n",
            "Epoch: 9, Step: 616/655, Loss: 2.209167, Accuracy: 18.25%\n",
            "Epoch: 9, Step: 617/655, Loss: 2.209218, Accuracy: 18.24%\n",
            "Epoch: 9, Step: 618/655, Loss: 2.209085, Accuracy: 18.23%\n",
            "Epoch: 9, Step: 619/655, Loss: 2.209135, Accuracy: 18.23%\n",
            "Epoch: 9, Step: 620/655, Loss: 2.208900, Accuracy: 18.24%\n",
            "Epoch: 9, Step: 621/655, Loss: 2.208854, Accuracy: 18.23%\n",
            "Epoch: 9, Step: 622/655, Loss: 2.208898, Accuracy: 18.22%\n",
            "Epoch: 9, Step: 623/655, Loss: 2.208851, Accuracy: 18.23%\n",
            "Epoch: 9, Step: 624/655, Loss: 2.208811, Accuracy: 18.23%\n",
            "Epoch: 9, Step: 625/655, Loss: 2.208773, Accuracy: 18.21%\n",
            "Epoch: 9, Step: 626/655, Loss: 2.208724, Accuracy: 18.22%\n",
            "Epoch: 9, Step: 627/655, Loss: 2.208787, Accuracy: 18.22%\n",
            "Epoch: 9, Step: 628/655, Loss: 2.208707, Accuracy: 18.22%\n",
            "Epoch: 9, Step: 629/655, Loss: 2.208528, Accuracy: 18.21%\n",
            "Epoch: 9, Step: 630/655, Loss: 2.208331, Accuracy: 18.23%\n",
            "Epoch: 9, Step: 631/655, Loss: 2.208157, Accuracy: 18.24%\n",
            "Epoch: 9, Step: 632/655, Loss: 2.208302, Accuracy: 18.23%\n",
            "Epoch: 9, Step: 633/655, Loss: 2.208472, Accuracy: 18.21%\n",
            "Epoch: 9, Step: 634/655, Loss: 2.208349, Accuracy: 18.22%\n",
            "Epoch: 9, Step: 635/655, Loss: 2.208479, Accuracy: 18.21%\n",
            "Epoch: 9, Step: 636/655, Loss: 2.208592, Accuracy: 18.19%\n",
            "Epoch: 9, Step: 637/655, Loss: 2.208722, Accuracy: 18.18%\n",
            "Epoch: 9, Step: 638/655, Loss: 2.208789, Accuracy: 18.18%\n",
            "Epoch: 9, Step: 639/655, Loss: 2.208862, Accuracy: 18.16%\n",
            "Epoch: 9, Step: 640/655, Loss: 2.208767, Accuracy: 18.16%\n",
            "Epoch: 9, Step: 641/655, Loss: 2.208709, Accuracy: 18.15%\n",
            "Epoch: 9, Step: 642/655, Loss: 2.208552, Accuracy: 18.15%\n",
            "Epoch: 9, Step: 643/655, Loss: 2.208629, Accuracy: 18.14%\n",
            "Epoch: 9, Step: 644/655, Loss: 2.208826, Accuracy: 18.12%\n",
            "Epoch: 9, Step: 645/655, Loss: 2.208688, Accuracy: 18.11%\n",
            "Epoch: 9, Step: 646/655, Loss: 2.208601, Accuracy: 18.11%\n",
            "Epoch: 9, Step: 647/655, Loss: 2.208537, Accuracy: 18.10%\n",
            "Epoch: 9, Step: 648/655, Loss: 2.208599, Accuracy: 18.11%\n",
            "Epoch: 9, Step: 649/655, Loss: 2.208554, Accuracy: 18.11%\n",
            "Epoch: 9, Step: 650/655, Loss: 2.208440, Accuracy: 18.12%\n",
            "Epoch: 9, Step: 651/655, Loss: 2.208381, Accuracy: 18.13%\n",
            "Epoch: 9, Step: 652/655, Loss: 2.208366, Accuracy: 18.12%\n",
            "Epoch: 9, Step: 653/655, Loss: 2.208426, Accuracy: 18.13%\n",
            "Epoch: 9, Step: 654/655, Loss: 2.208214, Accuracy: 18.15%\n",
            "Epoch: 9, Step: 655/655, Loss: 2.208146, Accuracy: 18.15%\n",
            "Epoch: 10, Step: 1/655, Loss: 2.162682, Accuracy: 21.88%\n",
            "Epoch: 10, Step: 2/655, Loss: 2.191828, Accuracy: 18.75%\n",
            "Epoch: 10, Step: 3/655, Loss: 2.279911, Accuracy: 14.58%\n",
            "Epoch: 10, Step: 4/655, Loss: 2.252271, Accuracy: 15.62%\n",
            "Epoch: 10, Step: 5/655, Loss: 2.253549, Accuracy: 16.25%\n",
            "Epoch: 10, Step: 6/655, Loss: 2.260364, Accuracy: 15.10%\n",
            "Epoch: 10, Step: 7/655, Loss: 2.254213, Accuracy: 16.07%\n",
            "Epoch: 10, Step: 8/655, Loss: 2.242971, Accuracy: 16.02%\n",
            "Epoch: 10, Step: 9/655, Loss: 2.248410, Accuracy: 15.28%\n",
            "Epoch: 10, Step: 10/655, Loss: 2.248080, Accuracy: 14.38%\n",
            "Epoch: 10, Step: 11/655, Loss: 2.246303, Accuracy: 14.49%\n",
            "Epoch: 10, Step: 12/655, Loss: 2.245010, Accuracy: 14.32%\n",
            "Epoch: 10, Step: 13/655, Loss: 2.248721, Accuracy: 14.42%\n",
            "Epoch: 10, Step: 14/655, Loss: 2.251623, Accuracy: 14.29%\n",
            "Epoch: 10, Step: 15/655, Loss: 2.253978, Accuracy: 13.96%\n",
            "Epoch: 10, Step: 16/655, Loss: 2.256892, Accuracy: 13.67%\n",
            "Epoch: 10, Step: 17/655, Loss: 2.256197, Accuracy: 13.79%\n",
            "Epoch: 10, Step: 18/655, Loss: 2.247143, Accuracy: 14.76%\n",
            "Epoch: 10, Step: 19/655, Loss: 2.247564, Accuracy: 14.97%\n",
            "Epoch: 10, Step: 20/655, Loss: 2.249123, Accuracy: 15.31%\n",
            "Epoch: 10, Step: 21/655, Loss: 2.248638, Accuracy: 15.18%\n",
            "Epoch: 10, Step: 22/655, Loss: 2.246896, Accuracy: 15.06%\n",
            "Epoch: 10, Step: 23/655, Loss: 2.248238, Accuracy: 14.81%\n",
            "Epoch: 10, Step: 24/655, Loss: 2.241380, Accuracy: 15.89%\n",
            "Epoch: 10, Step: 25/655, Loss: 2.236584, Accuracy: 16.12%\n",
            "Epoch: 10, Step: 26/655, Loss: 2.232724, Accuracy: 16.11%\n",
            "Epoch: 10, Step: 27/655, Loss: 2.233039, Accuracy: 16.09%\n",
            "Epoch: 10, Step: 28/655, Loss: 2.230389, Accuracy: 16.18%\n",
            "Epoch: 10, Step: 29/655, Loss: 2.227696, Accuracy: 16.06%\n",
            "Epoch: 10, Step: 30/655, Loss: 2.228131, Accuracy: 16.25%\n",
            "Epoch: 10, Step: 31/655, Loss: 2.229138, Accuracy: 16.33%\n",
            "Epoch: 10, Step: 32/655, Loss: 2.226962, Accuracy: 16.50%\n",
            "Epoch: 10, Step: 33/655, Loss: 2.224219, Accuracy: 16.57%\n",
            "Epoch: 10, Step: 34/655, Loss: 2.222861, Accuracy: 16.73%\n",
            "Epoch: 10, Step: 35/655, Loss: 2.218544, Accuracy: 17.23%\n",
            "Epoch: 10, Step: 36/655, Loss: 2.219681, Accuracy: 17.36%\n",
            "Epoch: 10, Step: 37/655, Loss: 2.219765, Accuracy: 17.31%\n",
            "Epoch: 10, Step: 38/655, Loss: 2.215750, Accuracy: 17.52%\n",
            "Epoch: 10, Step: 39/655, Loss: 2.213077, Accuracy: 17.71%\n",
            "Epoch: 10, Step: 40/655, Loss: 2.212403, Accuracy: 17.89%\n",
            "Epoch: 10, Step: 41/655, Loss: 2.212011, Accuracy: 17.76%\n",
            "Epoch: 10, Step: 42/655, Loss: 2.213489, Accuracy: 17.63%\n",
            "Epoch: 10, Step: 43/655, Loss: 2.215283, Accuracy: 17.59%\n",
            "Epoch: 10, Step: 44/655, Loss: 2.212884, Accuracy: 17.61%\n",
            "Epoch: 10, Step: 45/655, Loss: 2.209658, Accuracy: 17.57%\n",
            "Epoch: 10, Step: 46/655, Loss: 2.204916, Accuracy: 18.14%\n",
            "Epoch: 10, Step: 47/655, Loss: 2.206548, Accuracy: 18.09%\n",
            "Epoch: 10, Step: 48/655, Loss: 2.206753, Accuracy: 18.16%\n",
            "Epoch: 10, Step: 49/655, Loss: 2.203699, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 50/655, Loss: 2.203616, Accuracy: 18.69%\n",
            "Epoch: 10, Step: 51/655, Loss: 2.203445, Accuracy: 18.69%\n",
            "Epoch: 10, Step: 52/655, Loss: 2.204764, Accuracy: 18.81%\n",
            "Epoch: 10, Step: 53/655, Loss: 2.205203, Accuracy: 18.81%\n",
            "Epoch: 10, Step: 54/655, Loss: 2.204715, Accuracy: 18.69%\n",
            "Epoch: 10, Step: 55/655, Loss: 2.205994, Accuracy: 18.58%\n",
            "Epoch: 10, Step: 56/655, Loss: 2.205488, Accuracy: 18.58%\n",
            "Epoch: 10, Step: 57/655, Loss: 2.203528, Accuracy: 18.80%\n",
            "Epoch: 10, Step: 58/655, Loss: 2.203685, Accuracy: 18.80%\n",
            "Epoch: 10, Step: 59/655, Loss: 2.203456, Accuracy: 18.75%\n",
            "Epoch: 10, Step: 60/655, Loss: 2.201760, Accuracy: 18.85%\n",
            "Epoch: 10, Step: 61/655, Loss: 2.202017, Accuracy: 19.01%\n",
            "Epoch: 10, Step: 62/655, Loss: 2.201873, Accuracy: 19.10%\n",
            "Epoch: 10, Step: 63/655, Loss: 2.201406, Accuracy: 19.20%\n",
            "Epoch: 10, Step: 64/655, Loss: 2.203207, Accuracy: 19.09%\n",
            "Epoch: 10, Step: 65/655, Loss: 2.205170, Accuracy: 18.94%\n",
            "Epoch: 10, Step: 66/655, Loss: 2.204193, Accuracy: 18.94%\n",
            "Epoch: 10, Step: 67/655, Loss: 2.205578, Accuracy: 18.89%\n",
            "Epoch: 10, Step: 68/655, Loss: 2.205261, Accuracy: 18.89%\n",
            "Epoch: 10, Step: 69/655, Loss: 2.206807, Accuracy: 18.98%\n",
            "Epoch: 10, Step: 70/655, Loss: 2.209386, Accuracy: 18.93%\n",
            "Epoch: 10, Step: 71/655, Loss: 2.210181, Accuracy: 18.84%\n",
            "Epoch: 10, Step: 72/655, Loss: 2.210721, Accuracy: 18.92%\n",
            "Epoch: 10, Step: 73/655, Loss: 2.211403, Accuracy: 18.92%\n",
            "Epoch: 10, Step: 74/655, Loss: 2.213085, Accuracy: 18.88%\n",
            "Epoch: 10, Step: 75/655, Loss: 2.211043, Accuracy: 18.88%\n",
            "Epoch: 10, Step: 76/655, Loss: 2.210557, Accuracy: 18.71%\n",
            "Epoch: 10, Step: 77/655, Loss: 2.209029, Accuracy: 18.79%\n",
            "Epoch: 10, Step: 78/655, Loss: 2.209671, Accuracy: 18.75%\n",
            "Epoch: 10, Step: 79/655, Loss: 2.210838, Accuracy: 18.67%\n",
            "Epoch: 10, Step: 80/655, Loss: 2.210250, Accuracy: 18.71%\n",
            "Epoch: 10, Step: 81/655, Loss: 2.211646, Accuracy: 18.67%\n",
            "Epoch: 10, Step: 82/655, Loss: 2.211307, Accuracy: 18.75%\n",
            "Epoch: 10, Step: 83/655, Loss: 2.210607, Accuracy: 18.64%\n",
            "Epoch: 10, Step: 84/655, Loss: 2.210975, Accuracy: 18.56%\n",
            "Epoch: 10, Step: 85/655, Loss: 2.211693, Accuracy: 18.60%\n",
            "Epoch: 10, Step: 86/655, Loss: 2.209843, Accuracy: 18.68%\n",
            "Epoch: 10, Step: 87/655, Loss: 2.209644, Accuracy: 18.64%\n",
            "Epoch: 10, Step: 88/655, Loss: 2.209329, Accuracy: 18.57%\n",
            "Epoch: 10, Step: 89/655, Loss: 2.208962, Accuracy: 18.68%\n",
            "Epoch: 10, Step: 90/655, Loss: 2.209960, Accuracy: 18.61%\n",
            "Epoch: 10, Step: 91/655, Loss: 2.210205, Accuracy: 18.58%\n",
            "Epoch: 10, Step: 92/655, Loss: 2.209890, Accuracy: 18.68%\n",
            "Epoch: 10, Step: 93/655, Loss: 2.207696, Accuracy: 18.75%\n",
            "Epoch: 10, Step: 94/655, Loss: 2.208544, Accuracy: 18.75%\n",
            "Epoch: 10, Step: 95/655, Loss: 2.208474, Accuracy: 18.72%\n",
            "Epoch: 10, Step: 96/655, Loss: 2.209484, Accuracy: 18.72%\n",
            "Epoch: 10, Step: 97/655, Loss: 2.208353, Accuracy: 18.75%\n",
            "Epoch: 10, Step: 98/655, Loss: 2.209186, Accuracy: 18.65%\n",
            "Epoch: 10, Step: 99/655, Loss: 2.208777, Accuracy: 18.69%\n",
            "Epoch: 10, Step: 100/655, Loss: 2.208572, Accuracy: 18.62%\n",
            "Epoch: 10, Step: 101/655, Loss: 2.208300, Accuracy: 18.60%\n",
            "Epoch: 10, Step: 102/655, Loss: 2.206883, Accuracy: 18.54%\n",
            "Epoch: 10, Step: 103/655, Loss: 2.205740, Accuracy: 18.72%\n",
            "Epoch: 10, Step: 104/655, Loss: 2.206488, Accuracy: 18.63%\n",
            "Epoch: 10, Step: 105/655, Loss: 2.206964, Accuracy: 18.60%\n",
            "Epoch: 10, Step: 106/655, Loss: 2.206316, Accuracy: 18.57%\n",
            "Epoch: 10, Step: 107/655, Loss: 2.207195, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 108/655, Loss: 2.206886, Accuracy: 18.66%\n",
            "Epoch: 10, Step: 109/655, Loss: 2.205833, Accuracy: 18.66%\n",
            "Epoch: 10, Step: 110/655, Loss: 2.205384, Accuracy: 18.58%\n",
            "Epoch: 10, Step: 111/655, Loss: 2.205046, Accuracy: 18.55%\n",
            "Epoch: 10, Step: 112/655, Loss: 2.204880, Accuracy: 18.67%\n",
            "Epoch: 10, Step: 113/655, Loss: 2.203929, Accuracy: 18.72%\n",
            "Epoch: 10, Step: 114/655, Loss: 2.203761, Accuracy: 18.78%\n",
            "Epoch: 10, Step: 115/655, Loss: 2.203993, Accuracy: 18.70%\n",
            "Epoch: 10, Step: 116/655, Loss: 2.203829, Accuracy: 18.67%\n",
            "Epoch: 10, Step: 117/655, Loss: 2.203657, Accuracy: 18.64%\n",
            "Epoch: 10, Step: 118/655, Loss: 2.203138, Accuracy: 18.70%\n",
            "Epoch: 10, Step: 119/655, Loss: 2.203817, Accuracy: 18.64%\n",
            "Epoch: 10, Step: 120/655, Loss: 2.203964, Accuracy: 18.70%\n",
            "Epoch: 10, Step: 121/655, Loss: 2.204104, Accuracy: 18.83%\n",
            "Epoch: 10, Step: 122/655, Loss: 2.204758, Accuracy: 18.75%\n",
            "Epoch: 10, Step: 123/655, Loss: 2.204692, Accuracy: 18.85%\n",
            "Epoch: 10, Step: 124/655, Loss: 2.205531, Accuracy: 18.83%\n",
            "Epoch: 10, Step: 125/655, Loss: 2.205786, Accuracy: 18.82%\n",
            "Epoch: 10, Step: 126/655, Loss: 2.205577, Accuracy: 18.82%\n",
            "Epoch: 10, Step: 127/655, Loss: 2.205334, Accuracy: 18.82%\n",
            "Epoch: 10, Step: 128/655, Loss: 2.204759, Accuracy: 18.82%\n",
            "Epoch: 10, Step: 129/655, Loss: 2.204430, Accuracy: 18.80%\n",
            "Epoch: 10, Step: 130/655, Loss: 2.205164, Accuracy: 18.80%\n",
            "Epoch: 10, Step: 131/655, Loss: 2.205710, Accuracy: 18.77%\n",
            "Epoch: 10, Step: 132/655, Loss: 2.205041, Accuracy: 18.77%\n",
            "Epoch: 10, Step: 133/655, Loss: 2.206052, Accuracy: 18.68%\n",
            "Epoch: 10, Step: 134/655, Loss: 2.206055, Accuracy: 18.66%\n",
            "Epoch: 10, Step: 135/655, Loss: 2.206313, Accuracy: 18.61%\n",
            "Epoch: 10, Step: 136/655, Loss: 2.205907, Accuracy: 18.57%\n",
            "Epoch: 10, Step: 137/655, Loss: 2.207967, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 138/655, Loss: 2.207807, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 139/655, Loss: 2.207962, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 140/655, Loss: 2.208078, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 141/655, Loss: 2.209025, Accuracy: 18.37%\n",
            "Epoch: 10, Step: 142/655, Loss: 2.208955, Accuracy: 18.38%\n",
            "Epoch: 10, Step: 143/655, Loss: 2.208169, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 144/655, Loss: 2.208004, Accuracy: 18.38%\n",
            "Epoch: 10, Step: 145/655, Loss: 2.208888, Accuracy: 18.28%\n",
            "Epoch: 10, Step: 146/655, Loss: 2.209691, Accuracy: 18.26%\n",
            "Epoch: 10, Step: 147/655, Loss: 2.209045, Accuracy: 18.37%\n",
            "Epoch: 10, Step: 148/655, Loss: 2.209216, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 149/655, Loss: 2.209538, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 150/655, Loss: 2.208669, Accuracy: 18.33%\n",
            "Epoch: 10, Step: 151/655, Loss: 2.208663, Accuracy: 18.32%\n",
            "Epoch: 10, Step: 152/655, Loss: 2.207718, Accuracy: 18.36%\n",
            "Epoch: 10, Step: 153/655, Loss: 2.207486, Accuracy: 18.40%\n",
            "Epoch: 10, Step: 154/655, Loss: 2.208152, Accuracy: 18.38%\n",
            "Epoch: 10, Step: 155/655, Loss: 2.208707, Accuracy: 18.33%\n",
            "Epoch: 10, Step: 156/655, Loss: 2.208122, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 157/655, Loss: 2.208901, Accuracy: 18.33%\n",
            "Epoch: 10, Step: 158/655, Loss: 2.208999, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 159/655, Loss: 2.209345, Accuracy: 18.38%\n",
            "Epoch: 10, Step: 160/655, Loss: 2.208765, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 161/655, Loss: 2.208617, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 162/655, Loss: 2.208491, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 163/655, Loss: 2.208188, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 164/655, Loss: 2.208933, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 165/655, Loss: 2.209232, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 166/655, Loss: 2.208978, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 167/655, Loss: 2.208464, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 168/655, Loss: 2.208040, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 169/655, Loss: 2.208050, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 170/655, Loss: 2.207987, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 171/655, Loss: 2.207403, Accuracy: 18.55%\n",
            "Epoch: 10, Step: 172/655, Loss: 2.206867, Accuracy: 18.55%\n",
            "Epoch: 10, Step: 173/655, Loss: 2.207193, Accuracy: 18.53%\n",
            "Epoch: 10, Step: 174/655, Loss: 2.207495, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 175/655, Loss: 2.208018, Accuracy: 18.50%\n",
            "Epoch: 10, Step: 176/655, Loss: 2.207328, Accuracy: 18.54%\n",
            "Epoch: 10, Step: 177/655, Loss: 2.207040, Accuracy: 18.54%\n",
            "Epoch: 10, Step: 178/655, Loss: 2.206405, Accuracy: 18.59%\n",
            "Epoch: 10, Step: 179/655, Loss: 2.206080, Accuracy: 18.65%\n",
            "Epoch: 10, Step: 180/655, Loss: 2.206781, Accuracy: 18.66%\n",
            "Epoch: 10, Step: 181/655, Loss: 2.206974, Accuracy: 18.66%\n",
            "Epoch: 10, Step: 182/655, Loss: 2.206901, Accuracy: 18.66%\n",
            "Epoch: 10, Step: 183/655, Loss: 2.207024, Accuracy: 18.63%\n",
            "Epoch: 10, Step: 184/655, Loss: 2.206711, Accuracy: 18.65%\n",
            "Epoch: 10, Step: 185/655, Loss: 2.206422, Accuracy: 18.70%\n",
            "Epoch: 10, Step: 186/655, Loss: 2.206761, Accuracy: 18.70%\n",
            "Epoch: 10, Step: 187/655, Loss: 2.206667, Accuracy: 18.67%\n",
            "Epoch: 10, Step: 188/655, Loss: 2.207471, Accuracy: 18.63%\n",
            "Epoch: 10, Step: 189/655, Loss: 2.207049, Accuracy: 18.63%\n",
            "Epoch: 10, Step: 190/655, Loss: 2.205967, Accuracy: 18.62%\n",
            "Epoch: 10, Step: 191/655, Loss: 2.206405, Accuracy: 18.64%\n",
            "Epoch: 10, Step: 192/655, Loss: 2.206812, Accuracy: 18.57%\n",
            "Epoch: 10, Step: 193/655, Loss: 2.206715, Accuracy: 18.62%\n",
            "Epoch: 10, Step: 194/655, Loss: 2.206484, Accuracy: 18.67%\n",
            "Epoch: 10, Step: 195/655, Loss: 2.206981, Accuracy: 18.62%\n",
            "Epoch: 10, Step: 196/655, Loss: 2.206759, Accuracy: 18.70%\n",
            "Epoch: 10, Step: 197/655, Loss: 2.205826, Accuracy: 18.72%\n",
            "Epoch: 10, Step: 198/655, Loss: 2.205961, Accuracy: 18.72%\n",
            "Epoch: 10, Step: 199/655, Loss: 2.206296, Accuracy: 18.69%\n",
            "Epoch: 10, Step: 200/655, Loss: 2.206506, Accuracy: 18.69%\n",
            "Epoch: 10, Step: 201/655, Loss: 2.206121, Accuracy: 18.72%\n",
            "Epoch: 10, Step: 202/655, Loss: 2.205660, Accuracy: 18.70%\n",
            "Epoch: 10, Step: 203/655, Loss: 2.206351, Accuracy: 18.67%\n",
            "Epoch: 10, Step: 204/655, Loss: 2.206899, Accuracy: 18.64%\n",
            "Epoch: 10, Step: 205/655, Loss: 2.207414, Accuracy: 18.61%\n",
            "Epoch: 10, Step: 206/655, Loss: 2.206979, Accuracy: 18.67%\n",
            "Epoch: 10, Step: 207/655, Loss: 2.205906, Accuracy: 18.75%\n",
            "Epoch: 10, Step: 208/655, Loss: 2.206583, Accuracy: 18.73%\n",
            "Epoch: 10, Step: 209/655, Loss: 2.206675, Accuracy: 18.75%\n",
            "Epoch: 10, Step: 210/655, Loss: 2.206621, Accuracy: 18.72%\n",
            "Epoch: 10, Step: 211/655, Loss: 2.207077, Accuracy: 18.69%\n",
            "Epoch: 10, Step: 212/655, Loss: 2.206498, Accuracy: 18.71%\n",
            "Epoch: 10, Step: 213/655, Loss: 2.206468, Accuracy: 18.68%\n",
            "Epoch: 10, Step: 214/655, Loss: 2.206267, Accuracy: 18.65%\n",
            "Epoch: 10, Step: 215/655, Loss: 2.206343, Accuracy: 18.68%\n",
            "Epoch: 10, Step: 216/655, Loss: 2.205901, Accuracy: 18.69%\n",
            "Epoch: 10, Step: 217/655, Loss: 2.205700, Accuracy: 18.72%\n",
            "Epoch: 10, Step: 218/655, Loss: 2.205941, Accuracy: 18.69%\n",
            "Epoch: 10, Step: 219/655, Loss: 2.206311, Accuracy: 18.65%\n",
            "Epoch: 10, Step: 220/655, Loss: 2.206090, Accuracy: 18.65%\n",
            "Epoch: 10, Step: 221/655, Loss: 2.206181, Accuracy: 18.68%\n",
            "Epoch: 10, Step: 222/655, Loss: 2.206165, Accuracy: 18.64%\n",
            "Epoch: 10, Step: 223/655, Loss: 2.206314, Accuracy: 18.65%\n",
            "Epoch: 10, Step: 224/655, Loss: 2.206241, Accuracy: 18.65%\n",
            "Epoch: 10, Step: 225/655, Loss: 2.206203, Accuracy: 18.62%\n",
            "Epoch: 10, Step: 226/655, Loss: 2.206207, Accuracy: 18.64%\n",
            "Epoch: 10, Step: 227/655, Loss: 2.206723, Accuracy: 18.63%\n",
            "Epoch: 10, Step: 228/655, Loss: 2.207079, Accuracy: 18.63%\n",
            "Epoch: 10, Step: 229/655, Loss: 2.207412, Accuracy: 18.60%\n",
            "Epoch: 10, Step: 230/655, Loss: 2.207801, Accuracy: 18.55%\n",
            "Epoch: 10, Step: 231/655, Loss: 2.208214, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 232/655, Loss: 2.208299, Accuracy: 18.53%\n",
            "Epoch: 10, Step: 233/655, Loss: 2.208366, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 234/655, Loss: 2.208316, Accuracy: 18.54%\n",
            "Epoch: 10, Step: 235/655, Loss: 2.207781, Accuracy: 18.60%\n",
            "Epoch: 10, Step: 236/655, Loss: 2.207495, Accuracy: 18.63%\n",
            "Epoch: 10, Step: 237/655, Loss: 2.207367, Accuracy: 18.66%\n",
            "Epoch: 10, Step: 238/655, Loss: 2.207662, Accuracy: 18.66%\n",
            "Epoch: 10, Step: 239/655, Loss: 2.207553, Accuracy: 18.65%\n",
            "Epoch: 10, Step: 240/655, Loss: 2.206704, Accuracy: 18.66%\n",
            "Epoch: 10, Step: 241/655, Loss: 2.206913, Accuracy: 18.67%\n",
            "Epoch: 10, Step: 242/655, Loss: 2.206135, Accuracy: 18.70%\n",
            "Epoch: 10, Step: 243/655, Loss: 2.206433, Accuracy: 18.70%\n",
            "Epoch: 10, Step: 244/655, Loss: 2.206441, Accuracy: 18.67%\n",
            "Epoch: 10, Step: 245/655, Loss: 2.206835, Accuracy: 18.66%\n",
            "Epoch: 10, Step: 246/655, Loss: 2.207141, Accuracy: 18.66%\n",
            "Epoch: 10, Step: 247/655, Loss: 2.207345, Accuracy: 18.70%\n",
            "Epoch: 10, Step: 248/655, Loss: 2.207434, Accuracy: 18.70%\n",
            "Epoch: 10, Step: 249/655, Loss: 2.207641, Accuracy: 18.70%\n",
            "Epoch: 10, Step: 250/655, Loss: 2.207168, Accuracy: 18.70%\n",
            "Epoch: 10, Step: 251/655, Loss: 2.207487, Accuracy: 18.66%\n",
            "Epoch: 10, Step: 252/655, Loss: 2.207792, Accuracy: 18.65%\n",
            "Epoch: 10, Step: 253/655, Loss: 2.207883, Accuracy: 18.63%\n",
            "Epoch: 10, Step: 254/655, Loss: 2.207644, Accuracy: 18.60%\n",
            "Epoch: 10, Step: 255/655, Loss: 2.207928, Accuracy: 18.58%\n",
            "Epoch: 10, Step: 256/655, Loss: 2.207959, Accuracy: 18.57%\n",
            "Epoch: 10, Step: 257/655, Loss: 2.207666, Accuracy: 18.58%\n",
            "Epoch: 10, Step: 258/655, Loss: 2.207512, Accuracy: 18.59%\n",
            "Epoch: 10, Step: 259/655, Loss: 2.207299, Accuracy: 18.59%\n",
            "Epoch: 10, Step: 260/655, Loss: 2.207667, Accuracy: 18.59%\n",
            "Epoch: 10, Step: 261/655, Loss: 2.207749, Accuracy: 18.61%\n",
            "Epoch: 10, Step: 262/655, Loss: 2.208202, Accuracy: 18.57%\n",
            "Epoch: 10, Step: 263/655, Loss: 2.208329, Accuracy: 18.60%\n",
            "Epoch: 10, Step: 264/655, Loss: 2.208998, Accuracy: 18.56%\n",
            "Epoch: 10, Step: 265/655, Loss: 2.209619, Accuracy: 18.53%\n",
            "Epoch: 10, Step: 266/655, Loss: 2.209476, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 267/655, Loss: 2.210038, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 268/655, Loss: 2.209941, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 269/655, Loss: 2.210049, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 270/655, Loss: 2.210181, Accuracy: 18.40%\n",
            "Epoch: 10, Step: 271/655, Loss: 2.210384, Accuracy: 18.40%\n",
            "Epoch: 10, Step: 272/655, Loss: 2.210769, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 273/655, Loss: 2.211017, Accuracy: 18.40%\n",
            "Epoch: 10, Step: 274/655, Loss: 2.210832, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 275/655, Loss: 2.210459, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 276/655, Loss: 2.210778, Accuracy: 18.40%\n",
            "Epoch: 10, Step: 277/655, Loss: 2.210631, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 278/655, Loss: 2.210930, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 279/655, Loss: 2.210839, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 280/655, Loss: 2.210145, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 281/655, Loss: 2.210161, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 282/655, Loss: 2.210591, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 283/655, Loss: 2.210529, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 284/655, Loss: 2.210072, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 285/655, Loss: 2.210151, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 286/655, Loss: 2.210029, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 287/655, Loss: 2.210134, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 288/655, Loss: 2.210159, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 289/655, Loss: 2.209871, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 290/655, Loss: 2.209508, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 291/655, Loss: 2.209995, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 292/655, Loss: 2.210099, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 293/655, Loss: 2.209929, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 294/655, Loss: 2.209961, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 295/655, Loss: 2.209816, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 296/655, Loss: 2.210048, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 297/655, Loss: 2.209999, Accuracy: 18.38%\n",
            "Epoch: 10, Step: 298/655, Loss: 2.210318, Accuracy: 18.36%\n",
            "Epoch: 10, Step: 299/655, Loss: 2.209981, Accuracy: 18.36%\n",
            "Epoch: 10, Step: 300/655, Loss: 2.209594, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 301/655, Loss: 2.209346, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 302/655, Loss: 2.209183, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 303/655, Loss: 2.208990, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 304/655, Loss: 2.209141, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 305/655, Loss: 2.209239, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 306/655, Loss: 2.208954, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 307/655, Loss: 2.208950, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 308/655, Loss: 2.209001, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 309/655, Loss: 2.208704, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 310/655, Loss: 2.209042, Accuracy: 18.38%\n",
            "Epoch: 10, Step: 311/655, Loss: 2.208735, Accuracy: 18.38%\n",
            "Epoch: 10, Step: 312/655, Loss: 2.208521, Accuracy: 18.37%\n",
            "Epoch: 10, Step: 313/655, Loss: 2.208518, Accuracy: 18.38%\n",
            "Epoch: 10, Step: 314/655, Loss: 2.208313, Accuracy: 18.40%\n",
            "Epoch: 10, Step: 315/655, Loss: 2.208115, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 316/655, Loss: 2.208373, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 317/655, Loss: 2.208403, Accuracy: 18.39%\n",
            "Epoch: 10, Step: 318/655, Loss: 2.208189, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 319/655, Loss: 2.208003, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 320/655, Loss: 2.208181, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 321/655, Loss: 2.207959, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 322/655, Loss: 2.208145, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 323/655, Loss: 2.207773, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 324/655, Loss: 2.207791, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 325/655, Loss: 2.207523, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 326/655, Loss: 2.207422, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 327/655, Loss: 2.207131, Accuracy: 18.51%\n",
            "Epoch: 10, Step: 328/655, Loss: 2.207173, Accuracy: 18.51%\n",
            "Epoch: 10, Step: 329/655, Loss: 2.207310, Accuracy: 18.53%\n",
            "Epoch: 10, Step: 330/655, Loss: 2.207192, Accuracy: 18.55%\n",
            "Epoch: 10, Step: 331/655, Loss: 2.207585, Accuracy: 18.51%\n",
            "Epoch: 10, Step: 332/655, Loss: 2.207575, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 333/655, Loss: 2.207628, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 334/655, Loss: 2.207548, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 335/655, Loss: 2.207334, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 336/655, Loss: 2.207207, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 337/655, Loss: 2.206861, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 338/655, Loss: 2.206811, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 339/655, Loss: 2.206495, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 340/655, Loss: 2.206379, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 341/655, Loss: 2.206149, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 342/655, Loss: 2.206218, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 343/655, Loss: 2.206397, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 344/655, Loss: 2.206195, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 345/655, Loss: 2.206491, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 346/655, Loss: 2.206569, Accuracy: 18.40%\n",
            "Epoch: 10, Step: 347/655, Loss: 2.206812, Accuracy: 18.37%\n",
            "Epoch: 10, Step: 348/655, Loss: 2.206618, Accuracy: 18.39%\n",
            "Epoch: 10, Step: 349/655, Loss: 2.207061, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 350/655, Loss: 2.207599, Accuracy: 18.31%\n",
            "Epoch: 10, Step: 351/655, Loss: 2.207345, Accuracy: 18.31%\n",
            "Epoch: 10, Step: 352/655, Loss: 2.207395, Accuracy: 18.32%\n",
            "Epoch: 10, Step: 353/655, Loss: 2.207291, Accuracy: 18.33%\n",
            "Epoch: 10, Step: 354/655, Loss: 2.207163, Accuracy: 18.34%\n",
            "Epoch: 10, Step: 355/655, Loss: 2.207120, Accuracy: 18.33%\n",
            "Epoch: 10, Step: 356/655, Loss: 2.207142, Accuracy: 18.31%\n",
            "Epoch: 10, Step: 357/655, Loss: 2.207271, Accuracy: 18.32%\n",
            "Epoch: 10, Step: 358/655, Loss: 2.207201, Accuracy: 18.33%\n",
            "Epoch: 10, Step: 359/655, Loss: 2.207004, Accuracy: 18.32%\n",
            "Epoch: 10, Step: 360/655, Loss: 2.206612, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 361/655, Loss: 2.206613, Accuracy: 18.38%\n",
            "Epoch: 10, Step: 362/655, Loss: 2.206541, Accuracy: 18.37%\n",
            "Epoch: 10, Step: 363/655, Loss: 2.206691, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 364/655, Loss: 2.206978, Accuracy: 18.36%\n",
            "Epoch: 10, Step: 365/655, Loss: 2.207086, Accuracy: 18.39%\n",
            "Epoch: 10, Step: 366/655, Loss: 2.207327, Accuracy: 18.37%\n",
            "Epoch: 10, Step: 367/655, Loss: 2.207267, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 368/655, Loss: 2.207009, Accuracy: 18.38%\n",
            "Epoch: 10, Step: 369/655, Loss: 2.206889, Accuracy: 18.39%\n",
            "Epoch: 10, Step: 370/655, Loss: 2.206927, Accuracy: 18.39%\n",
            "Epoch: 10, Step: 371/655, Loss: 2.207080, Accuracy: 18.37%\n",
            "Epoch: 10, Step: 372/655, Loss: 2.207206, Accuracy: 18.36%\n",
            "Epoch: 10, Step: 373/655, Loss: 2.207459, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 374/655, Loss: 2.207368, Accuracy: 18.37%\n",
            "Epoch: 10, Step: 375/655, Loss: 2.207235, Accuracy: 18.39%\n",
            "Epoch: 10, Step: 376/655, Loss: 2.207681, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 377/655, Loss: 2.208020, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 378/655, Loss: 2.207808, Accuracy: 18.36%\n",
            "Epoch: 10, Step: 379/655, Loss: 2.207992, Accuracy: 18.37%\n",
            "Epoch: 10, Step: 380/655, Loss: 2.208422, Accuracy: 18.34%\n",
            "Epoch: 10, Step: 381/655, Loss: 2.208481, Accuracy: 18.32%\n",
            "Epoch: 10, Step: 382/655, Loss: 2.208830, Accuracy: 18.30%\n",
            "Epoch: 10, Step: 383/655, Loss: 2.208884, Accuracy: 18.29%\n",
            "Epoch: 10, Step: 384/655, Loss: 2.208581, Accuracy: 18.31%\n",
            "Epoch: 10, Step: 385/655, Loss: 2.208397, Accuracy: 18.32%\n",
            "Epoch: 10, Step: 386/655, Loss: 2.208880, Accuracy: 18.30%\n",
            "Epoch: 10, Step: 387/655, Loss: 2.208742, Accuracy: 18.32%\n",
            "Epoch: 10, Step: 388/655, Loss: 2.208799, Accuracy: 18.33%\n",
            "Epoch: 10, Step: 389/655, Loss: 2.208919, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 390/655, Loss: 2.209028, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 391/655, Loss: 2.209103, Accuracy: 18.36%\n",
            "Epoch: 10, Step: 392/655, Loss: 2.209096, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 393/655, Loss: 2.208994, Accuracy: 18.34%\n",
            "Epoch: 10, Step: 394/655, Loss: 2.208907, Accuracy: 18.33%\n",
            "Epoch: 10, Step: 395/655, Loss: 2.209047, Accuracy: 18.31%\n",
            "Epoch: 10, Step: 396/655, Loss: 2.209193, Accuracy: 18.31%\n",
            "Epoch: 10, Step: 397/655, Loss: 2.209306, Accuracy: 18.32%\n",
            "Epoch: 10, Step: 398/655, Loss: 2.209214, Accuracy: 18.31%\n",
            "Epoch: 10, Step: 399/655, Loss: 2.209467, Accuracy: 18.29%\n",
            "Epoch: 10, Step: 400/655, Loss: 2.209312, Accuracy: 18.32%\n",
            "Epoch: 10, Step: 401/655, Loss: 2.209044, Accuracy: 18.32%\n",
            "Epoch: 10, Step: 402/655, Loss: 2.208988, Accuracy: 18.32%\n",
            "Epoch: 10, Step: 403/655, Loss: 2.208807, Accuracy: 18.32%\n",
            "Epoch: 10, Step: 404/655, Loss: 2.208681, Accuracy: 18.33%\n",
            "Epoch: 10, Step: 405/655, Loss: 2.208404, Accuracy: 18.34%\n",
            "Epoch: 10, Step: 406/655, Loss: 2.208453, Accuracy: 18.32%\n",
            "Epoch: 10, Step: 407/655, Loss: 2.208421, Accuracy: 18.34%\n",
            "Epoch: 10, Step: 408/655, Loss: 2.208472, Accuracy: 18.33%\n",
            "Epoch: 10, Step: 409/655, Loss: 2.208393, Accuracy: 18.36%\n",
            "Epoch: 10, Step: 410/655, Loss: 2.208572, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 411/655, Loss: 2.208477, Accuracy: 18.37%\n",
            "Epoch: 10, Step: 412/655, Loss: 2.208505, Accuracy: 18.39%\n",
            "Epoch: 10, Step: 413/655, Loss: 2.208761, Accuracy: 18.38%\n",
            "Epoch: 10, Step: 414/655, Loss: 2.208417, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 415/655, Loss: 2.207926, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 416/655, Loss: 2.207834, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 417/655, Loss: 2.207910, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 418/655, Loss: 2.207723, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 419/655, Loss: 2.207882, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 420/655, Loss: 2.207726, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 421/655, Loss: 2.207640, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 422/655, Loss: 2.207702, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 423/655, Loss: 2.207690, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 424/655, Loss: 2.207726, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 425/655, Loss: 2.207772, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 426/655, Loss: 2.208177, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 427/655, Loss: 2.207982, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 428/655, Loss: 2.207852, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 429/655, Loss: 2.207785, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 430/655, Loss: 2.208099, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 431/655, Loss: 2.208281, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 432/655, Loss: 2.208330, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 433/655, Loss: 2.208426, Accuracy: 18.40%\n",
            "Epoch: 10, Step: 434/655, Loss: 2.208807, Accuracy: 18.37%\n",
            "Epoch: 10, Step: 435/655, Loss: 2.209057, Accuracy: 18.36%\n",
            "Epoch: 10, Step: 436/655, Loss: 2.209242, Accuracy: 18.38%\n",
            "Epoch: 10, Step: 437/655, Loss: 2.209321, Accuracy: 18.38%\n",
            "Epoch: 10, Step: 438/655, Loss: 2.209394, Accuracy: 18.37%\n",
            "Epoch: 10, Step: 439/655, Loss: 2.209672, Accuracy: 18.36%\n",
            "Epoch: 10, Step: 440/655, Loss: 2.209661, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 441/655, Loss: 2.209804, Accuracy: 18.34%\n",
            "Epoch: 10, Step: 442/655, Loss: 2.209813, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 443/655, Loss: 2.209743, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 444/655, Loss: 2.209562, Accuracy: 18.36%\n",
            "Epoch: 10, Step: 445/655, Loss: 2.209339, Accuracy: 18.37%\n",
            "Epoch: 10, Step: 446/655, Loss: 2.208999, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 447/655, Loss: 2.208950, Accuracy: 18.40%\n",
            "Epoch: 10, Step: 448/655, Loss: 2.208700, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 449/655, Loss: 2.208760, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 450/655, Loss: 2.209004, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 451/655, Loss: 2.208893, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 452/655, Loss: 2.208802, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 453/655, Loss: 2.208795, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 454/655, Loss: 2.208771, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 455/655, Loss: 2.208513, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 456/655, Loss: 2.208637, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 457/655, Loss: 2.208504, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 458/655, Loss: 2.208730, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 459/655, Loss: 2.208703, Accuracy: 18.51%\n",
            "Epoch: 10, Step: 460/655, Loss: 2.208779, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 461/655, Loss: 2.208723, Accuracy: 18.53%\n",
            "Epoch: 10, Step: 462/655, Loss: 2.208747, Accuracy: 18.54%\n",
            "Epoch: 10, Step: 463/655, Loss: 2.208717, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 464/655, Loss: 2.208459, Accuracy: 18.53%\n",
            "Epoch: 10, Step: 465/655, Loss: 2.208263, Accuracy: 18.56%\n",
            "Epoch: 10, Step: 466/655, Loss: 2.207974, Accuracy: 18.58%\n",
            "Epoch: 10, Step: 467/655, Loss: 2.207800, Accuracy: 18.58%\n",
            "Epoch: 10, Step: 468/655, Loss: 2.207741, Accuracy: 18.57%\n",
            "Epoch: 10, Step: 469/655, Loss: 2.207746, Accuracy: 18.58%\n",
            "Epoch: 10, Step: 470/655, Loss: 2.207692, Accuracy: 18.58%\n",
            "Epoch: 10, Step: 471/655, Loss: 2.207566, Accuracy: 18.57%\n",
            "Epoch: 10, Step: 472/655, Loss: 2.207750, Accuracy: 18.56%\n",
            "Epoch: 10, Step: 473/655, Loss: 2.208241, Accuracy: 18.54%\n",
            "Epoch: 10, Step: 474/655, Loss: 2.208513, Accuracy: 18.53%\n",
            "Epoch: 10, Step: 475/655, Loss: 2.208411, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 476/655, Loss: 2.208304, Accuracy: 18.51%\n",
            "Epoch: 10, Step: 477/655, Loss: 2.208362, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 478/655, Loss: 2.208182, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 479/655, Loss: 2.208128, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 480/655, Loss: 2.208272, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 481/655, Loss: 2.208532, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 482/655, Loss: 2.208628, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 483/655, Loss: 2.208618, Accuracy: 18.50%\n",
            "Epoch: 10, Step: 484/655, Loss: 2.208683, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 485/655, Loss: 2.208808, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 486/655, Loss: 2.209044, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 487/655, Loss: 2.209007, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 488/655, Loss: 2.208772, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 489/655, Loss: 2.208715, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 490/655, Loss: 2.208567, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 491/655, Loss: 2.208461, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 492/655, Loss: 2.208604, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 493/655, Loss: 2.208390, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 494/655, Loss: 2.208537, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 495/655, Loss: 2.208475, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 496/655, Loss: 2.208517, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 497/655, Loss: 2.208458, Accuracy: 18.53%\n",
            "Epoch: 10, Step: 498/655, Loss: 2.208452, Accuracy: 18.51%\n",
            "Epoch: 10, Step: 499/655, Loss: 2.208473, Accuracy: 18.53%\n",
            "Epoch: 10, Step: 500/655, Loss: 2.208371, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 501/655, Loss: 2.208383, Accuracy: 18.53%\n",
            "Epoch: 10, Step: 502/655, Loss: 2.208071, Accuracy: 18.53%\n",
            "Epoch: 10, Step: 503/655, Loss: 2.208133, Accuracy: 18.53%\n",
            "Epoch: 10, Step: 504/655, Loss: 2.208171, Accuracy: 18.55%\n",
            "Epoch: 10, Step: 505/655, Loss: 2.208200, Accuracy: 18.55%\n",
            "Epoch: 10, Step: 506/655, Loss: 2.208172, Accuracy: 18.55%\n",
            "Epoch: 10, Step: 507/655, Loss: 2.208218, Accuracy: 18.54%\n",
            "Epoch: 10, Step: 508/655, Loss: 2.208411, Accuracy: 18.53%\n",
            "Epoch: 10, Step: 509/655, Loss: 2.208719, Accuracy: 18.51%\n",
            "Epoch: 10, Step: 510/655, Loss: 2.208782, Accuracy: 18.51%\n",
            "Epoch: 10, Step: 511/655, Loss: 2.208777, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 512/655, Loss: 2.208891, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 513/655, Loss: 2.208876, Accuracy: 18.51%\n",
            "Epoch: 10, Step: 514/655, Loss: 2.208892, Accuracy: 18.50%\n",
            "Epoch: 10, Step: 515/655, Loss: 2.208964, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 516/655, Loss: 2.208973, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 517/655, Loss: 2.209102, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 518/655, Loss: 2.209251, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 519/655, Loss: 2.209095, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 520/655, Loss: 2.208940, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 521/655, Loss: 2.208779, Accuracy: 18.50%\n",
            "Epoch: 10, Step: 522/655, Loss: 2.208621, Accuracy: 18.50%\n",
            "Epoch: 10, Step: 523/655, Loss: 2.208602, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 524/655, Loss: 2.208901, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 525/655, Loss: 2.209046, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 526/655, Loss: 2.209316, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 527/655, Loss: 2.209282, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 528/655, Loss: 2.209276, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 529/655, Loss: 2.209127, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 530/655, Loss: 2.208816, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 531/655, Loss: 2.208895, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 532/655, Loss: 2.208903, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 533/655, Loss: 2.208737, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 534/655, Loss: 2.208499, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 535/655, Loss: 2.208477, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 536/655, Loss: 2.208532, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 537/655, Loss: 2.208628, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 538/655, Loss: 2.208730, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 539/655, Loss: 2.208485, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 540/655, Loss: 2.208294, Accuracy: 18.50%\n",
            "Epoch: 10, Step: 541/655, Loss: 2.208393, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 542/655, Loss: 2.208267, Accuracy: 18.50%\n",
            "Epoch: 10, Step: 543/655, Loss: 2.208126, Accuracy: 18.51%\n",
            "Epoch: 10, Step: 544/655, Loss: 2.208212, Accuracy: 18.51%\n",
            "Epoch: 10, Step: 545/655, Loss: 2.208227, Accuracy: 18.53%\n",
            "Epoch: 10, Step: 546/655, Loss: 2.208248, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 547/655, Loss: 2.208230, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 548/655, Loss: 2.208297, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 549/655, Loss: 2.208096, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 550/655, Loss: 2.207942, Accuracy: 18.52%\n",
            "Epoch: 10, Step: 551/655, Loss: 2.208300, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 552/655, Loss: 2.208314, Accuracy: 18.51%\n",
            "Epoch: 10, Step: 553/655, Loss: 2.208262, Accuracy: 18.50%\n",
            "Epoch: 10, Step: 554/655, Loss: 2.208438, Accuracy: 18.50%\n",
            "Epoch: 10, Step: 555/655, Loss: 2.208430, Accuracy: 18.50%\n",
            "Epoch: 10, Step: 556/655, Loss: 2.208404, Accuracy: 18.50%\n",
            "Epoch: 10, Step: 557/655, Loss: 2.208802, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 558/655, Loss: 2.208709, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 559/655, Loss: 2.208790, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 560/655, Loss: 2.208831, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 561/655, Loss: 2.208909, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 562/655, Loss: 2.208902, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 563/655, Loss: 2.208788, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 564/655, Loss: 2.208899, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 565/655, Loss: 2.208989, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 566/655, Loss: 2.209212, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 567/655, Loss: 2.209326, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 568/655, Loss: 2.208994, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 569/655, Loss: 2.208932, Accuracy: 18.50%\n",
            "Epoch: 10, Step: 570/655, Loss: 2.208751, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 571/655, Loss: 2.208651, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 572/655, Loss: 2.208573, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 573/655, Loss: 2.208463, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 574/655, Loss: 2.208604, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 575/655, Loss: 2.208477, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 576/655, Loss: 2.208398, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 577/655, Loss: 2.208181, Accuracy: 18.50%\n",
            "Epoch: 10, Step: 578/655, Loss: 2.207991, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 579/655, Loss: 2.207991, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 580/655, Loss: 2.207949, Accuracy: 18.49%\n",
            "Epoch: 10, Step: 581/655, Loss: 2.208271, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 582/655, Loss: 2.208095, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 583/655, Loss: 2.208283, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 584/655, Loss: 2.208180, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 585/655, Loss: 2.208128, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 586/655, Loss: 2.208421, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 587/655, Loss: 2.208641, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 588/655, Loss: 2.208735, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 589/655, Loss: 2.208472, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 590/655, Loss: 2.208393, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 591/655, Loss: 2.208482, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 592/655, Loss: 2.208682, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 593/655, Loss: 2.208975, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 594/655, Loss: 2.208957, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 595/655, Loss: 2.208966, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 596/655, Loss: 2.209067, Accuracy: 18.39%\n",
            "Epoch: 10, Step: 597/655, Loss: 2.209033, Accuracy: 18.40%\n",
            "Epoch: 10, Step: 598/655, Loss: 2.209072, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 599/655, Loss: 2.209089, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 600/655, Loss: 2.209053, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 601/655, Loss: 2.209086, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 602/655, Loss: 2.208937, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 603/655, Loss: 2.208888, Accuracy: 18.42%\n",
            "Epoch: 10, Step: 604/655, Loss: 2.208728, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 605/655, Loss: 2.208793, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 606/655, Loss: 2.208570, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 607/655, Loss: 2.208611, Accuracy: 18.39%\n",
            "Epoch: 10, Step: 608/655, Loss: 2.208572, Accuracy: 18.39%\n",
            "Epoch: 10, Step: 609/655, Loss: 2.208530, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 610/655, Loss: 2.208181, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 611/655, Loss: 2.207967, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 612/655, Loss: 2.207865, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 613/655, Loss: 2.207778, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 614/655, Loss: 2.207588, Accuracy: 18.48%\n",
            "Epoch: 10, Step: 615/655, Loss: 2.207709, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 616/655, Loss: 2.207625, Accuracy: 18.47%\n",
            "Epoch: 10, Step: 617/655, Loss: 2.207644, Accuracy: 18.46%\n",
            "Epoch: 10, Step: 618/655, Loss: 2.207762, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 619/655, Loss: 2.207811, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 620/655, Loss: 2.207810, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 621/655, Loss: 2.207729, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 622/655, Loss: 2.207641, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 623/655, Loss: 2.207598, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 624/655, Loss: 2.207544, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 625/655, Loss: 2.207448, Accuracy: 18.45%\n",
            "Epoch: 10, Step: 626/655, Loss: 2.207436, Accuracy: 18.44%\n",
            "Epoch: 10, Step: 627/655, Loss: 2.207568, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 628/655, Loss: 2.207746, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 629/655, Loss: 2.207803, Accuracy: 18.43%\n",
            "Epoch: 10, Step: 630/655, Loss: 2.207884, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 631/655, Loss: 2.207933, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 632/655, Loss: 2.207843, Accuracy: 18.41%\n",
            "Epoch: 10, Step: 633/655, Loss: 2.208073, Accuracy: 18.40%\n",
            "Epoch: 10, Step: 634/655, Loss: 2.208064, Accuracy: 18.39%\n",
            "Epoch: 10, Step: 635/655, Loss: 2.207970, Accuracy: 18.40%\n",
            "Epoch: 10, Step: 636/655, Loss: 2.208021, Accuracy: 18.40%\n",
            "Epoch: 10, Step: 637/655, Loss: 2.207921, Accuracy: 18.40%\n",
            "Epoch: 10, Step: 638/655, Loss: 2.207924, Accuracy: 18.40%\n",
            "Epoch: 10, Step: 639/655, Loss: 2.207905, Accuracy: 18.38%\n",
            "Epoch: 10, Step: 640/655, Loss: 2.208025, Accuracy: 18.39%\n",
            "Epoch: 10, Step: 641/655, Loss: 2.207965, Accuracy: 18.37%\n",
            "Epoch: 10, Step: 642/655, Loss: 2.208090, Accuracy: 18.38%\n",
            "Epoch: 10, Step: 643/655, Loss: 2.208039, Accuracy: 18.36%\n",
            "Epoch: 10, Step: 644/655, Loss: 2.208122, Accuracy: 18.36%\n",
            "Epoch: 10, Step: 645/655, Loss: 2.208033, Accuracy: 18.36%\n",
            "Epoch: 10, Step: 646/655, Loss: 2.208011, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 647/655, Loss: 2.208193, Accuracy: 18.34%\n",
            "Epoch: 10, Step: 648/655, Loss: 2.208377, Accuracy: 18.34%\n",
            "Epoch: 10, Step: 649/655, Loss: 2.208553, Accuracy: 18.33%\n",
            "Epoch: 10, Step: 650/655, Loss: 2.208429, Accuracy: 18.34%\n",
            "Epoch: 10, Step: 651/655, Loss: 2.208302, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 652/655, Loss: 2.208282, Accuracy: 18.34%\n",
            "Epoch: 10, Step: 653/655, Loss: 2.208176, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 654/655, Loss: 2.208160, Accuracy: 18.35%\n",
            "Epoch: 10, Step: 655/655, Loss: 2.207946, Accuracy: 18.35%\n",
            "Epoch: 11, Step: 1/655, Loss: 2.156715, Accuracy: 28.12%\n",
            "Epoch: 11, Step: 2/655, Loss: 2.150831, Accuracy: 26.56%\n",
            "Epoch: 11, Step: 3/655, Loss: 2.204719, Accuracy: 23.96%\n",
            "Epoch: 11, Step: 4/655, Loss: 2.195174, Accuracy: 22.66%\n",
            "Epoch: 11, Step: 5/655, Loss: 2.186675, Accuracy: 21.88%\n",
            "Epoch: 11, Step: 6/655, Loss: 2.199319, Accuracy: 19.27%\n",
            "Epoch: 11, Step: 7/655, Loss: 2.175015, Accuracy: 21.43%\n",
            "Epoch: 11, Step: 8/655, Loss: 2.177092, Accuracy: 20.31%\n",
            "Epoch: 11, Step: 9/655, Loss: 2.182135, Accuracy: 20.14%\n",
            "Epoch: 11, Step: 10/655, Loss: 2.179363, Accuracy: 20.31%\n",
            "Epoch: 11, Step: 11/655, Loss: 2.170278, Accuracy: 20.74%\n",
            "Epoch: 11, Step: 12/655, Loss: 2.172881, Accuracy: 20.31%\n",
            "Epoch: 11, Step: 13/655, Loss: 2.170708, Accuracy: 20.43%\n",
            "Epoch: 11, Step: 14/655, Loss: 2.173125, Accuracy: 19.87%\n",
            "Epoch: 11, Step: 15/655, Loss: 2.171004, Accuracy: 20.00%\n",
            "Epoch: 11, Step: 16/655, Loss: 2.169077, Accuracy: 19.73%\n",
            "Epoch: 11, Step: 17/655, Loss: 2.175856, Accuracy: 19.67%\n",
            "Epoch: 11, Step: 18/655, Loss: 2.182184, Accuracy: 19.27%\n",
            "Epoch: 11, Step: 19/655, Loss: 2.175659, Accuracy: 19.57%\n",
            "Epoch: 11, Step: 20/655, Loss: 2.176377, Accuracy: 19.06%\n",
            "Epoch: 11, Step: 21/655, Loss: 2.178511, Accuracy: 19.05%\n",
            "Epoch: 11, Step: 22/655, Loss: 2.176239, Accuracy: 18.89%\n",
            "Epoch: 11, Step: 23/655, Loss: 2.177319, Accuracy: 19.02%\n",
            "Epoch: 11, Step: 24/655, Loss: 2.183401, Accuracy: 18.88%\n",
            "Epoch: 11, Step: 25/655, Loss: 2.190409, Accuracy: 18.50%\n",
            "Epoch: 11, Step: 26/655, Loss: 2.190859, Accuracy: 18.63%\n",
            "Epoch: 11, Step: 27/655, Loss: 2.190735, Accuracy: 18.75%\n",
            "Epoch: 11, Step: 28/655, Loss: 2.191732, Accuracy: 18.53%\n",
            "Epoch: 11, Step: 29/655, Loss: 2.190483, Accuracy: 18.97%\n",
            "Epoch: 11, Step: 30/655, Loss: 2.191286, Accuracy: 18.85%\n",
            "Epoch: 11, Step: 31/655, Loss: 2.189232, Accuracy: 18.85%\n",
            "Epoch: 11, Step: 32/655, Loss: 2.192944, Accuracy: 18.85%\n",
            "Epoch: 11, Step: 33/655, Loss: 2.191047, Accuracy: 19.03%\n",
            "Epoch: 11, Step: 34/655, Loss: 2.191406, Accuracy: 18.93%\n",
            "Epoch: 11, Step: 35/655, Loss: 2.194419, Accuracy: 19.02%\n",
            "Epoch: 11, Step: 36/655, Loss: 2.194184, Accuracy: 19.01%\n",
            "Epoch: 11, Step: 37/655, Loss: 2.193150, Accuracy: 18.83%\n",
            "Epoch: 11, Step: 38/655, Loss: 2.191922, Accuracy: 19.16%\n",
            "Epoch: 11, Step: 39/655, Loss: 2.191668, Accuracy: 19.07%\n",
            "Epoch: 11, Step: 40/655, Loss: 2.192962, Accuracy: 19.06%\n",
            "Epoch: 11, Step: 41/655, Loss: 2.193436, Accuracy: 18.98%\n",
            "Epoch: 11, Step: 42/655, Loss: 2.193186, Accuracy: 19.05%\n",
            "Epoch: 11, Step: 43/655, Loss: 2.193631, Accuracy: 19.04%\n",
            "Epoch: 11, Step: 44/655, Loss: 2.191215, Accuracy: 19.11%\n",
            "Epoch: 11, Step: 45/655, Loss: 2.190529, Accuracy: 19.10%\n",
            "Epoch: 11, Step: 46/655, Loss: 2.192246, Accuracy: 18.82%\n",
            "Epoch: 11, Step: 47/655, Loss: 2.193018, Accuracy: 18.75%\n",
            "Epoch: 11, Step: 48/655, Loss: 2.190693, Accuracy: 18.82%\n",
            "Epoch: 11, Step: 49/655, Loss: 2.190995, Accuracy: 18.94%\n",
            "Epoch: 11, Step: 50/655, Loss: 2.192097, Accuracy: 18.88%\n",
            "Epoch: 11, Step: 51/655, Loss: 2.191197, Accuracy: 18.87%\n",
            "Epoch: 11, Step: 52/655, Loss: 2.191333, Accuracy: 18.81%\n",
            "Epoch: 11, Step: 53/655, Loss: 2.191168, Accuracy: 18.81%\n",
            "Epoch: 11, Step: 54/655, Loss: 2.189215, Accuracy: 18.69%\n",
            "Epoch: 11, Step: 55/655, Loss: 2.189377, Accuracy: 18.47%\n",
            "Epoch: 11, Step: 56/655, Loss: 2.189342, Accuracy: 18.42%\n",
            "Epoch: 11, Step: 57/655, Loss: 2.190903, Accuracy: 18.37%\n",
            "Epoch: 11, Step: 58/655, Loss: 2.190899, Accuracy: 18.48%\n",
            "Epoch: 11, Step: 59/655, Loss: 2.194297, Accuracy: 18.33%\n",
            "Epoch: 11, Step: 60/655, Loss: 2.193845, Accuracy: 18.39%\n",
            "Epoch: 11, Step: 61/655, Loss: 2.194513, Accuracy: 18.49%\n",
            "Epoch: 11, Step: 62/655, Loss: 2.195905, Accuracy: 18.50%\n",
            "Epoch: 11, Step: 63/655, Loss: 2.197282, Accuracy: 18.45%\n",
            "Epoch: 11, Step: 64/655, Loss: 2.197907, Accuracy: 18.31%\n",
            "Epoch: 11, Step: 65/655, Loss: 2.197070, Accuracy: 18.51%\n",
            "Epoch: 11, Step: 66/655, Loss: 2.197777, Accuracy: 18.37%\n",
            "Epoch: 11, Step: 67/655, Loss: 2.199459, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 68/655, Loss: 2.198980, Accuracy: 18.24%\n",
            "Epoch: 11, Step: 69/655, Loss: 2.199448, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 70/655, Loss: 2.199325, Accuracy: 18.21%\n",
            "Epoch: 11, Step: 71/655, Loss: 2.199042, Accuracy: 18.31%\n",
            "Epoch: 11, Step: 72/655, Loss: 2.199488, Accuracy: 18.32%\n",
            "Epoch: 11, Step: 73/655, Loss: 2.198849, Accuracy: 18.36%\n",
            "Epoch: 11, Step: 74/655, Loss: 2.197107, Accuracy: 18.54%\n",
            "Epoch: 11, Step: 75/655, Loss: 2.198347, Accuracy: 18.38%\n",
            "Epoch: 11, Step: 76/655, Loss: 2.199781, Accuracy: 18.30%\n",
            "Epoch: 11, Step: 77/655, Loss: 2.199341, Accuracy: 18.34%\n",
            "Epoch: 11, Step: 78/655, Loss: 2.200092, Accuracy: 18.27%\n",
            "Epoch: 11, Step: 79/655, Loss: 2.199737, Accuracy: 18.28%\n",
            "Epoch: 11, Step: 80/655, Loss: 2.201258, Accuracy: 18.20%\n",
            "Epoch: 11, Step: 81/655, Loss: 2.200145, Accuracy: 18.21%\n",
            "Epoch: 11, Step: 82/655, Loss: 2.201062, Accuracy: 18.18%\n",
            "Epoch: 11, Step: 83/655, Loss: 2.201866, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 84/655, Loss: 2.200596, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 85/655, Loss: 2.201289, Accuracy: 18.20%\n",
            "Epoch: 11, Step: 86/655, Loss: 2.202718, Accuracy: 18.20%\n",
            "Epoch: 11, Step: 87/655, Loss: 2.202887, Accuracy: 18.18%\n",
            "Epoch: 11, Step: 88/655, Loss: 2.204651, Accuracy: 18.11%\n",
            "Epoch: 11, Step: 89/655, Loss: 2.203910, Accuracy: 18.08%\n",
            "Epoch: 11, Step: 90/655, Loss: 2.205643, Accuracy: 17.95%\n",
            "Epoch: 11, Step: 91/655, Loss: 2.205126, Accuracy: 18.06%\n",
            "Epoch: 11, Step: 92/655, Loss: 2.204858, Accuracy: 18.07%\n",
            "Epoch: 11, Step: 93/655, Loss: 2.204557, Accuracy: 18.11%\n",
            "Epoch: 11, Step: 94/655, Loss: 2.203514, Accuracy: 18.12%\n",
            "Epoch: 11, Step: 95/655, Loss: 2.203406, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 96/655, Loss: 2.202417, Accuracy: 18.29%\n",
            "Epoch: 11, Step: 97/655, Loss: 2.201620, Accuracy: 18.40%\n",
            "Epoch: 11, Step: 98/655, Loss: 2.201446, Accuracy: 18.49%\n",
            "Epoch: 11, Step: 99/655, Loss: 2.201765, Accuracy: 18.43%\n",
            "Epoch: 11, Step: 100/655, Loss: 2.201667, Accuracy: 18.47%\n",
            "Epoch: 11, Step: 101/655, Loss: 2.201877, Accuracy: 18.47%\n",
            "Epoch: 11, Step: 102/655, Loss: 2.202135, Accuracy: 18.54%\n",
            "Epoch: 11, Step: 103/655, Loss: 2.202214, Accuracy: 18.51%\n",
            "Epoch: 11, Step: 104/655, Loss: 2.202278, Accuracy: 18.45%\n",
            "Epoch: 11, Step: 105/655, Loss: 2.201503, Accuracy: 18.48%\n",
            "Epoch: 11, Step: 106/655, Loss: 2.202911, Accuracy: 18.46%\n",
            "Epoch: 11, Step: 107/655, Loss: 2.201846, Accuracy: 18.49%\n",
            "Epoch: 11, Step: 108/655, Loss: 2.202569, Accuracy: 18.43%\n",
            "Epoch: 11, Step: 109/655, Loss: 2.200740, Accuracy: 18.49%\n",
            "Epoch: 11, Step: 110/655, Loss: 2.200908, Accuracy: 18.41%\n",
            "Epoch: 11, Step: 111/655, Loss: 2.200770, Accuracy: 18.44%\n",
            "Epoch: 11, Step: 112/655, Loss: 2.200125, Accuracy: 18.47%\n",
            "Epoch: 11, Step: 113/655, Loss: 2.198785, Accuracy: 18.50%\n",
            "Epoch: 11, Step: 114/655, Loss: 2.198690, Accuracy: 18.45%\n",
            "Epoch: 11, Step: 115/655, Loss: 2.200591, Accuracy: 18.37%\n",
            "Epoch: 11, Step: 116/655, Loss: 2.200287, Accuracy: 18.48%\n",
            "Epoch: 11, Step: 117/655, Loss: 2.201061, Accuracy: 18.48%\n",
            "Epoch: 11, Step: 118/655, Loss: 2.200581, Accuracy: 18.43%\n",
            "Epoch: 11, Step: 119/655, Loss: 2.199522, Accuracy: 18.41%\n",
            "Epoch: 11, Step: 120/655, Loss: 2.199248, Accuracy: 18.46%\n",
            "Epoch: 11, Step: 121/655, Loss: 2.199728, Accuracy: 18.44%\n",
            "Epoch: 11, Step: 122/655, Loss: 2.199182, Accuracy: 18.42%\n",
            "Epoch: 11, Step: 123/655, Loss: 2.200036, Accuracy: 18.29%\n",
            "Epoch: 11, Step: 124/655, Loss: 2.200377, Accuracy: 18.32%\n",
            "Epoch: 11, Step: 125/655, Loss: 2.200639, Accuracy: 18.38%\n",
            "Epoch: 11, Step: 126/655, Loss: 2.200488, Accuracy: 18.45%\n",
            "Epoch: 11, Step: 127/655, Loss: 2.201702, Accuracy: 18.45%\n",
            "Epoch: 11, Step: 128/655, Loss: 2.202292, Accuracy: 18.43%\n",
            "Epoch: 11, Step: 129/655, Loss: 2.202729, Accuracy: 18.46%\n",
            "Epoch: 11, Step: 130/655, Loss: 2.202908, Accuracy: 18.46%\n",
            "Epoch: 11, Step: 131/655, Loss: 2.203743, Accuracy: 18.39%\n",
            "Epoch: 11, Step: 132/655, Loss: 2.203948, Accuracy: 18.37%\n",
            "Epoch: 11, Step: 133/655, Loss: 2.203640, Accuracy: 18.40%\n",
            "Epoch: 11, Step: 134/655, Loss: 2.204254, Accuracy: 18.35%\n",
            "Epoch: 11, Step: 135/655, Loss: 2.204577, Accuracy: 18.31%\n",
            "Epoch: 11, Step: 136/655, Loss: 2.204409, Accuracy: 18.38%\n",
            "Epoch: 11, Step: 137/655, Loss: 2.205358, Accuracy: 18.32%\n",
            "Epoch: 11, Step: 138/655, Loss: 2.205555, Accuracy: 18.30%\n",
            "Epoch: 11, Step: 139/655, Loss: 2.204848, Accuracy: 18.32%\n",
            "Epoch: 11, Step: 140/655, Loss: 2.204443, Accuracy: 18.46%\n",
            "Epoch: 11, Step: 141/655, Loss: 2.204375, Accuracy: 18.37%\n",
            "Epoch: 11, Step: 142/655, Loss: 2.204063, Accuracy: 18.31%\n",
            "Epoch: 11, Step: 143/655, Loss: 2.203974, Accuracy: 18.27%\n",
            "Epoch: 11, Step: 144/655, Loss: 2.204514, Accuracy: 18.23%\n",
            "Epoch: 11, Step: 145/655, Loss: 2.205759, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 146/655, Loss: 2.205492, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 147/655, Loss: 2.206491, Accuracy: 18.11%\n",
            "Epoch: 11, Step: 148/655, Loss: 2.206421, Accuracy: 18.12%\n",
            "Epoch: 11, Step: 149/655, Loss: 2.207363, Accuracy: 18.02%\n",
            "Epoch: 11, Step: 150/655, Loss: 2.207824, Accuracy: 18.04%\n",
            "Epoch: 11, Step: 151/655, Loss: 2.207359, Accuracy: 18.03%\n",
            "Epoch: 11, Step: 152/655, Loss: 2.207660, Accuracy: 17.99%\n",
            "Epoch: 11, Step: 153/655, Loss: 2.207667, Accuracy: 17.97%\n",
            "Epoch: 11, Step: 154/655, Loss: 2.207020, Accuracy: 17.92%\n",
            "Epoch: 11, Step: 155/655, Loss: 2.206606, Accuracy: 17.88%\n",
            "Epoch: 11, Step: 156/655, Loss: 2.205842, Accuracy: 17.95%\n",
            "Epoch: 11, Step: 157/655, Loss: 2.206179, Accuracy: 17.93%\n",
            "Epoch: 11, Step: 158/655, Loss: 2.206297, Accuracy: 17.94%\n",
            "Epoch: 11, Step: 159/655, Loss: 2.206533, Accuracy: 17.90%\n",
            "Epoch: 11, Step: 160/655, Loss: 2.206658, Accuracy: 17.93%\n",
            "Epoch: 11, Step: 161/655, Loss: 2.206683, Accuracy: 17.97%\n",
            "Epoch: 11, Step: 162/655, Loss: 2.206982, Accuracy: 18.04%\n",
            "Epoch: 11, Step: 163/655, Loss: 2.207294, Accuracy: 18.02%\n",
            "Epoch: 11, Step: 164/655, Loss: 2.207642, Accuracy: 17.99%\n",
            "Epoch: 11, Step: 165/655, Loss: 2.206932, Accuracy: 18.07%\n",
            "Epoch: 11, Step: 166/655, Loss: 2.205907, Accuracy: 18.07%\n",
            "Epoch: 11, Step: 167/655, Loss: 2.206972, Accuracy: 18.00%\n",
            "Epoch: 11, Step: 168/655, Loss: 2.207025, Accuracy: 17.95%\n",
            "Epoch: 11, Step: 169/655, Loss: 2.207227, Accuracy: 17.92%\n",
            "Epoch: 11, Step: 170/655, Loss: 2.207406, Accuracy: 17.92%\n",
            "Epoch: 11, Step: 171/655, Loss: 2.207853, Accuracy: 17.95%\n",
            "Epoch: 11, Step: 172/655, Loss: 2.207693, Accuracy: 17.88%\n",
            "Epoch: 11, Step: 173/655, Loss: 2.207911, Accuracy: 17.86%\n",
            "Epoch: 11, Step: 174/655, Loss: 2.208026, Accuracy: 17.89%\n",
            "Epoch: 11, Step: 175/655, Loss: 2.207699, Accuracy: 17.91%\n",
            "Epoch: 11, Step: 176/655, Loss: 2.208506, Accuracy: 17.86%\n",
            "Epoch: 11, Step: 177/655, Loss: 2.208150, Accuracy: 17.88%\n",
            "Epoch: 11, Step: 178/655, Loss: 2.207520, Accuracy: 17.92%\n",
            "Epoch: 11, Step: 179/655, Loss: 2.207916, Accuracy: 17.91%\n",
            "Epoch: 11, Step: 180/655, Loss: 2.207664, Accuracy: 17.88%\n",
            "Epoch: 11, Step: 181/655, Loss: 2.207245, Accuracy: 17.85%\n",
            "Epoch: 11, Step: 182/655, Loss: 2.207414, Accuracy: 17.84%\n",
            "Epoch: 11, Step: 183/655, Loss: 2.207068, Accuracy: 17.84%\n",
            "Epoch: 11, Step: 184/655, Loss: 2.207029, Accuracy: 17.85%\n",
            "Epoch: 11, Step: 185/655, Loss: 2.207222, Accuracy: 17.84%\n",
            "Epoch: 11, Step: 186/655, Loss: 2.208095, Accuracy: 17.79%\n",
            "Epoch: 11, Step: 187/655, Loss: 2.208053, Accuracy: 17.81%\n",
            "Epoch: 11, Step: 188/655, Loss: 2.207561, Accuracy: 17.79%\n",
            "Epoch: 11, Step: 189/655, Loss: 2.207636, Accuracy: 17.74%\n",
            "Epoch: 11, Step: 190/655, Loss: 2.208202, Accuracy: 17.73%\n",
            "Epoch: 11, Step: 191/655, Loss: 2.207971, Accuracy: 17.72%\n",
            "Epoch: 11, Step: 192/655, Loss: 2.207872, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 193/655, Loss: 2.207996, Accuracy: 17.79%\n",
            "Epoch: 11, Step: 194/655, Loss: 2.208502, Accuracy: 17.75%\n",
            "Epoch: 11, Step: 195/655, Loss: 2.208399, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 196/655, Loss: 2.208390, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 197/655, Loss: 2.207990, Accuracy: 17.81%\n",
            "Epoch: 11, Step: 198/655, Loss: 2.207699, Accuracy: 17.85%\n",
            "Epoch: 11, Step: 199/655, Loss: 2.207848, Accuracy: 17.85%\n",
            "Epoch: 11, Step: 200/655, Loss: 2.208667, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 201/655, Loss: 2.208574, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 202/655, Loss: 2.208984, Accuracy: 17.81%\n",
            "Epoch: 11, Step: 203/655, Loss: 2.208794, Accuracy: 17.80%\n",
            "Epoch: 11, Step: 204/655, Loss: 2.209352, Accuracy: 17.74%\n",
            "Epoch: 11, Step: 205/655, Loss: 2.208799, Accuracy: 17.80%\n",
            "Epoch: 11, Step: 206/655, Loss: 2.209073, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 207/655, Loss: 2.208783, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 208/655, Loss: 2.208800, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 209/655, Loss: 2.209038, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 210/655, Loss: 2.208867, Accuracy: 17.83%\n",
            "Epoch: 11, Step: 211/655, Loss: 2.208597, Accuracy: 17.80%\n",
            "Epoch: 11, Step: 212/655, Loss: 2.208633, Accuracy: 17.79%\n",
            "Epoch: 11, Step: 213/655, Loss: 2.208273, Accuracy: 17.83%\n",
            "Epoch: 11, Step: 214/655, Loss: 2.207803, Accuracy: 17.83%\n",
            "Epoch: 11, Step: 215/655, Loss: 2.208519, Accuracy: 17.79%\n",
            "Epoch: 11, Step: 216/655, Loss: 2.208912, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 217/655, Loss: 2.209278, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 218/655, Loss: 2.209435, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 219/655, Loss: 2.209452, Accuracy: 17.74%\n",
            "Epoch: 11, Step: 220/655, Loss: 2.209329, Accuracy: 17.71%\n",
            "Epoch: 11, Step: 221/655, Loss: 2.209592, Accuracy: 17.75%\n",
            "Epoch: 11, Step: 222/655, Loss: 2.209491, Accuracy: 17.75%\n",
            "Epoch: 11, Step: 223/655, Loss: 2.209736, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 224/655, Loss: 2.209270, Accuracy: 17.80%\n",
            "Epoch: 11, Step: 225/655, Loss: 2.209246, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 226/655, Loss: 2.209602, Accuracy: 17.80%\n",
            "Epoch: 11, Step: 227/655, Loss: 2.209258, Accuracy: 17.79%\n",
            "Epoch: 11, Step: 228/655, Loss: 2.209583, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 229/655, Loss: 2.209877, Accuracy: 17.70%\n",
            "Epoch: 11, Step: 230/655, Loss: 2.209981, Accuracy: 17.70%\n",
            "Epoch: 11, Step: 231/655, Loss: 2.209111, Accuracy: 17.74%\n",
            "Epoch: 11, Step: 232/655, Loss: 2.209013, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 233/655, Loss: 2.208802, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 234/655, Loss: 2.208113, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 235/655, Loss: 2.207995, Accuracy: 17.74%\n",
            "Epoch: 11, Step: 236/655, Loss: 2.207529, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 237/655, Loss: 2.207477, Accuracy: 17.80%\n",
            "Epoch: 11, Step: 238/655, Loss: 2.208115, Accuracy: 17.75%\n",
            "Epoch: 11, Step: 239/655, Loss: 2.208268, Accuracy: 17.80%\n",
            "Epoch: 11, Step: 240/655, Loss: 2.208698, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 241/655, Loss: 2.208368, Accuracy: 17.82%\n",
            "Epoch: 11, Step: 242/655, Loss: 2.208293, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 243/655, Loss: 2.208204, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 244/655, Loss: 2.207726, Accuracy: 17.84%\n",
            "Epoch: 11, Step: 245/655, Loss: 2.207853, Accuracy: 17.83%\n",
            "Epoch: 11, Step: 246/655, Loss: 2.207712, Accuracy: 17.82%\n",
            "Epoch: 11, Step: 247/655, Loss: 2.207787, Accuracy: 17.83%\n",
            "Epoch: 11, Step: 248/655, Loss: 2.208385, Accuracy: 17.79%\n",
            "Epoch: 11, Step: 249/655, Loss: 2.208077, Accuracy: 17.80%\n",
            "Epoch: 11, Step: 250/655, Loss: 2.207748, Accuracy: 17.85%\n",
            "Epoch: 11, Step: 251/655, Loss: 2.207593, Accuracy: 17.88%\n",
            "Epoch: 11, Step: 252/655, Loss: 2.207507, Accuracy: 17.86%\n",
            "Epoch: 11, Step: 253/655, Loss: 2.207922, Accuracy: 17.85%\n",
            "Epoch: 11, Step: 254/655, Loss: 2.208311, Accuracy: 17.85%\n",
            "Epoch: 11, Step: 255/655, Loss: 2.208820, Accuracy: 17.83%\n",
            "Epoch: 11, Step: 256/655, Loss: 2.209572, Accuracy: 17.80%\n",
            "Epoch: 11, Step: 257/655, Loss: 2.209627, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 258/655, Loss: 2.210102, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 259/655, Loss: 2.209645, Accuracy: 17.80%\n",
            "Epoch: 11, Step: 260/655, Loss: 2.209642, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 261/655, Loss: 2.209780, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 262/655, Loss: 2.209257, Accuracy: 17.83%\n",
            "Epoch: 11, Step: 263/655, Loss: 2.209426, Accuracy: 17.81%\n",
            "Epoch: 11, Step: 264/655, Loss: 2.209561, Accuracy: 17.83%\n",
            "Epoch: 11, Step: 265/655, Loss: 2.209712, Accuracy: 17.79%\n",
            "Epoch: 11, Step: 266/655, Loss: 2.209899, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 267/655, Loss: 2.209576, Accuracy: 17.80%\n",
            "Epoch: 11, Step: 268/655, Loss: 2.209265, Accuracy: 17.81%\n",
            "Epoch: 11, Step: 269/655, Loss: 2.209333, Accuracy: 17.83%\n",
            "Epoch: 11, Step: 270/655, Loss: 2.209186, Accuracy: 17.84%\n",
            "Epoch: 11, Step: 271/655, Loss: 2.208714, Accuracy: 17.84%\n",
            "Epoch: 11, Step: 272/655, Loss: 2.208296, Accuracy: 17.80%\n",
            "Epoch: 11, Step: 273/655, Loss: 2.208396, Accuracy: 17.79%\n",
            "Epoch: 11, Step: 274/655, Loss: 2.208397, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 275/655, Loss: 2.208296, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 276/655, Loss: 2.208439, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 277/655, Loss: 2.208007, Accuracy: 17.80%\n",
            "Epoch: 11, Step: 278/655, Loss: 2.207906, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 279/655, Loss: 2.208021, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 280/655, Loss: 2.207569, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 281/655, Loss: 2.207371, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 282/655, Loss: 2.207766, Accuracy: 17.75%\n",
            "Epoch: 11, Step: 283/655, Loss: 2.207764, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 284/655, Loss: 2.207913, Accuracy: 17.73%\n",
            "Epoch: 11, Step: 285/655, Loss: 2.207872, Accuracy: 17.73%\n",
            "Epoch: 11, Step: 286/655, Loss: 2.207591, Accuracy: 17.73%\n",
            "Epoch: 11, Step: 287/655, Loss: 2.207759, Accuracy: 17.69%\n",
            "Epoch: 11, Step: 288/655, Loss: 2.207639, Accuracy: 17.64%\n",
            "Epoch: 11, Step: 289/655, Loss: 2.208076, Accuracy: 17.61%\n",
            "Epoch: 11, Step: 290/655, Loss: 2.208218, Accuracy: 17.62%\n",
            "Epoch: 11, Step: 291/655, Loss: 2.208446, Accuracy: 17.62%\n",
            "Epoch: 11, Step: 292/655, Loss: 2.208130, Accuracy: 17.64%\n",
            "Epoch: 11, Step: 293/655, Loss: 2.207753, Accuracy: 17.70%\n",
            "Epoch: 11, Step: 294/655, Loss: 2.208031, Accuracy: 17.70%\n",
            "Epoch: 11, Step: 295/655, Loss: 2.207889, Accuracy: 17.73%\n",
            "Epoch: 11, Step: 296/655, Loss: 2.208165, Accuracy: 17.74%\n",
            "Epoch: 11, Step: 297/655, Loss: 2.208180, Accuracy: 17.75%\n",
            "Epoch: 11, Step: 298/655, Loss: 2.208177, Accuracy: 17.74%\n",
            "Epoch: 11, Step: 299/655, Loss: 2.208396, Accuracy: 17.74%\n",
            "Epoch: 11, Step: 300/655, Loss: 2.208540, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 301/655, Loss: 2.208316, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 302/655, Loss: 2.208669, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 303/655, Loss: 2.208463, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 304/655, Loss: 2.208121, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 305/655, Loss: 2.208320, Accuracy: 17.75%\n",
            "Epoch: 11, Step: 306/655, Loss: 2.208406, Accuracy: 17.72%\n",
            "Epoch: 11, Step: 307/655, Loss: 2.208533, Accuracy: 17.73%\n",
            "Epoch: 11, Step: 308/655, Loss: 2.208660, Accuracy: 17.69%\n",
            "Epoch: 11, Step: 309/655, Loss: 2.208651, Accuracy: 17.70%\n",
            "Epoch: 11, Step: 310/655, Loss: 2.208646, Accuracy: 17.70%\n",
            "Epoch: 11, Step: 311/655, Loss: 2.208739, Accuracy: 17.69%\n",
            "Epoch: 11, Step: 312/655, Loss: 2.209194, Accuracy: 17.69%\n",
            "Epoch: 11, Step: 313/655, Loss: 2.209004, Accuracy: 17.69%\n",
            "Epoch: 11, Step: 314/655, Loss: 2.208736, Accuracy: 17.67%\n",
            "Epoch: 11, Step: 315/655, Loss: 2.209406, Accuracy: 17.64%\n",
            "Epoch: 11, Step: 316/655, Loss: 2.209441, Accuracy: 17.64%\n",
            "Epoch: 11, Step: 317/655, Loss: 2.209461, Accuracy: 17.67%\n",
            "Epoch: 11, Step: 318/655, Loss: 2.209289, Accuracy: 17.66%\n",
            "Epoch: 11, Step: 319/655, Loss: 2.209413, Accuracy: 17.62%\n",
            "Epoch: 11, Step: 320/655, Loss: 2.209237, Accuracy: 17.65%\n",
            "Epoch: 11, Step: 321/655, Loss: 2.209234, Accuracy: 17.62%\n",
            "Epoch: 11, Step: 322/655, Loss: 2.209171, Accuracy: 17.63%\n",
            "Epoch: 11, Step: 323/655, Loss: 2.209239, Accuracy: 17.64%\n",
            "Epoch: 11, Step: 324/655, Loss: 2.209011, Accuracy: 17.63%\n",
            "Epoch: 11, Step: 325/655, Loss: 2.208981, Accuracy: 17.66%\n",
            "Epoch: 11, Step: 326/655, Loss: 2.209022, Accuracy: 17.66%\n",
            "Epoch: 11, Step: 327/655, Loss: 2.209065, Accuracy: 17.65%\n",
            "Epoch: 11, Step: 328/655, Loss: 2.209389, Accuracy: 17.64%\n",
            "Epoch: 11, Step: 329/655, Loss: 2.209742, Accuracy: 17.62%\n",
            "Epoch: 11, Step: 330/655, Loss: 2.209454, Accuracy: 17.66%\n",
            "Epoch: 11, Step: 331/655, Loss: 2.209607, Accuracy: 17.64%\n",
            "Epoch: 11, Step: 332/655, Loss: 2.209645, Accuracy: 17.60%\n",
            "Epoch: 11, Step: 333/655, Loss: 2.209475, Accuracy: 17.68%\n",
            "Epoch: 11, Step: 334/655, Loss: 2.209042, Accuracy: 17.74%\n",
            "Epoch: 11, Step: 335/655, Loss: 2.209140, Accuracy: 17.73%\n",
            "Epoch: 11, Step: 336/655, Loss: 2.208713, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 337/655, Loss: 2.208377, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 338/655, Loss: 2.208798, Accuracy: 17.75%\n",
            "Epoch: 11, Step: 339/655, Loss: 2.208940, Accuracy: 17.72%\n",
            "Epoch: 11, Step: 340/655, Loss: 2.208437, Accuracy: 17.72%\n",
            "Epoch: 11, Step: 341/655, Loss: 2.207978, Accuracy: 17.74%\n",
            "Epoch: 11, Step: 342/655, Loss: 2.207945, Accuracy: 17.74%\n",
            "Epoch: 11, Step: 343/655, Loss: 2.208086, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 344/655, Loss: 2.208086, Accuracy: 17.75%\n",
            "Epoch: 11, Step: 345/655, Loss: 2.208118, Accuracy: 17.74%\n",
            "Epoch: 11, Step: 346/655, Loss: 2.207933, Accuracy: 17.75%\n",
            "Epoch: 11, Step: 347/655, Loss: 2.208168, Accuracy: 17.73%\n",
            "Epoch: 11, Step: 348/655, Loss: 2.207953, Accuracy: 17.74%\n",
            "Epoch: 11, Step: 349/655, Loss: 2.208164, Accuracy: 17.72%\n",
            "Epoch: 11, Step: 350/655, Loss: 2.207945, Accuracy: 17.71%\n",
            "Epoch: 11, Step: 351/655, Loss: 2.208268, Accuracy: 17.71%\n",
            "Epoch: 11, Step: 352/655, Loss: 2.208936, Accuracy: 17.68%\n",
            "Epoch: 11, Step: 353/655, Loss: 2.208824, Accuracy: 17.67%\n",
            "Epoch: 11, Step: 354/655, Loss: 2.209326, Accuracy: 17.65%\n",
            "Epoch: 11, Step: 355/655, Loss: 2.209781, Accuracy: 17.61%\n",
            "Epoch: 11, Step: 356/655, Loss: 2.210131, Accuracy: 17.60%\n",
            "Epoch: 11, Step: 357/655, Loss: 2.210114, Accuracy: 17.61%\n",
            "Epoch: 11, Step: 358/655, Loss: 2.210139, Accuracy: 17.62%\n",
            "Epoch: 11, Step: 359/655, Loss: 2.209994, Accuracy: 17.67%\n",
            "Epoch: 11, Step: 360/655, Loss: 2.210137, Accuracy: 17.66%\n",
            "Epoch: 11, Step: 361/655, Loss: 2.210284, Accuracy: 17.68%\n",
            "Epoch: 11, Step: 362/655, Loss: 2.210365, Accuracy: 17.68%\n",
            "Epoch: 11, Step: 363/655, Loss: 2.210298, Accuracy: 17.68%\n",
            "Epoch: 11, Step: 364/655, Loss: 2.210239, Accuracy: 17.69%\n",
            "Epoch: 11, Step: 365/655, Loss: 2.210290, Accuracy: 17.68%\n",
            "Epoch: 11, Step: 366/655, Loss: 2.210030, Accuracy: 17.72%\n",
            "Epoch: 11, Step: 367/655, Loss: 2.209977, Accuracy: 17.69%\n",
            "Epoch: 11, Step: 368/655, Loss: 2.209581, Accuracy: 17.71%\n",
            "Epoch: 11, Step: 369/655, Loss: 2.209333, Accuracy: 17.75%\n",
            "Epoch: 11, Step: 370/655, Loss: 2.209277, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 371/655, Loss: 2.209058, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 372/655, Loss: 2.209225, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 373/655, Loss: 2.209202, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 374/655, Loss: 2.209213, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 375/655, Loss: 2.209170, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 376/655, Loss: 2.208940, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 377/655, Loss: 2.208706, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 378/655, Loss: 2.208787, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 379/655, Loss: 2.208879, Accuracy: 17.79%\n",
            "Epoch: 11, Step: 380/655, Loss: 2.208878, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 381/655, Loss: 2.208948, Accuracy: 17.76%\n",
            "Epoch: 11, Step: 382/655, Loss: 2.209253, Accuracy: 17.74%\n",
            "Epoch: 11, Step: 383/655, Loss: 2.209535, Accuracy: 17.74%\n",
            "Epoch: 11, Step: 384/655, Loss: 2.209479, Accuracy: 17.77%\n",
            "Epoch: 11, Step: 385/655, Loss: 2.209325, Accuracy: 17.78%\n",
            "Epoch: 11, Step: 386/655, Loss: 2.209027, Accuracy: 17.80%\n",
            "Epoch: 11, Step: 387/655, Loss: 2.208693, Accuracy: 17.83%\n",
            "Epoch: 11, Step: 388/655, Loss: 2.208713, Accuracy: 17.82%\n",
            "Epoch: 11, Step: 389/655, Loss: 2.208661, Accuracy: 17.82%\n",
            "Epoch: 11, Step: 390/655, Loss: 2.208613, Accuracy: 17.83%\n",
            "Epoch: 11, Step: 391/655, Loss: 2.208646, Accuracy: 17.85%\n",
            "Epoch: 11, Step: 392/655, Loss: 2.208501, Accuracy: 17.87%\n",
            "Epoch: 11, Step: 393/655, Loss: 2.208573, Accuracy: 17.86%\n",
            "Epoch: 11, Step: 394/655, Loss: 2.208660, Accuracy: 17.86%\n",
            "Epoch: 11, Step: 395/655, Loss: 2.208508, Accuracy: 17.87%\n",
            "Epoch: 11, Step: 396/655, Loss: 2.208576, Accuracy: 17.86%\n",
            "Epoch: 11, Step: 397/655, Loss: 2.208633, Accuracy: 17.86%\n",
            "Epoch: 11, Step: 398/655, Loss: 2.208660, Accuracy: 17.85%\n",
            "Epoch: 11, Step: 399/655, Loss: 2.208474, Accuracy: 17.89%\n",
            "Epoch: 11, Step: 400/655, Loss: 2.208292, Accuracy: 17.88%\n",
            "Epoch: 11, Step: 401/655, Loss: 2.208216, Accuracy: 17.88%\n",
            "Epoch: 11, Step: 402/655, Loss: 2.208161, Accuracy: 17.90%\n",
            "Epoch: 11, Step: 403/655, Loss: 2.208383, Accuracy: 17.90%\n",
            "Epoch: 11, Step: 404/655, Loss: 2.208744, Accuracy: 17.88%\n",
            "Epoch: 11, Step: 405/655, Loss: 2.209003, Accuracy: 17.85%\n",
            "Epoch: 11, Step: 406/655, Loss: 2.209097, Accuracy: 17.88%\n",
            "Epoch: 11, Step: 407/655, Loss: 2.208821, Accuracy: 17.91%\n",
            "Epoch: 11, Step: 408/655, Loss: 2.208622, Accuracy: 17.93%\n",
            "Epoch: 11, Step: 409/655, Loss: 2.208543, Accuracy: 17.95%\n",
            "Epoch: 11, Step: 410/655, Loss: 2.208286, Accuracy: 17.99%\n",
            "Epoch: 11, Step: 411/655, Loss: 2.208381, Accuracy: 17.97%\n",
            "Epoch: 11, Step: 412/655, Loss: 2.208491, Accuracy: 17.95%\n",
            "Epoch: 11, Step: 413/655, Loss: 2.208654, Accuracy: 17.94%\n",
            "Epoch: 11, Step: 414/655, Loss: 2.208673, Accuracy: 17.96%\n",
            "Epoch: 11, Step: 415/655, Loss: 2.208512, Accuracy: 17.97%\n",
            "Epoch: 11, Step: 416/655, Loss: 2.208384, Accuracy: 17.97%\n",
            "Epoch: 11, Step: 417/655, Loss: 2.208407, Accuracy: 17.96%\n",
            "Epoch: 11, Step: 418/655, Loss: 2.208217, Accuracy: 17.99%\n",
            "Epoch: 11, Step: 419/655, Loss: 2.208185, Accuracy: 17.99%\n",
            "Epoch: 11, Step: 420/655, Loss: 2.208265, Accuracy: 17.98%\n",
            "Epoch: 11, Step: 421/655, Loss: 2.208436, Accuracy: 17.96%\n",
            "Epoch: 11, Step: 422/655, Loss: 2.208271, Accuracy: 17.97%\n",
            "Epoch: 11, Step: 423/655, Loss: 2.208143, Accuracy: 17.98%\n",
            "Epoch: 11, Step: 424/655, Loss: 2.208131, Accuracy: 17.99%\n",
            "Epoch: 11, Step: 425/655, Loss: 2.208395, Accuracy: 18.01%\n",
            "Epoch: 11, Step: 426/655, Loss: 2.208413, Accuracy: 17.99%\n",
            "Epoch: 11, Step: 427/655, Loss: 2.208268, Accuracy: 18.02%\n",
            "Epoch: 11, Step: 428/655, Loss: 2.208312, Accuracy: 18.01%\n",
            "Epoch: 11, Step: 429/655, Loss: 2.208078, Accuracy: 17.99%\n",
            "Epoch: 11, Step: 430/655, Loss: 2.208050, Accuracy: 17.99%\n",
            "Epoch: 11, Step: 431/655, Loss: 2.207899, Accuracy: 18.00%\n",
            "Epoch: 11, Step: 432/655, Loss: 2.207855, Accuracy: 18.00%\n",
            "Epoch: 11, Step: 433/655, Loss: 2.207859, Accuracy: 18.02%\n",
            "Epoch: 11, Step: 434/655, Loss: 2.208157, Accuracy: 18.00%\n",
            "Epoch: 11, Step: 435/655, Loss: 2.208219, Accuracy: 18.02%\n",
            "Epoch: 11, Step: 436/655, Loss: 2.208487, Accuracy: 18.00%\n",
            "Epoch: 11, Step: 437/655, Loss: 2.208380, Accuracy: 18.02%\n",
            "Epoch: 11, Step: 438/655, Loss: 2.208767, Accuracy: 18.02%\n",
            "Epoch: 11, Step: 439/655, Loss: 2.208808, Accuracy: 18.01%\n",
            "Epoch: 11, Step: 440/655, Loss: 2.208811, Accuracy: 18.00%\n",
            "Epoch: 11, Step: 441/655, Loss: 2.208741, Accuracy: 18.01%\n",
            "Epoch: 11, Step: 442/655, Loss: 2.208705, Accuracy: 17.99%\n",
            "Epoch: 11, Step: 443/655, Loss: 2.208916, Accuracy: 17.99%\n",
            "Epoch: 11, Step: 444/655, Loss: 2.208901, Accuracy: 17.97%\n",
            "Epoch: 11, Step: 445/655, Loss: 2.209068, Accuracy: 17.97%\n",
            "Epoch: 11, Step: 446/655, Loss: 2.209022, Accuracy: 17.99%\n",
            "Epoch: 11, Step: 447/655, Loss: 2.209186, Accuracy: 17.98%\n",
            "Epoch: 11, Step: 448/655, Loss: 2.209140, Accuracy: 18.00%\n",
            "Epoch: 11, Step: 449/655, Loss: 2.209125, Accuracy: 18.00%\n",
            "Epoch: 11, Step: 450/655, Loss: 2.209090, Accuracy: 17.99%\n",
            "Epoch: 11, Step: 451/655, Loss: 2.208889, Accuracy: 18.00%\n",
            "Epoch: 11, Step: 452/655, Loss: 2.208922, Accuracy: 18.00%\n",
            "Epoch: 11, Step: 453/655, Loss: 2.208606, Accuracy: 18.03%\n",
            "Epoch: 11, Step: 454/655, Loss: 2.208717, Accuracy: 18.02%\n",
            "Epoch: 11, Step: 455/655, Loss: 2.208734, Accuracy: 18.04%\n",
            "Epoch: 11, Step: 456/655, Loss: 2.208682, Accuracy: 18.04%\n",
            "Epoch: 11, Step: 457/655, Loss: 2.208466, Accuracy: 18.07%\n",
            "Epoch: 11, Step: 458/655, Loss: 2.208620, Accuracy: 18.06%\n",
            "Epoch: 11, Step: 459/655, Loss: 2.208824, Accuracy: 18.06%\n",
            "Epoch: 11, Step: 460/655, Loss: 2.208707, Accuracy: 18.06%\n",
            "Epoch: 11, Step: 461/655, Loss: 2.208570, Accuracy: 18.07%\n",
            "Epoch: 11, Step: 462/655, Loss: 2.208352, Accuracy: 18.07%\n",
            "Epoch: 11, Step: 463/655, Loss: 2.208335, Accuracy: 18.08%\n",
            "Epoch: 11, Step: 464/655, Loss: 2.208272, Accuracy: 18.08%\n",
            "Epoch: 11, Step: 465/655, Loss: 2.208251, Accuracy: 18.09%\n",
            "Epoch: 11, Step: 466/655, Loss: 2.208153, Accuracy: 18.12%\n",
            "Epoch: 11, Step: 467/655, Loss: 2.208195, Accuracy: 18.13%\n",
            "Epoch: 11, Step: 468/655, Loss: 2.208245, Accuracy: 18.12%\n",
            "Epoch: 11, Step: 469/655, Loss: 2.208168, Accuracy: 18.11%\n",
            "Epoch: 11, Step: 470/655, Loss: 2.207855, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 471/655, Loss: 2.207769, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 472/655, Loss: 2.207947, Accuracy: 18.14%\n",
            "Epoch: 11, Step: 473/655, Loss: 2.207860, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 474/655, Loss: 2.207889, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 475/655, Loss: 2.207818, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 476/655, Loss: 2.207719, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 477/655, Loss: 2.207628, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 478/655, Loss: 2.207684, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 479/655, Loss: 2.207678, Accuracy: 18.21%\n",
            "Epoch: 11, Step: 480/655, Loss: 2.207680, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 481/655, Loss: 2.207451, Accuracy: 18.21%\n",
            "Epoch: 11, Step: 482/655, Loss: 2.207821, Accuracy: 18.20%\n",
            "Epoch: 11, Step: 483/655, Loss: 2.208014, Accuracy: 18.18%\n",
            "Epoch: 11, Step: 484/655, Loss: 2.208040, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 485/655, Loss: 2.208504, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 486/655, Loss: 2.208385, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 487/655, Loss: 2.208262, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 488/655, Loss: 2.208417, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 489/655, Loss: 2.208150, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 490/655, Loss: 2.208075, Accuracy: 18.18%\n",
            "Epoch: 11, Step: 491/655, Loss: 2.208179, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 492/655, Loss: 2.208179, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 493/655, Loss: 2.208339, Accuracy: 18.14%\n",
            "Epoch: 11, Step: 494/655, Loss: 2.208357, Accuracy: 18.13%\n",
            "Epoch: 11, Step: 495/655, Loss: 2.208527, Accuracy: 18.12%\n",
            "Epoch: 11, Step: 496/655, Loss: 2.208549, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 497/655, Loss: 2.208580, Accuracy: 18.13%\n",
            "Epoch: 11, Step: 498/655, Loss: 2.208496, Accuracy: 18.14%\n",
            "Epoch: 11, Step: 499/655, Loss: 2.208698, Accuracy: 18.12%\n",
            "Epoch: 11, Step: 500/655, Loss: 2.208763, Accuracy: 18.12%\n",
            "Epoch: 11, Step: 501/655, Loss: 2.208776, Accuracy: 18.13%\n",
            "Epoch: 11, Step: 502/655, Loss: 2.208557, Accuracy: 18.12%\n",
            "Epoch: 11, Step: 503/655, Loss: 2.208480, Accuracy: 18.13%\n",
            "Epoch: 11, Step: 504/655, Loss: 2.208563, Accuracy: 18.13%\n",
            "Epoch: 11, Step: 505/655, Loss: 2.208435, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 506/655, Loss: 2.208327, Accuracy: 18.18%\n",
            "Epoch: 11, Step: 507/655, Loss: 2.208427, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 508/655, Loss: 2.208383, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 509/655, Loss: 2.208178, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 510/655, Loss: 2.208319, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 511/655, Loss: 2.208362, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 512/655, Loss: 2.208586, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 513/655, Loss: 2.208542, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 514/655, Loss: 2.208484, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 515/655, Loss: 2.208404, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 516/655, Loss: 2.208373, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 517/655, Loss: 2.208245, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 518/655, Loss: 2.208392, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 519/655, Loss: 2.208354, Accuracy: 18.14%\n",
            "Epoch: 11, Step: 520/655, Loss: 2.208314, Accuracy: 18.12%\n",
            "Epoch: 11, Step: 521/655, Loss: 2.208278, Accuracy: 18.14%\n",
            "Epoch: 11, Step: 522/655, Loss: 2.208052, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 523/655, Loss: 2.208125, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 524/655, Loss: 2.208149, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 525/655, Loss: 2.208106, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 526/655, Loss: 2.208207, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 527/655, Loss: 2.208266, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 528/655, Loss: 2.208237, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 529/655, Loss: 2.208017, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 530/655, Loss: 2.208126, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 531/655, Loss: 2.208027, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 532/655, Loss: 2.207806, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 533/655, Loss: 2.207759, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 534/655, Loss: 2.207751, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 535/655, Loss: 2.207865, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 536/655, Loss: 2.208050, Accuracy: 18.18%\n",
            "Epoch: 11, Step: 537/655, Loss: 2.208305, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 538/655, Loss: 2.208099, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 539/655, Loss: 2.208201, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 540/655, Loss: 2.208099, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 541/655, Loss: 2.208222, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 542/655, Loss: 2.208490, Accuracy: 18.13%\n",
            "Epoch: 11, Step: 543/655, Loss: 2.208457, Accuracy: 18.13%\n",
            "Epoch: 11, Step: 544/655, Loss: 2.208535, Accuracy: 18.14%\n",
            "Epoch: 11, Step: 545/655, Loss: 2.208443, Accuracy: 18.14%\n",
            "Epoch: 11, Step: 546/655, Loss: 2.208436, Accuracy: 18.13%\n",
            "Epoch: 11, Step: 547/655, Loss: 2.208292, Accuracy: 18.14%\n",
            "Epoch: 11, Step: 548/655, Loss: 2.208299, Accuracy: 18.13%\n",
            "Epoch: 11, Step: 549/655, Loss: 2.208424, Accuracy: 18.13%\n",
            "Epoch: 11, Step: 550/655, Loss: 2.208245, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 551/655, Loss: 2.208523, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 552/655, Loss: 2.208438, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 553/655, Loss: 2.208307, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 554/655, Loss: 2.208222, Accuracy: 18.18%\n",
            "Epoch: 11, Step: 555/655, Loss: 2.208282, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 556/655, Loss: 2.208273, Accuracy: 18.18%\n",
            "Epoch: 11, Step: 557/655, Loss: 2.208037, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 558/655, Loss: 2.207938, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 559/655, Loss: 2.207817, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 560/655, Loss: 2.207932, Accuracy: 18.20%\n",
            "Epoch: 11, Step: 561/655, Loss: 2.207903, Accuracy: 18.20%\n",
            "Epoch: 11, Step: 562/655, Loss: 2.207807, Accuracy: 18.21%\n",
            "Epoch: 11, Step: 563/655, Loss: 2.207643, Accuracy: 18.22%\n",
            "Epoch: 11, Step: 564/655, Loss: 2.207760, Accuracy: 18.21%\n",
            "Epoch: 11, Step: 565/655, Loss: 2.207653, Accuracy: 18.23%\n",
            "Epoch: 11, Step: 566/655, Loss: 2.207630, Accuracy: 18.23%\n",
            "Epoch: 11, Step: 567/655, Loss: 2.207503, Accuracy: 18.23%\n",
            "Epoch: 11, Step: 568/655, Loss: 2.207447, Accuracy: 18.23%\n",
            "Epoch: 11, Step: 569/655, Loss: 2.207357, Accuracy: 18.24%\n",
            "Epoch: 11, Step: 570/655, Loss: 2.207213, Accuracy: 18.23%\n",
            "Epoch: 11, Step: 571/655, Loss: 2.207172, Accuracy: 18.24%\n",
            "Epoch: 11, Step: 572/655, Loss: 2.207157, Accuracy: 18.24%\n",
            "Epoch: 11, Step: 573/655, Loss: 2.207158, Accuracy: 18.24%\n",
            "Epoch: 11, Step: 574/655, Loss: 2.207323, Accuracy: 18.23%\n",
            "Epoch: 11, Step: 575/655, Loss: 2.207363, Accuracy: 18.24%\n",
            "Epoch: 11, Step: 576/655, Loss: 2.207343, Accuracy: 18.23%\n",
            "Epoch: 11, Step: 577/655, Loss: 2.207331, Accuracy: 18.22%\n",
            "Epoch: 11, Step: 578/655, Loss: 2.207348, Accuracy: 18.21%\n",
            "Epoch: 11, Step: 579/655, Loss: 2.207504, Accuracy: 18.22%\n",
            "Epoch: 11, Step: 580/655, Loss: 2.207408, Accuracy: 18.24%\n",
            "Epoch: 11, Step: 581/655, Loss: 2.207379, Accuracy: 18.23%\n",
            "Epoch: 11, Step: 582/655, Loss: 2.207209, Accuracy: 18.24%\n",
            "Epoch: 11, Step: 583/655, Loss: 2.207306, Accuracy: 18.25%\n",
            "Epoch: 11, Step: 584/655, Loss: 2.207237, Accuracy: 18.25%\n",
            "Epoch: 11, Step: 585/655, Loss: 2.207228, Accuracy: 18.26%\n",
            "Epoch: 11, Step: 586/655, Loss: 2.207268, Accuracy: 18.25%\n",
            "Epoch: 11, Step: 587/655, Loss: 2.207317, Accuracy: 18.26%\n",
            "Epoch: 11, Step: 588/655, Loss: 2.207454, Accuracy: 18.24%\n",
            "Epoch: 11, Step: 589/655, Loss: 2.207456, Accuracy: 18.24%\n",
            "Epoch: 11, Step: 590/655, Loss: 2.207504, Accuracy: 18.23%\n",
            "Epoch: 11, Step: 591/655, Loss: 2.207502, Accuracy: 18.23%\n",
            "Epoch: 11, Step: 592/655, Loss: 2.207397, Accuracy: 18.23%\n",
            "Epoch: 11, Step: 593/655, Loss: 2.207472, Accuracy: 18.22%\n",
            "Epoch: 11, Step: 594/655, Loss: 2.207192, Accuracy: 18.23%\n",
            "Epoch: 11, Step: 595/655, Loss: 2.207052, Accuracy: 18.24%\n",
            "Epoch: 11, Step: 596/655, Loss: 2.207093, Accuracy: 18.23%\n",
            "Epoch: 11, Step: 597/655, Loss: 2.207001, Accuracy: 18.22%\n",
            "Epoch: 11, Step: 598/655, Loss: 2.207122, Accuracy: 18.21%\n",
            "Epoch: 11, Step: 599/655, Loss: 2.207151, Accuracy: 18.20%\n",
            "Epoch: 11, Step: 600/655, Loss: 2.207200, Accuracy: 18.20%\n",
            "Epoch: 11, Step: 601/655, Loss: 2.207321, Accuracy: 18.20%\n",
            "Epoch: 11, Step: 602/655, Loss: 2.207340, Accuracy: 18.21%\n",
            "Epoch: 11, Step: 603/655, Loss: 2.207534, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 604/655, Loss: 2.207434, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 605/655, Loss: 2.207512, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 606/655, Loss: 2.207555, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 607/655, Loss: 2.207341, Accuracy: 18.20%\n",
            "Epoch: 11, Step: 608/655, Loss: 2.207526, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 609/655, Loss: 2.207793, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 610/655, Loss: 2.207779, Accuracy: 18.18%\n",
            "Epoch: 11, Step: 611/655, Loss: 2.207715, Accuracy: 18.19%\n",
            "Epoch: 11, Step: 612/655, Loss: 2.207871, Accuracy: 18.18%\n",
            "Epoch: 11, Step: 613/655, Loss: 2.207985, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 614/655, Loss: 2.208016, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 615/655, Loss: 2.208073, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 616/655, Loss: 2.207977, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 617/655, Loss: 2.208019, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 618/655, Loss: 2.207800, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 619/655, Loss: 2.207707, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 620/655, Loss: 2.207653, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 621/655, Loss: 2.207547, Accuracy: 18.18%\n",
            "Epoch: 11, Step: 622/655, Loss: 2.207590, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 623/655, Loss: 2.207727, Accuracy: 18.17%\n",
            "Epoch: 11, Step: 624/655, Loss: 2.207810, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 625/655, Loss: 2.207700, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 626/655, Loss: 2.207808, Accuracy: 18.16%\n",
            "Epoch: 11, Step: 627/655, Loss: 2.207681, Accuracy: 18.15%\n",
            "Epoch: 11, Step: 628/655, Loss: 2.207717, Accuracy: 18.14%\n",
            "Epoch: 11, Step: 629/655, Loss: 2.207754, Accuracy: 18.14%\n",
            "Epoch: 11, Step: 630/655, Loss: 2.207671, Accuracy: 18.14%\n",
            "Epoch: 11, Step: 631/655, Loss: 2.207714, Accuracy: 18.14%\n",
            "Epoch: 11, Step: 632/655, Loss: 2.207810, Accuracy: 18.11%\n",
            "Epoch: 11, Step: 633/655, Loss: 2.207820, Accuracy: 18.10%\n",
            "Epoch: 11, Step: 634/655, Loss: 2.207720, Accuracy: 18.10%\n",
            "Epoch: 11, Step: 635/655, Loss: 2.207719, Accuracy: 18.10%\n",
            "Epoch: 11, Step: 636/655, Loss: 2.207945, Accuracy: 18.09%\n",
            "Epoch: 11, Step: 637/655, Loss: 2.207992, Accuracy: 18.08%\n",
            "Epoch: 11, Step: 638/655, Loss: 2.208190, Accuracy: 18.06%\n",
            "Epoch: 11, Step: 639/655, Loss: 2.208196, Accuracy: 18.06%\n",
            "Epoch: 11, Step: 640/655, Loss: 2.208292, Accuracy: 18.06%\n",
            "Epoch: 11, Step: 641/655, Loss: 2.208374, Accuracy: 18.04%\n",
            "Epoch: 11, Step: 642/655, Loss: 2.208001, Accuracy: 18.07%\n",
            "Epoch: 11, Step: 643/655, Loss: 2.208076, Accuracy: 18.07%\n",
            "Epoch: 11, Step: 644/655, Loss: 2.208158, Accuracy: 18.05%\n",
            "Epoch: 11, Step: 645/655, Loss: 2.208106, Accuracy: 18.05%\n",
            "Epoch: 11, Step: 646/655, Loss: 2.208300, Accuracy: 18.02%\n",
            "Epoch: 11, Step: 647/655, Loss: 2.208262, Accuracy: 18.03%\n",
            "Epoch: 11, Step: 648/655, Loss: 2.208239, Accuracy: 18.03%\n",
            "Epoch: 11, Step: 649/655, Loss: 2.208248, Accuracy: 18.04%\n",
            "Epoch: 11, Step: 650/655, Loss: 2.208110, Accuracy: 18.04%\n",
            "Epoch: 11, Step: 651/655, Loss: 2.208249, Accuracy: 18.03%\n",
            "Epoch: 11, Step: 652/655, Loss: 2.208093, Accuracy: 18.05%\n",
            "Epoch: 11, Step: 653/655, Loss: 2.208182, Accuracy: 18.04%\n",
            "Epoch: 11, Step: 654/655, Loss: 2.207959, Accuracy: 18.04%\n",
            "Epoch: 11, Step: 655/655, Loss: 2.208067, Accuracy: 18.04%\n",
            "Epoch: 12, Step: 1/655, Loss: 2.143740, Accuracy: 28.12%\n",
            "Epoch: 12, Step: 2/655, Loss: 2.158999, Accuracy: 23.44%\n",
            "Epoch: 12, Step: 3/655, Loss: 2.203123, Accuracy: 18.75%\n",
            "Epoch: 12, Step: 4/655, Loss: 2.208303, Accuracy: 19.53%\n",
            "Epoch: 12, Step: 5/655, Loss: 2.234190, Accuracy: 18.12%\n",
            "Epoch: 12, Step: 6/655, Loss: 2.225919, Accuracy: 18.23%\n",
            "Epoch: 12, Step: 7/655, Loss: 2.211183, Accuracy: 17.86%\n",
            "Epoch: 12, Step: 8/655, Loss: 2.213885, Accuracy: 17.97%\n",
            "Epoch: 12, Step: 9/655, Loss: 2.210906, Accuracy: 19.10%\n",
            "Epoch: 12, Step: 10/655, Loss: 2.201948, Accuracy: 18.44%\n",
            "Epoch: 12, Step: 11/655, Loss: 2.205268, Accuracy: 18.18%\n",
            "Epoch: 12, Step: 12/655, Loss: 2.201385, Accuracy: 18.49%\n",
            "Epoch: 12, Step: 13/655, Loss: 2.200989, Accuracy: 19.23%\n",
            "Epoch: 12, Step: 14/655, Loss: 2.204929, Accuracy: 19.42%\n",
            "Epoch: 12, Step: 15/655, Loss: 2.203995, Accuracy: 19.17%\n",
            "Epoch: 12, Step: 16/655, Loss: 2.203204, Accuracy: 18.95%\n",
            "Epoch: 12, Step: 17/655, Loss: 2.197219, Accuracy: 18.93%\n",
            "Epoch: 12, Step: 18/655, Loss: 2.199376, Accuracy: 18.40%\n",
            "Epoch: 12, Step: 19/655, Loss: 2.198181, Accuracy: 18.42%\n",
            "Epoch: 12, Step: 20/655, Loss: 2.195778, Accuracy: 18.91%\n",
            "Epoch: 12, Step: 21/655, Loss: 2.200774, Accuracy: 18.90%\n",
            "Epoch: 12, Step: 22/655, Loss: 2.202397, Accuracy: 18.61%\n",
            "Epoch: 12, Step: 23/655, Loss: 2.207175, Accuracy: 18.61%\n",
            "Epoch: 12, Step: 24/655, Loss: 2.207721, Accuracy: 18.23%\n",
            "Epoch: 12, Step: 25/655, Loss: 2.210393, Accuracy: 18.12%\n",
            "Epoch: 12, Step: 26/655, Loss: 2.213926, Accuracy: 17.79%\n",
            "Epoch: 12, Step: 27/655, Loss: 2.214787, Accuracy: 18.06%\n",
            "Epoch: 12, Step: 28/655, Loss: 2.215485, Accuracy: 17.97%\n",
            "Epoch: 12, Step: 29/655, Loss: 2.213215, Accuracy: 18.21%\n",
            "Epoch: 12, Step: 30/655, Loss: 2.210482, Accuracy: 18.12%\n",
            "Epoch: 12, Step: 31/655, Loss: 2.209182, Accuracy: 18.15%\n",
            "Epoch: 12, Step: 32/655, Loss: 2.210239, Accuracy: 17.97%\n",
            "Epoch: 12, Step: 33/655, Loss: 2.207849, Accuracy: 17.99%\n",
            "Epoch: 12, Step: 34/655, Loss: 2.203464, Accuracy: 18.11%\n",
            "Epoch: 12, Step: 35/655, Loss: 2.203108, Accuracy: 17.95%\n",
            "Epoch: 12, Step: 36/655, Loss: 2.204222, Accuracy: 17.88%\n",
            "Epoch: 12, Step: 37/655, Loss: 2.207126, Accuracy: 17.99%\n",
            "Epoch: 12, Step: 38/655, Loss: 2.204423, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 39/655, Loss: 2.203465, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 40/655, Loss: 2.204313, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 41/655, Loss: 2.206229, Accuracy: 18.06%\n",
            "Epoch: 12, Step: 42/655, Loss: 2.206789, Accuracy: 18.01%\n",
            "Epoch: 12, Step: 43/655, Loss: 2.207008, Accuracy: 17.95%\n",
            "Epoch: 12, Step: 44/655, Loss: 2.206792, Accuracy: 17.90%\n",
            "Epoch: 12, Step: 45/655, Loss: 2.209120, Accuracy: 17.71%\n",
            "Epoch: 12, Step: 46/655, Loss: 2.208800, Accuracy: 17.73%\n",
            "Epoch: 12, Step: 47/655, Loss: 2.209397, Accuracy: 17.69%\n",
            "Epoch: 12, Step: 48/655, Loss: 2.213570, Accuracy: 17.77%\n",
            "Epoch: 12, Step: 49/655, Loss: 2.215245, Accuracy: 17.73%\n",
            "Epoch: 12, Step: 50/655, Loss: 2.216149, Accuracy: 17.75%\n",
            "Epoch: 12, Step: 51/655, Loss: 2.217431, Accuracy: 17.83%\n",
            "Epoch: 12, Step: 52/655, Loss: 2.216508, Accuracy: 17.91%\n",
            "Epoch: 12, Step: 53/655, Loss: 2.215470, Accuracy: 17.92%\n",
            "Epoch: 12, Step: 54/655, Loss: 2.215028, Accuracy: 17.94%\n",
            "Epoch: 12, Step: 55/655, Loss: 2.213939, Accuracy: 18.01%\n",
            "Epoch: 12, Step: 56/655, Loss: 2.211442, Accuracy: 18.02%\n",
            "Epoch: 12, Step: 57/655, Loss: 2.212186, Accuracy: 18.04%\n",
            "Epoch: 12, Step: 58/655, Loss: 2.211411, Accuracy: 18.16%\n",
            "Epoch: 12, Step: 59/655, Loss: 2.210147, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 60/655, Loss: 2.209340, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 61/655, Loss: 2.211381, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 62/655, Loss: 2.211508, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 63/655, Loss: 2.210185, Accuracy: 18.40%\n",
            "Epoch: 12, Step: 64/655, Loss: 2.211653, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 65/655, Loss: 2.211256, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 66/655, Loss: 2.211503, Accuracy: 18.42%\n",
            "Epoch: 12, Step: 67/655, Loss: 2.212572, Accuracy: 18.42%\n",
            "Epoch: 12, Step: 68/655, Loss: 2.213430, Accuracy: 18.38%\n",
            "Epoch: 12, Step: 69/655, Loss: 2.215794, Accuracy: 18.48%\n",
            "Epoch: 12, Step: 70/655, Loss: 2.214328, Accuracy: 18.53%\n",
            "Epoch: 12, Step: 71/655, Loss: 2.215266, Accuracy: 18.49%\n",
            "Epoch: 12, Step: 72/655, Loss: 2.213627, Accuracy: 18.53%\n",
            "Epoch: 12, Step: 73/655, Loss: 2.212213, Accuracy: 18.54%\n",
            "Epoch: 12, Step: 74/655, Loss: 2.212017, Accuracy: 18.50%\n",
            "Epoch: 12, Step: 75/655, Loss: 2.211454, Accuracy: 18.58%\n",
            "Epoch: 12, Step: 76/655, Loss: 2.211112, Accuracy: 18.67%\n",
            "Epoch: 12, Step: 77/655, Loss: 2.210897, Accuracy: 18.75%\n",
            "Epoch: 12, Step: 78/655, Loss: 2.209511, Accuracy: 18.95%\n",
            "Epoch: 12, Step: 79/655, Loss: 2.209282, Accuracy: 19.07%\n",
            "Epoch: 12, Step: 80/655, Loss: 2.207991, Accuracy: 19.22%\n",
            "Epoch: 12, Step: 81/655, Loss: 2.206482, Accuracy: 19.33%\n",
            "Epoch: 12, Step: 82/655, Loss: 2.206338, Accuracy: 19.21%\n",
            "Epoch: 12, Step: 83/655, Loss: 2.204997, Accuracy: 19.31%\n",
            "Epoch: 12, Step: 84/655, Loss: 2.203701, Accuracy: 19.27%\n",
            "Epoch: 12, Step: 85/655, Loss: 2.203443, Accuracy: 19.26%\n",
            "Epoch: 12, Step: 86/655, Loss: 2.204992, Accuracy: 19.19%\n",
            "Epoch: 12, Step: 87/655, Loss: 2.204848, Accuracy: 19.22%\n",
            "Epoch: 12, Step: 88/655, Loss: 2.205841, Accuracy: 19.14%\n",
            "Epoch: 12, Step: 89/655, Loss: 2.206278, Accuracy: 19.07%\n",
            "Epoch: 12, Step: 90/655, Loss: 2.207402, Accuracy: 18.96%\n",
            "Epoch: 12, Step: 91/655, Loss: 2.207068, Accuracy: 18.92%\n",
            "Epoch: 12, Step: 92/655, Loss: 2.207525, Accuracy: 18.89%\n",
            "Epoch: 12, Step: 93/655, Loss: 2.208203, Accuracy: 18.82%\n",
            "Epoch: 12, Step: 94/655, Loss: 2.208774, Accuracy: 18.75%\n",
            "Epoch: 12, Step: 95/655, Loss: 2.209703, Accuracy: 18.62%\n",
            "Epoch: 12, Step: 96/655, Loss: 2.208981, Accuracy: 18.62%\n",
            "Epoch: 12, Step: 97/655, Loss: 2.208253, Accuracy: 18.52%\n",
            "Epoch: 12, Step: 98/655, Loss: 2.209247, Accuracy: 18.53%\n",
            "Epoch: 12, Step: 99/655, Loss: 2.209790, Accuracy: 18.56%\n",
            "Epoch: 12, Step: 100/655, Loss: 2.210059, Accuracy: 18.50%\n",
            "Epoch: 12, Step: 101/655, Loss: 2.209622, Accuracy: 18.47%\n",
            "Epoch: 12, Step: 102/655, Loss: 2.210837, Accuracy: 18.35%\n",
            "Epoch: 12, Step: 103/655, Loss: 2.210358, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 104/655, Loss: 2.211906, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 105/655, Loss: 2.211867, Accuracy: 18.18%\n",
            "Epoch: 12, Step: 106/655, Loss: 2.212702, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 107/655, Loss: 2.212459, Accuracy: 18.17%\n",
            "Epoch: 12, Step: 108/655, Loss: 2.213246, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 109/655, Loss: 2.212863, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 110/655, Loss: 2.212242, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 111/655, Loss: 2.212490, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 112/655, Loss: 2.212427, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 113/655, Loss: 2.212103, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 114/655, Loss: 2.212495, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 115/655, Loss: 2.213679, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 116/655, Loss: 2.213250, Accuracy: 18.21%\n",
            "Epoch: 12, Step: 117/655, Loss: 2.213503, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 118/655, Loss: 2.212888, Accuracy: 18.35%\n",
            "Epoch: 12, Step: 119/655, Loss: 2.211998, Accuracy: 18.43%\n",
            "Epoch: 12, Step: 120/655, Loss: 2.212477, Accuracy: 18.39%\n",
            "Epoch: 12, Step: 121/655, Loss: 2.213303, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 122/655, Loss: 2.213348, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 123/655, Loss: 2.215651, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 124/655, Loss: 2.214992, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 125/655, Loss: 2.215362, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 126/655, Loss: 2.215309, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 127/655, Loss: 2.214831, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 128/655, Loss: 2.213958, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 129/655, Loss: 2.213994, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 130/655, Loss: 2.215453, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 131/655, Loss: 2.215146, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 132/655, Loss: 2.214981, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 133/655, Loss: 2.214803, Accuracy: 18.21%\n",
            "Epoch: 12, Step: 134/655, Loss: 2.214845, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 135/655, Loss: 2.214993, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 136/655, Loss: 2.215714, Accuracy: 18.13%\n",
            "Epoch: 12, Step: 137/655, Loss: 2.216490, Accuracy: 18.09%\n",
            "Epoch: 12, Step: 138/655, Loss: 2.216354, Accuracy: 18.09%\n",
            "Epoch: 12, Step: 139/655, Loss: 2.216791, Accuracy: 18.10%\n",
            "Epoch: 12, Step: 140/655, Loss: 2.216526, Accuracy: 18.10%\n",
            "Epoch: 12, Step: 141/655, Loss: 2.216879, Accuracy: 18.09%\n",
            "Epoch: 12, Step: 142/655, Loss: 2.216961, Accuracy: 18.11%\n",
            "Epoch: 12, Step: 143/655, Loss: 2.216994, Accuracy: 18.12%\n",
            "Epoch: 12, Step: 144/655, Loss: 2.218056, Accuracy: 18.08%\n",
            "Epoch: 12, Step: 145/655, Loss: 2.218266, Accuracy: 18.04%\n",
            "Epoch: 12, Step: 146/655, Loss: 2.218170, Accuracy: 18.02%\n",
            "Epoch: 12, Step: 147/655, Loss: 2.218926, Accuracy: 17.94%\n",
            "Epoch: 12, Step: 148/655, Loss: 2.218559, Accuracy: 17.97%\n",
            "Epoch: 12, Step: 149/655, Loss: 2.218728, Accuracy: 17.99%\n",
            "Epoch: 12, Step: 150/655, Loss: 2.218484, Accuracy: 17.98%\n",
            "Epoch: 12, Step: 151/655, Loss: 2.217980, Accuracy: 18.03%\n",
            "Epoch: 12, Step: 152/655, Loss: 2.217930, Accuracy: 18.05%\n",
            "Epoch: 12, Step: 153/655, Loss: 2.217720, Accuracy: 18.01%\n",
            "Epoch: 12, Step: 154/655, Loss: 2.217753, Accuracy: 17.98%\n",
            "Epoch: 12, Step: 155/655, Loss: 2.217864, Accuracy: 17.96%\n",
            "Epoch: 12, Step: 156/655, Loss: 2.217533, Accuracy: 17.97%\n",
            "Epoch: 12, Step: 157/655, Loss: 2.217260, Accuracy: 17.99%\n",
            "Epoch: 12, Step: 158/655, Loss: 2.217740, Accuracy: 17.96%\n",
            "Epoch: 12, Step: 159/655, Loss: 2.218073, Accuracy: 17.94%\n",
            "Epoch: 12, Step: 160/655, Loss: 2.217934, Accuracy: 17.99%\n",
            "Epoch: 12, Step: 161/655, Loss: 2.217636, Accuracy: 18.03%\n",
            "Epoch: 12, Step: 162/655, Loss: 2.218102, Accuracy: 18.06%\n",
            "Epoch: 12, Step: 163/655, Loss: 2.217539, Accuracy: 18.06%\n",
            "Epoch: 12, Step: 164/655, Loss: 2.217708, Accuracy: 18.03%\n",
            "Epoch: 12, Step: 165/655, Loss: 2.217558, Accuracy: 18.07%\n",
            "Epoch: 12, Step: 166/655, Loss: 2.218120, Accuracy: 18.02%\n",
            "Epoch: 12, Step: 167/655, Loss: 2.218422, Accuracy: 17.98%\n",
            "Epoch: 12, Step: 168/655, Loss: 2.218473, Accuracy: 17.99%\n",
            "Epoch: 12, Step: 169/655, Loss: 2.217728, Accuracy: 17.99%\n",
            "Epoch: 12, Step: 170/655, Loss: 2.218818, Accuracy: 17.94%\n",
            "Epoch: 12, Step: 171/655, Loss: 2.218852, Accuracy: 17.98%\n",
            "Epoch: 12, Step: 172/655, Loss: 2.217845, Accuracy: 18.04%\n",
            "Epoch: 12, Step: 173/655, Loss: 2.218209, Accuracy: 18.03%\n",
            "Epoch: 12, Step: 174/655, Loss: 2.218284, Accuracy: 17.96%\n",
            "Epoch: 12, Step: 175/655, Loss: 2.218179, Accuracy: 17.96%\n",
            "Epoch: 12, Step: 176/655, Loss: 2.218727, Accuracy: 17.93%\n",
            "Epoch: 12, Step: 177/655, Loss: 2.218423, Accuracy: 17.97%\n",
            "Epoch: 12, Step: 178/655, Loss: 2.219173, Accuracy: 17.96%\n",
            "Epoch: 12, Step: 179/655, Loss: 2.219167, Accuracy: 17.96%\n",
            "Epoch: 12, Step: 180/655, Loss: 2.219449, Accuracy: 17.95%\n",
            "Epoch: 12, Step: 181/655, Loss: 2.218835, Accuracy: 17.97%\n",
            "Epoch: 12, Step: 182/655, Loss: 2.218639, Accuracy: 18.01%\n",
            "Epoch: 12, Step: 183/655, Loss: 2.218418, Accuracy: 18.03%\n",
            "Epoch: 12, Step: 184/655, Loss: 2.218591, Accuracy: 18.04%\n",
            "Epoch: 12, Step: 185/655, Loss: 2.218484, Accuracy: 18.01%\n",
            "Epoch: 12, Step: 186/655, Loss: 2.218342, Accuracy: 18.04%\n",
            "Epoch: 12, Step: 187/655, Loss: 2.218407, Accuracy: 18.05%\n",
            "Epoch: 12, Step: 188/655, Loss: 2.218151, Accuracy: 18.10%\n",
            "Epoch: 12, Step: 189/655, Loss: 2.218340, Accuracy: 18.15%\n",
            "Epoch: 12, Step: 190/655, Loss: 2.217974, Accuracy: 18.17%\n",
            "Epoch: 12, Step: 191/655, Loss: 2.218572, Accuracy: 18.13%\n",
            "Epoch: 12, Step: 192/655, Loss: 2.218394, Accuracy: 18.16%\n",
            "Epoch: 12, Step: 193/655, Loss: 2.218208, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 194/655, Loss: 2.218029, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 195/655, Loss: 2.217516, Accuracy: 18.21%\n",
            "Epoch: 12, Step: 196/655, Loss: 2.217442, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 197/655, Loss: 2.217538, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 198/655, Loss: 2.217324, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 199/655, Loss: 2.217496, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 200/655, Loss: 2.217471, Accuracy: 18.23%\n",
            "Epoch: 12, Step: 201/655, Loss: 2.218034, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 202/655, Loss: 2.218061, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 203/655, Loss: 2.217457, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 204/655, Loss: 2.217657, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 205/655, Loss: 2.217726, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 206/655, Loss: 2.217558, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 207/655, Loss: 2.217759, Accuracy: 18.18%\n",
            "Epoch: 12, Step: 208/655, Loss: 2.217833, Accuracy: 18.19%\n",
            "Epoch: 12, Step: 209/655, Loss: 2.218143, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 210/655, Loss: 2.218124, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 211/655, Loss: 2.217552, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 212/655, Loss: 2.217256, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 213/655, Loss: 2.216599, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 214/655, Loss: 2.217220, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 215/655, Loss: 2.217208, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 216/655, Loss: 2.216850, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 217/655, Loss: 2.217495, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 218/655, Loss: 2.217084, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 219/655, Loss: 2.216719, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 220/655, Loss: 2.216517, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 221/655, Loss: 2.216269, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 222/655, Loss: 2.216696, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 223/655, Loss: 2.216840, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 224/655, Loss: 2.216526, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 225/655, Loss: 2.216308, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 226/655, Loss: 2.216330, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 227/655, Loss: 2.215672, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 228/655, Loss: 2.215593, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 229/655, Loss: 2.215525, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 230/655, Loss: 2.215571, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 231/655, Loss: 2.216465, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 232/655, Loss: 2.216806, Accuracy: 18.21%\n",
            "Epoch: 12, Step: 233/655, Loss: 2.217111, Accuracy: 18.21%\n",
            "Epoch: 12, Step: 234/655, Loss: 2.217498, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 235/655, Loss: 2.217031, Accuracy: 18.16%\n",
            "Epoch: 12, Step: 236/655, Loss: 2.216803, Accuracy: 18.19%\n",
            "Epoch: 12, Step: 237/655, Loss: 2.216429, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 238/655, Loss: 2.216793, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 239/655, Loss: 2.216862, Accuracy: 18.23%\n",
            "Epoch: 12, Step: 240/655, Loss: 2.216724, Accuracy: 18.23%\n",
            "Epoch: 12, Step: 241/655, Loss: 2.216265, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 242/655, Loss: 2.216013, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 243/655, Loss: 2.215463, Accuracy: 18.39%\n",
            "Epoch: 12, Step: 244/655, Loss: 2.215683, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 245/655, Loss: 2.215620, Accuracy: 18.35%\n",
            "Epoch: 12, Step: 246/655, Loss: 2.215226, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 247/655, Loss: 2.214946, Accuracy: 18.38%\n",
            "Epoch: 12, Step: 248/655, Loss: 2.215099, Accuracy: 18.35%\n",
            "Epoch: 12, Step: 249/655, Loss: 2.215235, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 250/655, Loss: 2.215274, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 251/655, Loss: 2.215561, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 252/655, Loss: 2.215397, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 253/655, Loss: 2.215052, Accuracy: 18.35%\n",
            "Epoch: 12, Step: 254/655, Loss: 2.215162, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 255/655, Loss: 2.215454, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 256/655, Loss: 2.214932, Accuracy: 18.35%\n",
            "Epoch: 12, Step: 257/655, Loss: 2.214780, Accuracy: 18.35%\n",
            "Epoch: 12, Step: 258/655, Loss: 2.214095, Accuracy: 18.39%\n",
            "Epoch: 12, Step: 259/655, Loss: 2.214775, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 260/655, Loss: 2.214991, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 261/655, Loss: 2.214273, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 262/655, Loss: 2.213720, Accuracy: 18.43%\n",
            "Epoch: 12, Step: 263/655, Loss: 2.213474, Accuracy: 18.42%\n",
            "Epoch: 12, Step: 264/655, Loss: 2.213569, Accuracy: 18.43%\n",
            "Epoch: 12, Step: 265/655, Loss: 2.213571, Accuracy: 18.47%\n",
            "Epoch: 12, Step: 266/655, Loss: 2.213595, Accuracy: 18.44%\n",
            "Epoch: 12, Step: 267/655, Loss: 2.213733, Accuracy: 18.43%\n",
            "Epoch: 12, Step: 268/655, Loss: 2.214379, Accuracy: 18.40%\n",
            "Epoch: 12, Step: 269/655, Loss: 2.214294, Accuracy: 18.42%\n",
            "Epoch: 12, Step: 270/655, Loss: 2.214351, Accuracy: 18.39%\n",
            "Epoch: 12, Step: 271/655, Loss: 2.213785, Accuracy: 18.39%\n",
            "Epoch: 12, Step: 272/655, Loss: 2.213598, Accuracy: 18.35%\n",
            "Epoch: 12, Step: 273/655, Loss: 2.213316, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 274/655, Loss: 2.213172, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 275/655, Loss: 2.213324, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 276/655, Loss: 2.213468, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 277/655, Loss: 2.213531, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 278/655, Loss: 2.213029, Accuracy: 18.38%\n",
            "Epoch: 12, Step: 279/655, Loss: 2.212852, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 280/655, Loss: 2.212802, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 281/655, Loss: 2.212825, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 282/655, Loss: 2.212639, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 283/655, Loss: 2.212461, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 284/655, Loss: 2.212219, Accuracy: 18.39%\n",
            "Epoch: 12, Step: 285/655, Loss: 2.212019, Accuracy: 18.41%\n",
            "Epoch: 12, Step: 286/655, Loss: 2.211529, Accuracy: 18.45%\n",
            "Epoch: 12, Step: 287/655, Loss: 2.211746, Accuracy: 18.41%\n",
            "Epoch: 12, Step: 288/655, Loss: 2.211425, Accuracy: 18.44%\n",
            "Epoch: 12, Step: 289/655, Loss: 2.211523, Accuracy: 18.41%\n",
            "Epoch: 12, Step: 290/655, Loss: 2.211505, Accuracy: 18.41%\n",
            "Epoch: 12, Step: 291/655, Loss: 2.211536, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 292/655, Loss: 2.211887, Accuracy: 18.38%\n",
            "Epoch: 12, Step: 293/655, Loss: 2.212207, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 294/655, Loss: 2.212031, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 295/655, Loss: 2.211934, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 296/655, Loss: 2.211941, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 297/655, Loss: 2.211431, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 298/655, Loss: 2.211220, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 299/655, Loss: 2.211473, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 300/655, Loss: 2.211442, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 301/655, Loss: 2.211113, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 302/655, Loss: 2.211248, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 303/655, Loss: 2.211379, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 304/655, Loss: 2.211418, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 305/655, Loss: 2.211838, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 306/655, Loss: 2.212213, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 307/655, Loss: 2.212385, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 308/655, Loss: 2.212198, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 309/655, Loss: 2.212262, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 310/655, Loss: 2.212052, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 311/655, Loss: 2.212481, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 312/655, Loss: 2.212773, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 313/655, Loss: 2.212817, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 314/655, Loss: 2.213282, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 315/655, Loss: 2.213212, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 316/655, Loss: 2.213276, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 317/655, Loss: 2.212984, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 318/655, Loss: 2.212959, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 319/655, Loss: 2.212923, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 320/655, Loss: 2.212850, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 321/655, Loss: 2.212685, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 322/655, Loss: 2.212628, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 323/655, Loss: 2.212360, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 324/655, Loss: 2.212953, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 325/655, Loss: 2.213474, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 326/655, Loss: 2.213457, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 327/655, Loss: 2.213031, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 328/655, Loss: 2.213030, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 329/655, Loss: 2.212640, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 330/655, Loss: 2.212719, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 331/655, Loss: 2.212827, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 332/655, Loss: 2.212736, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 333/655, Loss: 2.212256, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 334/655, Loss: 2.212251, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 335/655, Loss: 2.212056, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 336/655, Loss: 2.211903, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 337/655, Loss: 2.211337, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 338/655, Loss: 2.211254, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 339/655, Loss: 2.210993, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 340/655, Loss: 2.211266, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 341/655, Loss: 2.211485, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 342/655, Loss: 2.211158, Accuracy: 18.35%\n",
            "Epoch: 12, Step: 343/655, Loss: 2.211248, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 344/655, Loss: 2.211135, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 345/655, Loss: 2.211247, Accuracy: 18.35%\n",
            "Epoch: 12, Step: 346/655, Loss: 2.211562, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 347/655, Loss: 2.211550, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 348/655, Loss: 2.211627, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 349/655, Loss: 2.211738, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 350/655, Loss: 2.211635, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 351/655, Loss: 2.211456, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 352/655, Loss: 2.211817, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 353/655, Loss: 2.211646, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 354/655, Loss: 2.211757, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 355/655, Loss: 2.211300, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 356/655, Loss: 2.211349, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 357/655, Loss: 2.210971, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 358/655, Loss: 2.210714, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 359/655, Loss: 2.210598, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 360/655, Loss: 2.210485, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 361/655, Loss: 2.210221, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 362/655, Loss: 2.209955, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 363/655, Loss: 2.209828, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 364/655, Loss: 2.209724, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 365/655, Loss: 2.209920, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 366/655, Loss: 2.209876, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 367/655, Loss: 2.209554, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 368/655, Loss: 2.209833, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 369/655, Loss: 2.209950, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 370/655, Loss: 2.210273, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 371/655, Loss: 2.210410, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 372/655, Loss: 2.210539, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 373/655, Loss: 2.210452, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 374/655, Loss: 2.210176, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 375/655, Loss: 2.209736, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 376/655, Loss: 2.209521, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 377/655, Loss: 2.209152, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 378/655, Loss: 2.209186, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 379/655, Loss: 2.209258, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 380/655, Loss: 2.209508, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 381/655, Loss: 2.209276, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 382/655, Loss: 2.209423, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 383/655, Loss: 2.209634, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 384/655, Loss: 2.209577, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 385/655, Loss: 2.209345, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 386/655, Loss: 2.209086, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 387/655, Loss: 2.209064, Accuracy: 18.23%\n",
            "Epoch: 12, Step: 388/655, Loss: 2.209302, Accuracy: 18.21%\n",
            "Epoch: 12, Step: 389/655, Loss: 2.209129, Accuracy: 18.21%\n",
            "Epoch: 12, Step: 390/655, Loss: 2.209423, Accuracy: 18.19%\n",
            "Epoch: 12, Step: 391/655, Loss: 2.209171, Accuracy: 18.17%\n",
            "Epoch: 12, Step: 392/655, Loss: 2.209106, Accuracy: 18.18%\n",
            "Epoch: 12, Step: 393/655, Loss: 2.208962, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 394/655, Loss: 2.208637, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 395/655, Loss: 2.208739, Accuracy: 18.19%\n",
            "Epoch: 12, Step: 396/655, Loss: 2.208842, Accuracy: 18.21%\n",
            "Epoch: 12, Step: 397/655, Loss: 2.208724, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 398/655, Loss: 2.208981, Accuracy: 18.18%\n",
            "Epoch: 12, Step: 399/655, Loss: 2.209260, Accuracy: 18.17%\n",
            "Epoch: 12, Step: 400/655, Loss: 2.209427, Accuracy: 18.19%\n",
            "Epoch: 12, Step: 401/655, Loss: 2.209270, Accuracy: 18.21%\n",
            "Epoch: 12, Step: 402/655, Loss: 2.209620, Accuracy: 18.18%\n",
            "Epoch: 12, Step: 403/655, Loss: 2.209737, Accuracy: 18.21%\n",
            "Epoch: 12, Step: 404/655, Loss: 2.209636, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 405/655, Loss: 2.209865, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 406/655, Loss: 2.209866, Accuracy: 18.23%\n",
            "Epoch: 12, Step: 407/655, Loss: 2.210071, Accuracy: 18.23%\n",
            "Epoch: 12, Step: 408/655, Loss: 2.210292, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 409/655, Loss: 2.210159, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 410/655, Loss: 2.210089, Accuracy: 18.18%\n",
            "Epoch: 12, Step: 411/655, Loss: 2.210205, Accuracy: 18.16%\n",
            "Epoch: 12, Step: 412/655, Loss: 2.210374, Accuracy: 18.16%\n",
            "Epoch: 12, Step: 413/655, Loss: 2.210310, Accuracy: 18.16%\n",
            "Epoch: 12, Step: 414/655, Loss: 2.210028, Accuracy: 18.18%\n",
            "Epoch: 12, Step: 415/655, Loss: 2.210042, Accuracy: 18.18%\n",
            "Epoch: 12, Step: 416/655, Loss: 2.210066, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 417/655, Loss: 2.210229, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 418/655, Loss: 2.210395, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 419/655, Loss: 2.210644, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 420/655, Loss: 2.210444, Accuracy: 18.23%\n",
            "Epoch: 12, Step: 421/655, Loss: 2.210527, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 422/655, Loss: 2.210277, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 423/655, Loss: 2.210262, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 424/655, Loss: 2.210397, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 425/655, Loss: 2.210146, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 426/655, Loss: 2.210062, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 427/655, Loss: 2.210119, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 428/655, Loss: 2.209874, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 429/655, Loss: 2.209567, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 430/655, Loss: 2.209350, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 431/655, Loss: 2.209383, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 432/655, Loss: 2.209363, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 433/655, Loss: 2.209324, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 434/655, Loss: 2.209563, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 435/655, Loss: 2.209765, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 436/655, Loss: 2.209689, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 437/655, Loss: 2.209579, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 438/655, Loss: 2.209491, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 439/655, Loss: 2.209470, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 440/655, Loss: 2.209461, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 441/655, Loss: 2.209516, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 442/655, Loss: 2.209147, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 443/655, Loss: 2.209320, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 444/655, Loss: 2.209347, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 445/655, Loss: 2.209050, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 446/655, Loss: 2.209197, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 447/655, Loss: 2.208801, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 448/655, Loss: 2.208823, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 449/655, Loss: 2.208873, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 450/655, Loss: 2.209046, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 451/655, Loss: 2.208905, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 452/655, Loss: 2.208865, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 453/655, Loss: 2.208863, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 454/655, Loss: 2.208753, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 455/655, Loss: 2.208484, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 456/655, Loss: 2.208622, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 457/655, Loss: 2.208721, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 458/655, Loss: 2.208681, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 459/655, Loss: 2.208626, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 460/655, Loss: 2.208572, Accuracy: 18.35%\n",
            "Epoch: 12, Step: 461/655, Loss: 2.208843, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 462/655, Loss: 2.209029, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 463/655, Loss: 2.209015, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 464/655, Loss: 2.209149, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 465/655, Loss: 2.209142, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 466/655, Loss: 2.209082, Accuracy: 18.35%\n",
            "Epoch: 12, Step: 467/655, Loss: 2.209393, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 468/655, Loss: 2.209281, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 469/655, Loss: 2.209293, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 470/655, Loss: 2.209883, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 471/655, Loss: 2.209788, Accuracy: 18.35%\n",
            "Epoch: 12, Step: 472/655, Loss: 2.209648, Accuracy: 18.35%\n",
            "Epoch: 12, Step: 473/655, Loss: 2.209447, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 474/655, Loss: 2.209725, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 475/655, Loss: 2.209815, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 476/655, Loss: 2.209959, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 477/655, Loss: 2.209829, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 478/655, Loss: 2.209812, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 479/655, Loss: 2.209816, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 480/655, Loss: 2.209916, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 481/655, Loss: 2.209979, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 482/655, Loss: 2.209827, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 483/655, Loss: 2.209692, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 484/655, Loss: 2.209807, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 485/655, Loss: 2.209735, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 486/655, Loss: 2.209996, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 487/655, Loss: 2.209842, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 488/655, Loss: 2.209796, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 489/655, Loss: 2.209988, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 490/655, Loss: 2.209943, Accuracy: 18.21%\n",
            "Epoch: 12, Step: 491/655, Loss: 2.209602, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 492/655, Loss: 2.209447, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 493/655, Loss: 2.209208, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 494/655, Loss: 2.209520, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 495/655, Loss: 2.209659, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 496/655, Loss: 2.209848, Accuracy: 18.21%\n",
            "Epoch: 12, Step: 497/655, Loss: 2.209938, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 498/655, Loss: 2.209997, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 499/655, Loss: 2.209939, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 500/655, Loss: 2.210102, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 501/655, Loss: 2.210074, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 502/655, Loss: 2.209971, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 503/655, Loss: 2.210037, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 504/655, Loss: 2.210083, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 505/655, Loss: 2.210046, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 506/655, Loss: 2.209735, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 507/655, Loss: 2.209760, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 508/655, Loss: 2.209769, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 509/655, Loss: 2.209861, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 510/655, Loss: 2.210070, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 511/655, Loss: 2.210039, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 512/655, Loss: 2.209898, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 513/655, Loss: 2.209981, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 514/655, Loss: 2.209951, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 515/655, Loss: 2.209998, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 516/655, Loss: 2.210118, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 517/655, Loss: 2.210051, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 518/655, Loss: 2.210137, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 519/655, Loss: 2.210033, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 520/655, Loss: 2.210047, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 521/655, Loss: 2.210206, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 522/655, Loss: 2.210259, Accuracy: 18.23%\n",
            "Epoch: 12, Step: 523/655, Loss: 2.210293, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 524/655, Loss: 2.210355, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 525/655, Loss: 2.210074, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 526/655, Loss: 2.210042, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 527/655, Loss: 2.210001, Accuracy: 18.23%\n",
            "Epoch: 12, Step: 528/655, Loss: 2.210050, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 529/655, Loss: 2.209856, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 530/655, Loss: 2.209839, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 531/655, Loss: 2.209798, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 532/655, Loss: 2.209492, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 533/655, Loss: 2.209595, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 534/655, Loss: 2.209580, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 535/655, Loss: 2.209257, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 536/655, Loss: 2.209048, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 537/655, Loss: 2.208789, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 538/655, Loss: 2.208875, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 539/655, Loss: 2.208990, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 540/655, Loss: 2.209177, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 541/655, Loss: 2.209343, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 542/655, Loss: 2.209456, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 543/655, Loss: 2.209185, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 544/655, Loss: 2.209058, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 545/655, Loss: 2.208914, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 546/655, Loss: 2.209086, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 547/655, Loss: 2.209195, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 548/655, Loss: 2.209126, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 549/655, Loss: 2.209040, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 550/655, Loss: 2.209273, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 551/655, Loss: 2.209258, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 552/655, Loss: 2.209375, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 553/655, Loss: 2.209512, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 554/655, Loss: 2.209261, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 555/655, Loss: 2.209352, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 556/655, Loss: 2.209448, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 557/655, Loss: 2.209327, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 558/655, Loss: 2.209073, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 559/655, Loss: 2.209033, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 560/655, Loss: 2.209032, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 561/655, Loss: 2.209064, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 562/655, Loss: 2.209327, Accuracy: 18.23%\n",
            "Epoch: 12, Step: 563/655, Loss: 2.209232, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 564/655, Loss: 2.209477, Accuracy: 18.24%\n",
            "Epoch: 12, Step: 565/655, Loss: 2.209422, Accuracy: 18.23%\n",
            "Epoch: 12, Step: 566/655, Loss: 2.209361, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 567/655, Loss: 2.209270, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 568/655, Loss: 2.209408, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 569/655, Loss: 2.209363, Accuracy: 18.21%\n",
            "Epoch: 12, Step: 570/655, Loss: 2.209616, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 571/655, Loss: 2.209785, Accuracy: 18.19%\n",
            "Epoch: 12, Step: 572/655, Loss: 2.209602, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 573/655, Loss: 2.209602, Accuracy: 18.19%\n",
            "Epoch: 12, Step: 574/655, Loss: 2.209568, Accuracy: 18.18%\n",
            "Epoch: 12, Step: 575/655, Loss: 2.209395, Accuracy: 18.20%\n",
            "Epoch: 12, Step: 576/655, Loss: 2.209344, Accuracy: 18.21%\n",
            "Epoch: 12, Step: 577/655, Loss: 2.209167, Accuracy: 18.22%\n",
            "Epoch: 12, Step: 578/655, Loss: 2.208866, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 579/655, Loss: 2.208937, Accuracy: 18.25%\n",
            "Epoch: 12, Step: 580/655, Loss: 2.209013, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 581/655, Loss: 2.208934, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 582/655, Loss: 2.208738, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 583/655, Loss: 2.208915, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 584/655, Loss: 2.208849, Accuracy: 18.26%\n",
            "Epoch: 12, Step: 585/655, Loss: 2.208731, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 586/655, Loss: 2.208749, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 587/655, Loss: 2.208765, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 588/655, Loss: 2.208799, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 589/655, Loss: 2.208704, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 590/655, Loss: 2.208739, Accuracy: 18.27%\n",
            "Epoch: 12, Step: 591/655, Loss: 2.208758, Accuracy: 18.28%\n",
            "Epoch: 12, Step: 592/655, Loss: 2.208599, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 593/655, Loss: 2.208646, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 594/655, Loss: 2.208445, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 595/655, Loss: 2.208462, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 596/655, Loss: 2.208463, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 597/655, Loss: 2.208515, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 598/655, Loss: 2.208569, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 599/655, Loss: 2.208499, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 600/655, Loss: 2.208384, Accuracy: 18.32%\n",
            "Epoch: 12, Step: 601/655, Loss: 2.208158, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 602/655, Loss: 2.208087, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 603/655, Loss: 2.208138, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 604/655, Loss: 2.207985, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 605/655, Loss: 2.207920, Accuracy: 18.38%\n",
            "Epoch: 12, Step: 606/655, Loss: 2.208040, Accuracy: 18.39%\n",
            "Epoch: 12, Step: 607/655, Loss: 2.207986, Accuracy: 18.39%\n",
            "Epoch: 12, Step: 608/655, Loss: 2.208061, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 609/655, Loss: 2.208240, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 610/655, Loss: 2.208411, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 611/655, Loss: 2.208307, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 612/655, Loss: 2.208254, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 613/655, Loss: 2.208093, Accuracy: 18.40%\n",
            "Epoch: 12, Step: 614/655, Loss: 2.208067, Accuracy: 18.40%\n",
            "Epoch: 12, Step: 615/655, Loss: 2.207902, Accuracy: 18.39%\n",
            "Epoch: 12, Step: 616/655, Loss: 2.207825, Accuracy: 18.40%\n",
            "Epoch: 12, Step: 617/655, Loss: 2.207659, Accuracy: 18.41%\n",
            "Epoch: 12, Step: 618/655, Loss: 2.207493, Accuracy: 18.41%\n",
            "Epoch: 12, Step: 619/655, Loss: 2.207681, Accuracy: 18.40%\n",
            "Epoch: 12, Step: 620/655, Loss: 2.207694, Accuracy: 18.39%\n",
            "Epoch: 12, Step: 621/655, Loss: 2.207917, Accuracy: 18.38%\n",
            "Epoch: 12, Step: 622/655, Loss: 2.208072, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 623/655, Loss: 2.208108, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 624/655, Loss: 2.208283, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 625/655, Loss: 2.208258, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 626/655, Loss: 2.208335, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 627/655, Loss: 2.208339, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 628/655, Loss: 2.208368, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 629/655, Loss: 2.208489, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 630/655, Loss: 2.208599, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 631/655, Loss: 2.208758, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 632/655, Loss: 2.208519, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 633/655, Loss: 2.208765, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 634/655, Loss: 2.208835, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 635/655, Loss: 2.208751, Accuracy: 18.31%\n",
            "Epoch: 12, Step: 636/655, Loss: 2.208786, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 637/655, Loss: 2.208749, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 638/655, Loss: 2.208748, Accuracy: 18.29%\n",
            "Epoch: 12, Step: 639/655, Loss: 2.208758, Accuracy: 18.30%\n",
            "Epoch: 12, Step: 640/655, Loss: 2.208593, Accuracy: 18.33%\n",
            "Epoch: 12, Step: 641/655, Loss: 2.208667, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 642/655, Loss: 2.208575, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 643/655, Loss: 2.208651, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 644/655, Loss: 2.208527, Accuracy: 18.35%\n",
            "Epoch: 12, Step: 645/655, Loss: 2.208550, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 646/655, Loss: 2.208491, Accuracy: 18.34%\n",
            "Epoch: 12, Step: 647/655, Loss: 2.208491, Accuracy: 18.36%\n",
            "Epoch: 12, Step: 648/655, Loss: 2.208467, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 649/655, Loss: 2.208306, Accuracy: 18.37%\n",
            "Epoch: 12, Step: 650/655, Loss: 2.208284, Accuracy: 18.38%\n",
            "Epoch: 12, Step: 651/655, Loss: 2.208288, Accuracy: 18.38%\n",
            "Epoch: 12, Step: 652/655, Loss: 2.208234, Accuracy: 18.38%\n",
            "Epoch: 12, Step: 653/655, Loss: 2.207948, Accuracy: 18.40%\n",
            "Epoch: 12, Step: 654/655, Loss: 2.207983, Accuracy: 18.39%\n",
            "Epoch: 12, Step: 655/655, Loss: 2.208137, Accuracy: 18.38%\n",
            "Epoch: 13, Step: 1/655, Loss: 2.175215, Accuracy: 15.62%\n",
            "Epoch: 13, Step: 2/655, Loss: 2.182053, Accuracy: 21.88%\n",
            "Epoch: 13, Step: 3/655, Loss: 2.159438, Accuracy: 25.00%\n",
            "Epoch: 13, Step: 4/655, Loss: 2.204911, Accuracy: 20.31%\n",
            "Epoch: 13, Step: 5/655, Loss: 2.195957, Accuracy: 21.25%\n",
            "Epoch: 13, Step: 6/655, Loss: 2.202764, Accuracy: 20.31%\n",
            "Epoch: 13, Step: 7/655, Loss: 2.203369, Accuracy: 20.98%\n",
            "Epoch: 13, Step: 8/655, Loss: 2.203063, Accuracy: 20.31%\n",
            "Epoch: 13, Step: 9/655, Loss: 2.200155, Accuracy: 20.83%\n",
            "Epoch: 13, Step: 10/655, Loss: 2.198446, Accuracy: 20.94%\n",
            "Epoch: 13, Step: 11/655, Loss: 2.191869, Accuracy: 20.45%\n",
            "Epoch: 13, Step: 12/655, Loss: 2.190947, Accuracy: 19.79%\n",
            "Epoch: 13, Step: 13/655, Loss: 2.198096, Accuracy: 19.47%\n",
            "Epoch: 13, Step: 14/655, Loss: 2.203240, Accuracy: 18.97%\n",
            "Epoch: 13, Step: 15/655, Loss: 2.196977, Accuracy: 18.96%\n",
            "Epoch: 13, Step: 16/655, Loss: 2.209309, Accuracy: 18.16%\n",
            "Epoch: 13, Step: 17/655, Loss: 2.212293, Accuracy: 18.20%\n",
            "Epoch: 13, Step: 18/655, Loss: 2.212512, Accuracy: 18.23%\n",
            "Epoch: 13, Step: 19/655, Loss: 2.215840, Accuracy: 17.93%\n",
            "Epoch: 13, Step: 20/655, Loss: 2.219880, Accuracy: 17.81%\n",
            "Epoch: 13, Step: 21/655, Loss: 2.217228, Accuracy: 18.01%\n",
            "Epoch: 13, Step: 22/655, Loss: 2.221381, Accuracy: 17.90%\n",
            "Epoch: 13, Step: 23/655, Loss: 2.223008, Accuracy: 18.07%\n",
            "Epoch: 13, Step: 24/655, Loss: 2.220053, Accuracy: 18.10%\n",
            "Epoch: 13, Step: 25/655, Loss: 2.221034, Accuracy: 18.25%\n",
            "Epoch: 13, Step: 26/655, Loss: 2.215895, Accuracy: 18.03%\n",
            "Epoch: 13, Step: 27/655, Loss: 2.207400, Accuracy: 18.06%\n",
            "Epoch: 13, Step: 28/655, Loss: 2.209336, Accuracy: 18.30%\n",
            "Epoch: 13, Step: 29/655, Loss: 2.210833, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 30/655, Loss: 2.209708, Accuracy: 18.65%\n",
            "Epoch: 13, Step: 31/655, Loss: 2.204648, Accuracy: 19.25%\n",
            "Epoch: 13, Step: 32/655, Loss: 2.205450, Accuracy: 19.14%\n",
            "Epoch: 13, Step: 33/655, Loss: 2.201346, Accuracy: 19.13%\n",
            "Epoch: 13, Step: 34/655, Loss: 2.199453, Accuracy: 19.30%\n",
            "Epoch: 13, Step: 35/655, Loss: 2.198204, Accuracy: 19.38%\n",
            "Epoch: 13, Step: 36/655, Loss: 2.195460, Accuracy: 19.36%\n",
            "Epoch: 13, Step: 37/655, Loss: 2.200469, Accuracy: 19.09%\n",
            "Epoch: 13, Step: 38/655, Loss: 2.201734, Accuracy: 18.75%\n",
            "Epoch: 13, Step: 39/655, Loss: 2.203733, Accuracy: 18.59%\n",
            "Epoch: 13, Step: 40/655, Loss: 2.203126, Accuracy: 18.75%\n",
            "Epoch: 13, Step: 41/655, Loss: 2.198660, Accuracy: 18.98%\n",
            "Epoch: 13, Step: 42/655, Loss: 2.196969, Accuracy: 19.05%\n",
            "Epoch: 13, Step: 43/655, Loss: 2.198353, Accuracy: 19.11%\n",
            "Epoch: 13, Step: 44/655, Loss: 2.199275, Accuracy: 19.11%\n",
            "Epoch: 13, Step: 45/655, Loss: 2.198839, Accuracy: 19.24%\n",
            "Epoch: 13, Step: 46/655, Loss: 2.196899, Accuracy: 19.50%\n",
            "Epoch: 13, Step: 47/655, Loss: 2.197790, Accuracy: 19.35%\n",
            "Epoch: 13, Step: 48/655, Loss: 2.195064, Accuracy: 19.34%\n",
            "Epoch: 13, Step: 49/655, Loss: 2.194352, Accuracy: 19.45%\n",
            "Epoch: 13, Step: 50/655, Loss: 2.193798, Accuracy: 19.56%\n",
            "Epoch: 13, Step: 51/655, Loss: 2.195533, Accuracy: 19.55%\n",
            "Epoch: 13, Step: 52/655, Loss: 2.194620, Accuracy: 19.71%\n",
            "Epoch: 13, Step: 53/655, Loss: 2.194551, Accuracy: 19.58%\n",
            "Epoch: 13, Step: 54/655, Loss: 2.194687, Accuracy: 19.73%\n",
            "Epoch: 13, Step: 55/655, Loss: 2.195735, Accuracy: 19.60%\n",
            "Epoch: 13, Step: 56/655, Loss: 2.196660, Accuracy: 19.59%\n",
            "Epoch: 13, Step: 57/655, Loss: 2.194278, Accuracy: 19.68%\n",
            "Epoch: 13, Step: 58/655, Loss: 2.196132, Accuracy: 19.67%\n",
            "Epoch: 13, Step: 59/655, Loss: 2.193453, Accuracy: 19.86%\n",
            "Epoch: 13, Step: 60/655, Loss: 2.193712, Accuracy: 19.90%\n",
            "Epoch: 13, Step: 61/655, Loss: 2.193874, Accuracy: 19.88%\n",
            "Epoch: 13, Step: 62/655, Loss: 2.195557, Accuracy: 19.86%\n",
            "Epoch: 13, Step: 63/655, Loss: 2.195460, Accuracy: 19.79%\n",
            "Epoch: 13, Step: 64/655, Loss: 2.197188, Accuracy: 19.63%\n",
            "Epoch: 13, Step: 65/655, Loss: 2.194794, Accuracy: 19.90%\n",
            "Epoch: 13, Step: 66/655, Loss: 2.193154, Accuracy: 19.84%\n",
            "Epoch: 13, Step: 67/655, Loss: 2.191736, Accuracy: 19.96%\n",
            "Epoch: 13, Step: 68/655, Loss: 2.195619, Accuracy: 19.76%\n",
            "Epoch: 13, Step: 69/655, Loss: 2.196183, Accuracy: 19.61%\n",
            "Epoch: 13, Step: 70/655, Loss: 2.196193, Accuracy: 19.55%\n",
            "Epoch: 13, Step: 71/655, Loss: 2.195013, Accuracy: 19.59%\n",
            "Epoch: 13, Step: 72/655, Loss: 2.194518, Accuracy: 19.66%\n",
            "Epoch: 13, Step: 73/655, Loss: 2.196995, Accuracy: 19.52%\n",
            "Epoch: 13, Step: 74/655, Loss: 2.198015, Accuracy: 19.47%\n",
            "Epoch: 13, Step: 75/655, Loss: 2.197132, Accuracy: 19.50%\n",
            "Epoch: 13, Step: 76/655, Loss: 2.197531, Accuracy: 19.28%\n",
            "Epoch: 13, Step: 77/655, Loss: 2.196806, Accuracy: 19.32%\n",
            "Epoch: 13, Step: 78/655, Loss: 2.197736, Accuracy: 19.35%\n",
            "Epoch: 13, Step: 79/655, Loss: 2.197079, Accuracy: 19.38%\n",
            "Epoch: 13, Step: 80/655, Loss: 2.193828, Accuracy: 19.57%\n",
            "Epoch: 13, Step: 81/655, Loss: 2.194336, Accuracy: 19.52%\n",
            "Epoch: 13, Step: 82/655, Loss: 2.194784, Accuracy: 19.51%\n",
            "Epoch: 13, Step: 83/655, Loss: 2.193150, Accuracy: 19.69%\n",
            "Epoch: 13, Step: 84/655, Loss: 2.192213, Accuracy: 19.79%\n",
            "Epoch: 13, Step: 85/655, Loss: 2.193781, Accuracy: 19.67%\n",
            "Epoch: 13, Step: 86/655, Loss: 2.193797, Accuracy: 19.66%\n",
            "Epoch: 13, Step: 87/655, Loss: 2.193757, Accuracy: 19.79%\n",
            "Epoch: 13, Step: 88/655, Loss: 2.194958, Accuracy: 19.74%\n",
            "Epoch: 13, Step: 89/655, Loss: 2.195475, Accuracy: 19.66%\n",
            "Epoch: 13, Step: 90/655, Loss: 2.195313, Accuracy: 19.69%\n",
            "Epoch: 13, Step: 91/655, Loss: 2.195587, Accuracy: 19.64%\n",
            "Epoch: 13, Step: 92/655, Loss: 2.194956, Accuracy: 19.57%\n",
            "Epoch: 13, Step: 93/655, Loss: 2.194606, Accuracy: 19.66%\n",
            "Epoch: 13, Step: 94/655, Loss: 2.194308, Accuracy: 19.65%\n",
            "Epoch: 13, Step: 95/655, Loss: 2.195370, Accuracy: 19.54%\n",
            "Epoch: 13, Step: 96/655, Loss: 2.194195, Accuracy: 19.69%\n",
            "Epoch: 13, Step: 97/655, Loss: 2.193372, Accuracy: 19.68%\n",
            "Epoch: 13, Step: 98/655, Loss: 2.193812, Accuracy: 19.64%\n",
            "Epoch: 13, Step: 99/655, Loss: 2.192966, Accuracy: 19.63%\n",
            "Epoch: 13, Step: 100/655, Loss: 2.192751, Accuracy: 19.59%\n",
            "Epoch: 13, Step: 101/655, Loss: 2.193322, Accuracy: 19.49%\n",
            "Epoch: 13, Step: 102/655, Loss: 2.193369, Accuracy: 19.52%\n",
            "Epoch: 13, Step: 103/655, Loss: 2.193625, Accuracy: 19.57%\n",
            "Epoch: 13, Step: 104/655, Loss: 2.194319, Accuracy: 19.50%\n",
            "Epoch: 13, Step: 105/655, Loss: 2.194309, Accuracy: 19.35%\n",
            "Epoch: 13, Step: 106/655, Loss: 2.194208, Accuracy: 19.46%\n",
            "Epoch: 13, Step: 107/655, Loss: 2.195686, Accuracy: 19.48%\n",
            "Epoch: 13, Step: 108/655, Loss: 2.195175, Accuracy: 19.56%\n",
            "Epoch: 13, Step: 109/655, Loss: 2.194449, Accuracy: 19.67%\n",
            "Epoch: 13, Step: 110/655, Loss: 2.195455, Accuracy: 19.52%\n",
            "Epoch: 13, Step: 111/655, Loss: 2.195665, Accuracy: 19.45%\n",
            "Epoch: 13, Step: 112/655, Loss: 2.196220, Accuracy: 19.39%\n",
            "Epoch: 13, Step: 113/655, Loss: 2.196102, Accuracy: 19.39%\n",
            "Epoch: 13, Step: 114/655, Loss: 2.196118, Accuracy: 19.41%\n",
            "Epoch: 13, Step: 115/655, Loss: 2.196132, Accuracy: 19.48%\n",
            "Epoch: 13, Step: 116/655, Loss: 2.195221, Accuracy: 19.64%\n",
            "Epoch: 13, Step: 117/655, Loss: 2.195118, Accuracy: 19.66%\n",
            "Epoch: 13, Step: 118/655, Loss: 2.195913, Accuracy: 19.57%\n",
            "Epoch: 13, Step: 119/655, Loss: 2.195787, Accuracy: 19.56%\n",
            "Epoch: 13, Step: 120/655, Loss: 2.195560, Accuracy: 19.58%\n",
            "Epoch: 13, Step: 121/655, Loss: 2.194657, Accuracy: 19.60%\n",
            "Epoch: 13, Step: 122/655, Loss: 2.194971, Accuracy: 19.60%\n",
            "Epoch: 13, Step: 123/655, Loss: 2.194309, Accuracy: 19.72%\n",
            "Epoch: 13, Step: 124/655, Loss: 2.195023, Accuracy: 19.66%\n",
            "Epoch: 13, Step: 125/655, Loss: 2.194215, Accuracy: 19.70%\n",
            "Epoch: 13, Step: 126/655, Loss: 2.194328, Accuracy: 19.74%\n",
            "Epoch: 13, Step: 127/655, Loss: 2.195160, Accuracy: 19.71%\n",
            "Epoch: 13, Step: 128/655, Loss: 2.194929, Accuracy: 19.63%\n",
            "Epoch: 13, Step: 129/655, Loss: 2.194735, Accuracy: 19.65%\n",
            "Epoch: 13, Step: 130/655, Loss: 2.194412, Accuracy: 19.66%\n",
            "Epoch: 13, Step: 131/655, Loss: 2.194558, Accuracy: 19.61%\n",
            "Epoch: 13, Step: 132/655, Loss: 2.195866, Accuracy: 19.55%\n",
            "Epoch: 13, Step: 133/655, Loss: 2.196385, Accuracy: 19.48%\n",
            "Epoch: 13, Step: 134/655, Loss: 2.196795, Accuracy: 19.47%\n",
            "Epoch: 13, Step: 135/655, Loss: 2.197463, Accuracy: 19.40%\n",
            "Epoch: 13, Step: 136/655, Loss: 2.197172, Accuracy: 19.35%\n",
            "Epoch: 13, Step: 137/655, Loss: 2.197094, Accuracy: 19.39%\n",
            "Epoch: 13, Step: 138/655, Loss: 2.197298, Accuracy: 19.34%\n",
            "Epoch: 13, Step: 139/655, Loss: 2.198694, Accuracy: 19.27%\n",
            "Epoch: 13, Step: 140/655, Loss: 2.198854, Accuracy: 19.29%\n",
            "Epoch: 13, Step: 141/655, Loss: 2.199099, Accuracy: 19.22%\n",
            "Epoch: 13, Step: 142/655, Loss: 2.200083, Accuracy: 19.19%\n",
            "Epoch: 13, Step: 143/655, Loss: 2.199545, Accuracy: 19.21%\n",
            "Epoch: 13, Step: 144/655, Loss: 2.200081, Accuracy: 19.10%\n",
            "Epoch: 13, Step: 145/655, Loss: 2.201679, Accuracy: 19.03%\n",
            "Epoch: 13, Step: 146/655, Loss: 2.201663, Accuracy: 18.99%\n",
            "Epoch: 13, Step: 147/655, Loss: 2.202131, Accuracy: 18.98%\n",
            "Epoch: 13, Step: 148/655, Loss: 2.202421, Accuracy: 19.02%\n",
            "Epoch: 13, Step: 149/655, Loss: 2.201855, Accuracy: 19.02%\n",
            "Epoch: 13, Step: 150/655, Loss: 2.201904, Accuracy: 19.00%\n",
            "Epoch: 13, Step: 151/655, Loss: 2.200951, Accuracy: 19.06%\n",
            "Epoch: 13, Step: 152/655, Loss: 2.201841, Accuracy: 19.00%\n",
            "Epoch: 13, Step: 153/655, Loss: 2.202114, Accuracy: 18.93%\n",
            "Epoch: 13, Step: 154/655, Loss: 2.201887, Accuracy: 18.91%\n",
            "Epoch: 13, Step: 155/655, Loss: 2.201832, Accuracy: 18.89%\n",
            "Epoch: 13, Step: 156/655, Loss: 2.201616, Accuracy: 18.91%\n",
            "Epoch: 13, Step: 157/655, Loss: 2.201540, Accuracy: 18.97%\n",
            "Epoch: 13, Step: 158/655, Loss: 2.202600, Accuracy: 18.93%\n",
            "Epoch: 13, Step: 159/655, Loss: 2.201956, Accuracy: 18.95%\n",
            "Epoch: 13, Step: 160/655, Loss: 2.201656, Accuracy: 18.93%\n",
            "Epoch: 13, Step: 161/655, Loss: 2.201069, Accuracy: 18.92%\n",
            "Epoch: 13, Step: 162/655, Loss: 2.201497, Accuracy: 18.90%\n",
            "Epoch: 13, Step: 163/655, Loss: 2.202112, Accuracy: 18.87%\n",
            "Epoch: 13, Step: 164/655, Loss: 2.202404, Accuracy: 18.79%\n",
            "Epoch: 13, Step: 165/655, Loss: 2.202574, Accuracy: 18.79%\n",
            "Epoch: 13, Step: 166/655, Loss: 2.202766, Accuracy: 18.75%\n",
            "Epoch: 13, Step: 167/655, Loss: 2.203650, Accuracy: 18.71%\n",
            "Epoch: 13, Step: 168/655, Loss: 2.203820, Accuracy: 18.69%\n",
            "Epoch: 13, Step: 169/655, Loss: 2.204384, Accuracy: 18.68%\n",
            "Epoch: 13, Step: 170/655, Loss: 2.203983, Accuracy: 18.81%\n",
            "Epoch: 13, Step: 171/655, Loss: 2.203820, Accuracy: 18.88%\n",
            "Epoch: 13, Step: 172/655, Loss: 2.204025, Accuracy: 18.90%\n",
            "Epoch: 13, Step: 173/655, Loss: 2.204449, Accuracy: 18.89%\n",
            "Epoch: 13, Step: 174/655, Loss: 2.203935, Accuracy: 18.82%\n",
            "Epoch: 13, Step: 175/655, Loss: 2.204439, Accuracy: 18.79%\n",
            "Epoch: 13, Step: 176/655, Loss: 2.204208, Accuracy: 18.82%\n",
            "Epoch: 13, Step: 177/655, Loss: 2.203579, Accuracy: 18.89%\n",
            "Epoch: 13, Step: 178/655, Loss: 2.203407, Accuracy: 18.89%\n",
            "Epoch: 13, Step: 179/655, Loss: 2.203268, Accuracy: 18.91%\n",
            "Epoch: 13, Step: 180/655, Loss: 2.203537, Accuracy: 18.87%\n",
            "Epoch: 13, Step: 181/655, Loss: 2.203871, Accuracy: 18.84%\n",
            "Epoch: 13, Step: 182/655, Loss: 2.203977, Accuracy: 18.84%\n",
            "Epoch: 13, Step: 183/655, Loss: 2.203561, Accuracy: 18.84%\n",
            "Epoch: 13, Step: 184/655, Loss: 2.202672, Accuracy: 18.87%\n",
            "Epoch: 13, Step: 185/655, Loss: 2.202395, Accuracy: 18.89%\n",
            "Epoch: 13, Step: 186/655, Loss: 2.202202, Accuracy: 18.90%\n",
            "Epoch: 13, Step: 187/655, Loss: 2.202154, Accuracy: 18.85%\n",
            "Epoch: 13, Step: 188/655, Loss: 2.202155, Accuracy: 18.85%\n",
            "Epoch: 13, Step: 189/655, Loss: 2.201846, Accuracy: 18.87%\n",
            "Epoch: 13, Step: 190/655, Loss: 2.201834, Accuracy: 18.90%\n",
            "Epoch: 13, Step: 191/655, Loss: 2.202272, Accuracy: 18.98%\n",
            "Epoch: 13, Step: 192/655, Loss: 2.203108, Accuracy: 18.93%\n",
            "Epoch: 13, Step: 193/655, Loss: 2.203414, Accuracy: 18.88%\n",
            "Epoch: 13, Step: 194/655, Loss: 2.202823, Accuracy: 18.94%\n",
            "Epoch: 13, Step: 195/655, Loss: 2.202586, Accuracy: 18.96%\n",
            "Epoch: 13, Step: 196/655, Loss: 2.201686, Accuracy: 18.97%\n",
            "Epoch: 13, Step: 197/655, Loss: 2.201089, Accuracy: 19.04%\n",
            "Epoch: 13, Step: 198/655, Loss: 2.201245, Accuracy: 19.07%\n",
            "Epoch: 13, Step: 199/655, Loss: 2.200823, Accuracy: 19.03%\n",
            "Epoch: 13, Step: 200/655, Loss: 2.200734, Accuracy: 19.00%\n",
            "Epoch: 13, Step: 201/655, Loss: 2.201017, Accuracy: 18.94%\n",
            "Epoch: 13, Step: 202/655, Loss: 2.201277, Accuracy: 18.92%\n",
            "Epoch: 13, Step: 203/655, Loss: 2.201161, Accuracy: 18.95%\n",
            "Epoch: 13, Step: 204/655, Loss: 2.200724, Accuracy: 19.00%\n",
            "Epoch: 13, Step: 205/655, Loss: 2.201220, Accuracy: 18.98%\n",
            "Epoch: 13, Step: 206/655, Loss: 2.201263, Accuracy: 18.92%\n",
            "Epoch: 13, Step: 207/655, Loss: 2.201380, Accuracy: 18.89%\n",
            "Epoch: 13, Step: 208/655, Loss: 2.201187, Accuracy: 18.93%\n",
            "Epoch: 13, Step: 209/655, Loss: 2.201253, Accuracy: 18.94%\n",
            "Epoch: 13, Step: 210/655, Loss: 2.201610, Accuracy: 18.90%\n",
            "Epoch: 13, Step: 211/655, Loss: 2.202152, Accuracy: 18.88%\n",
            "Epoch: 13, Step: 212/655, Loss: 2.202460, Accuracy: 18.87%\n",
            "Epoch: 13, Step: 213/655, Loss: 2.202126, Accuracy: 18.87%\n",
            "Epoch: 13, Step: 214/655, Loss: 2.202139, Accuracy: 18.87%\n",
            "Epoch: 13, Step: 215/655, Loss: 2.202171, Accuracy: 18.88%\n",
            "Epoch: 13, Step: 216/655, Loss: 2.202024, Accuracy: 18.88%\n",
            "Epoch: 13, Step: 217/655, Loss: 2.202279, Accuracy: 18.88%\n",
            "Epoch: 13, Step: 218/655, Loss: 2.202024, Accuracy: 18.86%\n",
            "Epoch: 13, Step: 219/655, Loss: 2.201831, Accuracy: 18.88%\n",
            "Epoch: 13, Step: 220/655, Loss: 2.201492, Accuracy: 18.85%\n",
            "Epoch: 13, Step: 221/655, Loss: 2.201529, Accuracy: 18.86%\n",
            "Epoch: 13, Step: 222/655, Loss: 2.201914, Accuracy: 18.82%\n",
            "Epoch: 13, Step: 223/655, Loss: 2.202422, Accuracy: 18.79%\n",
            "Epoch: 13, Step: 224/655, Loss: 2.202530, Accuracy: 18.78%\n",
            "Epoch: 13, Step: 225/655, Loss: 2.202298, Accuracy: 18.76%\n",
            "Epoch: 13, Step: 226/655, Loss: 2.202436, Accuracy: 18.76%\n",
            "Epoch: 13, Step: 227/655, Loss: 2.202539, Accuracy: 18.78%\n",
            "Epoch: 13, Step: 228/655, Loss: 2.202212, Accuracy: 18.78%\n",
            "Epoch: 13, Step: 229/655, Loss: 2.202361, Accuracy: 18.82%\n",
            "Epoch: 13, Step: 230/655, Loss: 2.202613, Accuracy: 18.82%\n",
            "Epoch: 13, Step: 231/655, Loss: 2.202527, Accuracy: 18.86%\n",
            "Epoch: 13, Step: 232/655, Loss: 2.202518, Accuracy: 18.84%\n",
            "Epoch: 13, Step: 233/655, Loss: 2.202661, Accuracy: 18.86%\n",
            "Epoch: 13, Step: 234/655, Loss: 2.202901, Accuracy: 18.82%\n",
            "Epoch: 13, Step: 235/655, Loss: 2.203698, Accuracy: 18.79%\n",
            "Epoch: 13, Step: 236/655, Loss: 2.203667, Accuracy: 18.79%\n",
            "Epoch: 13, Step: 237/655, Loss: 2.204031, Accuracy: 18.76%\n",
            "Epoch: 13, Step: 238/655, Loss: 2.204689, Accuracy: 18.74%\n",
            "Epoch: 13, Step: 239/655, Loss: 2.204528, Accuracy: 18.78%\n",
            "Epoch: 13, Step: 240/655, Loss: 2.204745, Accuracy: 18.78%\n",
            "Epoch: 13, Step: 241/655, Loss: 2.205235, Accuracy: 18.75%\n",
            "Epoch: 13, Step: 242/655, Loss: 2.205107, Accuracy: 18.79%\n",
            "Epoch: 13, Step: 243/655, Loss: 2.205364, Accuracy: 18.79%\n",
            "Epoch: 13, Step: 244/655, Loss: 2.205643, Accuracy: 18.79%\n",
            "Epoch: 13, Step: 245/655, Loss: 2.205559, Accuracy: 18.83%\n",
            "Epoch: 13, Step: 246/655, Loss: 2.205580, Accuracy: 18.83%\n",
            "Epoch: 13, Step: 247/655, Loss: 2.205483, Accuracy: 18.85%\n",
            "Epoch: 13, Step: 248/655, Loss: 2.205336, Accuracy: 18.85%\n",
            "Epoch: 13, Step: 249/655, Loss: 2.205592, Accuracy: 18.89%\n",
            "Epoch: 13, Step: 250/655, Loss: 2.205831, Accuracy: 18.90%\n",
            "Epoch: 13, Step: 251/655, Loss: 2.205858, Accuracy: 18.90%\n",
            "Epoch: 13, Step: 252/655, Loss: 2.205647, Accuracy: 18.90%\n",
            "Epoch: 13, Step: 253/655, Loss: 2.205082, Accuracy: 18.92%\n",
            "Epoch: 13, Step: 254/655, Loss: 2.205105, Accuracy: 18.98%\n",
            "Epoch: 13, Step: 255/655, Loss: 2.205322, Accuracy: 18.97%\n",
            "Epoch: 13, Step: 256/655, Loss: 2.205661, Accuracy: 18.93%\n",
            "Epoch: 13, Step: 257/655, Loss: 2.205667, Accuracy: 18.94%\n",
            "Epoch: 13, Step: 258/655, Loss: 2.205686, Accuracy: 18.94%\n",
            "Epoch: 13, Step: 259/655, Loss: 2.205898, Accuracy: 18.94%\n",
            "Epoch: 13, Step: 260/655, Loss: 2.205727, Accuracy: 18.94%\n",
            "Epoch: 13, Step: 261/655, Loss: 2.205551, Accuracy: 18.99%\n",
            "Epoch: 13, Step: 262/655, Loss: 2.205929, Accuracy: 18.96%\n",
            "Epoch: 13, Step: 263/655, Loss: 2.205729, Accuracy: 19.01%\n",
            "Epoch: 13, Step: 264/655, Loss: 2.206325, Accuracy: 18.95%\n",
            "Epoch: 13, Step: 265/655, Loss: 2.206038, Accuracy: 19.00%\n",
            "Epoch: 13, Step: 266/655, Loss: 2.205856, Accuracy: 19.02%\n",
            "Epoch: 13, Step: 267/655, Loss: 2.205581, Accuracy: 19.02%\n",
            "Epoch: 13, Step: 268/655, Loss: 2.205656, Accuracy: 19.03%\n",
            "Epoch: 13, Step: 269/655, Loss: 2.206007, Accuracy: 19.01%\n",
            "Epoch: 13, Step: 270/655, Loss: 2.205764, Accuracy: 19.00%\n",
            "Epoch: 13, Step: 271/655, Loss: 2.205582, Accuracy: 18.97%\n",
            "Epoch: 13, Step: 272/655, Loss: 2.205543, Accuracy: 18.96%\n",
            "Epoch: 13, Step: 273/655, Loss: 2.205618, Accuracy: 18.96%\n",
            "Epoch: 13, Step: 274/655, Loss: 2.205575, Accuracy: 18.97%\n",
            "Epoch: 13, Step: 275/655, Loss: 2.205507, Accuracy: 18.97%\n",
            "Epoch: 13, Step: 276/655, Loss: 2.205941, Accuracy: 18.94%\n",
            "Epoch: 13, Step: 277/655, Loss: 2.206240, Accuracy: 18.92%\n",
            "Epoch: 13, Step: 278/655, Loss: 2.205919, Accuracy: 18.93%\n",
            "Epoch: 13, Step: 279/655, Loss: 2.205740, Accuracy: 18.92%\n",
            "Epoch: 13, Step: 280/655, Loss: 2.205931, Accuracy: 18.88%\n",
            "Epoch: 13, Step: 281/655, Loss: 2.205801, Accuracy: 18.86%\n",
            "Epoch: 13, Step: 282/655, Loss: 2.205868, Accuracy: 18.84%\n",
            "Epoch: 13, Step: 283/655, Loss: 2.206416, Accuracy: 18.81%\n",
            "Epoch: 13, Step: 284/655, Loss: 2.206654, Accuracy: 18.77%\n",
            "Epoch: 13, Step: 285/655, Loss: 2.206711, Accuracy: 18.76%\n",
            "Epoch: 13, Step: 286/655, Loss: 2.206881, Accuracy: 18.77%\n",
            "Epoch: 13, Step: 287/655, Loss: 2.206727, Accuracy: 18.76%\n",
            "Epoch: 13, Step: 288/655, Loss: 2.206820, Accuracy: 18.73%\n",
            "Epoch: 13, Step: 289/655, Loss: 2.207088, Accuracy: 18.73%\n",
            "Epoch: 13, Step: 290/655, Loss: 2.207110, Accuracy: 18.75%\n",
            "Epoch: 13, Step: 291/655, Loss: 2.206906, Accuracy: 18.77%\n",
            "Epoch: 13, Step: 292/655, Loss: 2.206710, Accuracy: 18.76%\n",
            "Epoch: 13, Step: 293/655, Loss: 2.207320, Accuracy: 18.72%\n",
            "Epoch: 13, Step: 294/655, Loss: 2.207211, Accuracy: 18.71%\n",
            "Epoch: 13, Step: 295/655, Loss: 2.206988, Accuracy: 18.69%\n",
            "Epoch: 13, Step: 296/655, Loss: 2.206926, Accuracy: 18.67%\n",
            "Epoch: 13, Step: 297/655, Loss: 2.206925, Accuracy: 18.66%\n",
            "Epoch: 13, Step: 298/655, Loss: 2.206778, Accuracy: 18.68%\n",
            "Epoch: 13, Step: 299/655, Loss: 2.207080, Accuracy: 18.66%\n",
            "Epoch: 13, Step: 300/655, Loss: 2.207013, Accuracy: 18.62%\n",
            "Epoch: 13, Step: 301/655, Loss: 2.206887, Accuracy: 18.64%\n",
            "Epoch: 13, Step: 302/655, Loss: 2.207063, Accuracy: 18.62%\n",
            "Epoch: 13, Step: 303/655, Loss: 2.207254, Accuracy: 18.60%\n",
            "Epoch: 13, Step: 304/655, Loss: 2.207666, Accuracy: 18.58%\n",
            "Epoch: 13, Step: 305/655, Loss: 2.207837, Accuracy: 18.57%\n",
            "Epoch: 13, Step: 306/655, Loss: 2.207523, Accuracy: 18.59%\n",
            "Epoch: 13, Step: 307/655, Loss: 2.207997, Accuracy: 18.58%\n",
            "Epoch: 13, Step: 308/655, Loss: 2.208104, Accuracy: 18.59%\n",
            "Epoch: 13, Step: 309/655, Loss: 2.208383, Accuracy: 18.60%\n",
            "Epoch: 13, Step: 310/655, Loss: 2.208427, Accuracy: 18.63%\n",
            "Epoch: 13, Step: 311/655, Loss: 2.208006, Accuracy: 18.61%\n",
            "Epoch: 13, Step: 312/655, Loss: 2.208459, Accuracy: 18.59%\n",
            "Epoch: 13, Step: 313/655, Loss: 2.208906, Accuracy: 18.55%\n",
            "Epoch: 13, Step: 314/655, Loss: 2.208863, Accuracy: 18.57%\n",
            "Epoch: 13, Step: 315/655, Loss: 2.209029, Accuracy: 18.56%\n",
            "Epoch: 13, Step: 316/655, Loss: 2.208883, Accuracy: 18.54%\n",
            "Epoch: 13, Step: 317/655, Loss: 2.208835, Accuracy: 18.57%\n",
            "Epoch: 13, Step: 318/655, Loss: 2.208862, Accuracy: 18.55%\n",
            "Epoch: 13, Step: 319/655, Loss: 2.208902, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 320/655, Loss: 2.209068, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 321/655, Loss: 2.209369, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 322/655, Loss: 2.209626, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 323/655, Loss: 2.209488, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 324/655, Loss: 2.209216, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 325/655, Loss: 2.209083, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 326/655, Loss: 2.208880, Accuracy: 18.54%\n",
            "Epoch: 13, Step: 327/655, Loss: 2.209074, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 328/655, Loss: 2.209042, Accuracy: 18.49%\n",
            "Epoch: 13, Step: 329/655, Loss: 2.208779, Accuracy: 18.47%\n",
            "Epoch: 13, Step: 330/655, Loss: 2.208675, Accuracy: 18.49%\n",
            "Epoch: 13, Step: 331/655, Loss: 2.208643, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 332/655, Loss: 2.208653, Accuracy: 18.48%\n",
            "Epoch: 13, Step: 333/655, Loss: 2.208750, Accuracy: 18.49%\n",
            "Epoch: 13, Step: 334/655, Loss: 2.208955, Accuracy: 18.47%\n",
            "Epoch: 13, Step: 335/655, Loss: 2.209025, Accuracy: 18.47%\n",
            "Epoch: 13, Step: 336/655, Loss: 2.209037, Accuracy: 18.45%\n",
            "Epoch: 13, Step: 337/655, Loss: 2.209077, Accuracy: 18.44%\n",
            "Epoch: 13, Step: 338/655, Loss: 2.209141, Accuracy: 18.46%\n",
            "Epoch: 13, Step: 339/655, Loss: 2.209368, Accuracy: 18.46%\n",
            "Epoch: 13, Step: 340/655, Loss: 2.209105, Accuracy: 18.44%\n",
            "Epoch: 13, Step: 341/655, Loss: 2.208967, Accuracy: 18.48%\n",
            "Epoch: 13, Step: 342/655, Loss: 2.208778, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 343/655, Loss: 2.208648, Accuracy: 18.53%\n",
            "Epoch: 13, Step: 344/655, Loss: 2.208330, Accuracy: 18.58%\n",
            "Epoch: 13, Step: 345/655, Loss: 2.208334, Accuracy: 18.60%\n",
            "Epoch: 13, Step: 346/655, Loss: 2.208465, Accuracy: 18.61%\n",
            "Epoch: 13, Step: 347/655, Loss: 2.208785, Accuracy: 18.58%\n",
            "Epoch: 13, Step: 348/655, Loss: 2.208665, Accuracy: 18.62%\n",
            "Epoch: 13, Step: 349/655, Loss: 2.208698, Accuracy: 18.62%\n",
            "Epoch: 13, Step: 350/655, Loss: 2.208643, Accuracy: 18.62%\n",
            "Epoch: 13, Step: 351/655, Loss: 2.208508, Accuracy: 18.63%\n",
            "Epoch: 13, Step: 352/655, Loss: 2.208595, Accuracy: 18.61%\n",
            "Epoch: 13, Step: 353/655, Loss: 2.208528, Accuracy: 18.61%\n",
            "Epoch: 13, Step: 354/655, Loss: 2.208518, Accuracy: 18.63%\n",
            "Epoch: 13, Step: 355/655, Loss: 2.208751, Accuracy: 18.62%\n",
            "Epoch: 13, Step: 356/655, Loss: 2.209092, Accuracy: 18.62%\n",
            "Epoch: 13, Step: 357/655, Loss: 2.209115, Accuracy: 18.63%\n",
            "Epoch: 13, Step: 358/655, Loss: 2.209368, Accuracy: 18.61%\n",
            "Epoch: 13, Step: 359/655, Loss: 2.209278, Accuracy: 18.61%\n",
            "Epoch: 13, Step: 360/655, Loss: 2.209177, Accuracy: 18.61%\n",
            "Epoch: 13, Step: 361/655, Loss: 2.209229, Accuracy: 18.62%\n",
            "Epoch: 13, Step: 362/655, Loss: 2.209397, Accuracy: 18.61%\n",
            "Epoch: 13, Step: 363/655, Loss: 2.209268, Accuracy: 18.60%\n",
            "Epoch: 13, Step: 364/655, Loss: 2.209294, Accuracy: 18.57%\n",
            "Epoch: 13, Step: 365/655, Loss: 2.209638, Accuracy: 18.56%\n",
            "Epoch: 13, Step: 366/655, Loss: 2.209686, Accuracy: 18.54%\n",
            "Epoch: 13, Step: 367/655, Loss: 2.209553, Accuracy: 18.54%\n",
            "Epoch: 13, Step: 368/655, Loss: 2.209657, Accuracy: 18.53%\n",
            "Epoch: 13, Step: 369/655, Loss: 2.209354, Accuracy: 18.54%\n",
            "Epoch: 13, Step: 370/655, Loss: 2.209292, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 371/655, Loss: 2.209186, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 372/655, Loss: 2.208990, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 373/655, Loss: 2.209065, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 374/655, Loss: 2.208845, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 375/655, Loss: 2.208913, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 376/655, Loss: 2.209177, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 377/655, Loss: 2.209356, Accuracy: 18.49%\n",
            "Epoch: 13, Step: 378/655, Loss: 2.209630, Accuracy: 18.49%\n",
            "Epoch: 13, Step: 379/655, Loss: 2.209449, Accuracy: 18.49%\n",
            "Epoch: 13, Step: 380/655, Loss: 2.209353, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 381/655, Loss: 2.209521, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 382/655, Loss: 2.209513, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 383/655, Loss: 2.209187, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 384/655, Loss: 2.209227, Accuracy: 18.53%\n",
            "Epoch: 13, Step: 385/655, Loss: 2.208944, Accuracy: 18.54%\n",
            "Epoch: 13, Step: 386/655, Loss: 2.209056, Accuracy: 18.55%\n",
            "Epoch: 13, Step: 387/655, Loss: 2.208997, Accuracy: 18.54%\n",
            "Epoch: 13, Step: 388/655, Loss: 2.209009, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 389/655, Loss: 2.209213, Accuracy: 18.53%\n",
            "Epoch: 13, Step: 390/655, Loss: 2.209079, Accuracy: 18.53%\n",
            "Epoch: 13, Step: 391/655, Loss: 2.209333, Accuracy: 18.49%\n",
            "Epoch: 13, Step: 392/655, Loss: 2.209137, Accuracy: 18.49%\n",
            "Epoch: 13, Step: 393/655, Loss: 2.209376, Accuracy: 18.46%\n",
            "Epoch: 13, Step: 394/655, Loss: 2.209037, Accuracy: 18.46%\n",
            "Epoch: 13, Step: 395/655, Loss: 2.209273, Accuracy: 18.44%\n",
            "Epoch: 13, Step: 396/655, Loss: 2.209182, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 397/655, Loss: 2.209070, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 398/655, Loss: 2.208882, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 399/655, Loss: 2.209017, Accuracy: 18.39%\n",
            "Epoch: 13, Step: 400/655, Loss: 2.209139, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 401/655, Loss: 2.209000, Accuracy: 18.41%\n",
            "Epoch: 13, Step: 402/655, Loss: 2.209357, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 403/655, Loss: 2.209252, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 404/655, Loss: 2.209222, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 405/655, Loss: 2.208998, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 406/655, Loss: 2.209244, Accuracy: 18.38%\n",
            "Epoch: 13, Step: 407/655, Loss: 2.209401, Accuracy: 18.37%\n",
            "Epoch: 13, Step: 408/655, Loss: 2.209269, Accuracy: 18.37%\n",
            "Epoch: 13, Step: 409/655, Loss: 2.209156, Accuracy: 18.39%\n",
            "Epoch: 13, Step: 410/655, Loss: 2.208936, Accuracy: 18.39%\n",
            "Epoch: 13, Step: 411/655, Loss: 2.208531, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 412/655, Loss: 2.208781, Accuracy: 18.38%\n",
            "Epoch: 13, Step: 413/655, Loss: 2.208471, Accuracy: 18.38%\n",
            "Epoch: 13, Step: 414/655, Loss: 2.208429, Accuracy: 18.35%\n",
            "Epoch: 13, Step: 415/655, Loss: 2.208341, Accuracy: 18.34%\n",
            "Epoch: 13, Step: 416/655, Loss: 2.208262, Accuracy: 18.36%\n",
            "Epoch: 13, Step: 417/655, Loss: 2.208359, Accuracy: 18.37%\n",
            "Epoch: 13, Step: 418/655, Loss: 2.208651, Accuracy: 18.37%\n",
            "Epoch: 13, Step: 419/655, Loss: 2.208876, Accuracy: 18.35%\n",
            "Epoch: 13, Step: 420/655, Loss: 2.209130, Accuracy: 18.32%\n",
            "Epoch: 13, Step: 421/655, Loss: 2.208901, Accuracy: 18.33%\n",
            "Epoch: 13, Step: 422/655, Loss: 2.208939, Accuracy: 18.32%\n",
            "Epoch: 13, Step: 423/655, Loss: 2.208658, Accuracy: 18.33%\n",
            "Epoch: 13, Step: 424/655, Loss: 2.208086, Accuracy: 18.35%\n",
            "Epoch: 13, Step: 425/655, Loss: 2.207986, Accuracy: 18.37%\n",
            "Epoch: 13, Step: 426/655, Loss: 2.208188, Accuracy: 18.35%\n",
            "Epoch: 13, Step: 427/655, Loss: 2.208137, Accuracy: 18.35%\n",
            "Epoch: 13, Step: 428/655, Loss: 2.207935, Accuracy: 18.36%\n",
            "Epoch: 13, Step: 429/655, Loss: 2.208267, Accuracy: 18.35%\n",
            "Epoch: 13, Step: 430/655, Loss: 2.208263, Accuracy: 18.35%\n",
            "Epoch: 13, Step: 431/655, Loss: 2.208137, Accuracy: 18.37%\n",
            "Epoch: 13, Step: 432/655, Loss: 2.208080, Accuracy: 18.37%\n",
            "Epoch: 13, Step: 433/655, Loss: 2.208082, Accuracy: 18.37%\n",
            "Epoch: 13, Step: 434/655, Loss: 2.208317, Accuracy: 18.36%\n",
            "Epoch: 13, Step: 435/655, Loss: 2.208383, Accuracy: 18.36%\n",
            "Epoch: 13, Step: 436/655, Loss: 2.208530, Accuracy: 18.36%\n",
            "Epoch: 13, Step: 437/655, Loss: 2.208676, Accuracy: 18.34%\n",
            "Epoch: 13, Step: 438/655, Loss: 2.208733, Accuracy: 18.34%\n",
            "Epoch: 13, Step: 439/655, Loss: 2.208596, Accuracy: 18.33%\n",
            "Epoch: 13, Step: 440/655, Loss: 2.208473, Accuracy: 18.32%\n",
            "Epoch: 13, Step: 441/655, Loss: 2.208162, Accuracy: 18.32%\n",
            "Epoch: 13, Step: 442/655, Loss: 2.208180, Accuracy: 18.32%\n",
            "Epoch: 13, Step: 443/655, Loss: 2.208373, Accuracy: 18.31%\n",
            "Epoch: 13, Step: 444/655, Loss: 2.208131, Accuracy: 18.31%\n",
            "Epoch: 13, Step: 445/655, Loss: 2.208317, Accuracy: 18.31%\n",
            "Epoch: 13, Step: 446/655, Loss: 2.208110, Accuracy: 18.30%\n",
            "Epoch: 13, Step: 447/655, Loss: 2.208022, Accuracy: 18.32%\n",
            "Epoch: 13, Step: 448/655, Loss: 2.208122, Accuracy: 18.33%\n",
            "Epoch: 13, Step: 449/655, Loss: 2.208435, Accuracy: 18.33%\n",
            "Epoch: 13, Step: 450/655, Loss: 2.208055, Accuracy: 18.35%\n",
            "Epoch: 13, Step: 451/655, Loss: 2.208015, Accuracy: 18.37%\n",
            "Epoch: 13, Step: 452/655, Loss: 2.208080, Accuracy: 18.36%\n",
            "Epoch: 13, Step: 453/655, Loss: 2.208196, Accuracy: 18.35%\n",
            "Epoch: 13, Step: 454/655, Loss: 2.208218, Accuracy: 18.36%\n",
            "Epoch: 13, Step: 455/655, Loss: 2.207861, Accuracy: 18.39%\n",
            "Epoch: 13, Step: 456/655, Loss: 2.208198, Accuracy: 18.37%\n",
            "Epoch: 13, Step: 457/655, Loss: 2.208110, Accuracy: 18.39%\n",
            "Epoch: 13, Step: 458/655, Loss: 2.207865, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 459/655, Loss: 2.207956, Accuracy: 18.39%\n",
            "Epoch: 13, Step: 460/655, Loss: 2.208234, Accuracy: 18.39%\n",
            "Epoch: 13, Step: 461/655, Loss: 2.208195, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 462/655, Loss: 2.208090, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 463/655, Loss: 2.207728, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 464/655, Loss: 2.207844, Accuracy: 18.45%\n",
            "Epoch: 13, Step: 465/655, Loss: 2.207999, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 466/655, Loss: 2.207938, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 467/655, Loss: 2.208196, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 468/655, Loss: 2.208215, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 469/655, Loss: 2.208435, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 470/655, Loss: 2.208422, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 471/655, Loss: 2.208524, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 472/655, Loss: 2.208575, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 473/655, Loss: 2.208649, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 474/655, Loss: 2.208720, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 475/655, Loss: 2.209159, Accuracy: 18.41%\n",
            "Epoch: 13, Step: 476/655, Loss: 2.208851, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 477/655, Loss: 2.209260, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 478/655, Loss: 2.209150, Accuracy: 18.41%\n",
            "Epoch: 13, Step: 479/655, Loss: 2.209176, Accuracy: 18.39%\n",
            "Epoch: 13, Step: 480/655, Loss: 2.209147, Accuracy: 18.39%\n",
            "Epoch: 13, Step: 481/655, Loss: 2.208898, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 482/655, Loss: 2.209033, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 483/655, Loss: 2.209192, Accuracy: 18.39%\n",
            "Epoch: 13, Step: 484/655, Loss: 2.209351, Accuracy: 18.38%\n",
            "Epoch: 13, Step: 485/655, Loss: 2.209265, Accuracy: 18.41%\n",
            "Epoch: 13, Step: 486/655, Loss: 2.209242, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 487/655, Loss: 2.209237, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 488/655, Loss: 2.209376, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 489/655, Loss: 2.209657, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 490/655, Loss: 2.209610, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 491/655, Loss: 2.209666, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 492/655, Loss: 2.209448, Accuracy: 18.44%\n",
            "Epoch: 13, Step: 493/655, Loss: 2.209350, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 494/655, Loss: 2.209316, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 495/655, Loss: 2.209376, Accuracy: 18.41%\n",
            "Epoch: 13, Step: 496/655, Loss: 2.209365, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 497/655, Loss: 2.209304, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 498/655, Loss: 2.209608, Accuracy: 18.39%\n",
            "Epoch: 13, Step: 499/655, Loss: 2.209298, Accuracy: 18.41%\n",
            "Epoch: 13, Step: 500/655, Loss: 2.209526, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 501/655, Loss: 2.209198, Accuracy: 18.41%\n",
            "Epoch: 13, Step: 502/655, Loss: 2.209125, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 503/655, Loss: 2.209158, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 504/655, Loss: 2.209175, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 505/655, Loss: 2.209017, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 506/655, Loss: 2.208840, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 507/655, Loss: 2.208953, Accuracy: 18.41%\n",
            "Epoch: 13, Step: 508/655, Loss: 2.209022, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 509/655, Loss: 2.208661, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 510/655, Loss: 2.208558, Accuracy: 18.41%\n",
            "Epoch: 13, Step: 511/655, Loss: 2.208284, Accuracy: 18.45%\n",
            "Epoch: 13, Step: 512/655, Loss: 2.208309, Accuracy: 18.44%\n",
            "Epoch: 13, Step: 513/655, Loss: 2.208388, Accuracy: 18.44%\n",
            "Epoch: 13, Step: 514/655, Loss: 2.208341, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 515/655, Loss: 2.208068, Accuracy: 18.44%\n",
            "Epoch: 13, Step: 516/655, Loss: 2.207885, Accuracy: 18.46%\n",
            "Epoch: 13, Step: 517/655, Loss: 2.207862, Accuracy: 18.46%\n",
            "Epoch: 13, Step: 518/655, Loss: 2.207638, Accuracy: 18.45%\n",
            "Epoch: 13, Step: 519/655, Loss: 2.207710, Accuracy: 18.45%\n",
            "Epoch: 13, Step: 520/655, Loss: 2.207728, Accuracy: 18.43%\n",
            "Epoch: 13, Step: 521/655, Loss: 2.207855, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 522/655, Loss: 2.207955, Accuracy: 18.41%\n",
            "Epoch: 13, Step: 523/655, Loss: 2.208134, Accuracy: 18.38%\n",
            "Epoch: 13, Step: 524/655, Loss: 2.208246, Accuracy: 18.36%\n",
            "Epoch: 13, Step: 525/655, Loss: 2.208238, Accuracy: 18.34%\n",
            "Epoch: 13, Step: 526/655, Loss: 2.208247, Accuracy: 18.35%\n",
            "Epoch: 13, Step: 527/655, Loss: 2.208112, Accuracy: 18.35%\n",
            "Epoch: 13, Step: 528/655, Loss: 2.207892, Accuracy: 18.37%\n",
            "Epoch: 13, Step: 529/655, Loss: 2.207890, Accuracy: 18.38%\n",
            "Epoch: 13, Step: 530/655, Loss: 2.207901, Accuracy: 18.38%\n",
            "Epoch: 13, Step: 531/655, Loss: 2.207930, Accuracy: 18.38%\n",
            "Epoch: 13, Step: 532/655, Loss: 2.207940, Accuracy: 18.39%\n",
            "Epoch: 13, Step: 533/655, Loss: 2.208011, Accuracy: 18.39%\n",
            "Epoch: 13, Step: 534/655, Loss: 2.207930, Accuracy: 18.39%\n",
            "Epoch: 13, Step: 535/655, Loss: 2.207873, Accuracy: 18.39%\n",
            "Epoch: 13, Step: 536/655, Loss: 2.207716, Accuracy: 18.38%\n",
            "Epoch: 13, Step: 537/655, Loss: 2.207701, Accuracy: 18.42%\n",
            "Epoch: 13, Step: 538/655, Loss: 2.207697, Accuracy: 18.41%\n",
            "Epoch: 13, Step: 539/655, Loss: 2.207828, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 540/655, Loss: 2.207668, Accuracy: 18.40%\n",
            "Epoch: 13, Step: 541/655, Loss: 2.207578, Accuracy: 18.41%\n",
            "Epoch: 13, Step: 542/655, Loss: 2.207361, Accuracy: 18.44%\n",
            "Epoch: 13, Step: 543/655, Loss: 2.207297, Accuracy: 18.46%\n",
            "Epoch: 13, Step: 544/655, Loss: 2.207109, Accuracy: 18.47%\n",
            "Epoch: 13, Step: 545/655, Loss: 2.206952, Accuracy: 18.48%\n",
            "Epoch: 13, Step: 546/655, Loss: 2.206970, Accuracy: 18.49%\n",
            "Epoch: 13, Step: 547/655, Loss: 2.207006, Accuracy: 18.48%\n",
            "Epoch: 13, Step: 548/655, Loss: 2.207137, Accuracy: 18.48%\n",
            "Epoch: 13, Step: 549/655, Loss: 2.206851, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 550/655, Loss: 2.207027, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 551/655, Loss: 2.207085, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 552/655, Loss: 2.207413, Accuracy: 18.48%\n",
            "Epoch: 13, Step: 553/655, Loss: 2.207204, Accuracy: 18.47%\n",
            "Epoch: 13, Step: 554/655, Loss: 2.207328, Accuracy: 18.47%\n",
            "Epoch: 13, Step: 555/655, Loss: 2.207297, Accuracy: 18.47%\n",
            "Epoch: 13, Step: 556/655, Loss: 2.207315, Accuracy: 18.49%\n",
            "Epoch: 13, Step: 557/655, Loss: 2.207288, Accuracy: 18.49%\n",
            "Epoch: 13, Step: 558/655, Loss: 2.207299, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 559/655, Loss: 2.207453, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 560/655, Loss: 2.207547, Accuracy: 18.49%\n",
            "Epoch: 13, Step: 561/655, Loss: 2.207548, Accuracy: 18.49%\n",
            "Epoch: 13, Step: 562/655, Loss: 2.207502, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 563/655, Loss: 2.207535, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 564/655, Loss: 2.207443, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 565/655, Loss: 2.207294, Accuracy: 18.53%\n",
            "Epoch: 13, Step: 566/655, Loss: 2.207195, Accuracy: 18.53%\n",
            "Epoch: 13, Step: 567/655, Loss: 2.207417, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 568/655, Loss: 2.207501, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 569/655, Loss: 2.207583, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 570/655, Loss: 2.207464, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 571/655, Loss: 2.207414, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 572/655, Loss: 2.207428, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 573/655, Loss: 2.207563, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 574/655, Loss: 2.207465, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 575/655, Loss: 2.207264, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 576/655, Loss: 2.207377, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 577/655, Loss: 2.207360, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 578/655, Loss: 2.207346, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 579/655, Loss: 2.207294, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 580/655, Loss: 2.207341, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 581/655, Loss: 2.207107, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 582/655, Loss: 2.207091, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 583/655, Loss: 2.206927, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 584/655, Loss: 2.207036, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 585/655, Loss: 2.207043, Accuracy: 18.53%\n",
            "Epoch: 13, Step: 586/655, Loss: 2.207073, Accuracy: 18.54%\n",
            "Epoch: 13, Step: 587/655, Loss: 2.206824, Accuracy: 18.56%\n",
            "Epoch: 13, Step: 588/655, Loss: 2.206846, Accuracy: 18.55%\n",
            "Epoch: 13, Step: 589/655, Loss: 2.206729, Accuracy: 18.55%\n",
            "Epoch: 13, Step: 590/655, Loss: 2.206773, Accuracy: 18.55%\n",
            "Epoch: 13, Step: 591/655, Loss: 2.206492, Accuracy: 18.58%\n",
            "Epoch: 13, Step: 592/655, Loss: 2.206577, Accuracy: 18.58%\n",
            "Epoch: 13, Step: 593/655, Loss: 2.206431, Accuracy: 18.60%\n",
            "Epoch: 13, Step: 594/655, Loss: 2.206534, Accuracy: 18.58%\n",
            "Epoch: 13, Step: 595/655, Loss: 2.206422, Accuracy: 18.58%\n",
            "Epoch: 13, Step: 596/655, Loss: 2.206538, Accuracy: 18.57%\n",
            "Epoch: 13, Step: 597/655, Loss: 2.206700, Accuracy: 18.57%\n",
            "Epoch: 13, Step: 598/655, Loss: 2.206731, Accuracy: 18.56%\n",
            "Epoch: 13, Step: 599/655, Loss: 2.206769, Accuracy: 18.55%\n",
            "Epoch: 13, Step: 600/655, Loss: 2.206941, Accuracy: 18.56%\n",
            "Epoch: 13, Step: 601/655, Loss: 2.206958, Accuracy: 18.56%\n",
            "Epoch: 13, Step: 602/655, Loss: 2.206926, Accuracy: 18.55%\n",
            "Epoch: 13, Step: 603/655, Loss: 2.206889, Accuracy: 18.55%\n",
            "Epoch: 13, Step: 604/655, Loss: 2.206766, Accuracy: 18.57%\n",
            "Epoch: 13, Step: 605/655, Loss: 2.206858, Accuracy: 18.57%\n",
            "Epoch: 13, Step: 606/655, Loss: 2.207111, Accuracy: 18.56%\n",
            "Epoch: 13, Step: 607/655, Loss: 2.206975, Accuracy: 18.57%\n",
            "Epoch: 13, Step: 608/655, Loss: 2.206954, Accuracy: 18.58%\n",
            "Epoch: 13, Step: 609/655, Loss: 2.206775, Accuracy: 18.58%\n",
            "Epoch: 13, Step: 610/655, Loss: 2.206621, Accuracy: 18.60%\n",
            "Epoch: 13, Step: 611/655, Loss: 2.206568, Accuracy: 18.60%\n",
            "Epoch: 13, Step: 612/655, Loss: 2.206591, Accuracy: 18.58%\n",
            "Epoch: 13, Step: 613/655, Loss: 2.206516, Accuracy: 18.57%\n",
            "Epoch: 13, Step: 614/655, Loss: 2.206723, Accuracy: 18.57%\n",
            "Epoch: 13, Step: 615/655, Loss: 2.206748, Accuracy: 18.56%\n",
            "Epoch: 13, Step: 616/655, Loss: 2.206764, Accuracy: 18.55%\n",
            "Epoch: 13, Step: 617/655, Loss: 2.206827, Accuracy: 18.54%\n",
            "Epoch: 13, Step: 618/655, Loss: 2.206899, Accuracy: 18.54%\n",
            "Epoch: 13, Step: 619/655, Loss: 2.206810, Accuracy: 18.53%\n",
            "Epoch: 13, Step: 620/655, Loss: 2.206900, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 621/655, Loss: 2.206946, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 622/655, Loss: 2.206816, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 623/655, Loss: 2.206979, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 624/655, Loss: 2.207020, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 625/655, Loss: 2.206905, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 626/655, Loss: 2.206980, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 627/655, Loss: 2.207138, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 628/655, Loss: 2.207171, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 629/655, Loss: 2.207121, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 630/655, Loss: 2.206987, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 631/655, Loss: 2.207160, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 632/655, Loss: 2.206888, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 633/655, Loss: 2.207071, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 634/655, Loss: 2.207092, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 635/655, Loss: 2.207199, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 636/655, Loss: 2.207217, Accuracy: 18.49%\n",
            "Epoch: 13, Step: 637/655, Loss: 2.207272, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 638/655, Loss: 2.207323, Accuracy: 18.52%\n",
            "Epoch: 13, Step: 639/655, Loss: 2.207431, Accuracy: 18.53%\n",
            "Epoch: 13, Step: 640/655, Loss: 2.207467, Accuracy: 18.53%\n",
            "Epoch: 13, Step: 641/655, Loss: 2.207432, Accuracy: 18.54%\n",
            "Epoch: 13, Step: 642/655, Loss: 2.207459, Accuracy: 18.54%\n",
            "Epoch: 13, Step: 643/655, Loss: 2.207703, Accuracy: 18.53%\n",
            "Epoch: 13, Step: 644/655, Loss: 2.207699, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 645/655, Loss: 2.207860, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 646/655, Loss: 2.208012, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 647/655, Loss: 2.207674, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 648/655, Loss: 2.207691, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 649/655, Loss: 2.207721, Accuracy: 18.53%\n",
            "Epoch: 13, Step: 650/655, Loss: 2.207816, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 651/655, Loss: 2.207675, Accuracy: 18.51%\n",
            "Epoch: 13, Step: 652/655, Loss: 2.207830, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 653/655, Loss: 2.207829, Accuracy: 18.50%\n",
            "Epoch: 13, Step: 654/655, Loss: 2.207931, Accuracy: 18.49%\n",
            "Epoch: 13, Step: 655/655, Loss: 2.207681, Accuracy: 18.50%\n",
            "Epoch: 14, Step: 1/655, Loss: 2.348266, Accuracy: 15.62%\n",
            "Epoch: 14, Step: 2/655, Loss: 2.198572, Accuracy: 25.00%\n",
            "Epoch: 14, Step: 3/655, Loss: 2.212742, Accuracy: 22.92%\n",
            "Epoch: 14, Step: 4/655, Loss: 2.207433, Accuracy: 22.66%\n",
            "Epoch: 14, Step: 5/655, Loss: 2.185143, Accuracy: 21.25%\n",
            "Epoch: 14, Step: 6/655, Loss: 2.194346, Accuracy: 20.31%\n",
            "Epoch: 14, Step: 7/655, Loss: 2.184224, Accuracy: 20.98%\n",
            "Epoch: 14, Step: 8/655, Loss: 2.187079, Accuracy: 22.27%\n",
            "Epoch: 14, Step: 9/655, Loss: 2.172671, Accuracy: 22.22%\n",
            "Epoch: 14, Step: 10/655, Loss: 2.167933, Accuracy: 22.19%\n",
            "Epoch: 14, Step: 11/655, Loss: 2.168199, Accuracy: 21.59%\n",
            "Epoch: 14, Step: 12/655, Loss: 2.170930, Accuracy: 21.61%\n",
            "Epoch: 14, Step: 13/655, Loss: 2.180434, Accuracy: 21.63%\n",
            "Epoch: 14, Step: 14/655, Loss: 2.178391, Accuracy: 20.98%\n",
            "Epoch: 14, Step: 15/655, Loss: 2.177781, Accuracy: 21.25%\n",
            "Epoch: 14, Step: 16/655, Loss: 2.171239, Accuracy: 21.68%\n",
            "Epoch: 14, Step: 17/655, Loss: 2.176889, Accuracy: 21.51%\n",
            "Epoch: 14, Step: 18/655, Loss: 2.176245, Accuracy: 21.18%\n",
            "Epoch: 14, Step: 19/655, Loss: 2.177643, Accuracy: 21.38%\n",
            "Epoch: 14, Step: 20/655, Loss: 2.178071, Accuracy: 21.25%\n",
            "Epoch: 14, Step: 21/655, Loss: 2.185345, Accuracy: 20.83%\n",
            "Epoch: 14, Step: 22/655, Loss: 2.181558, Accuracy: 21.45%\n",
            "Epoch: 14, Step: 23/655, Loss: 2.184587, Accuracy: 21.33%\n",
            "Epoch: 14, Step: 24/655, Loss: 2.184262, Accuracy: 21.61%\n",
            "Epoch: 14, Step: 25/655, Loss: 2.178880, Accuracy: 21.75%\n",
            "Epoch: 14, Step: 26/655, Loss: 2.176185, Accuracy: 21.51%\n",
            "Epoch: 14, Step: 27/655, Loss: 2.179912, Accuracy: 21.41%\n",
            "Epoch: 14, Step: 28/655, Loss: 2.180727, Accuracy: 21.65%\n",
            "Epoch: 14, Step: 29/655, Loss: 2.182951, Accuracy: 21.44%\n",
            "Epoch: 14, Step: 30/655, Loss: 2.180741, Accuracy: 21.56%\n",
            "Epoch: 14, Step: 31/655, Loss: 2.178207, Accuracy: 21.37%\n",
            "Epoch: 14, Step: 32/655, Loss: 2.181716, Accuracy: 21.19%\n",
            "Epoch: 14, Step: 33/655, Loss: 2.180852, Accuracy: 21.02%\n",
            "Epoch: 14, Step: 34/655, Loss: 2.179526, Accuracy: 20.86%\n",
            "Epoch: 14, Step: 35/655, Loss: 2.181891, Accuracy: 20.80%\n",
            "Epoch: 14, Step: 36/655, Loss: 2.180821, Accuracy: 20.57%\n",
            "Epoch: 14, Step: 37/655, Loss: 2.181447, Accuracy: 20.52%\n",
            "Epoch: 14, Step: 38/655, Loss: 2.181048, Accuracy: 20.31%\n",
            "Epoch: 14, Step: 39/655, Loss: 2.179546, Accuracy: 20.19%\n",
            "Epoch: 14, Step: 40/655, Loss: 2.184436, Accuracy: 20.00%\n",
            "Epoch: 14, Step: 41/655, Loss: 2.184134, Accuracy: 20.05%\n",
            "Epoch: 14, Step: 42/655, Loss: 2.183398, Accuracy: 20.24%\n",
            "Epoch: 14, Step: 43/655, Loss: 2.185105, Accuracy: 20.06%\n",
            "Epoch: 14, Step: 44/655, Loss: 2.185177, Accuracy: 20.31%\n",
            "Epoch: 14, Step: 45/655, Loss: 2.184694, Accuracy: 20.21%\n",
            "Epoch: 14, Step: 46/655, Loss: 2.182069, Accuracy: 20.38%\n",
            "Epoch: 14, Step: 47/655, Loss: 2.181095, Accuracy: 20.41%\n",
            "Epoch: 14, Step: 48/655, Loss: 2.179906, Accuracy: 20.31%\n",
            "Epoch: 14, Step: 49/655, Loss: 2.183117, Accuracy: 20.22%\n",
            "Epoch: 14, Step: 50/655, Loss: 2.182940, Accuracy: 20.31%\n",
            "Epoch: 14, Step: 51/655, Loss: 2.181969, Accuracy: 20.22%\n",
            "Epoch: 14, Step: 52/655, Loss: 2.182352, Accuracy: 20.13%\n",
            "Epoch: 14, Step: 53/655, Loss: 2.180428, Accuracy: 20.17%\n",
            "Epoch: 14, Step: 54/655, Loss: 2.180802, Accuracy: 20.14%\n",
            "Epoch: 14, Step: 55/655, Loss: 2.182676, Accuracy: 19.94%\n",
            "Epoch: 14, Step: 56/655, Loss: 2.185546, Accuracy: 19.87%\n",
            "Epoch: 14, Step: 57/655, Loss: 2.185405, Accuracy: 20.07%\n",
            "Epoch: 14, Step: 58/655, Loss: 2.187162, Accuracy: 19.99%\n",
            "Epoch: 14, Step: 59/655, Loss: 2.186782, Accuracy: 19.97%\n",
            "Epoch: 14, Step: 60/655, Loss: 2.186137, Accuracy: 20.16%\n",
            "Epoch: 14, Step: 61/655, Loss: 2.184878, Accuracy: 20.18%\n",
            "Epoch: 14, Step: 62/655, Loss: 2.183827, Accuracy: 20.21%\n",
            "Epoch: 14, Step: 63/655, Loss: 2.186119, Accuracy: 20.19%\n",
            "Epoch: 14, Step: 64/655, Loss: 2.186718, Accuracy: 20.17%\n",
            "Epoch: 14, Step: 65/655, Loss: 2.184180, Accuracy: 20.48%\n",
            "Epoch: 14, Step: 66/655, Loss: 2.184916, Accuracy: 20.41%\n",
            "Epoch: 14, Step: 67/655, Loss: 2.184755, Accuracy: 20.29%\n",
            "Epoch: 14, Step: 68/655, Loss: 2.185069, Accuracy: 20.27%\n",
            "Epoch: 14, Step: 69/655, Loss: 2.183595, Accuracy: 20.38%\n",
            "Epoch: 14, Step: 70/655, Loss: 2.181388, Accuracy: 20.40%\n",
            "Epoch: 14, Step: 71/655, Loss: 2.181353, Accuracy: 20.38%\n",
            "Epoch: 14, Step: 72/655, Loss: 2.180306, Accuracy: 20.49%\n",
            "Epoch: 14, Step: 73/655, Loss: 2.181599, Accuracy: 20.38%\n",
            "Epoch: 14, Step: 74/655, Loss: 2.183218, Accuracy: 20.19%\n",
            "Epoch: 14, Step: 75/655, Loss: 2.184244, Accuracy: 20.12%\n",
            "Epoch: 14, Step: 76/655, Loss: 2.182690, Accuracy: 20.27%\n",
            "Epoch: 14, Step: 77/655, Loss: 2.183359, Accuracy: 20.09%\n",
            "Epoch: 14, Step: 78/655, Loss: 2.184603, Accuracy: 20.07%\n",
            "Epoch: 14, Step: 79/655, Loss: 2.184704, Accuracy: 20.09%\n",
            "Epoch: 14, Step: 80/655, Loss: 2.184510, Accuracy: 19.92%\n",
            "Epoch: 14, Step: 81/655, Loss: 2.187129, Accuracy: 19.83%\n",
            "Epoch: 14, Step: 82/655, Loss: 2.187279, Accuracy: 19.93%\n",
            "Epoch: 14, Step: 83/655, Loss: 2.187887, Accuracy: 20.03%\n",
            "Epoch: 14, Step: 84/655, Loss: 2.188293, Accuracy: 20.01%\n",
            "Epoch: 14, Step: 85/655, Loss: 2.186697, Accuracy: 20.11%\n",
            "Epoch: 14, Step: 86/655, Loss: 2.187047, Accuracy: 20.06%\n",
            "Epoch: 14, Step: 87/655, Loss: 2.187411, Accuracy: 20.11%\n",
            "Epoch: 14, Step: 88/655, Loss: 2.187762, Accuracy: 20.03%\n",
            "Epoch: 14, Step: 89/655, Loss: 2.188186, Accuracy: 20.08%\n",
            "Epoch: 14, Step: 90/655, Loss: 2.187835, Accuracy: 20.03%\n",
            "Epoch: 14, Step: 91/655, Loss: 2.189285, Accuracy: 19.99%\n",
            "Epoch: 14, Step: 92/655, Loss: 2.189988, Accuracy: 20.04%\n",
            "Epoch: 14, Step: 93/655, Loss: 2.189148, Accuracy: 20.09%\n",
            "Epoch: 14, Step: 94/655, Loss: 2.188604, Accuracy: 20.15%\n",
            "Epoch: 14, Step: 95/655, Loss: 2.190021, Accuracy: 20.10%\n",
            "Epoch: 14, Step: 96/655, Loss: 2.190764, Accuracy: 20.08%\n",
            "Epoch: 14, Step: 97/655, Loss: 2.191316, Accuracy: 20.14%\n",
            "Epoch: 14, Step: 98/655, Loss: 2.192265, Accuracy: 20.12%\n",
            "Epoch: 14, Step: 99/655, Loss: 2.193323, Accuracy: 20.04%\n",
            "Epoch: 14, Step: 100/655, Loss: 2.192917, Accuracy: 19.97%\n",
            "Epoch: 14, Step: 101/655, Loss: 2.193139, Accuracy: 19.93%\n",
            "Epoch: 14, Step: 102/655, Loss: 2.193226, Accuracy: 19.88%\n",
            "Epoch: 14, Step: 103/655, Loss: 2.192893, Accuracy: 19.93%\n",
            "Epoch: 14, Step: 104/655, Loss: 2.194415, Accuracy: 19.83%\n",
            "Epoch: 14, Step: 105/655, Loss: 2.195454, Accuracy: 19.88%\n",
            "Epoch: 14, Step: 106/655, Loss: 2.193675, Accuracy: 19.99%\n",
            "Epoch: 14, Step: 107/655, Loss: 2.193636, Accuracy: 19.98%\n",
            "Epoch: 14, Step: 108/655, Loss: 2.193822, Accuracy: 19.91%\n",
            "Epoch: 14, Step: 109/655, Loss: 2.194405, Accuracy: 19.93%\n",
            "Epoch: 14, Step: 110/655, Loss: 2.193386, Accuracy: 20.03%\n",
            "Epoch: 14, Step: 111/655, Loss: 2.193500, Accuracy: 19.99%\n",
            "Epoch: 14, Step: 112/655, Loss: 2.193693, Accuracy: 19.98%\n",
            "Epoch: 14, Step: 113/655, Loss: 2.195108, Accuracy: 19.86%\n",
            "Epoch: 14, Step: 114/655, Loss: 2.194699, Accuracy: 19.82%\n",
            "Epoch: 14, Step: 115/655, Loss: 2.195061, Accuracy: 19.67%\n",
            "Epoch: 14, Step: 116/655, Loss: 2.195321, Accuracy: 19.64%\n",
            "Epoch: 14, Step: 117/655, Loss: 2.195785, Accuracy: 19.66%\n",
            "Epoch: 14, Step: 118/655, Loss: 2.196005, Accuracy: 19.73%\n",
            "Epoch: 14, Step: 119/655, Loss: 2.196145, Accuracy: 19.75%\n",
            "Epoch: 14, Step: 120/655, Loss: 2.197519, Accuracy: 19.64%\n",
            "Epoch: 14, Step: 121/655, Loss: 2.196628, Accuracy: 19.71%\n",
            "Epoch: 14, Step: 122/655, Loss: 2.195916, Accuracy: 19.70%\n",
            "Epoch: 14, Step: 123/655, Loss: 2.195426, Accuracy: 19.72%\n",
            "Epoch: 14, Step: 124/655, Loss: 2.195231, Accuracy: 19.68%\n",
            "Epoch: 14, Step: 125/655, Loss: 2.195423, Accuracy: 19.65%\n",
            "Epoch: 14, Step: 126/655, Loss: 2.195960, Accuracy: 19.59%\n",
            "Epoch: 14, Step: 127/655, Loss: 2.195730, Accuracy: 19.54%\n",
            "Epoch: 14, Step: 128/655, Loss: 2.195425, Accuracy: 19.60%\n",
            "Epoch: 14, Step: 129/655, Loss: 2.195384, Accuracy: 19.65%\n",
            "Epoch: 14, Step: 130/655, Loss: 2.194983, Accuracy: 19.66%\n",
            "Epoch: 14, Step: 131/655, Loss: 2.195742, Accuracy: 19.61%\n",
            "Epoch: 14, Step: 132/655, Loss: 2.195746, Accuracy: 19.70%\n",
            "Epoch: 14, Step: 133/655, Loss: 2.195159, Accuracy: 19.74%\n",
            "Epoch: 14, Step: 134/655, Loss: 2.195388, Accuracy: 19.75%\n",
            "Epoch: 14, Step: 135/655, Loss: 2.194807, Accuracy: 19.79%\n",
            "Epoch: 14, Step: 136/655, Loss: 2.195192, Accuracy: 19.76%\n",
            "Epoch: 14, Step: 137/655, Loss: 2.194821, Accuracy: 19.78%\n",
            "Epoch: 14, Step: 138/655, Loss: 2.195318, Accuracy: 19.72%\n",
            "Epoch: 14, Step: 139/655, Loss: 2.195315, Accuracy: 19.78%\n",
            "Epoch: 14, Step: 140/655, Loss: 2.194430, Accuracy: 19.80%\n",
            "Epoch: 14, Step: 141/655, Loss: 2.195042, Accuracy: 19.77%\n",
            "Epoch: 14, Step: 142/655, Loss: 2.195432, Accuracy: 19.76%\n",
            "Epoch: 14, Step: 143/655, Loss: 2.195672, Accuracy: 19.71%\n",
            "Epoch: 14, Step: 144/655, Loss: 2.195920, Accuracy: 19.68%\n",
            "Epoch: 14, Step: 145/655, Loss: 2.196405, Accuracy: 19.68%\n",
            "Epoch: 14, Step: 146/655, Loss: 2.196869, Accuracy: 19.65%\n",
            "Epoch: 14, Step: 147/655, Loss: 2.197625, Accuracy: 19.58%\n",
            "Epoch: 14, Step: 148/655, Loss: 2.197287, Accuracy: 19.59%\n",
            "Epoch: 14, Step: 149/655, Loss: 2.196686, Accuracy: 19.61%\n",
            "Epoch: 14, Step: 150/655, Loss: 2.196274, Accuracy: 19.60%\n",
            "Epoch: 14, Step: 151/655, Loss: 2.196280, Accuracy: 19.68%\n",
            "Epoch: 14, Step: 152/655, Loss: 2.195864, Accuracy: 19.72%\n",
            "Epoch: 14, Step: 153/655, Loss: 2.195381, Accuracy: 19.71%\n",
            "Epoch: 14, Step: 154/655, Loss: 2.196566, Accuracy: 19.66%\n",
            "Epoch: 14, Step: 155/655, Loss: 2.197350, Accuracy: 19.60%\n",
            "Epoch: 14, Step: 156/655, Loss: 2.197133, Accuracy: 19.63%\n",
            "Epoch: 14, Step: 157/655, Loss: 2.197370, Accuracy: 19.67%\n",
            "Epoch: 14, Step: 158/655, Loss: 2.197685, Accuracy: 19.68%\n",
            "Epoch: 14, Step: 159/655, Loss: 2.198361, Accuracy: 19.60%\n",
            "Epoch: 14, Step: 160/655, Loss: 2.198838, Accuracy: 19.53%\n",
            "Epoch: 14, Step: 161/655, Loss: 2.199443, Accuracy: 19.45%\n",
            "Epoch: 14, Step: 162/655, Loss: 2.200039, Accuracy: 19.41%\n",
            "Epoch: 14, Step: 163/655, Loss: 2.199882, Accuracy: 19.40%\n",
            "Epoch: 14, Step: 164/655, Loss: 2.199016, Accuracy: 19.44%\n",
            "Epoch: 14, Step: 165/655, Loss: 2.199417, Accuracy: 19.38%\n",
            "Epoch: 14, Step: 166/655, Loss: 2.199035, Accuracy: 19.39%\n",
            "Epoch: 14, Step: 167/655, Loss: 2.198542, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 168/655, Loss: 2.198150, Accuracy: 19.49%\n",
            "Epoch: 14, Step: 169/655, Loss: 2.197885, Accuracy: 19.51%\n",
            "Epoch: 14, Step: 170/655, Loss: 2.197775, Accuracy: 19.54%\n",
            "Epoch: 14, Step: 171/655, Loss: 2.197906, Accuracy: 19.55%\n",
            "Epoch: 14, Step: 172/655, Loss: 2.198110, Accuracy: 19.60%\n",
            "Epoch: 14, Step: 173/655, Loss: 2.198364, Accuracy: 19.60%\n",
            "Epoch: 14, Step: 174/655, Loss: 2.197992, Accuracy: 19.61%\n",
            "Epoch: 14, Step: 175/655, Loss: 2.198505, Accuracy: 19.59%\n",
            "Epoch: 14, Step: 176/655, Loss: 2.198633, Accuracy: 19.57%\n",
            "Epoch: 14, Step: 177/655, Loss: 2.199574, Accuracy: 19.47%\n",
            "Epoch: 14, Step: 178/655, Loss: 2.199179, Accuracy: 19.49%\n",
            "Epoch: 14, Step: 179/655, Loss: 2.198870, Accuracy: 19.45%\n",
            "Epoch: 14, Step: 180/655, Loss: 2.198724, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 181/655, Loss: 2.198805, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 182/655, Loss: 2.199104, Accuracy: 19.40%\n",
            "Epoch: 14, Step: 183/655, Loss: 2.198702, Accuracy: 19.43%\n",
            "Epoch: 14, Step: 184/655, Loss: 2.198124, Accuracy: 19.50%\n",
            "Epoch: 14, Step: 185/655, Loss: 2.198397, Accuracy: 19.48%\n",
            "Epoch: 14, Step: 186/655, Loss: 2.198631, Accuracy: 19.49%\n",
            "Epoch: 14, Step: 187/655, Loss: 2.198623, Accuracy: 19.54%\n",
            "Epoch: 14, Step: 188/655, Loss: 2.198676, Accuracy: 19.53%\n",
            "Epoch: 14, Step: 189/655, Loss: 2.199748, Accuracy: 19.51%\n",
            "Epoch: 14, Step: 190/655, Loss: 2.199777, Accuracy: 19.47%\n",
            "Epoch: 14, Step: 191/655, Loss: 2.199047, Accuracy: 19.50%\n",
            "Epoch: 14, Step: 192/655, Loss: 2.199187, Accuracy: 19.45%\n",
            "Epoch: 14, Step: 193/655, Loss: 2.198611, Accuracy: 19.43%\n",
            "Epoch: 14, Step: 194/655, Loss: 2.198729, Accuracy: 19.44%\n",
            "Epoch: 14, Step: 195/655, Loss: 2.199161, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 196/655, Loss: 2.199105, Accuracy: 19.50%\n",
            "Epoch: 14, Step: 197/655, Loss: 2.198478, Accuracy: 19.54%\n",
            "Epoch: 14, Step: 198/655, Loss: 2.198471, Accuracy: 19.49%\n",
            "Epoch: 14, Step: 199/655, Loss: 2.199178, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 200/655, Loss: 2.199804, Accuracy: 19.42%\n",
            "Epoch: 14, Step: 201/655, Loss: 2.198683, Accuracy: 19.43%\n",
            "Epoch: 14, Step: 202/655, Loss: 2.199027, Accuracy: 19.40%\n",
            "Epoch: 14, Step: 203/655, Loss: 2.199625, Accuracy: 19.40%\n",
            "Epoch: 14, Step: 204/655, Loss: 2.199816, Accuracy: 19.39%\n",
            "Epoch: 14, Step: 205/655, Loss: 2.199276, Accuracy: 19.44%\n",
            "Epoch: 14, Step: 206/655, Loss: 2.199361, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 207/655, Loss: 2.199962, Accuracy: 19.47%\n",
            "Epoch: 14, Step: 208/655, Loss: 2.200195, Accuracy: 19.47%\n",
            "Epoch: 14, Step: 209/655, Loss: 2.200160, Accuracy: 19.44%\n",
            "Epoch: 14, Step: 210/655, Loss: 2.199882, Accuracy: 19.45%\n",
            "Epoch: 14, Step: 211/655, Loss: 2.200003, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 212/655, Loss: 2.199692, Accuracy: 19.49%\n",
            "Epoch: 14, Step: 213/655, Loss: 2.199493, Accuracy: 19.51%\n",
            "Epoch: 14, Step: 214/655, Loss: 2.199936, Accuracy: 19.47%\n",
            "Epoch: 14, Step: 215/655, Loss: 2.199559, Accuracy: 19.52%\n",
            "Epoch: 14, Step: 216/655, Loss: 2.199233, Accuracy: 19.55%\n",
            "Epoch: 14, Step: 217/655, Loss: 2.199545, Accuracy: 19.51%\n",
            "Epoch: 14, Step: 218/655, Loss: 2.199981, Accuracy: 19.48%\n",
            "Epoch: 14, Step: 219/655, Loss: 2.201093, Accuracy: 19.41%\n",
            "Epoch: 14, Step: 220/655, Loss: 2.201066, Accuracy: 19.42%\n",
            "Epoch: 14, Step: 221/655, Loss: 2.200832, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 222/655, Loss: 2.200808, Accuracy: 19.47%\n",
            "Epoch: 14, Step: 223/655, Loss: 2.200716, Accuracy: 19.52%\n",
            "Epoch: 14, Step: 224/655, Loss: 2.200736, Accuracy: 19.52%\n",
            "Epoch: 14, Step: 225/655, Loss: 2.201370, Accuracy: 19.50%\n",
            "Epoch: 14, Step: 226/655, Loss: 2.200389, Accuracy: 19.50%\n",
            "Epoch: 14, Step: 227/655, Loss: 2.200593, Accuracy: 19.52%\n",
            "Epoch: 14, Step: 228/655, Loss: 2.201161, Accuracy: 19.50%\n",
            "Epoch: 14, Step: 229/655, Loss: 2.201211, Accuracy: 19.50%\n",
            "Epoch: 14, Step: 230/655, Loss: 2.201274, Accuracy: 19.50%\n",
            "Epoch: 14, Step: 231/655, Loss: 2.201845, Accuracy: 19.47%\n",
            "Epoch: 14, Step: 232/655, Loss: 2.201599, Accuracy: 19.45%\n",
            "Epoch: 14, Step: 233/655, Loss: 2.201685, Accuracy: 19.47%\n",
            "Epoch: 14, Step: 234/655, Loss: 2.201393, Accuracy: 19.48%\n",
            "Epoch: 14, Step: 235/655, Loss: 2.201096, Accuracy: 19.48%\n",
            "Epoch: 14, Step: 236/655, Loss: 2.201092, Accuracy: 19.45%\n",
            "Epoch: 14, Step: 237/655, Loss: 2.201181, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 238/655, Loss: 2.201204, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 239/655, Loss: 2.201011, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 240/655, Loss: 2.200825, Accuracy: 19.48%\n",
            "Epoch: 14, Step: 241/655, Loss: 2.200797, Accuracy: 19.49%\n",
            "Epoch: 14, Step: 242/655, Loss: 2.201307, Accuracy: 19.45%\n",
            "Epoch: 14, Step: 243/655, Loss: 2.200969, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 244/655, Loss: 2.201545, Accuracy: 19.40%\n",
            "Epoch: 14, Step: 245/655, Loss: 2.201401, Accuracy: 19.44%\n",
            "Epoch: 14, Step: 246/655, Loss: 2.201716, Accuracy: 19.45%\n",
            "Epoch: 14, Step: 247/655, Loss: 2.201694, Accuracy: 19.43%\n",
            "Epoch: 14, Step: 248/655, Loss: 2.201365, Accuracy: 19.44%\n",
            "Epoch: 14, Step: 249/655, Loss: 2.201327, Accuracy: 19.45%\n",
            "Epoch: 14, Step: 250/655, Loss: 2.200866, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 251/655, Loss: 2.201172, Accuracy: 19.43%\n",
            "Epoch: 14, Step: 252/655, Loss: 2.201442, Accuracy: 19.44%\n",
            "Epoch: 14, Step: 253/655, Loss: 2.201703, Accuracy: 19.43%\n",
            "Epoch: 14, Step: 254/655, Loss: 2.201810, Accuracy: 19.45%\n",
            "Epoch: 14, Step: 255/655, Loss: 2.202094, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 256/655, Loss: 2.201809, Accuracy: 19.47%\n",
            "Epoch: 14, Step: 257/655, Loss: 2.201653, Accuracy: 19.50%\n",
            "Epoch: 14, Step: 258/655, Loss: 2.202307, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 259/655, Loss: 2.202484, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 260/655, Loss: 2.202578, Accuracy: 19.44%\n",
            "Epoch: 14, Step: 261/655, Loss: 2.202564, Accuracy: 19.42%\n",
            "Epoch: 14, Step: 262/655, Loss: 2.203025, Accuracy: 19.37%\n",
            "Epoch: 14, Step: 263/655, Loss: 2.203405, Accuracy: 19.34%\n",
            "Epoch: 14, Step: 264/655, Loss: 2.203224, Accuracy: 19.37%\n",
            "Epoch: 14, Step: 265/655, Loss: 2.202799, Accuracy: 19.40%\n",
            "Epoch: 14, Step: 266/655, Loss: 2.202717, Accuracy: 19.44%\n",
            "Epoch: 14, Step: 267/655, Loss: 2.202848, Accuracy: 19.43%\n",
            "Epoch: 14, Step: 268/655, Loss: 2.202744, Accuracy: 19.44%\n",
            "Epoch: 14, Step: 269/655, Loss: 2.202844, Accuracy: 19.44%\n",
            "Epoch: 14, Step: 270/655, Loss: 2.202865, Accuracy: 19.42%\n",
            "Epoch: 14, Step: 271/655, Loss: 2.202498, Accuracy: 19.44%\n",
            "Epoch: 14, Step: 272/655, Loss: 2.201903, Accuracy: 19.49%\n",
            "Epoch: 14, Step: 273/655, Loss: 2.202052, Accuracy: 19.48%\n",
            "Epoch: 14, Step: 274/655, Loss: 2.202037, Accuracy: 19.49%\n",
            "Epoch: 14, Step: 275/655, Loss: 2.202046, Accuracy: 19.52%\n",
            "Epoch: 14, Step: 276/655, Loss: 2.202173, Accuracy: 19.53%\n",
            "Epoch: 14, Step: 277/655, Loss: 2.202076, Accuracy: 19.52%\n",
            "Epoch: 14, Step: 278/655, Loss: 2.201937, Accuracy: 19.53%\n",
            "Epoch: 14, Step: 279/655, Loss: 2.202335, Accuracy: 19.53%\n",
            "Epoch: 14, Step: 280/655, Loss: 2.202153, Accuracy: 19.55%\n",
            "Epoch: 14, Step: 281/655, Loss: 2.201992, Accuracy: 19.52%\n",
            "Epoch: 14, Step: 282/655, Loss: 2.202065, Accuracy: 19.49%\n",
            "Epoch: 14, Step: 283/655, Loss: 2.202102, Accuracy: 19.48%\n",
            "Epoch: 14, Step: 284/655, Loss: 2.202152, Accuracy: 19.47%\n",
            "Epoch: 14, Step: 285/655, Loss: 2.201901, Accuracy: 19.48%\n",
            "Epoch: 14, Step: 286/655, Loss: 2.201891, Accuracy: 19.50%\n",
            "Epoch: 14, Step: 287/655, Loss: 2.201797, Accuracy: 19.50%\n",
            "Epoch: 14, Step: 288/655, Loss: 2.201316, Accuracy: 19.52%\n",
            "Epoch: 14, Step: 289/655, Loss: 2.201078, Accuracy: 19.52%\n",
            "Epoch: 14, Step: 290/655, Loss: 2.201639, Accuracy: 19.48%\n",
            "Epoch: 14, Step: 291/655, Loss: 2.202113, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 292/655, Loss: 2.202195, Accuracy: 19.46%\n",
            "Epoch: 14, Step: 293/655, Loss: 2.202567, Accuracy: 19.44%\n",
            "Epoch: 14, Step: 294/655, Loss: 2.202565, Accuracy: 19.43%\n",
            "Epoch: 14, Step: 295/655, Loss: 2.202623, Accuracy: 19.44%\n",
            "Epoch: 14, Step: 296/655, Loss: 2.202616, Accuracy: 19.45%\n",
            "Epoch: 14, Step: 297/655, Loss: 2.202819, Accuracy: 19.41%\n",
            "Epoch: 14, Step: 298/655, Loss: 2.202717, Accuracy: 19.43%\n",
            "Epoch: 14, Step: 299/655, Loss: 2.202966, Accuracy: 19.40%\n",
            "Epoch: 14, Step: 300/655, Loss: 2.203182, Accuracy: 19.36%\n",
            "Epoch: 14, Step: 301/655, Loss: 2.203079, Accuracy: 19.35%\n",
            "Epoch: 14, Step: 302/655, Loss: 2.203111, Accuracy: 19.34%\n",
            "Epoch: 14, Step: 303/655, Loss: 2.203056, Accuracy: 19.33%\n",
            "Epoch: 14, Step: 304/655, Loss: 2.203254, Accuracy: 19.28%\n",
            "Epoch: 14, Step: 305/655, Loss: 2.202824, Accuracy: 19.30%\n",
            "Epoch: 14, Step: 306/655, Loss: 2.202609, Accuracy: 19.31%\n",
            "Epoch: 14, Step: 307/655, Loss: 2.202842, Accuracy: 19.30%\n",
            "Epoch: 14, Step: 308/655, Loss: 2.202751, Accuracy: 19.28%\n",
            "Epoch: 14, Step: 309/655, Loss: 2.203288, Accuracy: 19.26%\n",
            "Epoch: 14, Step: 310/655, Loss: 2.203034, Accuracy: 19.27%\n",
            "Epoch: 14, Step: 311/655, Loss: 2.202749, Accuracy: 19.28%\n",
            "Epoch: 14, Step: 312/655, Loss: 2.202686, Accuracy: 19.25%\n",
            "Epoch: 14, Step: 313/655, Loss: 2.202636, Accuracy: 19.28%\n",
            "Epoch: 14, Step: 314/655, Loss: 2.202363, Accuracy: 19.28%\n",
            "Epoch: 14, Step: 315/655, Loss: 2.202775, Accuracy: 19.28%\n",
            "Epoch: 14, Step: 316/655, Loss: 2.202773, Accuracy: 19.28%\n",
            "Epoch: 14, Step: 317/655, Loss: 2.202416, Accuracy: 19.30%\n",
            "Epoch: 14, Step: 318/655, Loss: 2.202692, Accuracy: 19.27%\n",
            "Epoch: 14, Step: 319/655, Loss: 2.202793, Accuracy: 19.26%\n",
            "Epoch: 14, Step: 320/655, Loss: 2.203370, Accuracy: 19.22%\n",
            "Epoch: 14, Step: 321/655, Loss: 2.203525, Accuracy: 19.20%\n",
            "Epoch: 14, Step: 322/655, Loss: 2.203666, Accuracy: 19.21%\n",
            "Epoch: 14, Step: 323/655, Loss: 2.203700, Accuracy: 19.21%\n",
            "Epoch: 14, Step: 324/655, Loss: 2.204173, Accuracy: 19.17%\n",
            "Epoch: 14, Step: 325/655, Loss: 2.204110, Accuracy: 19.17%\n",
            "Epoch: 14, Step: 326/655, Loss: 2.204347, Accuracy: 19.16%\n",
            "Epoch: 14, Step: 327/655, Loss: 2.204367, Accuracy: 19.13%\n",
            "Epoch: 14, Step: 328/655, Loss: 2.204963, Accuracy: 19.08%\n",
            "Epoch: 14, Step: 329/655, Loss: 2.205063, Accuracy: 19.09%\n",
            "Epoch: 14, Step: 330/655, Loss: 2.204926, Accuracy: 19.12%\n",
            "Epoch: 14, Step: 331/655, Loss: 2.204423, Accuracy: 19.13%\n",
            "Epoch: 14, Step: 332/655, Loss: 2.204550, Accuracy: 19.13%\n",
            "Epoch: 14, Step: 333/655, Loss: 2.204516, Accuracy: 19.12%\n",
            "Epoch: 14, Step: 334/655, Loss: 2.204832, Accuracy: 19.11%\n",
            "Epoch: 14, Step: 335/655, Loss: 2.204596, Accuracy: 19.13%\n",
            "Epoch: 14, Step: 336/655, Loss: 2.204343, Accuracy: 19.12%\n",
            "Epoch: 14, Step: 337/655, Loss: 2.203724, Accuracy: 19.16%\n",
            "Epoch: 14, Step: 338/655, Loss: 2.203495, Accuracy: 19.18%\n",
            "Epoch: 14, Step: 339/655, Loss: 2.203443, Accuracy: 19.19%\n",
            "Epoch: 14, Step: 340/655, Loss: 2.203684, Accuracy: 19.18%\n",
            "Epoch: 14, Step: 341/655, Loss: 2.203320, Accuracy: 19.18%\n",
            "Epoch: 14, Step: 342/655, Loss: 2.203198, Accuracy: 19.20%\n",
            "Epoch: 14, Step: 343/655, Loss: 2.203325, Accuracy: 19.19%\n",
            "Epoch: 14, Step: 344/655, Loss: 2.203234, Accuracy: 19.20%\n",
            "Epoch: 14, Step: 345/655, Loss: 2.203029, Accuracy: 19.20%\n",
            "Epoch: 14, Step: 346/655, Loss: 2.203142, Accuracy: 19.18%\n",
            "Epoch: 14, Step: 347/655, Loss: 2.203472, Accuracy: 19.16%\n",
            "Epoch: 14, Step: 348/655, Loss: 2.203998, Accuracy: 19.16%\n",
            "Epoch: 14, Step: 349/655, Loss: 2.203940, Accuracy: 19.16%\n",
            "Epoch: 14, Step: 350/655, Loss: 2.203808, Accuracy: 19.16%\n",
            "Epoch: 14, Step: 351/655, Loss: 2.203585, Accuracy: 19.15%\n",
            "Epoch: 14, Step: 352/655, Loss: 2.203958, Accuracy: 19.14%\n",
            "Epoch: 14, Step: 353/655, Loss: 2.204121, Accuracy: 19.10%\n",
            "Epoch: 14, Step: 354/655, Loss: 2.203843, Accuracy: 19.12%\n",
            "Epoch: 14, Step: 355/655, Loss: 2.204197, Accuracy: 19.12%\n",
            "Epoch: 14, Step: 356/655, Loss: 2.204142, Accuracy: 19.08%\n",
            "Epoch: 14, Step: 357/655, Loss: 2.203844, Accuracy: 19.07%\n",
            "Epoch: 14, Step: 358/655, Loss: 2.203872, Accuracy: 19.08%\n",
            "Epoch: 14, Step: 359/655, Loss: 2.203979, Accuracy: 19.05%\n",
            "Epoch: 14, Step: 360/655, Loss: 2.203913, Accuracy: 19.06%\n",
            "Epoch: 14, Step: 361/655, Loss: 2.203994, Accuracy: 19.08%\n",
            "Epoch: 14, Step: 362/655, Loss: 2.204306, Accuracy: 19.05%\n",
            "Epoch: 14, Step: 363/655, Loss: 2.204412, Accuracy: 19.03%\n",
            "Epoch: 14, Step: 364/655, Loss: 2.204443, Accuracy: 19.02%\n",
            "Epoch: 14, Step: 365/655, Loss: 2.204476, Accuracy: 19.00%\n",
            "Epoch: 14, Step: 366/655, Loss: 2.204593, Accuracy: 19.01%\n",
            "Epoch: 14, Step: 367/655, Loss: 2.204627, Accuracy: 19.01%\n",
            "Epoch: 14, Step: 368/655, Loss: 2.204482, Accuracy: 19.04%\n",
            "Epoch: 14, Step: 369/655, Loss: 2.204472, Accuracy: 19.05%\n",
            "Epoch: 14, Step: 370/655, Loss: 2.204137, Accuracy: 19.08%\n",
            "Epoch: 14, Step: 371/655, Loss: 2.204178, Accuracy: 19.09%\n",
            "Epoch: 14, Step: 372/655, Loss: 2.204038, Accuracy: 19.05%\n",
            "Epoch: 14, Step: 373/655, Loss: 2.203805, Accuracy: 19.09%\n",
            "Epoch: 14, Step: 374/655, Loss: 2.203721, Accuracy: 19.08%\n",
            "Epoch: 14, Step: 375/655, Loss: 2.203753, Accuracy: 19.09%\n",
            "Epoch: 14, Step: 376/655, Loss: 2.203910, Accuracy: 19.08%\n",
            "Epoch: 14, Step: 377/655, Loss: 2.203971, Accuracy: 19.07%\n",
            "Epoch: 14, Step: 378/655, Loss: 2.203755, Accuracy: 19.05%\n",
            "Epoch: 14, Step: 379/655, Loss: 2.203688, Accuracy: 19.01%\n",
            "Epoch: 14, Step: 380/655, Loss: 2.204275, Accuracy: 18.99%\n",
            "Epoch: 14, Step: 381/655, Loss: 2.203889, Accuracy: 19.00%\n",
            "Epoch: 14, Step: 382/655, Loss: 2.204319, Accuracy: 18.95%\n",
            "Epoch: 14, Step: 383/655, Loss: 2.204276, Accuracy: 18.98%\n",
            "Epoch: 14, Step: 384/655, Loss: 2.204103, Accuracy: 18.95%\n",
            "Epoch: 14, Step: 385/655, Loss: 2.204329, Accuracy: 18.93%\n",
            "Epoch: 14, Step: 386/655, Loss: 2.204357, Accuracy: 18.93%\n",
            "Epoch: 14, Step: 387/655, Loss: 2.204509, Accuracy: 18.90%\n",
            "Epoch: 14, Step: 388/655, Loss: 2.204591, Accuracy: 18.89%\n",
            "Epoch: 14, Step: 389/655, Loss: 2.204629, Accuracy: 18.92%\n",
            "Epoch: 14, Step: 390/655, Loss: 2.204644, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 391/655, Loss: 2.204840, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 392/655, Loss: 2.204706, Accuracy: 18.93%\n",
            "Epoch: 14, Step: 393/655, Loss: 2.204796, Accuracy: 18.92%\n",
            "Epoch: 14, Step: 394/655, Loss: 2.204737, Accuracy: 18.96%\n",
            "Epoch: 14, Step: 395/655, Loss: 2.204699, Accuracy: 18.96%\n",
            "Epoch: 14, Step: 396/655, Loss: 2.204619, Accuracy: 18.96%\n",
            "Epoch: 14, Step: 397/655, Loss: 2.204517, Accuracy: 18.98%\n",
            "Epoch: 14, Step: 398/655, Loss: 2.204280, Accuracy: 19.00%\n",
            "Epoch: 14, Step: 399/655, Loss: 2.204476, Accuracy: 19.02%\n",
            "Epoch: 14, Step: 400/655, Loss: 2.204589, Accuracy: 19.04%\n",
            "Epoch: 14, Step: 401/655, Loss: 2.204703, Accuracy: 19.02%\n",
            "Epoch: 14, Step: 402/655, Loss: 2.204835, Accuracy: 19.00%\n",
            "Epoch: 14, Step: 403/655, Loss: 2.204838, Accuracy: 18.98%\n",
            "Epoch: 14, Step: 404/655, Loss: 2.204661, Accuracy: 19.01%\n",
            "Epoch: 14, Step: 405/655, Loss: 2.204851, Accuracy: 18.99%\n",
            "Epoch: 14, Step: 406/655, Loss: 2.204849, Accuracy: 19.01%\n",
            "Epoch: 14, Step: 407/655, Loss: 2.204947, Accuracy: 19.00%\n",
            "Epoch: 14, Step: 408/655, Loss: 2.205185, Accuracy: 18.98%\n",
            "Epoch: 14, Step: 409/655, Loss: 2.205141, Accuracy: 18.98%\n",
            "Epoch: 14, Step: 410/655, Loss: 2.205049, Accuracy: 19.00%\n",
            "Epoch: 14, Step: 411/655, Loss: 2.204825, Accuracy: 19.00%\n",
            "Epoch: 14, Step: 412/655, Loss: 2.204686, Accuracy: 19.01%\n",
            "Epoch: 14, Step: 413/655, Loss: 2.204395, Accuracy: 19.03%\n",
            "Epoch: 14, Step: 414/655, Loss: 2.204622, Accuracy: 19.02%\n",
            "Epoch: 14, Step: 415/655, Loss: 2.204673, Accuracy: 19.01%\n",
            "Epoch: 14, Step: 416/655, Loss: 2.204874, Accuracy: 18.99%\n",
            "Epoch: 14, Step: 417/655, Loss: 2.205116, Accuracy: 18.97%\n",
            "Epoch: 14, Step: 418/655, Loss: 2.205266, Accuracy: 18.97%\n",
            "Epoch: 14, Step: 419/655, Loss: 2.205267, Accuracy: 18.98%\n",
            "Epoch: 14, Step: 420/655, Loss: 2.205340, Accuracy: 19.00%\n",
            "Epoch: 14, Step: 421/655, Loss: 2.205424, Accuracy: 18.99%\n",
            "Epoch: 14, Step: 422/655, Loss: 2.205481, Accuracy: 18.98%\n",
            "Epoch: 14, Step: 423/655, Loss: 2.205608, Accuracy: 18.97%\n",
            "Epoch: 14, Step: 424/655, Loss: 2.205609, Accuracy: 18.94%\n",
            "Epoch: 14, Step: 425/655, Loss: 2.205712, Accuracy: 18.94%\n",
            "Epoch: 14, Step: 426/655, Loss: 2.205811, Accuracy: 18.92%\n",
            "Epoch: 14, Step: 427/655, Loss: 2.205953, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 428/655, Loss: 2.206201, Accuracy: 18.90%\n",
            "Epoch: 14, Step: 429/655, Loss: 2.206034, Accuracy: 18.90%\n",
            "Epoch: 14, Step: 430/655, Loss: 2.205766, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 431/655, Loss: 2.205867, Accuracy: 18.90%\n",
            "Epoch: 14, Step: 432/655, Loss: 2.205964, Accuracy: 18.89%\n",
            "Epoch: 14, Step: 433/655, Loss: 2.205923, Accuracy: 18.92%\n",
            "Epoch: 14, Step: 434/655, Loss: 2.206007, Accuracy: 18.90%\n",
            "Epoch: 14, Step: 435/655, Loss: 2.206098, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 436/655, Loss: 2.206029, Accuracy: 18.90%\n",
            "Epoch: 14, Step: 437/655, Loss: 2.205717, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 438/655, Loss: 2.206063, Accuracy: 18.90%\n",
            "Epoch: 14, Step: 439/655, Loss: 2.206152, Accuracy: 18.90%\n",
            "Epoch: 14, Step: 440/655, Loss: 2.206466, Accuracy: 18.89%\n",
            "Epoch: 14, Step: 441/655, Loss: 2.206476, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 442/655, Loss: 2.206719, Accuracy: 18.90%\n",
            "Epoch: 14, Step: 443/655, Loss: 2.206646, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 444/655, Loss: 2.206402, Accuracy: 18.92%\n",
            "Epoch: 14, Step: 445/655, Loss: 2.206568, Accuracy: 18.93%\n",
            "Epoch: 14, Step: 446/655, Loss: 2.206827, Accuracy: 18.90%\n",
            "Epoch: 14, Step: 447/655, Loss: 2.206896, Accuracy: 18.90%\n",
            "Epoch: 14, Step: 448/655, Loss: 2.206695, Accuracy: 18.93%\n",
            "Epoch: 14, Step: 449/655, Loss: 2.206539, Accuracy: 18.94%\n",
            "Epoch: 14, Step: 450/655, Loss: 2.206366, Accuracy: 18.94%\n",
            "Epoch: 14, Step: 451/655, Loss: 2.206485, Accuracy: 18.96%\n",
            "Epoch: 14, Step: 452/655, Loss: 2.206522, Accuracy: 18.96%\n",
            "Epoch: 14, Step: 453/655, Loss: 2.206745, Accuracy: 18.96%\n",
            "Epoch: 14, Step: 454/655, Loss: 2.206709, Accuracy: 18.97%\n",
            "Epoch: 14, Step: 455/655, Loss: 2.206926, Accuracy: 18.98%\n",
            "Epoch: 14, Step: 456/655, Loss: 2.206981, Accuracy: 18.98%\n",
            "Epoch: 14, Step: 457/655, Loss: 2.207301, Accuracy: 18.98%\n",
            "Epoch: 14, Step: 458/655, Loss: 2.207366, Accuracy: 18.98%\n",
            "Epoch: 14, Step: 459/655, Loss: 2.207307, Accuracy: 18.95%\n",
            "Epoch: 14, Step: 460/655, Loss: 2.207467, Accuracy: 18.93%\n",
            "Epoch: 14, Step: 461/655, Loss: 2.207638, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 462/655, Loss: 2.207644, Accuracy: 18.93%\n",
            "Epoch: 14, Step: 463/655, Loss: 2.207320, Accuracy: 18.95%\n",
            "Epoch: 14, Step: 464/655, Loss: 2.207298, Accuracy: 18.92%\n",
            "Epoch: 14, Step: 465/655, Loss: 2.207653, Accuracy: 18.89%\n",
            "Epoch: 14, Step: 466/655, Loss: 2.207556, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 467/655, Loss: 2.207280, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 468/655, Loss: 2.207232, Accuracy: 18.92%\n",
            "Epoch: 14, Step: 469/655, Loss: 2.207046, Accuracy: 18.94%\n",
            "Epoch: 14, Step: 470/655, Loss: 2.207156, Accuracy: 18.93%\n",
            "Epoch: 14, Step: 471/655, Loss: 2.207482, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 472/655, Loss: 2.207515, Accuracy: 18.92%\n",
            "Epoch: 14, Step: 473/655, Loss: 2.207505, Accuracy: 18.93%\n",
            "Epoch: 14, Step: 474/655, Loss: 2.207617, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 475/655, Loss: 2.207804, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 476/655, Loss: 2.207714, Accuracy: 18.93%\n",
            "Epoch: 14, Step: 477/655, Loss: 2.207690, Accuracy: 18.94%\n",
            "Epoch: 14, Step: 478/655, Loss: 2.207919, Accuracy: 18.93%\n",
            "Epoch: 14, Step: 479/655, Loss: 2.207713, Accuracy: 18.93%\n",
            "Epoch: 14, Step: 480/655, Loss: 2.207578, Accuracy: 18.93%\n",
            "Epoch: 14, Step: 481/655, Loss: 2.207462, Accuracy: 18.94%\n",
            "Epoch: 14, Step: 482/655, Loss: 2.207473, Accuracy: 18.95%\n",
            "Epoch: 14, Step: 483/655, Loss: 2.207630, Accuracy: 18.94%\n",
            "Epoch: 14, Step: 484/655, Loss: 2.207578, Accuracy: 18.92%\n",
            "Epoch: 14, Step: 485/655, Loss: 2.207460, Accuracy: 18.92%\n",
            "Epoch: 14, Step: 486/655, Loss: 2.207254, Accuracy: 18.94%\n",
            "Epoch: 14, Step: 487/655, Loss: 2.207021, Accuracy: 18.93%\n",
            "Epoch: 14, Step: 488/655, Loss: 2.207001, Accuracy: 18.92%\n",
            "Epoch: 14, Step: 489/655, Loss: 2.207124, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 490/655, Loss: 2.207116, Accuracy: 18.90%\n",
            "Epoch: 14, Step: 491/655, Loss: 2.207136, Accuracy: 18.89%\n",
            "Epoch: 14, Step: 492/655, Loss: 2.207182, Accuracy: 18.88%\n",
            "Epoch: 14, Step: 493/655, Loss: 2.207349, Accuracy: 18.88%\n",
            "Epoch: 14, Step: 494/655, Loss: 2.207225, Accuracy: 18.88%\n",
            "Epoch: 14, Step: 495/655, Loss: 2.207211, Accuracy: 18.87%\n",
            "Epoch: 14, Step: 496/655, Loss: 2.207309, Accuracy: 18.86%\n",
            "Epoch: 14, Step: 497/655, Loss: 2.207259, Accuracy: 18.85%\n",
            "Epoch: 14, Step: 498/655, Loss: 2.207350, Accuracy: 18.84%\n",
            "Epoch: 14, Step: 499/655, Loss: 2.207445, Accuracy: 18.83%\n",
            "Epoch: 14, Step: 500/655, Loss: 2.207424, Accuracy: 18.83%\n",
            "Epoch: 14, Step: 501/655, Loss: 2.207923, Accuracy: 18.81%\n",
            "Epoch: 14, Step: 502/655, Loss: 2.207945, Accuracy: 18.79%\n",
            "Epoch: 14, Step: 503/655, Loss: 2.207978, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 504/655, Loss: 2.207975, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 505/655, Loss: 2.207925, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 506/655, Loss: 2.207785, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 507/655, Loss: 2.207631, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 508/655, Loss: 2.207662, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 509/655, Loss: 2.207612, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 510/655, Loss: 2.207755, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 511/655, Loss: 2.207800, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 512/655, Loss: 2.207895, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 513/655, Loss: 2.208000, Accuracy: 18.79%\n",
            "Epoch: 14, Step: 514/655, Loss: 2.208054, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 515/655, Loss: 2.208040, Accuracy: 18.79%\n",
            "Epoch: 14, Step: 516/655, Loss: 2.207891, Accuracy: 18.80%\n",
            "Epoch: 14, Step: 517/655, Loss: 2.207929, Accuracy: 18.82%\n",
            "Epoch: 14, Step: 518/655, Loss: 2.208049, Accuracy: 18.82%\n",
            "Epoch: 14, Step: 519/655, Loss: 2.208010, Accuracy: 18.82%\n",
            "Epoch: 14, Step: 520/655, Loss: 2.208097, Accuracy: 18.80%\n",
            "Epoch: 14, Step: 521/655, Loss: 2.208099, Accuracy: 18.81%\n",
            "Epoch: 14, Step: 522/655, Loss: 2.208131, Accuracy: 18.82%\n",
            "Epoch: 14, Step: 523/655, Loss: 2.208227, Accuracy: 18.82%\n",
            "Epoch: 14, Step: 524/655, Loss: 2.208250, Accuracy: 18.83%\n",
            "Epoch: 14, Step: 525/655, Loss: 2.208331, Accuracy: 18.81%\n",
            "Epoch: 14, Step: 526/655, Loss: 2.208514, Accuracy: 18.79%\n",
            "Epoch: 14, Step: 527/655, Loss: 2.208582, Accuracy: 18.80%\n",
            "Epoch: 14, Step: 528/655, Loss: 2.208516, Accuracy: 18.80%\n",
            "Epoch: 14, Step: 529/655, Loss: 2.208638, Accuracy: 18.80%\n",
            "Epoch: 14, Step: 530/655, Loss: 2.208890, Accuracy: 18.79%\n",
            "Epoch: 14, Step: 531/655, Loss: 2.208757, Accuracy: 18.80%\n",
            "Epoch: 14, Step: 532/655, Loss: 2.208711, Accuracy: 18.80%\n",
            "Epoch: 14, Step: 533/655, Loss: 2.208870, Accuracy: 18.80%\n",
            "Epoch: 14, Step: 534/655, Loss: 2.208930, Accuracy: 18.79%\n",
            "Epoch: 14, Step: 535/655, Loss: 2.209033, Accuracy: 18.79%\n",
            "Epoch: 14, Step: 536/655, Loss: 2.208956, Accuracy: 18.79%\n",
            "Epoch: 14, Step: 537/655, Loss: 2.209046, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 538/655, Loss: 2.208944, Accuracy: 18.79%\n",
            "Epoch: 14, Step: 539/655, Loss: 2.208810, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 540/655, Loss: 2.208591, Accuracy: 18.79%\n",
            "Epoch: 14, Step: 541/655, Loss: 2.208766, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 542/655, Loss: 2.208879, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 543/655, Loss: 2.209023, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 544/655, Loss: 2.209016, Accuracy: 18.79%\n",
            "Epoch: 14, Step: 545/655, Loss: 2.209167, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 546/655, Loss: 2.209293, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 547/655, Loss: 2.209132, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 548/655, Loss: 2.209086, Accuracy: 18.74%\n",
            "Epoch: 14, Step: 549/655, Loss: 2.209181, Accuracy: 18.73%\n",
            "Epoch: 14, Step: 550/655, Loss: 2.209054, Accuracy: 18.74%\n",
            "Epoch: 14, Step: 551/655, Loss: 2.209067, Accuracy: 18.74%\n",
            "Epoch: 14, Step: 552/655, Loss: 2.209103, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 553/655, Loss: 2.209225, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 554/655, Loss: 2.209160, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 555/655, Loss: 2.209276, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 556/655, Loss: 2.209106, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 557/655, Loss: 2.209268, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 558/655, Loss: 2.209360, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 559/655, Loss: 2.209348, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 560/655, Loss: 2.209268, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 561/655, Loss: 2.209250, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 562/655, Loss: 2.209164, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 563/655, Loss: 2.208946, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 564/655, Loss: 2.208991, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 565/655, Loss: 2.209010, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 566/655, Loss: 2.209089, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 567/655, Loss: 2.209176, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 568/655, Loss: 2.209282, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 569/655, Loss: 2.209284, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 570/655, Loss: 2.209191, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 571/655, Loss: 2.209079, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 572/655, Loss: 2.209051, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 573/655, Loss: 2.209175, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 574/655, Loss: 2.209160, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 575/655, Loss: 2.209136, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 576/655, Loss: 2.209246, Accuracy: 18.74%\n",
            "Epoch: 14, Step: 577/655, Loss: 2.209263, Accuracy: 18.74%\n",
            "Epoch: 14, Step: 578/655, Loss: 2.209152, Accuracy: 18.75%\n",
            "Epoch: 14, Step: 579/655, Loss: 2.209390, Accuracy: 18.73%\n",
            "Epoch: 14, Step: 580/655, Loss: 2.209236, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 581/655, Loss: 2.209186, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 582/655, Loss: 2.209187, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 583/655, Loss: 2.209414, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 584/655, Loss: 2.209429, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 585/655, Loss: 2.209197, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 586/655, Loss: 2.209283, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 587/655, Loss: 2.209244, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 588/655, Loss: 2.209424, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 589/655, Loss: 2.209326, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 590/655, Loss: 2.209315, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 591/655, Loss: 2.208985, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 592/655, Loss: 2.208927, Accuracy: 18.75%\n",
            "Epoch: 14, Step: 593/655, Loss: 2.208945, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 594/655, Loss: 2.209133, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 595/655, Loss: 2.209173, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 596/655, Loss: 2.209366, Accuracy: 18.75%\n",
            "Epoch: 14, Step: 597/655, Loss: 2.209187, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 598/655, Loss: 2.209175, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 599/655, Loss: 2.209286, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 600/655, Loss: 2.209244, Accuracy: 18.75%\n",
            "Epoch: 14, Step: 601/655, Loss: 2.209237, Accuracy: 18.76%\n",
            "Epoch: 14, Step: 602/655, Loss: 2.209069, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 603/655, Loss: 2.208979, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 604/655, Loss: 2.209063, Accuracy: 18.79%\n",
            "Epoch: 14, Step: 605/655, Loss: 2.209138, Accuracy: 18.77%\n",
            "Epoch: 14, Step: 606/655, Loss: 2.208968, Accuracy: 18.78%\n",
            "Epoch: 14, Step: 607/655, Loss: 2.208836, Accuracy: 18.79%\n",
            "Epoch: 14, Step: 608/655, Loss: 2.208778, Accuracy: 18.79%\n",
            "Epoch: 14, Step: 609/655, Loss: 2.208623, Accuracy: 18.80%\n",
            "Epoch: 14, Step: 610/655, Loss: 2.208539, Accuracy: 18.81%\n",
            "Epoch: 14, Step: 611/655, Loss: 2.208325, Accuracy: 18.84%\n",
            "Epoch: 14, Step: 612/655, Loss: 2.208220, Accuracy: 18.85%\n",
            "Epoch: 14, Step: 613/655, Loss: 2.208102, Accuracy: 18.85%\n",
            "Epoch: 14, Step: 614/655, Loss: 2.208221, Accuracy: 18.86%\n",
            "Epoch: 14, Step: 615/655, Loss: 2.207993, Accuracy: 18.86%\n",
            "Epoch: 14, Step: 616/655, Loss: 2.207927, Accuracy: 18.87%\n",
            "Epoch: 14, Step: 617/655, Loss: 2.207894, Accuracy: 18.85%\n",
            "Epoch: 14, Step: 618/655, Loss: 2.207705, Accuracy: 18.86%\n",
            "Epoch: 14, Step: 619/655, Loss: 2.207675, Accuracy: 18.87%\n",
            "Epoch: 14, Step: 620/655, Loss: 2.207786, Accuracy: 18.87%\n",
            "Epoch: 14, Step: 621/655, Loss: 2.207574, Accuracy: 18.87%\n",
            "Epoch: 14, Step: 622/655, Loss: 2.207407, Accuracy: 18.87%\n",
            "Epoch: 14, Step: 623/655, Loss: 2.207277, Accuracy: 18.90%\n",
            "Epoch: 14, Step: 624/655, Loss: 2.207172, Accuracy: 18.90%\n",
            "Epoch: 14, Step: 625/655, Loss: 2.206978, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 626/655, Loss: 2.207073, Accuracy: 18.90%\n",
            "Epoch: 14, Step: 627/655, Loss: 2.207192, Accuracy: 18.89%\n",
            "Epoch: 14, Step: 628/655, Loss: 2.206935, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 629/655, Loss: 2.206898, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 630/655, Loss: 2.206824, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 631/655, Loss: 2.206728, Accuracy: 18.92%\n",
            "Epoch: 14, Step: 632/655, Loss: 2.206801, Accuracy: 18.91%\n",
            "Epoch: 14, Step: 633/655, Loss: 2.207158, Accuracy: 18.89%\n",
            "Epoch: 14, Step: 634/655, Loss: 2.207322, Accuracy: 18.88%\n",
            "Epoch: 14, Step: 635/655, Loss: 2.207139, Accuracy: 18.88%\n",
            "Epoch: 14, Step: 636/655, Loss: 2.207252, Accuracy: 18.86%\n",
            "Epoch: 14, Step: 637/655, Loss: 2.207447, Accuracy: 18.85%\n",
            "Epoch: 14, Step: 638/655, Loss: 2.207387, Accuracy: 18.84%\n",
            "Epoch: 14, Step: 639/655, Loss: 2.207572, Accuracy: 18.84%\n",
            "Epoch: 14, Step: 640/655, Loss: 2.207356, Accuracy: 18.84%\n",
            "Epoch: 14, Step: 641/655, Loss: 2.207436, Accuracy: 18.84%\n",
            "Epoch: 14, Step: 642/655, Loss: 2.207436, Accuracy: 18.84%\n",
            "Epoch: 14, Step: 643/655, Loss: 2.207524, Accuracy: 18.84%\n",
            "Epoch: 14, Step: 644/655, Loss: 2.207497, Accuracy: 18.85%\n",
            "Epoch: 14, Step: 645/655, Loss: 2.207356, Accuracy: 18.86%\n",
            "Epoch: 14, Step: 646/655, Loss: 2.207637, Accuracy: 18.84%\n",
            "Epoch: 14, Step: 647/655, Loss: 2.207775, Accuracy: 18.83%\n",
            "Epoch: 14, Step: 648/655, Loss: 2.207897, Accuracy: 18.82%\n",
            "Epoch: 14, Step: 649/655, Loss: 2.207726, Accuracy: 18.82%\n",
            "Epoch: 14, Step: 650/655, Loss: 2.207708, Accuracy: 18.82%\n",
            "Epoch: 14, Step: 651/655, Loss: 2.207794, Accuracy: 18.81%\n",
            "Epoch: 14, Step: 652/655, Loss: 2.207944, Accuracy: 18.81%\n",
            "Epoch: 14, Step: 653/655, Loss: 2.207875, Accuracy: 18.83%\n",
            "Epoch: 14, Step: 654/655, Loss: 2.207791, Accuracy: 18.82%\n",
            "Epoch: 14, Step: 655/655, Loss: 2.207800, Accuracy: 18.82%\n",
            "Epoch: 15, Step: 1/655, Loss: 2.171275, Accuracy: 25.00%\n",
            "Epoch: 15, Step: 2/655, Loss: 2.184408, Accuracy: 21.88%\n",
            "Epoch: 15, Step: 3/655, Loss: 2.152923, Accuracy: 25.00%\n",
            "Epoch: 15, Step: 4/655, Loss: 2.139451, Accuracy: 26.56%\n",
            "Epoch: 15, Step: 5/655, Loss: 2.170552, Accuracy: 23.75%\n",
            "Epoch: 15, Step: 6/655, Loss: 2.181012, Accuracy: 23.44%\n",
            "Epoch: 15, Step: 7/655, Loss: 2.168209, Accuracy: 22.77%\n",
            "Epoch: 15, Step: 8/655, Loss: 2.180269, Accuracy: 22.66%\n",
            "Epoch: 15, Step: 9/655, Loss: 2.190279, Accuracy: 22.22%\n",
            "Epoch: 15, Step: 10/655, Loss: 2.197488, Accuracy: 22.19%\n",
            "Epoch: 15, Step: 11/655, Loss: 2.192464, Accuracy: 21.59%\n",
            "Epoch: 15, Step: 12/655, Loss: 2.191311, Accuracy: 21.88%\n",
            "Epoch: 15, Step: 13/655, Loss: 2.193113, Accuracy: 21.63%\n",
            "Epoch: 15, Step: 14/655, Loss: 2.198106, Accuracy: 20.76%\n",
            "Epoch: 15, Step: 15/655, Loss: 2.201654, Accuracy: 20.62%\n",
            "Epoch: 15, Step: 16/655, Loss: 2.197144, Accuracy: 20.90%\n",
            "Epoch: 15, Step: 17/655, Loss: 2.187642, Accuracy: 21.32%\n",
            "Epoch: 15, Step: 18/655, Loss: 2.181145, Accuracy: 21.70%\n",
            "Epoch: 15, Step: 19/655, Loss: 2.182101, Accuracy: 21.22%\n",
            "Epoch: 15, Step: 20/655, Loss: 2.181564, Accuracy: 20.94%\n",
            "Epoch: 15, Step: 21/655, Loss: 2.184713, Accuracy: 20.83%\n",
            "Epoch: 15, Step: 22/655, Loss: 2.187078, Accuracy: 20.88%\n",
            "Epoch: 15, Step: 23/655, Loss: 2.186386, Accuracy: 20.65%\n",
            "Epoch: 15, Step: 24/655, Loss: 2.189105, Accuracy: 20.83%\n",
            "Epoch: 15, Step: 25/655, Loss: 2.189850, Accuracy: 20.88%\n",
            "Epoch: 15, Step: 26/655, Loss: 2.187784, Accuracy: 20.91%\n",
            "Epoch: 15, Step: 27/655, Loss: 2.191389, Accuracy: 20.72%\n",
            "Epoch: 15, Step: 28/655, Loss: 2.189249, Accuracy: 20.20%\n",
            "Epoch: 15, Step: 29/655, Loss: 2.187716, Accuracy: 20.37%\n",
            "Epoch: 15, Step: 30/655, Loss: 2.191340, Accuracy: 20.00%\n",
            "Epoch: 15, Step: 31/655, Loss: 2.192294, Accuracy: 19.86%\n",
            "Epoch: 15, Step: 32/655, Loss: 2.193961, Accuracy: 19.63%\n",
            "Epoch: 15, Step: 33/655, Loss: 2.197010, Accuracy: 19.60%\n",
            "Epoch: 15, Step: 34/655, Loss: 2.196988, Accuracy: 19.94%\n",
            "Epoch: 15, Step: 35/655, Loss: 2.196614, Accuracy: 20.00%\n",
            "Epoch: 15, Step: 36/655, Loss: 2.195502, Accuracy: 20.05%\n",
            "Epoch: 15, Step: 37/655, Loss: 2.196688, Accuracy: 19.76%\n",
            "Epoch: 15, Step: 38/655, Loss: 2.201913, Accuracy: 19.49%\n",
            "Epoch: 15, Step: 39/655, Loss: 2.202308, Accuracy: 19.39%\n",
            "Epoch: 15, Step: 40/655, Loss: 2.200527, Accuracy: 19.61%\n",
            "Epoch: 15, Step: 41/655, Loss: 2.198508, Accuracy: 19.59%\n",
            "Epoch: 15, Step: 42/655, Loss: 2.197536, Accuracy: 19.72%\n",
            "Epoch: 15, Step: 43/655, Loss: 2.198259, Accuracy: 19.77%\n",
            "Epoch: 15, Step: 44/655, Loss: 2.200650, Accuracy: 19.60%\n",
            "Epoch: 15, Step: 45/655, Loss: 2.199627, Accuracy: 19.38%\n",
            "Epoch: 15, Step: 46/655, Loss: 2.199727, Accuracy: 19.23%\n",
            "Epoch: 15, Step: 47/655, Loss: 2.201297, Accuracy: 19.41%\n",
            "Epoch: 15, Step: 48/655, Loss: 2.199762, Accuracy: 19.53%\n",
            "Epoch: 15, Step: 49/655, Loss: 2.199068, Accuracy: 19.52%\n",
            "Epoch: 15, Step: 50/655, Loss: 2.197720, Accuracy: 19.56%\n",
            "Epoch: 15, Step: 51/655, Loss: 2.199211, Accuracy: 19.49%\n",
            "Epoch: 15, Step: 52/655, Loss: 2.196606, Accuracy: 19.77%\n",
            "Epoch: 15, Step: 53/655, Loss: 2.195493, Accuracy: 20.05%\n",
            "Epoch: 15, Step: 54/655, Loss: 2.197658, Accuracy: 19.97%\n",
            "Epoch: 15, Step: 55/655, Loss: 2.197399, Accuracy: 19.83%\n",
            "Epoch: 15, Step: 56/655, Loss: 2.199040, Accuracy: 19.70%\n",
            "Epoch: 15, Step: 57/655, Loss: 2.199092, Accuracy: 19.79%\n",
            "Epoch: 15, Step: 58/655, Loss: 2.195163, Accuracy: 19.77%\n",
            "Epoch: 15, Step: 59/655, Loss: 2.194456, Accuracy: 19.81%\n",
            "Epoch: 15, Step: 60/655, Loss: 2.193556, Accuracy: 19.84%\n",
            "Epoch: 15, Step: 61/655, Loss: 2.194826, Accuracy: 19.72%\n",
            "Epoch: 15, Step: 62/655, Loss: 2.194764, Accuracy: 19.66%\n",
            "Epoch: 15, Step: 63/655, Loss: 2.195126, Accuracy: 19.64%\n",
            "Epoch: 15, Step: 64/655, Loss: 2.194140, Accuracy: 19.78%\n",
            "Epoch: 15, Step: 65/655, Loss: 2.195719, Accuracy: 19.66%\n",
            "Epoch: 15, Step: 66/655, Loss: 2.195338, Accuracy: 19.60%\n",
            "Epoch: 15, Step: 67/655, Loss: 2.196538, Accuracy: 19.64%\n",
            "Epoch: 15, Step: 68/655, Loss: 2.196529, Accuracy: 19.67%\n",
            "Epoch: 15, Step: 69/655, Loss: 2.195506, Accuracy: 19.75%\n",
            "Epoch: 15, Step: 70/655, Loss: 2.196319, Accuracy: 19.73%\n",
            "Epoch: 15, Step: 71/655, Loss: 2.196064, Accuracy: 19.72%\n",
            "Epoch: 15, Step: 72/655, Loss: 2.196146, Accuracy: 19.75%\n",
            "Epoch: 15, Step: 73/655, Loss: 2.194438, Accuracy: 19.95%\n",
            "Epoch: 15, Step: 74/655, Loss: 2.194697, Accuracy: 20.02%\n",
            "Epoch: 15, Step: 75/655, Loss: 2.194162, Accuracy: 19.96%\n",
            "Epoch: 15, Step: 76/655, Loss: 2.195066, Accuracy: 19.74%\n",
            "Epoch: 15, Step: 77/655, Loss: 2.195397, Accuracy: 19.76%\n",
            "Epoch: 15, Step: 78/655, Loss: 2.195604, Accuracy: 19.75%\n",
            "Epoch: 15, Step: 79/655, Loss: 2.195557, Accuracy: 19.90%\n",
            "Epoch: 15, Step: 80/655, Loss: 2.198044, Accuracy: 19.77%\n",
            "Epoch: 15, Step: 81/655, Loss: 2.198183, Accuracy: 19.79%\n",
            "Epoch: 15, Step: 82/655, Loss: 2.197902, Accuracy: 19.78%\n",
            "Epoch: 15, Step: 83/655, Loss: 2.198915, Accuracy: 19.73%\n",
            "Epoch: 15, Step: 84/655, Loss: 2.198658, Accuracy: 19.75%\n",
            "Epoch: 15, Step: 85/655, Loss: 2.200129, Accuracy: 19.63%\n",
            "Epoch: 15, Step: 86/655, Loss: 2.202504, Accuracy: 19.59%\n",
            "Epoch: 15, Step: 87/655, Loss: 2.202982, Accuracy: 19.50%\n",
            "Epoch: 15, Step: 88/655, Loss: 2.205246, Accuracy: 19.39%\n",
            "Epoch: 15, Step: 89/655, Loss: 2.205579, Accuracy: 19.38%\n",
            "Epoch: 15, Step: 90/655, Loss: 2.205084, Accuracy: 19.34%\n",
            "Epoch: 15, Step: 91/655, Loss: 2.205432, Accuracy: 19.30%\n",
            "Epoch: 15, Step: 92/655, Loss: 2.206984, Accuracy: 19.23%\n",
            "Epoch: 15, Step: 93/655, Loss: 2.205859, Accuracy: 19.42%\n",
            "Epoch: 15, Step: 94/655, Loss: 2.204324, Accuracy: 19.48%\n",
            "Epoch: 15, Step: 95/655, Loss: 2.206096, Accuracy: 19.44%\n",
            "Epoch: 15, Step: 96/655, Loss: 2.206203, Accuracy: 19.50%\n",
            "Epoch: 15, Step: 97/655, Loss: 2.207023, Accuracy: 19.46%\n",
            "Epoch: 15, Step: 98/655, Loss: 2.206999, Accuracy: 19.42%\n",
            "Epoch: 15, Step: 99/655, Loss: 2.207035, Accuracy: 19.44%\n",
            "Epoch: 15, Step: 100/655, Loss: 2.207280, Accuracy: 19.34%\n",
            "Epoch: 15, Step: 101/655, Loss: 2.206468, Accuracy: 19.40%\n",
            "Epoch: 15, Step: 102/655, Loss: 2.206896, Accuracy: 19.36%\n",
            "Epoch: 15, Step: 103/655, Loss: 2.207270, Accuracy: 19.36%\n",
            "Epoch: 15, Step: 104/655, Loss: 2.206552, Accuracy: 19.38%\n",
            "Epoch: 15, Step: 105/655, Loss: 2.204869, Accuracy: 19.43%\n",
            "Epoch: 15, Step: 106/655, Loss: 2.205309, Accuracy: 19.46%\n",
            "Epoch: 15, Step: 107/655, Loss: 2.206874, Accuracy: 19.39%\n",
            "Epoch: 15, Step: 108/655, Loss: 2.205917, Accuracy: 19.42%\n",
            "Epoch: 15, Step: 109/655, Loss: 2.205371, Accuracy: 19.44%\n",
            "Epoch: 15, Step: 110/655, Loss: 2.204814, Accuracy: 19.57%\n",
            "Epoch: 15, Step: 111/655, Loss: 2.203086, Accuracy: 19.71%\n",
            "Epoch: 15, Step: 112/655, Loss: 2.202703, Accuracy: 19.75%\n",
            "Epoch: 15, Step: 113/655, Loss: 2.202940, Accuracy: 19.63%\n",
            "Epoch: 15, Step: 114/655, Loss: 2.203447, Accuracy: 19.60%\n",
            "Epoch: 15, Step: 115/655, Loss: 2.204239, Accuracy: 19.59%\n",
            "Epoch: 15, Step: 116/655, Loss: 2.204156, Accuracy: 19.64%\n",
            "Epoch: 15, Step: 117/655, Loss: 2.203501, Accuracy: 19.60%\n",
            "Epoch: 15, Step: 118/655, Loss: 2.203200, Accuracy: 19.62%\n",
            "Epoch: 15, Step: 119/655, Loss: 2.201122, Accuracy: 19.72%\n",
            "Epoch: 15, Step: 120/655, Loss: 2.201572, Accuracy: 19.66%\n",
            "Epoch: 15, Step: 121/655, Loss: 2.201444, Accuracy: 19.63%\n",
            "Epoch: 15, Step: 122/655, Loss: 2.200852, Accuracy: 19.62%\n",
            "Epoch: 15, Step: 123/655, Loss: 2.200068, Accuracy: 19.59%\n",
            "Epoch: 15, Step: 124/655, Loss: 2.199454, Accuracy: 19.53%\n",
            "Epoch: 15, Step: 125/655, Loss: 2.199597, Accuracy: 19.48%\n",
            "Epoch: 15, Step: 126/655, Loss: 2.199550, Accuracy: 19.49%\n",
            "Epoch: 15, Step: 127/655, Loss: 2.198985, Accuracy: 19.64%\n",
            "Epoch: 15, Step: 128/655, Loss: 2.199895, Accuracy: 19.60%\n",
            "Epoch: 15, Step: 129/655, Loss: 2.200486, Accuracy: 19.55%\n",
            "Epoch: 15, Step: 130/655, Loss: 2.200426, Accuracy: 19.66%\n",
            "Epoch: 15, Step: 131/655, Loss: 2.200648, Accuracy: 19.58%\n",
            "Epoch: 15, Step: 132/655, Loss: 2.199781, Accuracy: 19.72%\n",
            "Epoch: 15, Step: 133/655, Loss: 2.200226, Accuracy: 19.71%\n",
            "Epoch: 15, Step: 134/655, Loss: 2.200507, Accuracy: 19.75%\n",
            "Epoch: 15, Step: 135/655, Loss: 2.201225, Accuracy: 19.75%\n",
            "Epoch: 15, Step: 136/655, Loss: 2.202178, Accuracy: 19.65%\n",
            "Epoch: 15, Step: 137/655, Loss: 2.201891, Accuracy: 19.66%\n",
            "Epoch: 15, Step: 138/655, Loss: 2.201021, Accuracy: 19.63%\n",
            "Epoch: 15, Step: 139/655, Loss: 2.201952, Accuracy: 19.54%\n",
            "Epoch: 15, Step: 140/655, Loss: 2.202076, Accuracy: 19.60%\n",
            "Epoch: 15, Step: 141/655, Loss: 2.202325, Accuracy: 19.61%\n",
            "Epoch: 15, Step: 142/655, Loss: 2.201760, Accuracy: 19.61%\n",
            "Epoch: 15, Step: 143/655, Loss: 2.201371, Accuracy: 19.60%\n",
            "Epoch: 15, Step: 144/655, Loss: 2.201189, Accuracy: 19.64%\n",
            "Epoch: 15, Step: 145/655, Loss: 2.201141, Accuracy: 19.59%\n",
            "Epoch: 15, Step: 146/655, Loss: 2.200823, Accuracy: 19.52%\n",
            "Epoch: 15, Step: 147/655, Loss: 2.200980, Accuracy: 19.52%\n",
            "Epoch: 15, Step: 148/655, Loss: 2.201679, Accuracy: 19.47%\n",
            "Epoch: 15, Step: 149/655, Loss: 2.201387, Accuracy: 19.42%\n",
            "Epoch: 15, Step: 150/655, Loss: 2.201990, Accuracy: 19.35%\n",
            "Epoch: 15, Step: 151/655, Loss: 2.201628, Accuracy: 19.39%\n",
            "Epoch: 15, Step: 152/655, Loss: 2.202046, Accuracy: 19.37%\n",
            "Epoch: 15, Step: 153/655, Loss: 2.201188, Accuracy: 19.40%\n",
            "Epoch: 15, Step: 154/655, Loss: 2.200483, Accuracy: 19.34%\n",
            "Epoch: 15, Step: 155/655, Loss: 2.201005, Accuracy: 19.31%\n",
            "Epoch: 15, Step: 156/655, Loss: 2.200448, Accuracy: 19.29%\n",
            "Epoch: 15, Step: 157/655, Loss: 2.200474, Accuracy: 19.21%\n",
            "Epoch: 15, Step: 158/655, Loss: 2.200633, Accuracy: 19.24%\n",
            "Epoch: 15, Step: 159/655, Loss: 2.200633, Accuracy: 19.34%\n",
            "Epoch: 15, Step: 160/655, Loss: 2.200169, Accuracy: 19.34%\n",
            "Epoch: 15, Step: 161/655, Loss: 2.199199, Accuracy: 19.37%\n",
            "Epoch: 15, Step: 162/655, Loss: 2.199304, Accuracy: 19.35%\n",
            "Epoch: 15, Step: 163/655, Loss: 2.199548, Accuracy: 19.36%\n",
            "Epoch: 15, Step: 164/655, Loss: 2.200405, Accuracy: 19.32%\n",
            "Epoch: 15, Step: 165/655, Loss: 2.201167, Accuracy: 19.24%\n",
            "Epoch: 15, Step: 166/655, Loss: 2.200937, Accuracy: 19.28%\n",
            "Epoch: 15, Step: 167/655, Loss: 2.200682, Accuracy: 19.22%\n",
            "Epoch: 15, Step: 168/655, Loss: 2.200702, Accuracy: 19.25%\n",
            "Epoch: 15, Step: 169/655, Loss: 2.201275, Accuracy: 19.27%\n",
            "Epoch: 15, Step: 170/655, Loss: 2.201136, Accuracy: 19.26%\n",
            "Epoch: 15, Step: 171/655, Loss: 2.200735, Accuracy: 19.30%\n",
            "Epoch: 15, Step: 172/655, Loss: 2.200659, Accuracy: 19.28%\n",
            "Epoch: 15, Step: 173/655, Loss: 2.201046, Accuracy: 19.26%\n",
            "Epoch: 15, Step: 174/655, Loss: 2.201226, Accuracy: 19.25%\n",
            "Epoch: 15, Step: 175/655, Loss: 2.200981, Accuracy: 19.29%\n",
            "Epoch: 15, Step: 176/655, Loss: 2.201111, Accuracy: 19.26%\n",
            "Epoch: 15, Step: 177/655, Loss: 2.200904, Accuracy: 19.31%\n",
            "Epoch: 15, Step: 178/655, Loss: 2.200849, Accuracy: 19.35%\n",
            "Epoch: 15, Step: 179/655, Loss: 2.201555, Accuracy: 19.31%\n",
            "Epoch: 15, Step: 180/655, Loss: 2.201743, Accuracy: 19.25%\n",
            "Epoch: 15, Step: 181/655, Loss: 2.201788, Accuracy: 19.23%\n",
            "Epoch: 15, Step: 182/655, Loss: 2.201470, Accuracy: 19.30%\n",
            "Epoch: 15, Step: 183/655, Loss: 2.201463, Accuracy: 19.35%\n",
            "Epoch: 15, Step: 184/655, Loss: 2.202010, Accuracy: 19.33%\n",
            "Epoch: 15, Step: 185/655, Loss: 2.202352, Accuracy: 19.34%\n",
            "Epoch: 15, Step: 186/655, Loss: 2.202711, Accuracy: 19.35%\n",
            "Epoch: 15, Step: 187/655, Loss: 2.203339, Accuracy: 19.28%\n",
            "Epoch: 15, Step: 188/655, Loss: 2.203093, Accuracy: 19.30%\n",
            "Epoch: 15, Step: 189/655, Loss: 2.202582, Accuracy: 19.26%\n",
            "Epoch: 15, Step: 190/655, Loss: 2.202422, Accuracy: 19.29%\n",
            "Epoch: 15, Step: 191/655, Loss: 2.201954, Accuracy: 19.26%\n",
            "Epoch: 15, Step: 192/655, Loss: 2.202893, Accuracy: 19.22%\n",
            "Epoch: 15, Step: 193/655, Loss: 2.202467, Accuracy: 19.25%\n",
            "Epoch: 15, Step: 194/655, Loss: 2.202608, Accuracy: 19.25%\n",
            "Epoch: 15, Step: 195/655, Loss: 2.202990, Accuracy: 19.25%\n",
            "Epoch: 15, Step: 196/655, Loss: 2.203225, Accuracy: 19.20%\n",
            "Epoch: 15, Step: 197/655, Loss: 2.203460, Accuracy: 19.19%\n",
            "Epoch: 15, Step: 198/655, Loss: 2.203688, Accuracy: 19.19%\n",
            "Epoch: 15, Step: 199/655, Loss: 2.204202, Accuracy: 19.13%\n",
            "Epoch: 15, Step: 200/655, Loss: 2.203497, Accuracy: 19.16%\n",
            "Epoch: 15, Step: 201/655, Loss: 2.203889, Accuracy: 19.15%\n",
            "Epoch: 15, Step: 202/655, Loss: 2.204102, Accuracy: 19.11%\n",
            "Epoch: 15, Step: 203/655, Loss: 2.203797, Accuracy: 19.15%\n",
            "Epoch: 15, Step: 204/655, Loss: 2.203583, Accuracy: 19.16%\n",
            "Epoch: 15, Step: 205/655, Loss: 2.204055, Accuracy: 19.12%\n",
            "Epoch: 15, Step: 206/655, Loss: 2.204383, Accuracy: 19.11%\n",
            "Epoch: 15, Step: 207/655, Loss: 2.204684, Accuracy: 19.08%\n",
            "Epoch: 15, Step: 208/655, Loss: 2.204445, Accuracy: 19.10%\n",
            "Epoch: 15, Step: 209/655, Loss: 2.204096, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 210/655, Loss: 2.203969, Accuracy: 19.14%\n",
            "Epoch: 15, Step: 211/655, Loss: 2.203904, Accuracy: 19.14%\n",
            "Epoch: 15, Step: 212/655, Loss: 2.203702, Accuracy: 19.16%\n",
            "Epoch: 15, Step: 213/655, Loss: 2.203911, Accuracy: 19.18%\n",
            "Epoch: 15, Step: 214/655, Loss: 2.204183, Accuracy: 19.20%\n",
            "Epoch: 15, Step: 215/655, Loss: 2.204130, Accuracy: 19.22%\n",
            "Epoch: 15, Step: 216/655, Loss: 2.204988, Accuracy: 19.20%\n",
            "Epoch: 15, Step: 217/655, Loss: 2.204837, Accuracy: 19.23%\n",
            "Epoch: 15, Step: 218/655, Loss: 2.204937, Accuracy: 19.19%\n",
            "Epoch: 15, Step: 219/655, Loss: 2.205433, Accuracy: 19.15%\n",
            "Epoch: 15, Step: 220/655, Loss: 2.206313, Accuracy: 19.12%\n",
            "Epoch: 15, Step: 221/655, Loss: 2.205826, Accuracy: 19.16%\n",
            "Epoch: 15, Step: 222/655, Loss: 2.205847, Accuracy: 19.14%\n",
            "Epoch: 15, Step: 223/655, Loss: 2.205260, Accuracy: 19.16%\n",
            "Epoch: 15, Step: 224/655, Loss: 2.205107, Accuracy: 19.13%\n",
            "Epoch: 15, Step: 225/655, Loss: 2.204520, Accuracy: 19.12%\n",
            "Epoch: 15, Step: 226/655, Loss: 2.204562, Accuracy: 19.14%\n",
            "Epoch: 15, Step: 227/655, Loss: 2.204810, Accuracy: 19.14%\n",
            "Epoch: 15, Step: 228/655, Loss: 2.205292, Accuracy: 19.07%\n",
            "Epoch: 15, Step: 229/655, Loss: 2.205451, Accuracy: 19.05%\n",
            "Epoch: 15, Step: 230/655, Loss: 2.205473, Accuracy: 19.02%\n",
            "Epoch: 15, Step: 231/655, Loss: 2.205686, Accuracy: 18.99%\n",
            "Epoch: 15, Step: 232/655, Loss: 2.205532, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 233/655, Loss: 2.205540, Accuracy: 18.99%\n",
            "Epoch: 15, Step: 234/655, Loss: 2.205993, Accuracy: 18.96%\n",
            "Epoch: 15, Step: 235/655, Loss: 2.206068, Accuracy: 18.95%\n",
            "Epoch: 15, Step: 236/655, Loss: 2.205670, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 237/655, Loss: 2.205377, Accuracy: 19.01%\n",
            "Epoch: 15, Step: 238/655, Loss: 2.204803, Accuracy: 19.03%\n",
            "Epoch: 15, Step: 239/655, Loss: 2.204928, Accuracy: 19.01%\n",
            "Epoch: 15, Step: 240/655, Loss: 2.204499, Accuracy: 19.01%\n",
            "Epoch: 15, Step: 241/655, Loss: 2.204497, Accuracy: 19.00%\n",
            "Epoch: 15, Step: 242/655, Loss: 2.204613, Accuracy: 19.03%\n",
            "Epoch: 15, Step: 243/655, Loss: 2.204260, Accuracy: 19.05%\n",
            "Epoch: 15, Step: 244/655, Loss: 2.204238, Accuracy: 19.06%\n",
            "Epoch: 15, Step: 245/655, Loss: 2.204214, Accuracy: 19.07%\n",
            "Epoch: 15, Step: 246/655, Loss: 2.204281, Accuracy: 19.05%\n",
            "Epoch: 15, Step: 247/655, Loss: 2.205066, Accuracy: 19.05%\n",
            "Epoch: 15, Step: 248/655, Loss: 2.204763, Accuracy: 19.05%\n",
            "Epoch: 15, Step: 249/655, Loss: 2.205176, Accuracy: 19.06%\n",
            "Epoch: 15, Step: 250/655, Loss: 2.205040, Accuracy: 19.07%\n",
            "Epoch: 15, Step: 251/655, Loss: 2.204518, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 252/655, Loss: 2.204316, Accuracy: 19.11%\n",
            "Epoch: 15, Step: 253/655, Loss: 2.204292, Accuracy: 19.08%\n",
            "Epoch: 15, Step: 254/655, Loss: 2.204691, Accuracy: 19.07%\n",
            "Epoch: 15, Step: 255/655, Loss: 2.204345, Accuracy: 19.13%\n",
            "Epoch: 15, Step: 256/655, Loss: 2.204226, Accuracy: 19.12%\n",
            "Epoch: 15, Step: 257/655, Loss: 2.204476, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 258/655, Loss: 2.203813, Accuracy: 19.14%\n",
            "Epoch: 15, Step: 259/655, Loss: 2.203790, Accuracy: 19.17%\n",
            "Epoch: 15, Step: 260/655, Loss: 2.203942, Accuracy: 19.18%\n",
            "Epoch: 15, Step: 261/655, Loss: 2.203890, Accuracy: 19.19%\n",
            "Epoch: 15, Step: 262/655, Loss: 2.204245, Accuracy: 19.20%\n",
            "Epoch: 15, Step: 263/655, Loss: 2.204203, Accuracy: 19.18%\n",
            "Epoch: 15, Step: 264/655, Loss: 2.204331, Accuracy: 19.15%\n",
            "Epoch: 15, Step: 265/655, Loss: 2.205049, Accuracy: 19.12%\n",
            "Epoch: 15, Step: 266/655, Loss: 2.205030, Accuracy: 19.15%\n",
            "Epoch: 15, Step: 267/655, Loss: 2.204992, Accuracy: 19.14%\n",
            "Epoch: 15, Step: 268/655, Loss: 2.205463, Accuracy: 19.11%\n",
            "Epoch: 15, Step: 269/655, Loss: 2.205359, Accuracy: 19.08%\n",
            "Epoch: 15, Step: 270/655, Loss: 2.205054, Accuracy: 19.12%\n",
            "Epoch: 15, Step: 271/655, Loss: 2.205293, Accuracy: 19.08%\n",
            "Epoch: 15, Step: 272/655, Loss: 2.205528, Accuracy: 19.05%\n",
            "Epoch: 15, Step: 273/655, Loss: 2.205671, Accuracy: 19.01%\n",
            "Epoch: 15, Step: 274/655, Loss: 2.205795, Accuracy: 19.01%\n",
            "Epoch: 15, Step: 275/655, Loss: 2.205635, Accuracy: 19.02%\n",
            "Epoch: 15, Step: 276/655, Loss: 2.205527, Accuracy: 19.02%\n",
            "Epoch: 15, Step: 277/655, Loss: 2.205682, Accuracy: 19.03%\n",
            "Epoch: 15, Step: 278/655, Loss: 2.205685, Accuracy: 19.03%\n",
            "Epoch: 15, Step: 279/655, Loss: 2.205953, Accuracy: 19.03%\n",
            "Epoch: 15, Step: 280/655, Loss: 2.206066, Accuracy: 19.02%\n",
            "Epoch: 15, Step: 281/655, Loss: 2.205913, Accuracy: 19.06%\n",
            "Epoch: 15, Step: 282/655, Loss: 2.205990, Accuracy: 19.08%\n",
            "Epoch: 15, Step: 283/655, Loss: 2.205647, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 284/655, Loss: 2.205894, Accuracy: 19.11%\n",
            "Epoch: 15, Step: 285/655, Loss: 2.205574, Accuracy: 19.18%\n",
            "Epoch: 15, Step: 286/655, Loss: 2.205752, Accuracy: 19.19%\n",
            "Epoch: 15, Step: 287/655, Loss: 2.206078, Accuracy: 19.13%\n",
            "Epoch: 15, Step: 288/655, Loss: 2.206085, Accuracy: 19.13%\n",
            "Epoch: 15, Step: 289/655, Loss: 2.205702, Accuracy: 19.15%\n",
            "Epoch: 15, Step: 290/655, Loss: 2.205821, Accuracy: 19.12%\n",
            "Epoch: 15, Step: 291/655, Loss: 2.205894, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 292/655, Loss: 2.205897, Accuracy: 19.10%\n",
            "Epoch: 15, Step: 293/655, Loss: 2.205688, Accuracy: 19.13%\n",
            "Epoch: 15, Step: 294/655, Loss: 2.206110, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 295/655, Loss: 2.205999, Accuracy: 19.10%\n",
            "Epoch: 15, Step: 296/655, Loss: 2.206087, Accuracy: 19.12%\n",
            "Epoch: 15, Step: 297/655, Loss: 2.205814, Accuracy: 19.16%\n",
            "Epoch: 15, Step: 298/655, Loss: 2.205513, Accuracy: 19.16%\n",
            "Epoch: 15, Step: 299/655, Loss: 2.205187, Accuracy: 19.19%\n",
            "Epoch: 15, Step: 300/655, Loss: 2.204711, Accuracy: 19.23%\n",
            "Epoch: 15, Step: 301/655, Loss: 2.204846, Accuracy: 19.22%\n",
            "Epoch: 15, Step: 302/655, Loss: 2.205253, Accuracy: 19.22%\n",
            "Epoch: 15, Step: 303/655, Loss: 2.204897, Accuracy: 19.27%\n",
            "Epoch: 15, Step: 304/655, Loss: 2.204962, Accuracy: 19.26%\n",
            "Epoch: 15, Step: 305/655, Loss: 2.205074, Accuracy: 19.24%\n",
            "Epoch: 15, Step: 306/655, Loss: 2.205314, Accuracy: 19.22%\n",
            "Epoch: 15, Step: 307/655, Loss: 2.205309, Accuracy: 19.21%\n",
            "Epoch: 15, Step: 308/655, Loss: 2.205276, Accuracy: 19.20%\n",
            "Epoch: 15, Step: 309/655, Loss: 2.205219, Accuracy: 19.21%\n",
            "Epoch: 15, Step: 310/655, Loss: 2.205506, Accuracy: 19.19%\n",
            "Epoch: 15, Step: 311/655, Loss: 2.205522, Accuracy: 19.19%\n",
            "Epoch: 15, Step: 312/655, Loss: 2.205450, Accuracy: 19.17%\n",
            "Epoch: 15, Step: 313/655, Loss: 2.205092, Accuracy: 19.20%\n",
            "Epoch: 15, Step: 314/655, Loss: 2.205252, Accuracy: 19.22%\n",
            "Epoch: 15, Step: 315/655, Loss: 2.205522, Accuracy: 19.18%\n",
            "Epoch: 15, Step: 316/655, Loss: 2.205296, Accuracy: 19.20%\n",
            "Epoch: 15, Step: 317/655, Loss: 2.205296, Accuracy: 19.20%\n",
            "Epoch: 15, Step: 318/655, Loss: 2.205438, Accuracy: 19.19%\n",
            "Epoch: 15, Step: 319/655, Loss: 2.205335, Accuracy: 19.18%\n",
            "Epoch: 15, Step: 320/655, Loss: 2.205790, Accuracy: 19.15%\n",
            "Epoch: 15, Step: 321/655, Loss: 2.205367, Accuracy: 19.18%\n",
            "Epoch: 15, Step: 322/655, Loss: 2.205373, Accuracy: 19.20%\n",
            "Epoch: 15, Step: 323/655, Loss: 2.205397, Accuracy: 19.20%\n",
            "Epoch: 15, Step: 324/655, Loss: 2.205774, Accuracy: 19.16%\n",
            "Epoch: 15, Step: 325/655, Loss: 2.205503, Accuracy: 19.17%\n",
            "Epoch: 15, Step: 326/655, Loss: 2.205469, Accuracy: 19.18%\n",
            "Epoch: 15, Step: 327/655, Loss: 2.205792, Accuracy: 19.18%\n",
            "Epoch: 15, Step: 328/655, Loss: 2.205645, Accuracy: 19.16%\n",
            "Epoch: 15, Step: 329/655, Loss: 2.205398, Accuracy: 19.16%\n",
            "Epoch: 15, Step: 330/655, Loss: 2.205300, Accuracy: 19.17%\n",
            "Epoch: 15, Step: 331/655, Loss: 2.205793, Accuracy: 19.15%\n",
            "Epoch: 15, Step: 332/655, Loss: 2.205983, Accuracy: 19.16%\n",
            "Epoch: 15, Step: 333/655, Loss: 2.206059, Accuracy: 19.15%\n",
            "Epoch: 15, Step: 334/655, Loss: 2.206263, Accuracy: 19.11%\n",
            "Epoch: 15, Step: 335/655, Loss: 2.206050, Accuracy: 19.14%\n",
            "Epoch: 15, Step: 336/655, Loss: 2.206295, Accuracy: 19.13%\n",
            "Epoch: 15, Step: 337/655, Loss: 2.206179, Accuracy: 19.13%\n",
            "Epoch: 15, Step: 338/655, Loss: 2.206190, Accuracy: 19.13%\n",
            "Epoch: 15, Step: 339/655, Loss: 2.205906, Accuracy: 19.15%\n",
            "Epoch: 15, Step: 340/655, Loss: 2.206027, Accuracy: 19.13%\n",
            "Epoch: 15, Step: 341/655, Loss: 2.206076, Accuracy: 19.13%\n",
            "Epoch: 15, Step: 342/655, Loss: 2.205840, Accuracy: 19.17%\n",
            "Epoch: 15, Step: 343/655, Loss: 2.206036, Accuracy: 19.18%\n",
            "Epoch: 15, Step: 344/655, Loss: 2.206099, Accuracy: 19.19%\n",
            "Epoch: 15, Step: 345/655, Loss: 2.206131, Accuracy: 19.18%\n",
            "Epoch: 15, Step: 346/655, Loss: 2.206081, Accuracy: 19.17%\n",
            "Epoch: 15, Step: 347/655, Loss: 2.205862, Accuracy: 19.18%\n",
            "Epoch: 15, Step: 348/655, Loss: 2.205809, Accuracy: 19.19%\n",
            "Epoch: 15, Step: 349/655, Loss: 2.206202, Accuracy: 19.15%\n",
            "Epoch: 15, Step: 350/655, Loss: 2.205759, Accuracy: 19.19%\n",
            "Epoch: 15, Step: 351/655, Loss: 2.206208, Accuracy: 19.16%\n",
            "Epoch: 15, Step: 352/655, Loss: 2.205960, Accuracy: 19.15%\n",
            "Epoch: 15, Step: 353/655, Loss: 2.205719, Accuracy: 19.16%\n",
            "Epoch: 15, Step: 354/655, Loss: 2.205891, Accuracy: 19.16%\n",
            "Epoch: 15, Step: 355/655, Loss: 2.205776, Accuracy: 19.15%\n",
            "Epoch: 15, Step: 356/655, Loss: 2.206181, Accuracy: 19.14%\n",
            "Epoch: 15, Step: 357/655, Loss: 2.206174, Accuracy: 19.14%\n",
            "Epoch: 15, Step: 358/655, Loss: 2.206287, Accuracy: 19.13%\n",
            "Epoch: 15, Step: 359/655, Loss: 2.206278, Accuracy: 19.14%\n",
            "Epoch: 15, Step: 360/655, Loss: 2.206469, Accuracy: 19.14%\n",
            "Epoch: 15, Step: 361/655, Loss: 2.206430, Accuracy: 19.11%\n",
            "Epoch: 15, Step: 362/655, Loss: 2.206627, Accuracy: 19.11%\n",
            "Epoch: 15, Step: 363/655, Loss: 2.206661, Accuracy: 19.11%\n",
            "Epoch: 15, Step: 364/655, Loss: 2.206877, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 365/655, Loss: 2.206555, Accuracy: 19.12%\n",
            "Epoch: 15, Step: 366/655, Loss: 2.206298, Accuracy: 19.13%\n",
            "Epoch: 15, Step: 367/655, Loss: 2.206265, Accuracy: 19.12%\n",
            "Epoch: 15, Step: 368/655, Loss: 2.206317, Accuracy: 19.12%\n",
            "Epoch: 15, Step: 369/655, Loss: 2.206399, Accuracy: 19.11%\n",
            "Epoch: 15, Step: 370/655, Loss: 2.206476, Accuracy: 19.10%\n",
            "Epoch: 15, Step: 371/655, Loss: 2.206757, Accuracy: 19.07%\n",
            "Epoch: 15, Step: 372/655, Loss: 2.207088, Accuracy: 19.08%\n",
            "Epoch: 15, Step: 373/655, Loss: 2.207219, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 374/655, Loss: 2.207089, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 375/655, Loss: 2.206886, Accuracy: 19.11%\n",
            "Epoch: 15, Step: 376/655, Loss: 2.207237, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 377/655, Loss: 2.207235, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 378/655, Loss: 2.207323, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 379/655, Loss: 2.207119, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 380/655, Loss: 2.206942, Accuracy: 19.12%\n",
            "Epoch: 15, Step: 381/655, Loss: 2.206794, Accuracy: 19.12%\n",
            "Epoch: 15, Step: 382/655, Loss: 2.206386, Accuracy: 19.15%\n",
            "Epoch: 15, Step: 383/655, Loss: 2.206540, Accuracy: 19.13%\n",
            "Epoch: 15, Step: 384/655, Loss: 2.206788, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 385/655, Loss: 2.206884, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 386/655, Loss: 2.206843, Accuracy: 19.07%\n",
            "Epoch: 15, Step: 387/655, Loss: 2.206669, Accuracy: 19.10%\n",
            "Epoch: 15, Step: 388/655, Loss: 2.206717, Accuracy: 19.07%\n",
            "Epoch: 15, Step: 389/655, Loss: 2.206612, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 390/655, Loss: 2.206395, Accuracy: 19.08%\n",
            "Epoch: 15, Step: 391/655, Loss: 2.206007, Accuracy: 19.11%\n",
            "Epoch: 15, Step: 392/655, Loss: 2.206135, Accuracy: 19.11%\n",
            "Epoch: 15, Step: 393/655, Loss: 2.205945, Accuracy: 19.10%\n",
            "Epoch: 15, Step: 394/655, Loss: 2.205885, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 395/655, Loss: 2.205780, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 396/655, Loss: 2.205568, Accuracy: 19.11%\n",
            "Epoch: 15, Step: 397/655, Loss: 2.205706, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 398/655, Loss: 2.205836, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 399/655, Loss: 2.206215, Accuracy: 19.06%\n",
            "Epoch: 15, Step: 400/655, Loss: 2.206175, Accuracy: 19.08%\n",
            "Epoch: 15, Step: 401/655, Loss: 2.206320, Accuracy: 19.07%\n",
            "Epoch: 15, Step: 402/655, Loss: 2.206300, Accuracy: 19.06%\n",
            "Epoch: 15, Step: 403/655, Loss: 2.206329, Accuracy: 19.06%\n",
            "Epoch: 15, Step: 404/655, Loss: 2.206189, Accuracy: 19.07%\n",
            "Epoch: 15, Step: 405/655, Loss: 2.206194, Accuracy: 19.07%\n",
            "Epoch: 15, Step: 406/655, Loss: 2.206342, Accuracy: 19.08%\n",
            "Epoch: 15, Step: 407/655, Loss: 2.206198, Accuracy: 19.07%\n",
            "Epoch: 15, Step: 408/655, Loss: 2.205825, Accuracy: 19.09%\n",
            "Epoch: 15, Step: 409/655, Loss: 2.205560, Accuracy: 19.08%\n",
            "Epoch: 15, Step: 410/655, Loss: 2.205452, Accuracy: 19.08%\n",
            "Epoch: 15, Step: 411/655, Loss: 2.205496, Accuracy: 19.10%\n",
            "Epoch: 15, Step: 412/655, Loss: 2.205768, Accuracy: 19.10%\n",
            "Epoch: 15, Step: 413/655, Loss: 2.205689, Accuracy: 19.08%\n",
            "Epoch: 15, Step: 414/655, Loss: 2.205728, Accuracy: 19.05%\n",
            "Epoch: 15, Step: 415/655, Loss: 2.205296, Accuracy: 19.06%\n",
            "Epoch: 15, Step: 416/655, Loss: 2.205587, Accuracy: 19.04%\n",
            "Epoch: 15, Step: 417/655, Loss: 2.205678, Accuracy: 19.05%\n",
            "Epoch: 15, Step: 418/655, Loss: 2.205267, Accuracy: 19.07%\n",
            "Epoch: 15, Step: 419/655, Loss: 2.205149, Accuracy: 19.08%\n",
            "Epoch: 15, Step: 420/655, Loss: 2.205144, Accuracy: 19.06%\n",
            "Epoch: 15, Step: 421/655, Loss: 2.205117, Accuracy: 19.07%\n",
            "Epoch: 15, Step: 422/655, Loss: 2.205265, Accuracy: 19.05%\n",
            "Epoch: 15, Step: 423/655, Loss: 2.205352, Accuracy: 19.06%\n",
            "Epoch: 15, Step: 424/655, Loss: 2.205385, Accuracy: 19.07%\n",
            "Epoch: 15, Step: 425/655, Loss: 2.205561, Accuracy: 19.04%\n",
            "Epoch: 15, Step: 426/655, Loss: 2.205705, Accuracy: 19.03%\n",
            "Epoch: 15, Step: 427/655, Loss: 2.205616, Accuracy: 19.04%\n",
            "Epoch: 15, Step: 428/655, Loss: 2.205624, Accuracy: 19.03%\n",
            "Epoch: 15, Step: 429/655, Loss: 2.205648, Accuracy: 19.02%\n",
            "Epoch: 15, Step: 430/655, Loss: 2.205768, Accuracy: 19.02%\n",
            "Epoch: 15, Step: 431/655, Loss: 2.205363, Accuracy: 19.07%\n",
            "Epoch: 15, Step: 432/655, Loss: 2.205583, Accuracy: 19.06%\n",
            "Epoch: 15, Step: 433/655, Loss: 2.205890, Accuracy: 19.03%\n",
            "Epoch: 15, Step: 434/655, Loss: 2.206025, Accuracy: 19.02%\n",
            "Epoch: 15, Step: 435/655, Loss: 2.205727, Accuracy: 19.03%\n",
            "Epoch: 15, Step: 436/655, Loss: 2.206071, Accuracy: 19.02%\n",
            "Epoch: 15, Step: 437/655, Loss: 2.206106, Accuracy: 19.01%\n",
            "Epoch: 15, Step: 438/655, Loss: 2.206083, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 439/655, Loss: 2.206202, Accuracy: 18.94%\n",
            "Epoch: 15, Step: 440/655, Loss: 2.206184, Accuracy: 18.91%\n",
            "Epoch: 15, Step: 441/655, Loss: 2.206411, Accuracy: 18.91%\n",
            "Epoch: 15, Step: 442/655, Loss: 2.206691, Accuracy: 18.91%\n",
            "Epoch: 15, Step: 443/655, Loss: 2.206704, Accuracy: 18.92%\n",
            "Epoch: 15, Step: 444/655, Loss: 2.206807, Accuracy: 18.90%\n",
            "Epoch: 15, Step: 445/655, Loss: 2.206570, Accuracy: 18.91%\n",
            "Epoch: 15, Step: 446/655, Loss: 2.206523, Accuracy: 18.90%\n",
            "Epoch: 15, Step: 447/655, Loss: 2.206632, Accuracy: 18.89%\n",
            "Epoch: 15, Step: 448/655, Loss: 2.206663, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 449/655, Loss: 2.206656, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 450/655, Loss: 2.206561, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 451/655, Loss: 2.206447, Accuracy: 18.90%\n",
            "Epoch: 15, Step: 452/655, Loss: 2.206321, Accuracy: 18.90%\n",
            "Epoch: 15, Step: 453/655, Loss: 2.206032, Accuracy: 18.92%\n",
            "Epoch: 15, Step: 454/655, Loss: 2.206097, Accuracy: 18.92%\n",
            "Epoch: 15, Step: 455/655, Loss: 2.205978, Accuracy: 18.94%\n",
            "Epoch: 15, Step: 456/655, Loss: 2.205802, Accuracy: 18.94%\n",
            "Epoch: 15, Step: 457/655, Loss: 2.205809, Accuracy: 18.96%\n",
            "Epoch: 15, Step: 458/655, Loss: 2.206154, Accuracy: 18.93%\n",
            "Epoch: 15, Step: 459/655, Loss: 2.206298, Accuracy: 18.94%\n",
            "Epoch: 15, Step: 460/655, Loss: 2.205998, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 461/655, Loss: 2.206089, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 462/655, Loss: 2.206291, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 463/655, Loss: 2.206396, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 464/655, Loss: 2.206170, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 465/655, Loss: 2.206354, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 466/655, Loss: 2.206475, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 467/655, Loss: 2.206233, Accuracy: 19.00%\n",
            "Epoch: 15, Step: 468/655, Loss: 2.206251, Accuracy: 19.02%\n",
            "Epoch: 15, Step: 469/655, Loss: 2.206116, Accuracy: 19.02%\n",
            "Epoch: 15, Step: 470/655, Loss: 2.206318, Accuracy: 19.02%\n",
            "Epoch: 15, Step: 471/655, Loss: 2.205953, Accuracy: 19.04%\n",
            "Epoch: 15, Step: 472/655, Loss: 2.205880, Accuracy: 19.04%\n",
            "Epoch: 15, Step: 473/655, Loss: 2.205839, Accuracy: 19.01%\n",
            "Epoch: 15, Step: 474/655, Loss: 2.205907, Accuracy: 19.00%\n",
            "Epoch: 15, Step: 475/655, Loss: 2.205945, Accuracy: 18.99%\n",
            "Epoch: 15, Step: 476/655, Loss: 2.206118, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 477/655, Loss: 2.206224, Accuracy: 18.95%\n",
            "Epoch: 15, Step: 478/655, Loss: 2.206024, Accuracy: 18.95%\n",
            "Epoch: 15, Step: 479/655, Loss: 2.205895, Accuracy: 18.95%\n",
            "Epoch: 15, Step: 480/655, Loss: 2.205805, Accuracy: 18.96%\n",
            "Epoch: 15, Step: 481/655, Loss: 2.205906, Accuracy: 18.96%\n",
            "Epoch: 15, Step: 482/655, Loss: 2.205818, Accuracy: 18.95%\n",
            "Epoch: 15, Step: 483/655, Loss: 2.205617, Accuracy: 18.96%\n",
            "Epoch: 15, Step: 484/655, Loss: 2.205651, Accuracy: 18.96%\n",
            "Epoch: 15, Step: 485/655, Loss: 2.205724, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 486/655, Loss: 2.205615, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 487/655, Loss: 2.205991, Accuracy: 18.95%\n",
            "Epoch: 15, Step: 488/655, Loss: 2.206046, Accuracy: 18.94%\n",
            "Epoch: 15, Step: 489/655, Loss: 2.205972, Accuracy: 18.94%\n",
            "Epoch: 15, Step: 490/655, Loss: 2.206202, Accuracy: 18.93%\n",
            "Epoch: 15, Step: 491/655, Loss: 2.206554, Accuracy: 18.92%\n",
            "Epoch: 15, Step: 492/655, Loss: 2.206627, Accuracy: 18.90%\n",
            "Epoch: 15, Step: 493/655, Loss: 2.206653, Accuracy: 18.89%\n",
            "Epoch: 15, Step: 494/655, Loss: 2.206728, Accuracy: 18.90%\n",
            "Epoch: 15, Step: 495/655, Loss: 2.206641, Accuracy: 18.90%\n",
            "Epoch: 15, Step: 496/655, Loss: 2.206766, Accuracy: 18.91%\n",
            "Epoch: 15, Step: 497/655, Loss: 2.206840, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 498/655, Loss: 2.206908, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 499/655, Loss: 2.207023, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 500/655, Loss: 2.207173, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 501/655, Loss: 2.207116, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 502/655, Loss: 2.207096, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 503/655, Loss: 2.206936, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 504/655, Loss: 2.206903, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 505/655, Loss: 2.206817, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 506/655, Loss: 2.206730, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 507/655, Loss: 2.206630, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 508/655, Loss: 2.206630, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 509/655, Loss: 2.206563, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 510/655, Loss: 2.206780, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 511/655, Loss: 2.206682, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 512/655, Loss: 2.206763, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 513/655, Loss: 2.206810, Accuracy: 18.85%\n",
            "Epoch: 15, Step: 514/655, Loss: 2.206856, Accuracy: 18.84%\n",
            "Epoch: 15, Step: 515/655, Loss: 2.206700, Accuracy: 18.84%\n",
            "Epoch: 15, Step: 516/655, Loss: 2.207057, Accuracy: 18.82%\n",
            "Epoch: 15, Step: 517/655, Loss: 2.207132, Accuracy: 18.81%\n",
            "Epoch: 15, Step: 518/655, Loss: 2.207349, Accuracy: 18.82%\n",
            "Epoch: 15, Step: 519/655, Loss: 2.207347, Accuracy: 18.80%\n",
            "Epoch: 15, Step: 520/655, Loss: 2.207108, Accuracy: 18.82%\n",
            "Epoch: 15, Step: 521/655, Loss: 2.207099, Accuracy: 18.82%\n",
            "Epoch: 15, Step: 522/655, Loss: 2.207061, Accuracy: 18.81%\n",
            "Epoch: 15, Step: 523/655, Loss: 2.206966, Accuracy: 18.83%\n",
            "Epoch: 15, Step: 524/655, Loss: 2.206961, Accuracy: 18.83%\n",
            "Epoch: 15, Step: 525/655, Loss: 2.206963, Accuracy: 18.83%\n",
            "Epoch: 15, Step: 526/655, Loss: 2.206971, Accuracy: 18.84%\n",
            "Epoch: 15, Step: 527/655, Loss: 2.207104, Accuracy: 18.83%\n",
            "Epoch: 15, Step: 528/655, Loss: 2.207050, Accuracy: 18.83%\n",
            "Epoch: 15, Step: 529/655, Loss: 2.207001, Accuracy: 18.84%\n",
            "Epoch: 15, Step: 530/655, Loss: 2.207237, Accuracy: 18.84%\n",
            "Epoch: 15, Step: 531/655, Loss: 2.207222, Accuracy: 18.84%\n",
            "Epoch: 15, Step: 532/655, Loss: 2.207423, Accuracy: 18.83%\n",
            "Epoch: 15, Step: 533/655, Loss: 2.207511, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 534/655, Loss: 2.207515, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 535/655, Loss: 2.207519, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 536/655, Loss: 2.207520, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 537/655, Loss: 2.207572, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 538/655, Loss: 2.207827, Accuracy: 18.85%\n",
            "Epoch: 15, Step: 539/655, Loss: 2.207792, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 540/655, Loss: 2.207937, Accuracy: 18.85%\n",
            "Epoch: 15, Step: 541/655, Loss: 2.207726, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 542/655, Loss: 2.207625, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 543/655, Loss: 2.207774, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 544/655, Loss: 2.207892, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 545/655, Loss: 2.207994, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 546/655, Loss: 2.208023, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 547/655, Loss: 2.208069, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 548/655, Loss: 2.208152, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 549/655, Loss: 2.208325, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 550/655, Loss: 2.208452, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 551/655, Loss: 2.208345, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 552/655, Loss: 2.208183, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 553/655, Loss: 2.208188, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 554/655, Loss: 2.208040, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 555/655, Loss: 2.208088, Accuracy: 18.85%\n",
            "Epoch: 15, Step: 556/655, Loss: 2.208046, Accuracy: 18.83%\n",
            "Epoch: 15, Step: 557/655, Loss: 2.208154, Accuracy: 18.83%\n",
            "Epoch: 15, Step: 558/655, Loss: 2.208185, Accuracy: 18.81%\n",
            "Epoch: 15, Step: 559/655, Loss: 2.208000, Accuracy: 18.83%\n",
            "Epoch: 15, Step: 560/655, Loss: 2.207823, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 561/655, Loss: 2.207850, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 562/655, Loss: 2.207946, Accuracy: 18.85%\n",
            "Epoch: 15, Step: 563/655, Loss: 2.207969, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 564/655, Loss: 2.208172, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 565/655, Loss: 2.208045, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 566/655, Loss: 2.208012, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 567/655, Loss: 2.207940, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 568/655, Loss: 2.207962, Accuracy: 18.85%\n",
            "Epoch: 15, Step: 569/655, Loss: 2.208111, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 570/655, Loss: 2.208101, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 571/655, Loss: 2.207907, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 572/655, Loss: 2.208020, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 573/655, Loss: 2.208157, Accuracy: 18.86%\n",
            "Epoch: 15, Step: 574/655, Loss: 2.208240, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 575/655, Loss: 2.208323, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 576/655, Loss: 2.208436, Accuracy: 18.87%\n",
            "Epoch: 15, Step: 577/655, Loss: 2.207987, Accuracy: 18.89%\n",
            "Epoch: 15, Step: 578/655, Loss: 2.207756, Accuracy: 18.90%\n",
            "Epoch: 15, Step: 579/655, Loss: 2.207906, Accuracy: 18.88%\n",
            "Epoch: 15, Step: 580/655, Loss: 2.207884, Accuracy: 18.89%\n",
            "Epoch: 15, Step: 581/655, Loss: 2.207862, Accuracy: 18.91%\n",
            "Epoch: 15, Step: 582/655, Loss: 2.207525, Accuracy: 18.94%\n",
            "Epoch: 15, Step: 583/655, Loss: 2.207734, Accuracy: 18.93%\n",
            "Epoch: 15, Step: 584/655, Loss: 2.207810, Accuracy: 18.94%\n",
            "Epoch: 15, Step: 585/655, Loss: 2.207865, Accuracy: 18.94%\n",
            "Epoch: 15, Step: 586/655, Loss: 2.207632, Accuracy: 18.96%\n",
            "Epoch: 15, Step: 587/655, Loss: 2.207846, Accuracy: 18.95%\n",
            "Epoch: 15, Step: 588/655, Loss: 2.207809, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 589/655, Loss: 2.207651, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 590/655, Loss: 2.207646, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 591/655, Loss: 2.207690, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 592/655, Loss: 2.207514, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 593/655, Loss: 2.207550, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 594/655, Loss: 2.207618, Accuracy: 18.96%\n",
            "Epoch: 15, Step: 595/655, Loss: 2.207642, Accuracy: 18.94%\n",
            "Epoch: 15, Step: 596/655, Loss: 2.207755, Accuracy: 18.93%\n",
            "Epoch: 15, Step: 597/655, Loss: 2.207652, Accuracy: 18.95%\n",
            "Epoch: 15, Step: 598/655, Loss: 2.207747, Accuracy: 18.94%\n",
            "Epoch: 15, Step: 599/655, Loss: 2.207615, Accuracy: 18.95%\n",
            "Epoch: 15, Step: 600/655, Loss: 2.207708, Accuracy: 18.95%\n",
            "Epoch: 15, Step: 601/655, Loss: 2.207515, Accuracy: 18.96%\n",
            "Epoch: 15, Step: 602/655, Loss: 2.207469, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 603/655, Loss: 2.207508, Accuracy: 18.96%\n",
            "Epoch: 15, Step: 604/655, Loss: 2.207392, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 605/655, Loss: 2.207359, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 606/655, Loss: 2.207305, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 607/655, Loss: 2.207727, Accuracy: 18.95%\n",
            "Epoch: 15, Step: 608/655, Loss: 2.207691, Accuracy: 18.96%\n",
            "Epoch: 15, Step: 609/655, Loss: 2.207886, Accuracy: 18.96%\n",
            "Epoch: 15, Step: 610/655, Loss: 2.208085, Accuracy: 18.94%\n",
            "Epoch: 15, Step: 611/655, Loss: 2.207969, Accuracy: 18.95%\n",
            "Epoch: 15, Step: 612/655, Loss: 2.207840, Accuracy: 18.95%\n",
            "Epoch: 15, Step: 613/655, Loss: 2.207931, Accuracy: 18.96%\n",
            "Epoch: 15, Step: 614/655, Loss: 2.207818, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 615/655, Loss: 2.207785, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 616/655, Loss: 2.207543, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 617/655, Loss: 2.207502, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 618/655, Loss: 2.207242, Accuracy: 19.01%\n",
            "Epoch: 15, Step: 619/655, Loss: 2.207306, Accuracy: 19.01%\n",
            "Epoch: 15, Step: 620/655, Loss: 2.207434, Accuracy: 18.99%\n",
            "Epoch: 15, Step: 621/655, Loss: 2.207478, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 622/655, Loss: 2.207451, Accuracy: 18.99%\n",
            "Epoch: 15, Step: 623/655, Loss: 2.207562, Accuracy: 19.00%\n",
            "Epoch: 15, Step: 624/655, Loss: 2.207737, Accuracy: 19.00%\n",
            "Epoch: 15, Step: 625/655, Loss: 2.207538, Accuracy: 19.01%\n",
            "Epoch: 15, Step: 626/655, Loss: 2.207773, Accuracy: 18.99%\n",
            "Epoch: 15, Step: 627/655, Loss: 2.207683, Accuracy: 18.99%\n",
            "Epoch: 15, Step: 628/655, Loss: 2.207684, Accuracy: 18.99%\n",
            "Epoch: 15, Step: 629/655, Loss: 2.207504, Accuracy: 19.00%\n",
            "Epoch: 15, Step: 630/655, Loss: 2.207581, Accuracy: 18.99%\n",
            "Epoch: 15, Step: 631/655, Loss: 2.207691, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 632/655, Loss: 2.207664, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 633/655, Loss: 2.207659, Accuracy: 18.99%\n",
            "Epoch: 15, Step: 634/655, Loss: 2.207769, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 635/655, Loss: 2.207606, Accuracy: 18.99%\n",
            "Epoch: 15, Step: 636/655, Loss: 2.207473, Accuracy: 18.99%\n",
            "Epoch: 15, Step: 637/655, Loss: 2.207624, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 638/655, Loss: 2.207814, Accuracy: 18.96%\n",
            "Epoch: 15, Step: 639/655, Loss: 2.207622, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 640/655, Loss: 2.207637, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 641/655, Loss: 2.207603, Accuracy: 18.99%\n",
            "Epoch: 15, Step: 642/655, Loss: 2.207378, Accuracy: 19.01%\n",
            "Epoch: 15, Step: 643/655, Loss: 2.207354, Accuracy: 19.00%\n",
            "Epoch: 15, Step: 644/655, Loss: 2.207244, Accuracy: 19.03%\n",
            "Epoch: 15, Step: 645/655, Loss: 2.207289, Accuracy: 19.03%\n",
            "Epoch: 15, Step: 646/655, Loss: 2.207318, Accuracy: 19.03%\n",
            "Epoch: 15, Step: 647/655, Loss: 2.207474, Accuracy: 19.03%\n",
            "Epoch: 15, Step: 648/655, Loss: 2.207495, Accuracy: 19.03%\n",
            "Epoch: 15, Step: 649/655, Loss: 2.207659, Accuracy: 19.02%\n",
            "Epoch: 15, Step: 650/655, Loss: 2.207788, Accuracy: 19.00%\n",
            "Epoch: 15, Step: 651/655, Loss: 2.207735, Accuracy: 19.00%\n",
            "Epoch: 15, Step: 652/655, Loss: 2.207803, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 653/655, Loss: 2.207931, Accuracy: 18.97%\n",
            "Epoch: 15, Step: 654/655, Loss: 2.207835, Accuracy: 18.98%\n",
            "Epoch: 15, Step: 655/655, Loss: 2.208140, Accuracy: 18.98%\n",
            "Epoch: 16, Step: 1/655, Loss: 2.244341, Accuracy: 18.75%\n",
            "Epoch: 16, Step: 2/655, Loss: 2.143894, Accuracy: 14.06%\n",
            "Epoch: 16, Step: 3/655, Loss: 2.157546, Accuracy: 15.62%\n",
            "Epoch: 16, Step: 4/655, Loss: 2.159990, Accuracy: 14.84%\n",
            "Epoch: 16, Step: 5/655, Loss: 2.167945, Accuracy: 15.00%\n",
            "Epoch: 16, Step: 6/655, Loss: 2.178938, Accuracy: 16.15%\n",
            "Epoch: 16, Step: 7/655, Loss: 2.176447, Accuracy: 16.52%\n",
            "Epoch: 16, Step: 8/655, Loss: 2.181968, Accuracy: 16.80%\n",
            "Epoch: 16, Step: 9/655, Loss: 2.173430, Accuracy: 17.36%\n",
            "Epoch: 16, Step: 10/655, Loss: 2.164778, Accuracy: 18.12%\n",
            "Epoch: 16, Step: 11/655, Loss: 2.165034, Accuracy: 18.18%\n",
            "Epoch: 16, Step: 12/655, Loss: 2.176022, Accuracy: 17.97%\n",
            "Epoch: 16, Step: 13/655, Loss: 2.181636, Accuracy: 18.03%\n",
            "Epoch: 16, Step: 14/655, Loss: 2.185730, Accuracy: 17.63%\n",
            "Epoch: 16, Step: 15/655, Loss: 2.195548, Accuracy: 17.08%\n",
            "Epoch: 16, Step: 16/655, Loss: 2.198849, Accuracy: 17.58%\n",
            "Epoch: 16, Step: 17/655, Loss: 2.203100, Accuracy: 17.28%\n",
            "Epoch: 16, Step: 18/655, Loss: 2.199061, Accuracy: 17.71%\n",
            "Epoch: 16, Step: 19/655, Loss: 2.201423, Accuracy: 17.60%\n",
            "Epoch: 16, Step: 20/655, Loss: 2.206262, Accuracy: 17.50%\n",
            "Epoch: 16, Step: 21/655, Loss: 2.207148, Accuracy: 17.71%\n",
            "Epoch: 16, Step: 22/655, Loss: 2.201082, Accuracy: 18.18%\n",
            "Epoch: 16, Step: 23/655, Loss: 2.198169, Accuracy: 18.07%\n",
            "Epoch: 16, Step: 24/655, Loss: 2.199675, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 25/655, Loss: 2.199461, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 26/655, Loss: 2.195974, Accuracy: 18.75%\n",
            "Epoch: 16, Step: 27/655, Loss: 2.198326, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 28/655, Loss: 2.201871, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 29/655, Loss: 2.201308, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 30/655, Loss: 2.203299, Accuracy: 18.33%\n",
            "Epoch: 16, Step: 31/655, Loss: 2.205953, Accuracy: 18.04%\n",
            "Epoch: 16, Step: 32/655, Loss: 2.205518, Accuracy: 18.26%\n",
            "Epoch: 16, Step: 33/655, Loss: 2.203035, Accuracy: 18.56%\n",
            "Epoch: 16, Step: 34/655, Loss: 2.204554, Accuracy: 18.57%\n",
            "Epoch: 16, Step: 35/655, Loss: 2.206140, Accuracy: 18.30%\n",
            "Epoch: 16, Step: 36/655, Loss: 2.206607, Accuracy: 18.23%\n",
            "Epoch: 16, Step: 37/655, Loss: 2.206265, Accuracy: 18.33%\n",
            "Epoch: 16, Step: 38/655, Loss: 2.206938, Accuracy: 18.17%\n",
            "Epoch: 16, Step: 39/655, Loss: 2.204105, Accuracy: 18.35%\n",
            "Epoch: 16, Step: 40/655, Loss: 2.205539, Accuracy: 18.20%\n",
            "Epoch: 16, Step: 41/655, Loss: 2.206505, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 42/655, Loss: 2.206296, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 43/655, Loss: 2.204087, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 44/655, Loss: 2.200824, Accuracy: 18.54%\n",
            "Epoch: 16, Step: 45/655, Loss: 2.202022, Accuracy: 18.33%\n",
            "Epoch: 16, Step: 46/655, Loss: 2.201986, Accuracy: 18.41%\n",
            "Epoch: 16, Step: 47/655, Loss: 2.203226, Accuracy: 18.28%\n",
            "Epoch: 16, Step: 48/655, Loss: 2.203978, Accuracy: 18.23%\n",
            "Epoch: 16, Step: 49/655, Loss: 2.204341, Accuracy: 18.30%\n",
            "Epoch: 16, Step: 50/655, Loss: 2.205073, Accuracy: 18.06%\n",
            "Epoch: 16, Step: 51/655, Loss: 2.205588, Accuracy: 17.95%\n",
            "Epoch: 16, Step: 52/655, Loss: 2.202054, Accuracy: 18.15%\n",
            "Epoch: 16, Step: 53/655, Loss: 2.201040, Accuracy: 18.10%\n",
            "Epoch: 16, Step: 54/655, Loss: 2.199197, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 55/655, Loss: 2.199010, Accuracy: 18.30%\n",
            "Epoch: 16, Step: 56/655, Loss: 2.200361, Accuracy: 18.19%\n",
            "Epoch: 16, Step: 57/655, Loss: 2.200290, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 58/655, Loss: 2.199775, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 59/655, Loss: 2.198693, Accuracy: 18.33%\n",
            "Epoch: 16, Step: 60/655, Loss: 2.199347, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 61/655, Loss: 2.201574, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 62/655, Loss: 2.198327, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 63/655, Loss: 2.200013, Accuracy: 18.35%\n",
            "Epoch: 16, Step: 64/655, Loss: 2.201028, Accuracy: 18.16%\n",
            "Epoch: 16, Step: 65/655, Loss: 2.201499, Accuracy: 18.03%\n",
            "Epoch: 16, Step: 66/655, Loss: 2.202684, Accuracy: 17.99%\n",
            "Epoch: 16, Step: 67/655, Loss: 2.203215, Accuracy: 17.82%\n",
            "Epoch: 16, Step: 68/655, Loss: 2.203967, Accuracy: 17.88%\n",
            "Epoch: 16, Step: 69/655, Loss: 2.204105, Accuracy: 17.93%\n",
            "Epoch: 16, Step: 70/655, Loss: 2.206369, Accuracy: 17.77%\n",
            "Epoch: 16, Step: 71/655, Loss: 2.203954, Accuracy: 17.74%\n",
            "Epoch: 16, Step: 72/655, Loss: 2.205188, Accuracy: 17.62%\n",
            "Epoch: 16, Step: 73/655, Loss: 2.206130, Accuracy: 17.68%\n",
            "Epoch: 16, Step: 74/655, Loss: 2.207084, Accuracy: 17.61%\n",
            "Epoch: 16, Step: 75/655, Loss: 2.206297, Accuracy: 17.62%\n",
            "Epoch: 16, Step: 76/655, Loss: 2.205447, Accuracy: 17.60%\n",
            "Epoch: 16, Step: 77/655, Loss: 2.205566, Accuracy: 17.53%\n",
            "Epoch: 16, Step: 78/655, Loss: 2.206103, Accuracy: 17.55%\n",
            "Epoch: 16, Step: 79/655, Loss: 2.206101, Accuracy: 17.60%\n",
            "Epoch: 16, Step: 80/655, Loss: 2.206640, Accuracy: 17.54%\n",
            "Epoch: 16, Step: 81/655, Loss: 2.205539, Accuracy: 17.71%\n",
            "Epoch: 16, Step: 82/655, Loss: 2.208209, Accuracy: 17.61%\n",
            "Epoch: 16, Step: 83/655, Loss: 2.207816, Accuracy: 17.58%\n",
            "Epoch: 16, Step: 84/655, Loss: 2.207410, Accuracy: 17.71%\n",
            "Epoch: 16, Step: 85/655, Loss: 2.208142, Accuracy: 17.83%\n",
            "Epoch: 16, Step: 86/655, Loss: 2.207749, Accuracy: 17.91%\n",
            "Epoch: 16, Step: 87/655, Loss: 2.207219, Accuracy: 17.96%\n",
            "Epoch: 16, Step: 88/655, Loss: 2.208786, Accuracy: 17.79%\n",
            "Epoch: 16, Step: 89/655, Loss: 2.208401, Accuracy: 17.84%\n",
            "Epoch: 16, Step: 90/655, Loss: 2.208379, Accuracy: 17.88%\n",
            "Epoch: 16, Step: 91/655, Loss: 2.207995, Accuracy: 17.96%\n",
            "Epoch: 16, Step: 92/655, Loss: 2.207505, Accuracy: 18.04%\n",
            "Epoch: 16, Step: 93/655, Loss: 2.209672, Accuracy: 17.91%\n",
            "Epoch: 16, Step: 94/655, Loss: 2.209892, Accuracy: 17.85%\n",
            "Epoch: 16, Step: 95/655, Loss: 2.210342, Accuracy: 17.96%\n",
            "Epoch: 16, Step: 96/655, Loss: 2.211430, Accuracy: 17.81%\n",
            "Epoch: 16, Step: 97/655, Loss: 2.211374, Accuracy: 17.75%\n",
            "Epoch: 16, Step: 98/655, Loss: 2.212082, Accuracy: 17.76%\n",
            "Epoch: 16, Step: 99/655, Loss: 2.211817, Accuracy: 17.80%\n",
            "Epoch: 16, Step: 100/655, Loss: 2.212005, Accuracy: 17.84%\n",
            "Epoch: 16, Step: 101/655, Loss: 2.211409, Accuracy: 17.85%\n",
            "Epoch: 16, Step: 102/655, Loss: 2.211080, Accuracy: 17.86%\n",
            "Epoch: 16, Step: 103/655, Loss: 2.210431, Accuracy: 17.90%\n",
            "Epoch: 16, Step: 104/655, Loss: 2.209814, Accuracy: 17.91%\n",
            "Epoch: 16, Step: 105/655, Loss: 2.210747, Accuracy: 17.89%\n",
            "Epoch: 16, Step: 106/655, Loss: 2.211035, Accuracy: 17.87%\n",
            "Epoch: 16, Step: 107/655, Loss: 2.210230, Accuracy: 17.87%\n",
            "Epoch: 16, Step: 108/655, Loss: 2.210662, Accuracy: 17.88%\n",
            "Epoch: 16, Step: 109/655, Loss: 2.210935, Accuracy: 17.89%\n",
            "Epoch: 16, Step: 110/655, Loss: 2.211361, Accuracy: 17.84%\n",
            "Epoch: 16, Step: 111/655, Loss: 2.210063, Accuracy: 17.91%\n",
            "Epoch: 16, Step: 112/655, Loss: 2.210667, Accuracy: 17.86%\n",
            "Epoch: 16, Step: 113/655, Loss: 2.210921, Accuracy: 17.87%\n",
            "Epoch: 16, Step: 114/655, Loss: 2.210353, Accuracy: 17.85%\n",
            "Epoch: 16, Step: 115/655, Loss: 2.211298, Accuracy: 17.69%\n",
            "Epoch: 16, Step: 116/655, Loss: 2.211252, Accuracy: 17.70%\n",
            "Epoch: 16, Step: 117/655, Loss: 2.210995, Accuracy: 17.71%\n",
            "Epoch: 16, Step: 118/655, Loss: 2.211348, Accuracy: 17.72%\n",
            "Epoch: 16, Step: 119/655, Loss: 2.211626, Accuracy: 17.70%\n",
            "Epoch: 16, Step: 120/655, Loss: 2.211023, Accuracy: 17.66%\n",
            "Epoch: 16, Step: 121/655, Loss: 2.210504, Accuracy: 17.69%\n",
            "Epoch: 16, Step: 122/655, Loss: 2.211719, Accuracy: 17.65%\n",
            "Epoch: 16, Step: 123/655, Loss: 2.211056, Accuracy: 17.78%\n",
            "Epoch: 16, Step: 124/655, Loss: 2.211783, Accuracy: 17.74%\n",
            "Epoch: 16, Step: 125/655, Loss: 2.211968, Accuracy: 17.77%\n",
            "Epoch: 16, Step: 126/655, Loss: 2.211786, Accuracy: 17.81%\n",
            "Epoch: 16, Step: 127/655, Loss: 2.212110, Accuracy: 17.74%\n",
            "Epoch: 16, Step: 128/655, Loss: 2.211422, Accuracy: 17.82%\n",
            "Epoch: 16, Step: 129/655, Loss: 2.212279, Accuracy: 17.76%\n",
            "Epoch: 16, Step: 130/655, Loss: 2.211435, Accuracy: 17.79%\n",
            "Epoch: 16, Step: 131/655, Loss: 2.211565, Accuracy: 17.84%\n",
            "Epoch: 16, Step: 132/655, Loss: 2.211866, Accuracy: 17.78%\n",
            "Epoch: 16, Step: 133/655, Loss: 2.212262, Accuracy: 17.76%\n",
            "Epoch: 16, Step: 134/655, Loss: 2.213676, Accuracy: 17.70%\n",
            "Epoch: 16, Step: 135/655, Loss: 2.214128, Accuracy: 17.73%\n",
            "Epoch: 16, Step: 136/655, Loss: 2.214721, Accuracy: 17.69%\n",
            "Epoch: 16, Step: 137/655, Loss: 2.214769, Accuracy: 17.66%\n",
            "Epoch: 16, Step: 138/655, Loss: 2.213745, Accuracy: 17.78%\n",
            "Epoch: 16, Step: 139/655, Loss: 2.214610, Accuracy: 17.69%\n",
            "Epoch: 16, Step: 140/655, Loss: 2.213992, Accuracy: 17.68%\n",
            "Epoch: 16, Step: 141/655, Loss: 2.213725, Accuracy: 17.77%\n",
            "Epoch: 16, Step: 142/655, Loss: 2.214553, Accuracy: 17.74%\n",
            "Epoch: 16, Step: 143/655, Loss: 2.214828, Accuracy: 17.74%\n",
            "Epoch: 16, Step: 144/655, Loss: 2.215317, Accuracy: 17.73%\n",
            "Epoch: 16, Step: 145/655, Loss: 2.215084, Accuracy: 17.78%\n",
            "Epoch: 16, Step: 146/655, Loss: 2.216066, Accuracy: 17.74%\n",
            "Epoch: 16, Step: 147/655, Loss: 2.215967, Accuracy: 17.90%\n",
            "Epoch: 16, Step: 148/655, Loss: 2.216130, Accuracy: 17.91%\n",
            "Epoch: 16, Step: 149/655, Loss: 2.216156, Accuracy: 17.95%\n",
            "Epoch: 16, Step: 150/655, Loss: 2.215855, Accuracy: 17.98%\n",
            "Epoch: 16, Step: 151/655, Loss: 2.215154, Accuracy: 18.07%\n",
            "Epoch: 16, Step: 152/655, Loss: 2.216269, Accuracy: 18.01%\n",
            "Epoch: 16, Step: 153/655, Loss: 2.215671, Accuracy: 18.08%\n",
            "Epoch: 16, Step: 154/655, Loss: 2.215515, Accuracy: 18.10%\n",
            "Epoch: 16, Step: 155/655, Loss: 2.215464, Accuracy: 18.08%\n",
            "Epoch: 16, Step: 156/655, Loss: 2.214760, Accuracy: 18.03%\n",
            "Epoch: 16, Step: 157/655, Loss: 2.214094, Accuracy: 18.13%\n",
            "Epoch: 16, Step: 158/655, Loss: 2.214665, Accuracy: 18.12%\n",
            "Epoch: 16, Step: 159/655, Loss: 2.214367, Accuracy: 18.22%\n",
            "Epoch: 16, Step: 160/655, Loss: 2.214407, Accuracy: 18.18%\n",
            "Epoch: 16, Step: 161/655, Loss: 2.214143, Accuracy: 18.19%\n",
            "Epoch: 16, Step: 162/655, Loss: 2.214055, Accuracy: 18.13%\n",
            "Epoch: 16, Step: 163/655, Loss: 2.214084, Accuracy: 18.12%\n",
            "Epoch: 16, Step: 164/655, Loss: 2.214144, Accuracy: 18.14%\n",
            "Epoch: 16, Step: 165/655, Loss: 2.214873, Accuracy: 18.07%\n",
            "Epoch: 16, Step: 166/655, Loss: 2.215378, Accuracy: 18.05%\n",
            "Epoch: 16, Step: 167/655, Loss: 2.215173, Accuracy: 18.13%\n",
            "Epoch: 16, Step: 168/655, Loss: 2.214839, Accuracy: 18.21%\n",
            "Epoch: 16, Step: 169/655, Loss: 2.214684, Accuracy: 18.23%\n",
            "Epoch: 16, Step: 170/655, Loss: 2.214774, Accuracy: 18.24%\n",
            "Epoch: 16, Step: 171/655, Loss: 2.214386, Accuracy: 18.29%\n",
            "Epoch: 16, Step: 172/655, Loss: 2.213432, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 173/655, Loss: 2.212784, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 174/655, Loss: 2.213005, Accuracy: 18.41%\n",
            "Epoch: 16, Step: 175/655, Loss: 2.213411, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 176/655, Loss: 2.213343, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 177/655, Loss: 2.213354, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 178/655, Loss: 2.212985, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 179/655, Loss: 2.214144, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 180/655, Loss: 2.213809, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 181/655, Loss: 2.215041, Accuracy: 18.28%\n",
            "Epoch: 16, Step: 182/655, Loss: 2.214799, Accuracy: 18.27%\n",
            "Epoch: 16, Step: 183/655, Loss: 2.214873, Accuracy: 18.24%\n",
            "Epoch: 16, Step: 184/655, Loss: 2.214504, Accuracy: 18.27%\n",
            "Epoch: 16, Step: 185/655, Loss: 2.214587, Accuracy: 18.26%\n",
            "Epoch: 16, Step: 186/655, Loss: 2.214413, Accuracy: 18.25%\n",
            "Epoch: 16, Step: 187/655, Loss: 2.214669, Accuracy: 18.30%\n",
            "Epoch: 16, Step: 188/655, Loss: 2.213931, Accuracy: 18.30%\n",
            "Epoch: 16, Step: 189/655, Loss: 2.214163, Accuracy: 18.32%\n",
            "Epoch: 16, Step: 190/655, Loss: 2.213745, Accuracy: 18.34%\n",
            "Epoch: 16, Step: 191/655, Loss: 2.214267, Accuracy: 18.31%\n",
            "Epoch: 16, Step: 192/655, Loss: 2.214859, Accuracy: 18.28%\n",
            "Epoch: 16, Step: 193/655, Loss: 2.214478, Accuracy: 18.33%\n",
            "Epoch: 16, Step: 194/655, Loss: 2.214782, Accuracy: 18.32%\n",
            "Epoch: 16, Step: 195/655, Loss: 2.215294, Accuracy: 18.32%\n",
            "Epoch: 16, Step: 196/655, Loss: 2.215553, Accuracy: 18.26%\n",
            "Epoch: 16, Step: 197/655, Loss: 2.215957, Accuracy: 18.21%\n",
            "Epoch: 16, Step: 198/655, Loss: 2.215328, Accuracy: 18.28%\n",
            "Epoch: 16, Step: 199/655, Loss: 2.215180, Accuracy: 18.22%\n",
            "Epoch: 16, Step: 200/655, Loss: 2.214966, Accuracy: 18.27%\n",
            "Epoch: 16, Step: 201/655, Loss: 2.215145, Accuracy: 18.22%\n",
            "Epoch: 16, Step: 202/655, Loss: 2.215331, Accuracy: 18.19%\n",
            "Epoch: 16, Step: 203/655, Loss: 2.215686, Accuracy: 18.20%\n",
            "Epoch: 16, Step: 204/655, Loss: 2.215837, Accuracy: 18.17%\n",
            "Epoch: 16, Step: 205/655, Loss: 2.214883, Accuracy: 18.22%\n",
            "Epoch: 16, Step: 206/655, Loss: 2.215105, Accuracy: 18.22%\n",
            "Epoch: 16, Step: 207/655, Loss: 2.215052, Accuracy: 18.21%\n",
            "Epoch: 16, Step: 208/655, Loss: 2.215814, Accuracy: 18.19%\n",
            "Epoch: 16, Step: 209/655, Loss: 2.215652, Accuracy: 18.21%\n",
            "Epoch: 16, Step: 210/655, Loss: 2.215677, Accuracy: 18.18%\n",
            "Epoch: 16, Step: 211/655, Loss: 2.216054, Accuracy: 18.16%\n",
            "Epoch: 16, Step: 212/655, Loss: 2.215522, Accuracy: 18.25%\n",
            "Epoch: 16, Step: 213/655, Loss: 2.215635, Accuracy: 18.24%\n",
            "Epoch: 16, Step: 214/655, Loss: 2.215679, Accuracy: 18.25%\n",
            "Epoch: 16, Step: 215/655, Loss: 2.215235, Accuracy: 18.26%\n",
            "Epoch: 16, Step: 216/655, Loss: 2.215826, Accuracy: 18.24%\n",
            "Epoch: 16, Step: 217/655, Loss: 2.215768, Accuracy: 18.22%\n",
            "Epoch: 16, Step: 218/655, Loss: 2.215309, Accuracy: 18.23%\n",
            "Epoch: 16, Step: 219/655, Loss: 2.215404, Accuracy: 18.22%\n",
            "Epoch: 16, Step: 220/655, Loss: 2.215095, Accuracy: 18.22%\n",
            "Epoch: 16, Step: 221/655, Loss: 2.215200, Accuracy: 18.24%\n",
            "Epoch: 16, Step: 222/655, Loss: 2.214882, Accuracy: 18.24%\n",
            "Epoch: 16, Step: 223/655, Loss: 2.215088, Accuracy: 18.23%\n",
            "Epoch: 16, Step: 224/655, Loss: 2.215093, Accuracy: 18.23%\n",
            "Epoch: 16, Step: 225/655, Loss: 2.214972, Accuracy: 18.24%\n",
            "Epoch: 16, Step: 226/655, Loss: 2.214789, Accuracy: 18.22%\n",
            "Epoch: 16, Step: 227/655, Loss: 2.215171, Accuracy: 18.20%\n",
            "Epoch: 16, Step: 228/655, Loss: 2.215300, Accuracy: 18.22%\n",
            "Epoch: 16, Step: 229/655, Loss: 2.215127, Accuracy: 18.22%\n",
            "Epoch: 16, Step: 230/655, Loss: 2.214935, Accuracy: 18.23%\n",
            "Epoch: 16, Step: 231/655, Loss: 2.215846, Accuracy: 18.21%\n",
            "Epoch: 16, Step: 232/655, Loss: 2.216137, Accuracy: 18.25%\n",
            "Epoch: 16, Step: 233/655, Loss: 2.216040, Accuracy: 18.23%\n",
            "Epoch: 16, Step: 234/655, Loss: 2.215987, Accuracy: 18.24%\n",
            "Epoch: 16, Step: 235/655, Loss: 2.215692, Accuracy: 18.30%\n",
            "Epoch: 16, Step: 236/655, Loss: 2.215562, Accuracy: 18.33%\n",
            "Epoch: 16, Step: 237/655, Loss: 2.214961, Accuracy: 18.30%\n",
            "Epoch: 16, Step: 238/655, Loss: 2.215029, Accuracy: 18.29%\n",
            "Epoch: 16, Step: 239/655, Loss: 2.215033, Accuracy: 18.28%\n",
            "Epoch: 16, Step: 240/655, Loss: 2.215559, Accuracy: 18.27%\n",
            "Epoch: 16, Step: 241/655, Loss: 2.215884, Accuracy: 18.27%\n",
            "Epoch: 16, Step: 242/655, Loss: 2.215465, Accuracy: 18.31%\n",
            "Epoch: 16, Step: 243/655, Loss: 2.215502, Accuracy: 18.33%\n",
            "Epoch: 16, Step: 244/655, Loss: 2.215097, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 245/655, Loss: 2.215572, Accuracy: 18.33%\n",
            "Epoch: 16, Step: 246/655, Loss: 2.215020, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 247/655, Loss: 2.215439, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 248/655, Loss: 2.215745, Accuracy: 18.32%\n",
            "Epoch: 16, Step: 249/655, Loss: 2.215363, Accuracy: 18.35%\n",
            "Epoch: 16, Step: 250/655, Loss: 2.215212, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 251/655, Loss: 2.214760, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 252/655, Loss: 2.214726, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 253/655, Loss: 2.214742, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 254/655, Loss: 2.214503, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 255/655, Loss: 2.214367, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 256/655, Loss: 2.214298, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 257/655, Loss: 2.214582, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 258/655, Loss: 2.214112, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 259/655, Loss: 2.213764, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 260/655, Loss: 2.213159, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 261/655, Loss: 2.212704, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 262/655, Loss: 2.212692, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 263/655, Loss: 2.213010, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 264/655, Loss: 2.212886, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 265/655, Loss: 2.212897, Accuracy: 18.41%\n",
            "Epoch: 16, Step: 266/655, Loss: 2.212534, Accuracy: 18.42%\n",
            "Epoch: 16, Step: 267/655, Loss: 2.212494, Accuracy: 18.41%\n",
            "Epoch: 16, Step: 268/655, Loss: 2.212586, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 269/655, Loss: 2.212566, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 270/655, Loss: 2.212570, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 271/655, Loss: 2.212801, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 272/655, Loss: 2.212853, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 273/655, Loss: 2.212911, Accuracy: 18.42%\n",
            "Epoch: 16, Step: 274/655, Loss: 2.212907, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 275/655, Loss: 2.212840, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 276/655, Loss: 2.212915, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 277/655, Loss: 2.212628, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 278/655, Loss: 2.212827, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 279/655, Loss: 2.212597, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 280/655, Loss: 2.212606, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 281/655, Loss: 2.212486, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 282/655, Loss: 2.212624, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 283/655, Loss: 2.212371, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 284/655, Loss: 2.211923, Accuracy: 18.54%\n",
            "Epoch: 16, Step: 285/655, Loss: 2.211792, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 286/655, Loss: 2.211809, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 287/655, Loss: 2.211868, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 288/655, Loss: 2.211958, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 289/655, Loss: 2.211640, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 290/655, Loss: 2.211730, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 291/655, Loss: 2.211756, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 292/655, Loss: 2.211760, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 293/655, Loss: 2.212037, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 294/655, Loss: 2.211582, Accuracy: 18.42%\n",
            "Epoch: 16, Step: 295/655, Loss: 2.211024, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 296/655, Loss: 2.211328, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 297/655, Loss: 2.211060, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 298/655, Loss: 2.210785, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 299/655, Loss: 2.210813, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 300/655, Loss: 2.210964, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 301/655, Loss: 2.210767, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 302/655, Loss: 2.210778, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 303/655, Loss: 2.210813, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 304/655, Loss: 2.210865, Accuracy: 18.42%\n",
            "Epoch: 16, Step: 305/655, Loss: 2.211071, Accuracy: 18.41%\n",
            "Epoch: 16, Step: 306/655, Loss: 2.211215, Accuracy: 18.41%\n",
            "Epoch: 16, Step: 307/655, Loss: 2.210856, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 308/655, Loss: 2.210538, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 309/655, Loss: 2.210972, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 310/655, Loss: 2.211092, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 311/655, Loss: 2.210999, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 312/655, Loss: 2.211041, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 313/655, Loss: 2.210983, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 314/655, Loss: 2.211154, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 315/655, Loss: 2.211591, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 316/655, Loss: 2.211416, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 317/655, Loss: 2.211564, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 318/655, Loss: 2.211958, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 319/655, Loss: 2.211718, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 320/655, Loss: 2.211719, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 321/655, Loss: 2.211704, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 322/655, Loss: 2.211676, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 323/655, Loss: 2.211948, Accuracy: 18.31%\n",
            "Epoch: 16, Step: 324/655, Loss: 2.211590, Accuracy: 18.30%\n",
            "Epoch: 16, Step: 325/655, Loss: 2.211526, Accuracy: 18.26%\n",
            "Epoch: 16, Step: 326/655, Loss: 2.211593, Accuracy: 18.28%\n",
            "Epoch: 16, Step: 327/655, Loss: 2.211504, Accuracy: 18.29%\n",
            "Epoch: 16, Step: 328/655, Loss: 2.211614, Accuracy: 18.27%\n",
            "Epoch: 16, Step: 329/655, Loss: 2.211187, Accuracy: 18.29%\n",
            "Epoch: 16, Step: 330/655, Loss: 2.211627, Accuracy: 18.29%\n",
            "Epoch: 16, Step: 331/655, Loss: 2.211334, Accuracy: 18.29%\n",
            "Epoch: 16, Step: 332/655, Loss: 2.211254, Accuracy: 18.28%\n",
            "Epoch: 16, Step: 333/655, Loss: 2.210755, Accuracy: 18.35%\n",
            "Epoch: 16, Step: 334/655, Loss: 2.210987, Accuracy: 18.34%\n",
            "Epoch: 16, Step: 335/655, Loss: 2.211002, Accuracy: 18.35%\n",
            "Epoch: 16, Step: 336/655, Loss: 2.211014, Accuracy: 18.35%\n",
            "Epoch: 16, Step: 337/655, Loss: 2.210637, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 338/655, Loss: 2.210733, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 339/655, Loss: 2.210949, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 340/655, Loss: 2.210850, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 341/655, Loss: 2.210648, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 342/655, Loss: 2.210677, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 343/655, Loss: 2.210607, Accuracy: 18.35%\n",
            "Epoch: 16, Step: 344/655, Loss: 2.210614, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 345/655, Loss: 2.210596, Accuracy: 18.33%\n",
            "Epoch: 16, Step: 346/655, Loss: 2.210515, Accuracy: 18.33%\n",
            "Epoch: 16, Step: 347/655, Loss: 2.210602, Accuracy: 18.34%\n",
            "Epoch: 16, Step: 348/655, Loss: 2.210469, Accuracy: 18.35%\n",
            "Epoch: 16, Step: 349/655, Loss: 2.210844, Accuracy: 18.34%\n",
            "Epoch: 16, Step: 350/655, Loss: 2.210736, Accuracy: 18.34%\n",
            "Epoch: 16, Step: 351/655, Loss: 2.210662, Accuracy: 18.35%\n",
            "Epoch: 16, Step: 352/655, Loss: 2.210593, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 353/655, Loss: 2.210578, Accuracy: 18.33%\n",
            "Epoch: 16, Step: 354/655, Loss: 2.210462, Accuracy: 18.34%\n",
            "Epoch: 16, Step: 355/655, Loss: 2.210234, Accuracy: 18.34%\n",
            "Epoch: 16, Step: 356/655, Loss: 2.210586, Accuracy: 18.31%\n",
            "Epoch: 16, Step: 357/655, Loss: 2.210409, Accuracy: 18.29%\n",
            "Epoch: 16, Step: 358/655, Loss: 2.210196, Accuracy: 18.30%\n",
            "Epoch: 16, Step: 359/655, Loss: 2.209973, Accuracy: 18.33%\n",
            "Epoch: 16, Step: 360/655, Loss: 2.209652, Accuracy: 18.35%\n",
            "Epoch: 16, Step: 361/655, Loss: 2.209460, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 362/655, Loss: 2.209357, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 363/655, Loss: 2.209161, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 364/655, Loss: 2.209138, Accuracy: 18.42%\n",
            "Epoch: 16, Step: 365/655, Loss: 2.209322, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 366/655, Loss: 2.209215, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 367/655, Loss: 2.209186, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 368/655, Loss: 2.209189, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 369/655, Loss: 2.208883, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 370/655, Loss: 2.208872, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 371/655, Loss: 2.209250, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 372/655, Loss: 2.209185, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 373/655, Loss: 2.209123, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 374/655, Loss: 2.209316, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 375/655, Loss: 2.209498, Accuracy: 18.41%\n",
            "Epoch: 16, Step: 376/655, Loss: 2.209465, Accuracy: 18.41%\n",
            "Epoch: 16, Step: 377/655, Loss: 2.209554, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 378/655, Loss: 2.209576, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 379/655, Loss: 2.209435, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 380/655, Loss: 2.209281, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 381/655, Loss: 2.208888, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 382/655, Loss: 2.208643, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 383/655, Loss: 2.208562, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 384/655, Loss: 2.208479, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 385/655, Loss: 2.208143, Accuracy: 18.52%\n",
            "Epoch: 16, Step: 386/655, Loss: 2.208016, Accuracy: 18.54%\n",
            "Epoch: 16, Step: 387/655, Loss: 2.208114, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 388/655, Loss: 2.207802, Accuracy: 18.55%\n",
            "Epoch: 16, Step: 389/655, Loss: 2.207721, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 390/655, Loss: 2.207628, Accuracy: 18.52%\n",
            "Epoch: 16, Step: 391/655, Loss: 2.207438, Accuracy: 18.54%\n",
            "Epoch: 16, Step: 392/655, Loss: 2.207195, Accuracy: 18.54%\n",
            "Epoch: 16, Step: 393/655, Loss: 2.207178, Accuracy: 18.58%\n",
            "Epoch: 16, Step: 394/655, Loss: 2.206951, Accuracy: 18.57%\n",
            "Epoch: 16, Step: 395/655, Loss: 2.207074, Accuracy: 18.57%\n",
            "Epoch: 16, Step: 396/655, Loss: 2.207114, Accuracy: 18.56%\n",
            "Epoch: 16, Step: 397/655, Loss: 2.207106, Accuracy: 18.58%\n",
            "Epoch: 16, Step: 398/655, Loss: 2.206651, Accuracy: 18.59%\n",
            "Epoch: 16, Step: 399/655, Loss: 2.206484, Accuracy: 18.57%\n",
            "Epoch: 16, Step: 400/655, Loss: 2.206290, Accuracy: 18.58%\n",
            "Epoch: 16, Step: 401/655, Loss: 2.206089, Accuracy: 18.61%\n",
            "Epoch: 16, Step: 402/655, Loss: 2.205956, Accuracy: 18.63%\n",
            "Epoch: 16, Step: 403/655, Loss: 2.206241, Accuracy: 18.61%\n",
            "Epoch: 16, Step: 404/655, Loss: 2.206163, Accuracy: 18.62%\n",
            "Epoch: 16, Step: 405/655, Loss: 2.206229, Accuracy: 18.59%\n",
            "Epoch: 16, Step: 406/655, Loss: 2.206291, Accuracy: 18.56%\n",
            "Epoch: 16, Step: 407/655, Loss: 2.206572, Accuracy: 18.54%\n",
            "Epoch: 16, Step: 408/655, Loss: 2.206651, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 409/655, Loss: 2.206406, Accuracy: 18.54%\n",
            "Epoch: 16, Step: 410/655, Loss: 2.206471, Accuracy: 18.54%\n",
            "Epoch: 16, Step: 411/655, Loss: 2.206609, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 412/655, Loss: 2.206631, Accuracy: 18.55%\n",
            "Epoch: 16, Step: 413/655, Loss: 2.206469, Accuracy: 18.58%\n",
            "Epoch: 16, Step: 414/655, Loss: 2.206549, Accuracy: 18.56%\n",
            "Epoch: 16, Step: 415/655, Loss: 2.206714, Accuracy: 18.56%\n",
            "Epoch: 16, Step: 416/655, Loss: 2.206671, Accuracy: 18.55%\n",
            "Epoch: 16, Step: 417/655, Loss: 2.206282, Accuracy: 18.56%\n",
            "Epoch: 16, Step: 418/655, Loss: 2.206074, Accuracy: 18.56%\n",
            "Epoch: 16, Step: 419/655, Loss: 2.206258, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 420/655, Loss: 2.206493, Accuracy: 18.54%\n",
            "Epoch: 16, Step: 421/655, Loss: 2.206842, Accuracy: 18.52%\n",
            "Epoch: 16, Step: 422/655, Loss: 2.206579, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 423/655, Loss: 2.206575, Accuracy: 18.55%\n",
            "Epoch: 16, Step: 424/655, Loss: 2.206497, Accuracy: 18.57%\n",
            "Epoch: 16, Step: 425/655, Loss: 2.206515, Accuracy: 18.57%\n",
            "Epoch: 16, Step: 426/655, Loss: 2.206643, Accuracy: 18.54%\n",
            "Epoch: 16, Step: 427/655, Loss: 2.206305, Accuracy: 18.56%\n",
            "Epoch: 16, Step: 428/655, Loss: 2.206337, Accuracy: 18.55%\n",
            "Epoch: 16, Step: 429/655, Loss: 2.206234, Accuracy: 18.55%\n",
            "Epoch: 16, Step: 430/655, Loss: 2.205945, Accuracy: 18.54%\n",
            "Epoch: 16, Step: 431/655, Loss: 2.206009, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 432/655, Loss: 2.205965, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 433/655, Loss: 2.206035, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 434/655, Loss: 2.205863, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 435/655, Loss: 2.205841, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 436/655, Loss: 2.205632, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 437/655, Loss: 2.205569, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 438/655, Loss: 2.205619, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 439/655, Loss: 2.205662, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 440/655, Loss: 2.205879, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 441/655, Loss: 2.205957, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 442/655, Loss: 2.205755, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 443/655, Loss: 2.205896, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 444/655, Loss: 2.205443, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 445/655, Loss: 2.205839, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 446/655, Loss: 2.205740, Accuracy: 18.55%\n",
            "Epoch: 16, Step: 447/655, Loss: 2.205516, Accuracy: 18.56%\n",
            "Epoch: 16, Step: 448/655, Loss: 2.205781, Accuracy: 18.55%\n",
            "Epoch: 16, Step: 449/655, Loss: 2.205658, Accuracy: 18.56%\n",
            "Epoch: 16, Step: 450/655, Loss: 2.205699, Accuracy: 18.54%\n",
            "Epoch: 16, Step: 451/655, Loss: 2.205878, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 452/655, Loss: 2.206039, Accuracy: 18.54%\n",
            "Epoch: 16, Step: 453/655, Loss: 2.205972, Accuracy: 18.54%\n",
            "Epoch: 16, Step: 454/655, Loss: 2.205964, Accuracy: 18.55%\n",
            "Epoch: 16, Step: 455/655, Loss: 2.206031, Accuracy: 18.52%\n",
            "Epoch: 16, Step: 456/655, Loss: 2.205832, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 457/655, Loss: 2.205454, Accuracy: 18.52%\n",
            "Epoch: 16, Step: 458/655, Loss: 2.205185, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 459/655, Loss: 2.205288, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 460/655, Loss: 2.205484, Accuracy: 18.52%\n",
            "Epoch: 16, Step: 461/655, Loss: 2.205712, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 462/655, Loss: 2.206194, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 463/655, Loss: 2.206265, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 464/655, Loss: 2.206168, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 465/655, Loss: 2.206375, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 466/655, Loss: 2.206395, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 467/655, Loss: 2.206447, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 468/655, Loss: 2.206524, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 469/655, Loss: 2.206224, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 470/655, Loss: 2.206347, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 471/655, Loss: 2.206211, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 472/655, Loss: 2.206319, Accuracy: 18.52%\n",
            "Epoch: 16, Step: 473/655, Loss: 2.206364, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 474/655, Loss: 2.206402, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 475/655, Loss: 2.206060, Accuracy: 18.52%\n",
            "Epoch: 16, Step: 476/655, Loss: 2.205898, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 477/655, Loss: 2.205908, Accuracy: 18.52%\n",
            "Epoch: 16, Step: 478/655, Loss: 2.206128, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 479/655, Loss: 2.206411, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 480/655, Loss: 2.206330, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 481/655, Loss: 2.206679, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 482/655, Loss: 2.206718, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 483/655, Loss: 2.206856, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 484/655, Loss: 2.206827, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 485/655, Loss: 2.206968, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 486/655, Loss: 2.207077, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 487/655, Loss: 2.207187, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 488/655, Loss: 2.207064, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 489/655, Loss: 2.207305, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 490/655, Loss: 2.207251, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 491/655, Loss: 2.206995, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 492/655, Loss: 2.207164, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 493/655, Loss: 2.207152, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 494/655, Loss: 2.207128, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 495/655, Loss: 2.207329, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 496/655, Loss: 2.207387, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 497/655, Loss: 2.207531, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 498/655, Loss: 2.207493, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 499/655, Loss: 2.207530, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 500/655, Loss: 2.207400, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 501/655, Loss: 2.207616, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 502/655, Loss: 2.207477, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 503/655, Loss: 2.207325, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 504/655, Loss: 2.207206, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 505/655, Loss: 2.207269, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 506/655, Loss: 2.207107, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 507/655, Loss: 2.206955, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 508/655, Loss: 2.206957, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 509/655, Loss: 2.206928, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 510/655, Loss: 2.207045, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 511/655, Loss: 2.207308, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 512/655, Loss: 2.207522, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 513/655, Loss: 2.207335, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 514/655, Loss: 2.207374, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 515/655, Loss: 2.207134, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 516/655, Loss: 2.206988, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 517/655, Loss: 2.207325, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 518/655, Loss: 2.207572, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 519/655, Loss: 2.207398, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 520/655, Loss: 2.207360, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 521/655, Loss: 2.207397, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 522/655, Loss: 2.207700, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 523/655, Loss: 2.207781, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 524/655, Loss: 2.207665, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 525/655, Loss: 2.207701, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 526/655, Loss: 2.207824, Accuracy: 18.42%\n",
            "Epoch: 16, Step: 527/655, Loss: 2.207820, Accuracy: 18.42%\n",
            "Epoch: 16, Step: 528/655, Loss: 2.207933, Accuracy: 18.42%\n",
            "Epoch: 16, Step: 529/655, Loss: 2.207906, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 530/655, Loss: 2.207819, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 531/655, Loss: 2.207771, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 532/655, Loss: 2.207622, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 533/655, Loss: 2.207668, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 534/655, Loss: 2.207801, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 535/655, Loss: 2.207820, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 536/655, Loss: 2.207861, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 537/655, Loss: 2.207997, Accuracy: 18.42%\n",
            "Epoch: 16, Step: 538/655, Loss: 2.208022, Accuracy: 18.41%\n",
            "Epoch: 16, Step: 539/655, Loss: 2.208043, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 540/655, Loss: 2.208277, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 541/655, Loss: 2.208057, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 542/655, Loss: 2.208235, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 543/655, Loss: 2.208424, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 544/655, Loss: 2.208614, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 545/655, Loss: 2.208581, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 546/655, Loss: 2.208425, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 547/655, Loss: 2.208161, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 548/655, Loss: 2.208054, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 549/655, Loss: 2.208226, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 550/655, Loss: 2.208056, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 551/655, Loss: 2.207946, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 552/655, Loss: 2.207874, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 553/655, Loss: 2.207757, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 554/655, Loss: 2.207777, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 555/655, Loss: 2.207631, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 556/655, Loss: 2.207594, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 557/655, Loss: 2.207716, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 558/655, Loss: 2.207566, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 559/655, Loss: 2.207437, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 560/655, Loss: 2.207655, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 561/655, Loss: 2.207751, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 562/655, Loss: 2.207542, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 563/655, Loss: 2.207239, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 564/655, Loss: 2.207336, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 565/655, Loss: 2.207301, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 566/655, Loss: 2.207351, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 567/655, Loss: 2.207414, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 568/655, Loss: 2.207420, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 569/655, Loss: 2.207540, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 570/655, Loss: 2.207436, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 571/655, Loss: 2.207595, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 572/655, Loss: 2.207648, Accuracy: 18.41%\n",
            "Epoch: 16, Step: 573/655, Loss: 2.207753, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 574/655, Loss: 2.207471, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 575/655, Loss: 2.207621, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 576/655, Loss: 2.207467, Accuracy: 18.41%\n",
            "Epoch: 16, Step: 577/655, Loss: 2.207439, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 578/655, Loss: 2.207572, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 579/655, Loss: 2.207595, Accuracy: 18.40%\n",
            "Epoch: 16, Step: 580/655, Loss: 2.207716, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 581/655, Loss: 2.207646, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 582/655, Loss: 2.207643, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 583/655, Loss: 2.207894, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 584/655, Loss: 2.207831, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 585/655, Loss: 2.208031, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 586/655, Loss: 2.208161, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 587/655, Loss: 2.208101, Accuracy: 18.37%\n",
            "Epoch: 16, Step: 588/655, Loss: 2.208024, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 589/655, Loss: 2.208061, Accuracy: 18.36%\n",
            "Epoch: 16, Step: 590/655, Loss: 2.207906, Accuracy: 18.38%\n",
            "Epoch: 16, Step: 591/655, Loss: 2.208020, Accuracy: 18.39%\n",
            "Epoch: 16, Step: 592/655, Loss: 2.207625, Accuracy: 18.42%\n",
            "Epoch: 16, Step: 593/655, Loss: 2.207693, Accuracy: 18.42%\n",
            "Epoch: 16, Step: 594/655, Loss: 2.207584, Accuracy: 18.41%\n",
            "Epoch: 16, Step: 595/655, Loss: 2.207608, Accuracy: 18.41%\n",
            "Epoch: 16, Step: 596/655, Loss: 2.207416, Accuracy: 18.41%\n",
            "Epoch: 16, Step: 597/655, Loss: 2.207405, Accuracy: 18.42%\n",
            "Epoch: 16, Step: 598/655, Loss: 2.207381, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 599/655, Loss: 2.207472, Accuracy: 18.42%\n",
            "Epoch: 16, Step: 600/655, Loss: 2.207344, Accuracy: 18.41%\n",
            "Epoch: 16, Step: 601/655, Loss: 2.207172, Accuracy: 18.42%\n",
            "Epoch: 16, Step: 602/655, Loss: 2.207252, Accuracy: 18.43%\n",
            "Epoch: 16, Step: 603/655, Loss: 2.207167, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 604/655, Loss: 2.207283, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 605/655, Loss: 2.207305, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 606/655, Loss: 2.207237, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 607/655, Loss: 2.207276, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 608/655, Loss: 2.207126, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 609/655, Loss: 2.207143, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 610/655, Loss: 2.207085, Accuracy: 18.44%\n",
            "Epoch: 16, Step: 611/655, Loss: 2.207122, Accuracy: 18.45%\n",
            "Epoch: 16, Step: 612/655, Loss: 2.207121, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 613/655, Loss: 2.207191, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 614/655, Loss: 2.207242, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 615/655, Loss: 2.207288, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 616/655, Loss: 2.207447, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 617/655, Loss: 2.207395, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 618/655, Loss: 2.207480, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 619/655, Loss: 2.207604, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 620/655, Loss: 2.207864, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 621/655, Loss: 2.207621, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 622/655, Loss: 2.207639, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 623/655, Loss: 2.207685, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 624/655, Loss: 2.207563, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 625/655, Loss: 2.207606, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 626/655, Loss: 2.207760, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 627/655, Loss: 2.207681, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 628/655, Loss: 2.207874, Accuracy: 18.52%\n",
            "Epoch: 16, Step: 629/655, Loss: 2.207887, Accuracy: 18.52%\n",
            "Epoch: 16, Step: 630/655, Loss: 2.207720, Accuracy: 18.52%\n",
            "Epoch: 16, Step: 631/655, Loss: 2.207565, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 632/655, Loss: 2.207408, Accuracy: 18.53%\n",
            "Epoch: 16, Step: 633/655, Loss: 2.207373, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 634/655, Loss: 2.207351, Accuracy: 18.51%\n",
            "Epoch: 16, Step: 635/655, Loss: 2.207519, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 636/655, Loss: 2.207422, Accuracy: 18.52%\n",
            "Epoch: 16, Step: 637/655, Loss: 2.207480, Accuracy: 18.52%\n",
            "Epoch: 16, Step: 638/655, Loss: 2.207714, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 639/655, Loss: 2.207668, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 640/655, Loss: 2.207768, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 641/655, Loss: 2.207705, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 642/655, Loss: 2.207738, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 643/655, Loss: 2.207771, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 644/655, Loss: 2.207876, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 645/655, Loss: 2.207716, Accuracy: 18.49%\n",
            "Epoch: 16, Step: 646/655, Loss: 2.207532, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 647/655, Loss: 2.207399, Accuracy: 18.50%\n",
            "Epoch: 16, Step: 648/655, Loss: 2.207517, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 649/655, Loss: 2.207770, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 650/655, Loss: 2.207683, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 651/655, Loss: 2.207541, Accuracy: 18.48%\n",
            "Epoch: 16, Step: 652/655, Loss: 2.207522, Accuracy: 18.47%\n",
            "Epoch: 16, Step: 653/655, Loss: 2.207684, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 654/655, Loss: 2.207916, Accuracy: 18.46%\n",
            "Epoch: 16, Step: 655/655, Loss: 2.207694, Accuracy: 18.47%\n",
            "Epoch: 17, Step: 1/655, Loss: 2.203219, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 2/655, Loss: 2.202210, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 3/655, Loss: 2.195858, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 4/655, Loss: 2.191791, Accuracy: 19.53%\n",
            "Epoch: 17, Step: 5/655, Loss: 2.196238, Accuracy: 18.12%\n",
            "Epoch: 17, Step: 6/655, Loss: 2.193826, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 7/655, Loss: 2.190578, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 8/655, Loss: 2.191197, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 9/655, Loss: 2.196272, Accuracy: 18.40%\n",
            "Epoch: 17, Step: 10/655, Loss: 2.205408, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 11/655, Loss: 2.209325, Accuracy: 18.18%\n",
            "Epoch: 17, Step: 12/655, Loss: 2.210150, Accuracy: 17.71%\n",
            "Epoch: 17, Step: 13/655, Loss: 2.210069, Accuracy: 17.31%\n",
            "Epoch: 17, Step: 14/655, Loss: 2.216354, Accuracy: 16.96%\n",
            "Epoch: 17, Step: 15/655, Loss: 2.219507, Accuracy: 17.50%\n",
            "Epoch: 17, Step: 16/655, Loss: 2.223353, Accuracy: 17.38%\n",
            "Epoch: 17, Step: 17/655, Loss: 2.227194, Accuracy: 17.28%\n",
            "Epoch: 17, Step: 18/655, Loss: 2.228785, Accuracy: 17.36%\n",
            "Epoch: 17, Step: 19/655, Loss: 2.221754, Accuracy: 17.43%\n",
            "Epoch: 17, Step: 20/655, Loss: 2.222929, Accuracy: 17.50%\n",
            "Epoch: 17, Step: 21/655, Loss: 2.228334, Accuracy: 17.41%\n",
            "Epoch: 17, Step: 22/655, Loss: 2.221538, Accuracy: 17.33%\n",
            "Epoch: 17, Step: 23/655, Loss: 2.219376, Accuracy: 17.93%\n",
            "Epoch: 17, Step: 24/655, Loss: 2.216217, Accuracy: 18.36%\n",
            "Epoch: 17, Step: 25/655, Loss: 2.212636, Accuracy: 18.25%\n",
            "Epoch: 17, Step: 26/655, Loss: 2.212360, Accuracy: 18.27%\n",
            "Epoch: 17, Step: 27/655, Loss: 2.216609, Accuracy: 18.29%\n",
            "Epoch: 17, Step: 28/655, Loss: 2.212462, Accuracy: 18.86%\n",
            "Epoch: 17, Step: 29/655, Loss: 2.210962, Accuracy: 19.07%\n",
            "Epoch: 17, Step: 30/655, Loss: 2.212564, Accuracy: 18.96%\n",
            "Epoch: 17, Step: 31/655, Loss: 2.211234, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 32/655, Loss: 2.213262, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 33/655, Loss: 2.215490, Accuracy: 18.47%\n",
            "Epoch: 17, Step: 34/655, Loss: 2.212443, Accuracy: 18.66%\n",
            "Epoch: 17, Step: 35/655, Loss: 2.212977, Accuracy: 18.48%\n",
            "Epoch: 17, Step: 36/655, Loss: 2.212631, Accuracy: 18.92%\n",
            "Epoch: 17, Step: 37/655, Loss: 2.213098, Accuracy: 19.09%\n",
            "Epoch: 17, Step: 38/655, Loss: 2.212954, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 39/655, Loss: 2.212164, Accuracy: 18.59%\n",
            "Epoch: 17, Step: 40/655, Loss: 2.211814, Accuracy: 18.52%\n",
            "Epoch: 17, Step: 41/655, Loss: 2.212837, Accuracy: 18.67%\n",
            "Epoch: 17, Step: 42/655, Loss: 2.213060, Accuracy: 18.45%\n",
            "Epoch: 17, Step: 43/655, Loss: 2.212659, Accuracy: 18.68%\n",
            "Epoch: 17, Step: 44/655, Loss: 2.213861, Accuracy: 18.61%\n",
            "Epoch: 17, Step: 45/655, Loss: 2.216702, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 46/655, Loss: 2.215326, Accuracy: 18.68%\n",
            "Epoch: 17, Step: 47/655, Loss: 2.217946, Accuracy: 18.42%\n",
            "Epoch: 17, Step: 48/655, Loss: 2.219774, Accuracy: 18.29%\n",
            "Epoch: 17, Step: 49/655, Loss: 2.216980, Accuracy: 18.30%\n",
            "Epoch: 17, Step: 50/655, Loss: 2.215879, Accuracy: 18.31%\n",
            "Epoch: 17, Step: 51/655, Loss: 2.215646, Accuracy: 18.08%\n",
            "Epoch: 17, Step: 52/655, Loss: 2.214650, Accuracy: 18.15%\n",
            "Epoch: 17, Step: 53/655, Loss: 2.213989, Accuracy: 18.10%\n",
            "Epoch: 17, Step: 54/655, Loss: 2.215448, Accuracy: 17.94%\n",
            "Epoch: 17, Step: 55/655, Loss: 2.216327, Accuracy: 18.07%\n",
            "Epoch: 17, Step: 56/655, Loss: 2.216466, Accuracy: 17.97%\n",
            "Epoch: 17, Step: 57/655, Loss: 2.217707, Accuracy: 17.93%\n",
            "Epoch: 17, Step: 58/655, Loss: 2.215499, Accuracy: 17.89%\n",
            "Epoch: 17, Step: 59/655, Loss: 2.214881, Accuracy: 17.85%\n",
            "Epoch: 17, Step: 60/655, Loss: 2.212801, Accuracy: 17.97%\n",
            "Epoch: 17, Step: 61/655, Loss: 2.212240, Accuracy: 17.83%\n",
            "Epoch: 17, Step: 62/655, Loss: 2.212900, Accuracy: 17.94%\n",
            "Epoch: 17, Step: 63/655, Loss: 2.212606, Accuracy: 17.86%\n",
            "Epoch: 17, Step: 64/655, Loss: 2.212750, Accuracy: 17.87%\n",
            "Epoch: 17, Step: 65/655, Loss: 2.212976, Accuracy: 17.74%\n",
            "Epoch: 17, Step: 66/655, Loss: 2.211547, Accuracy: 17.85%\n",
            "Epoch: 17, Step: 67/655, Loss: 2.210807, Accuracy: 17.86%\n",
            "Epoch: 17, Step: 68/655, Loss: 2.211276, Accuracy: 17.92%\n",
            "Epoch: 17, Step: 69/655, Loss: 2.212472, Accuracy: 17.89%\n",
            "Epoch: 17, Step: 70/655, Loss: 2.213189, Accuracy: 17.95%\n",
            "Epoch: 17, Step: 71/655, Loss: 2.212604, Accuracy: 17.83%\n",
            "Epoch: 17, Step: 72/655, Loss: 2.210617, Accuracy: 18.01%\n",
            "Epoch: 17, Step: 73/655, Loss: 2.210809, Accuracy: 17.94%\n",
            "Epoch: 17, Step: 74/655, Loss: 2.210081, Accuracy: 17.95%\n",
            "Epoch: 17, Step: 75/655, Loss: 2.210280, Accuracy: 17.92%\n",
            "Epoch: 17, Step: 76/655, Loss: 2.210314, Accuracy: 17.97%\n",
            "Epoch: 17, Step: 77/655, Loss: 2.209508, Accuracy: 18.18%\n",
            "Epoch: 17, Step: 78/655, Loss: 2.210198, Accuracy: 18.15%\n",
            "Epoch: 17, Step: 79/655, Loss: 2.210546, Accuracy: 18.00%\n",
            "Epoch: 17, Step: 80/655, Loss: 2.211144, Accuracy: 18.05%\n",
            "Epoch: 17, Step: 81/655, Loss: 2.211248, Accuracy: 18.09%\n",
            "Epoch: 17, Step: 82/655, Loss: 2.210946, Accuracy: 18.14%\n",
            "Epoch: 17, Step: 83/655, Loss: 2.210922, Accuracy: 18.11%\n",
            "Epoch: 17, Step: 84/655, Loss: 2.212921, Accuracy: 18.04%\n",
            "Epoch: 17, Step: 85/655, Loss: 2.214411, Accuracy: 17.94%\n",
            "Epoch: 17, Step: 86/655, Loss: 2.215943, Accuracy: 17.91%\n",
            "Epoch: 17, Step: 87/655, Loss: 2.218020, Accuracy: 17.89%\n",
            "Epoch: 17, Step: 88/655, Loss: 2.218461, Accuracy: 17.86%\n",
            "Epoch: 17, Step: 89/655, Loss: 2.217640, Accuracy: 17.91%\n",
            "Epoch: 17, Step: 90/655, Loss: 2.216689, Accuracy: 18.06%\n",
            "Epoch: 17, Step: 91/655, Loss: 2.217191, Accuracy: 18.10%\n",
            "Epoch: 17, Step: 92/655, Loss: 2.215641, Accuracy: 18.17%\n",
            "Epoch: 17, Step: 93/655, Loss: 2.215707, Accuracy: 18.18%\n",
            "Epoch: 17, Step: 94/655, Loss: 2.216342, Accuracy: 18.18%\n",
            "Epoch: 17, Step: 95/655, Loss: 2.217172, Accuracy: 18.03%\n",
            "Epoch: 17, Step: 96/655, Loss: 2.216819, Accuracy: 17.90%\n",
            "Epoch: 17, Step: 97/655, Loss: 2.218515, Accuracy: 17.78%\n",
            "Epoch: 17, Step: 98/655, Loss: 2.218447, Accuracy: 17.83%\n",
            "Epoch: 17, Step: 99/655, Loss: 2.218222, Accuracy: 17.87%\n",
            "Epoch: 17, Step: 100/655, Loss: 2.217124, Accuracy: 17.97%\n",
            "Epoch: 17, Step: 101/655, Loss: 2.217974, Accuracy: 17.88%\n",
            "Epoch: 17, Step: 102/655, Loss: 2.216800, Accuracy: 18.01%\n",
            "Epoch: 17, Step: 103/655, Loss: 2.217067, Accuracy: 17.99%\n",
            "Epoch: 17, Step: 104/655, Loss: 2.217529, Accuracy: 18.00%\n",
            "Epoch: 17, Step: 105/655, Loss: 2.217767, Accuracy: 17.98%\n",
            "Epoch: 17, Step: 106/655, Loss: 2.216866, Accuracy: 18.01%\n",
            "Epoch: 17, Step: 107/655, Loss: 2.216830, Accuracy: 18.02%\n",
            "Epoch: 17, Step: 108/655, Loss: 2.217018, Accuracy: 18.03%\n",
            "Epoch: 17, Step: 109/655, Loss: 2.217170, Accuracy: 18.03%\n",
            "Epoch: 17, Step: 110/655, Loss: 2.216624, Accuracy: 18.04%\n",
            "Epoch: 17, Step: 111/655, Loss: 2.216885, Accuracy: 18.07%\n",
            "Epoch: 17, Step: 112/655, Loss: 2.217065, Accuracy: 18.02%\n",
            "Epoch: 17, Step: 113/655, Loss: 2.216178, Accuracy: 18.11%\n",
            "Epoch: 17, Step: 114/655, Loss: 2.215009, Accuracy: 18.23%\n",
            "Epoch: 17, Step: 115/655, Loss: 2.214654, Accuracy: 18.23%\n",
            "Epoch: 17, Step: 116/655, Loss: 2.214280, Accuracy: 18.35%\n",
            "Epoch: 17, Step: 117/655, Loss: 2.213913, Accuracy: 18.40%\n",
            "Epoch: 17, Step: 118/655, Loss: 2.213648, Accuracy: 18.43%\n",
            "Epoch: 17, Step: 119/655, Loss: 2.213214, Accuracy: 18.43%\n",
            "Epoch: 17, Step: 120/655, Loss: 2.213250, Accuracy: 18.46%\n",
            "Epoch: 17, Step: 121/655, Loss: 2.212707, Accuracy: 18.52%\n",
            "Epoch: 17, Step: 122/655, Loss: 2.213441, Accuracy: 18.49%\n",
            "Epoch: 17, Step: 123/655, Loss: 2.212942, Accuracy: 18.52%\n",
            "Epoch: 17, Step: 124/655, Loss: 2.212480, Accuracy: 18.62%\n",
            "Epoch: 17, Step: 125/655, Loss: 2.212293, Accuracy: 18.68%\n",
            "Epoch: 17, Step: 126/655, Loss: 2.213239, Accuracy: 18.68%\n",
            "Epoch: 17, Step: 127/655, Loss: 2.212438, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 128/655, Loss: 2.212688, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 129/655, Loss: 2.212003, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 130/655, Loss: 2.212700, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 131/655, Loss: 2.212890, Accuracy: 18.77%\n",
            "Epoch: 17, Step: 132/655, Loss: 2.212926, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 133/655, Loss: 2.213990, Accuracy: 18.73%\n",
            "Epoch: 17, Step: 134/655, Loss: 2.214506, Accuracy: 18.73%\n",
            "Epoch: 17, Step: 135/655, Loss: 2.213868, Accuracy: 18.73%\n",
            "Epoch: 17, Step: 136/655, Loss: 2.213881, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 137/655, Loss: 2.213481, Accuracy: 18.84%\n",
            "Epoch: 17, Step: 138/655, Loss: 2.213272, Accuracy: 18.86%\n",
            "Epoch: 17, Step: 139/655, Loss: 2.212348, Accuracy: 19.00%\n",
            "Epoch: 17, Step: 140/655, Loss: 2.211883, Accuracy: 18.97%\n",
            "Epoch: 17, Step: 141/655, Loss: 2.211062, Accuracy: 19.06%\n",
            "Epoch: 17, Step: 142/655, Loss: 2.211770, Accuracy: 19.06%\n",
            "Epoch: 17, Step: 143/655, Loss: 2.212507, Accuracy: 19.01%\n",
            "Epoch: 17, Step: 144/655, Loss: 2.212461, Accuracy: 18.99%\n",
            "Epoch: 17, Step: 145/655, Loss: 2.212695, Accuracy: 18.92%\n",
            "Epoch: 17, Step: 146/655, Loss: 2.213628, Accuracy: 18.84%\n",
            "Epoch: 17, Step: 147/655, Loss: 2.214047, Accuracy: 18.81%\n",
            "Epoch: 17, Step: 148/655, Loss: 2.213613, Accuracy: 18.81%\n",
            "Epoch: 17, Step: 149/655, Loss: 2.213824, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 150/655, Loss: 2.213988, Accuracy: 18.81%\n",
            "Epoch: 17, Step: 151/655, Loss: 2.213556, Accuracy: 18.87%\n",
            "Epoch: 17, Step: 152/655, Loss: 2.212971, Accuracy: 18.94%\n",
            "Epoch: 17, Step: 153/655, Loss: 2.212748, Accuracy: 18.97%\n",
            "Epoch: 17, Step: 154/655, Loss: 2.212721, Accuracy: 18.97%\n",
            "Epoch: 17, Step: 155/655, Loss: 2.212496, Accuracy: 19.01%\n",
            "Epoch: 17, Step: 156/655, Loss: 2.211832, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 157/655, Loss: 2.212318, Accuracy: 18.99%\n",
            "Epoch: 17, Step: 158/655, Loss: 2.212791, Accuracy: 18.93%\n",
            "Epoch: 17, Step: 159/655, Loss: 2.212324, Accuracy: 18.99%\n",
            "Epoch: 17, Step: 160/655, Loss: 2.212540, Accuracy: 18.96%\n",
            "Epoch: 17, Step: 161/655, Loss: 2.212432, Accuracy: 19.04%\n",
            "Epoch: 17, Step: 162/655, Loss: 2.212096, Accuracy: 19.08%\n",
            "Epoch: 17, Step: 163/655, Loss: 2.211629, Accuracy: 19.10%\n",
            "Epoch: 17, Step: 164/655, Loss: 2.211355, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 165/655, Loss: 2.211838, Accuracy: 19.05%\n",
            "Epoch: 17, Step: 166/655, Loss: 2.211869, Accuracy: 19.01%\n",
            "Epoch: 17, Step: 167/655, Loss: 2.212609, Accuracy: 18.97%\n",
            "Epoch: 17, Step: 168/655, Loss: 2.212657, Accuracy: 18.92%\n",
            "Epoch: 17, Step: 169/655, Loss: 2.212111, Accuracy: 18.92%\n",
            "Epoch: 17, Step: 170/655, Loss: 2.212342, Accuracy: 18.88%\n",
            "Epoch: 17, Step: 171/655, Loss: 2.212621, Accuracy: 18.86%\n",
            "Epoch: 17, Step: 172/655, Loss: 2.212114, Accuracy: 18.88%\n",
            "Epoch: 17, Step: 173/655, Loss: 2.212682, Accuracy: 18.84%\n",
            "Epoch: 17, Step: 174/655, Loss: 2.212917, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 175/655, Loss: 2.212676, Accuracy: 18.84%\n",
            "Epoch: 17, Step: 176/655, Loss: 2.212547, Accuracy: 18.89%\n",
            "Epoch: 17, Step: 177/655, Loss: 2.212517, Accuracy: 18.87%\n",
            "Epoch: 17, Step: 178/655, Loss: 2.212037, Accuracy: 18.86%\n",
            "Epoch: 17, Step: 179/655, Loss: 2.211752, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 180/655, Loss: 2.211631, Accuracy: 18.82%\n",
            "Epoch: 17, Step: 181/655, Loss: 2.211381, Accuracy: 18.84%\n",
            "Epoch: 17, Step: 182/655, Loss: 2.211580, Accuracy: 18.82%\n",
            "Epoch: 17, Step: 183/655, Loss: 2.211857, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 184/655, Loss: 2.211448, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 185/655, Loss: 2.211121, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 186/655, Loss: 2.211347, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 187/655, Loss: 2.211647, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 188/655, Loss: 2.211607, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 189/655, Loss: 2.211579, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 190/655, Loss: 2.211080, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 191/655, Loss: 2.210998, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 192/655, Loss: 2.210994, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 193/655, Loss: 2.211338, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 194/655, Loss: 2.211376, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 195/655, Loss: 2.211078, Accuracy: 18.77%\n",
            "Epoch: 17, Step: 196/655, Loss: 2.210801, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 197/655, Loss: 2.210776, Accuracy: 18.88%\n",
            "Epoch: 17, Step: 198/655, Loss: 2.210700, Accuracy: 18.86%\n",
            "Epoch: 17, Step: 199/655, Loss: 2.210185, Accuracy: 18.91%\n",
            "Epoch: 17, Step: 200/655, Loss: 2.210662, Accuracy: 18.84%\n",
            "Epoch: 17, Step: 201/655, Loss: 2.210948, Accuracy: 18.84%\n",
            "Epoch: 17, Step: 202/655, Loss: 2.210823, Accuracy: 18.89%\n",
            "Epoch: 17, Step: 203/655, Loss: 2.211102, Accuracy: 18.86%\n",
            "Epoch: 17, Step: 204/655, Loss: 2.211153, Accuracy: 18.84%\n",
            "Epoch: 17, Step: 205/655, Loss: 2.211042, Accuracy: 18.89%\n",
            "Epoch: 17, Step: 206/655, Loss: 2.211292, Accuracy: 18.87%\n",
            "Epoch: 17, Step: 207/655, Loss: 2.210948, Accuracy: 18.93%\n",
            "Epoch: 17, Step: 208/655, Loss: 2.211391, Accuracy: 18.95%\n",
            "Epoch: 17, Step: 209/655, Loss: 2.210933, Accuracy: 18.96%\n",
            "Epoch: 17, Step: 210/655, Loss: 2.210877, Accuracy: 18.99%\n",
            "Epoch: 17, Step: 211/655, Loss: 2.210730, Accuracy: 19.00%\n",
            "Epoch: 17, Step: 212/655, Loss: 2.211085, Accuracy: 18.96%\n",
            "Epoch: 17, Step: 213/655, Loss: 2.211245, Accuracy: 18.93%\n",
            "Epoch: 17, Step: 214/655, Loss: 2.211133, Accuracy: 18.91%\n",
            "Epoch: 17, Step: 215/655, Loss: 2.210739, Accuracy: 18.92%\n",
            "Epoch: 17, Step: 216/655, Loss: 2.210906, Accuracy: 18.94%\n",
            "Epoch: 17, Step: 217/655, Loss: 2.210928, Accuracy: 18.91%\n",
            "Epoch: 17, Step: 218/655, Loss: 2.211157, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 219/655, Loss: 2.211371, Accuracy: 18.81%\n",
            "Epoch: 17, Step: 220/655, Loss: 2.210985, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 221/655, Loss: 2.210715, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 222/655, Loss: 2.210693, Accuracy: 18.82%\n",
            "Epoch: 17, Step: 223/655, Loss: 2.210452, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 224/655, Loss: 2.210044, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 225/655, Loss: 2.210330, Accuracy: 18.81%\n",
            "Epoch: 17, Step: 226/655, Loss: 2.210085, Accuracy: 18.81%\n",
            "Epoch: 17, Step: 227/655, Loss: 2.209654, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 228/655, Loss: 2.209598, Accuracy: 18.82%\n",
            "Epoch: 17, Step: 229/655, Loss: 2.209175, Accuracy: 18.86%\n",
            "Epoch: 17, Step: 230/655, Loss: 2.209420, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 231/655, Loss: 2.210152, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 232/655, Loss: 2.210029, Accuracy: 18.84%\n",
            "Epoch: 17, Step: 233/655, Loss: 2.210166, Accuracy: 18.86%\n",
            "Epoch: 17, Step: 234/655, Loss: 2.209974, Accuracy: 18.87%\n",
            "Epoch: 17, Step: 235/655, Loss: 2.209447, Accuracy: 18.91%\n",
            "Epoch: 17, Step: 236/655, Loss: 2.209515, Accuracy: 18.90%\n",
            "Epoch: 17, Step: 237/655, Loss: 2.209236, Accuracy: 18.93%\n",
            "Epoch: 17, Step: 238/655, Loss: 2.208826, Accuracy: 19.00%\n",
            "Epoch: 17, Step: 239/655, Loss: 2.208759, Accuracy: 19.02%\n",
            "Epoch: 17, Step: 240/655, Loss: 2.208355, Accuracy: 19.02%\n",
            "Epoch: 17, Step: 241/655, Loss: 2.208494, Accuracy: 19.02%\n",
            "Epoch: 17, Step: 242/655, Loss: 2.209030, Accuracy: 19.00%\n",
            "Epoch: 17, Step: 243/655, Loss: 2.209593, Accuracy: 18.93%\n",
            "Epoch: 17, Step: 244/655, Loss: 2.209211, Accuracy: 18.94%\n",
            "Epoch: 17, Step: 245/655, Loss: 2.209647, Accuracy: 18.92%\n",
            "Epoch: 17, Step: 246/655, Loss: 2.209307, Accuracy: 18.92%\n",
            "Epoch: 17, Step: 247/655, Loss: 2.209128, Accuracy: 18.88%\n",
            "Epoch: 17, Step: 248/655, Loss: 2.208989, Accuracy: 18.90%\n",
            "Epoch: 17, Step: 249/655, Loss: 2.208942, Accuracy: 18.91%\n",
            "Epoch: 17, Step: 250/655, Loss: 2.208729, Accuracy: 18.94%\n",
            "Epoch: 17, Step: 251/655, Loss: 2.208068, Accuracy: 18.97%\n",
            "Epoch: 17, Step: 252/655, Loss: 2.208097, Accuracy: 18.97%\n",
            "Epoch: 17, Step: 253/655, Loss: 2.208418, Accuracy: 18.97%\n",
            "Epoch: 17, Step: 254/655, Loss: 2.208519, Accuracy: 18.97%\n",
            "Epoch: 17, Step: 255/655, Loss: 2.208418, Accuracy: 18.97%\n",
            "Epoch: 17, Step: 256/655, Loss: 2.207905, Accuracy: 18.99%\n",
            "Epoch: 17, Step: 257/655, Loss: 2.208271, Accuracy: 18.98%\n",
            "Epoch: 17, Step: 258/655, Loss: 2.208142, Accuracy: 18.97%\n",
            "Epoch: 17, Step: 259/655, Loss: 2.208089, Accuracy: 18.97%\n",
            "Epoch: 17, Step: 260/655, Loss: 2.207910, Accuracy: 18.99%\n",
            "Epoch: 17, Step: 261/655, Loss: 2.207798, Accuracy: 18.99%\n",
            "Epoch: 17, Step: 262/655, Loss: 2.207657, Accuracy: 19.02%\n",
            "Epoch: 17, Step: 263/655, Loss: 2.207721, Accuracy: 19.00%\n",
            "Epoch: 17, Step: 264/655, Loss: 2.207504, Accuracy: 18.99%\n",
            "Epoch: 17, Step: 265/655, Loss: 2.207417, Accuracy: 19.02%\n",
            "Epoch: 17, Step: 266/655, Loss: 2.207575, Accuracy: 18.96%\n",
            "Epoch: 17, Step: 267/655, Loss: 2.207252, Accuracy: 18.94%\n",
            "Epoch: 17, Step: 268/655, Loss: 2.207386, Accuracy: 18.91%\n",
            "Epoch: 17, Step: 269/655, Loss: 2.206896, Accuracy: 18.94%\n",
            "Epoch: 17, Step: 270/655, Loss: 2.206389, Accuracy: 18.99%\n",
            "Epoch: 17, Step: 271/655, Loss: 2.206442, Accuracy: 18.98%\n",
            "Epoch: 17, Step: 272/655, Loss: 2.207062, Accuracy: 18.97%\n",
            "Epoch: 17, Step: 273/655, Loss: 2.207138, Accuracy: 18.94%\n",
            "Epoch: 17, Step: 274/655, Loss: 2.206960, Accuracy: 18.92%\n",
            "Epoch: 17, Step: 275/655, Loss: 2.206713, Accuracy: 18.93%\n",
            "Epoch: 17, Step: 276/655, Loss: 2.206728, Accuracy: 18.92%\n",
            "Epoch: 17, Step: 277/655, Loss: 2.206233, Accuracy: 18.96%\n",
            "Epoch: 17, Step: 278/655, Loss: 2.206695, Accuracy: 18.97%\n",
            "Epoch: 17, Step: 279/655, Loss: 2.206541, Accuracy: 18.95%\n",
            "Epoch: 17, Step: 280/655, Loss: 2.206445, Accuracy: 18.95%\n",
            "Epoch: 17, Step: 281/655, Loss: 2.206514, Accuracy: 18.97%\n",
            "Epoch: 17, Step: 282/655, Loss: 2.206206, Accuracy: 19.00%\n",
            "Epoch: 17, Step: 283/655, Loss: 2.205820, Accuracy: 18.99%\n",
            "Epoch: 17, Step: 284/655, Loss: 2.206459, Accuracy: 18.98%\n",
            "Epoch: 17, Step: 285/655, Loss: 2.206541, Accuracy: 18.94%\n",
            "Epoch: 17, Step: 286/655, Loss: 2.206375, Accuracy: 18.97%\n",
            "Epoch: 17, Step: 287/655, Loss: 2.206346, Accuracy: 18.96%\n",
            "Epoch: 17, Step: 288/655, Loss: 2.206283, Accuracy: 18.98%\n",
            "Epoch: 17, Step: 289/655, Loss: 2.206594, Accuracy: 18.99%\n",
            "Epoch: 17, Step: 290/655, Loss: 2.206290, Accuracy: 19.04%\n",
            "Epoch: 17, Step: 291/655, Loss: 2.206189, Accuracy: 19.02%\n",
            "Epoch: 17, Step: 292/655, Loss: 2.205409, Accuracy: 19.04%\n",
            "Epoch: 17, Step: 293/655, Loss: 2.205199, Accuracy: 19.06%\n",
            "Epoch: 17, Step: 294/655, Loss: 2.204777, Accuracy: 19.06%\n",
            "Epoch: 17, Step: 295/655, Loss: 2.204839, Accuracy: 19.07%\n",
            "Epoch: 17, Step: 296/655, Loss: 2.204738, Accuracy: 19.07%\n",
            "Epoch: 17, Step: 297/655, Loss: 2.204926, Accuracy: 19.06%\n",
            "Epoch: 17, Step: 298/655, Loss: 2.204841, Accuracy: 19.09%\n",
            "Epoch: 17, Step: 299/655, Loss: 2.204392, Accuracy: 19.13%\n",
            "Epoch: 17, Step: 300/655, Loss: 2.204158, Accuracy: 19.15%\n",
            "Epoch: 17, Step: 301/655, Loss: 2.204068, Accuracy: 19.13%\n",
            "Epoch: 17, Step: 302/655, Loss: 2.203461, Accuracy: 19.21%\n",
            "Epoch: 17, Step: 303/655, Loss: 2.203762, Accuracy: 19.17%\n",
            "Epoch: 17, Step: 304/655, Loss: 2.203715, Accuracy: 19.19%\n",
            "Epoch: 17, Step: 305/655, Loss: 2.203627, Accuracy: 19.21%\n",
            "Epoch: 17, Step: 306/655, Loss: 2.203768, Accuracy: 19.22%\n",
            "Epoch: 17, Step: 307/655, Loss: 2.204007, Accuracy: 19.22%\n",
            "Epoch: 17, Step: 308/655, Loss: 2.204303, Accuracy: 19.22%\n",
            "Epoch: 17, Step: 309/655, Loss: 2.204332, Accuracy: 19.22%\n",
            "Epoch: 17, Step: 310/655, Loss: 2.203723, Accuracy: 19.24%\n",
            "Epoch: 17, Step: 311/655, Loss: 2.204216, Accuracy: 19.20%\n",
            "Epoch: 17, Step: 312/655, Loss: 2.204449, Accuracy: 19.18%\n",
            "Epoch: 17, Step: 313/655, Loss: 2.204434, Accuracy: 19.18%\n",
            "Epoch: 17, Step: 314/655, Loss: 2.204564, Accuracy: 19.16%\n",
            "Epoch: 17, Step: 315/655, Loss: 2.204819, Accuracy: 19.15%\n",
            "Epoch: 17, Step: 316/655, Loss: 2.204704, Accuracy: 19.13%\n",
            "Epoch: 17, Step: 317/655, Loss: 2.204128, Accuracy: 19.18%\n",
            "Epoch: 17, Step: 318/655, Loss: 2.203809, Accuracy: 19.18%\n",
            "Epoch: 17, Step: 319/655, Loss: 2.204053, Accuracy: 19.18%\n",
            "Epoch: 17, Step: 320/655, Loss: 2.203806, Accuracy: 19.20%\n",
            "Epoch: 17, Step: 321/655, Loss: 2.203744, Accuracy: 19.19%\n",
            "Epoch: 17, Step: 322/655, Loss: 2.203902, Accuracy: 19.17%\n",
            "Epoch: 17, Step: 323/655, Loss: 2.203997, Accuracy: 19.15%\n",
            "Epoch: 17, Step: 324/655, Loss: 2.204376, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 325/655, Loss: 2.204140, Accuracy: 19.09%\n",
            "Epoch: 17, Step: 326/655, Loss: 2.204540, Accuracy: 19.07%\n",
            "Epoch: 17, Step: 327/655, Loss: 2.204853, Accuracy: 19.07%\n",
            "Epoch: 17, Step: 328/655, Loss: 2.204485, Accuracy: 19.07%\n",
            "Epoch: 17, Step: 329/655, Loss: 2.204166, Accuracy: 19.12%\n",
            "Epoch: 17, Step: 330/655, Loss: 2.204225, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 331/655, Loss: 2.204138, Accuracy: 19.13%\n",
            "Epoch: 17, Step: 332/655, Loss: 2.204030, Accuracy: 19.15%\n",
            "Epoch: 17, Step: 333/655, Loss: 2.204061, Accuracy: 19.13%\n",
            "Epoch: 17, Step: 334/655, Loss: 2.203661, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 335/655, Loss: 2.203816, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 336/655, Loss: 2.203552, Accuracy: 19.16%\n",
            "Epoch: 17, Step: 337/655, Loss: 2.203198, Accuracy: 19.18%\n",
            "Epoch: 17, Step: 338/655, Loss: 2.203123, Accuracy: 19.16%\n",
            "Epoch: 17, Step: 339/655, Loss: 2.203053, Accuracy: 19.12%\n",
            "Epoch: 17, Step: 340/655, Loss: 2.203695, Accuracy: 19.08%\n",
            "Epoch: 17, Step: 341/655, Loss: 2.203546, Accuracy: 19.10%\n",
            "Epoch: 17, Step: 342/655, Loss: 2.203748, Accuracy: 19.08%\n",
            "Epoch: 17, Step: 343/655, Loss: 2.203504, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 344/655, Loss: 2.203649, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 345/655, Loss: 2.203668, Accuracy: 19.10%\n",
            "Epoch: 17, Step: 346/655, Loss: 2.203443, Accuracy: 19.12%\n",
            "Epoch: 17, Step: 347/655, Loss: 2.203091, Accuracy: 19.14%\n",
            "Epoch: 17, Step: 348/655, Loss: 2.202925, Accuracy: 19.14%\n",
            "Epoch: 17, Step: 349/655, Loss: 2.203134, Accuracy: 19.15%\n",
            "Epoch: 17, Step: 350/655, Loss: 2.203176, Accuracy: 19.15%\n",
            "Epoch: 17, Step: 351/655, Loss: 2.203493, Accuracy: 19.12%\n",
            "Epoch: 17, Step: 352/655, Loss: 2.203610, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 353/655, Loss: 2.202984, Accuracy: 19.13%\n",
            "Epoch: 17, Step: 354/655, Loss: 2.203132, Accuracy: 19.15%\n",
            "Epoch: 17, Step: 355/655, Loss: 2.203011, Accuracy: 19.15%\n",
            "Epoch: 17, Step: 356/655, Loss: 2.203254, Accuracy: 19.14%\n",
            "Epoch: 17, Step: 357/655, Loss: 2.203309, Accuracy: 19.13%\n",
            "Epoch: 17, Step: 358/655, Loss: 2.203260, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 359/655, Loss: 2.203080, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 360/655, Loss: 2.203178, Accuracy: 19.09%\n",
            "Epoch: 17, Step: 361/655, Loss: 2.202878, Accuracy: 19.10%\n",
            "Epoch: 17, Step: 362/655, Loss: 2.203041, Accuracy: 19.09%\n",
            "Epoch: 17, Step: 363/655, Loss: 2.202749, Accuracy: 19.09%\n",
            "Epoch: 17, Step: 364/655, Loss: 2.202874, Accuracy: 19.10%\n",
            "Epoch: 17, Step: 365/655, Loss: 2.203455, Accuracy: 19.08%\n",
            "Epoch: 17, Step: 366/655, Loss: 2.203544, Accuracy: 19.10%\n",
            "Epoch: 17, Step: 367/655, Loss: 2.203797, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 368/655, Loss: 2.203904, Accuracy: 19.09%\n",
            "Epoch: 17, Step: 369/655, Loss: 2.203726, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 370/655, Loss: 2.203650, Accuracy: 19.10%\n",
            "Epoch: 17, Step: 371/655, Loss: 2.203378, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 372/655, Loss: 2.203330, Accuracy: 19.09%\n",
            "Epoch: 17, Step: 373/655, Loss: 2.203493, Accuracy: 19.10%\n",
            "Epoch: 17, Step: 374/655, Loss: 2.203775, Accuracy: 19.10%\n",
            "Epoch: 17, Step: 375/655, Loss: 2.203935, Accuracy: 19.09%\n",
            "Epoch: 17, Step: 376/655, Loss: 2.204035, Accuracy: 19.12%\n",
            "Epoch: 17, Step: 377/655, Loss: 2.203883, Accuracy: 19.13%\n",
            "Epoch: 17, Step: 378/655, Loss: 2.203977, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 379/655, Loss: 2.204164, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 380/655, Loss: 2.204118, Accuracy: 19.12%\n",
            "Epoch: 17, Step: 381/655, Loss: 2.204276, Accuracy: 19.09%\n",
            "Epoch: 17, Step: 382/655, Loss: 2.204327, Accuracy: 19.07%\n",
            "Epoch: 17, Step: 383/655, Loss: 2.204400, Accuracy: 19.08%\n",
            "Epoch: 17, Step: 384/655, Loss: 2.204407, Accuracy: 19.08%\n",
            "Epoch: 17, Step: 385/655, Loss: 2.204520, Accuracy: 19.07%\n",
            "Epoch: 17, Step: 386/655, Loss: 2.204648, Accuracy: 19.07%\n",
            "Epoch: 17, Step: 387/655, Loss: 2.204669, Accuracy: 19.05%\n",
            "Epoch: 17, Step: 388/655, Loss: 2.204427, Accuracy: 19.09%\n",
            "Epoch: 17, Step: 389/655, Loss: 2.204491, Accuracy: 19.07%\n",
            "Epoch: 17, Step: 390/655, Loss: 2.204315, Accuracy: 19.11%\n",
            "Epoch: 17, Step: 391/655, Loss: 2.204270, Accuracy: 19.10%\n",
            "Epoch: 17, Step: 392/655, Loss: 2.204010, Accuracy: 19.12%\n",
            "Epoch: 17, Step: 393/655, Loss: 2.204094, Accuracy: 19.10%\n",
            "Epoch: 17, Step: 394/655, Loss: 2.204210, Accuracy: 19.08%\n",
            "Epoch: 17, Step: 395/655, Loss: 2.204179, Accuracy: 19.08%\n",
            "Epoch: 17, Step: 396/655, Loss: 2.203976, Accuracy: 19.07%\n",
            "Epoch: 17, Step: 397/655, Loss: 2.203930, Accuracy: 19.06%\n",
            "Epoch: 17, Step: 398/655, Loss: 2.204077, Accuracy: 19.04%\n",
            "Epoch: 17, Step: 399/655, Loss: 2.204406, Accuracy: 19.03%\n",
            "Epoch: 17, Step: 400/655, Loss: 2.204297, Accuracy: 19.05%\n",
            "Epoch: 17, Step: 401/655, Loss: 2.204686, Accuracy: 19.03%\n",
            "Epoch: 17, Step: 402/655, Loss: 2.205031, Accuracy: 19.03%\n",
            "Epoch: 17, Step: 403/655, Loss: 2.205192, Accuracy: 19.01%\n",
            "Epoch: 17, Step: 404/655, Loss: 2.205122, Accuracy: 18.99%\n",
            "Epoch: 17, Step: 405/655, Loss: 2.205099, Accuracy: 18.98%\n",
            "Epoch: 17, Step: 406/655, Loss: 2.204860, Accuracy: 19.00%\n",
            "Epoch: 17, Step: 407/655, Loss: 2.204772, Accuracy: 19.03%\n",
            "Epoch: 17, Step: 408/655, Loss: 2.204987, Accuracy: 19.03%\n",
            "Epoch: 17, Step: 409/655, Loss: 2.204670, Accuracy: 19.03%\n",
            "Epoch: 17, Step: 410/655, Loss: 2.204422, Accuracy: 19.03%\n",
            "Epoch: 17, Step: 411/655, Loss: 2.204606, Accuracy: 19.02%\n",
            "Epoch: 17, Step: 412/655, Loss: 2.204800, Accuracy: 19.00%\n",
            "Epoch: 17, Step: 413/655, Loss: 2.204779, Accuracy: 18.98%\n",
            "Epoch: 17, Step: 414/655, Loss: 2.204835, Accuracy: 19.00%\n",
            "Epoch: 17, Step: 415/655, Loss: 2.204743, Accuracy: 19.01%\n",
            "Epoch: 17, Step: 416/655, Loss: 2.204754, Accuracy: 19.00%\n",
            "Epoch: 17, Step: 417/655, Loss: 2.205094, Accuracy: 18.98%\n",
            "Epoch: 17, Step: 418/655, Loss: 2.204935, Accuracy: 19.00%\n",
            "Epoch: 17, Step: 419/655, Loss: 2.205180, Accuracy: 18.98%\n",
            "Epoch: 17, Step: 420/655, Loss: 2.204933, Accuracy: 19.02%\n",
            "Epoch: 17, Step: 421/655, Loss: 2.204892, Accuracy: 19.02%\n",
            "Epoch: 17, Step: 422/655, Loss: 2.204503, Accuracy: 19.05%\n",
            "Epoch: 17, Step: 423/655, Loss: 2.204684, Accuracy: 19.04%\n",
            "Epoch: 17, Step: 424/655, Loss: 2.204668, Accuracy: 19.03%\n",
            "Epoch: 17, Step: 425/655, Loss: 2.204768, Accuracy: 19.03%\n",
            "Epoch: 17, Step: 426/655, Loss: 2.204833, Accuracy: 19.02%\n",
            "Epoch: 17, Step: 427/655, Loss: 2.204563, Accuracy: 19.02%\n",
            "Epoch: 17, Step: 428/655, Loss: 2.204598, Accuracy: 19.02%\n",
            "Epoch: 17, Step: 429/655, Loss: 2.204785, Accuracy: 19.01%\n",
            "Epoch: 17, Step: 430/655, Loss: 2.204584, Accuracy: 19.02%\n",
            "Epoch: 17, Step: 431/655, Loss: 2.204522, Accuracy: 19.04%\n",
            "Epoch: 17, Step: 432/655, Loss: 2.204438, Accuracy: 19.05%\n",
            "Epoch: 17, Step: 433/655, Loss: 2.204671, Accuracy: 19.02%\n",
            "Epoch: 17, Step: 434/655, Loss: 2.204971, Accuracy: 19.02%\n",
            "Epoch: 17, Step: 435/655, Loss: 2.205100, Accuracy: 19.03%\n",
            "Epoch: 17, Step: 436/655, Loss: 2.204965, Accuracy: 19.04%\n",
            "Epoch: 17, Step: 437/655, Loss: 2.204963, Accuracy: 19.04%\n",
            "Epoch: 17, Step: 438/655, Loss: 2.205091, Accuracy: 19.06%\n",
            "Epoch: 17, Step: 439/655, Loss: 2.205237, Accuracy: 19.06%\n",
            "Epoch: 17, Step: 440/655, Loss: 2.205553, Accuracy: 19.03%\n",
            "Epoch: 17, Step: 441/655, Loss: 2.205953, Accuracy: 19.00%\n",
            "Epoch: 17, Step: 442/655, Loss: 2.206028, Accuracy: 19.00%\n",
            "Epoch: 17, Step: 443/655, Loss: 2.206222, Accuracy: 18.98%\n",
            "Epoch: 17, Step: 444/655, Loss: 2.206355, Accuracy: 18.96%\n",
            "Epoch: 17, Step: 445/655, Loss: 2.206326, Accuracy: 18.95%\n",
            "Epoch: 17, Step: 446/655, Loss: 2.206424, Accuracy: 18.94%\n",
            "Epoch: 17, Step: 447/655, Loss: 2.206487, Accuracy: 18.93%\n",
            "Epoch: 17, Step: 448/655, Loss: 2.206424, Accuracy: 18.96%\n",
            "Epoch: 17, Step: 449/655, Loss: 2.206246, Accuracy: 18.98%\n",
            "Epoch: 17, Step: 450/655, Loss: 2.206564, Accuracy: 18.96%\n",
            "Epoch: 17, Step: 451/655, Loss: 2.206698, Accuracy: 18.95%\n",
            "Epoch: 17, Step: 452/655, Loss: 2.206886, Accuracy: 18.94%\n",
            "Epoch: 17, Step: 453/655, Loss: 2.206736, Accuracy: 18.95%\n",
            "Epoch: 17, Step: 454/655, Loss: 2.206819, Accuracy: 18.92%\n",
            "Epoch: 17, Step: 455/655, Loss: 2.206811, Accuracy: 18.92%\n",
            "Epoch: 17, Step: 456/655, Loss: 2.207094, Accuracy: 18.89%\n",
            "Epoch: 17, Step: 457/655, Loss: 2.207003, Accuracy: 18.87%\n",
            "Epoch: 17, Step: 458/655, Loss: 2.207197, Accuracy: 18.87%\n",
            "Epoch: 17, Step: 459/655, Loss: 2.207051, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 460/655, Loss: 2.207242, Accuracy: 18.82%\n",
            "Epoch: 17, Step: 461/655, Loss: 2.207064, Accuracy: 18.84%\n",
            "Epoch: 17, Step: 462/655, Loss: 2.206852, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 463/655, Loss: 2.206925, Accuracy: 18.82%\n",
            "Epoch: 17, Step: 464/655, Loss: 2.207034, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 465/655, Loss: 2.206952, Accuracy: 18.82%\n",
            "Epoch: 17, Step: 466/655, Loss: 2.206758, Accuracy: 18.82%\n",
            "Epoch: 17, Step: 467/655, Loss: 2.206812, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 468/655, Loss: 2.207010, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 469/655, Loss: 2.206888, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 470/655, Loss: 2.206906, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 471/655, Loss: 2.206976, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 472/655, Loss: 2.207078, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 473/655, Loss: 2.207226, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 474/655, Loss: 2.207077, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 475/655, Loss: 2.207010, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 476/655, Loss: 2.207212, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 477/655, Loss: 2.207245, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 478/655, Loss: 2.207279, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 479/655, Loss: 2.207554, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 480/655, Loss: 2.207595, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 481/655, Loss: 2.207682, Accuracy: 18.73%\n",
            "Epoch: 17, Step: 482/655, Loss: 2.207665, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 483/655, Loss: 2.207752, Accuracy: 18.72%\n",
            "Epoch: 17, Step: 484/655, Loss: 2.207609, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 485/655, Loss: 2.207554, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 486/655, Loss: 2.207823, Accuracy: 18.72%\n",
            "Epoch: 17, Step: 487/655, Loss: 2.207742, Accuracy: 18.72%\n",
            "Epoch: 17, Step: 488/655, Loss: 2.207690, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 489/655, Loss: 2.207832, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 490/655, Loss: 2.207935, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 491/655, Loss: 2.207570, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 492/655, Loss: 2.207279, Accuracy: 18.77%\n",
            "Epoch: 17, Step: 493/655, Loss: 2.207255, Accuracy: 18.77%\n",
            "Epoch: 17, Step: 494/655, Loss: 2.207588, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 495/655, Loss: 2.207662, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 496/655, Loss: 2.207889, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 497/655, Loss: 2.207778, Accuracy: 18.77%\n",
            "Epoch: 17, Step: 498/655, Loss: 2.207615, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 499/655, Loss: 2.207528, Accuracy: 18.77%\n",
            "Epoch: 17, Step: 500/655, Loss: 2.207588, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 501/655, Loss: 2.207500, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 502/655, Loss: 2.207455, Accuracy: 18.79%\n",
            "Epoch: 17, Step: 503/655, Loss: 2.207553, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 504/655, Loss: 2.207466, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 505/655, Loss: 2.207465, Accuracy: 18.77%\n",
            "Epoch: 17, Step: 506/655, Loss: 2.207630, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 507/655, Loss: 2.207655, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 508/655, Loss: 2.207625, Accuracy: 18.72%\n",
            "Epoch: 17, Step: 509/655, Loss: 2.207357, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 510/655, Loss: 2.207386, Accuracy: 18.73%\n",
            "Epoch: 17, Step: 511/655, Loss: 2.207374, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 512/655, Loss: 2.207607, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 513/655, Loss: 2.207469, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 514/655, Loss: 2.207524, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 515/655, Loss: 2.207385, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 516/655, Loss: 2.207174, Accuracy: 18.79%\n",
            "Epoch: 17, Step: 517/655, Loss: 2.207313, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 518/655, Loss: 2.207319, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 519/655, Loss: 2.207289, Accuracy: 18.73%\n",
            "Epoch: 17, Step: 520/655, Loss: 2.207344, Accuracy: 18.72%\n",
            "Epoch: 17, Step: 521/655, Loss: 2.207520, Accuracy: 18.71%\n",
            "Epoch: 17, Step: 522/655, Loss: 2.207456, Accuracy: 18.71%\n",
            "Epoch: 17, Step: 523/655, Loss: 2.207412, Accuracy: 18.71%\n",
            "Epoch: 17, Step: 524/655, Loss: 2.207394, Accuracy: 18.71%\n",
            "Epoch: 17, Step: 525/655, Loss: 2.207523, Accuracy: 18.71%\n",
            "Epoch: 17, Step: 526/655, Loss: 2.207387, Accuracy: 18.73%\n",
            "Epoch: 17, Step: 527/655, Loss: 2.207172, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 528/655, Loss: 2.207345, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 529/655, Loss: 2.207340, Accuracy: 18.73%\n",
            "Epoch: 17, Step: 530/655, Loss: 2.207229, Accuracy: 18.73%\n",
            "Epoch: 17, Step: 531/655, Loss: 2.207487, Accuracy: 18.73%\n",
            "Epoch: 17, Step: 532/655, Loss: 2.207639, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 533/655, Loss: 2.207501, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 534/655, Loss: 2.207309, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 535/655, Loss: 2.207600, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 536/655, Loss: 2.207610, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 537/655, Loss: 2.207446, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 538/655, Loss: 2.207585, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 539/655, Loss: 2.207486, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 540/655, Loss: 2.207534, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 541/655, Loss: 2.207352, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 542/655, Loss: 2.207549, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 543/655, Loss: 2.207803, Accuracy: 18.77%\n",
            "Epoch: 17, Step: 544/655, Loss: 2.207768, Accuracy: 18.79%\n",
            "Epoch: 17, Step: 545/655, Loss: 2.207628, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 546/655, Loss: 2.207656, Accuracy: 18.79%\n",
            "Epoch: 17, Step: 547/655, Loss: 2.207519, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 548/655, Loss: 2.207309, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 549/655, Loss: 2.207261, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 550/655, Loss: 2.207397, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 551/655, Loss: 2.207243, Accuracy: 18.79%\n",
            "Epoch: 17, Step: 552/655, Loss: 2.207147, Accuracy: 18.82%\n",
            "Epoch: 17, Step: 553/655, Loss: 2.207026, Accuracy: 18.81%\n",
            "Epoch: 17, Step: 554/655, Loss: 2.206958, Accuracy: 18.81%\n",
            "Epoch: 17, Step: 555/655, Loss: 2.206873, Accuracy: 18.81%\n",
            "Epoch: 17, Step: 556/655, Loss: 2.206821, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 557/655, Loss: 2.206866, Accuracy: 18.80%\n",
            "Epoch: 17, Step: 558/655, Loss: 2.206968, Accuracy: 18.79%\n",
            "Epoch: 17, Step: 559/655, Loss: 2.206837, Accuracy: 18.82%\n",
            "Epoch: 17, Step: 560/655, Loss: 2.206959, Accuracy: 18.82%\n",
            "Epoch: 17, Step: 561/655, Loss: 2.206816, Accuracy: 18.82%\n",
            "Epoch: 17, Step: 562/655, Loss: 2.206998, Accuracy: 18.82%\n",
            "Epoch: 17, Step: 563/655, Loss: 2.206952, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 564/655, Loss: 2.206895, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 565/655, Loss: 2.207115, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 566/655, Loss: 2.207028, Accuracy: 18.84%\n",
            "Epoch: 17, Step: 567/655, Loss: 2.206964, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 568/655, Loss: 2.207133, Accuracy: 18.84%\n",
            "Epoch: 17, Step: 569/655, Loss: 2.207138, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 570/655, Loss: 2.206877, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 571/655, Loss: 2.206952, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 572/655, Loss: 2.206746, Accuracy: 18.87%\n",
            "Epoch: 17, Step: 573/655, Loss: 2.206741, Accuracy: 18.89%\n",
            "Epoch: 17, Step: 574/655, Loss: 2.206742, Accuracy: 18.89%\n",
            "Epoch: 17, Step: 575/655, Loss: 2.206789, Accuracy: 18.90%\n",
            "Epoch: 17, Step: 576/655, Loss: 2.206798, Accuracy: 18.89%\n",
            "Epoch: 17, Step: 577/655, Loss: 2.206858, Accuracy: 18.89%\n",
            "Epoch: 17, Step: 578/655, Loss: 2.206849, Accuracy: 18.92%\n",
            "Epoch: 17, Step: 579/655, Loss: 2.206723, Accuracy: 18.93%\n",
            "Epoch: 17, Step: 580/655, Loss: 2.206970, Accuracy: 18.93%\n",
            "Epoch: 17, Step: 581/655, Loss: 2.206891, Accuracy: 18.92%\n",
            "Epoch: 17, Step: 582/655, Loss: 2.206979, Accuracy: 18.92%\n",
            "Epoch: 17, Step: 583/655, Loss: 2.207019, Accuracy: 18.90%\n",
            "Epoch: 17, Step: 584/655, Loss: 2.207068, Accuracy: 18.90%\n",
            "Epoch: 17, Step: 585/655, Loss: 2.207066, Accuracy: 18.89%\n",
            "Epoch: 17, Step: 586/655, Loss: 2.207244, Accuracy: 18.89%\n",
            "Epoch: 17, Step: 587/655, Loss: 2.207196, Accuracy: 18.88%\n",
            "Epoch: 17, Step: 588/655, Loss: 2.206849, Accuracy: 18.90%\n",
            "Epoch: 17, Step: 589/655, Loss: 2.206898, Accuracy: 18.90%\n",
            "Epoch: 17, Step: 590/655, Loss: 2.206964, Accuracy: 18.90%\n",
            "Epoch: 17, Step: 591/655, Loss: 2.206916, Accuracy: 18.89%\n",
            "Epoch: 17, Step: 592/655, Loss: 2.206980, Accuracy: 18.87%\n",
            "Epoch: 17, Step: 593/655, Loss: 2.206900, Accuracy: 18.86%\n",
            "Epoch: 17, Step: 594/655, Loss: 2.206780, Accuracy: 18.88%\n",
            "Epoch: 17, Step: 595/655, Loss: 2.206666, Accuracy: 18.86%\n",
            "Epoch: 17, Step: 596/655, Loss: 2.206726, Accuracy: 18.86%\n",
            "Epoch: 17, Step: 597/655, Loss: 2.206663, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 598/655, Loss: 2.206641, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 599/655, Loss: 2.206464, Accuracy: 18.87%\n",
            "Epoch: 17, Step: 600/655, Loss: 2.206541, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 601/655, Loss: 2.206677, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 602/655, Loss: 2.206946, Accuracy: 18.82%\n",
            "Epoch: 17, Step: 603/655, Loss: 2.207074, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 604/655, Loss: 2.206886, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 605/655, Loss: 2.206860, Accuracy: 18.87%\n",
            "Epoch: 17, Step: 606/655, Loss: 2.206845, Accuracy: 18.87%\n",
            "Epoch: 17, Step: 607/655, Loss: 2.206674, Accuracy: 18.88%\n",
            "Epoch: 17, Step: 608/655, Loss: 2.206680, Accuracy: 18.88%\n",
            "Epoch: 17, Step: 609/655, Loss: 2.206733, Accuracy: 18.88%\n",
            "Epoch: 17, Step: 610/655, Loss: 2.206849, Accuracy: 18.86%\n",
            "Epoch: 17, Step: 611/655, Loss: 2.207043, Accuracy: 18.87%\n",
            "Epoch: 17, Step: 612/655, Loss: 2.207025, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 613/655, Loss: 2.207064, Accuracy: 18.85%\n",
            "Epoch: 17, Step: 614/655, Loss: 2.207258, Accuracy: 18.82%\n",
            "Epoch: 17, Step: 615/655, Loss: 2.207164, Accuracy: 18.83%\n",
            "Epoch: 17, Step: 616/655, Loss: 2.207502, Accuracy: 18.81%\n",
            "Epoch: 17, Step: 617/655, Loss: 2.207583, Accuracy: 18.81%\n",
            "Epoch: 17, Step: 618/655, Loss: 2.207598, Accuracy: 18.79%\n",
            "Epoch: 17, Step: 619/655, Loss: 2.207560, Accuracy: 18.79%\n",
            "Epoch: 17, Step: 620/655, Loss: 2.207542, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 621/655, Loss: 2.207622, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 622/655, Loss: 2.207637, Accuracy: 18.77%\n",
            "Epoch: 17, Step: 623/655, Loss: 2.207678, Accuracy: 18.77%\n",
            "Epoch: 17, Step: 624/655, Loss: 2.207661, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 625/655, Loss: 2.207637, Accuracy: 18.77%\n",
            "Epoch: 17, Step: 626/655, Loss: 2.207670, Accuracy: 18.79%\n",
            "Epoch: 17, Step: 627/655, Loss: 2.207636, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 628/655, Loss: 2.207498, Accuracy: 18.79%\n",
            "Epoch: 17, Step: 629/655, Loss: 2.207544, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 630/655, Loss: 2.207572, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 631/655, Loss: 2.207400, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 632/655, Loss: 2.207358, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 633/655, Loss: 2.207312, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 634/655, Loss: 2.207186, Accuracy: 18.77%\n",
            "Epoch: 17, Step: 635/655, Loss: 2.207411, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 636/655, Loss: 2.207527, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 637/655, Loss: 2.207457, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 638/655, Loss: 2.207402, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 639/655, Loss: 2.207455, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 640/655, Loss: 2.207456, Accuracy: 18.78%\n",
            "Epoch: 17, Step: 641/655, Loss: 2.207654, Accuracy: 18.76%\n",
            "Epoch: 17, Step: 642/655, Loss: 2.207620, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 643/655, Loss: 2.207753, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 644/655, Loss: 2.207884, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 645/655, Loss: 2.207890, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 646/655, Loss: 2.208132, Accuracy: 18.73%\n",
            "Epoch: 17, Step: 647/655, Loss: 2.208210, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 648/655, Loss: 2.208108, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 649/655, Loss: 2.208021, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 650/655, Loss: 2.207763, Accuracy: 18.74%\n",
            "Epoch: 17, Step: 651/655, Loss: 2.207881, Accuracy: 18.73%\n",
            "Epoch: 17, Step: 652/655, Loss: 2.207749, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 653/655, Loss: 2.207720, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 654/655, Loss: 2.207731, Accuracy: 18.75%\n",
            "Epoch: 17, Step: 655/655, Loss: 2.208123, Accuracy: 18.75%\n",
            "Epoch: 18, Step: 1/655, Loss: 2.141029, Accuracy: 15.62%\n",
            "Epoch: 18, Step: 2/655, Loss: 2.215149, Accuracy: 12.50%\n",
            "Epoch: 18, Step: 3/655, Loss: 2.240895, Accuracy: 13.54%\n",
            "Epoch: 18, Step: 4/655, Loss: 2.203667, Accuracy: 17.97%\n",
            "Epoch: 18, Step: 5/655, Loss: 2.197337, Accuracy: 18.75%\n",
            "Epoch: 18, Step: 6/655, Loss: 2.193257, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 7/655, Loss: 2.207965, Accuracy: 16.96%\n",
            "Epoch: 18, Step: 8/655, Loss: 2.206808, Accuracy: 16.80%\n",
            "Epoch: 18, Step: 9/655, Loss: 2.189280, Accuracy: 17.71%\n",
            "Epoch: 18, Step: 10/655, Loss: 2.200400, Accuracy: 17.50%\n",
            "Epoch: 18, Step: 11/655, Loss: 2.197194, Accuracy: 18.47%\n",
            "Epoch: 18, Step: 12/655, Loss: 2.188900, Accuracy: 19.01%\n",
            "Epoch: 18, Step: 13/655, Loss: 2.202774, Accuracy: 17.79%\n",
            "Epoch: 18, Step: 14/655, Loss: 2.196947, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 15/655, Loss: 2.195934, Accuracy: 17.50%\n",
            "Epoch: 18, Step: 16/655, Loss: 2.196649, Accuracy: 17.77%\n",
            "Epoch: 18, Step: 17/655, Loss: 2.195564, Accuracy: 18.38%\n",
            "Epoch: 18, Step: 18/655, Loss: 2.199473, Accuracy: 18.58%\n",
            "Epoch: 18, Step: 19/655, Loss: 2.199253, Accuracy: 18.75%\n",
            "Epoch: 18, Step: 20/655, Loss: 2.197544, Accuracy: 18.59%\n",
            "Epoch: 18, Step: 21/655, Loss: 2.201911, Accuracy: 18.30%\n",
            "Epoch: 18, Step: 22/655, Loss: 2.206218, Accuracy: 18.61%\n",
            "Epoch: 18, Step: 23/655, Loss: 2.206902, Accuracy: 18.48%\n",
            "Epoch: 18, Step: 24/655, Loss: 2.210762, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 25/655, Loss: 2.213341, Accuracy: 17.88%\n",
            "Epoch: 18, Step: 26/655, Loss: 2.213300, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 27/655, Loss: 2.210685, Accuracy: 18.29%\n",
            "Epoch: 18, Step: 28/655, Loss: 2.210005, Accuracy: 18.64%\n",
            "Epoch: 18, Step: 29/655, Loss: 2.211309, Accuracy: 18.64%\n",
            "Epoch: 18, Step: 30/655, Loss: 2.207837, Accuracy: 18.65%\n",
            "Epoch: 18, Step: 31/655, Loss: 2.205526, Accuracy: 18.95%\n",
            "Epoch: 18, Step: 32/655, Loss: 2.202317, Accuracy: 19.24%\n",
            "Epoch: 18, Step: 33/655, Loss: 2.203515, Accuracy: 18.94%\n",
            "Epoch: 18, Step: 34/655, Loss: 2.205092, Accuracy: 19.03%\n",
            "Epoch: 18, Step: 35/655, Loss: 2.205447, Accuracy: 18.84%\n",
            "Epoch: 18, Step: 36/655, Loss: 2.205203, Accuracy: 18.92%\n",
            "Epoch: 18, Step: 37/655, Loss: 2.206325, Accuracy: 18.92%\n",
            "Epoch: 18, Step: 38/655, Loss: 2.209668, Accuracy: 18.75%\n",
            "Epoch: 18, Step: 39/655, Loss: 2.208069, Accuracy: 18.75%\n",
            "Epoch: 18, Step: 40/655, Loss: 2.203514, Accuracy: 18.83%\n",
            "Epoch: 18, Step: 41/655, Loss: 2.200611, Accuracy: 18.98%\n",
            "Epoch: 18, Step: 42/655, Loss: 2.197699, Accuracy: 18.97%\n",
            "Epoch: 18, Step: 43/655, Loss: 2.198807, Accuracy: 19.04%\n",
            "Epoch: 18, Step: 44/655, Loss: 2.198363, Accuracy: 18.96%\n",
            "Epoch: 18, Step: 45/655, Loss: 2.200283, Accuracy: 19.17%\n",
            "Epoch: 18, Step: 46/655, Loss: 2.202625, Accuracy: 19.02%\n",
            "Epoch: 18, Step: 47/655, Loss: 2.201789, Accuracy: 19.35%\n",
            "Epoch: 18, Step: 48/655, Loss: 2.200744, Accuracy: 19.21%\n",
            "Epoch: 18, Step: 49/655, Loss: 2.200777, Accuracy: 19.26%\n",
            "Epoch: 18, Step: 50/655, Loss: 2.202712, Accuracy: 19.12%\n",
            "Epoch: 18, Step: 51/655, Loss: 2.200474, Accuracy: 19.36%\n",
            "Epoch: 18, Step: 52/655, Loss: 2.200473, Accuracy: 19.41%\n",
            "Epoch: 18, Step: 53/655, Loss: 2.201888, Accuracy: 19.16%\n",
            "Epoch: 18, Step: 54/655, Loss: 2.201536, Accuracy: 19.16%\n",
            "Epoch: 18, Step: 55/655, Loss: 2.202680, Accuracy: 19.15%\n",
            "Epoch: 18, Step: 56/655, Loss: 2.201944, Accuracy: 19.08%\n",
            "Epoch: 18, Step: 57/655, Loss: 2.203380, Accuracy: 18.91%\n",
            "Epoch: 18, Step: 58/655, Loss: 2.203742, Accuracy: 18.75%\n",
            "Epoch: 18, Step: 59/655, Loss: 2.200449, Accuracy: 18.91%\n",
            "Epoch: 18, Step: 60/655, Loss: 2.200086, Accuracy: 18.70%\n",
            "Epoch: 18, Step: 61/655, Loss: 2.201509, Accuracy: 18.75%\n",
            "Epoch: 18, Step: 62/655, Loss: 2.201627, Accuracy: 18.75%\n",
            "Epoch: 18, Step: 63/655, Loss: 2.200767, Accuracy: 18.70%\n",
            "Epoch: 18, Step: 64/655, Loss: 2.203183, Accuracy: 18.60%\n",
            "Epoch: 18, Step: 65/655, Loss: 2.204694, Accuracy: 18.46%\n",
            "Epoch: 18, Step: 66/655, Loss: 2.202957, Accuracy: 18.51%\n",
            "Epoch: 18, Step: 67/655, Loss: 2.201755, Accuracy: 18.61%\n",
            "Epoch: 18, Step: 68/655, Loss: 2.202432, Accuracy: 18.61%\n",
            "Epoch: 18, Step: 69/655, Loss: 2.202278, Accuracy: 18.52%\n",
            "Epoch: 18, Step: 70/655, Loss: 2.203249, Accuracy: 18.39%\n",
            "Epoch: 18, Step: 71/655, Loss: 2.203980, Accuracy: 18.31%\n",
            "Epoch: 18, Step: 72/655, Loss: 2.204664, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 73/655, Loss: 2.205197, Accuracy: 18.36%\n",
            "Epoch: 18, Step: 74/655, Loss: 2.204363, Accuracy: 18.50%\n",
            "Epoch: 18, Step: 75/655, Loss: 2.203592, Accuracy: 18.62%\n",
            "Epoch: 18, Step: 76/655, Loss: 2.203190, Accuracy: 18.54%\n",
            "Epoch: 18, Step: 77/655, Loss: 2.203382, Accuracy: 18.59%\n",
            "Epoch: 18, Step: 78/655, Loss: 2.202986, Accuracy: 18.67%\n",
            "Epoch: 18, Step: 79/655, Loss: 2.200932, Accuracy: 18.75%\n",
            "Epoch: 18, Step: 80/655, Loss: 2.199416, Accuracy: 18.87%\n",
            "Epoch: 18, Step: 81/655, Loss: 2.200439, Accuracy: 18.90%\n",
            "Epoch: 18, Step: 82/655, Loss: 2.201122, Accuracy: 18.94%\n",
            "Epoch: 18, Step: 83/655, Loss: 2.202153, Accuracy: 18.90%\n",
            "Epoch: 18, Step: 84/655, Loss: 2.201142, Accuracy: 18.79%\n",
            "Epoch: 18, Step: 85/655, Loss: 2.201842, Accuracy: 18.82%\n",
            "Epoch: 18, Step: 86/655, Loss: 2.199896, Accuracy: 18.93%\n",
            "Epoch: 18, Step: 87/655, Loss: 2.199358, Accuracy: 18.97%\n",
            "Epoch: 18, Step: 88/655, Loss: 2.199466, Accuracy: 19.07%\n",
            "Epoch: 18, Step: 89/655, Loss: 2.198385, Accuracy: 19.10%\n",
            "Epoch: 18, Step: 90/655, Loss: 2.196971, Accuracy: 19.17%\n",
            "Epoch: 18, Step: 91/655, Loss: 2.196852, Accuracy: 19.20%\n",
            "Epoch: 18, Step: 92/655, Loss: 2.197452, Accuracy: 19.26%\n",
            "Epoch: 18, Step: 93/655, Loss: 2.197633, Accuracy: 19.25%\n",
            "Epoch: 18, Step: 94/655, Loss: 2.197000, Accuracy: 19.28%\n",
            "Epoch: 18, Step: 95/655, Loss: 2.197789, Accuracy: 19.21%\n",
            "Epoch: 18, Step: 96/655, Loss: 2.197243, Accuracy: 19.14%\n",
            "Epoch: 18, Step: 97/655, Loss: 2.196899, Accuracy: 19.07%\n",
            "Epoch: 18, Step: 98/655, Loss: 2.198520, Accuracy: 19.01%\n",
            "Epoch: 18, Step: 99/655, Loss: 2.198718, Accuracy: 18.91%\n",
            "Epoch: 18, Step: 100/655, Loss: 2.198852, Accuracy: 18.88%\n",
            "Epoch: 18, Step: 101/655, Loss: 2.200603, Accuracy: 18.75%\n",
            "Epoch: 18, Step: 102/655, Loss: 2.200681, Accuracy: 18.75%\n",
            "Epoch: 18, Step: 103/655, Loss: 2.200357, Accuracy: 18.81%\n",
            "Epoch: 18, Step: 104/655, Loss: 2.200287, Accuracy: 18.90%\n",
            "Epoch: 18, Step: 105/655, Loss: 2.200936, Accuracy: 18.84%\n",
            "Epoch: 18, Step: 106/655, Loss: 2.199718, Accuracy: 18.96%\n",
            "Epoch: 18, Step: 107/655, Loss: 2.199563, Accuracy: 18.84%\n",
            "Epoch: 18, Step: 108/655, Loss: 2.199663, Accuracy: 18.87%\n",
            "Epoch: 18, Step: 109/655, Loss: 2.199062, Accuracy: 18.86%\n",
            "Epoch: 18, Step: 110/655, Loss: 2.198516, Accuracy: 18.92%\n",
            "Epoch: 18, Step: 111/655, Loss: 2.198463, Accuracy: 18.95%\n",
            "Epoch: 18, Step: 112/655, Loss: 2.197434, Accuracy: 19.00%\n",
            "Epoch: 18, Step: 113/655, Loss: 2.196437, Accuracy: 19.08%\n",
            "Epoch: 18, Step: 114/655, Loss: 2.196367, Accuracy: 19.00%\n",
            "Epoch: 18, Step: 115/655, Loss: 2.195854, Accuracy: 19.08%\n",
            "Epoch: 18, Step: 116/655, Loss: 2.195863, Accuracy: 19.02%\n",
            "Epoch: 18, Step: 117/655, Loss: 2.195604, Accuracy: 18.99%\n",
            "Epoch: 18, Step: 118/655, Loss: 2.195376, Accuracy: 19.09%\n",
            "Epoch: 18, Step: 119/655, Loss: 2.196047, Accuracy: 19.09%\n",
            "Epoch: 18, Step: 120/655, Loss: 2.196165, Accuracy: 19.06%\n",
            "Epoch: 18, Step: 121/655, Loss: 2.196954, Accuracy: 18.98%\n",
            "Epoch: 18, Step: 122/655, Loss: 2.197229, Accuracy: 18.93%\n",
            "Epoch: 18, Step: 123/655, Loss: 2.197048, Accuracy: 18.98%\n",
            "Epoch: 18, Step: 124/655, Loss: 2.196932, Accuracy: 18.98%\n",
            "Epoch: 18, Step: 125/655, Loss: 2.195933, Accuracy: 18.95%\n",
            "Epoch: 18, Step: 126/655, Loss: 2.195350, Accuracy: 18.97%\n",
            "Epoch: 18, Step: 127/655, Loss: 2.195141, Accuracy: 19.00%\n",
            "Epoch: 18, Step: 128/655, Loss: 2.195117, Accuracy: 19.04%\n",
            "Epoch: 18, Step: 129/655, Loss: 2.195624, Accuracy: 18.99%\n",
            "Epoch: 18, Step: 130/655, Loss: 2.196191, Accuracy: 18.94%\n",
            "Epoch: 18, Step: 131/655, Loss: 2.195757, Accuracy: 18.96%\n",
            "Epoch: 18, Step: 132/655, Loss: 2.195582, Accuracy: 18.94%\n",
            "Epoch: 18, Step: 133/655, Loss: 2.196338, Accuracy: 18.89%\n",
            "Epoch: 18, Step: 134/655, Loss: 2.196482, Accuracy: 18.84%\n",
            "Epoch: 18, Step: 135/655, Loss: 2.196339, Accuracy: 18.91%\n",
            "Epoch: 18, Step: 136/655, Loss: 2.197063, Accuracy: 18.96%\n",
            "Epoch: 18, Step: 137/655, Loss: 2.196136, Accuracy: 18.98%\n",
            "Epoch: 18, Step: 138/655, Loss: 2.196950, Accuracy: 18.91%\n",
            "Epoch: 18, Step: 139/655, Loss: 2.196535, Accuracy: 18.95%\n",
            "Epoch: 18, Step: 140/655, Loss: 2.196115, Accuracy: 18.91%\n",
            "Epoch: 18, Step: 141/655, Loss: 2.196748, Accuracy: 18.88%\n",
            "Epoch: 18, Step: 142/655, Loss: 2.197760, Accuracy: 18.77%\n",
            "Epoch: 18, Step: 143/655, Loss: 2.197906, Accuracy: 18.75%\n",
            "Epoch: 18, Step: 144/655, Loss: 2.197896, Accuracy: 18.66%\n",
            "Epoch: 18, Step: 145/655, Loss: 2.199457, Accuracy: 18.64%\n",
            "Epoch: 18, Step: 146/655, Loss: 2.198654, Accuracy: 18.62%\n",
            "Epoch: 18, Step: 147/655, Loss: 2.198437, Accuracy: 18.69%\n",
            "Epoch: 18, Step: 148/655, Loss: 2.198321, Accuracy: 18.64%\n",
            "Epoch: 18, Step: 149/655, Loss: 2.198660, Accuracy: 18.62%\n",
            "Epoch: 18, Step: 150/655, Loss: 2.199315, Accuracy: 18.58%\n",
            "Epoch: 18, Step: 151/655, Loss: 2.199164, Accuracy: 18.58%\n",
            "Epoch: 18, Step: 152/655, Loss: 2.199380, Accuracy: 18.56%\n",
            "Epoch: 18, Step: 153/655, Loss: 2.199633, Accuracy: 18.57%\n",
            "Epoch: 18, Step: 154/655, Loss: 2.199127, Accuracy: 18.59%\n",
            "Epoch: 18, Step: 155/655, Loss: 2.198826, Accuracy: 18.59%\n",
            "Epoch: 18, Step: 156/655, Loss: 2.199938, Accuracy: 18.55%\n",
            "Epoch: 18, Step: 157/655, Loss: 2.199605, Accuracy: 18.55%\n",
            "Epoch: 18, Step: 158/655, Loss: 2.198355, Accuracy: 18.57%\n",
            "Epoch: 18, Step: 159/655, Loss: 2.198832, Accuracy: 18.53%\n",
            "Epoch: 18, Step: 160/655, Loss: 2.198728, Accuracy: 18.55%\n",
            "Epoch: 18, Step: 161/655, Loss: 2.198802, Accuracy: 18.61%\n",
            "Epoch: 18, Step: 162/655, Loss: 2.199061, Accuracy: 18.63%\n",
            "Epoch: 18, Step: 163/655, Loss: 2.199179, Accuracy: 18.63%\n",
            "Epoch: 18, Step: 164/655, Loss: 2.199669, Accuracy: 18.62%\n",
            "Epoch: 18, Step: 165/655, Loss: 2.200191, Accuracy: 18.60%\n",
            "Epoch: 18, Step: 166/655, Loss: 2.201190, Accuracy: 18.56%\n",
            "Epoch: 18, Step: 167/655, Loss: 2.201275, Accuracy: 18.54%\n",
            "Epoch: 18, Step: 168/655, Loss: 2.200806, Accuracy: 18.56%\n",
            "Epoch: 18, Step: 169/655, Loss: 2.200608, Accuracy: 18.58%\n",
            "Epoch: 18, Step: 170/655, Loss: 2.200297, Accuracy: 18.57%\n",
            "Epoch: 18, Step: 171/655, Loss: 2.200070, Accuracy: 18.53%\n",
            "Epoch: 18, Step: 172/655, Loss: 2.200245, Accuracy: 18.51%\n",
            "Epoch: 18, Step: 173/655, Loss: 2.200945, Accuracy: 18.50%\n",
            "Epoch: 18, Step: 174/655, Loss: 2.201358, Accuracy: 18.48%\n",
            "Epoch: 18, Step: 175/655, Loss: 2.201671, Accuracy: 18.46%\n",
            "Epoch: 18, Step: 176/655, Loss: 2.201501, Accuracy: 18.45%\n",
            "Epoch: 18, Step: 177/655, Loss: 2.202062, Accuracy: 18.49%\n",
            "Epoch: 18, Step: 178/655, Loss: 2.201614, Accuracy: 18.56%\n",
            "Epoch: 18, Step: 179/655, Loss: 2.201760, Accuracy: 18.52%\n",
            "Epoch: 18, Step: 180/655, Loss: 2.202442, Accuracy: 18.45%\n",
            "Epoch: 18, Step: 181/655, Loss: 2.202833, Accuracy: 18.44%\n",
            "Epoch: 18, Step: 182/655, Loss: 2.203244, Accuracy: 18.44%\n",
            "Epoch: 18, Step: 183/655, Loss: 2.203365, Accuracy: 18.46%\n",
            "Epoch: 18, Step: 184/655, Loss: 2.203355, Accuracy: 18.51%\n",
            "Epoch: 18, Step: 185/655, Loss: 2.203234, Accuracy: 18.50%\n",
            "Epoch: 18, Step: 186/655, Loss: 2.203853, Accuracy: 18.50%\n",
            "Epoch: 18, Step: 187/655, Loss: 2.203174, Accuracy: 18.57%\n",
            "Epoch: 18, Step: 188/655, Loss: 2.203293, Accuracy: 18.57%\n",
            "Epoch: 18, Step: 189/655, Loss: 2.202771, Accuracy: 18.60%\n",
            "Epoch: 18, Step: 190/655, Loss: 2.203177, Accuracy: 18.62%\n",
            "Epoch: 18, Step: 191/655, Loss: 2.203118, Accuracy: 18.67%\n",
            "Epoch: 18, Step: 192/655, Loss: 2.202489, Accuracy: 18.70%\n",
            "Epoch: 18, Step: 193/655, Loss: 2.202390, Accuracy: 18.67%\n",
            "Epoch: 18, Step: 194/655, Loss: 2.202710, Accuracy: 18.72%\n",
            "Epoch: 18, Step: 195/655, Loss: 2.202532, Accuracy: 18.75%\n",
            "Epoch: 18, Step: 196/655, Loss: 2.202783, Accuracy: 18.73%\n",
            "Epoch: 18, Step: 197/655, Loss: 2.202914, Accuracy: 18.75%\n",
            "Epoch: 18, Step: 198/655, Loss: 2.203101, Accuracy: 18.78%\n",
            "Epoch: 18, Step: 199/655, Loss: 2.202833, Accuracy: 18.77%\n",
            "Epoch: 18, Step: 200/655, Loss: 2.202878, Accuracy: 18.80%\n",
            "Epoch: 18, Step: 201/655, Loss: 2.203314, Accuracy: 18.73%\n",
            "Epoch: 18, Step: 202/655, Loss: 2.203847, Accuracy: 18.70%\n",
            "Epoch: 18, Step: 203/655, Loss: 2.203929, Accuracy: 18.66%\n",
            "Epoch: 18, Step: 204/655, Loss: 2.204457, Accuracy: 18.60%\n",
            "Epoch: 18, Step: 205/655, Loss: 2.203806, Accuracy: 18.64%\n",
            "Epoch: 18, Step: 206/655, Loss: 2.203723, Accuracy: 18.64%\n",
            "Epoch: 18, Step: 207/655, Loss: 2.203552, Accuracy: 18.63%\n",
            "Epoch: 18, Step: 208/655, Loss: 2.203318, Accuracy: 18.58%\n",
            "Epoch: 18, Step: 209/655, Loss: 2.204000, Accuracy: 18.54%\n",
            "Epoch: 18, Step: 210/655, Loss: 2.204236, Accuracy: 18.57%\n",
            "Epoch: 18, Step: 211/655, Loss: 2.204392, Accuracy: 18.59%\n",
            "Epoch: 18, Step: 212/655, Loss: 2.203952, Accuracy: 18.56%\n",
            "Epoch: 18, Step: 213/655, Loss: 2.204615, Accuracy: 18.59%\n",
            "Epoch: 18, Step: 214/655, Loss: 2.203799, Accuracy: 18.59%\n",
            "Epoch: 18, Step: 215/655, Loss: 2.204018, Accuracy: 18.55%\n",
            "Epoch: 18, Step: 216/655, Loss: 2.204556, Accuracy: 18.49%\n",
            "Epoch: 18, Step: 217/655, Loss: 2.204302, Accuracy: 18.49%\n",
            "Epoch: 18, Step: 218/655, Loss: 2.205384, Accuracy: 18.43%\n",
            "Epoch: 18, Step: 219/655, Loss: 2.205066, Accuracy: 18.45%\n",
            "Epoch: 18, Step: 220/655, Loss: 2.204566, Accuracy: 18.49%\n",
            "Epoch: 18, Step: 221/655, Loss: 2.204249, Accuracy: 18.54%\n",
            "Epoch: 18, Step: 222/655, Loss: 2.205083, Accuracy: 18.51%\n",
            "Epoch: 18, Step: 223/655, Loss: 2.205139, Accuracy: 18.48%\n",
            "Epoch: 18, Step: 224/655, Loss: 2.205679, Accuracy: 18.46%\n",
            "Epoch: 18, Step: 225/655, Loss: 2.204827, Accuracy: 18.47%\n",
            "Epoch: 18, Step: 226/655, Loss: 2.205037, Accuracy: 18.45%\n",
            "Epoch: 18, Step: 227/655, Loss: 2.205375, Accuracy: 18.42%\n",
            "Epoch: 18, Step: 228/655, Loss: 2.205540, Accuracy: 18.39%\n",
            "Epoch: 18, Step: 229/655, Loss: 2.205173, Accuracy: 18.38%\n",
            "Epoch: 18, Step: 230/655, Loss: 2.205342, Accuracy: 18.33%\n",
            "Epoch: 18, Step: 231/655, Loss: 2.205366, Accuracy: 18.32%\n",
            "Epoch: 18, Step: 232/655, Loss: 2.205563, Accuracy: 18.32%\n",
            "Epoch: 18, Step: 233/655, Loss: 2.205118, Accuracy: 18.32%\n",
            "Epoch: 18, Step: 234/655, Loss: 2.205287, Accuracy: 18.32%\n",
            "Epoch: 18, Step: 235/655, Loss: 2.205632, Accuracy: 18.31%\n",
            "Epoch: 18, Step: 236/655, Loss: 2.205998, Accuracy: 18.33%\n",
            "Epoch: 18, Step: 237/655, Loss: 2.206035, Accuracy: 18.31%\n",
            "Epoch: 18, Step: 238/655, Loss: 2.206351, Accuracy: 18.30%\n",
            "Epoch: 18, Step: 239/655, Loss: 2.206872, Accuracy: 18.32%\n",
            "Epoch: 18, Step: 240/655, Loss: 2.205989, Accuracy: 18.35%\n",
            "Epoch: 18, Step: 241/655, Loss: 2.205642, Accuracy: 18.36%\n",
            "Epoch: 18, Step: 242/655, Loss: 2.205480, Accuracy: 18.38%\n",
            "Epoch: 18, Step: 243/655, Loss: 2.205787, Accuracy: 18.35%\n",
            "Epoch: 18, Step: 244/655, Loss: 2.206181, Accuracy: 18.35%\n",
            "Epoch: 18, Step: 245/655, Loss: 2.206685, Accuracy: 18.32%\n",
            "Epoch: 18, Step: 246/655, Loss: 2.206623, Accuracy: 18.36%\n",
            "Epoch: 18, Step: 247/655, Loss: 2.206904, Accuracy: 18.33%\n",
            "Epoch: 18, Step: 248/655, Loss: 2.206912, Accuracy: 18.31%\n",
            "Epoch: 18, Step: 249/655, Loss: 2.207162, Accuracy: 18.29%\n",
            "Epoch: 18, Step: 250/655, Loss: 2.207416, Accuracy: 18.26%\n",
            "Epoch: 18, Step: 251/655, Loss: 2.206649, Accuracy: 18.33%\n",
            "Epoch: 18, Step: 252/655, Loss: 2.206912, Accuracy: 18.30%\n",
            "Epoch: 18, Step: 253/655, Loss: 2.206573, Accuracy: 18.28%\n",
            "Epoch: 18, Step: 254/655, Loss: 2.206533, Accuracy: 18.29%\n",
            "Epoch: 18, Step: 255/655, Loss: 2.205890, Accuracy: 18.31%\n",
            "Epoch: 18, Step: 256/655, Loss: 2.206167, Accuracy: 18.29%\n",
            "Epoch: 18, Step: 257/655, Loss: 2.206219, Accuracy: 18.25%\n",
            "Epoch: 18, Step: 258/655, Loss: 2.206113, Accuracy: 18.22%\n",
            "Epoch: 18, Step: 259/655, Loss: 2.206351, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 260/655, Loss: 2.206160, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 261/655, Loss: 2.205805, Accuracy: 18.26%\n",
            "Epoch: 18, Step: 262/655, Loss: 2.205696, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 263/655, Loss: 2.205756, Accuracy: 18.25%\n",
            "Epoch: 18, Step: 264/655, Loss: 2.205900, Accuracy: 18.25%\n",
            "Epoch: 18, Step: 265/655, Loss: 2.205953, Accuracy: 18.22%\n",
            "Epoch: 18, Step: 266/655, Loss: 2.205934, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 267/655, Loss: 2.205949, Accuracy: 18.22%\n",
            "Epoch: 18, Step: 268/655, Loss: 2.205933, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 269/655, Loss: 2.206153, Accuracy: 18.25%\n",
            "Epoch: 18, Step: 270/655, Loss: 2.205760, Accuracy: 18.28%\n",
            "Epoch: 18, Step: 271/655, Loss: 2.205786, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 272/655, Loss: 2.205621, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 273/655, Loss: 2.205375, Accuracy: 18.22%\n",
            "Epoch: 18, Step: 274/655, Loss: 2.205574, Accuracy: 18.21%\n",
            "Epoch: 18, Step: 275/655, Loss: 2.205677, Accuracy: 18.24%\n",
            "Epoch: 18, Step: 276/655, Loss: 2.205515, Accuracy: 18.24%\n",
            "Epoch: 18, Step: 277/655, Loss: 2.205751, Accuracy: 18.21%\n",
            "Epoch: 18, Step: 278/655, Loss: 2.206103, Accuracy: 18.18%\n",
            "Epoch: 18, Step: 279/655, Loss: 2.206199, Accuracy: 18.19%\n",
            "Epoch: 18, Step: 280/655, Loss: 2.206329, Accuracy: 18.19%\n",
            "Epoch: 18, Step: 281/655, Loss: 2.206489, Accuracy: 18.16%\n",
            "Epoch: 18, Step: 282/655, Loss: 2.206501, Accuracy: 18.14%\n",
            "Epoch: 18, Step: 283/655, Loss: 2.206511, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 284/655, Loss: 2.206603, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 285/655, Loss: 2.206859, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 286/655, Loss: 2.206962, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 287/655, Loss: 2.206629, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 288/655, Loss: 2.206656, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 289/655, Loss: 2.206602, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 290/655, Loss: 2.206832, Accuracy: 18.15%\n",
            "Epoch: 18, Step: 291/655, Loss: 2.206957, Accuracy: 18.16%\n",
            "Epoch: 18, Step: 292/655, Loss: 2.206611, Accuracy: 18.16%\n",
            "Epoch: 18, Step: 293/655, Loss: 2.206853, Accuracy: 18.14%\n",
            "Epoch: 18, Step: 294/655, Loss: 2.206749, Accuracy: 18.14%\n",
            "Epoch: 18, Step: 295/655, Loss: 2.206948, Accuracy: 18.14%\n",
            "Epoch: 18, Step: 296/655, Loss: 2.206665, Accuracy: 18.15%\n",
            "Epoch: 18, Step: 297/655, Loss: 2.206926, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 298/655, Loss: 2.207033, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 299/655, Loss: 2.206996, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 300/655, Loss: 2.206826, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 301/655, Loss: 2.206616, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 302/655, Loss: 2.206679, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 303/655, Loss: 2.206725, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 304/655, Loss: 2.206771, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 305/655, Loss: 2.206629, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 306/655, Loss: 2.206450, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 307/655, Loss: 2.206244, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 308/655, Loss: 2.205971, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 309/655, Loss: 2.205772, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 310/655, Loss: 2.205862, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 311/655, Loss: 2.206305, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 312/655, Loss: 2.206490, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 313/655, Loss: 2.206378, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 314/655, Loss: 2.206441, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 315/655, Loss: 2.206375, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 316/655, Loss: 2.206062, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 317/655, Loss: 2.206347, Accuracy: 18.04%\n",
            "Epoch: 18, Step: 318/655, Loss: 2.206114, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 319/655, Loss: 2.205997, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 320/655, Loss: 2.205780, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 321/655, Loss: 2.205275, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 322/655, Loss: 2.205352, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 323/655, Loss: 2.205034, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 324/655, Loss: 2.205021, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 325/655, Loss: 2.204944, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 326/655, Loss: 2.204764, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 327/655, Loss: 2.204551, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 328/655, Loss: 2.204432, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 329/655, Loss: 2.204154, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 330/655, Loss: 2.204066, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 331/655, Loss: 2.204228, Accuracy: 18.04%\n",
            "Epoch: 18, Step: 332/655, Loss: 2.204376, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 333/655, Loss: 2.204265, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 334/655, Loss: 2.204174, Accuracy: 18.01%\n",
            "Epoch: 18, Step: 335/655, Loss: 2.204115, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 336/655, Loss: 2.203849, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 337/655, Loss: 2.203876, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 338/655, Loss: 2.203776, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 339/655, Loss: 2.203807, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 340/655, Loss: 2.203877, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 341/655, Loss: 2.203598, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 342/655, Loss: 2.203399, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 343/655, Loss: 2.202995, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 344/655, Loss: 2.203375, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 345/655, Loss: 2.203171, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 346/655, Loss: 2.203299, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 347/655, Loss: 2.203364, Accuracy: 18.04%\n",
            "Epoch: 18, Step: 348/655, Loss: 2.203018, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 349/655, Loss: 2.203243, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 350/655, Loss: 2.203460, Accuracy: 18.04%\n",
            "Epoch: 18, Step: 351/655, Loss: 2.203379, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 352/655, Loss: 2.203312, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 353/655, Loss: 2.203405, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 354/655, Loss: 2.203370, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 355/655, Loss: 2.203578, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 356/655, Loss: 2.203597, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 357/655, Loss: 2.203365, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 358/655, Loss: 2.203596, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 359/655, Loss: 2.203940, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 360/655, Loss: 2.203979, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 361/655, Loss: 2.203954, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 362/655, Loss: 2.204121, Accuracy: 18.04%\n",
            "Epoch: 18, Step: 363/655, Loss: 2.204486, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 364/655, Loss: 2.204385, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 365/655, Loss: 2.204241, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 366/655, Loss: 2.204258, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 367/655, Loss: 2.204586, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 368/655, Loss: 2.204682, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 369/655, Loss: 2.204518, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 370/655, Loss: 2.204451, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 371/655, Loss: 2.204681, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 372/655, Loss: 2.204260, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 373/655, Loss: 2.204412, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 374/655, Loss: 2.204628, Accuracy: 18.13%\n",
            "Epoch: 18, Step: 375/655, Loss: 2.204835, Accuracy: 18.13%\n",
            "Epoch: 18, Step: 376/655, Loss: 2.204736, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 377/655, Loss: 2.205141, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 378/655, Loss: 2.205399, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 379/655, Loss: 2.205201, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 380/655, Loss: 2.204987, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 381/655, Loss: 2.205460, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 382/655, Loss: 2.205672, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 383/655, Loss: 2.205581, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 384/655, Loss: 2.205243, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 385/655, Loss: 2.205538, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 386/655, Loss: 2.206030, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 387/655, Loss: 2.205889, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 388/655, Loss: 2.206202, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 389/655, Loss: 2.206286, Accuracy: 18.04%\n",
            "Epoch: 18, Step: 390/655, Loss: 2.206374, Accuracy: 18.04%\n",
            "Epoch: 18, Step: 391/655, Loss: 2.206496, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 392/655, Loss: 2.206210, Accuracy: 18.04%\n",
            "Epoch: 18, Step: 393/655, Loss: 2.206125, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 394/655, Loss: 2.206103, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 395/655, Loss: 2.206070, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 396/655, Loss: 2.205583, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 397/655, Loss: 2.206194, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 398/655, Loss: 2.206073, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 399/655, Loss: 2.206405, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 400/655, Loss: 2.206405, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 401/655, Loss: 2.206346, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 402/655, Loss: 2.206446, Accuracy: 18.04%\n",
            "Epoch: 18, Step: 403/655, Loss: 2.206613, Accuracy: 18.04%\n",
            "Epoch: 18, Step: 404/655, Loss: 2.206666, Accuracy: 18.04%\n",
            "Epoch: 18, Step: 405/655, Loss: 2.206759, Accuracy: 18.04%\n",
            "Epoch: 18, Step: 406/655, Loss: 2.207009, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 407/655, Loss: 2.207037, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 408/655, Loss: 2.207082, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 409/655, Loss: 2.207227, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 410/655, Loss: 2.207030, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 411/655, Loss: 2.207272, Accuracy: 18.01%\n",
            "Epoch: 18, Step: 412/655, Loss: 2.207011, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 413/655, Loss: 2.207046, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 414/655, Loss: 2.207230, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 415/655, Loss: 2.207108, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 416/655, Loss: 2.207033, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 417/655, Loss: 2.207086, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 418/655, Loss: 2.207065, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 419/655, Loss: 2.206985, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 420/655, Loss: 2.207307, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 421/655, Loss: 2.207151, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 422/655, Loss: 2.207240, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 423/655, Loss: 2.207285, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 424/655, Loss: 2.207496, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 425/655, Loss: 2.207487, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 426/655, Loss: 2.207885, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 427/655, Loss: 2.207927, Accuracy: 18.04%\n",
            "Epoch: 18, Step: 428/655, Loss: 2.207985, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 429/655, Loss: 2.208159, Accuracy: 18.04%\n",
            "Epoch: 18, Step: 430/655, Loss: 2.207998, Accuracy: 18.04%\n",
            "Epoch: 18, Step: 431/655, Loss: 2.208101, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 432/655, Loss: 2.208099, Accuracy: 18.01%\n",
            "Epoch: 18, Step: 433/655, Loss: 2.208322, Accuracy: 18.01%\n",
            "Epoch: 18, Step: 434/655, Loss: 2.208475, Accuracy: 18.01%\n",
            "Epoch: 18, Step: 435/655, Loss: 2.208619, Accuracy: 17.99%\n",
            "Epoch: 18, Step: 436/655, Loss: 2.208635, Accuracy: 18.01%\n",
            "Epoch: 18, Step: 437/655, Loss: 2.208340, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 438/655, Loss: 2.208123, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 439/655, Loss: 2.208206, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 440/655, Loss: 2.207980, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 441/655, Loss: 2.208191, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 442/655, Loss: 2.208087, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 443/655, Loss: 2.207906, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 444/655, Loss: 2.208224, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 445/655, Loss: 2.207972, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 446/655, Loss: 2.207669, Accuracy: 18.13%\n",
            "Epoch: 18, Step: 447/655, Loss: 2.207835, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 448/655, Loss: 2.207614, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 449/655, Loss: 2.207463, Accuracy: 18.14%\n",
            "Epoch: 18, Step: 450/655, Loss: 2.207655, Accuracy: 18.15%\n",
            "Epoch: 18, Step: 451/655, Loss: 2.207789, Accuracy: 18.14%\n",
            "Epoch: 18, Step: 452/655, Loss: 2.207883, Accuracy: 18.13%\n",
            "Epoch: 18, Step: 453/655, Loss: 2.208226, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 454/655, Loss: 2.208286, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 455/655, Loss: 2.208144, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 456/655, Loss: 2.208113, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 457/655, Loss: 2.208131, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 458/655, Loss: 2.208216, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 459/655, Loss: 2.208390, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 460/655, Loss: 2.208570, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 461/655, Loss: 2.208501, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 462/655, Loss: 2.208561, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 463/655, Loss: 2.208620, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 464/655, Loss: 2.208690, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 465/655, Loss: 2.208754, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 466/655, Loss: 2.208750, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 467/655, Loss: 2.208960, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 468/655, Loss: 2.209185, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 469/655, Loss: 2.208849, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 470/655, Loss: 2.208831, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 471/655, Loss: 2.209048, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 472/655, Loss: 2.209230, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 473/655, Loss: 2.209192, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 474/655, Loss: 2.209227, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 475/655, Loss: 2.209314, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 476/655, Loss: 2.209255, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 477/655, Loss: 2.209070, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 478/655, Loss: 2.209141, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 479/655, Loss: 2.209349, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 480/655, Loss: 2.209551, Accuracy: 18.01%\n",
            "Epoch: 18, Step: 481/655, Loss: 2.209648, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 482/655, Loss: 2.209793, Accuracy: 18.01%\n",
            "Epoch: 18, Step: 483/655, Loss: 2.209877, Accuracy: 18.00%\n",
            "Epoch: 18, Step: 484/655, Loss: 2.209785, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 485/655, Loss: 2.209637, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 486/655, Loss: 2.209475, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 487/655, Loss: 2.209478, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 488/655, Loss: 2.209559, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 489/655, Loss: 2.209598, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 490/655, Loss: 2.209755, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 491/655, Loss: 2.209938, Accuracy: 17.99%\n",
            "Epoch: 18, Step: 492/655, Loss: 2.209802, Accuracy: 17.99%\n",
            "Epoch: 18, Step: 493/655, Loss: 2.209572, Accuracy: 18.01%\n",
            "Epoch: 18, Step: 494/655, Loss: 2.209549, Accuracy: 18.02%\n",
            "Epoch: 18, Step: 495/655, Loss: 2.209641, Accuracy: 18.01%\n",
            "Epoch: 18, Step: 496/655, Loss: 2.209696, Accuracy: 18.00%\n",
            "Epoch: 18, Step: 497/655, Loss: 2.209639, Accuracy: 18.01%\n",
            "Epoch: 18, Step: 498/655, Loss: 2.209608, Accuracy: 18.00%\n",
            "Epoch: 18, Step: 499/655, Loss: 2.209361, Accuracy: 18.03%\n",
            "Epoch: 18, Step: 500/655, Loss: 2.209245, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 501/655, Loss: 2.209270, Accuracy: 18.05%\n",
            "Epoch: 18, Step: 502/655, Loss: 2.208874, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 503/655, Loss: 2.208889, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 504/655, Loss: 2.208856, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 505/655, Loss: 2.208792, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 506/655, Loss: 2.208666, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 507/655, Loss: 2.208533, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 508/655, Loss: 2.208373, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 509/655, Loss: 2.208553, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 510/655, Loss: 2.208587, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 511/655, Loss: 2.208662, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 512/655, Loss: 2.208606, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 513/655, Loss: 2.208794, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 514/655, Loss: 2.208624, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 515/655, Loss: 2.208661, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 516/655, Loss: 2.208526, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 517/655, Loss: 2.208556, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 518/655, Loss: 2.208358, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 519/655, Loss: 2.208366, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 520/655, Loss: 2.208213, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 521/655, Loss: 2.208157, Accuracy: 18.07%\n",
            "Epoch: 18, Step: 522/655, Loss: 2.208031, Accuracy: 18.06%\n",
            "Epoch: 18, Step: 523/655, Loss: 2.207801, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 524/655, Loss: 2.207800, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 525/655, Loss: 2.207664, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 526/655, Loss: 2.207803, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 527/655, Loss: 2.207645, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 528/655, Loss: 2.207362, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 529/655, Loss: 2.207615, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 530/655, Loss: 2.207672, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 531/655, Loss: 2.207695, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 532/655, Loss: 2.207650, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 533/655, Loss: 2.207727, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 534/655, Loss: 2.207932, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 535/655, Loss: 2.207856, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 536/655, Loss: 2.207684, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 537/655, Loss: 2.207756, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 538/655, Loss: 2.208099, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 539/655, Loss: 2.208177, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 540/655, Loss: 2.208305, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 541/655, Loss: 2.208275, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 542/655, Loss: 2.208245, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 543/655, Loss: 2.208203, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 544/655, Loss: 2.208214, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 545/655, Loss: 2.208122, Accuracy: 18.08%\n",
            "Epoch: 18, Step: 546/655, Loss: 2.207904, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 547/655, Loss: 2.207577, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 548/655, Loss: 2.207599, Accuracy: 18.13%\n",
            "Epoch: 18, Step: 549/655, Loss: 2.207725, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 550/655, Loss: 2.207744, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 551/655, Loss: 2.207818, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 552/655, Loss: 2.207883, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 553/655, Loss: 2.207795, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 554/655, Loss: 2.207804, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 555/655, Loss: 2.207660, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 556/655, Loss: 2.207725, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 557/655, Loss: 2.207534, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 558/655, Loss: 2.207529, Accuracy: 18.13%\n",
            "Epoch: 18, Step: 559/655, Loss: 2.207399, Accuracy: 18.14%\n",
            "Epoch: 18, Step: 560/655, Loss: 2.207484, Accuracy: 18.13%\n",
            "Epoch: 18, Step: 561/655, Loss: 2.207548, Accuracy: 18.13%\n",
            "Epoch: 18, Step: 562/655, Loss: 2.207734, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 563/655, Loss: 2.207506, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 564/655, Loss: 2.207627, Accuracy: 18.13%\n",
            "Epoch: 18, Step: 565/655, Loss: 2.207905, Accuracy: 18.13%\n",
            "Epoch: 18, Step: 566/655, Loss: 2.207958, Accuracy: 18.13%\n",
            "Epoch: 18, Step: 567/655, Loss: 2.208232, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 568/655, Loss: 2.208173, Accuracy: 18.13%\n",
            "Epoch: 18, Step: 569/655, Loss: 2.208032, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 570/655, Loss: 2.207925, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 571/655, Loss: 2.207990, Accuracy: 18.12%\n",
            "Epoch: 18, Step: 572/655, Loss: 2.208027, Accuracy: 18.09%\n",
            "Epoch: 18, Step: 573/655, Loss: 2.208023, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 574/655, Loss: 2.208061, Accuracy: 18.10%\n",
            "Epoch: 18, Step: 575/655, Loss: 2.208108, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 576/655, Loss: 2.207958, Accuracy: 18.13%\n",
            "Epoch: 18, Step: 577/655, Loss: 2.208040, Accuracy: 18.14%\n",
            "Epoch: 18, Step: 578/655, Loss: 2.208014, Accuracy: 18.13%\n",
            "Epoch: 18, Step: 579/655, Loss: 2.208040, Accuracy: 18.11%\n",
            "Epoch: 18, Step: 580/655, Loss: 2.207828, Accuracy: 18.14%\n",
            "Epoch: 18, Step: 581/655, Loss: 2.208044, Accuracy: 18.13%\n",
            "Epoch: 18, Step: 582/655, Loss: 2.208120, Accuracy: 18.15%\n",
            "Epoch: 18, Step: 583/655, Loss: 2.207937, Accuracy: 18.17%\n",
            "Epoch: 18, Step: 584/655, Loss: 2.208142, Accuracy: 18.18%\n",
            "Epoch: 18, Step: 585/655, Loss: 2.208145, Accuracy: 18.18%\n",
            "Epoch: 18, Step: 586/655, Loss: 2.208358, Accuracy: 18.18%\n",
            "Epoch: 18, Step: 587/655, Loss: 2.208457, Accuracy: 18.18%\n",
            "Epoch: 18, Step: 588/655, Loss: 2.208481, Accuracy: 18.18%\n",
            "Epoch: 18, Step: 589/655, Loss: 2.208599, Accuracy: 18.18%\n",
            "Epoch: 18, Step: 590/655, Loss: 2.208427, Accuracy: 18.18%\n",
            "Epoch: 18, Step: 591/655, Loss: 2.208565, Accuracy: 18.18%\n",
            "Epoch: 18, Step: 592/655, Loss: 2.208424, Accuracy: 18.19%\n",
            "Epoch: 18, Step: 593/655, Loss: 2.208509, Accuracy: 18.19%\n",
            "Epoch: 18, Step: 594/655, Loss: 2.208378, Accuracy: 18.21%\n",
            "Epoch: 18, Step: 595/655, Loss: 2.208290, Accuracy: 18.21%\n",
            "Epoch: 18, Step: 596/655, Loss: 2.208204, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 597/655, Loss: 2.208318, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 598/655, Loss: 2.208102, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 599/655, Loss: 2.207927, Accuracy: 18.24%\n",
            "Epoch: 18, Step: 600/655, Loss: 2.207896, Accuracy: 18.24%\n",
            "Epoch: 18, Step: 601/655, Loss: 2.207793, Accuracy: 18.25%\n",
            "Epoch: 18, Step: 602/655, Loss: 2.208031, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 603/655, Loss: 2.208006, Accuracy: 18.24%\n",
            "Epoch: 18, Step: 604/655, Loss: 2.207848, Accuracy: 18.25%\n",
            "Epoch: 18, Step: 605/655, Loss: 2.207825, Accuracy: 18.24%\n",
            "Epoch: 18, Step: 606/655, Loss: 2.207689, Accuracy: 18.24%\n",
            "Epoch: 18, Step: 607/655, Loss: 2.207681, Accuracy: 18.25%\n",
            "Epoch: 18, Step: 608/655, Loss: 2.207836, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 609/655, Loss: 2.207833, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 610/655, Loss: 2.207800, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 611/655, Loss: 2.207647, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 612/655, Loss: 2.207587, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 613/655, Loss: 2.207521, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 614/655, Loss: 2.207517, Accuracy: 18.24%\n",
            "Epoch: 18, Step: 615/655, Loss: 2.207330, Accuracy: 18.26%\n",
            "Epoch: 18, Step: 616/655, Loss: 2.207159, Accuracy: 18.26%\n",
            "Epoch: 18, Step: 617/655, Loss: 2.207225, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 618/655, Loss: 2.207291, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 619/655, Loss: 2.207161, Accuracy: 18.29%\n",
            "Epoch: 18, Step: 620/655, Loss: 2.207163, Accuracy: 18.30%\n",
            "Epoch: 18, Step: 621/655, Loss: 2.207099, Accuracy: 18.29%\n",
            "Epoch: 18, Step: 622/655, Loss: 2.207209, Accuracy: 18.28%\n",
            "Epoch: 18, Step: 623/655, Loss: 2.207311, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 624/655, Loss: 2.207311, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 625/655, Loss: 2.207330, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 626/655, Loss: 2.207461, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 627/655, Loss: 2.207697, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 628/655, Loss: 2.207631, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 629/655, Loss: 2.207388, Accuracy: 18.28%\n",
            "Epoch: 18, Step: 630/655, Loss: 2.207267, Accuracy: 18.29%\n",
            "Epoch: 18, Step: 631/655, Loss: 2.207370, Accuracy: 18.28%\n",
            "Epoch: 18, Step: 632/655, Loss: 2.207486, Accuracy: 18.28%\n",
            "Epoch: 18, Step: 633/655, Loss: 2.207425, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 634/655, Loss: 2.207286, Accuracy: 18.26%\n",
            "Epoch: 18, Step: 635/655, Loss: 2.207287, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 636/655, Loss: 2.207223, Accuracy: 18.28%\n",
            "Epoch: 18, Step: 637/655, Loss: 2.207149, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 638/655, Loss: 2.207309, Accuracy: 18.28%\n",
            "Epoch: 18, Step: 639/655, Loss: 2.207348, Accuracy: 18.28%\n",
            "Epoch: 18, Step: 640/655, Loss: 2.207530, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 641/655, Loss: 2.207387, Accuracy: 18.25%\n",
            "Epoch: 18, Step: 642/655, Loss: 2.207546, Accuracy: 18.25%\n",
            "Epoch: 18, Step: 643/655, Loss: 2.207488, Accuracy: 18.25%\n",
            "Epoch: 18, Step: 644/655, Loss: 2.207373, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 645/655, Loss: 2.207525, Accuracy: 18.27%\n",
            "Epoch: 18, Step: 646/655, Loss: 2.207505, Accuracy: 18.26%\n",
            "Epoch: 18, Step: 647/655, Loss: 2.207537, Accuracy: 18.25%\n",
            "Epoch: 18, Step: 648/655, Loss: 2.207772, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 649/655, Loss: 2.207843, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 650/655, Loss: 2.207960, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 651/655, Loss: 2.207941, Accuracy: 18.23%\n",
            "Epoch: 18, Step: 652/655, Loss: 2.208115, Accuracy: 18.22%\n",
            "Epoch: 18, Step: 653/655, Loss: 2.208116, Accuracy: 18.21%\n",
            "Epoch: 18, Step: 654/655, Loss: 2.208080, Accuracy: 18.22%\n",
            "Epoch: 18, Step: 655/655, Loss: 2.207688, Accuracy: 18.23%\n",
            "Epoch: 19, Step: 1/655, Loss: 2.261414, Accuracy: 15.62%\n",
            "Epoch: 19, Step: 2/655, Loss: 2.280736, Accuracy: 18.75%\n",
            "Epoch: 19, Step: 3/655, Loss: 2.250067, Accuracy: 17.71%\n",
            "Epoch: 19, Step: 4/655, Loss: 2.266362, Accuracy: 17.19%\n",
            "Epoch: 19, Step: 5/655, Loss: 2.268995, Accuracy: 15.00%\n",
            "Epoch: 19, Step: 6/655, Loss: 2.245705, Accuracy: 16.15%\n",
            "Epoch: 19, Step: 7/655, Loss: 2.233851, Accuracy: 17.86%\n",
            "Epoch: 19, Step: 8/655, Loss: 2.221317, Accuracy: 18.36%\n",
            "Epoch: 19, Step: 9/655, Loss: 2.216726, Accuracy: 18.75%\n",
            "Epoch: 19, Step: 10/655, Loss: 2.209099, Accuracy: 18.44%\n",
            "Epoch: 19, Step: 11/655, Loss: 2.211235, Accuracy: 17.90%\n",
            "Epoch: 19, Step: 12/655, Loss: 2.217507, Accuracy: 17.45%\n",
            "Epoch: 19, Step: 13/655, Loss: 2.216803, Accuracy: 17.31%\n",
            "Epoch: 19, Step: 14/655, Loss: 2.208480, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 15/655, Loss: 2.211613, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 16/655, Loss: 2.198733, Accuracy: 17.97%\n",
            "Epoch: 19, Step: 17/655, Loss: 2.205508, Accuracy: 17.46%\n",
            "Epoch: 19, Step: 18/655, Loss: 2.204830, Accuracy: 17.36%\n",
            "Epoch: 19, Step: 19/655, Loss: 2.209896, Accuracy: 17.11%\n",
            "Epoch: 19, Step: 20/655, Loss: 2.207798, Accuracy: 17.34%\n",
            "Epoch: 19, Step: 21/655, Loss: 2.203901, Accuracy: 17.71%\n",
            "Epoch: 19, Step: 22/655, Loss: 2.204064, Accuracy: 17.90%\n",
            "Epoch: 19, Step: 23/655, Loss: 2.206633, Accuracy: 17.66%\n",
            "Epoch: 19, Step: 24/655, Loss: 2.209063, Accuracy: 17.71%\n",
            "Epoch: 19, Step: 25/655, Loss: 2.203970, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 26/655, Loss: 2.207015, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 27/655, Loss: 2.207219, Accuracy: 18.29%\n",
            "Epoch: 19, Step: 28/655, Loss: 2.208522, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 29/655, Loss: 2.208956, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 30/655, Loss: 2.214136, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 31/655, Loss: 2.212709, Accuracy: 18.25%\n",
            "Epoch: 19, Step: 32/655, Loss: 2.209392, Accuracy: 18.46%\n",
            "Epoch: 19, Step: 33/655, Loss: 2.207835, Accuracy: 18.66%\n",
            "Epoch: 19, Step: 34/655, Loss: 2.210873, Accuracy: 18.47%\n",
            "Epoch: 19, Step: 35/655, Loss: 2.212238, Accuracy: 18.66%\n",
            "Epoch: 19, Step: 36/655, Loss: 2.210615, Accuracy: 18.84%\n",
            "Epoch: 19, Step: 37/655, Loss: 2.209253, Accuracy: 18.92%\n",
            "Epoch: 19, Step: 38/655, Loss: 2.209244, Accuracy: 19.00%\n",
            "Epoch: 19, Step: 39/655, Loss: 2.209550, Accuracy: 18.83%\n",
            "Epoch: 19, Step: 40/655, Loss: 2.208272, Accuracy: 19.06%\n",
            "Epoch: 19, Step: 41/655, Loss: 2.206357, Accuracy: 19.05%\n",
            "Epoch: 19, Step: 42/655, Loss: 2.207550, Accuracy: 18.90%\n",
            "Epoch: 19, Step: 43/655, Loss: 2.207653, Accuracy: 18.82%\n",
            "Epoch: 19, Step: 44/655, Loss: 2.209134, Accuracy: 18.68%\n",
            "Epoch: 19, Step: 45/655, Loss: 2.208419, Accuracy: 18.61%\n",
            "Epoch: 19, Step: 46/655, Loss: 2.206074, Accuracy: 18.75%\n",
            "Epoch: 19, Step: 47/655, Loss: 2.209372, Accuracy: 18.48%\n",
            "Epoch: 19, Step: 48/655, Loss: 2.206608, Accuracy: 18.55%\n",
            "Epoch: 19, Step: 49/655, Loss: 2.207530, Accuracy: 18.62%\n",
            "Epoch: 19, Step: 50/655, Loss: 2.207010, Accuracy: 18.62%\n",
            "Epoch: 19, Step: 51/655, Loss: 2.206547, Accuracy: 18.63%\n",
            "Epoch: 19, Step: 52/655, Loss: 2.203809, Accuracy: 18.75%\n",
            "Epoch: 19, Step: 53/655, Loss: 2.204876, Accuracy: 18.75%\n",
            "Epoch: 19, Step: 54/655, Loss: 2.205491, Accuracy: 18.69%\n",
            "Epoch: 19, Step: 55/655, Loss: 2.205001, Accuracy: 18.64%\n",
            "Epoch: 19, Step: 56/655, Loss: 2.204791, Accuracy: 18.64%\n",
            "Epoch: 19, Step: 57/655, Loss: 2.205230, Accuracy: 18.59%\n",
            "Epoch: 19, Step: 58/655, Loss: 2.206750, Accuracy: 18.48%\n",
            "Epoch: 19, Step: 59/655, Loss: 2.208232, Accuracy: 18.59%\n",
            "Epoch: 19, Step: 60/655, Loss: 2.209123, Accuracy: 18.49%\n",
            "Epoch: 19, Step: 61/655, Loss: 2.209800, Accuracy: 18.60%\n",
            "Epoch: 19, Step: 62/655, Loss: 2.210376, Accuracy: 18.60%\n",
            "Epoch: 19, Step: 63/655, Loss: 2.211093, Accuracy: 18.55%\n",
            "Epoch: 19, Step: 64/655, Loss: 2.211659, Accuracy: 18.60%\n",
            "Epoch: 19, Step: 65/655, Loss: 2.211141, Accuracy: 18.51%\n",
            "Epoch: 19, Step: 66/655, Loss: 2.212164, Accuracy: 18.42%\n",
            "Epoch: 19, Step: 67/655, Loss: 2.209179, Accuracy: 18.56%\n",
            "Epoch: 19, Step: 68/655, Loss: 2.209704, Accuracy: 18.47%\n",
            "Epoch: 19, Step: 69/655, Loss: 2.209340, Accuracy: 18.66%\n",
            "Epoch: 19, Step: 70/655, Loss: 2.210054, Accuracy: 18.57%\n",
            "Epoch: 19, Step: 71/655, Loss: 2.208374, Accuracy: 18.62%\n",
            "Epoch: 19, Step: 72/655, Loss: 2.208617, Accuracy: 18.62%\n",
            "Epoch: 19, Step: 73/655, Loss: 2.208474, Accuracy: 18.66%\n",
            "Epoch: 19, Step: 74/655, Loss: 2.207144, Accuracy: 18.75%\n",
            "Epoch: 19, Step: 75/655, Loss: 2.207723, Accuracy: 18.71%\n",
            "Epoch: 19, Step: 76/655, Loss: 2.211064, Accuracy: 18.54%\n",
            "Epoch: 19, Step: 77/655, Loss: 2.211644, Accuracy: 18.51%\n",
            "Epoch: 19, Step: 78/655, Loss: 2.211607, Accuracy: 18.75%\n",
            "Epoch: 19, Step: 79/655, Loss: 2.212782, Accuracy: 18.71%\n",
            "Epoch: 19, Step: 80/655, Loss: 2.211899, Accuracy: 18.87%\n",
            "Epoch: 19, Step: 81/655, Loss: 2.213649, Accuracy: 18.94%\n",
            "Epoch: 19, Step: 82/655, Loss: 2.213317, Accuracy: 19.05%\n",
            "Epoch: 19, Step: 83/655, Loss: 2.214438, Accuracy: 18.94%\n",
            "Epoch: 19, Step: 84/655, Loss: 2.213931, Accuracy: 18.90%\n",
            "Epoch: 19, Step: 85/655, Loss: 2.213007, Accuracy: 18.86%\n",
            "Epoch: 19, Step: 86/655, Loss: 2.212584, Accuracy: 18.79%\n",
            "Epoch: 19, Step: 87/655, Loss: 2.213045, Accuracy: 18.75%\n",
            "Epoch: 19, Step: 88/655, Loss: 2.213876, Accuracy: 18.79%\n",
            "Epoch: 19, Step: 89/655, Loss: 2.214984, Accuracy: 18.64%\n",
            "Epoch: 19, Step: 90/655, Loss: 2.215307, Accuracy: 18.51%\n",
            "Epoch: 19, Step: 91/655, Loss: 2.214683, Accuracy: 18.44%\n",
            "Epoch: 19, Step: 92/655, Loss: 2.213893, Accuracy: 18.44%\n",
            "Epoch: 19, Step: 93/655, Loss: 2.213564, Accuracy: 18.41%\n",
            "Epoch: 19, Step: 94/655, Loss: 2.214841, Accuracy: 18.28%\n",
            "Epoch: 19, Step: 95/655, Loss: 2.215339, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 96/655, Loss: 2.214895, Accuracy: 18.20%\n",
            "Epoch: 19, Step: 97/655, Loss: 2.213231, Accuracy: 18.20%\n",
            "Epoch: 19, Step: 98/655, Loss: 2.213968, Accuracy: 18.14%\n",
            "Epoch: 19, Step: 99/655, Loss: 2.214189, Accuracy: 18.24%\n",
            "Epoch: 19, Step: 100/655, Loss: 2.213291, Accuracy: 18.34%\n",
            "Epoch: 19, Step: 101/655, Loss: 2.214411, Accuracy: 18.22%\n",
            "Epoch: 19, Step: 102/655, Loss: 2.214231, Accuracy: 18.26%\n",
            "Epoch: 19, Step: 103/655, Loss: 2.214083, Accuracy: 18.29%\n",
            "Epoch: 19, Step: 104/655, Loss: 2.213378, Accuracy: 18.36%\n",
            "Epoch: 19, Step: 105/655, Loss: 2.213452, Accuracy: 18.45%\n",
            "Epoch: 19, Step: 106/655, Loss: 2.214322, Accuracy: 18.43%\n",
            "Epoch: 19, Step: 107/655, Loss: 2.214251, Accuracy: 18.43%\n",
            "Epoch: 19, Step: 108/655, Loss: 2.213570, Accuracy: 18.46%\n",
            "Epoch: 19, Step: 109/655, Loss: 2.213433, Accuracy: 18.49%\n",
            "Epoch: 19, Step: 110/655, Loss: 2.212942, Accuracy: 18.66%\n",
            "Epoch: 19, Step: 111/655, Loss: 2.210881, Accuracy: 18.69%\n",
            "Epoch: 19, Step: 112/655, Loss: 2.210687, Accuracy: 18.72%\n",
            "Epoch: 19, Step: 113/655, Loss: 2.211486, Accuracy: 18.61%\n",
            "Epoch: 19, Step: 114/655, Loss: 2.210737, Accuracy: 18.59%\n",
            "Epoch: 19, Step: 115/655, Loss: 2.210756, Accuracy: 18.48%\n",
            "Epoch: 19, Step: 116/655, Loss: 2.210537, Accuracy: 18.43%\n",
            "Epoch: 19, Step: 117/655, Loss: 2.211137, Accuracy: 18.35%\n",
            "Epoch: 19, Step: 118/655, Loss: 2.210951, Accuracy: 18.43%\n",
            "Epoch: 19, Step: 119/655, Loss: 2.212692, Accuracy: 18.38%\n",
            "Epoch: 19, Step: 120/655, Loss: 2.212400, Accuracy: 18.39%\n",
            "Epoch: 19, Step: 121/655, Loss: 2.211827, Accuracy: 18.41%\n",
            "Epoch: 19, Step: 122/655, Loss: 2.212827, Accuracy: 18.31%\n",
            "Epoch: 19, Step: 123/655, Loss: 2.212267, Accuracy: 18.32%\n",
            "Epoch: 19, Step: 124/655, Loss: 2.211722, Accuracy: 18.30%\n",
            "Epoch: 19, Step: 125/655, Loss: 2.212496, Accuracy: 18.18%\n",
            "Epoch: 19, Step: 126/655, Loss: 2.212688, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 127/655, Loss: 2.212427, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 128/655, Loss: 2.211911, Accuracy: 18.21%\n",
            "Epoch: 19, Step: 129/655, Loss: 2.212371, Accuracy: 18.19%\n",
            "Epoch: 19, Step: 130/655, Loss: 2.212858, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 131/655, Loss: 2.213743, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 132/655, Loss: 2.213545, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 133/655, Loss: 2.213895, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 134/655, Loss: 2.213881, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 135/655, Loss: 2.214661, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 136/655, Loss: 2.214375, Accuracy: 17.99%\n",
            "Epoch: 19, Step: 137/655, Loss: 2.214646, Accuracy: 17.97%\n",
            "Epoch: 19, Step: 138/655, Loss: 2.213760, Accuracy: 17.93%\n",
            "Epoch: 19, Step: 139/655, Loss: 2.214002, Accuracy: 17.94%\n",
            "Epoch: 19, Step: 140/655, Loss: 2.213759, Accuracy: 17.95%\n",
            "Epoch: 19, Step: 141/655, Loss: 2.214160, Accuracy: 17.93%\n",
            "Epoch: 19, Step: 142/655, Loss: 2.213626, Accuracy: 17.98%\n",
            "Epoch: 19, Step: 143/655, Loss: 2.214106, Accuracy: 17.94%\n",
            "Epoch: 19, Step: 144/655, Loss: 2.212934, Accuracy: 17.97%\n",
            "Epoch: 19, Step: 145/655, Loss: 2.211913, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 146/655, Loss: 2.212036, Accuracy: 17.98%\n",
            "Epoch: 19, Step: 147/655, Loss: 2.211178, Accuracy: 17.96%\n",
            "Epoch: 19, Step: 148/655, Loss: 2.210998, Accuracy: 17.91%\n",
            "Epoch: 19, Step: 149/655, Loss: 2.210733, Accuracy: 17.95%\n",
            "Epoch: 19, Step: 150/655, Loss: 2.211531, Accuracy: 17.92%\n",
            "Epoch: 19, Step: 151/655, Loss: 2.211326, Accuracy: 17.96%\n",
            "Epoch: 19, Step: 152/655, Loss: 2.211202, Accuracy: 17.93%\n",
            "Epoch: 19, Step: 153/655, Loss: 2.211423, Accuracy: 17.87%\n",
            "Epoch: 19, Step: 154/655, Loss: 2.210875, Accuracy: 17.88%\n",
            "Epoch: 19, Step: 155/655, Loss: 2.211126, Accuracy: 17.84%\n",
            "Epoch: 19, Step: 156/655, Loss: 2.210932, Accuracy: 17.87%\n",
            "Epoch: 19, Step: 157/655, Loss: 2.210733, Accuracy: 17.87%\n",
            "Epoch: 19, Step: 158/655, Loss: 2.210254, Accuracy: 17.86%\n",
            "Epoch: 19, Step: 159/655, Loss: 2.210098, Accuracy: 17.87%\n",
            "Epoch: 19, Step: 160/655, Loss: 2.210049, Accuracy: 17.85%\n",
            "Epoch: 19, Step: 161/655, Loss: 2.210201, Accuracy: 17.86%\n",
            "Epoch: 19, Step: 162/655, Loss: 2.210184, Accuracy: 17.88%\n",
            "Epoch: 19, Step: 163/655, Loss: 2.210132, Accuracy: 17.91%\n",
            "Epoch: 19, Step: 164/655, Loss: 2.210122, Accuracy: 17.97%\n",
            "Epoch: 19, Step: 165/655, Loss: 2.210663, Accuracy: 17.97%\n",
            "Epoch: 19, Step: 166/655, Loss: 2.211057, Accuracy: 17.98%\n",
            "Epoch: 19, Step: 167/655, Loss: 2.211063, Accuracy: 17.96%\n",
            "Epoch: 19, Step: 168/655, Loss: 2.210850, Accuracy: 17.99%\n",
            "Epoch: 19, Step: 169/655, Loss: 2.211056, Accuracy: 17.90%\n",
            "Epoch: 19, Step: 170/655, Loss: 2.210968, Accuracy: 17.96%\n",
            "Epoch: 19, Step: 171/655, Loss: 2.210864, Accuracy: 17.96%\n",
            "Epoch: 19, Step: 172/655, Loss: 2.210984, Accuracy: 17.97%\n",
            "Epoch: 19, Step: 173/655, Loss: 2.210836, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 174/655, Loss: 2.210485, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 175/655, Loss: 2.209925, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 176/655, Loss: 2.209647, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 177/655, Loss: 2.209841, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 178/655, Loss: 2.209482, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 179/655, Loss: 2.209827, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 180/655, Loss: 2.210000, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 181/655, Loss: 2.210179, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 182/655, Loss: 2.210220, Accuracy: 17.98%\n",
            "Epoch: 19, Step: 183/655, Loss: 2.209647, Accuracy: 18.00%\n",
            "Epoch: 19, Step: 184/655, Loss: 2.209568, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 185/655, Loss: 2.209866, Accuracy: 17.99%\n",
            "Epoch: 19, Step: 186/655, Loss: 2.209433, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 187/655, Loss: 2.209750, Accuracy: 17.98%\n",
            "Epoch: 19, Step: 188/655, Loss: 2.209480, Accuracy: 18.00%\n",
            "Epoch: 19, Step: 189/655, Loss: 2.209016, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 190/655, Loss: 2.208766, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 191/655, Loss: 2.209558, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 192/655, Loss: 2.209161, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 193/655, Loss: 2.209665, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 194/655, Loss: 2.210406, Accuracy: 17.98%\n",
            "Epoch: 19, Step: 195/655, Loss: 2.210805, Accuracy: 17.95%\n",
            "Epoch: 19, Step: 196/655, Loss: 2.210683, Accuracy: 17.94%\n",
            "Epoch: 19, Step: 197/655, Loss: 2.211007, Accuracy: 17.91%\n",
            "Epoch: 19, Step: 198/655, Loss: 2.210833, Accuracy: 17.99%\n",
            "Epoch: 19, Step: 199/655, Loss: 2.211273, Accuracy: 17.96%\n",
            "Epoch: 19, Step: 200/655, Loss: 2.211821, Accuracy: 17.97%\n",
            "Epoch: 19, Step: 201/655, Loss: 2.211643, Accuracy: 17.93%\n",
            "Epoch: 19, Step: 202/655, Loss: 2.212100, Accuracy: 17.93%\n",
            "Epoch: 19, Step: 203/655, Loss: 2.212524, Accuracy: 17.89%\n",
            "Epoch: 19, Step: 204/655, Loss: 2.212289, Accuracy: 17.89%\n",
            "Epoch: 19, Step: 205/655, Loss: 2.212318, Accuracy: 17.91%\n",
            "Epoch: 19, Step: 206/655, Loss: 2.211574, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 207/655, Loss: 2.210943, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 208/655, Loss: 2.210939, Accuracy: 17.98%\n",
            "Epoch: 19, Step: 209/655, Loss: 2.211514, Accuracy: 18.00%\n",
            "Epoch: 19, Step: 210/655, Loss: 2.211231, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 211/655, Loss: 2.210709, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 212/655, Loss: 2.210742, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 213/655, Loss: 2.210699, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 214/655, Loss: 2.210753, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 215/655, Loss: 2.210609, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 216/655, Loss: 2.210400, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 217/655, Loss: 2.210649, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 218/655, Loss: 2.210621, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 219/655, Loss: 2.210960, Accuracy: 17.99%\n",
            "Epoch: 19, Step: 220/655, Loss: 2.210056, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 221/655, Loss: 2.210535, Accuracy: 18.00%\n",
            "Epoch: 19, Step: 222/655, Loss: 2.211393, Accuracy: 17.99%\n",
            "Epoch: 19, Step: 223/655, Loss: 2.211817, Accuracy: 17.92%\n",
            "Epoch: 19, Step: 224/655, Loss: 2.211775, Accuracy: 17.91%\n",
            "Epoch: 19, Step: 225/655, Loss: 2.212026, Accuracy: 17.92%\n",
            "Epoch: 19, Step: 226/655, Loss: 2.212105, Accuracy: 17.92%\n",
            "Epoch: 19, Step: 227/655, Loss: 2.211906, Accuracy: 17.91%\n",
            "Epoch: 19, Step: 228/655, Loss: 2.211764, Accuracy: 17.89%\n",
            "Epoch: 19, Step: 229/655, Loss: 2.211209, Accuracy: 17.92%\n",
            "Epoch: 19, Step: 230/655, Loss: 2.211290, Accuracy: 17.92%\n",
            "Epoch: 19, Step: 231/655, Loss: 2.211664, Accuracy: 17.91%\n",
            "Epoch: 19, Step: 232/655, Loss: 2.212226, Accuracy: 17.89%\n",
            "Epoch: 19, Step: 233/655, Loss: 2.212152, Accuracy: 17.89%\n",
            "Epoch: 19, Step: 234/655, Loss: 2.211553, Accuracy: 17.96%\n",
            "Epoch: 19, Step: 235/655, Loss: 2.211427, Accuracy: 17.95%\n",
            "Epoch: 19, Step: 236/655, Loss: 2.211375, Accuracy: 17.98%\n",
            "Epoch: 19, Step: 237/655, Loss: 2.211323, Accuracy: 17.97%\n",
            "Epoch: 19, Step: 238/655, Loss: 2.211368, Accuracy: 17.99%\n",
            "Epoch: 19, Step: 239/655, Loss: 2.211804, Accuracy: 17.99%\n",
            "Epoch: 19, Step: 240/655, Loss: 2.212289, Accuracy: 17.92%\n",
            "Epoch: 19, Step: 241/655, Loss: 2.212176, Accuracy: 17.91%\n",
            "Epoch: 19, Step: 242/655, Loss: 2.211952, Accuracy: 17.96%\n",
            "Epoch: 19, Step: 243/655, Loss: 2.212084, Accuracy: 17.94%\n",
            "Epoch: 19, Step: 244/655, Loss: 2.212185, Accuracy: 17.93%\n",
            "Epoch: 19, Step: 245/655, Loss: 2.212152, Accuracy: 17.93%\n",
            "Epoch: 19, Step: 246/655, Loss: 2.212520, Accuracy: 17.95%\n",
            "Epoch: 19, Step: 247/655, Loss: 2.212961, Accuracy: 17.95%\n",
            "Epoch: 19, Step: 248/655, Loss: 2.212653, Accuracy: 17.99%\n",
            "Epoch: 19, Step: 249/655, Loss: 2.212586, Accuracy: 18.00%\n",
            "Epoch: 19, Step: 250/655, Loss: 2.212209, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 251/655, Loss: 2.212409, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 252/655, Loss: 2.212482, Accuracy: 17.98%\n",
            "Epoch: 19, Step: 253/655, Loss: 2.212787, Accuracy: 17.97%\n",
            "Epoch: 19, Step: 254/655, Loss: 2.213130, Accuracy: 17.94%\n",
            "Epoch: 19, Step: 255/655, Loss: 2.212941, Accuracy: 17.94%\n",
            "Epoch: 19, Step: 256/655, Loss: 2.212840, Accuracy: 17.96%\n",
            "Epoch: 19, Step: 257/655, Loss: 2.212372, Accuracy: 18.00%\n",
            "Epoch: 19, Step: 258/655, Loss: 2.212700, Accuracy: 17.95%\n",
            "Epoch: 19, Step: 259/655, Loss: 2.212747, Accuracy: 17.91%\n",
            "Epoch: 19, Step: 260/655, Loss: 2.213037, Accuracy: 17.87%\n",
            "Epoch: 19, Step: 261/655, Loss: 2.212509, Accuracy: 17.95%\n",
            "Epoch: 19, Step: 262/655, Loss: 2.212508, Accuracy: 17.94%\n",
            "Epoch: 19, Step: 263/655, Loss: 2.212374, Accuracy: 17.95%\n",
            "Epoch: 19, Step: 264/655, Loss: 2.211423, Accuracy: 17.97%\n",
            "Epoch: 19, Step: 265/655, Loss: 2.211452, Accuracy: 18.00%\n",
            "Epoch: 19, Step: 266/655, Loss: 2.211359, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 267/655, Loss: 2.211529, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 268/655, Loss: 2.211679, Accuracy: 18.00%\n",
            "Epoch: 19, Step: 269/655, Loss: 2.211150, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 270/655, Loss: 2.211566, Accuracy: 18.00%\n",
            "Epoch: 19, Step: 271/655, Loss: 2.211783, Accuracy: 18.00%\n",
            "Epoch: 19, Step: 272/655, Loss: 2.211815, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 273/655, Loss: 2.211861, Accuracy: 17.99%\n",
            "Epoch: 19, Step: 274/655, Loss: 2.211422, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 275/655, Loss: 2.211359, Accuracy: 17.98%\n",
            "Epoch: 19, Step: 276/655, Loss: 2.211806, Accuracy: 17.96%\n",
            "Epoch: 19, Step: 277/655, Loss: 2.211774, Accuracy: 17.97%\n",
            "Epoch: 19, Step: 278/655, Loss: 2.210992, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 279/655, Loss: 2.211006, Accuracy: 17.95%\n",
            "Epoch: 19, Step: 280/655, Loss: 2.210960, Accuracy: 17.97%\n",
            "Epoch: 19, Step: 281/655, Loss: 2.211010, Accuracy: 17.95%\n",
            "Epoch: 19, Step: 282/655, Loss: 2.210725, Accuracy: 18.00%\n",
            "Epoch: 19, Step: 283/655, Loss: 2.210364, Accuracy: 18.00%\n",
            "Epoch: 19, Step: 284/655, Loss: 2.210014, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 285/655, Loss: 2.209746, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 286/655, Loss: 2.209465, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 287/655, Loss: 2.209457, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 288/655, Loss: 2.209553, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 289/655, Loss: 2.209588, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 290/655, Loss: 2.209612, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 291/655, Loss: 2.209771, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 292/655, Loss: 2.210110, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 293/655, Loss: 2.209713, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 294/655, Loss: 2.209255, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 295/655, Loss: 2.209367, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 296/655, Loss: 2.209623, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 297/655, Loss: 2.209890, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 298/655, Loss: 2.209674, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 299/655, Loss: 2.209746, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 300/655, Loss: 2.209681, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 301/655, Loss: 2.210134, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 302/655, Loss: 2.209989, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 303/655, Loss: 2.209296, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 304/655, Loss: 2.209177, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 305/655, Loss: 2.209294, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 306/655, Loss: 2.209198, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 307/655, Loss: 2.209133, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 308/655, Loss: 2.208838, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 309/655, Loss: 2.208676, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 310/655, Loss: 2.208837, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 311/655, Loss: 2.208966, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 312/655, Loss: 2.208619, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 313/655, Loss: 2.208710, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 314/655, Loss: 2.208868, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 315/655, Loss: 2.208785, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 316/655, Loss: 2.208577, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 317/655, Loss: 2.208237, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 318/655, Loss: 2.208476, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 319/655, Loss: 2.208605, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 320/655, Loss: 2.208264, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 321/655, Loss: 2.208041, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 322/655, Loss: 2.207918, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 323/655, Loss: 2.208186, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 324/655, Loss: 2.207881, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 325/655, Loss: 2.207774, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 326/655, Loss: 2.207617, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 327/655, Loss: 2.208160, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 328/655, Loss: 2.207854, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 329/655, Loss: 2.208142, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 330/655, Loss: 2.208269, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 331/655, Loss: 2.208127, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 332/655, Loss: 2.207890, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 333/655, Loss: 2.207810, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 334/655, Loss: 2.207452, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 335/655, Loss: 2.207361, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 336/655, Loss: 2.207375, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 337/655, Loss: 2.207763, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 338/655, Loss: 2.207659, Accuracy: 18.15%\n",
            "Epoch: 19, Step: 339/655, Loss: 2.207570, Accuracy: 18.20%\n",
            "Epoch: 19, Step: 340/655, Loss: 2.207621, Accuracy: 18.15%\n",
            "Epoch: 19, Step: 341/655, Loss: 2.207649, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 342/655, Loss: 2.207482, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 343/655, Loss: 2.207406, Accuracy: 18.14%\n",
            "Epoch: 19, Step: 344/655, Loss: 2.207630, Accuracy: 18.15%\n",
            "Epoch: 19, Step: 345/655, Loss: 2.207592, Accuracy: 18.14%\n",
            "Epoch: 19, Step: 346/655, Loss: 2.207763, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 347/655, Loss: 2.207836, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 348/655, Loss: 2.207708, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 349/655, Loss: 2.207426, Accuracy: 18.14%\n",
            "Epoch: 19, Step: 350/655, Loss: 2.207591, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 351/655, Loss: 2.207964, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 352/655, Loss: 2.207891, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 353/655, Loss: 2.208232, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 354/655, Loss: 2.208078, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 355/655, Loss: 2.208101, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 356/655, Loss: 2.208143, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 357/655, Loss: 2.207972, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 358/655, Loss: 2.207756, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 359/655, Loss: 2.207920, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 360/655, Loss: 2.207891, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 361/655, Loss: 2.207755, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 362/655, Loss: 2.207807, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 363/655, Loss: 2.207971, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 364/655, Loss: 2.208392, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 365/655, Loss: 2.208463, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 366/655, Loss: 2.208805, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 367/655, Loss: 2.208688, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 368/655, Loss: 2.208850, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 369/655, Loss: 2.208854, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 370/655, Loss: 2.208965, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 371/655, Loss: 2.208819, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 372/655, Loss: 2.208912, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 373/655, Loss: 2.208598, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 374/655, Loss: 2.208867, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 375/655, Loss: 2.208650, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 376/655, Loss: 2.208580, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 377/655, Loss: 2.208596, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 378/655, Loss: 2.208739, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 379/655, Loss: 2.208955, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 380/655, Loss: 2.208800, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 381/655, Loss: 2.209155, Accuracy: 18.00%\n",
            "Epoch: 19, Step: 382/655, Loss: 2.209021, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 383/655, Loss: 2.209035, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 384/655, Loss: 2.209036, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 385/655, Loss: 2.209307, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 386/655, Loss: 2.209369, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 387/655, Loss: 2.209303, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 388/655, Loss: 2.209793, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 389/655, Loss: 2.210059, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 390/655, Loss: 2.210123, Accuracy: 18.00%\n",
            "Epoch: 19, Step: 391/655, Loss: 2.210029, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 392/655, Loss: 2.210079, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 393/655, Loss: 2.210168, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 394/655, Loss: 2.210016, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 395/655, Loss: 2.210204, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 396/655, Loss: 2.210459, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 397/655, Loss: 2.210439, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 398/655, Loss: 2.210146, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 399/655, Loss: 2.210329, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 400/655, Loss: 2.210436, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 401/655, Loss: 2.210485, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 402/655, Loss: 2.210619, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 403/655, Loss: 2.210408, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 404/655, Loss: 2.210048, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 405/655, Loss: 2.210065, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 406/655, Loss: 2.209977, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 407/655, Loss: 2.209815, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 408/655, Loss: 2.209818, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 409/655, Loss: 2.209922, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 410/655, Loss: 2.209734, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 411/655, Loss: 2.209719, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 412/655, Loss: 2.210068, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 413/655, Loss: 2.210225, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 414/655, Loss: 2.210155, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 415/655, Loss: 2.210165, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 416/655, Loss: 2.210429, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 417/655, Loss: 2.210800, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 418/655, Loss: 2.210628, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 419/655, Loss: 2.210455, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 420/655, Loss: 2.210290, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 421/655, Loss: 2.210171, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 422/655, Loss: 2.210514, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 423/655, Loss: 2.210893, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 424/655, Loss: 2.210768, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 425/655, Loss: 2.210455, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 426/655, Loss: 2.210550, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 427/655, Loss: 2.210366, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 428/655, Loss: 2.210324, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 429/655, Loss: 2.210336, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 430/655, Loss: 2.210544, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 431/655, Loss: 2.210533, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 432/655, Loss: 2.210560, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 433/655, Loss: 2.210744, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 434/655, Loss: 2.210458, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 435/655, Loss: 2.210646, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 436/655, Loss: 2.210731, Accuracy: 18.00%\n",
            "Epoch: 19, Step: 437/655, Loss: 2.210603, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 438/655, Loss: 2.210388, Accuracy: 18.02%\n",
            "Epoch: 19, Step: 439/655, Loss: 2.210368, Accuracy: 18.01%\n",
            "Epoch: 19, Step: 440/655, Loss: 2.210252, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 441/655, Loss: 2.210011, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 442/655, Loss: 2.209963, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 443/655, Loss: 2.210065, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 444/655, Loss: 2.210089, Accuracy: 18.03%\n",
            "Epoch: 19, Step: 445/655, Loss: 2.209730, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 446/655, Loss: 2.209543, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 447/655, Loss: 2.209426, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 448/655, Loss: 2.209278, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 449/655, Loss: 2.209211, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 450/655, Loss: 2.209308, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 451/655, Loss: 2.209417, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 452/655, Loss: 2.209386, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 453/655, Loss: 2.209334, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 454/655, Loss: 2.209432, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 455/655, Loss: 2.209557, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 456/655, Loss: 2.209476, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 457/655, Loss: 2.209322, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 458/655, Loss: 2.209247, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 459/655, Loss: 2.209185, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 460/655, Loss: 2.209056, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 461/655, Loss: 2.209236, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 462/655, Loss: 2.209206, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 463/655, Loss: 2.209395, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 464/655, Loss: 2.209107, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 465/655, Loss: 2.209180, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 466/655, Loss: 2.209241, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 467/655, Loss: 2.209357, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 468/655, Loss: 2.209484, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 469/655, Loss: 2.209371, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 470/655, Loss: 2.209541, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 471/655, Loss: 2.209407, Accuracy: 18.14%\n",
            "Epoch: 19, Step: 472/655, Loss: 2.209566, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 473/655, Loss: 2.209454, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 474/655, Loss: 2.209515, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 475/655, Loss: 2.209300, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 476/655, Loss: 2.209028, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 477/655, Loss: 2.209069, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 478/655, Loss: 2.208860, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 479/655, Loss: 2.209005, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 480/655, Loss: 2.209163, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 481/655, Loss: 2.208972, Accuracy: 18.14%\n",
            "Epoch: 19, Step: 482/655, Loss: 2.209250, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 483/655, Loss: 2.209241, Accuracy: 18.14%\n",
            "Epoch: 19, Step: 484/655, Loss: 2.208979, Accuracy: 18.16%\n",
            "Epoch: 19, Step: 485/655, Loss: 2.208946, Accuracy: 18.18%\n",
            "Epoch: 19, Step: 486/655, Loss: 2.209288, Accuracy: 18.16%\n",
            "Epoch: 19, Step: 487/655, Loss: 2.209427, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 488/655, Loss: 2.209274, Accuracy: 18.17%\n",
            "Epoch: 19, Step: 489/655, Loss: 2.209394, Accuracy: 18.16%\n",
            "Epoch: 19, Step: 490/655, Loss: 2.209266, Accuracy: 18.14%\n",
            "Epoch: 19, Step: 491/655, Loss: 2.209292, Accuracy: 18.14%\n",
            "Epoch: 19, Step: 492/655, Loss: 2.209122, Accuracy: 18.15%\n",
            "Epoch: 19, Step: 493/655, Loss: 2.209190, Accuracy: 18.15%\n",
            "Epoch: 19, Step: 494/655, Loss: 2.209050, Accuracy: 18.17%\n",
            "Epoch: 19, Step: 495/655, Loss: 2.208929, Accuracy: 18.18%\n",
            "Epoch: 19, Step: 496/655, Loss: 2.208680, Accuracy: 18.21%\n",
            "Epoch: 19, Step: 497/655, Loss: 2.208512, Accuracy: 18.22%\n",
            "Epoch: 19, Step: 498/655, Loss: 2.208550, Accuracy: 18.20%\n",
            "Epoch: 19, Step: 499/655, Loss: 2.208588, Accuracy: 18.21%\n",
            "Epoch: 19, Step: 500/655, Loss: 2.208407, Accuracy: 18.21%\n",
            "Epoch: 19, Step: 501/655, Loss: 2.208362, Accuracy: 18.19%\n",
            "Epoch: 19, Step: 502/655, Loss: 2.208191, Accuracy: 18.19%\n",
            "Epoch: 19, Step: 503/655, Loss: 2.208138, Accuracy: 18.19%\n",
            "Epoch: 19, Step: 504/655, Loss: 2.207933, Accuracy: 18.21%\n",
            "Epoch: 19, Step: 505/655, Loss: 2.208100, Accuracy: 18.21%\n",
            "Epoch: 19, Step: 506/655, Loss: 2.208133, Accuracy: 18.21%\n",
            "Epoch: 19, Step: 507/655, Loss: 2.208385, Accuracy: 18.20%\n",
            "Epoch: 19, Step: 508/655, Loss: 2.208506, Accuracy: 18.19%\n",
            "Epoch: 19, Step: 509/655, Loss: 2.208330, Accuracy: 18.19%\n",
            "Epoch: 19, Step: 510/655, Loss: 2.208272, Accuracy: 18.18%\n",
            "Epoch: 19, Step: 511/655, Loss: 2.208265, Accuracy: 18.18%\n",
            "Epoch: 19, Step: 512/655, Loss: 2.208324, Accuracy: 18.18%\n",
            "Epoch: 19, Step: 513/655, Loss: 2.208638, Accuracy: 18.17%\n",
            "Epoch: 19, Step: 514/655, Loss: 2.208838, Accuracy: 18.16%\n",
            "Epoch: 19, Step: 515/655, Loss: 2.208874, Accuracy: 18.16%\n",
            "Epoch: 19, Step: 516/655, Loss: 2.208903, Accuracy: 18.16%\n",
            "Epoch: 19, Step: 517/655, Loss: 2.208692, Accuracy: 18.16%\n",
            "Epoch: 19, Step: 518/655, Loss: 2.208688, Accuracy: 18.16%\n",
            "Epoch: 19, Step: 519/655, Loss: 2.208627, Accuracy: 18.16%\n",
            "Epoch: 19, Step: 520/655, Loss: 2.208700, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 521/655, Loss: 2.208569, Accuracy: 18.14%\n",
            "Epoch: 19, Step: 522/655, Loss: 2.208553, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 523/655, Loss: 2.208108, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 524/655, Loss: 2.208062, Accuracy: 18.14%\n",
            "Epoch: 19, Step: 525/655, Loss: 2.208243, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 526/655, Loss: 2.208637, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 527/655, Loss: 2.208686, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 528/655, Loss: 2.208549, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 529/655, Loss: 2.208711, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 530/655, Loss: 2.208708, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 531/655, Loss: 2.208887, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 532/655, Loss: 2.208596, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 533/655, Loss: 2.208489, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 534/655, Loss: 2.208503, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 535/655, Loss: 2.208633, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 536/655, Loss: 2.208393, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 537/655, Loss: 2.208256, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 538/655, Loss: 2.208162, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 539/655, Loss: 2.208232, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 540/655, Loss: 2.208291, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 541/655, Loss: 2.208264, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 542/655, Loss: 2.207956, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 543/655, Loss: 2.207760, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 544/655, Loss: 2.207475, Accuracy: 18.14%\n",
            "Epoch: 19, Step: 545/655, Loss: 2.207526, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 546/655, Loss: 2.207309, Accuracy: 18.14%\n",
            "Epoch: 19, Step: 547/655, Loss: 2.207393, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 548/655, Loss: 2.207339, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 549/655, Loss: 2.207215, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 550/655, Loss: 2.207248, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 551/655, Loss: 2.207346, Accuracy: 18.14%\n",
            "Epoch: 19, Step: 552/655, Loss: 2.207456, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 553/655, Loss: 2.207488, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 554/655, Loss: 2.207556, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 555/655, Loss: 2.207553, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 556/655, Loss: 2.207570, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 557/655, Loss: 2.207503, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 558/655, Loss: 2.207593, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 559/655, Loss: 2.207836, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 560/655, Loss: 2.207572, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 561/655, Loss: 2.207685, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 562/655, Loss: 2.207757, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 563/655, Loss: 2.207956, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 564/655, Loss: 2.207885, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 565/655, Loss: 2.207762, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 566/655, Loss: 2.207862, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 567/655, Loss: 2.207769, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 568/655, Loss: 2.207898, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 569/655, Loss: 2.208227, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 570/655, Loss: 2.208163, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 571/655, Loss: 2.207898, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 572/655, Loss: 2.207617, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 573/655, Loss: 2.207712, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 574/655, Loss: 2.207875, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 575/655, Loss: 2.207936, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 576/655, Loss: 2.207961, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 577/655, Loss: 2.207618, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 578/655, Loss: 2.207679, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 579/655, Loss: 2.207740, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 580/655, Loss: 2.207771, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 581/655, Loss: 2.207638, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 582/655, Loss: 2.207810, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 583/655, Loss: 2.207539, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 584/655, Loss: 2.207447, Accuracy: 18.13%\n",
            "Epoch: 19, Step: 585/655, Loss: 2.207661, Accuracy: 18.14%\n",
            "Epoch: 19, Step: 586/655, Loss: 2.207681, Accuracy: 18.15%\n",
            "Epoch: 19, Step: 587/655, Loss: 2.207566, Accuracy: 18.18%\n",
            "Epoch: 19, Step: 588/655, Loss: 2.207317, Accuracy: 18.18%\n",
            "Epoch: 19, Step: 589/655, Loss: 2.207422, Accuracy: 18.17%\n",
            "Epoch: 19, Step: 590/655, Loss: 2.207558, Accuracy: 18.16%\n",
            "Epoch: 19, Step: 591/655, Loss: 2.207465, Accuracy: 18.16%\n",
            "Epoch: 19, Step: 592/655, Loss: 2.207596, Accuracy: 18.15%\n",
            "Epoch: 19, Step: 593/655, Loss: 2.207987, Accuracy: 18.12%\n",
            "Epoch: 19, Step: 594/655, Loss: 2.208039, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 595/655, Loss: 2.207877, Accuracy: 18.11%\n",
            "Epoch: 19, Step: 596/655, Loss: 2.207825, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 597/655, Loss: 2.207949, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 598/655, Loss: 2.207747, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 599/655, Loss: 2.207852, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 600/655, Loss: 2.207863, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 601/655, Loss: 2.208010, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 602/655, Loss: 2.207966, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 603/655, Loss: 2.207946, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 604/655, Loss: 2.207866, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 605/655, Loss: 2.207783, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 606/655, Loss: 2.207768, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 607/655, Loss: 2.207817, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 608/655, Loss: 2.208027, Accuracy: 18.04%\n",
            "Epoch: 19, Step: 609/655, Loss: 2.207925, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 610/655, Loss: 2.208011, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 611/655, Loss: 2.207908, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 612/655, Loss: 2.207976, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 613/655, Loss: 2.207974, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 614/655, Loss: 2.208078, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 615/655, Loss: 2.208142, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 616/655, Loss: 2.208272, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 617/655, Loss: 2.208507, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 618/655, Loss: 2.208570, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 619/655, Loss: 2.208533, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 620/655, Loss: 2.208477, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 621/655, Loss: 2.208608, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 622/655, Loss: 2.208400, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 623/655, Loss: 2.208522, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 624/655, Loss: 2.208383, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 625/655, Loss: 2.208503, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 626/655, Loss: 2.208749, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 627/655, Loss: 2.208671, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 628/655, Loss: 2.208695, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 629/655, Loss: 2.208670, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 630/655, Loss: 2.208585, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 631/655, Loss: 2.208672, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 632/655, Loss: 2.208608, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 633/655, Loss: 2.208564, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 634/655, Loss: 2.208572, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 635/655, Loss: 2.208510, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 636/655, Loss: 2.208378, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 637/655, Loss: 2.208280, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 638/655, Loss: 2.208413, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 639/655, Loss: 2.208484, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 640/655, Loss: 2.208397, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 641/655, Loss: 2.208428, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 642/655, Loss: 2.208448, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 643/655, Loss: 2.208422, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 644/655, Loss: 2.208371, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 645/655, Loss: 2.208374, Accuracy: 18.08%\n",
            "Epoch: 19, Step: 646/655, Loss: 2.208409, Accuracy: 18.07%\n",
            "Epoch: 19, Step: 647/655, Loss: 2.208497, Accuracy: 18.05%\n",
            "Epoch: 19, Step: 648/655, Loss: 2.208418, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 649/655, Loss: 2.208444, Accuracy: 18.06%\n",
            "Epoch: 19, Step: 650/655, Loss: 2.208282, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 651/655, Loss: 2.208166, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 652/655, Loss: 2.208070, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 653/655, Loss: 2.208041, Accuracy: 18.10%\n",
            "Epoch: 19, Step: 654/655, Loss: 2.208056, Accuracy: 18.09%\n",
            "Epoch: 19, Step: 655/655, Loss: 2.207728, Accuracy: 18.10%\n",
            "Epoch: 20, Step: 1/655, Loss: 2.349508, Accuracy: 6.25%\n",
            "Epoch: 20, Step: 2/655, Loss: 2.255956, Accuracy: 18.75%\n",
            "Epoch: 20, Step: 3/655, Loss: 2.266558, Accuracy: 17.71%\n",
            "Epoch: 20, Step: 4/655, Loss: 2.235287, Accuracy: 17.97%\n",
            "Epoch: 20, Step: 5/655, Loss: 2.227759, Accuracy: 16.88%\n",
            "Epoch: 20, Step: 6/655, Loss: 2.223311, Accuracy: 16.67%\n",
            "Epoch: 20, Step: 7/655, Loss: 2.225187, Accuracy: 17.41%\n",
            "Epoch: 20, Step: 8/655, Loss: 2.213465, Accuracy: 17.19%\n",
            "Epoch: 20, Step: 9/655, Loss: 2.216273, Accuracy: 15.97%\n",
            "Epoch: 20, Step: 10/655, Loss: 2.225615, Accuracy: 16.25%\n",
            "Epoch: 20, Step: 11/655, Loss: 2.224132, Accuracy: 16.48%\n",
            "Epoch: 20, Step: 12/655, Loss: 2.227412, Accuracy: 16.15%\n",
            "Epoch: 20, Step: 13/655, Loss: 2.222565, Accuracy: 16.35%\n",
            "Epoch: 20, Step: 14/655, Loss: 2.224158, Accuracy: 16.07%\n",
            "Epoch: 20, Step: 15/655, Loss: 2.225776, Accuracy: 16.04%\n",
            "Epoch: 20, Step: 16/655, Loss: 2.225317, Accuracy: 16.60%\n",
            "Epoch: 20, Step: 17/655, Loss: 2.217651, Accuracy: 16.91%\n",
            "Epoch: 20, Step: 18/655, Loss: 2.219323, Accuracy: 16.67%\n",
            "Epoch: 20, Step: 19/655, Loss: 2.215301, Accuracy: 16.94%\n",
            "Epoch: 20, Step: 20/655, Loss: 2.213113, Accuracy: 17.03%\n",
            "Epoch: 20, Step: 21/655, Loss: 2.210907, Accuracy: 17.26%\n",
            "Epoch: 20, Step: 22/655, Loss: 2.204750, Accuracy: 17.76%\n",
            "Epoch: 20, Step: 23/655, Loss: 2.204080, Accuracy: 17.80%\n",
            "Epoch: 20, Step: 24/655, Loss: 2.203666, Accuracy: 17.71%\n",
            "Epoch: 20, Step: 25/655, Loss: 2.198716, Accuracy: 18.12%\n",
            "Epoch: 20, Step: 26/655, Loss: 2.200594, Accuracy: 18.15%\n",
            "Epoch: 20, Step: 27/655, Loss: 2.199073, Accuracy: 18.75%\n",
            "Epoch: 20, Step: 28/655, Loss: 2.195971, Accuracy: 18.86%\n",
            "Epoch: 20, Step: 29/655, Loss: 2.198674, Accuracy: 18.86%\n",
            "Epoch: 20, Step: 30/655, Loss: 2.198849, Accuracy: 19.06%\n",
            "Epoch: 20, Step: 31/655, Loss: 2.198129, Accuracy: 18.95%\n",
            "Epoch: 20, Step: 32/655, Loss: 2.198621, Accuracy: 18.85%\n",
            "Epoch: 20, Step: 33/655, Loss: 2.199396, Accuracy: 18.84%\n",
            "Epoch: 20, Step: 34/655, Loss: 2.196987, Accuracy: 19.03%\n",
            "Epoch: 20, Step: 35/655, Loss: 2.196519, Accuracy: 18.93%\n",
            "Epoch: 20, Step: 36/655, Loss: 2.194534, Accuracy: 18.92%\n",
            "Epoch: 20, Step: 37/655, Loss: 2.195997, Accuracy: 18.83%\n",
            "Epoch: 20, Step: 38/655, Loss: 2.194119, Accuracy: 19.00%\n",
            "Epoch: 20, Step: 39/655, Loss: 2.192255, Accuracy: 19.23%\n",
            "Epoch: 20, Step: 40/655, Loss: 2.193897, Accuracy: 19.14%\n",
            "Epoch: 20, Step: 41/655, Loss: 2.195449, Accuracy: 19.05%\n",
            "Epoch: 20, Step: 42/655, Loss: 2.196175, Accuracy: 18.90%\n",
            "Epoch: 20, Step: 43/655, Loss: 2.196863, Accuracy: 18.97%\n",
            "Epoch: 20, Step: 44/655, Loss: 2.195297, Accuracy: 18.96%\n",
            "Epoch: 20, Step: 45/655, Loss: 2.193518, Accuracy: 18.96%\n",
            "Epoch: 20, Step: 46/655, Loss: 2.191554, Accuracy: 19.02%\n",
            "Epoch: 20, Step: 47/655, Loss: 2.191696, Accuracy: 18.88%\n",
            "Epoch: 20, Step: 48/655, Loss: 2.190269, Accuracy: 19.14%\n",
            "Epoch: 20, Step: 49/655, Loss: 2.189427, Accuracy: 19.13%\n",
            "Epoch: 20, Step: 50/655, Loss: 2.189219, Accuracy: 19.12%\n",
            "Epoch: 20, Step: 51/655, Loss: 2.191785, Accuracy: 18.87%\n",
            "Epoch: 20, Step: 52/655, Loss: 2.195579, Accuracy: 18.93%\n",
            "Epoch: 20, Step: 53/655, Loss: 2.197323, Accuracy: 18.81%\n",
            "Epoch: 20, Step: 54/655, Loss: 2.197079, Accuracy: 18.81%\n",
            "Epoch: 20, Step: 55/655, Loss: 2.196700, Accuracy: 18.81%\n",
            "Epoch: 20, Step: 56/655, Loss: 2.194831, Accuracy: 18.75%\n",
            "Epoch: 20, Step: 57/655, Loss: 2.196077, Accuracy: 18.75%\n",
            "Epoch: 20, Step: 58/655, Loss: 2.197785, Accuracy: 18.70%\n",
            "Epoch: 20, Step: 59/655, Loss: 2.199561, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 60/655, Loss: 2.199417, Accuracy: 18.54%\n",
            "Epoch: 20, Step: 61/655, Loss: 2.201267, Accuracy: 18.34%\n",
            "Epoch: 20, Step: 62/655, Loss: 2.201937, Accuracy: 18.35%\n",
            "Epoch: 20, Step: 63/655, Loss: 2.202845, Accuracy: 18.30%\n",
            "Epoch: 20, Step: 64/655, Loss: 2.202564, Accuracy: 18.46%\n",
            "Epoch: 20, Step: 65/655, Loss: 2.202108, Accuracy: 18.46%\n",
            "Epoch: 20, Step: 66/655, Loss: 2.202754, Accuracy: 18.42%\n",
            "Epoch: 20, Step: 67/655, Loss: 2.202022, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 68/655, Loss: 2.201760, Accuracy: 18.57%\n",
            "Epoch: 20, Step: 69/655, Loss: 2.201375, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 70/655, Loss: 2.201311, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 71/655, Loss: 2.200283, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 72/655, Loss: 2.200383, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 73/655, Loss: 2.200100, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 74/655, Loss: 2.201381, Accuracy: 18.54%\n",
            "Epoch: 20, Step: 75/655, Loss: 2.201075, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 76/655, Loss: 2.199884, Accuracy: 18.79%\n",
            "Epoch: 20, Step: 77/655, Loss: 2.199933, Accuracy: 18.83%\n",
            "Epoch: 20, Step: 78/655, Loss: 2.199568, Accuracy: 18.95%\n",
            "Epoch: 20, Step: 79/655, Loss: 2.200658, Accuracy: 18.83%\n",
            "Epoch: 20, Step: 80/655, Loss: 2.200644, Accuracy: 18.91%\n",
            "Epoch: 20, Step: 81/655, Loss: 2.199992, Accuracy: 18.94%\n",
            "Epoch: 20, Step: 82/655, Loss: 2.200802, Accuracy: 18.94%\n",
            "Epoch: 20, Step: 83/655, Loss: 2.201585, Accuracy: 18.86%\n",
            "Epoch: 20, Step: 84/655, Loss: 2.202848, Accuracy: 18.79%\n",
            "Epoch: 20, Step: 85/655, Loss: 2.203166, Accuracy: 18.71%\n",
            "Epoch: 20, Step: 86/655, Loss: 2.204339, Accuracy: 18.68%\n",
            "Epoch: 20, Step: 87/655, Loss: 2.204616, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 88/655, Loss: 2.204801, Accuracy: 18.57%\n",
            "Epoch: 20, Step: 89/655, Loss: 2.205443, Accuracy: 18.61%\n",
            "Epoch: 20, Step: 90/655, Loss: 2.204625, Accuracy: 18.54%\n",
            "Epoch: 20, Step: 91/655, Loss: 2.203983, Accuracy: 18.61%\n",
            "Epoch: 20, Step: 92/655, Loss: 2.203872, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 93/655, Loss: 2.203262, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 94/655, Loss: 2.202811, Accuracy: 18.72%\n",
            "Epoch: 20, Step: 95/655, Loss: 2.202414, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 96/655, Loss: 2.202604, Accuracy: 18.59%\n",
            "Epoch: 20, Step: 97/655, Loss: 2.203266, Accuracy: 18.49%\n",
            "Epoch: 20, Step: 98/655, Loss: 2.204233, Accuracy: 18.37%\n",
            "Epoch: 20, Step: 99/655, Loss: 2.203930, Accuracy: 18.40%\n",
            "Epoch: 20, Step: 100/655, Loss: 2.204592, Accuracy: 18.38%\n",
            "Epoch: 20, Step: 101/655, Loss: 2.206408, Accuracy: 18.25%\n",
            "Epoch: 20, Step: 102/655, Loss: 2.205915, Accuracy: 18.29%\n",
            "Epoch: 20, Step: 103/655, Loss: 2.205800, Accuracy: 18.23%\n",
            "Epoch: 20, Step: 104/655, Loss: 2.206359, Accuracy: 18.24%\n",
            "Epoch: 20, Step: 105/655, Loss: 2.206677, Accuracy: 18.27%\n",
            "Epoch: 20, Step: 106/655, Loss: 2.206059, Accuracy: 18.31%\n",
            "Epoch: 20, Step: 107/655, Loss: 2.206900, Accuracy: 18.28%\n",
            "Epoch: 20, Step: 108/655, Loss: 2.206785, Accuracy: 18.26%\n",
            "Epoch: 20, Step: 109/655, Loss: 2.207282, Accuracy: 18.32%\n",
            "Epoch: 20, Step: 110/655, Loss: 2.207343, Accuracy: 18.35%\n",
            "Epoch: 20, Step: 111/655, Loss: 2.206722, Accuracy: 18.41%\n",
            "Epoch: 20, Step: 112/655, Loss: 2.206007, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 113/655, Loss: 2.206039, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 114/655, Loss: 2.206776, Accuracy: 18.59%\n",
            "Epoch: 20, Step: 115/655, Loss: 2.208158, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 116/655, Loss: 2.207923, Accuracy: 18.59%\n",
            "Epoch: 20, Step: 117/655, Loss: 2.207746, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 118/655, Loss: 2.208166, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 119/655, Loss: 2.208582, Accuracy: 18.54%\n",
            "Epoch: 20, Step: 120/655, Loss: 2.207135, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 121/655, Loss: 2.206447, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 122/655, Loss: 2.206570, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 123/655, Loss: 2.205993, Accuracy: 18.57%\n",
            "Epoch: 20, Step: 124/655, Loss: 2.206886, Accuracy: 18.57%\n",
            "Epoch: 20, Step: 125/655, Loss: 2.207023, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 126/655, Loss: 2.207341, Accuracy: 18.50%\n",
            "Epoch: 20, Step: 127/655, Loss: 2.206708, Accuracy: 18.60%\n",
            "Epoch: 20, Step: 128/655, Loss: 2.207755, Accuracy: 18.60%\n",
            "Epoch: 20, Step: 129/655, Loss: 2.207104, Accuracy: 18.58%\n",
            "Epoch: 20, Step: 130/655, Loss: 2.207491, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 131/655, Loss: 2.207969, Accuracy: 18.54%\n",
            "Epoch: 20, Step: 132/655, Loss: 2.208363, Accuracy: 18.49%\n",
            "Epoch: 20, Step: 133/655, Loss: 2.209015, Accuracy: 18.44%\n",
            "Epoch: 20, Step: 134/655, Loss: 2.208402, Accuracy: 18.42%\n",
            "Epoch: 20, Step: 135/655, Loss: 2.208204, Accuracy: 18.45%\n",
            "Epoch: 20, Step: 136/655, Loss: 2.207414, Accuracy: 18.54%\n",
            "Epoch: 20, Step: 137/655, Loss: 2.208331, Accuracy: 18.45%\n",
            "Epoch: 20, Step: 138/655, Loss: 2.207367, Accuracy: 18.50%\n",
            "Epoch: 20, Step: 139/655, Loss: 2.207391, Accuracy: 18.46%\n",
            "Epoch: 20, Step: 140/655, Loss: 2.205997, Accuracy: 18.57%\n",
            "Epoch: 20, Step: 141/655, Loss: 2.206895, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 142/655, Loss: 2.207121, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 143/655, Loss: 2.207082, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 144/655, Loss: 2.207150, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 145/655, Loss: 2.207904, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 146/655, Loss: 2.208342, Accuracy: 18.49%\n",
            "Epoch: 20, Step: 147/655, Loss: 2.208959, Accuracy: 18.43%\n",
            "Epoch: 20, Step: 148/655, Loss: 2.209197, Accuracy: 18.41%\n",
            "Epoch: 20, Step: 149/655, Loss: 2.209077, Accuracy: 18.44%\n",
            "Epoch: 20, Step: 150/655, Loss: 2.209423, Accuracy: 18.42%\n",
            "Epoch: 20, Step: 151/655, Loss: 2.209092, Accuracy: 18.38%\n",
            "Epoch: 20, Step: 152/655, Loss: 2.209284, Accuracy: 18.36%\n",
            "Epoch: 20, Step: 153/655, Loss: 2.209575, Accuracy: 18.30%\n",
            "Epoch: 20, Step: 154/655, Loss: 2.209631, Accuracy: 18.28%\n",
            "Epoch: 20, Step: 155/655, Loss: 2.209853, Accuracy: 18.27%\n",
            "Epoch: 20, Step: 156/655, Loss: 2.210059, Accuracy: 18.31%\n",
            "Epoch: 20, Step: 157/655, Loss: 2.210164, Accuracy: 18.35%\n",
            "Epoch: 20, Step: 158/655, Loss: 2.209511, Accuracy: 18.43%\n",
            "Epoch: 20, Step: 159/655, Loss: 2.209443, Accuracy: 18.40%\n",
            "Epoch: 20, Step: 160/655, Loss: 2.210252, Accuracy: 18.38%\n",
            "Epoch: 20, Step: 161/655, Loss: 2.209897, Accuracy: 18.38%\n",
            "Epoch: 20, Step: 162/655, Loss: 2.209846, Accuracy: 18.36%\n",
            "Epoch: 20, Step: 163/655, Loss: 2.209759, Accuracy: 18.37%\n",
            "Epoch: 20, Step: 164/655, Loss: 2.209244, Accuracy: 18.37%\n",
            "Epoch: 20, Step: 165/655, Loss: 2.208352, Accuracy: 18.37%\n",
            "Epoch: 20, Step: 166/655, Loss: 2.208850, Accuracy: 18.35%\n",
            "Epoch: 20, Step: 167/655, Loss: 2.207984, Accuracy: 18.38%\n",
            "Epoch: 20, Step: 168/655, Loss: 2.207622, Accuracy: 18.40%\n",
            "Epoch: 20, Step: 169/655, Loss: 2.207134, Accuracy: 18.40%\n",
            "Epoch: 20, Step: 170/655, Loss: 2.206597, Accuracy: 18.46%\n",
            "Epoch: 20, Step: 171/655, Loss: 2.207111, Accuracy: 18.44%\n",
            "Epoch: 20, Step: 172/655, Loss: 2.207037, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 173/655, Loss: 2.206951, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 174/655, Loss: 2.207179, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 175/655, Loss: 2.206707, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 176/655, Loss: 2.206564, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 177/655, Loss: 2.206310, Accuracy: 18.54%\n",
            "Epoch: 20, Step: 178/655, Loss: 2.206617, Accuracy: 18.50%\n",
            "Epoch: 20, Step: 179/655, Loss: 2.206879, Accuracy: 18.49%\n",
            "Epoch: 20, Step: 180/655, Loss: 2.206135, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 181/655, Loss: 2.206214, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 182/655, Loss: 2.206444, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 183/655, Loss: 2.206131, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 184/655, Loss: 2.205793, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 185/655, Loss: 2.205830, Accuracy: 18.58%\n",
            "Epoch: 20, Step: 186/655, Loss: 2.205393, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 187/655, Loss: 2.204692, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 188/655, Loss: 2.204811, Accuracy: 18.60%\n",
            "Epoch: 20, Step: 189/655, Loss: 2.204288, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 190/655, Loss: 2.204272, Accuracy: 18.60%\n",
            "Epoch: 20, Step: 191/655, Loss: 2.204290, Accuracy: 18.60%\n",
            "Epoch: 20, Step: 192/655, Loss: 2.204400, Accuracy: 18.57%\n",
            "Epoch: 20, Step: 193/655, Loss: 2.204217, Accuracy: 18.60%\n",
            "Epoch: 20, Step: 194/655, Loss: 2.204097, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 195/655, Loss: 2.204028, Accuracy: 18.61%\n",
            "Epoch: 20, Step: 196/655, Loss: 2.204547, Accuracy: 18.56%\n",
            "Epoch: 20, Step: 197/655, Loss: 2.204666, Accuracy: 18.54%\n",
            "Epoch: 20, Step: 198/655, Loss: 2.205198, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 199/655, Loss: 2.205491, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 200/655, Loss: 2.205215, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 201/655, Loss: 2.205085, Accuracy: 18.59%\n",
            "Epoch: 20, Step: 202/655, Loss: 2.204528, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 203/655, Loss: 2.205099, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 204/655, Loss: 2.205700, Accuracy: 18.58%\n",
            "Epoch: 20, Step: 205/655, Loss: 2.205953, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 206/655, Loss: 2.206397, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 207/655, Loss: 2.206441, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 208/655, Loss: 2.206519, Accuracy: 18.49%\n",
            "Epoch: 20, Step: 209/655, Loss: 2.206366, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 210/655, Loss: 2.206551, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 211/655, Loss: 2.206311, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 212/655, Loss: 2.206369, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 213/655, Loss: 2.206699, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 214/655, Loss: 2.206793, Accuracy: 18.46%\n",
            "Epoch: 20, Step: 215/655, Loss: 2.207584, Accuracy: 18.43%\n",
            "Epoch: 20, Step: 216/655, Loss: 2.208488, Accuracy: 18.36%\n",
            "Epoch: 20, Step: 217/655, Loss: 2.208393, Accuracy: 18.38%\n",
            "Epoch: 20, Step: 218/655, Loss: 2.208431, Accuracy: 18.39%\n",
            "Epoch: 20, Step: 219/655, Loss: 2.208785, Accuracy: 18.41%\n",
            "Epoch: 20, Step: 220/655, Loss: 2.208942, Accuracy: 18.37%\n",
            "Epoch: 20, Step: 221/655, Loss: 2.208538, Accuracy: 18.37%\n",
            "Epoch: 20, Step: 222/655, Loss: 2.208372, Accuracy: 18.37%\n",
            "Epoch: 20, Step: 223/655, Loss: 2.208086, Accuracy: 18.43%\n",
            "Epoch: 20, Step: 224/655, Loss: 2.208762, Accuracy: 18.37%\n",
            "Epoch: 20, Step: 225/655, Loss: 2.208366, Accuracy: 18.36%\n",
            "Epoch: 20, Step: 226/655, Loss: 2.208337, Accuracy: 18.35%\n",
            "Epoch: 20, Step: 227/655, Loss: 2.207968, Accuracy: 18.42%\n",
            "Epoch: 20, Step: 228/655, Loss: 2.207941, Accuracy: 18.45%\n",
            "Epoch: 20, Step: 229/655, Loss: 2.208193, Accuracy: 18.40%\n",
            "Epoch: 20, Step: 230/655, Loss: 2.207572, Accuracy: 18.42%\n",
            "Epoch: 20, Step: 231/655, Loss: 2.207007, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 232/655, Loss: 2.207317, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 233/655, Loss: 2.207286, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 234/655, Loss: 2.207433, Accuracy: 18.56%\n",
            "Epoch: 20, Step: 235/655, Loss: 2.207271, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 236/655, Loss: 2.206967, Accuracy: 18.59%\n",
            "Epoch: 20, Step: 237/655, Loss: 2.207346, Accuracy: 18.60%\n",
            "Epoch: 20, Step: 238/655, Loss: 2.207028, Accuracy: 18.59%\n",
            "Epoch: 20, Step: 239/655, Loss: 2.206983, Accuracy: 18.61%\n",
            "Epoch: 20, Step: 240/655, Loss: 2.206719, Accuracy: 18.58%\n",
            "Epoch: 20, Step: 241/655, Loss: 2.206672, Accuracy: 18.61%\n",
            "Epoch: 20, Step: 242/655, Loss: 2.206310, Accuracy: 18.61%\n",
            "Epoch: 20, Step: 243/655, Loss: 2.206193, Accuracy: 18.61%\n",
            "Epoch: 20, Step: 244/655, Loss: 2.206211, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 245/655, Loss: 2.206304, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 246/655, Loss: 2.206312, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 247/655, Loss: 2.206601, Accuracy: 18.60%\n",
            "Epoch: 20, Step: 248/655, Loss: 2.206787, Accuracy: 18.60%\n",
            "Epoch: 20, Step: 249/655, Loss: 2.206965, Accuracy: 18.61%\n",
            "Epoch: 20, Step: 250/655, Loss: 2.207072, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 251/655, Loss: 2.207494, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 252/655, Loss: 2.207273, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 253/655, Loss: 2.207600, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 254/655, Loss: 2.207300, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 255/655, Loss: 2.207347, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 256/655, Loss: 2.207697, Accuracy: 18.60%\n",
            "Epoch: 20, Step: 257/655, Loss: 2.207600, Accuracy: 18.68%\n",
            "Epoch: 20, Step: 258/655, Loss: 2.207954, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 259/655, Loss: 2.208017, Accuracy: 18.59%\n",
            "Epoch: 20, Step: 260/655, Loss: 2.208100, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 261/655, Loss: 2.207982, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 262/655, Loss: 2.208400, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 263/655, Loss: 2.208401, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 264/655, Loss: 2.208380, Accuracy: 18.67%\n",
            "Epoch: 20, Step: 265/655, Loss: 2.208509, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 266/655, Loss: 2.208696, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 267/655, Loss: 2.208338, Accuracy: 18.68%\n",
            "Epoch: 20, Step: 268/655, Loss: 2.208027, Accuracy: 18.73%\n",
            "Epoch: 20, Step: 269/655, Loss: 2.207428, Accuracy: 18.76%\n",
            "Epoch: 20, Step: 270/655, Loss: 2.207742, Accuracy: 18.75%\n",
            "Epoch: 20, Step: 271/655, Loss: 2.207478, Accuracy: 18.78%\n",
            "Epoch: 20, Step: 272/655, Loss: 2.207205, Accuracy: 18.81%\n",
            "Epoch: 20, Step: 273/655, Loss: 2.206985, Accuracy: 18.83%\n",
            "Epoch: 20, Step: 274/655, Loss: 2.207140, Accuracy: 18.80%\n",
            "Epoch: 20, Step: 275/655, Loss: 2.207248, Accuracy: 18.82%\n",
            "Epoch: 20, Step: 276/655, Loss: 2.207410, Accuracy: 18.80%\n",
            "Epoch: 20, Step: 277/655, Loss: 2.207300, Accuracy: 18.80%\n",
            "Epoch: 20, Step: 278/655, Loss: 2.207339, Accuracy: 18.84%\n",
            "Epoch: 20, Step: 279/655, Loss: 2.207645, Accuracy: 18.82%\n",
            "Epoch: 20, Step: 280/655, Loss: 2.207900, Accuracy: 18.78%\n",
            "Epoch: 20, Step: 281/655, Loss: 2.208035, Accuracy: 18.74%\n",
            "Epoch: 20, Step: 282/655, Loss: 2.207216, Accuracy: 18.77%\n",
            "Epoch: 20, Step: 283/655, Loss: 2.207031, Accuracy: 18.78%\n",
            "Epoch: 20, Step: 284/655, Loss: 2.207417, Accuracy: 18.78%\n",
            "Epoch: 20, Step: 285/655, Loss: 2.207215, Accuracy: 18.78%\n",
            "Epoch: 20, Step: 286/655, Loss: 2.207191, Accuracy: 18.80%\n",
            "Epoch: 20, Step: 287/655, Loss: 2.207544, Accuracy: 18.76%\n",
            "Epoch: 20, Step: 288/655, Loss: 2.207394, Accuracy: 18.74%\n",
            "Epoch: 20, Step: 289/655, Loss: 2.207502, Accuracy: 18.74%\n",
            "Epoch: 20, Step: 290/655, Loss: 2.207825, Accuracy: 18.72%\n",
            "Epoch: 20, Step: 291/655, Loss: 2.207501, Accuracy: 18.72%\n",
            "Epoch: 20, Step: 292/655, Loss: 2.207612, Accuracy: 18.71%\n",
            "Epoch: 20, Step: 293/655, Loss: 2.207845, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 294/655, Loss: 2.208184, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 295/655, Loss: 2.208136, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 296/655, Loss: 2.208138, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 297/655, Loss: 2.208417, Accuracy: 18.67%\n",
            "Epoch: 20, Step: 298/655, Loss: 2.208548, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 299/655, Loss: 2.208538, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 300/655, Loss: 2.208867, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 301/655, Loss: 2.208599, Accuracy: 18.67%\n",
            "Epoch: 20, Step: 302/655, Loss: 2.208924, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 303/655, Loss: 2.209038, Accuracy: 18.67%\n",
            "Epoch: 20, Step: 304/655, Loss: 2.209327, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 305/655, Loss: 2.209067, Accuracy: 18.67%\n",
            "Epoch: 20, Step: 306/655, Loss: 2.209064, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 307/655, Loss: 2.209012, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 308/655, Loss: 2.209450, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 309/655, Loss: 2.209355, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 310/655, Loss: 2.209323, Accuracy: 18.61%\n",
            "Epoch: 20, Step: 311/655, Loss: 2.209047, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 312/655, Loss: 2.208778, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 313/655, Loss: 2.208758, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 314/655, Loss: 2.208695, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 315/655, Loss: 2.208905, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 316/655, Loss: 2.208905, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 317/655, Loss: 2.208773, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 318/655, Loss: 2.208969, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 319/655, Loss: 2.208782, Accuracy: 18.70%\n",
            "Epoch: 20, Step: 320/655, Loss: 2.209345, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 321/655, Loss: 2.209253, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 322/655, Loss: 2.209645, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 323/655, Loss: 2.209180, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 324/655, Loss: 2.208985, Accuracy: 18.67%\n",
            "Epoch: 20, Step: 325/655, Loss: 2.209234, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 326/655, Loss: 2.209467, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 327/655, Loss: 2.209147, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 328/655, Loss: 2.209539, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 329/655, Loss: 2.209653, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 330/655, Loss: 2.209416, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 331/655, Loss: 2.209875, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 332/655, Loss: 2.210166, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 333/655, Loss: 2.210203, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 334/655, Loss: 2.210205, Accuracy: 18.61%\n",
            "Epoch: 20, Step: 335/655, Loss: 2.210003, Accuracy: 18.68%\n",
            "Epoch: 20, Step: 336/655, Loss: 2.209996, Accuracy: 18.68%\n",
            "Epoch: 20, Step: 337/655, Loss: 2.209568, Accuracy: 18.70%\n",
            "Epoch: 20, Step: 338/655, Loss: 2.209460, Accuracy: 18.70%\n",
            "Epoch: 20, Step: 339/655, Loss: 2.209742, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 340/655, Loss: 2.209803, Accuracy: 18.68%\n",
            "Epoch: 20, Step: 341/655, Loss: 2.209463, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 342/655, Loss: 2.209780, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 343/655, Loss: 2.209943, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 344/655, Loss: 2.209983, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 345/655, Loss: 2.209886, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 346/655, Loss: 2.209745, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 347/655, Loss: 2.209826, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 348/655, Loss: 2.209281, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 349/655, Loss: 2.209392, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 350/655, Loss: 2.209501, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 351/655, Loss: 2.209433, Accuracy: 18.67%\n",
            "Epoch: 20, Step: 352/655, Loss: 2.208984, Accuracy: 18.68%\n",
            "Epoch: 20, Step: 353/655, Loss: 2.209013, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 354/655, Loss: 2.208795, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 355/655, Loss: 2.208873, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 356/655, Loss: 2.208928, Accuracy: 18.70%\n",
            "Epoch: 20, Step: 357/655, Loss: 2.209128, Accuracy: 18.71%\n",
            "Epoch: 20, Step: 358/655, Loss: 2.209316, Accuracy: 18.71%\n",
            "Epoch: 20, Step: 359/655, Loss: 2.209227, Accuracy: 18.72%\n",
            "Epoch: 20, Step: 360/655, Loss: 2.209052, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 361/655, Loss: 2.208897, Accuracy: 18.72%\n",
            "Epoch: 20, Step: 362/655, Loss: 2.208904, Accuracy: 18.72%\n",
            "Epoch: 20, Step: 363/655, Loss: 2.208812, Accuracy: 18.73%\n",
            "Epoch: 20, Step: 364/655, Loss: 2.209188, Accuracy: 18.73%\n",
            "Epoch: 20, Step: 365/655, Loss: 2.209171, Accuracy: 18.75%\n",
            "Epoch: 20, Step: 366/655, Loss: 2.209032, Accuracy: 18.76%\n",
            "Epoch: 20, Step: 367/655, Loss: 2.209466, Accuracy: 18.73%\n",
            "Epoch: 20, Step: 368/655, Loss: 2.209619, Accuracy: 18.70%\n",
            "Epoch: 20, Step: 369/655, Loss: 2.209626, Accuracy: 18.71%\n",
            "Epoch: 20, Step: 370/655, Loss: 2.210082, Accuracy: 18.68%\n",
            "Epoch: 20, Step: 371/655, Loss: 2.209827, Accuracy: 18.70%\n",
            "Epoch: 20, Step: 372/655, Loss: 2.209749, Accuracy: 18.67%\n",
            "Epoch: 20, Step: 373/655, Loss: 2.209889, Accuracy: 18.67%\n",
            "Epoch: 20, Step: 374/655, Loss: 2.210155, Accuracy: 18.68%\n",
            "Epoch: 20, Step: 375/655, Loss: 2.210209, Accuracy: 18.67%\n",
            "Epoch: 20, Step: 376/655, Loss: 2.210246, Accuracy: 18.68%\n",
            "Epoch: 20, Step: 377/655, Loss: 2.210061, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 378/655, Loss: 2.210247, Accuracy: 18.68%\n",
            "Epoch: 20, Step: 379/655, Loss: 2.209916, Accuracy: 18.70%\n",
            "Epoch: 20, Step: 380/655, Loss: 2.209814, Accuracy: 18.70%\n",
            "Epoch: 20, Step: 381/655, Loss: 2.209851, Accuracy: 18.70%\n",
            "Epoch: 20, Step: 382/655, Loss: 2.209784, Accuracy: 18.73%\n",
            "Epoch: 20, Step: 383/655, Loss: 2.209852, Accuracy: 18.73%\n",
            "Epoch: 20, Step: 384/655, Loss: 2.209360, Accuracy: 18.76%\n",
            "Epoch: 20, Step: 385/655, Loss: 2.209596, Accuracy: 18.73%\n",
            "Epoch: 20, Step: 386/655, Loss: 2.209880, Accuracy: 18.71%\n",
            "Epoch: 20, Step: 387/655, Loss: 2.209571, Accuracy: 18.73%\n",
            "Epoch: 20, Step: 388/655, Loss: 2.209732, Accuracy: 18.72%\n",
            "Epoch: 20, Step: 389/655, Loss: 2.209743, Accuracy: 18.73%\n",
            "Epoch: 20, Step: 390/655, Loss: 2.209400, Accuracy: 18.74%\n",
            "Epoch: 20, Step: 391/655, Loss: 2.209228, Accuracy: 18.73%\n",
            "Epoch: 20, Step: 392/655, Loss: 2.209133, Accuracy: 18.72%\n",
            "Epoch: 20, Step: 393/655, Loss: 2.208938, Accuracy: 18.71%\n",
            "Epoch: 20, Step: 394/655, Loss: 2.208935, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 395/655, Loss: 2.208560, Accuracy: 18.70%\n",
            "Epoch: 20, Step: 396/655, Loss: 2.208682, Accuracy: 18.70%\n",
            "Epoch: 20, Step: 397/655, Loss: 2.208317, Accuracy: 18.73%\n",
            "Epoch: 20, Step: 398/655, Loss: 2.208539, Accuracy: 18.73%\n",
            "Epoch: 20, Step: 399/655, Loss: 2.208504, Accuracy: 18.74%\n",
            "Epoch: 20, Step: 400/655, Loss: 2.208491, Accuracy: 18.72%\n",
            "Epoch: 20, Step: 401/655, Loss: 2.208660, Accuracy: 18.71%\n",
            "Epoch: 20, Step: 402/655, Loss: 2.208577, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 403/655, Loss: 2.208959, Accuracy: 18.67%\n",
            "Epoch: 20, Step: 404/655, Loss: 2.209177, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 405/655, Loss: 2.209100, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 406/655, Loss: 2.209412, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 407/655, Loss: 2.209262, Accuracy: 18.62%\n",
            "Epoch: 20, Step: 408/655, Loss: 2.209153, Accuracy: 18.61%\n",
            "Epoch: 20, Step: 409/655, Loss: 2.209307, Accuracy: 18.61%\n",
            "Epoch: 20, Step: 410/655, Loss: 2.209615, Accuracy: 18.58%\n",
            "Epoch: 20, Step: 411/655, Loss: 2.209623, Accuracy: 18.57%\n",
            "Epoch: 20, Step: 412/655, Loss: 2.209685, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 413/655, Loss: 2.210044, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 414/655, Loss: 2.210143, Accuracy: 18.49%\n",
            "Epoch: 20, Step: 415/655, Loss: 2.210075, Accuracy: 18.49%\n",
            "Epoch: 20, Step: 416/655, Loss: 2.209792, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 417/655, Loss: 2.209859, Accuracy: 18.49%\n",
            "Epoch: 20, Step: 418/655, Loss: 2.209710, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 419/655, Loss: 2.209693, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 420/655, Loss: 2.209446, Accuracy: 18.50%\n",
            "Epoch: 20, Step: 421/655, Loss: 2.209617, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 422/655, Loss: 2.209549, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 423/655, Loss: 2.209609, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 424/655, Loss: 2.209190, Accuracy: 18.56%\n",
            "Epoch: 20, Step: 425/655, Loss: 2.209123, Accuracy: 18.54%\n",
            "Epoch: 20, Step: 426/655, Loss: 2.208933, Accuracy: 18.56%\n",
            "Epoch: 20, Step: 427/655, Loss: 2.208886, Accuracy: 18.57%\n",
            "Epoch: 20, Step: 428/655, Loss: 2.208770, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 429/655, Loss: 2.208783, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 430/655, Loss: 2.208591, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 431/655, Loss: 2.208675, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 432/655, Loss: 2.208722, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 433/655, Loss: 2.208960, Accuracy: 18.50%\n",
            "Epoch: 20, Step: 434/655, Loss: 2.208989, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 435/655, Loss: 2.208837, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 436/655, Loss: 2.208549, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 437/655, Loss: 2.208273, Accuracy: 18.56%\n",
            "Epoch: 20, Step: 438/655, Loss: 2.207986, Accuracy: 18.58%\n",
            "Epoch: 20, Step: 439/655, Loss: 2.208228, Accuracy: 18.56%\n",
            "Epoch: 20, Step: 440/655, Loss: 2.208528, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 441/655, Loss: 2.208196, Accuracy: 18.54%\n",
            "Epoch: 20, Step: 442/655, Loss: 2.208080, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 443/655, Loss: 2.208181, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 444/655, Loss: 2.208055, Accuracy: 18.54%\n",
            "Epoch: 20, Step: 445/655, Loss: 2.208084, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 446/655, Loss: 2.208141, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 447/655, Loss: 2.208086, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 448/655, Loss: 2.208393, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 449/655, Loss: 2.208475, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 450/655, Loss: 2.208460, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 451/655, Loss: 2.208517, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 452/655, Loss: 2.208370, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 453/655, Loss: 2.208160, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 454/655, Loss: 2.208128, Accuracy: 18.56%\n",
            "Epoch: 20, Step: 455/655, Loss: 2.208382, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 456/655, Loss: 2.208195, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 457/655, Loss: 2.207901, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 458/655, Loss: 2.207922, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 459/655, Loss: 2.207633, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 460/655, Loss: 2.207480, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 461/655, Loss: 2.207356, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 462/655, Loss: 2.207525, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 463/655, Loss: 2.207524, Accuracy: 18.50%\n",
            "Epoch: 20, Step: 464/655, Loss: 2.207623, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 465/655, Loss: 2.207688, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 466/655, Loss: 2.207507, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 467/655, Loss: 2.207470, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 468/655, Loss: 2.207164, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 469/655, Loss: 2.207206, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 470/655, Loss: 2.207199, Accuracy: 18.50%\n",
            "Epoch: 20, Step: 471/655, Loss: 2.207172, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 472/655, Loss: 2.207117, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 473/655, Loss: 2.207210, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 474/655, Loss: 2.207439, Accuracy: 18.49%\n",
            "Epoch: 20, Step: 475/655, Loss: 2.207558, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 476/655, Loss: 2.207754, Accuracy: 18.46%\n",
            "Epoch: 20, Step: 477/655, Loss: 2.207669, Accuracy: 18.44%\n",
            "Epoch: 20, Step: 478/655, Loss: 2.207623, Accuracy: 18.44%\n",
            "Epoch: 20, Step: 479/655, Loss: 2.207924, Accuracy: 18.42%\n",
            "Epoch: 20, Step: 480/655, Loss: 2.207947, Accuracy: 18.41%\n",
            "Epoch: 20, Step: 481/655, Loss: 2.208020, Accuracy: 18.43%\n",
            "Epoch: 20, Step: 482/655, Loss: 2.208059, Accuracy: 18.43%\n",
            "Epoch: 20, Step: 483/655, Loss: 2.208064, Accuracy: 18.42%\n",
            "Epoch: 20, Step: 484/655, Loss: 2.208138, Accuracy: 18.42%\n",
            "Epoch: 20, Step: 485/655, Loss: 2.208235, Accuracy: 18.42%\n",
            "Epoch: 20, Step: 486/655, Loss: 2.208225, Accuracy: 18.43%\n",
            "Epoch: 20, Step: 487/655, Loss: 2.208232, Accuracy: 18.44%\n",
            "Epoch: 20, Step: 488/655, Loss: 2.208444, Accuracy: 18.42%\n",
            "Epoch: 20, Step: 489/655, Loss: 2.208624, Accuracy: 18.41%\n",
            "Epoch: 20, Step: 490/655, Loss: 2.208620, Accuracy: 18.43%\n",
            "Epoch: 20, Step: 491/655, Loss: 2.208404, Accuracy: 18.45%\n",
            "Epoch: 20, Step: 492/655, Loss: 2.208542, Accuracy: 18.44%\n",
            "Epoch: 20, Step: 493/655, Loss: 2.208598, Accuracy: 18.44%\n",
            "Epoch: 20, Step: 494/655, Loss: 2.208742, Accuracy: 18.43%\n",
            "Epoch: 20, Step: 495/655, Loss: 2.208883, Accuracy: 18.43%\n",
            "Epoch: 20, Step: 496/655, Loss: 2.208829, Accuracy: 18.43%\n",
            "Epoch: 20, Step: 497/655, Loss: 2.208823, Accuracy: 18.41%\n",
            "Epoch: 20, Step: 498/655, Loss: 2.208617, Accuracy: 18.44%\n",
            "Epoch: 20, Step: 499/655, Loss: 2.208732, Accuracy: 18.44%\n",
            "Epoch: 20, Step: 500/655, Loss: 2.208596, Accuracy: 18.46%\n",
            "Epoch: 20, Step: 501/655, Loss: 2.208667, Accuracy: 18.46%\n",
            "Epoch: 20, Step: 502/655, Loss: 2.208754, Accuracy: 18.44%\n",
            "Epoch: 20, Step: 503/655, Loss: 2.208886, Accuracy: 18.45%\n",
            "Epoch: 20, Step: 504/655, Loss: 2.208858, Accuracy: 18.45%\n",
            "Epoch: 20, Step: 505/655, Loss: 2.208783, Accuracy: 18.45%\n",
            "Epoch: 20, Step: 506/655, Loss: 2.208793, Accuracy: 18.45%\n",
            "Epoch: 20, Step: 507/655, Loss: 2.209052, Accuracy: 18.45%\n",
            "Epoch: 20, Step: 508/655, Loss: 2.208717, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 509/655, Loss: 2.208880, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 510/655, Loss: 2.208618, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 511/655, Loss: 2.208514, Accuracy: 18.50%\n",
            "Epoch: 20, Step: 512/655, Loss: 2.208290, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 513/655, Loss: 2.208290, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 514/655, Loss: 2.208265, Accuracy: 18.54%\n",
            "Epoch: 20, Step: 515/655, Loss: 2.208189, Accuracy: 18.54%\n",
            "Epoch: 20, Step: 516/655, Loss: 2.208230, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 517/655, Loss: 2.208261, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 518/655, Loss: 2.208452, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 519/655, Loss: 2.208388, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 520/655, Loss: 2.208111, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 521/655, Loss: 2.208276, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 522/655, Loss: 2.208245, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 523/655, Loss: 2.208422, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 524/655, Loss: 2.208678, Accuracy: 18.50%\n",
            "Epoch: 20, Step: 525/655, Loss: 2.208637, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 526/655, Loss: 2.208677, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 527/655, Loss: 2.208575, Accuracy: 18.50%\n",
            "Epoch: 20, Step: 528/655, Loss: 2.208399, Accuracy: 18.50%\n",
            "Epoch: 20, Step: 529/655, Loss: 2.208735, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 530/655, Loss: 2.208396, Accuracy: 18.49%\n",
            "Epoch: 20, Step: 531/655, Loss: 2.208511, Accuracy: 18.49%\n",
            "Epoch: 20, Step: 532/655, Loss: 2.208732, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 533/655, Loss: 2.208754, Accuracy: 18.46%\n",
            "Epoch: 20, Step: 534/655, Loss: 2.208558, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 535/655, Loss: 2.208525, Accuracy: 18.46%\n",
            "Epoch: 20, Step: 536/655, Loss: 2.208365, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 537/655, Loss: 2.208333, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 538/655, Loss: 2.208528, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 539/655, Loss: 2.208440, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 540/655, Loss: 2.208647, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 541/655, Loss: 2.208545, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 542/655, Loss: 2.208533, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 543/655, Loss: 2.208816, Accuracy: 18.45%\n",
            "Epoch: 20, Step: 544/655, Loss: 2.208850, Accuracy: 18.45%\n",
            "Epoch: 20, Step: 545/655, Loss: 2.208916, Accuracy: 18.46%\n",
            "Epoch: 20, Step: 546/655, Loss: 2.209026, Accuracy: 18.45%\n",
            "Epoch: 20, Step: 547/655, Loss: 2.209137, Accuracy: 18.44%\n",
            "Epoch: 20, Step: 548/655, Loss: 2.209285, Accuracy: 18.44%\n",
            "Epoch: 20, Step: 549/655, Loss: 2.209452, Accuracy: 18.43%\n",
            "Epoch: 20, Step: 550/655, Loss: 2.209520, Accuracy: 18.43%\n",
            "Epoch: 20, Step: 551/655, Loss: 2.209704, Accuracy: 18.42%\n",
            "Epoch: 20, Step: 552/655, Loss: 2.209637, Accuracy: 18.44%\n",
            "Epoch: 20, Step: 553/655, Loss: 2.209733, Accuracy: 18.42%\n",
            "Epoch: 20, Step: 554/655, Loss: 2.209827, Accuracy: 18.41%\n",
            "Epoch: 20, Step: 555/655, Loss: 2.209700, Accuracy: 18.43%\n",
            "Epoch: 20, Step: 556/655, Loss: 2.209528, Accuracy: 18.45%\n",
            "Epoch: 20, Step: 557/655, Loss: 2.209499, Accuracy: 18.45%\n",
            "Epoch: 20, Step: 558/655, Loss: 2.209534, Accuracy: 18.44%\n",
            "Epoch: 20, Step: 559/655, Loss: 2.209510, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 560/655, Loss: 2.209559, Accuracy: 18.46%\n",
            "Epoch: 20, Step: 561/655, Loss: 2.209580, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 562/655, Loss: 2.209554, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 563/655, Loss: 2.209439, Accuracy: 18.49%\n",
            "Epoch: 20, Step: 564/655, Loss: 2.209215, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 565/655, Loss: 2.209291, Accuracy: 18.50%\n",
            "Epoch: 20, Step: 566/655, Loss: 2.209163, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 567/655, Loss: 2.209242, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 568/655, Loss: 2.209446, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 569/655, Loss: 2.209648, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 570/655, Loss: 2.209601, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 571/655, Loss: 2.209503, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 572/655, Loss: 2.209501, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 573/655, Loss: 2.209464, Accuracy: 18.54%\n",
            "Epoch: 20, Step: 574/655, Loss: 2.209413, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 575/655, Loss: 2.209345, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 576/655, Loss: 2.209280, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 577/655, Loss: 2.209348, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 578/655, Loss: 2.209300, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 579/655, Loss: 2.209162, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 580/655, Loss: 2.209410, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 581/655, Loss: 2.209568, Accuracy: 18.49%\n",
            "Epoch: 20, Step: 582/655, Loss: 2.209564, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 583/655, Loss: 2.209704, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 584/655, Loss: 2.209636, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 585/655, Loss: 2.209707, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 586/655, Loss: 2.209668, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 587/655, Loss: 2.209556, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 588/655, Loss: 2.209518, Accuracy: 18.46%\n",
            "Epoch: 20, Step: 589/655, Loss: 2.209416, Accuracy: 18.48%\n",
            "Epoch: 20, Step: 590/655, Loss: 2.209630, Accuracy: 18.47%\n",
            "Epoch: 20, Step: 591/655, Loss: 2.209312, Accuracy: 18.49%\n",
            "Epoch: 20, Step: 592/655, Loss: 2.209309, Accuracy: 18.50%\n",
            "Epoch: 20, Step: 593/655, Loss: 2.209164, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 594/655, Loss: 2.209320, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 595/655, Loss: 2.209278, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 596/655, Loss: 2.209018, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 597/655, Loss: 2.209135, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 598/655, Loss: 2.209102, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 599/655, Loss: 2.209157, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 600/655, Loss: 2.209082, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 601/655, Loss: 2.209270, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 602/655, Loss: 2.209254, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 603/655, Loss: 2.209191, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 604/655, Loss: 2.209074, Accuracy: 18.50%\n",
            "Epoch: 20, Step: 605/655, Loss: 2.208998, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 606/655, Loss: 2.208715, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 607/655, Loss: 2.208740, Accuracy: 18.56%\n",
            "Epoch: 20, Step: 608/655, Loss: 2.208799, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 609/655, Loss: 2.208929, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 610/655, Loss: 2.209064, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 611/655, Loss: 2.209192, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 612/655, Loss: 2.209159, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 613/655, Loss: 2.209049, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 614/655, Loss: 2.209031, Accuracy: 18.53%\n",
            "Epoch: 20, Step: 615/655, Loss: 2.208852, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 616/655, Loss: 2.209016, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 617/655, Loss: 2.208920, Accuracy: 18.50%\n",
            "Epoch: 20, Step: 618/655, Loss: 2.208717, Accuracy: 18.52%\n",
            "Epoch: 20, Step: 619/655, Loss: 2.208790, Accuracy: 18.51%\n",
            "Epoch: 20, Step: 620/655, Loss: 2.208516, Accuracy: 18.54%\n",
            "Epoch: 20, Step: 621/655, Loss: 2.208255, Accuracy: 18.55%\n",
            "Epoch: 20, Step: 622/655, Loss: 2.208312, Accuracy: 18.56%\n",
            "Epoch: 20, Step: 623/655, Loss: 2.208129, Accuracy: 18.58%\n",
            "Epoch: 20, Step: 624/655, Loss: 2.208100, Accuracy: 18.57%\n",
            "Epoch: 20, Step: 625/655, Loss: 2.208022, Accuracy: 18.59%\n",
            "Epoch: 20, Step: 626/655, Loss: 2.208007, Accuracy: 18.59%\n",
            "Epoch: 20, Step: 627/655, Loss: 2.207901, Accuracy: 18.61%\n",
            "Epoch: 20, Step: 628/655, Loss: 2.207948, Accuracy: 18.60%\n",
            "Epoch: 20, Step: 629/655, Loss: 2.207851, Accuracy: 18.59%\n",
            "Epoch: 20, Step: 630/655, Loss: 2.207806, Accuracy: 18.59%\n",
            "Epoch: 20, Step: 631/655, Loss: 2.207796, Accuracy: 18.59%\n",
            "Epoch: 20, Step: 632/655, Loss: 2.207935, Accuracy: 18.57%\n",
            "Epoch: 20, Step: 633/655, Loss: 2.207956, Accuracy: 18.58%\n",
            "Epoch: 20, Step: 634/655, Loss: 2.207979, Accuracy: 18.59%\n",
            "Epoch: 20, Step: 635/655, Loss: 2.207868, Accuracy: 18.61%\n",
            "Epoch: 20, Step: 636/655, Loss: 2.207671, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 637/655, Loss: 2.207580, Accuracy: 18.65%\n",
            "Epoch: 20, Step: 638/655, Loss: 2.207574, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 639/655, Loss: 2.207406, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 640/655, Loss: 2.207428, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 641/655, Loss: 2.207481, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 642/655, Loss: 2.207419, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 643/655, Loss: 2.207360, Accuracy: 18.67%\n",
            "Epoch: 20, Step: 644/655, Loss: 2.207211, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 645/655, Loss: 2.207179, Accuracy: 18.68%\n",
            "Epoch: 20, Step: 646/655, Loss: 2.207026, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 647/655, Loss: 2.206962, Accuracy: 18.69%\n",
            "Epoch: 20, Step: 648/655, Loss: 2.207150, Accuracy: 18.68%\n",
            "Epoch: 20, Step: 649/655, Loss: 2.207284, Accuracy: 18.67%\n",
            "Epoch: 20, Step: 650/655, Loss: 2.207588, Accuracy: 18.66%\n",
            "Epoch: 20, Step: 651/655, Loss: 2.207801, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 652/655, Loss: 2.207825, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 653/655, Loss: 2.207945, Accuracy: 18.64%\n",
            "Epoch: 20, Step: 654/655, Loss: 2.207782, Accuracy: 18.63%\n",
            "Epoch: 20, Step: 655/655, Loss: 2.207907, Accuracy: 18.63%\n",
            "Epoch: 21, Step: 1/655, Loss: 2.272919, Accuracy: 15.62%\n",
            "Epoch: 21, Step: 2/655, Loss: 2.231461, Accuracy: 20.31%\n",
            "Epoch: 21, Step: 3/655, Loss: 2.227804, Accuracy: 19.79%\n",
            "Epoch: 21, Step: 4/655, Loss: 2.219633, Accuracy: 21.09%\n",
            "Epoch: 21, Step: 5/655, Loss: 2.234575, Accuracy: 20.62%\n",
            "Epoch: 21, Step: 6/655, Loss: 2.222644, Accuracy: 21.35%\n",
            "Epoch: 21, Step: 7/655, Loss: 2.224288, Accuracy: 20.09%\n",
            "Epoch: 21, Step: 8/655, Loss: 2.214250, Accuracy: 20.31%\n",
            "Epoch: 21, Step: 9/655, Loss: 2.211885, Accuracy: 20.14%\n",
            "Epoch: 21, Step: 10/655, Loss: 2.218615, Accuracy: 19.69%\n",
            "Epoch: 21, Step: 11/655, Loss: 2.218187, Accuracy: 19.89%\n",
            "Epoch: 21, Step: 12/655, Loss: 2.223741, Accuracy: 19.01%\n",
            "Epoch: 21, Step: 13/655, Loss: 2.217124, Accuracy: 19.71%\n",
            "Epoch: 21, Step: 14/655, Loss: 2.205106, Accuracy: 20.54%\n",
            "Epoch: 21, Step: 15/655, Loss: 2.211979, Accuracy: 20.21%\n",
            "Epoch: 21, Step: 16/655, Loss: 2.206914, Accuracy: 20.70%\n",
            "Epoch: 21, Step: 17/655, Loss: 2.209434, Accuracy: 20.40%\n",
            "Epoch: 21, Step: 18/655, Loss: 2.203757, Accuracy: 20.66%\n",
            "Epoch: 21, Step: 19/655, Loss: 2.201372, Accuracy: 20.72%\n",
            "Epoch: 21, Step: 20/655, Loss: 2.200579, Accuracy: 20.47%\n",
            "Epoch: 21, Step: 21/655, Loss: 2.197071, Accuracy: 20.68%\n",
            "Epoch: 21, Step: 22/655, Loss: 2.193012, Accuracy: 20.60%\n",
            "Epoch: 21, Step: 23/655, Loss: 2.193332, Accuracy: 20.24%\n",
            "Epoch: 21, Step: 24/655, Loss: 2.190854, Accuracy: 20.31%\n",
            "Epoch: 21, Step: 25/655, Loss: 2.189703, Accuracy: 20.38%\n",
            "Epoch: 21, Step: 26/655, Loss: 2.194749, Accuracy: 20.07%\n",
            "Epoch: 21, Step: 27/655, Loss: 2.194700, Accuracy: 20.14%\n",
            "Epoch: 21, Step: 28/655, Loss: 2.193012, Accuracy: 19.75%\n",
            "Epoch: 21, Step: 29/655, Loss: 2.193764, Accuracy: 19.61%\n",
            "Epoch: 21, Step: 30/655, Loss: 2.192856, Accuracy: 19.48%\n",
            "Epoch: 21, Step: 31/655, Loss: 2.192240, Accuracy: 19.46%\n",
            "Epoch: 21, Step: 32/655, Loss: 2.191930, Accuracy: 19.04%\n",
            "Epoch: 21, Step: 33/655, Loss: 2.194900, Accuracy: 18.75%\n",
            "Epoch: 21, Step: 34/655, Loss: 2.200130, Accuracy: 18.66%\n",
            "Epoch: 21, Step: 35/655, Loss: 2.200846, Accuracy: 18.66%\n",
            "Epoch: 21, Step: 36/655, Loss: 2.200345, Accuracy: 18.58%\n",
            "Epoch: 21, Step: 37/655, Loss: 2.201929, Accuracy: 18.33%\n",
            "Epoch: 21, Step: 38/655, Loss: 2.200702, Accuracy: 18.26%\n",
            "Epoch: 21, Step: 39/655, Loss: 2.201505, Accuracy: 18.43%\n",
            "Epoch: 21, Step: 40/655, Loss: 2.201675, Accuracy: 18.20%\n",
            "Epoch: 21, Step: 41/655, Loss: 2.199507, Accuracy: 18.52%\n",
            "Epoch: 21, Step: 42/655, Loss: 2.201866, Accuracy: 18.30%\n",
            "Epoch: 21, Step: 43/655, Loss: 2.202335, Accuracy: 18.31%\n",
            "Epoch: 21, Step: 44/655, Loss: 2.204750, Accuracy: 18.18%\n",
            "Epoch: 21, Step: 45/655, Loss: 2.205749, Accuracy: 17.92%\n",
            "Epoch: 21, Step: 46/655, Loss: 2.204757, Accuracy: 17.80%\n",
            "Epoch: 21, Step: 47/655, Loss: 2.204513, Accuracy: 17.82%\n",
            "Epoch: 21, Step: 48/655, Loss: 2.207779, Accuracy: 17.71%\n",
            "Epoch: 21, Step: 49/655, Loss: 2.208928, Accuracy: 17.60%\n",
            "Epoch: 21, Step: 50/655, Loss: 2.206542, Accuracy: 17.88%\n",
            "Epoch: 21, Step: 51/655, Loss: 2.208185, Accuracy: 17.89%\n",
            "Epoch: 21, Step: 52/655, Loss: 2.206254, Accuracy: 18.33%\n",
            "Epoch: 21, Step: 53/655, Loss: 2.206217, Accuracy: 18.40%\n",
            "Epoch: 21, Step: 54/655, Loss: 2.209406, Accuracy: 18.34%\n",
            "Epoch: 21, Step: 55/655, Loss: 2.206934, Accuracy: 18.41%\n",
            "Epoch: 21, Step: 56/655, Loss: 2.205005, Accuracy: 18.58%\n",
            "Epoch: 21, Step: 57/655, Loss: 2.205934, Accuracy: 18.70%\n",
            "Epoch: 21, Step: 58/655, Loss: 2.203907, Accuracy: 18.86%\n",
            "Epoch: 21, Step: 59/655, Loss: 2.201314, Accuracy: 18.96%\n",
            "Epoch: 21, Step: 60/655, Loss: 2.201849, Accuracy: 19.01%\n",
            "Epoch: 21, Step: 61/655, Loss: 2.201626, Accuracy: 19.11%\n",
            "Epoch: 21, Step: 62/655, Loss: 2.201878, Accuracy: 19.05%\n",
            "Epoch: 21, Step: 63/655, Loss: 2.202571, Accuracy: 19.15%\n",
            "Epoch: 21, Step: 64/655, Loss: 2.199724, Accuracy: 19.24%\n",
            "Epoch: 21, Step: 65/655, Loss: 2.199559, Accuracy: 19.28%\n",
            "Epoch: 21, Step: 66/655, Loss: 2.199699, Accuracy: 19.32%\n",
            "Epoch: 21, Step: 67/655, Loss: 2.199327, Accuracy: 19.31%\n",
            "Epoch: 21, Step: 68/655, Loss: 2.198596, Accuracy: 19.39%\n",
            "Epoch: 21, Step: 69/655, Loss: 2.197638, Accuracy: 19.38%\n",
            "Epoch: 21, Step: 70/655, Loss: 2.198125, Accuracy: 19.20%\n",
            "Epoch: 21, Step: 71/655, Loss: 2.199488, Accuracy: 19.10%\n",
            "Epoch: 21, Step: 72/655, Loss: 2.200583, Accuracy: 18.92%\n",
            "Epoch: 21, Step: 73/655, Loss: 2.200686, Accuracy: 19.01%\n",
            "Epoch: 21, Step: 74/655, Loss: 2.201190, Accuracy: 19.09%\n",
            "Epoch: 21, Step: 75/655, Loss: 2.201304, Accuracy: 19.12%\n",
            "Epoch: 21, Step: 76/655, Loss: 2.201728, Accuracy: 19.08%\n",
            "Epoch: 21, Step: 77/655, Loss: 2.201203, Accuracy: 19.07%\n",
            "Epoch: 21, Step: 78/655, Loss: 2.201774, Accuracy: 18.99%\n",
            "Epoch: 21, Step: 79/655, Loss: 2.200124, Accuracy: 18.95%\n",
            "Epoch: 21, Step: 80/655, Loss: 2.198970, Accuracy: 18.98%\n",
            "Epoch: 21, Step: 81/655, Loss: 2.197773, Accuracy: 19.06%\n",
            "Epoch: 21, Step: 82/655, Loss: 2.197651, Accuracy: 18.98%\n",
            "Epoch: 21, Step: 83/655, Loss: 2.197595, Accuracy: 18.86%\n",
            "Epoch: 21, Step: 84/655, Loss: 2.197178, Accuracy: 19.05%\n",
            "Epoch: 21, Step: 85/655, Loss: 2.198441, Accuracy: 19.01%\n",
            "Epoch: 21, Step: 86/655, Loss: 2.198132, Accuracy: 18.93%\n",
            "Epoch: 21, Step: 87/655, Loss: 2.198770, Accuracy: 18.93%\n",
            "Epoch: 21, Step: 88/655, Loss: 2.198931, Accuracy: 18.82%\n",
            "Epoch: 21, Step: 89/655, Loss: 2.198250, Accuracy: 18.82%\n",
            "Epoch: 21, Step: 90/655, Loss: 2.197878, Accuracy: 18.78%\n",
            "Epoch: 21, Step: 91/655, Loss: 2.198187, Accuracy: 18.75%\n",
            "Epoch: 21, Step: 92/655, Loss: 2.201206, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 93/655, Loss: 2.201369, Accuracy: 18.68%\n",
            "Epoch: 21, Step: 94/655, Loss: 2.201809, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 95/655, Loss: 2.201879, Accuracy: 18.55%\n",
            "Epoch: 21, Step: 96/655, Loss: 2.202910, Accuracy: 18.55%\n",
            "Epoch: 21, Step: 97/655, Loss: 2.201846, Accuracy: 18.69%\n",
            "Epoch: 21, Step: 98/655, Loss: 2.201863, Accuracy: 18.69%\n",
            "Epoch: 21, Step: 99/655, Loss: 2.203000, Accuracy: 18.59%\n",
            "Epoch: 21, Step: 100/655, Loss: 2.203671, Accuracy: 18.59%\n",
            "Epoch: 21, Step: 101/655, Loss: 2.203695, Accuracy: 18.66%\n",
            "Epoch: 21, Step: 102/655, Loss: 2.203826, Accuracy: 18.69%\n",
            "Epoch: 21, Step: 103/655, Loss: 2.202898, Accuracy: 18.84%\n",
            "Epoch: 21, Step: 104/655, Loss: 2.202964, Accuracy: 18.84%\n",
            "Epoch: 21, Step: 105/655, Loss: 2.203360, Accuracy: 18.78%\n",
            "Epoch: 21, Step: 106/655, Loss: 2.203594, Accuracy: 18.72%\n",
            "Epoch: 21, Step: 107/655, Loss: 2.203449, Accuracy: 18.75%\n",
            "Epoch: 21, Step: 108/655, Loss: 2.203295, Accuracy: 18.69%\n",
            "Epoch: 21, Step: 109/655, Loss: 2.202165, Accuracy: 18.81%\n",
            "Epoch: 21, Step: 110/655, Loss: 2.202435, Accuracy: 18.78%\n",
            "Epoch: 21, Step: 111/655, Loss: 2.201680, Accuracy: 18.75%\n",
            "Epoch: 21, Step: 112/655, Loss: 2.201796, Accuracy: 18.75%\n",
            "Epoch: 21, Step: 113/655, Loss: 2.201787, Accuracy: 18.72%\n",
            "Epoch: 21, Step: 114/655, Loss: 2.202082, Accuracy: 18.64%\n",
            "Epoch: 21, Step: 115/655, Loss: 2.201763, Accuracy: 18.64%\n",
            "Epoch: 21, Step: 116/655, Loss: 2.201005, Accuracy: 18.67%\n",
            "Epoch: 21, Step: 117/655, Loss: 2.202356, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 118/655, Loss: 2.203331, Accuracy: 18.59%\n",
            "Epoch: 21, Step: 119/655, Loss: 2.202835, Accuracy: 18.64%\n",
            "Epoch: 21, Step: 120/655, Loss: 2.203118, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 121/655, Loss: 2.203118, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 122/655, Loss: 2.204072, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 123/655, Loss: 2.203369, Accuracy: 18.67%\n",
            "Epoch: 21, Step: 124/655, Loss: 2.203625, Accuracy: 18.67%\n",
            "Epoch: 21, Step: 125/655, Loss: 2.203614, Accuracy: 18.73%\n",
            "Epoch: 21, Step: 126/655, Loss: 2.202596, Accuracy: 18.77%\n",
            "Epoch: 21, Step: 127/655, Loss: 2.202139, Accuracy: 18.77%\n",
            "Epoch: 21, Step: 128/655, Loss: 2.202306, Accuracy: 18.77%\n",
            "Epoch: 21, Step: 129/655, Loss: 2.201914, Accuracy: 18.87%\n",
            "Epoch: 21, Step: 130/655, Loss: 2.201780, Accuracy: 18.94%\n",
            "Epoch: 21, Step: 131/655, Loss: 2.202181, Accuracy: 18.92%\n",
            "Epoch: 21, Step: 132/655, Loss: 2.201045, Accuracy: 18.94%\n",
            "Epoch: 21, Step: 133/655, Loss: 2.200956, Accuracy: 18.96%\n",
            "Epoch: 21, Step: 134/655, Loss: 2.200436, Accuracy: 18.94%\n",
            "Epoch: 21, Step: 135/655, Loss: 2.199627, Accuracy: 18.98%\n",
            "Epoch: 21, Step: 136/655, Loss: 2.200267, Accuracy: 18.93%\n",
            "Epoch: 21, Step: 137/655, Loss: 2.199489, Accuracy: 19.02%\n",
            "Epoch: 21, Step: 138/655, Loss: 2.200062, Accuracy: 18.95%\n",
            "Epoch: 21, Step: 139/655, Loss: 2.199342, Accuracy: 18.95%\n",
            "Epoch: 21, Step: 140/655, Loss: 2.198922, Accuracy: 19.02%\n",
            "Epoch: 21, Step: 141/655, Loss: 2.198085, Accuracy: 19.08%\n",
            "Epoch: 21, Step: 142/655, Loss: 2.197244, Accuracy: 19.17%\n",
            "Epoch: 21, Step: 143/655, Loss: 2.198339, Accuracy: 19.08%\n",
            "Epoch: 21, Step: 144/655, Loss: 2.198875, Accuracy: 19.08%\n",
            "Epoch: 21, Step: 145/655, Loss: 2.200306, Accuracy: 19.01%\n",
            "Epoch: 21, Step: 146/655, Loss: 2.200704, Accuracy: 19.07%\n",
            "Epoch: 21, Step: 147/655, Loss: 2.201009, Accuracy: 19.03%\n",
            "Epoch: 21, Step: 148/655, Loss: 2.201901, Accuracy: 18.98%\n",
            "Epoch: 21, Step: 149/655, Loss: 2.202988, Accuracy: 18.92%\n",
            "Epoch: 21, Step: 150/655, Loss: 2.203369, Accuracy: 18.94%\n",
            "Epoch: 21, Step: 151/655, Loss: 2.203417, Accuracy: 19.00%\n",
            "Epoch: 21, Step: 152/655, Loss: 2.204138, Accuracy: 18.96%\n",
            "Epoch: 21, Step: 153/655, Loss: 2.204324, Accuracy: 18.91%\n",
            "Epoch: 21, Step: 154/655, Loss: 2.203774, Accuracy: 18.87%\n",
            "Epoch: 21, Step: 155/655, Loss: 2.203118, Accuracy: 18.91%\n",
            "Epoch: 21, Step: 156/655, Loss: 2.202580, Accuracy: 18.89%\n",
            "Epoch: 21, Step: 157/655, Loss: 2.202855, Accuracy: 18.93%\n",
            "Epoch: 21, Step: 158/655, Loss: 2.202842, Accuracy: 18.95%\n",
            "Epoch: 21, Step: 159/655, Loss: 2.202334, Accuracy: 18.95%\n",
            "Epoch: 21, Step: 160/655, Loss: 2.202251, Accuracy: 18.96%\n",
            "Epoch: 21, Step: 161/655, Loss: 2.203065, Accuracy: 18.91%\n",
            "Epoch: 21, Step: 162/655, Loss: 2.202325, Accuracy: 18.96%\n",
            "Epoch: 21, Step: 163/655, Loss: 2.201493, Accuracy: 19.02%\n",
            "Epoch: 21, Step: 164/655, Loss: 2.201071, Accuracy: 19.02%\n",
            "Epoch: 21, Step: 165/655, Loss: 2.201138, Accuracy: 19.03%\n",
            "Epoch: 21, Step: 166/655, Loss: 2.200620, Accuracy: 19.01%\n",
            "Epoch: 21, Step: 167/655, Loss: 2.200021, Accuracy: 18.99%\n",
            "Epoch: 21, Step: 168/655, Loss: 2.200115, Accuracy: 18.95%\n",
            "Epoch: 21, Step: 169/655, Loss: 2.199668, Accuracy: 18.97%\n",
            "Epoch: 21, Step: 170/655, Loss: 2.200835, Accuracy: 18.95%\n",
            "Epoch: 21, Step: 171/655, Loss: 2.200633, Accuracy: 19.01%\n",
            "Epoch: 21, Step: 172/655, Loss: 2.200941, Accuracy: 19.00%\n",
            "Epoch: 21, Step: 173/655, Loss: 2.200566, Accuracy: 19.08%\n",
            "Epoch: 21, Step: 174/655, Loss: 2.200258, Accuracy: 19.09%\n",
            "Epoch: 21, Step: 175/655, Loss: 2.201111, Accuracy: 19.04%\n",
            "Epoch: 21, Step: 176/655, Loss: 2.202191, Accuracy: 18.96%\n",
            "Epoch: 21, Step: 177/655, Loss: 2.202062, Accuracy: 18.98%\n",
            "Epoch: 21, Step: 178/655, Loss: 2.202028, Accuracy: 18.96%\n",
            "Epoch: 21, Step: 179/655, Loss: 2.201265, Accuracy: 19.01%\n",
            "Epoch: 21, Step: 180/655, Loss: 2.201762, Accuracy: 18.94%\n",
            "Epoch: 21, Step: 181/655, Loss: 2.202241, Accuracy: 18.96%\n",
            "Epoch: 21, Step: 182/655, Loss: 2.202211, Accuracy: 18.94%\n",
            "Epoch: 21, Step: 183/655, Loss: 2.202055, Accuracy: 18.94%\n",
            "Epoch: 21, Step: 184/655, Loss: 2.201709, Accuracy: 18.97%\n",
            "Epoch: 21, Step: 185/655, Loss: 2.202123, Accuracy: 18.92%\n",
            "Epoch: 21, Step: 186/655, Loss: 2.201609, Accuracy: 18.93%\n",
            "Epoch: 21, Step: 187/655, Loss: 2.201843, Accuracy: 18.90%\n",
            "Epoch: 21, Step: 188/655, Loss: 2.201638, Accuracy: 18.92%\n",
            "Epoch: 21, Step: 189/655, Loss: 2.201798, Accuracy: 18.88%\n",
            "Epoch: 21, Step: 190/655, Loss: 2.201063, Accuracy: 18.93%\n",
            "Epoch: 21, Step: 191/655, Loss: 2.201104, Accuracy: 18.95%\n",
            "Epoch: 21, Step: 192/655, Loss: 2.200859, Accuracy: 18.93%\n",
            "Epoch: 21, Step: 193/655, Loss: 2.200882, Accuracy: 18.94%\n",
            "Epoch: 21, Step: 194/655, Loss: 2.200876, Accuracy: 18.96%\n",
            "Epoch: 21, Step: 195/655, Loss: 2.200258, Accuracy: 18.96%\n",
            "Epoch: 21, Step: 196/655, Loss: 2.200273, Accuracy: 18.94%\n",
            "Epoch: 21, Step: 197/655, Loss: 2.200082, Accuracy: 18.96%\n",
            "Epoch: 21, Step: 198/655, Loss: 2.200151, Accuracy: 18.91%\n",
            "Epoch: 21, Step: 199/655, Loss: 2.200265, Accuracy: 18.91%\n",
            "Epoch: 21, Step: 200/655, Loss: 2.200256, Accuracy: 18.89%\n",
            "Epoch: 21, Step: 201/655, Loss: 2.200264, Accuracy: 18.86%\n",
            "Epoch: 21, Step: 202/655, Loss: 2.200166, Accuracy: 18.94%\n",
            "Epoch: 21, Step: 203/655, Loss: 2.200032, Accuracy: 19.00%\n",
            "Epoch: 21, Step: 204/655, Loss: 2.200500, Accuracy: 19.00%\n",
            "Epoch: 21, Step: 205/655, Loss: 2.200513, Accuracy: 18.96%\n",
            "Epoch: 21, Step: 206/655, Loss: 2.200955, Accuracy: 18.93%\n",
            "Epoch: 21, Step: 207/655, Loss: 2.201280, Accuracy: 18.96%\n",
            "Epoch: 21, Step: 208/655, Loss: 2.201289, Accuracy: 19.04%\n",
            "Epoch: 21, Step: 209/655, Loss: 2.201370, Accuracy: 18.99%\n",
            "Epoch: 21, Step: 210/655, Loss: 2.201329, Accuracy: 19.03%\n",
            "Epoch: 21, Step: 211/655, Loss: 2.202052, Accuracy: 19.02%\n",
            "Epoch: 21, Step: 212/655, Loss: 2.201610, Accuracy: 19.07%\n",
            "Epoch: 21, Step: 213/655, Loss: 2.201586, Accuracy: 19.06%\n",
            "Epoch: 21, Step: 214/655, Loss: 2.201775, Accuracy: 19.03%\n",
            "Epoch: 21, Step: 215/655, Loss: 2.201487, Accuracy: 19.00%\n",
            "Epoch: 21, Step: 216/655, Loss: 2.201911, Accuracy: 18.95%\n",
            "Epoch: 21, Step: 217/655, Loss: 2.202432, Accuracy: 18.91%\n",
            "Epoch: 21, Step: 218/655, Loss: 2.202429, Accuracy: 18.88%\n",
            "Epoch: 21, Step: 219/655, Loss: 2.202366, Accuracy: 18.85%\n",
            "Epoch: 21, Step: 220/655, Loss: 2.202272, Accuracy: 18.85%\n",
            "Epoch: 21, Step: 221/655, Loss: 2.201928, Accuracy: 18.91%\n",
            "Epoch: 21, Step: 222/655, Loss: 2.202503, Accuracy: 18.89%\n",
            "Epoch: 21, Step: 223/655, Loss: 2.202143, Accuracy: 18.90%\n",
            "Epoch: 21, Step: 224/655, Loss: 2.202103, Accuracy: 18.89%\n",
            "Epoch: 21, Step: 225/655, Loss: 2.202177, Accuracy: 18.88%\n",
            "Epoch: 21, Step: 226/655, Loss: 2.202583, Accuracy: 18.86%\n",
            "Epoch: 21, Step: 227/655, Loss: 2.202497, Accuracy: 18.85%\n",
            "Epoch: 21, Step: 228/655, Loss: 2.203043, Accuracy: 18.82%\n",
            "Epoch: 21, Step: 229/655, Loss: 2.202622, Accuracy: 18.87%\n",
            "Epoch: 21, Step: 230/655, Loss: 2.202801, Accuracy: 18.86%\n",
            "Epoch: 21, Step: 231/655, Loss: 2.202252, Accuracy: 18.90%\n",
            "Epoch: 21, Step: 232/655, Loss: 2.202637, Accuracy: 18.93%\n",
            "Epoch: 21, Step: 233/655, Loss: 2.203117, Accuracy: 18.91%\n",
            "Epoch: 21, Step: 234/655, Loss: 2.202574, Accuracy: 18.91%\n",
            "Epoch: 21, Step: 235/655, Loss: 2.202081, Accuracy: 18.90%\n",
            "Epoch: 21, Step: 236/655, Loss: 2.202521, Accuracy: 18.87%\n",
            "Epoch: 21, Step: 237/655, Loss: 2.202482, Accuracy: 18.87%\n",
            "Epoch: 21, Step: 238/655, Loss: 2.202627, Accuracy: 18.88%\n",
            "Epoch: 21, Step: 239/655, Loss: 2.202963, Accuracy: 18.87%\n",
            "Epoch: 21, Step: 240/655, Loss: 2.202863, Accuracy: 18.88%\n",
            "Epoch: 21, Step: 241/655, Loss: 2.202423, Accuracy: 18.89%\n",
            "Epoch: 21, Step: 242/655, Loss: 2.202587, Accuracy: 18.88%\n",
            "Epoch: 21, Step: 243/655, Loss: 2.202391, Accuracy: 18.93%\n",
            "Epoch: 21, Step: 244/655, Loss: 2.202203, Accuracy: 18.95%\n",
            "Epoch: 21, Step: 245/655, Loss: 2.202323, Accuracy: 18.93%\n",
            "Epoch: 21, Step: 246/655, Loss: 2.202722, Accuracy: 18.89%\n",
            "Epoch: 21, Step: 247/655, Loss: 2.202388, Accuracy: 18.89%\n",
            "Epoch: 21, Step: 248/655, Loss: 2.201795, Accuracy: 18.90%\n",
            "Epoch: 21, Step: 249/655, Loss: 2.201966, Accuracy: 18.90%\n",
            "Epoch: 21, Step: 250/655, Loss: 2.202424, Accuracy: 18.85%\n",
            "Epoch: 21, Step: 251/655, Loss: 2.202627, Accuracy: 18.81%\n",
            "Epoch: 21, Step: 252/655, Loss: 2.203398, Accuracy: 18.76%\n",
            "Epoch: 21, Step: 253/655, Loss: 2.203686, Accuracy: 18.76%\n",
            "Epoch: 21, Step: 254/655, Loss: 2.203123, Accuracy: 18.79%\n",
            "Epoch: 21, Step: 255/655, Loss: 2.203394, Accuracy: 18.76%\n",
            "Epoch: 21, Step: 256/655, Loss: 2.203656, Accuracy: 18.71%\n",
            "Epoch: 21, Step: 257/655, Loss: 2.203936, Accuracy: 18.70%\n",
            "Epoch: 21, Step: 258/655, Loss: 2.203945, Accuracy: 18.76%\n",
            "Epoch: 21, Step: 259/655, Loss: 2.204370, Accuracy: 18.74%\n",
            "Epoch: 21, Step: 260/655, Loss: 2.204119, Accuracy: 18.74%\n",
            "Epoch: 21, Step: 261/655, Loss: 2.203951, Accuracy: 18.76%\n",
            "Epoch: 21, Step: 262/655, Loss: 2.203985, Accuracy: 18.74%\n",
            "Epoch: 21, Step: 263/655, Loss: 2.203817, Accuracy: 18.79%\n",
            "Epoch: 21, Step: 264/655, Loss: 2.204061, Accuracy: 18.77%\n",
            "Epoch: 21, Step: 265/655, Loss: 2.203878, Accuracy: 18.76%\n",
            "Epoch: 21, Step: 266/655, Loss: 2.203738, Accuracy: 18.77%\n",
            "Epoch: 21, Step: 267/655, Loss: 2.203717, Accuracy: 18.76%\n",
            "Epoch: 21, Step: 268/655, Loss: 2.203902, Accuracy: 18.73%\n",
            "Epoch: 21, Step: 269/655, Loss: 2.203774, Accuracy: 18.70%\n",
            "Epoch: 21, Step: 270/655, Loss: 2.203603, Accuracy: 18.70%\n",
            "Epoch: 21, Step: 271/655, Loss: 2.203364, Accuracy: 18.78%\n",
            "Epoch: 21, Step: 272/655, Loss: 2.203497, Accuracy: 18.77%\n",
            "Epoch: 21, Step: 273/655, Loss: 2.203726, Accuracy: 18.76%\n",
            "Epoch: 21, Step: 274/655, Loss: 2.203567, Accuracy: 18.74%\n",
            "Epoch: 21, Step: 275/655, Loss: 2.203703, Accuracy: 18.72%\n",
            "Epoch: 21, Step: 276/655, Loss: 2.203720, Accuracy: 18.72%\n",
            "Epoch: 21, Step: 277/655, Loss: 2.204607, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 278/655, Loss: 2.204475, Accuracy: 18.67%\n",
            "Epoch: 21, Step: 279/655, Loss: 2.204933, Accuracy: 18.64%\n",
            "Epoch: 21, Step: 280/655, Loss: 2.205077, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 281/655, Loss: 2.204906, Accuracy: 18.66%\n",
            "Epoch: 21, Step: 282/655, Loss: 2.205220, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 283/655, Loss: 2.205330, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 284/655, Loss: 2.205393, Accuracy: 18.64%\n",
            "Epoch: 21, Step: 285/655, Loss: 2.204900, Accuracy: 18.68%\n",
            "Epoch: 21, Step: 286/655, Loss: 2.205220, Accuracy: 18.64%\n",
            "Epoch: 21, Step: 287/655, Loss: 2.205266, Accuracy: 18.63%\n",
            "Epoch: 21, Step: 288/655, Loss: 2.205332, Accuracy: 18.63%\n",
            "Epoch: 21, Step: 289/655, Loss: 2.205215, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 290/655, Loss: 2.205306, Accuracy: 18.64%\n",
            "Epoch: 21, Step: 291/655, Loss: 2.205082, Accuracy: 18.64%\n",
            "Epoch: 21, Step: 292/655, Loss: 2.205214, Accuracy: 18.63%\n",
            "Epoch: 21, Step: 293/655, Loss: 2.205235, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 294/655, Loss: 2.204974, Accuracy: 18.66%\n",
            "Epoch: 21, Step: 295/655, Loss: 2.204882, Accuracy: 18.68%\n",
            "Epoch: 21, Step: 296/655, Loss: 2.204785, Accuracy: 18.68%\n",
            "Epoch: 21, Step: 297/655, Loss: 2.205013, Accuracy: 18.66%\n",
            "Epoch: 21, Step: 298/655, Loss: 2.205099, Accuracy: 18.69%\n",
            "Epoch: 21, Step: 299/655, Loss: 2.204930, Accuracy: 18.66%\n",
            "Epoch: 21, Step: 300/655, Loss: 2.204683, Accuracy: 18.64%\n",
            "Epoch: 21, Step: 301/655, Loss: 2.204614, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 302/655, Loss: 2.205326, Accuracy: 18.61%\n",
            "Epoch: 21, Step: 303/655, Loss: 2.205143, Accuracy: 18.63%\n",
            "Epoch: 21, Step: 304/655, Loss: 2.205036, Accuracy: 18.64%\n",
            "Epoch: 21, Step: 305/655, Loss: 2.204746, Accuracy: 18.63%\n",
            "Epoch: 21, Step: 306/655, Loss: 2.204799, Accuracy: 18.64%\n",
            "Epoch: 21, Step: 307/655, Loss: 2.204699, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 308/655, Loss: 2.204566, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 309/655, Loss: 2.204713, Accuracy: 18.61%\n",
            "Epoch: 21, Step: 310/655, Loss: 2.205166, Accuracy: 18.57%\n",
            "Epoch: 21, Step: 311/655, Loss: 2.205169, Accuracy: 18.57%\n",
            "Epoch: 21, Step: 312/655, Loss: 2.204956, Accuracy: 18.61%\n",
            "Epoch: 21, Step: 313/655, Loss: 2.205280, Accuracy: 18.61%\n",
            "Epoch: 21, Step: 314/655, Loss: 2.205222, Accuracy: 18.60%\n",
            "Epoch: 21, Step: 315/655, Loss: 2.205532, Accuracy: 18.60%\n",
            "Epoch: 21, Step: 316/655, Loss: 2.205567, Accuracy: 18.60%\n",
            "Epoch: 21, Step: 317/655, Loss: 2.205364, Accuracy: 18.61%\n",
            "Epoch: 21, Step: 318/655, Loss: 2.205216, Accuracy: 18.64%\n",
            "Epoch: 21, Step: 319/655, Loss: 2.205014, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 320/655, Loss: 2.204967, Accuracy: 18.66%\n",
            "Epoch: 21, Step: 321/655, Loss: 2.204693, Accuracy: 18.68%\n",
            "Epoch: 21, Step: 322/655, Loss: 2.204592, Accuracy: 18.67%\n",
            "Epoch: 21, Step: 323/655, Loss: 2.204710, Accuracy: 18.66%\n",
            "Epoch: 21, Step: 324/655, Loss: 2.204776, Accuracy: 18.64%\n",
            "Epoch: 21, Step: 325/655, Loss: 2.204811, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 326/655, Loss: 2.204587, Accuracy: 18.63%\n",
            "Epoch: 21, Step: 327/655, Loss: 2.204391, Accuracy: 18.64%\n",
            "Epoch: 21, Step: 328/655, Loss: 2.204613, Accuracy: 18.66%\n",
            "Epoch: 21, Step: 329/655, Loss: 2.204338, Accuracy: 18.73%\n",
            "Epoch: 21, Step: 330/655, Loss: 2.204454, Accuracy: 18.70%\n",
            "Epoch: 21, Step: 331/655, Loss: 2.204311, Accuracy: 18.71%\n",
            "Epoch: 21, Step: 332/655, Loss: 2.204292, Accuracy: 18.71%\n",
            "Epoch: 21, Step: 333/655, Loss: 2.204169, Accuracy: 18.73%\n",
            "Epoch: 21, Step: 334/655, Loss: 2.204470, Accuracy: 18.68%\n",
            "Epoch: 21, Step: 335/655, Loss: 2.204424, Accuracy: 18.69%\n",
            "Epoch: 21, Step: 336/655, Loss: 2.204917, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 337/655, Loss: 2.205295, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 338/655, Loss: 2.205900, Accuracy: 18.57%\n",
            "Epoch: 21, Step: 339/655, Loss: 2.206395, Accuracy: 18.56%\n",
            "Epoch: 21, Step: 340/655, Loss: 2.206973, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 341/655, Loss: 2.206775, Accuracy: 18.57%\n",
            "Epoch: 21, Step: 342/655, Loss: 2.206651, Accuracy: 18.58%\n",
            "Epoch: 21, Step: 343/655, Loss: 2.206850, Accuracy: 18.57%\n",
            "Epoch: 21, Step: 344/655, Loss: 2.207009, Accuracy: 18.56%\n",
            "Epoch: 21, Step: 345/655, Loss: 2.206903, Accuracy: 18.58%\n",
            "Epoch: 21, Step: 346/655, Loss: 2.206807, Accuracy: 18.58%\n",
            "Epoch: 21, Step: 347/655, Loss: 2.206940, Accuracy: 18.56%\n",
            "Epoch: 21, Step: 348/655, Loss: 2.207161, Accuracy: 18.54%\n",
            "Epoch: 21, Step: 349/655, Loss: 2.207067, Accuracy: 18.56%\n",
            "Epoch: 21, Step: 350/655, Loss: 2.207119, Accuracy: 18.54%\n",
            "Epoch: 21, Step: 351/655, Loss: 2.206981, Accuracy: 18.55%\n",
            "Epoch: 21, Step: 352/655, Loss: 2.206839, Accuracy: 18.55%\n",
            "Epoch: 21, Step: 353/655, Loss: 2.206898, Accuracy: 18.56%\n",
            "Epoch: 21, Step: 354/655, Loss: 2.206809, Accuracy: 18.56%\n",
            "Epoch: 21, Step: 355/655, Loss: 2.206775, Accuracy: 18.60%\n",
            "Epoch: 21, Step: 356/655, Loss: 2.206528, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 357/655, Loss: 2.206658, Accuracy: 18.60%\n",
            "Epoch: 21, Step: 358/655, Loss: 2.206766, Accuracy: 18.60%\n",
            "Epoch: 21, Step: 359/655, Loss: 2.206817, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 360/655, Loss: 2.206506, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 361/655, Loss: 2.206703, Accuracy: 18.63%\n",
            "Epoch: 21, Step: 362/655, Loss: 2.206489, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 363/655, Loss: 2.206370, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 364/655, Loss: 2.206626, Accuracy: 18.66%\n",
            "Epoch: 21, Step: 365/655, Loss: 2.206548, Accuracy: 18.69%\n",
            "Epoch: 21, Step: 366/655, Loss: 2.206704, Accuracy: 18.71%\n",
            "Epoch: 21, Step: 367/655, Loss: 2.206661, Accuracy: 18.68%\n",
            "Epoch: 21, Step: 368/655, Loss: 2.207079, Accuracy: 18.66%\n",
            "Epoch: 21, Step: 369/655, Loss: 2.206912, Accuracy: 18.70%\n",
            "Epoch: 21, Step: 370/655, Loss: 2.206632, Accuracy: 18.73%\n",
            "Epoch: 21, Step: 371/655, Loss: 2.206362, Accuracy: 18.73%\n",
            "Epoch: 21, Step: 372/655, Loss: 2.206681, Accuracy: 18.70%\n",
            "Epoch: 21, Step: 373/655, Loss: 2.206375, Accuracy: 18.71%\n",
            "Epoch: 21, Step: 374/655, Loss: 2.206244, Accuracy: 18.72%\n",
            "Epoch: 21, Step: 375/655, Loss: 2.206333, Accuracy: 18.69%\n",
            "Epoch: 21, Step: 376/655, Loss: 2.206675, Accuracy: 18.67%\n",
            "Epoch: 21, Step: 377/655, Loss: 2.206743, Accuracy: 18.68%\n",
            "Epoch: 21, Step: 378/655, Loss: 2.206710, Accuracy: 18.68%\n",
            "Epoch: 21, Step: 379/655, Loss: 2.207389, Accuracy: 18.63%\n",
            "Epoch: 21, Step: 380/655, Loss: 2.207009, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 381/655, Loss: 2.206967, Accuracy: 18.65%\n",
            "Epoch: 21, Step: 382/655, Loss: 2.206968, Accuracy: 18.64%\n",
            "Epoch: 21, Step: 383/655, Loss: 2.207104, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 384/655, Loss: 2.207050, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 385/655, Loss: 2.206942, Accuracy: 18.63%\n",
            "Epoch: 21, Step: 386/655, Loss: 2.207156, Accuracy: 18.60%\n",
            "Epoch: 21, Step: 387/655, Loss: 2.207106, Accuracy: 18.58%\n",
            "Epoch: 21, Step: 388/655, Loss: 2.207001, Accuracy: 18.59%\n",
            "Epoch: 21, Step: 389/655, Loss: 2.206652, Accuracy: 18.61%\n",
            "Epoch: 21, Step: 390/655, Loss: 2.206814, Accuracy: 18.60%\n",
            "Epoch: 21, Step: 391/655, Loss: 2.206949, Accuracy: 18.59%\n",
            "Epoch: 21, Step: 392/655, Loss: 2.207192, Accuracy: 18.59%\n",
            "Epoch: 21, Step: 393/655, Loss: 2.207399, Accuracy: 18.57%\n",
            "Epoch: 21, Step: 394/655, Loss: 2.207389, Accuracy: 18.57%\n",
            "Epoch: 21, Step: 395/655, Loss: 2.206988, Accuracy: 18.60%\n",
            "Epoch: 21, Step: 396/655, Loss: 2.207035, Accuracy: 18.59%\n",
            "Epoch: 21, Step: 397/655, Loss: 2.206801, Accuracy: 18.58%\n",
            "Epoch: 21, Step: 398/655, Loss: 2.206771, Accuracy: 18.56%\n",
            "Epoch: 21, Step: 399/655, Loss: 2.206579, Accuracy: 18.55%\n",
            "Epoch: 21, Step: 400/655, Loss: 2.206611, Accuracy: 18.55%\n",
            "Epoch: 21, Step: 401/655, Loss: 2.206569, Accuracy: 18.55%\n",
            "Epoch: 21, Step: 402/655, Loss: 2.206560, Accuracy: 18.57%\n",
            "Epoch: 21, Step: 403/655, Loss: 2.206636, Accuracy: 18.55%\n",
            "Epoch: 21, Step: 404/655, Loss: 2.206561, Accuracy: 18.54%\n",
            "Epoch: 21, Step: 405/655, Loss: 2.206678, Accuracy: 18.55%\n",
            "Epoch: 21, Step: 406/655, Loss: 2.206729, Accuracy: 18.57%\n",
            "Epoch: 21, Step: 407/655, Loss: 2.206346, Accuracy: 18.60%\n",
            "Epoch: 21, Step: 408/655, Loss: 2.205942, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 409/655, Loss: 2.206037, Accuracy: 18.63%\n",
            "Epoch: 21, Step: 410/655, Loss: 2.206381, Accuracy: 18.61%\n",
            "Epoch: 21, Step: 411/655, Loss: 2.206830, Accuracy: 18.58%\n",
            "Epoch: 21, Step: 412/655, Loss: 2.206766, Accuracy: 18.59%\n",
            "Epoch: 21, Step: 413/655, Loss: 2.206605, Accuracy: 18.63%\n",
            "Epoch: 21, Step: 414/655, Loss: 2.206626, Accuracy: 18.63%\n",
            "Epoch: 21, Step: 415/655, Loss: 2.206636, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 416/655, Loss: 2.206750, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 417/655, Loss: 2.206645, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 418/655, Loss: 2.206524, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 419/655, Loss: 2.206724, Accuracy: 18.62%\n",
            "Epoch: 21, Step: 420/655, Loss: 2.206660, Accuracy: 18.59%\n",
            "Epoch: 21, Step: 421/655, Loss: 2.206559, Accuracy: 18.59%\n",
            "Epoch: 21, Step: 422/655, Loss: 2.206678, Accuracy: 18.59%\n",
            "Epoch: 21, Step: 423/655, Loss: 2.206715, Accuracy: 18.57%\n",
            "Epoch: 21, Step: 424/655, Loss: 2.206838, Accuracy: 18.57%\n",
            "Epoch: 21, Step: 425/655, Loss: 2.207023, Accuracy: 18.54%\n",
            "Epoch: 21, Step: 426/655, Loss: 2.207189, Accuracy: 18.55%\n",
            "Epoch: 21, Step: 427/655, Loss: 2.207236, Accuracy: 18.57%\n",
            "Epoch: 21, Step: 428/655, Loss: 2.207168, Accuracy: 18.56%\n",
            "Epoch: 21, Step: 429/655, Loss: 2.207183, Accuracy: 18.57%\n",
            "Epoch: 21, Step: 430/655, Loss: 2.207362, Accuracy: 18.58%\n",
            "Epoch: 21, Step: 431/655, Loss: 2.207332, Accuracy: 18.58%\n",
            "Epoch: 21, Step: 432/655, Loss: 2.207082, Accuracy: 18.58%\n",
            "Epoch: 21, Step: 433/655, Loss: 2.206887, Accuracy: 18.60%\n",
            "Epoch: 21, Step: 434/655, Loss: 2.207119, Accuracy: 18.58%\n",
            "Epoch: 21, Step: 435/655, Loss: 2.206964, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 436/655, Loss: 2.206658, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 437/655, Loss: 2.206849, Accuracy: 18.52%\n",
            "Epoch: 21, Step: 438/655, Loss: 2.206902, Accuracy: 18.54%\n",
            "Epoch: 21, Step: 439/655, Loss: 2.206865, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 440/655, Loss: 2.206983, Accuracy: 18.54%\n",
            "Epoch: 21, Step: 441/655, Loss: 2.206904, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 442/655, Loss: 2.207381, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 443/655, Loss: 2.207341, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 444/655, Loss: 2.207520, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 445/655, Loss: 2.207508, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 446/655, Loss: 2.207541, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 447/655, Loss: 2.207388, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 448/655, Loss: 2.207237, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 449/655, Loss: 2.207112, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 450/655, Loss: 2.207009, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 451/655, Loss: 2.207193, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 452/655, Loss: 2.207191, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 453/655, Loss: 2.206985, Accuracy: 18.52%\n",
            "Epoch: 21, Step: 454/655, Loss: 2.207191, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 455/655, Loss: 2.207071, Accuracy: 18.52%\n",
            "Epoch: 21, Step: 456/655, Loss: 2.207261, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 457/655, Loss: 2.207610, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 458/655, Loss: 2.207689, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 459/655, Loss: 2.207641, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 460/655, Loss: 2.207588, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 461/655, Loss: 2.207548, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 462/655, Loss: 2.207731, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 463/655, Loss: 2.207777, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 464/655, Loss: 2.207840, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 465/655, Loss: 2.207923, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 466/655, Loss: 2.208121, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 467/655, Loss: 2.207873, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 468/655, Loss: 2.207687, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 469/655, Loss: 2.207585, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 470/655, Loss: 2.207823, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 471/655, Loss: 2.207768, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 472/655, Loss: 2.207702, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 473/655, Loss: 2.207842, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 474/655, Loss: 2.207858, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 475/655, Loss: 2.207701, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 476/655, Loss: 2.207347, Accuracy: 18.57%\n",
            "Epoch: 21, Step: 477/655, Loss: 2.207416, Accuracy: 18.55%\n",
            "Epoch: 21, Step: 478/655, Loss: 2.207511, Accuracy: 18.54%\n",
            "Epoch: 21, Step: 479/655, Loss: 2.207504, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 480/655, Loss: 2.207415, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 481/655, Loss: 2.207605, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 482/655, Loss: 2.207711, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 483/655, Loss: 2.207674, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 484/655, Loss: 2.207626, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 485/655, Loss: 2.207668, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 486/655, Loss: 2.207397, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 487/655, Loss: 2.207367, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 488/655, Loss: 2.207590, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 489/655, Loss: 2.207530, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 490/655, Loss: 2.207353, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 491/655, Loss: 2.207551, Accuracy: 18.45%\n",
            "Epoch: 21, Step: 492/655, Loss: 2.207522, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 493/655, Loss: 2.207527, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 494/655, Loss: 2.207329, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 495/655, Loss: 2.207436, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 496/655, Loss: 2.207465, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 497/655, Loss: 2.207518, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 498/655, Loss: 2.207342, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 499/655, Loss: 2.207222, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 500/655, Loss: 2.207425, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 501/655, Loss: 2.207644, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 502/655, Loss: 2.207671, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 503/655, Loss: 2.207700, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 504/655, Loss: 2.207841, Accuracy: 18.46%\n",
            "Epoch: 21, Step: 505/655, Loss: 2.207839, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 506/655, Loss: 2.207529, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 507/655, Loss: 2.207395, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 508/655, Loss: 2.207550, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 509/655, Loss: 2.207682, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 510/655, Loss: 2.207606, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 511/655, Loss: 2.207514, Accuracy: 18.46%\n",
            "Epoch: 21, Step: 512/655, Loss: 2.207524, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 513/655, Loss: 2.207241, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 514/655, Loss: 2.207402, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 515/655, Loss: 2.207269, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 516/655, Loss: 2.206950, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 517/655, Loss: 2.207115, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 518/655, Loss: 2.206930, Accuracy: 18.54%\n",
            "Epoch: 21, Step: 519/655, Loss: 2.207085, Accuracy: 18.55%\n",
            "Epoch: 21, Step: 520/655, Loss: 2.207153, Accuracy: 18.55%\n",
            "Epoch: 21, Step: 521/655, Loss: 2.207241, Accuracy: 18.55%\n",
            "Epoch: 21, Step: 522/655, Loss: 2.207417, Accuracy: 18.54%\n",
            "Epoch: 21, Step: 523/655, Loss: 2.207339, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 524/655, Loss: 2.207331, Accuracy: 18.52%\n",
            "Epoch: 21, Step: 525/655, Loss: 2.207340, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 526/655, Loss: 2.207288, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 527/655, Loss: 2.207221, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 528/655, Loss: 2.207017, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 529/655, Loss: 2.207037, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 530/655, Loss: 2.207142, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 531/655, Loss: 2.207117, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 532/655, Loss: 2.207373, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 533/655, Loss: 2.207508, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 534/655, Loss: 2.207510, Accuracy: 18.45%\n",
            "Epoch: 21, Step: 535/655, Loss: 2.207710, Accuracy: 18.43%\n",
            "Epoch: 21, Step: 536/655, Loss: 2.207771, Accuracy: 18.43%\n",
            "Epoch: 21, Step: 537/655, Loss: 2.207683, Accuracy: 18.42%\n",
            "Epoch: 21, Step: 538/655, Loss: 2.207648, Accuracy: 18.40%\n",
            "Epoch: 21, Step: 539/655, Loss: 2.207891, Accuracy: 18.38%\n",
            "Epoch: 21, Step: 540/655, Loss: 2.207920, Accuracy: 18.40%\n",
            "Epoch: 21, Step: 541/655, Loss: 2.207832, Accuracy: 18.40%\n",
            "Epoch: 21, Step: 542/655, Loss: 2.207849, Accuracy: 18.39%\n",
            "Epoch: 21, Step: 543/655, Loss: 2.207691, Accuracy: 18.40%\n",
            "Epoch: 21, Step: 544/655, Loss: 2.207600, Accuracy: 18.40%\n",
            "Epoch: 21, Step: 545/655, Loss: 2.207601, Accuracy: 18.41%\n",
            "Epoch: 21, Step: 546/655, Loss: 2.207705, Accuracy: 18.42%\n",
            "Epoch: 21, Step: 547/655, Loss: 2.207504, Accuracy: 18.45%\n",
            "Epoch: 21, Step: 548/655, Loss: 2.207450, Accuracy: 18.45%\n",
            "Epoch: 21, Step: 549/655, Loss: 2.207433, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 550/655, Loss: 2.207403, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 551/655, Loss: 2.207150, Accuracy: 18.45%\n",
            "Epoch: 21, Step: 552/655, Loss: 2.207169, Accuracy: 18.46%\n",
            "Epoch: 21, Step: 553/655, Loss: 2.207405, Accuracy: 18.45%\n",
            "Epoch: 21, Step: 554/655, Loss: 2.207477, Accuracy: 18.45%\n",
            "Epoch: 21, Step: 555/655, Loss: 2.207363, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 556/655, Loss: 2.207581, Accuracy: 18.46%\n",
            "Epoch: 21, Step: 557/655, Loss: 2.207699, Accuracy: 18.46%\n",
            "Epoch: 21, Step: 558/655, Loss: 2.207432, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 559/655, Loss: 2.207324, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 560/655, Loss: 2.207261, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 561/655, Loss: 2.207499, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 562/655, Loss: 2.207294, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 563/655, Loss: 2.207414, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 564/655, Loss: 2.207412, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 565/655, Loss: 2.207369, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 566/655, Loss: 2.207338, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 567/655, Loss: 2.207465, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 568/655, Loss: 2.207319, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 569/655, Loss: 2.207070, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 570/655, Loss: 2.207130, Accuracy: 18.52%\n",
            "Epoch: 21, Step: 571/655, Loss: 2.207169, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 572/655, Loss: 2.207317, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 573/655, Loss: 2.207225, Accuracy: 18.54%\n",
            "Epoch: 21, Step: 574/655, Loss: 2.207253, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 575/655, Loss: 2.207387, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 576/655, Loss: 2.207382, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 577/655, Loss: 2.207561, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 578/655, Loss: 2.207460, Accuracy: 18.52%\n",
            "Epoch: 21, Step: 579/655, Loss: 2.207341, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 580/655, Loss: 2.207261, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 581/655, Loss: 2.207219, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 582/655, Loss: 2.207203, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 583/655, Loss: 2.207137, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 584/655, Loss: 2.207089, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 585/655, Loss: 2.207001, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 586/655, Loss: 2.206872, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 587/655, Loss: 2.206982, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 588/655, Loss: 2.206806, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 589/655, Loss: 2.206797, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 590/655, Loss: 2.206467, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 591/655, Loss: 2.206470, Accuracy: 18.54%\n",
            "Epoch: 21, Step: 592/655, Loss: 2.206763, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 593/655, Loss: 2.206819, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 594/655, Loss: 2.207169, Accuracy: 18.52%\n",
            "Epoch: 21, Step: 595/655, Loss: 2.207306, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 596/655, Loss: 2.207365, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 597/655, Loss: 2.207557, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 598/655, Loss: 2.207388, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 599/655, Loss: 2.207386, Accuracy: 18.53%\n",
            "Epoch: 21, Step: 600/655, Loss: 2.207399, Accuracy: 18.52%\n",
            "Epoch: 21, Step: 601/655, Loss: 2.207652, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 602/655, Loss: 2.207616, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 603/655, Loss: 2.207626, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 604/655, Loss: 2.207490, Accuracy: 18.52%\n",
            "Epoch: 21, Step: 605/655, Loss: 2.207479, Accuracy: 18.52%\n",
            "Epoch: 21, Step: 606/655, Loss: 2.207437, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 607/655, Loss: 2.207424, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 608/655, Loss: 2.207439, Accuracy: 18.50%\n",
            "Epoch: 21, Step: 609/655, Loss: 2.207221, Accuracy: 18.51%\n",
            "Epoch: 21, Step: 610/655, Loss: 2.207195, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 611/655, Loss: 2.207356, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 612/655, Loss: 2.207396, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 613/655, Loss: 2.207377, Accuracy: 18.48%\n",
            "Epoch: 21, Step: 614/655, Loss: 2.207167, Accuracy: 18.49%\n",
            "Epoch: 21, Step: 615/655, Loss: 2.207438, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 616/655, Loss: 2.207458, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 617/655, Loss: 2.207380, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 618/655, Loss: 2.207471, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 619/655, Loss: 2.207526, Accuracy: 18.47%\n",
            "Epoch: 21, Step: 620/655, Loss: 2.207525, Accuracy: 18.46%\n",
            "Epoch: 21, Step: 621/655, Loss: 2.207560, Accuracy: 18.45%\n",
            "Epoch: 21, Step: 622/655, Loss: 2.207532, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 623/655, Loss: 2.207446, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 624/655, Loss: 2.207571, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 625/655, Loss: 2.207600, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 626/655, Loss: 2.207821, Accuracy: 18.42%\n",
            "Epoch: 21, Step: 627/655, Loss: 2.207841, Accuracy: 18.42%\n",
            "Epoch: 21, Step: 628/655, Loss: 2.207719, Accuracy: 18.41%\n",
            "Epoch: 21, Step: 629/655, Loss: 2.207816, Accuracy: 18.41%\n",
            "Epoch: 21, Step: 630/655, Loss: 2.207877, Accuracy: 18.42%\n",
            "Epoch: 21, Step: 631/655, Loss: 2.208005, Accuracy: 18.41%\n",
            "Epoch: 21, Step: 632/655, Loss: 2.208104, Accuracy: 18.41%\n",
            "Epoch: 21, Step: 633/655, Loss: 2.208144, Accuracy: 18.42%\n",
            "Epoch: 21, Step: 634/655, Loss: 2.208195, Accuracy: 18.42%\n",
            "Epoch: 21, Step: 635/655, Loss: 2.208356, Accuracy: 18.42%\n",
            "Epoch: 21, Step: 636/655, Loss: 2.208296, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 637/655, Loss: 2.208321, Accuracy: 18.43%\n",
            "Epoch: 21, Step: 638/655, Loss: 2.208132, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 639/655, Loss: 2.208167, Accuracy: 18.43%\n",
            "Epoch: 21, Step: 640/655, Loss: 2.208245, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 641/655, Loss: 2.208332, Accuracy: 18.43%\n",
            "Epoch: 21, Step: 642/655, Loss: 2.208363, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 643/655, Loss: 2.208443, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 644/655, Loss: 2.208365, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 645/655, Loss: 2.208260, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 646/655, Loss: 2.208187, Accuracy: 18.45%\n",
            "Epoch: 21, Step: 647/655, Loss: 2.208274, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 648/655, Loss: 2.208289, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 649/655, Loss: 2.208220, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 650/655, Loss: 2.208084, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 651/655, Loss: 2.208077, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 652/655, Loss: 2.208188, Accuracy: 18.43%\n",
            "Epoch: 21, Step: 653/655, Loss: 2.208081, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 654/655, Loss: 2.207922, Accuracy: 18.44%\n",
            "Epoch: 21, Step: 655/655, Loss: 2.208082, Accuracy: 18.44%\n",
            "Epoch: 22, Step: 1/655, Loss: 2.220689, Accuracy: 28.12%\n",
            "Epoch: 22, Step: 2/655, Loss: 2.255886, Accuracy: 21.88%\n",
            "Epoch: 22, Step: 3/655, Loss: 2.197120, Accuracy: 25.00%\n",
            "Epoch: 22, Step: 4/655, Loss: 2.192836, Accuracy: 24.22%\n",
            "Epoch: 22, Step: 5/655, Loss: 2.208459, Accuracy: 23.12%\n",
            "Epoch: 22, Step: 6/655, Loss: 2.186639, Accuracy: 23.96%\n",
            "Epoch: 22, Step: 7/655, Loss: 2.174820, Accuracy: 23.66%\n",
            "Epoch: 22, Step: 8/655, Loss: 2.198897, Accuracy: 23.44%\n",
            "Epoch: 22, Step: 9/655, Loss: 2.200357, Accuracy: 21.88%\n",
            "Epoch: 22, Step: 10/655, Loss: 2.203161, Accuracy: 21.56%\n",
            "Epoch: 22, Step: 11/655, Loss: 2.203413, Accuracy: 20.74%\n",
            "Epoch: 22, Step: 12/655, Loss: 2.198064, Accuracy: 20.83%\n",
            "Epoch: 22, Step: 13/655, Loss: 2.194653, Accuracy: 20.91%\n",
            "Epoch: 22, Step: 14/655, Loss: 2.193571, Accuracy: 20.31%\n",
            "Epoch: 22, Step: 15/655, Loss: 2.188320, Accuracy: 19.58%\n",
            "Epoch: 22, Step: 16/655, Loss: 2.180649, Accuracy: 19.92%\n",
            "Epoch: 22, Step: 17/655, Loss: 2.180662, Accuracy: 19.30%\n",
            "Epoch: 22, Step: 18/655, Loss: 2.184009, Accuracy: 19.27%\n",
            "Epoch: 22, Step: 19/655, Loss: 2.195234, Accuracy: 18.59%\n",
            "Epoch: 22, Step: 20/655, Loss: 2.193351, Accuracy: 18.91%\n",
            "Epoch: 22, Step: 21/655, Loss: 2.192017, Accuracy: 19.20%\n",
            "Epoch: 22, Step: 22/655, Loss: 2.192822, Accuracy: 19.32%\n",
            "Epoch: 22, Step: 23/655, Loss: 2.197705, Accuracy: 18.89%\n",
            "Epoch: 22, Step: 24/655, Loss: 2.198405, Accuracy: 19.01%\n",
            "Epoch: 22, Step: 25/655, Loss: 2.196543, Accuracy: 18.88%\n",
            "Epoch: 22, Step: 26/655, Loss: 2.194355, Accuracy: 18.87%\n",
            "Epoch: 22, Step: 27/655, Loss: 2.200727, Accuracy: 18.63%\n",
            "Epoch: 22, Step: 28/655, Loss: 2.201152, Accuracy: 18.64%\n",
            "Epoch: 22, Step: 29/655, Loss: 2.204268, Accuracy: 18.97%\n",
            "Epoch: 22, Step: 30/655, Loss: 2.203446, Accuracy: 19.48%\n",
            "Epoch: 22, Step: 31/655, Loss: 2.203106, Accuracy: 19.56%\n",
            "Epoch: 22, Step: 32/655, Loss: 2.205132, Accuracy: 19.63%\n",
            "Epoch: 22, Step: 33/655, Loss: 2.204217, Accuracy: 19.41%\n",
            "Epoch: 22, Step: 34/655, Loss: 2.205450, Accuracy: 19.39%\n",
            "Epoch: 22, Step: 35/655, Loss: 2.201431, Accuracy: 19.73%\n",
            "Epoch: 22, Step: 36/655, Loss: 2.201476, Accuracy: 19.53%\n",
            "Epoch: 22, Step: 37/655, Loss: 2.198284, Accuracy: 19.85%\n",
            "Epoch: 22, Step: 38/655, Loss: 2.197101, Accuracy: 19.90%\n",
            "Epoch: 22, Step: 39/655, Loss: 2.194267, Accuracy: 20.03%\n",
            "Epoch: 22, Step: 40/655, Loss: 2.197739, Accuracy: 19.69%\n",
            "Epoch: 22, Step: 41/655, Loss: 2.202375, Accuracy: 19.59%\n",
            "Epoch: 22, Step: 42/655, Loss: 2.203138, Accuracy: 19.49%\n",
            "Epoch: 22, Step: 43/655, Loss: 2.200820, Accuracy: 19.62%\n",
            "Epoch: 22, Step: 44/655, Loss: 2.204262, Accuracy: 19.39%\n",
            "Epoch: 22, Step: 45/655, Loss: 2.205547, Accuracy: 19.17%\n",
            "Epoch: 22, Step: 46/655, Loss: 2.203974, Accuracy: 19.36%\n",
            "Epoch: 22, Step: 47/655, Loss: 2.202049, Accuracy: 19.41%\n",
            "Epoch: 22, Step: 48/655, Loss: 2.200881, Accuracy: 19.47%\n",
            "Epoch: 22, Step: 49/655, Loss: 2.200507, Accuracy: 19.32%\n",
            "Epoch: 22, Step: 50/655, Loss: 2.201762, Accuracy: 19.12%\n",
            "Epoch: 22, Step: 51/655, Loss: 2.203392, Accuracy: 19.00%\n",
            "Epoch: 22, Step: 52/655, Loss: 2.202516, Accuracy: 18.93%\n",
            "Epoch: 22, Step: 53/655, Loss: 2.200796, Accuracy: 19.10%\n",
            "Epoch: 22, Step: 54/655, Loss: 2.200724, Accuracy: 19.04%\n",
            "Epoch: 22, Step: 55/655, Loss: 2.198913, Accuracy: 19.38%\n",
            "Epoch: 22, Step: 56/655, Loss: 2.199642, Accuracy: 19.48%\n",
            "Epoch: 22, Step: 57/655, Loss: 2.198781, Accuracy: 19.35%\n",
            "Epoch: 22, Step: 58/655, Loss: 2.198689, Accuracy: 19.34%\n",
            "Epoch: 22, Step: 59/655, Loss: 2.197511, Accuracy: 19.39%\n",
            "Epoch: 22, Step: 60/655, Loss: 2.199471, Accuracy: 19.38%\n",
            "Epoch: 22, Step: 61/655, Loss: 2.198221, Accuracy: 19.57%\n",
            "Epoch: 22, Step: 62/655, Loss: 2.199756, Accuracy: 19.51%\n",
            "Epoch: 22, Step: 63/655, Loss: 2.199542, Accuracy: 19.39%\n",
            "Epoch: 22, Step: 64/655, Loss: 2.200299, Accuracy: 19.43%\n",
            "Epoch: 22, Step: 65/655, Loss: 2.199431, Accuracy: 19.62%\n",
            "Epoch: 22, Step: 66/655, Loss: 2.197994, Accuracy: 19.79%\n",
            "Epoch: 22, Step: 67/655, Loss: 2.198163, Accuracy: 19.87%\n",
            "Epoch: 22, Step: 68/655, Loss: 2.199322, Accuracy: 19.67%\n",
            "Epoch: 22, Step: 69/655, Loss: 2.196466, Accuracy: 19.79%\n",
            "Epoch: 22, Step: 70/655, Loss: 2.197811, Accuracy: 19.78%\n",
            "Epoch: 22, Step: 71/655, Loss: 2.198920, Accuracy: 19.76%\n",
            "Epoch: 22, Step: 72/655, Loss: 2.200111, Accuracy: 19.62%\n",
            "Epoch: 22, Step: 73/655, Loss: 2.199932, Accuracy: 19.52%\n",
            "Epoch: 22, Step: 74/655, Loss: 2.200721, Accuracy: 19.43%\n",
            "Epoch: 22, Step: 75/655, Loss: 2.200711, Accuracy: 19.58%\n",
            "Epoch: 22, Step: 76/655, Loss: 2.199237, Accuracy: 19.74%\n",
            "Epoch: 22, Step: 77/655, Loss: 2.201361, Accuracy: 19.56%\n",
            "Epoch: 22, Step: 78/655, Loss: 2.201104, Accuracy: 19.55%\n",
            "Epoch: 22, Step: 79/655, Loss: 2.200832, Accuracy: 19.54%\n",
            "Epoch: 22, Step: 80/655, Loss: 2.201686, Accuracy: 19.57%\n",
            "Epoch: 22, Step: 81/655, Loss: 2.203510, Accuracy: 19.48%\n",
            "Epoch: 22, Step: 82/655, Loss: 2.203820, Accuracy: 19.44%\n",
            "Epoch: 22, Step: 83/655, Loss: 2.203410, Accuracy: 19.43%\n",
            "Epoch: 22, Step: 84/655, Loss: 2.204651, Accuracy: 19.35%\n",
            "Epoch: 22, Step: 85/655, Loss: 2.205407, Accuracy: 19.30%\n",
            "Epoch: 22, Step: 86/655, Loss: 2.205943, Accuracy: 19.22%\n",
            "Epoch: 22, Step: 87/655, Loss: 2.204260, Accuracy: 19.25%\n",
            "Epoch: 22, Step: 88/655, Loss: 2.203841, Accuracy: 19.35%\n",
            "Epoch: 22, Step: 89/655, Loss: 2.203598, Accuracy: 19.42%\n",
            "Epoch: 22, Step: 90/655, Loss: 2.201926, Accuracy: 19.41%\n",
            "Epoch: 22, Step: 91/655, Loss: 2.202036, Accuracy: 19.37%\n",
            "Epoch: 22, Step: 92/655, Loss: 2.200904, Accuracy: 19.43%\n",
            "Epoch: 22, Step: 93/655, Loss: 2.200140, Accuracy: 19.49%\n",
            "Epoch: 22, Step: 94/655, Loss: 2.198900, Accuracy: 19.51%\n",
            "Epoch: 22, Step: 95/655, Loss: 2.197975, Accuracy: 19.57%\n",
            "Epoch: 22, Step: 96/655, Loss: 2.197687, Accuracy: 19.66%\n",
            "Epoch: 22, Step: 97/655, Loss: 2.200041, Accuracy: 19.59%\n",
            "Epoch: 22, Step: 98/655, Loss: 2.201170, Accuracy: 19.55%\n",
            "Epoch: 22, Step: 99/655, Loss: 2.201268, Accuracy: 19.54%\n",
            "Epoch: 22, Step: 100/655, Loss: 2.200662, Accuracy: 19.50%\n",
            "Epoch: 22, Step: 101/655, Loss: 2.200469, Accuracy: 19.46%\n",
            "Epoch: 22, Step: 102/655, Loss: 2.200731, Accuracy: 19.49%\n",
            "Epoch: 22, Step: 103/655, Loss: 2.200041, Accuracy: 19.63%\n",
            "Epoch: 22, Step: 104/655, Loss: 2.198627, Accuracy: 19.77%\n",
            "Epoch: 22, Step: 105/655, Loss: 2.199841, Accuracy: 19.67%\n",
            "Epoch: 22, Step: 106/655, Loss: 2.200317, Accuracy: 19.63%\n",
            "Epoch: 22, Step: 107/655, Loss: 2.200344, Accuracy: 19.60%\n",
            "Epoch: 22, Step: 108/655, Loss: 2.200691, Accuracy: 19.59%\n",
            "Epoch: 22, Step: 109/655, Loss: 2.200299, Accuracy: 19.55%\n",
            "Epoch: 22, Step: 110/655, Loss: 2.200796, Accuracy: 19.49%\n",
            "Epoch: 22, Step: 111/655, Loss: 2.200041, Accuracy: 19.45%\n",
            "Epoch: 22, Step: 112/655, Loss: 2.200547, Accuracy: 19.45%\n",
            "Epoch: 22, Step: 113/655, Loss: 2.200841, Accuracy: 19.44%\n",
            "Epoch: 22, Step: 114/655, Loss: 2.200437, Accuracy: 19.46%\n",
            "Epoch: 22, Step: 115/655, Loss: 2.200073, Accuracy: 19.46%\n",
            "Epoch: 22, Step: 116/655, Loss: 2.200245, Accuracy: 19.48%\n",
            "Epoch: 22, Step: 117/655, Loss: 2.199681, Accuracy: 19.58%\n",
            "Epoch: 22, Step: 118/655, Loss: 2.200623, Accuracy: 19.47%\n",
            "Epoch: 22, Step: 119/655, Loss: 2.199678, Accuracy: 19.46%\n",
            "Epoch: 22, Step: 120/655, Loss: 2.199985, Accuracy: 19.48%\n",
            "Epoch: 22, Step: 121/655, Loss: 2.199391, Accuracy: 19.47%\n",
            "Epoch: 22, Step: 122/655, Loss: 2.199081, Accuracy: 19.54%\n",
            "Epoch: 22, Step: 123/655, Loss: 2.199345, Accuracy: 19.54%\n",
            "Epoch: 22, Step: 124/655, Loss: 2.199228, Accuracy: 19.48%\n",
            "Epoch: 22, Step: 125/655, Loss: 2.198946, Accuracy: 19.57%\n",
            "Epoch: 22, Step: 126/655, Loss: 2.199997, Accuracy: 19.47%\n",
            "Epoch: 22, Step: 127/655, Loss: 2.200084, Accuracy: 19.41%\n",
            "Epoch: 22, Step: 128/655, Loss: 2.200474, Accuracy: 19.41%\n",
            "Epoch: 22, Step: 129/655, Loss: 2.200312, Accuracy: 19.38%\n",
            "Epoch: 22, Step: 130/655, Loss: 2.199773, Accuracy: 19.38%\n",
            "Epoch: 22, Step: 131/655, Loss: 2.200869, Accuracy: 19.32%\n",
            "Epoch: 22, Step: 132/655, Loss: 2.201959, Accuracy: 19.25%\n",
            "Epoch: 22, Step: 133/655, Loss: 2.201202, Accuracy: 19.27%\n",
            "Epoch: 22, Step: 134/655, Loss: 2.201308, Accuracy: 19.26%\n",
            "Epoch: 22, Step: 135/655, Loss: 2.201439, Accuracy: 19.28%\n",
            "Epoch: 22, Step: 136/655, Loss: 2.201091, Accuracy: 19.37%\n",
            "Epoch: 22, Step: 137/655, Loss: 2.201113, Accuracy: 19.48%\n",
            "Epoch: 22, Step: 138/655, Loss: 2.201457, Accuracy: 19.43%\n",
            "Epoch: 22, Step: 139/655, Loss: 2.202741, Accuracy: 19.38%\n",
            "Epoch: 22, Step: 140/655, Loss: 2.202537, Accuracy: 19.40%\n",
            "Epoch: 22, Step: 141/655, Loss: 2.203028, Accuracy: 19.35%\n",
            "Epoch: 22, Step: 142/655, Loss: 2.203267, Accuracy: 19.41%\n",
            "Epoch: 22, Step: 143/655, Loss: 2.203981, Accuracy: 19.38%\n",
            "Epoch: 22, Step: 144/655, Loss: 2.203104, Accuracy: 19.42%\n",
            "Epoch: 22, Step: 145/655, Loss: 2.202689, Accuracy: 19.40%\n",
            "Epoch: 22, Step: 146/655, Loss: 2.202489, Accuracy: 19.41%\n",
            "Epoch: 22, Step: 147/655, Loss: 2.202748, Accuracy: 19.39%\n",
            "Epoch: 22, Step: 148/655, Loss: 2.202942, Accuracy: 19.38%\n",
            "Epoch: 22, Step: 149/655, Loss: 2.202327, Accuracy: 19.36%\n",
            "Epoch: 22, Step: 150/655, Loss: 2.202803, Accuracy: 19.33%\n",
            "Epoch: 22, Step: 151/655, Loss: 2.202301, Accuracy: 19.33%\n",
            "Epoch: 22, Step: 152/655, Loss: 2.202386, Accuracy: 19.37%\n",
            "Epoch: 22, Step: 153/655, Loss: 2.202619, Accuracy: 19.34%\n",
            "Epoch: 22, Step: 154/655, Loss: 2.203308, Accuracy: 19.34%\n",
            "Epoch: 22, Step: 155/655, Loss: 2.204394, Accuracy: 19.27%\n",
            "Epoch: 22, Step: 156/655, Loss: 2.205594, Accuracy: 19.21%\n",
            "Epoch: 22, Step: 157/655, Loss: 2.205267, Accuracy: 19.21%\n",
            "Epoch: 22, Step: 158/655, Loss: 2.205559, Accuracy: 19.17%\n",
            "Epoch: 22, Step: 159/655, Loss: 2.205177, Accuracy: 19.18%\n",
            "Epoch: 22, Step: 160/655, Loss: 2.205519, Accuracy: 19.18%\n",
            "Epoch: 22, Step: 161/655, Loss: 2.204816, Accuracy: 19.22%\n",
            "Epoch: 22, Step: 162/655, Loss: 2.205557, Accuracy: 19.19%\n",
            "Epoch: 22, Step: 163/655, Loss: 2.205612, Accuracy: 19.15%\n",
            "Epoch: 22, Step: 164/655, Loss: 2.205774, Accuracy: 19.11%\n",
            "Epoch: 22, Step: 165/655, Loss: 2.206301, Accuracy: 19.05%\n",
            "Epoch: 22, Step: 166/655, Loss: 2.207162, Accuracy: 18.98%\n",
            "Epoch: 22, Step: 167/655, Loss: 2.206860, Accuracy: 18.97%\n",
            "Epoch: 22, Step: 168/655, Loss: 2.206792, Accuracy: 18.92%\n",
            "Epoch: 22, Step: 169/655, Loss: 2.206866, Accuracy: 18.92%\n",
            "Epoch: 22, Step: 170/655, Loss: 2.207182, Accuracy: 18.88%\n",
            "Epoch: 22, Step: 171/655, Loss: 2.208439, Accuracy: 18.82%\n",
            "Epoch: 22, Step: 172/655, Loss: 2.207991, Accuracy: 18.90%\n",
            "Epoch: 22, Step: 173/655, Loss: 2.208074, Accuracy: 18.93%\n",
            "Epoch: 22, Step: 174/655, Loss: 2.208136, Accuracy: 18.93%\n",
            "Epoch: 22, Step: 175/655, Loss: 2.207735, Accuracy: 18.89%\n",
            "Epoch: 22, Step: 176/655, Loss: 2.207627, Accuracy: 18.87%\n",
            "Epoch: 22, Step: 177/655, Loss: 2.207439, Accuracy: 18.89%\n",
            "Epoch: 22, Step: 178/655, Loss: 2.207633, Accuracy: 18.89%\n",
            "Epoch: 22, Step: 179/655, Loss: 2.207912, Accuracy: 18.91%\n",
            "Epoch: 22, Step: 180/655, Loss: 2.206836, Accuracy: 19.03%\n",
            "Epoch: 22, Step: 181/655, Loss: 2.207136, Accuracy: 19.01%\n",
            "Epoch: 22, Step: 182/655, Loss: 2.206719, Accuracy: 19.06%\n",
            "Epoch: 22, Step: 183/655, Loss: 2.206774, Accuracy: 19.09%\n",
            "Epoch: 22, Step: 184/655, Loss: 2.206296, Accuracy: 19.14%\n",
            "Epoch: 22, Step: 185/655, Loss: 2.206079, Accuracy: 19.12%\n",
            "Epoch: 22, Step: 186/655, Loss: 2.206511, Accuracy: 19.09%\n",
            "Epoch: 22, Step: 187/655, Loss: 2.206414, Accuracy: 19.08%\n",
            "Epoch: 22, Step: 188/655, Loss: 2.206859, Accuracy: 19.10%\n",
            "Epoch: 22, Step: 189/655, Loss: 2.207647, Accuracy: 19.10%\n",
            "Epoch: 22, Step: 190/655, Loss: 2.207278, Accuracy: 19.06%\n",
            "Epoch: 22, Step: 191/655, Loss: 2.208067, Accuracy: 19.03%\n",
            "Epoch: 22, Step: 192/655, Loss: 2.208640, Accuracy: 19.01%\n",
            "Epoch: 22, Step: 193/655, Loss: 2.209023, Accuracy: 18.98%\n",
            "Epoch: 22, Step: 194/655, Loss: 2.209253, Accuracy: 18.96%\n",
            "Epoch: 22, Step: 195/655, Loss: 2.209431, Accuracy: 18.96%\n",
            "Epoch: 22, Step: 196/655, Loss: 2.209521, Accuracy: 18.97%\n",
            "Epoch: 22, Step: 197/655, Loss: 2.210138, Accuracy: 18.94%\n",
            "Epoch: 22, Step: 198/655, Loss: 2.209279, Accuracy: 18.96%\n",
            "Epoch: 22, Step: 199/655, Loss: 2.208482, Accuracy: 19.00%\n",
            "Epoch: 22, Step: 200/655, Loss: 2.207887, Accuracy: 19.03%\n",
            "Epoch: 22, Step: 201/655, Loss: 2.207806, Accuracy: 18.98%\n",
            "Epoch: 22, Step: 202/655, Loss: 2.207470, Accuracy: 18.98%\n",
            "Epoch: 22, Step: 203/655, Loss: 2.207573, Accuracy: 18.97%\n",
            "Epoch: 22, Step: 204/655, Loss: 2.207011, Accuracy: 19.00%\n",
            "Epoch: 22, Step: 205/655, Loss: 2.207007, Accuracy: 19.04%\n",
            "Epoch: 22, Step: 206/655, Loss: 2.207586, Accuracy: 19.02%\n",
            "Epoch: 22, Step: 207/655, Loss: 2.207388, Accuracy: 19.07%\n",
            "Epoch: 22, Step: 208/655, Loss: 2.207134, Accuracy: 19.08%\n",
            "Epoch: 22, Step: 209/655, Loss: 2.207438, Accuracy: 19.03%\n",
            "Epoch: 22, Step: 210/655, Loss: 2.207580, Accuracy: 19.03%\n",
            "Epoch: 22, Step: 211/655, Loss: 2.207438, Accuracy: 19.05%\n",
            "Epoch: 22, Step: 212/655, Loss: 2.206966, Accuracy: 19.03%\n",
            "Epoch: 22, Step: 213/655, Loss: 2.207373, Accuracy: 19.04%\n",
            "Epoch: 22, Step: 214/655, Loss: 2.207021, Accuracy: 19.07%\n",
            "Epoch: 22, Step: 215/655, Loss: 2.207247, Accuracy: 19.07%\n",
            "Epoch: 22, Step: 216/655, Loss: 2.207182, Accuracy: 19.07%\n",
            "Epoch: 22, Step: 217/655, Loss: 2.207184, Accuracy: 19.07%\n",
            "Epoch: 22, Step: 218/655, Loss: 2.207465, Accuracy: 19.05%\n",
            "Epoch: 22, Step: 219/655, Loss: 2.207753, Accuracy: 19.02%\n",
            "Epoch: 22, Step: 220/655, Loss: 2.207997, Accuracy: 18.98%\n",
            "Epoch: 22, Step: 221/655, Loss: 2.207657, Accuracy: 19.00%\n",
            "Epoch: 22, Step: 222/655, Loss: 2.207507, Accuracy: 19.02%\n",
            "Epoch: 22, Step: 223/655, Loss: 2.207346, Accuracy: 19.03%\n",
            "Epoch: 22, Step: 224/655, Loss: 2.207514, Accuracy: 19.02%\n",
            "Epoch: 22, Step: 225/655, Loss: 2.207981, Accuracy: 18.96%\n",
            "Epoch: 22, Step: 226/655, Loss: 2.208518, Accuracy: 18.96%\n",
            "Epoch: 22, Step: 227/655, Loss: 2.208666, Accuracy: 18.90%\n",
            "Epoch: 22, Step: 228/655, Loss: 2.209027, Accuracy: 18.89%\n",
            "Epoch: 22, Step: 229/655, Loss: 2.209093, Accuracy: 18.86%\n",
            "Epoch: 22, Step: 230/655, Loss: 2.209275, Accuracy: 18.86%\n",
            "Epoch: 22, Step: 231/655, Loss: 2.209265, Accuracy: 18.90%\n",
            "Epoch: 22, Step: 232/655, Loss: 2.209266, Accuracy: 18.88%\n",
            "Epoch: 22, Step: 233/655, Loss: 2.209438, Accuracy: 18.87%\n",
            "Epoch: 22, Step: 234/655, Loss: 2.209795, Accuracy: 18.83%\n",
            "Epoch: 22, Step: 235/655, Loss: 2.209491, Accuracy: 18.84%\n",
            "Epoch: 22, Step: 236/655, Loss: 2.209342, Accuracy: 18.87%\n",
            "Epoch: 22, Step: 237/655, Loss: 2.209694, Accuracy: 18.79%\n",
            "Epoch: 22, Step: 238/655, Loss: 2.209931, Accuracy: 18.75%\n",
            "Epoch: 22, Step: 239/655, Loss: 2.209621, Accuracy: 18.76%\n",
            "Epoch: 22, Step: 240/655, Loss: 2.209566, Accuracy: 18.75%\n",
            "Epoch: 22, Step: 241/655, Loss: 2.209954, Accuracy: 18.71%\n",
            "Epoch: 22, Step: 242/655, Loss: 2.209917, Accuracy: 18.70%\n",
            "Epoch: 22, Step: 243/655, Loss: 2.209742, Accuracy: 18.72%\n",
            "Epoch: 22, Step: 244/655, Loss: 2.209458, Accuracy: 18.72%\n",
            "Epoch: 22, Step: 245/655, Loss: 2.209335, Accuracy: 18.71%\n",
            "Epoch: 22, Step: 246/655, Loss: 2.209247, Accuracy: 18.74%\n",
            "Epoch: 22, Step: 247/655, Loss: 2.209455, Accuracy: 18.70%\n",
            "Epoch: 22, Step: 248/655, Loss: 2.209602, Accuracy: 18.69%\n",
            "Epoch: 22, Step: 249/655, Loss: 2.209573, Accuracy: 18.66%\n",
            "Epoch: 22, Step: 250/655, Loss: 2.209462, Accuracy: 18.73%\n",
            "Epoch: 22, Step: 251/655, Loss: 2.209179, Accuracy: 18.74%\n",
            "Epoch: 22, Step: 252/655, Loss: 2.209196, Accuracy: 18.73%\n",
            "Epoch: 22, Step: 253/655, Loss: 2.209359, Accuracy: 18.73%\n",
            "Epoch: 22, Step: 254/655, Loss: 2.209036, Accuracy: 18.77%\n",
            "Epoch: 22, Step: 255/655, Loss: 2.208897, Accuracy: 18.77%\n",
            "Epoch: 22, Step: 256/655, Loss: 2.208892, Accuracy: 18.77%\n",
            "Epoch: 22, Step: 257/655, Loss: 2.208486, Accuracy: 18.84%\n",
            "Epoch: 22, Step: 258/655, Loss: 2.208638, Accuracy: 18.81%\n",
            "Epoch: 22, Step: 259/655, Loss: 2.208878, Accuracy: 18.77%\n",
            "Epoch: 22, Step: 260/655, Loss: 2.208661, Accuracy: 18.80%\n",
            "Epoch: 22, Step: 261/655, Loss: 2.208626, Accuracy: 18.82%\n",
            "Epoch: 22, Step: 262/655, Loss: 2.208333, Accuracy: 18.85%\n",
            "Epoch: 22, Step: 263/655, Loss: 2.208467, Accuracy: 18.82%\n",
            "Epoch: 22, Step: 264/655, Loss: 2.208601, Accuracy: 18.82%\n",
            "Epoch: 22, Step: 265/655, Loss: 2.208625, Accuracy: 18.80%\n",
            "Epoch: 22, Step: 266/655, Loss: 2.208586, Accuracy: 18.81%\n",
            "Epoch: 22, Step: 267/655, Loss: 2.208817, Accuracy: 18.80%\n",
            "Epoch: 22, Step: 268/655, Loss: 2.209131, Accuracy: 18.80%\n",
            "Epoch: 22, Step: 269/655, Loss: 2.209047, Accuracy: 18.81%\n",
            "Epoch: 22, Step: 270/655, Loss: 2.209287, Accuracy: 18.78%\n",
            "Epoch: 22, Step: 271/655, Loss: 2.208976, Accuracy: 18.77%\n",
            "Epoch: 22, Step: 272/655, Loss: 2.209232, Accuracy: 18.74%\n",
            "Epoch: 22, Step: 273/655, Loss: 2.209603, Accuracy: 18.70%\n",
            "Epoch: 22, Step: 274/655, Loss: 2.209606, Accuracy: 18.69%\n",
            "Epoch: 22, Step: 275/655, Loss: 2.209636, Accuracy: 18.72%\n",
            "Epoch: 22, Step: 276/655, Loss: 2.209756, Accuracy: 18.70%\n",
            "Epoch: 22, Step: 277/655, Loss: 2.209448, Accuracy: 18.72%\n",
            "Epoch: 22, Step: 278/655, Loss: 2.209208, Accuracy: 18.71%\n",
            "Epoch: 22, Step: 279/655, Loss: 2.209120, Accuracy: 18.71%\n",
            "Epoch: 22, Step: 280/655, Loss: 2.208764, Accuracy: 18.71%\n",
            "Epoch: 22, Step: 281/655, Loss: 2.208708, Accuracy: 18.71%\n",
            "Epoch: 22, Step: 282/655, Loss: 2.208878, Accuracy: 18.68%\n",
            "Epoch: 22, Step: 283/655, Loss: 2.209242, Accuracy: 18.66%\n",
            "Epoch: 22, Step: 284/655, Loss: 2.209380, Accuracy: 18.64%\n",
            "Epoch: 22, Step: 285/655, Loss: 2.209233, Accuracy: 18.72%\n",
            "Epoch: 22, Step: 286/655, Loss: 2.209044, Accuracy: 18.75%\n",
            "Epoch: 22, Step: 287/655, Loss: 2.209070, Accuracy: 18.73%\n",
            "Epoch: 22, Step: 288/655, Loss: 2.208683, Accuracy: 18.78%\n",
            "Epoch: 22, Step: 289/655, Loss: 2.208498, Accuracy: 18.77%\n",
            "Epoch: 22, Step: 290/655, Loss: 2.208515, Accuracy: 18.77%\n",
            "Epoch: 22, Step: 291/655, Loss: 2.208993, Accuracy: 18.75%\n",
            "Epoch: 22, Step: 292/655, Loss: 2.209214, Accuracy: 18.74%\n",
            "Epoch: 22, Step: 293/655, Loss: 2.208735, Accuracy: 18.75%\n",
            "Epoch: 22, Step: 294/655, Loss: 2.209126, Accuracy: 18.72%\n",
            "Epoch: 22, Step: 295/655, Loss: 2.209639, Accuracy: 18.73%\n",
            "Epoch: 22, Step: 296/655, Loss: 2.209099, Accuracy: 18.75%\n",
            "Epoch: 22, Step: 297/655, Loss: 2.208463, Accuracy: 18.78%\n",
            "Epoch: 22, Step: 298/655, Loss: 2.208743, Accuracy: 18.76%\n",
            "Epoch: 22, Step: 299/655, Loss: 2.208676, Accuracy: 18.75%\n",
            "Epoch: 22, Step: 300/655, Loss: 2.208891, Accuracy: 18.74%\n",
            "Epoch: 22, Step: 301/655, Loss: 2.208777, Accuracy: 18.72%\n",
            "Epoch: 22, Step: 302/655, Loss: 2.209101, Accuracy: 18.70%\n",
            "Epoch: 22, Step: 303/655, Loss: 2.209079, Accuracy: 18.71%\n",
            "Epoch: 22, Step: 304/655, Loss: 2.209145, Accuracy: 18.69%\n",
            "Epoch: 22, Step: 305/655, Loss: 2.208875, Accuracy: 18.69%\n",
            "Epoch: 22, Step: 306/655, Loss: 2.208607, Accuracy: 18.71%\n",
            "Epoch: 22, Step: 307/655, Loss: 2.208751, Accuracy: 18.71%\n",
            "Epoch: 22, Step: 308/655, Loss: 2.208623, Accuracy: 18.70%\n",
            "Epoch: 22, Step: 309/655, Loss: 2.208607, Accuracy: 18.70%\n",
            "Epoch: 22, Step: 310/655, Loss: 2.207958, Accuracy: 18.74%\n",
            "Epoch: 22, Step: 311/655, Loss: 2.207640, Accuracy: 18.74%\n",
            "Epoch: 22, Step: 312/655, Loss: 2.207086, Accuracy: 18.80%\n",
            "Epoch: 22, Step: 313/655, Loss: 2.207138, Accuracy: 18.78%\n",
            "Epoch: 22, Step: 314/655, Loss: 2.207477, Accuracy: 18.76%\n",
            "Epoch: 22, Step: 315/655, Loss: 2.207498, Accuracy: 18.75%\n",
            "Epoch: 22, Step: 316/655, Loss: 2.207411, Accuracy: 18.76%\n",
            "Epoch: 22, Step: 317/655, Loss: 2.207816, Accuracy: 18.71%\n",
            "Epoch: 22, Step: 318/655, Loss: 2.207758, Accuracy: 18.73%\n",
            "Epoch: 22, Step: 319/655, Loss: 2.207696, Accuracy: 18.75%\n",
            "Epoch: 22, Step: 320/655, Loss: 2.207761, Accuracy: 18.79%\n",
            "Epoch: 22, Step: 321/655, Loss: 2.207534, Accuracy: 18.79%\n",
            "Epoch: 22, Step: 322/655, Loss: 2.207364, Accuracy: 18.78%\n",
            "Epoch: 22, Step: 323/655, Loss: 2.207275, Accuracy: 18.80%\n",
            "Epoch: 22, Step: 324/655, Loss: 2.207212, Accuracy: 18.80%\n",
            "Epoch: 22, Step: 325/655, Loss: 2.207043, Accuracy: 18.79%\n",
            "Epoch: 22, Step: 326/655, Loss: 2.207292, Accuracy: 18.78%\n",
            "Epoch: 22, Step: 327/655, Loss: 2.207480, Accuracy: 18.77%\n",
            "Epoch: 22, Step: 328/655, Loss: 2.207367, Accuracy: 18.81%\n",
            "Epoch: 22, Step: 329/655, Loss: 2.206892, Accuracy: 18.86%\n",
            "Epoch: 22, Step: 330/655, Loss: 2.206716, Accuracy: 18.87%\n",
            "Epoch: 22, Step: 331/655, Loss: 2.206484, Accuracy: 18.89%\n",
            "Epoch: 22, Step: 332/655, Loss: 2.206377, Accuracy: 18.92%\n",
            "Epoch: 22, Step: 333/655, Loss: 2.206181, Accuracy: 18.92%\n",
            "Epoch: 22, Step: 334/655, Loss: 2.205981, Accuracy: 18.93%\n",
            "Epoch: 22, Step: 335/655, Loss: 2.206085, Accuracy: 18.92%\n",
            "Epoch: 22, Step: 336/655, Loss: 2.206144, Accuracy: 18.92%\n",
            "Epoch: 22, Step: 337/655, Loss: 2.206407, Accuracy: 18.92%\n",
            "Epoch: 22, Step: 338/655, Loss: 2.206618, Accuracy: 18.93%\n",
            "Epoch: 22, Step: 339/655, Loss: 2.206450, Accuracy: 18.90%\n",
            "Epoch: 22, Step: 340/655, Loss: 2.206260, Accuracy: 18.89%\n",
            "Epoch: 22, Step: 341/655, Loss: 2.206267, Accuracy: 18.89%\n",
            "Epoch: 22, Step: 342/655, Loss: 2.206076, Accuracy: 18.90%\n",
            "Epoch: 22, Step: 343/655, Loss: 2.206451, Accuracy: 18.87%\n",
            "Epoch: 22, Step: 344/655, Loss: 2.206496, Accuracy: 18.87%\n",
            "Epoch: 22, Step: 345/655, Loss: 2.206713, Accuracy: 18.84%\n",
            "Epoch: 22, Step: 346/655, Loss: 2.206857, Accuracy: 18.83%\n",
            "Epoch: 22, Step: 347/655, Loss: 2.206910, Accuracy: 18.82%\n",
            "Epoch: 22, Step: 348/655, Loss: 2.207390, Accuracy: 18.80%\n",
            "Epoch: 22, Step: 349/655, Loss: 2.207693, Accuracy: 18.80%\n",
            "Epoch: 22, Step: 350/655, Loss: 2.207406, Accuracy: 18.84%\n",
            "Epoch: 22, Step: 351/655, Loss: 2.207318, Accuracy: 18.84%\n",
            "Epoch: 22, Step: 352/655, Loss: 2.207114, Accuracy: 18.83%\n",
            "Epoch: 22, Step: 353/655, Loss: 2.206732, Accuracy: 18.85%\n",
            "Epoch: 22, Step: 354/655, Loss: 2.206646, Accuracy: 18.86%\n",
            "Epoch: 22, Step: 355/655, Loss: 2.206649, Accuracy: 18.86%\n",
            "Epoch: 22, Step: 356/655, Loss: 2.206245, Accuracy: 18.90%\n",
            "Epoch: 22, Step: 357/655, Loss: 2.206406, Accuracy: 18.86%\n",
            "Epoch: 22, Step: 358/655, Loss: 2.206033, Accuracy: 18.89%\n",
            "Epoch: 22, Step: 359/655, Loss: 2.206308, Accuracy: 18.89%\n",
            "Epoch: 22, Step: 360/655, Loss: 2.205976, Accuracy: 18.88%\n",
            "Epoch: 22, Step: 361/655, Loss: 2.205793, Accuracy: 18.88%\n",
            "Epoch: 22, Step: 362/655, Loss: 2.205890, Accuracy: 18.87%\n",
            "Epoch: 22, Step: 363/655, Loss: 2.205586, Accuracy: 18.90%\n",
            "Epoch: 22, Step: 364/655, Loss: 2.205696, Accuracy: 18.88%\n",
            "Epoch: 22, Step: 365/655, Loss: 2.205784, Accuracy: 18.90%\n",
            "Epoch: 22, Step: 366/655, Loss: 2.205972, Accuracy: 18.87%\n",
            "Epoch: 22, Step: 367/655, Loss: 2.205828, Accuracy: 18.85%\n",
            "Epoch: 22, Step: 368/655, Loss: 2.205864, Accuracy: 18.86%\n",
            "Epoch: 22, Step: 369/655, Loss: 2.206171, Accuracy: 18.85%\n",
            "Epoch: 22, Step: 370/655, Loss: 2.206163, Accuracy: 18.84%\n",
            "Epoch: 22, Step: 371/655, Loss: 2.206268, Accuracy: 18.82%\n",
            "Epoch: 22, Step: 372/655, Loss: 2.206059, Accuracy: 18.82%\n",
            "Epoch: 22, Step: 373/655, Loss: 2.206335, Accuracy: 18.81%\n",
            "Epoch: 22, Step: 374/655, Loss: 2.206218, Accuracy: 18.81%\n",
            "Epoch: 22, Step: 375/655, Loss: 2.205717, Accuracy: 18.82%\n",
            "Epoch: 22, Step: 376/655, Loss: 2.205863, Accuracy: 18.79%\n",
            "Epoch: 22, Step: 377/655, Loss: 2.205960, Accuracy: 18.75%\n",
            "Epoch: 22, Step: 378/655, Loss: 2.205805, Accuracy: 18.74%\n",
            "Epoch: 22, Step: 379/655, Loss: 2.205884, Accuracy: 18.76%\n",
            "Epoch: 22, Step: 380/655, Loss: 2.205845, Accuracy: 18.75%\n",
            "Epoch: 22, Step: 381/655, Loss: 2.205695, Accuracy: 18.74%\n",
            "Epoch: 22, Step: 382/655, Loss: 2.205516, Accuracy: 18.74%\n",
            "Epoch: 22, Step: 383/655, Loss: 2.205596, Accuracy: 18.72%\n",
            "Epoch: 22, Step: 384/655, Loss: 2.205672, Accuracy: 18.70%\n",
            "Epoch: 22, Step: 385/655, Loss: 2.205882, Accuracy: 18.70%\n",
            "Epoch: 22, Step: 386/655, Loss: 2.206169, Accuracy: 18.67%\n",
            "Epoch: 22, Step: 387/655, Loss: 2.206349, Accuracy: 18.64%\n",
            "Epoch: 22, Step: 388/655, Loss: 2.206401, Accuracy: 18.65%\n",
            "Epoch: 22, Step: 389/655, Loss: 2.206537, Accuracy: 18.63%\n",
            "Epoch: 22, Step: 390/655, Loss: 2.206641, Accuracy: 18.63%\n",
            "Epoch: 22, Step: 391/655, Loss: 2.206286, Accuracy: 18.65%\n",
            "Epoch: 22, Step: 392/655, Loss: 2.206147, Accuracy: 18.63%\n",
            "Epoch: 22, Step: 393/655, Loss: 2.206383, Accuracy: 18.63%\n",
            "Epoch: 22, Step: 394/655, Loss: 2.206509, Accuracy: 18.64%\n",
            "Epoch: 22, Step: 395/655, Loss: 2.206388, Accuracy: 18.66%\n",
            "Epoch: 22, Step: 396/655, Loss: 2.206503, Accuracy: 18.63%\n",
            "Epoch: 22, Step: 397/655, Loss: 2.206530, Accuracy: 18.62%\n",
            "Epoch: 22, Step: 398/655, Loss: 2.206692, Accuracy: 18.60%\n",
            "Epoch: 22, Step: 399/655, Loss: 2.206764, Accuracy: 18.60%\n",
            "Epoch: 22, Step: 400/655, Loss: 2.207041, Accuracy: 18.56%\n",
            "Epoch: 22, Step: 401/655, Loss: 2.206861, Accuracy: 18.55%\n",
            "Epoch: 22, Step: 402/655, Loss: 2.206551, Accuracy: 18.56%\n",
            "Epoch: 22, Step: 403/655, Loss: 2.206530, Accuracy: 18.55%\n",
            "Epoch: 22, Step: 404/655, Loss: 2.206458, Accuracy: 18.54%\n",
            "Epoch: 22, Step: 405/655, Loss: 2.206569, Accuracy: 18.53%\n",
            "Epoch: 22, Step: 406/655, Loss: 2.206503, Accuracy: 18.53%\n",
            "Epoch: 22, Step: 407/655, Loss: 2.206416, Accuracy: 18.54%\n",
            "Epoch: 22, Step: 408/655, Loss: 2.206681, Accuracy: 18.52%\n",
            "Epoch: 22, Step: 409/655, Loss: 2.206233, Accuracy: 18.56%\n",
            "Epoch: 22, Step: 410/655, Loss: 2.206102, Accuracy: 18.54%\n",
            "Epoch: 22, Step: 411/655, Loss: 2.205914, Accuracy: 18.55%\n",
            "Epoch: 22, Step: 412/655, Loss: 2.205957, Accuracy: 18.56%\n",
            "Epoch: 22, Step: 413/655, Loss: 2.206013, Accuracy: 18.54%\n",
            "Epoch: 22, Step: 414/655, Loss: 2.205884, Accuracy: 18.57%\n",
            "Epoch: 22, Step: 415/655, Loss: 2.205647, Accuracy: 18.58%\n",
            "Epoch: 22, Step: 416/655, Loss: 2.205864, Accuracy: 18.57%\n",
            "Epoch: 22, Step: 417/655, Loss: 2.205728, Accuracy: 18.58%\n",
            "Epoch: 22, Step: 418/655, Loss: 2.206078, Accuracy: 18.53%\n",
            "Epoch: 22, Step: 419/655, Loss: 2.206123, Accuracy: 18.53%\n",
            "Epoch: 22, Step: 420/655, Loss: 2.206284, Accuracy: 18.53%\n",
            "Epoch: 22, Step: 421/655, Loss: 2.206241, Accuracy: 18.53%\n",
            "Epoch: 22, Step: 422/655, Loss: 2.206698, Accuracy: 18.53%\n",
            "Epoch: 22, Step: 423/655, Loss: 2.206992, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 424/655, Loss: 2.207050, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 425/655, Loss: 2.207074, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 426/655, Loss: 2.207332, Accuracy: 18.44%\n",
            "Epoch: 22, Step: 427/655, Loss: 2.207645, Accuracy: 18.44%\n",
            "Epoch: 22, Step: 428/655, Loss: 2.207582, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 429/655, Loss: 2.207591, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 430/655, Loss: 2.207725, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 431/655, Loss: 2.207755, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 432/655, Loss: 2.207415, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 433/655, Loss: 2.207621, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 434/655, Loss: 2.207289, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 435/655, Loss: 2.207592, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 436/655, Loss: 2.207628, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 437/655, Loss: 2.207740, Accuracy: 18.42%\n",
            "Epoch: 22, Step: 438/655, Loss: 2.207751, Accuracy: 18.39%\n",
            "Epoch: 22, Step: 439/655, Loss: 2.207906, Accuracy: 18.37%\n",
            "Epoch: 22, Step: 440/655, Loss: 2.207760, Accuracy: 18.37%\n",
            "Epoch: 22, Step: 441/655, Loss: 2.207372, Accuracy: 18.39%\n",
            "Epoch: 22, Step: 442/655, Loss: 2.207412, Accuracy: 18.38%\n",
            "Epoch: 22, Step: 443/655, Loss: 2.207536, Accuracy: 18.37%\n",
            "Epoch: 22, Step: 444/655, Loss: 2.207433, Accuracy: 18.38%\n",
            "Epoch: 22, Step: 445/655, Loss: 2.207559, Accuracy: 18.37%\n",
            "Epoch: 22, Step: 446/655, Loss: 2.207686, Accuracy: 18.36%\n",
            "Epoch: 22, Step: 447/655, Loss: 2.207593, Accuracy: 18.38%\n",
            "Epoch: 22, Step: 448/655, Loss: 2.207709, Accuracy: 18.39%\n",
            "Epoch: 22, Step: 449/655, Loss: 2.207480, Accuracy: 18.38%\n",
            "Epoch: 22, Step: 450/655, Loss: 2.207705, Accuracy: 18.38%\n",
            "Epoch: 22, Step: 451/655, Loss: 2.207707, Accuracy: 18.39%\n",
            "Epoch: 22, Step: 452/655, Loss: 2.207563, Accuracy: 18.40%\n",
            "Epoch: 22, Step: 453/655, Loss: 2.207184, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 454/655, Loss: 2.207261, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 455/655, Loss: 2.207275, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 456/655, Loss: 2.207500, Accuracy: 18.41%\n",
            "Epoch: 22, Step: 457/655, Loss: 2.207795, Accuracy: 18.41%\n",
            "Epoch: 22, Step: 458/655, Loss: 2.207816, Accuracy: 18.41%\n",
            "Epoch: 22, Step: 459/655, Loss: 2.207429, Accuracy: 18.44%\n",
            "Epoch: 22, Step: 460/655, Loss: 2.207550, Accuracy: 18.41%\n",
            "Epoch: 22, Step: 461/655, Loss: 2.207435, Accuracy: 18.42%\n",
            "Epoch: 22, Step: 462/655, Loss: 2.207539, Accuracy: 18.41%\n",
            "Epoch: 22, Step: 463/655, Loss: 2.207557, Accuracy: 18.41%\n",
            "Epoch: 22, Step: 464/655, Loss: 2.207291, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 465/655, Loss: 2.207149, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 466/655, Loss: 2.207002, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 467/655, Loss: 2.207032, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 468/655, Loss: 2.207100, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 469/655, Loss: 2.207097, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 470/655, Loss: 2.207220, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 471/655, Loss: 2.207250, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 472/655, Loss: 2.207270, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 473/655, Loss: 2.207138, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 474/655, Loss: 2.207471, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 475/655, Loss: 2.207305, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 476/655, Loss: 2.207293, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 477/655, Loss: 2.207346, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 478/655, Loss: 2.207514, Accuracy: 18.44%\n",
            "Epoch: 22, Step: 479/655, Loss: 2.207664, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 480/655, Loss: 2.207732, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 481/655, Loss: 2.207608, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 482/655, Loss: 2.207647, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 483/655, Loss: 2.207663, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 484/655, Loss: 2.207918, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 485/655, Loss: 2.207874, Accuracy: 18.45%\n",
            "Epoch: 22, Step: 486/655, Loss: 2.207989, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 487/655, Loss: 2.207729, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 488/655, Loss: 2.207636, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 489/655, Loss: 2.207547, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 490/655, Loss: 2.207504, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 491/655, Loss: 2.207426, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 492/655, Loss: 2.207465, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 493/655, Loss: 2.207613, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 494/655, Loss: 2.207680, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 495/655, Loss: 2.207678, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 496/655, Loss: 2.207791, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 497/655, Loss: 2.207732, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 498/655, Loss: 2.207686, Accuracy: 18.51%\n",
            "Epoch: 22, Step: 499/655, Loss: 2.207599, Accuracy: 18.51%\n",
            "Epoch: 22, Step: 500/655, Loss: 2.207552, Accuracy: 18.51%\n",
            "Epoch: 22, Step: 501/655, Loss: 2.207657, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 502/655, Loss: 2.207735, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 503/655, Loss: 2.207569, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 504/655, Loss: 2.207797, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 505/655, Loss: 2.207838, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 506/655, Loss: 2.207510, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 507/655, Loss: 2.207380, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 508/655, Loss: 2.207663, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 509/655, Loss: 2.207640, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 510/655, Loss: 2.207628, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 511/655, Loss: 2.207575, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 512/655, Loss: 2.207690, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 513/655, Loss: 2.207736, Accuracy: 18.50%\n",
            "Epoch: 22, Step: 514/655, Loss: 2.207736, Accuracy: 18.52%\n",
            "Epoch: 22, Step: 515/655, Loss: 2.207647, Accuracy: 18.53%\n",
            "Epoch: 22, Step: 516/655, Loss: 2.207586, Accuracy: 18.53%\n",
            "Epoch: 22, Step: 517/655, Loss: 2.207557, Accuracy: 18.53%\n",
            "Epoch: 22, Step: 518/655, Loss: 2.207563, Accuracy: 18.54%\n",
            "Epoch: 22, Step: 519/655, Loss: 2.207677, Accuracy: 18.53%\n",
            "Epoch: 22, Step: 520/655, Loss: 2.207700, Accuracy: 18.51%\n",
            "Epoch: 22, Step: 521/655, Loss: 2.207700, Accuracy: 18.50%\n",
            "Epoch: 22, Step: 522/655, Loss: 2.207770, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 523/655, Loss: 2.207490, Accuracy: 18.52%\n",
            "Epoch: 22, Step: 524/655, Loss: 2.207297, Accuracy: 18.54%\n",
            "Epoch: 22, Step: 525/655, Loss: 2.207346, Accuracy: 18.53%\n",
            "Epoch: 22, Step: 526/655, Loss: 2.207535, Accuracy: 18.52%\n",
            "Epoch: 22, Step: 527/655, Loss: 2.207425, Accuracy: 18.52%\n",
            "Epoch: 22, Step: 528/655, Loss: 2.207616, Accuracy: 18.51%\n",
            "Epoch: 22, Step: 529/655, Loss: 2.207741, Accuracy: 18.50%\n",
            "Epoch: 22, Step: 530/655, Loss: 2.207881, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 531/655, Loss: 2.207848, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 532/655, Loss: 2.207941, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 533/655, Loss: 2.208262, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 534/655, Loss: 2.208065, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 535/655, Loss: 2.208081, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 536/655, Loss: 2.208222, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 537/655, Loss: 2.208247, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 538/655, Loss: 2.208313, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 539/655, Loss: 2.208463, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 540/655, Loss: 2.208612, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 541/655, Loss: 2.208730, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 542/655, Loss: 2.208985, Accuracy: 18.44%\n",
            "Epoch: 22, Step: 543/655, Loss: 2.208731, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 544/655, Loss: 2.208925, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 545/655, Loss: 2.208931, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 546/655, Loss: 2.209019, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 547/655, Loss: 2.209165, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 548/655, Loss: 2.209223, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 549/655, Loss: 2.209390, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 550/655, Loss: 2.209325, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 551/655, Loss: 2.209326, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 552/655, Loss: 2.209696, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 553/655, Loss: 2.209571, Accuracy: 18.44%\n",
            "Epoch: 22, Step: 554/655, Loss: 2.209508, Accuracy: 18.44%\n",
            "Epoch: 22, Step: 555/655, Loss: 2.209619, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 556/655, Loss: 2.209648, Accuracy: 18.42%\n",
            "Epoch: 22, Step: 557/655, Loss: 2.209416, Accuracy: 18.45%\n",
            "Epoch: 22, Step: 558/655, Loss: 2.209402, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 559/655, Loss: 2.209452, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 560/655, Loss: 2.209561, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 561/655, Loss: 2.209332, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 562/655, Loss: 2.209072, Accuracy: 18.50%\n",
            "Epoch: 22, Step: 563/655, Loss: 2.209123, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 564/655, Loss: 2.209155, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 565/655, Loss: 2.209348, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 566/655, Loss: 2.209314, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 567/655, Loss: 2.209284, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 568/655, Loss: 2.209391, Accuracy: 18.45%\n",
            "Epoch: 22, Step: 569/655, Loss: 2.209338, Accuracy: 18.44%\n",
            "Epoch: 22, Step: 570/655, Loss: 2.209337, Accuracy: 18.44%\n",
            "Epoch: 22, Step: 571/655, Loss: 2.209136, Accuracy: 18.45%\n",
            "Epoch: 22, Step: 572/655, Loss: 2.209135, Accuracy: 18.44%\n",
            "Epoch: 22, Step: 573/655, Loss: 2.209235, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 574/655, Loss: 2.209172, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 575/655, Loss: 2.209380, Accuracy: 18.42%\n",
            "Epoch: 22, Step: 576/655, Loss: 2.209238, Accuracy: 18.42%\n",
            "Epoch: 22, Step: 577/655, Loss: 2.209393, Accuracy: 18.40%\n",
            "Epoch: 22, Step: 578/655, Loss: 2.209327, Accuracy: 18.41%\n",
            "Epoch: 22, Step: 579/655, Loss: 2.209122, Accuracy: 18.40%\n",
            "Epoch: 22, Step: 580/655, Loss: 2.209075, Accuracy: 18.42%\n",
            "Epoch: 22, Step: 581/655, Loss: 2.209168, Accuracy: 18.42%\n",
            "Epoch: 22, Step: 582/655, Loss: 2.209302, Accuracy: 18.42%\n",
            "Epoch: 22, Step: 583/655, Loss: 2.209313, Accuracy: 18.42%\n",
            "Epoch: 22, Step: 584/655, Loss: 2.209472, Accuracy: 18.41%\n",
            "Epoch: 22, Step: 585/655, Loss: 2.209321, Accuracy: 18.41%\n",
            "Epoch: 22, Step: 586/655, Loss: 2.209329, Accuracy: 18.41%\n",
            "Epoch: 22, Step: 587/655, Loss: 2.209274, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 588/655, Loss: 2.209387, Accuracy: 18.44%\n",
            "Epoch: 22, Step: 589/655, Loss: 2.209254, Accuracy: 18.44%\n",
            "Epoch: 22, Step: 590/655, Loss: 2.209109, Accuracy: 18.44%\n",
            "Epoch: 22, Step: 591/655, Loss: 2.208997, Accuracy: 18.44%\n",
            "Epoch: 22, Step: 592/655, Loss: 2.209087, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 593/655, Loss: 2.209199, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 594/655, Loss: 2.209346, Accuracy: 18.43%\n",
            "Epoch: 22, Step: 595/655, Loss: 2.209133, Accuracy: 18.45%\n",
            "Epoch: 22, Step: 596/655, Loss: 2.209103, Accuracy: 18.45%\n",
            "Epoch: 22, Step: 597/655, Loss: 2.208927, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 598/655, Loss: 2.208805, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 599/655, Loss: 2.208795, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 600/655, Loss: 2.208715, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 601/655, Loss: 2.208456, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 602/655, Loss: 2.208433, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 603/655, Loss: 2.208493, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 604/655, Loss: 2.208462, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 605/655, Loss: 2.208473, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 606/655, Loss: 2.208360, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 607/655, Loss: 2.208261, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 608/655, Loss: 2.208102, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 609/655, Loss: 2.208151, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 610/655, Loss: 2.208062, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 611/655, Loss: 2.207894, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 612/655, Loss: 2.207745, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 613/655, Loss: 2.207936, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 614/655, Loss: 2.207923, Accuracy: 18.50%\n",
            "Epoch: 22, Step: 615/655, Loss: 2.207924, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 616/655, Loss: 2.207828, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 617/655, Loss: 2.208036, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 618/655, Loss: 2.207884, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 619/655, Loss: 2.207807, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 620/655, Loss: 2.208004, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 621/655, Loss: 2.208074, Accuracy: 18.45%\n",
            "Epoch: 22, Step: 622/655, Loss: 2.207905, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 623/655, Loss: 2.207959, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 624/655, Loss: 2.208164, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 625/655, Loss: 2.207977, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 626/655, Loss: 2.207964, Accuracy: 18.50%\n",
            "Epoch: 22, Step: 627/655, Loss: 2.208039, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 628/655, Loss: 2.207907, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 629/655, Loss: 2.207983, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 630/655, Loss: 2.207863, Accuracy: 18.51%\n",
            "Epoch: 22, Step: 631/655, Loss: 2.208035, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 632/655, Loss: 2.207974, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 633/655, Loss: 2.207807, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 634/655, Loss: 2.207770, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 635/655, Loss: 2.207742, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 636/655, Loss: 2.207653, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 637/655, Loss: 2.207665, Accuracy: 18.49%\n",
            "Epoch: 22, Step: 638/655, Loss: 2.207487, Accuracy: 18.50%\n",
            "Epoch: 22, Step: 639/655, Loss: 2.207574, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 640/655, Loss: 2.207797, Accuracy: 18.48%\n",
            "Epoch: 22, Step: 641/655, Loss: 2.207870, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 642/655, Loss: 2.207922, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 643/655, Loss: 2.207977, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 644/655, Loss: 2.208050, Accuracy: 18.45%\n",
            "Epoch: 22, Step: 645/655, Loss: 2.207922, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 646/655, Loss: 2.207951, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 647/655, Loss: 2.207909, Accuracy: 18.45%\n",
            "Epoch: 22, Step: 648/655, Loss: 2.207791, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 649/655, Loss: 2.207931, Accuracy: 18.45%\n",
            "Epoch: 22, Step: 650/655, Loss: 2.207895, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 651/655, Loss: 2.207955, Accuracy: 18.46%\n",
            "Epoch: 22, Step: 652/655, Loss: 2.208021, Accuracy: 18.45%\n",
            "Epoch: 22, Step: 653/655, Loss: 2.208038, Accuracy: 18.45%\n",
            "Epoch: 22, Step: 654/655, Loss: 2.207909, Accuracy: 18.47%\n",
            "Epoch: 22, Step: 655/655, Loss: 2.207720, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 1/655, Loss: 2.128303, Accuracy: 12.50%\n",
            "Epoch: 23, Step: 2/655, Loss: 2.210974, Accuracy: 15.62%\n",
            "Epoch: 23, Step: 3/655, Loss: 2.215318, Accuracy: 14.58%\n",
            "Epoch: 23, Step: 4/655, Loss: 2.254248, Accuracy: 14.06%\n",
            "Epoch: 23, Step: 5/655, Loss: 2.229233, Accuracy: 15.62%\n",
            "Epoch: 23, Step: 6/655, Loss: 2.219497, Accuracy: 15.10%\n",
            "Epoch: 23, Step: 7/655, Loss: 2.224341, Accuracy: 16.07%\n",
            "Epoch: 23, Step: 8/655, Loss: 2.239047, Accuracy: 16.41%\n",
            "Epoch: 23, Step: 9/655, Loss: 2.246659, Accuracy: 16.32%\n",
            "Epoch: 23, Step: 10/655, Loss: 2.239209, Accuracy: 16.88%\n",
            "Epoch: 23, Step: 11/655, Loss: 2.242335, Accuracy: 16.19%\n",
            "Epoch: 23, Step: 12/655, Loss: 2.232022, Accuracy: 17.45%\n",
            "Epoch: 23, Step: 13/655, Loss: 2.233814, Accuracy: 17.07%\n",
            "Epoch: 23, Step: 14/655, Loss: 2.219130, Accuracy: 18.08%\n",
            "Epoch: 23, Step: 15/655, Loss: 2.217111, Accuracy: 17.92%\n",
            "Epoch: 23, Step: 16/655, Loss: 2.219770, Accuracy: 17.97%\n",
            "Epoch: 23, Step: 17/655, Loss: 2.213536, Accuracy: 18.75%\n",
            "Epoch: 23, Step: 18/655, Loss: 2.215808, Accuracy: 18.92%\n",
            "Epoch: 23, Step: 19/655, Loss: 2.218971, Accuracy: 18.91%\n",
            "Epoch: 23, Step: 20/655, Loss: 2.222535, Accuracy: 18.91%\n",
            "Epoch: 23, Step: 21/655, Loss: 2.217880, Accuracy: 19.49%\n",
            "Epoch: 23, Step: 22/655, Loss: 2.214620, Accuracy: 19.74%\n",
            "Epoch: 23, Step: 23/655, Loss: 2.213508, Accuracy: 19.43%\n",
            "Epoch: 23, Step: 24/655, Loss: 2.217980, Accuracy: 19.01%\n",
            "Epoch: 23, Step: 25/655, Loss: 2.214817, Accuracy: 18.75%\n",
            "Epoch: 23, Step: 26/655, Loss: 2.206620, Accuracy: 19.11%\n",
            "Epoch: 23, Step: 27/655, Loss: 2.204999, Accuracy: 19.56%\n",
            "Epoch: 23, Step: 28/655, Loss: 2.203176, Accuracy: 19.53%\n",
            "Epoch: 23, Step: 29/655, Loss: 2.203503, Accuracy: 19.29%\n",
            "Epoch: 23, Step: 30/655, Loss: 2.202498, Accuracy: 19.17%\n",
            "Epoch: 23, Step: 31/655, Loss: 2.204273, Accuracy: 18.95%\n",
            "Epoch: 23, Step: 32/655, Loss: 2.206241, Accuracy: 19.04%\n",
            "Epoch: 23, Step: 33/655, Loss: 2.203050, Accuracy: 19.13%\n",
            "Epoch: 23, Step: 34/655, Loss: 2.204361, Accuracy: 19.12%\n",
            "Epoch: 23, Step: 35/655, Loss: 2.201659, Accuracy: 19.55%\n",
            "Epoch: 23, Step: 36/655, Loss: 2.203683, Accuracy: 19.36%\n",
            "Epoch: 23, Step: 37/655, Loss: 2.206331, Accuracy: 19.34%\n",
            "Epoch: 23, Step: 38/655, Loss: 2.209053, Accuracy: 19.16%\n",
            "Epoch: 23, Step: 39/655, Loss: 2.207423, Accuracy: 19.31%\n",
            "Epoch: 23, Step: 40/655, Loss: 2.206769, Accuracy: 19.45%\n",
            "Epoch: 23, Step: 41/655, Loss: 2.203261, Accuracy: 19.66%\n",
            "Epoch: 23, Step: 42/655, Loss: 2.203551, Accuracy: 19.79%\n",
            "Epoch: 23, Step: 43/655, Loss: 2.204152, Accuracy: 19.77%\n",
            "Epoch: 23, Step: 44/655, Loss: 2.206391, Accuracy: 19.67%\n",
            "Epoch: 23, Step: 45/655, Loss: 2.209712, Accuracy: 19.44%\n",
            "Epoch: 23, Step: 46/655, Loss: 2.210633, Accuracy: 19.29%\n",
            "Epoch: 23, Step: 47/655, Loss: 2.208446, Accuracy: 19.61%\n",
            "Epoch: 23, Step: 48/655, Loss: 2.207702, Accuracy: 19.73%\n",
            "Epoch: 23, Step: 49/655, Loss: 2.206001, Accuracy: 19.71%\n",
            "Epoch: 23, Step: 50/655, Loss: 2.205288, Accuracy: 19.88%\n",
            "Epoch: 23, Step: 51/655, Loss: 2.207193, Accuracy: 19.73%\n",
            "Epoch: 23, Step: 52/655, Loss: 2.207532, Accuracy: 19.59%\n",
            "Epoch: 23, Step: 53/655, Loss: 2.205838, Accuracy: 19.58%\n",
            "Epoch: 23, Step: 54/655, Loss: 2.208498, Accuracy: 19.33%\n",
            "Epoch: 23, Step: 55/655, Loss: 2.206504, Accuracy: 19.49%\n",
            "Epoch: 23, Step: 56/655, Loss: 2.204942, Accuracy: 19.75%\n",
            "Epoch: 23, Step: 57/655, Loss: 2.206167, Accuracy: 19.63%\n",
            "Epoch: 23, Step: 58/655, Loss: 2.205032, Accuracy: 19.50%\n",
            "Epoch: 23, Step: 59/655, Loss: 2.205414, Accuracy: 19.44%\n",
            "Epoch: 23, Step: 60/655, Loss: 2.206368, Accuracy: 19.38%\n",
            "Epoch: 23, Step: 61/655, Loss: 2.204685, Accuracy: 19.26%\n",
            "Epoch: 23, Step: 62/655, Loss: 2.204577, Accuracy: 19.25%\n",
            "Epoch: 23, Step: 63/655, Loss: 2.205034, Accuracy: 19.10%\n",
            "Epoch: 23, Step: 64/655, Loss: 2.202239, Accuracy: 19.14%\n",
            "Epoch: 23, Step: 65/655, Loss: 2.204953, Accuracy: 18.99%\n",
            "Epoch: 23, Step: 66/655, Loss: 2.203164, Accuracy: 18.94%\n",
            "Epoch: 23, Step: 67/655, Loss: 2.202729, Accuracy: 18.84%\n",
            "Epoch: 23, Step: 68/655, Loss: 2.202362, Accuracy: 18.80%\n",
            "Epoch: 23, Step: 69/655, Loss: 2.201767, Accuracy: 18.89%\n",
            "Epoch: 23, Step: 70/655, Loss: 2.201975, Accuracy: 18.93%\n",
            "Epoch: 23, Step: 71/655, Loss: 2.201576, Accuracy: 18.97%\n",
            "Epoch: 23, Step: 72/655, Loss: 2.201632, Accuracy: 18.79%\n",
            "Epoch: 23, Step: 73/655, Loss: 2.201465, Accuracy: 18.79%\n",
            "Epoch: 23, Step: 74/655, Loss: 2.201829, Accuracy: 18.92%\n",
            "Epoch: 23, Step: 75/655, Loss: 2.201216, Accuracy: 19.00%\n",
            "Epoch: 23, Step: 76/655, Loss: 2.202462, Accuracy: 18.87%\n",
            "Epoch: 23, Step: 77/655, Loss: 2.201078, Accuracy: 18.99%\n",
            "Epoch: 23, Step: 78/655, Loss: 2.201921, Accuracy: 18.95%\n",
            "Epoch: 23, Step: 79/655, Loss: 2.201453, Accuracy: 19.07%\n",
            "Epoch: 23, Step: 80/655, Loss: 2.201716, Accuracy: 18.87%\n",
            "Epoch: 23, Step: 81/655, Loss: 2.202832, Accuracy: 18.79%\n",
            "Epoch: 23, Step: 82/655, Loss: 2.203342, Accuracy: 18.90%\n",
            "Epoch: 23, Step: 83/655, Loss: 2.203681, Accuracy: 18.86%\n",
            "Epoch: 23, Step: 84/655, Loss: 2.204159, Accuracy: 18.86%\n",
            "Epoch: 23, Step: 85/655, Loss: 2.204404, Accuracy: 18.82%\n",
            "Epoch: 23, Step: 86/655, Loss: 2.204287, Accuracy: 18.82%\n",
            "Epoch: 23, Step: 87/655, Loss: 2.204346, Accuracy: 18.82%\n",
            "Epoch: 23, Step: 88/655, Loss: 2.204076, Accuracy: 18.82%\n",
            "Epoch: 23, Step: 89/655, Loss: 2.203616, Accuracy: 18.79%\n",
            "Epoch: 23, Step: 90/655, Loss: 2.202114, Accuracy: 18.92%\n",
            "Epoch: 23, Step: 91/655, Loss: 2.202488, Accuracy: 18.85%\n",
            "Epoch: 23, Step: 92/655, Loss: 2.201878, Accuracy: 18.89%\n",
            "Epoch: 23, Step: 93/655, Loss: 2.201907, Accuracy: 18.95%\n",
            "Epoch: 23, Step: 94/655, Loss: 2.201596, Accuracy: 18.98%\n",
            "Epoch: 23, Step: 95/655, Loss: 2.202730, Accuracy: 18.95%\n",
            "Epoch: 23, Step: 96/655, Loss: 2.202670, Accuracy: 19.01%\n",
            "Epoch: 23, Step: 97/655, Loss: 2.204554, Accuracy: 18.94%\n",
            "Epoch: 23, Step: 98/655, Loss: 2.203228, Accuracy: 19.01%\n",
            "Epoch: 23, Step: 99/655, Loss: 2.202378, Accuracy: 18.88%\n",
            "Epoch: 23, Step: 100/655, Loss: 2.202747, Accuracy: 18.84%\n",
            "Epoch: 23, Step: 101/655, Loss: 2.202286, Accuracy: 18.78%\n",
            "Epoch: 23, Step: 102/655, Loss: 2.200839, Accuracy: 18.81%\n",
            "Epoch: 23, Step: 103/655, Loss: 2.201896, Accuracy: 18.81%\n",
            "Epoch: 23, Step: 104/655, Loss: 2.202107, Accuracy: 18.78%\n",
            "Epoch: 23, Step: 105/655, Loss: 2.201776, Accuracy: 18.78%\n",
            "Epoch: 23, Step: 106/655, Loss: 2.200739, Accuracy: 18.78%\n",
            "Epoch: 23, Step: 107/655, Loss: 2.201245, Accuracy: 18.75%\n",
            "Epoch: 23, Step: 108/655, Loss: 2.202027, Accuracy: 18.69%\n",
            "Epoch: 23, Step: 109/655, Loss: 2.201186, Accuracy: 18.75%\n",
            "Epoch: 23, Step: 110/655, Loss: 2.201929, Accuracy: 18.69%\n",
            "Epoch: 23, Step: 111/655, Loss: 2.202070, Accuracy: 18.69%\n",
            "Epoch: 23, Step: 112/655, Loss: 2.203438, Accuracy: 18.69%\n",
            "Epoch: 23, Step: 113/655, Loss: 2.203487, Accuracy: 18.64%\n",
            "Epoch: 23, Step: 114/655, Loss: 2.204996, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 115/655, Loss: 2.205618, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 116/655, Loss: 2.205823, Accuracy: 18.56%\n",
            "Epoch: 23, Step: 117/655, Loss: 2.205896, Accuracy: 18.64%\n",
            "Epoch: 23, Step: 118/655, Loss: 2.205407, Accuracy: 18.72%\n",
            "Epoch: 23, Step: 119/655, Loss: 2.205166, Accuracy: 18.75%\n",
            "Epoch: 23, Step: 120/655, Loss: 2.205233, Accuracy: 18.75%\n",
            "Epoch: 23, Step: 121/655, Loss: 2.205561, Accuracy: 18.70%\n",
            "Epoch: 23, Step: 122/655, Loss: 2.205072, Accuracy: 18.72%\n",
            "Epoch: 23, Step: 123/655, Loss: 2.206383, Accuracy: 18.62%\n",
            "Epoch: 23, Step: 124/655, Loss: 2.205665, Accuracy: 18.62%\n",
            "Epoch: 23, Step: 125/655, Loss: 2.206550, Accuracy: 18.60%\n",
            "Epoch: 23, Step: 126/655, Loss: 2.205796, Accuracy: 18.60%\n",
            "Epoch: 23, Step: 127/655, Loss: 2.206043, Accuracy: 18.63%\n",
            "Epoch: 23, Step: 128/655, Loss: 2.206407, Accuracy: 18.68%\n",
            "Epoch: 23, Step: 129/655, Loss: 2.207272, Accuracy: 18.60%\n",
            "Epoch: 23, Step: 130/655, Loss: 2.207367, Accuracy: 18.56%\n",
            "Epoch: 23, Step: 131/655, Loss: 2.207651, Accuracy: 18.68%\n",
            "Epoch: 23, Step: 132/655, Loss: 2.207379, Accuracy: 18.58%\n",
            "Epoch: 23, Step: 133/655, Loss: 2.208423, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 134/655, Loss: 2.207572, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 135/655, Loss: 2.207578, Accuracy: 18.45%\n",
            "Epoch: 23, Step: 136/655, Loss: 2.208339, Accuracy: 18.38%\n",
            "Epoch: 23, Step: 137/655, Loss: 2.208292, Accuracy: 18.36%\n",
            "Epoch: 23, Step: 138/655, Loss: 2.208105, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 139/655, Loss: 2.207995, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 140/655, Loss: 2.206907, Accuracy: 18.59%\n",
            "Epoch: 23, Step: 141/655, Loss: 2.206611, Accuracy: 18.57%\n",
            "Epoch: 23, Step: 142/655, Loss: 2.206531, Accuracy: 18.60%\n",
            "Epoch: 23, Step: 143/655, Loss: 2.206515, Accuracy: 18.62%\n",
            "Epoch: 23, Step: 144/655, Loss: 2.206880, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 145/655, Loss: 2.207857, Accuracy: 18.56%\n",
            "Epoch: 23, Step: 146/655, Loss: 2.209276, Accuracy: 18.43%\n",
            "Epoch: 23, Step: 147/655, Loss: 2.209666, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 148/655, Loss: 2.208264, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 149/655, Loss: 2.208032, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 150/655, Loss: 2.207263, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 151/655, Loss: 2.207568, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 152/655, Loss: 2.207540, Accuracy: 18.56%\n",
            "Epoch: 23, Step: 153/655, Loss: 2.207409, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 154/655, Loss: 2.207274, Accuracy: 18.57%\n",
            "Epoch: 23, Step: 155/655, Loss: 2.207253, Accuracy: 18.57%\n",
            "Epoch: 23, Step: 156/655, Loss: 2.207631, Accuracy: 18.59%\n",
            "Epoch: 23, Step: 157/655, Loss: 2.207535, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 158/655, Loss: 2.207671, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 159/655, Loss: 2.207984, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 160/655, Loss: 2.207172, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 161/655, Loss: 2.207938, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 162/655, Loss: 2.207250, Accuracy: 18.42%\n",
            "Epoch: 23, Step: 163/655, Loss: 2.207288, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 164/655, Loss: 2.207559, Accuracy: 18.37%\n",
            "Epoch: 23, Step: 165/655, Loss: 2.207104, Accuracy: 18.30%\n",
            "Epoch: 23, Step: 166/655, Loss: 2.206439, Accuracy: 18.28%\n",
            "Epoch: 23, Step: 167/655, Loss: 2.206504, Accuracy: 18.26%\n",
            "Epoch: 23, Step: 168/655, Loss: 2.206017, Accuracy: 18.25%\n",
            "Epoch: 23, Step: 169/655, Loss: 2.205929, Accuracy: 18.23%\n",
            "Epoch: 23, Step: 170/655, Loss: 2.205675, Accuracy: 18.16%\n",
            "Epoch: 23, Step: 171/655, Loss: 2.205642, Accuracy: 18.13%\n",
            "Epoch: 23, Step: 172/655, Loss: 2.205292, Accuracy: 18.11%\n",
            "Epoch: 23, Step: 173/655, Loss: 2.205636, Accuracy: 18.06%\n",
            "Epoch: 23, Step: 174/655, Loss: 2.205571, Accuracy: 18.03%\n",
            "Epoch: 23, Step: 175/655, Loss: 2.205670, Accuracy: 18.02%\n",
            "Epoch: 23, Step: 176/655, Loss: 2.205871, Accuracy: 18.04%\n",
            "Epoch: 23, Step: 177/655, Loss: 2.206220, Accuracy: 17.99%\n",
            "Epoch: 23, Step: 178/655, Loss: 2.206748, Accuracy: 17.94%\n",
            "Epoch: 23, Step: 179/655, Loss: 2.206525, Accuracy: 17.96%\n",
            "Epoch: 23, Step: 180/655, Loss: 2.206109, Accuracy: 17.99%\n",
            "Epoch: 23, Step: 181/655, Loss: 2.206638, Accuracy: 17.97%\n",
            "Epoch: 23, Step: 182/655, Loss: 2.206144, Accuracy: 18.05%\n",
            "Epoch: 23, Step: 183/655, Loss: 2.205892, Accuracy: 18.05%\n",
            "Epoch: 23, Step: 184/655, Loss: 2.206440, Accuracy: 18.05%\n",
            "Epoch: 23, Step: 185/655, Loss: 2.206583, Accuracy: 18.09%\n",
            "Epoch: 23, Step: 186/655, Loss: 2.206839, Accuracy: 18.04%\n",
            "Epoch: 23, Step: 187/655, Loss: 2.205993, Accuracy: 18.06%\n",
            "Epoch: 23, Step: 188/655, Loss: 2.204880, Accuracy: 18.13%\n",
            "Epoch: 23, Step: 189/655, Loss: 2.205092, Accuracy: 18.17%\n",
            "Epoch: 23, Step: 190/655, Loss: 2.204698, Accuracy: 18.22%\n",
            "Epoch: 23, Step: 191/655, Loss: 2.204824, Accuracy: 18.23%\n",
            "Epoch: 23, Step: 192/655, Loss: 2.204313, Accuracy: 18.23%\n",
            "Epoch: 23, Step: 193/655, Loss: 2.204216, Accuracy: 18.23%\n",
            "Epoch: 23, Step: 194/655, Loss: 2.204243, Accuracy: 18.25%\n",
            "Epoch: 23, Step: 195/655, Loss: 2.204159, Accuracy: 18.30%\n",
            "Epoch: 23, Step: 196/655, Loss: 2.204527, Accuracy: 18.27%\n",
            "Epoch: 23, Step: 197/655, Loss: 2.205025, Accuracy: 18.26%\n",
            "Epoch: 23, Step: 198/655, Loss: 2.204724, Accuracy: 18.31%\n",
            "Epoch: 23, Step: 199/655, Loss: 2.204662, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 200/655, Loss: 2.204783, Accuracy: 18.28%\n",
            "Epoch: 23, Step: 201/655, Loss: 2.204840, Accuracy: 18.27%\n",
            "Epoch: 23, Step: 202/655, Loss: 2.204765, Accuracy: 18.27%\n",
            "Epoch: 23, Step: 203/655, Loss: 2.204350, Accuracy: 18.30%\n",
            "Epoch: 23, Step: 204/655, Loss: 2.204359, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 205/655, Loss: 2.203773, Accuracy: 18.37%\n",
            "Epoch: 23, Step: 206/655, Loss: 2.204145, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 207/655, Loss: 2.203573, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 208/655, Loss: 2.203641, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 209/655, Loss: 2.204119, Accuracy: 18.41%\n",
            "Epoch: 23, Step: 210/655, Loss: 2.203955, Accuracy: 18.44%\n",
            "Epoch: 23, Step: 211/655, Loss: 2.203110, Accuracy: 18.44%\n",
            "Epoch: 23, Step: 212/655, Loss: 2.203289, Accuracy: 18.43%\n",
            "Epoch: 23, Step: 213/655, Loss: 2.203616, Accuracy: 18.38%\n",
            "Epoch: 23, Step: 214/655, Loss: 2.204009, Accuracy: 18.37%\n",
            "Epoch: 23, Step: 215/655, Loss: 2.204012, Accuracy: 18.36%\n",
            "Epoch: 23, Step: 216/655, Loss: 2.203331, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 217/655, Loss: 2.203469, Accuracy: 18.42%\n",
            "Epoch: 23, Step: 218/655, Loss: 2.203090, Accuracy: 18.45%\n",
            "Epoch: 23, Step: 219/655, Loss: 2.203675, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 220/655, Loss: 2.203583, Accuracy: 18.47%\n",
            "Epoch: 23, Step: 221/655, Loss: 2.203521, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 222/655, Loss: 2.203681, Accuracy: 18.45%\n",
            "Epoch: 23, Step: 223/655, Loss: 2.203624, Accuracy: 18.41%\n",
            "Epoch: 23, Step: 224/655, Loss: 2.203246, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 225/655, Loss: 2.203133, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 226/655, Loss: 2.202529, Accuracy: 18.42%\n",
            "Epoch: 23, Step: 227/655, Loss: 2.202804, Accuracy: 18.43%\n",
            "Epoch: 23, Step: 228/655, Loss: 2.203151, Accuracy: 18.42%\n",
            "Epoch: 23, Step: 229/655, Loss: 2.203332, Accuracy: 18.37%\n",
            "Epoch: 23, Step: 230/655, Loss: 2.204189, Accuracy: 18.33%\n",
            "Epoch: 23, Step: 231/655, Loss: 2.204370, Accuracy: 18.33%\n",
            "Epoch: 23, Step: 232/655, Loss: 2.204397, Accuracy: 18.32%\n",
            "Epoch: 23, Step: 233/655, Loss: 2.205076, Accuracy: 18.27%\n",
            "Epoch: 23, Step: 234/655, Loss: 2.205462, Accuracy: 18.26%\n",
            "Epoch: 23, Step: 235/655, Loss: 2.205425, Accuracy: 18.28%\n",
            "Epoch: 23, Step: 236/655, Loss: 2.206063, Accuracy: 18.29%\n",
            "Epoch: 23, Step: 237/655, Loss: 2.206116, Accuracy: 18.26%\n",
            "Epoch: 23, Step: 238/655, Loss: 2.206412, Accuracy: 18.21%\n",
            "Epoch: 23, Step: 239/655, Loss: 2.206635, Accuracy: 18.25%\n",
            "Epoch: 23, Step: 240/655, Loss: 2.206050, Accuracy: 18.27%\n",
            "Epoch: 23, Step: 241/655, Loss: 2.205865, Accuracy: 18.30%\n",
            "Epoch: 23, Step: 242/655, Loss: 2.205861, Accuracy: 18.29%\n",
            "Epoch: 23, Step: 243/655, Loss: 2.205519, Accuracy: 18.33%\n",
            "Epoch: 23, Step: 244/655, Loss: 2.205664, Accuracy: 18.35%\n",
            "Epoch: 23, Step: 245/655, Loss: 2.205625, Accuracy: 18.37%\n",
            "Epoch: 23, Step: 246/655, Loss: 2.205981, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 247/655, Loss: 2.206023, Accuracy: 18.31%\n",
            "Epoch: 23, Step: 248/655, Loss: 2.205652, Accuracy: 18.32%\n",
            "Epoch: 23, Step: 249/655, Loss: 2.205553, Accuracy: 18.35%\n",
            "Epoch: 23, Step: 250/655, Loss: 2.205175, Accuracy: 18.35%\n",
            "Epoch: 23, Step: 251/655, Loss: 2.204956, Accuracy: 18.38%\n",
            "Epoch: 23, Step: 252/655, Loss: 2.205073, Accuracy: 18.38%\n",
            "Epoch: 23, Step: 253/655, Loss: 2.206125, Accuracy: 18.33%\n",
            "Epoch: 23, Step: 254/655, Loss: 2.205635, Accuracy: 18.36%\n",
            "Epoch: 23, Step: 255/655, Loss: 2.205676, Accuracy: 18.36%\n",
            "Epoch: 23, Step: 256/655, Loss: 2.205314, Accuracy: 18.38%\n",
            "Epoch: 23, Step: 257/655, Loss: 2.205633, Accuracy: 18.41%\n",
            "Epoch: 23, Step: 258/655, Loss: 2.204998, Accuracy: 18.45%\n",
            "Epoch: 23, Step: 259/655, Loss: 2.205222, Accuracy: 18.41%\n",
            "Epoch: 23, Step: 260/655, Loss: 2.205767, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 261/655, Loss: 2.205631, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 262/655, Loss: 2.205158, Accuracy: 18.44%\n",
            "Epoch: 23, Step: 263/655, Loss: 2.205731, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 264/655, Loss: 2.205968, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 265/655, Loss: 2.206008, Accuracy: 18.38%\n",
            "Epoch: 23, Step: 266/655, Loss: 2.205820, Accuracy: 18.37%\n",
            "Epoch: 23, Step: 267/655, Loss: 2.206388, Accuracy: 18.36%\n",
            "Epoch: 23, Step: 268/655, Loss: 2.207031, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 269/655, Loss: 2.206852, Accuracy: 18.37%\n",
            "Epoch: 23, Step: 270/655, Loss: 2.206741, Accuracy: 18.36%\n",
            "Epoch: 23, Step: 271/655, Loss: 2.206668, Accuracy: 18.35%\n",
            "Epoch: 23, Step: 272/655, Loss: 2.207159, Accuracy: 18.31%\n",
            "Epoch: 23, Step: 273/655, Loss: 2.207001, Accuracy: 18.32%\n",
            "Epoch: 23, Step: 274/655, Loss: 2.206827, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 275/655, Loss: 2.206832, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 276/655, Loss: 2.206896, Accuracy: 18.37%\n",
            "Epoch: 23, Step: 277/655, Loss: 2.206882, Accuracy: 18.37%\n",
            "Epoch: 23, Step: 278/655, Loss: 2.207024, Accuracy: 18.37%\n",
            "Epoch: 23, Step: 279/655, Loss: 2.207381, Accuracy: 18.32%\n",
            "Epoch: 23, Step: 280/655, Loss: 2.207413, Accuracy: 18.31%\n",
            "Epoch: 23, Step: 281/655, Loss: 2.207648, Accuracy: 18.27%\n",
            "Epoch: 23, Step: 282/655, Loss: 2.207387, Accuracy: 18.32%\n",
            "Epoch: 23, Step: 283/655, Loss: 2.207336, Accuracy: 18.35%\n",
            "Epoch: 23, Step: 284/655, Loss: 2.207151, Accuracy: 18.31%\n",
            "Epoch: 23, Step: 285/655, Loss: 2.207006, Accuracy: 18.31%\n",
            "Epoch: 23, Step: 286/655, Loss: 2.207223, Accuracy: 18.30%\n",
            "Epoch: 23, Step: 287/655, Loss: 2.206999, Accuracy: 18.31%\n",
            "Epoch: 23, Step: 288/655, Loss: 2.207252, Accuracy: 18.32%\n",
            "Epoch: 23, Step: 289/655, Loss: 2.207418, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 290/655, Loss: 2.207507, Accuracy: 18.33%\n",
            "Epoch: 23, Step: 291/655, Loss: 2.207887, Accuracy: 18.35%\n",
            "Epoch: 23, Step: 292/655, Loss: 2.208171, Accuracy: 18.31%\n",
            "Epoch: 23, Step: 293/655, Loss: 2.208479, Accuracy: 18.31%\n",
            "Epoch: 23, Step: 294/655, Loss: 2.208532, Accuracy: 18.31%\n",
            "Epoch: 23, Step: 295/655, Loss: 2.208501, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 296/655, Loss: 2.208363, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 297/655, Loss: 2.208625, Accuracy: 18.33%\n",
            "Epoch: 23, Step: 298/655, Loss: 2.208700, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 299/655, Loss: 2.208659, Accuracy: 18.35%\n",
            "Epoch: 23, Step: 300/655, Loss: 2.209313, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 301/655, Loss: 2.209190, Accuracy: 18.36%\n",
            "Epoch: 23, Step: 302/655, Loss: 2.209375, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 303/655, Loss: 2.209519, Accuracy: 18.32%\n",
            "Epoch: 23, Step: 304/655, Loss: 2.209891, Accuracy: 18.29%\n",
            "Epoch: 23, Step: 305/655, Loss: 2.209677, Accuracy: 18.33%\n",
            "Epoch: 23, Step: 306/655, Loss: 2.209848, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 307/655, Loss: 2.210051, Accuracy: 18.32%\n",
            "Epoch: 23, Step: 308/655, Loss: 2.209999, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 309/655, Loss: 2.209563, Accuracy: 18.38%\n",
            "Epoch: 23, Step: 310/655, Loss: 2.209658, Accuracy: 18.38%\n",
            "Epoch: 23, Step: 311/655, Loss: 2.209955, Accuracy: 18.36%\n",
            "Epoch: 23, Step: 312/655, Loss: 2.210019, Accuracy: 18.36%\n",
            "Epoch: 23, Step: 313/655, Loss: 2.209788, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 314/655, Loss: 2.209792, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 315/655, Loss: 2.209804, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 316/655, Loss: 2.210123, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 317/655, Loss: 2.210199, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 318/655, Loss: 2.210145, Accuracy: 18.36%\n",
            "Epoch: 23, Step: 319/655, Loss: 2.209794, Accuracy: 18.38%\n",
            "Epoch: 23, Step: 320/655, Loss: 2.209818, Accuracy: 18.35%\n",
            "Epoch: 23, Step: 321/655, Loss: 2.209798, Accuracy: 18.38%\n",
            "Epoch: 23, Step: 322/655, Loss: 2.209468, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 323/655, Loss: 2.209724, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 324/655, Loss: 2.209794, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 325/655, Loss: 2.209555, Accuracy: 18.43%\n",
            "Epoch: 23, Step: 326/655, Loss: 2.209879, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 327/655, Loss: 2.209880, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 328/655, Loss: 2.209853, Accuracy: 18.41%\n",
            "Epoch: 23, Step: 329/655, Loss: 2.209822, Accuracy: 18.41%\n",
            "Epoch: 23, Step: 330/655, Loss: 2.209941, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 331/655, Loss: 2.210486, Accuracy: 18.37%\n",
            "Epoch: 23, Step: 332/655, Loss: 2.210683, Accuracy: 18.37%\n",
            "Epoch: 23, Step: 333/655, Loss: 2.210209, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 334/655, Loss: 2.210508, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 335/655, Loss: 2.210881, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 336/655, Loss: 2.210923, Accuracy: 18.41%\n",
            "Epoch: 23, Step: 337/655, Loss: 2.210770, Accuracy: 18.43%\n",
            "Epoch: 23, Step: 338/655, Loss: 2.210784, Accuracy: 18.44%\n",
            "Epoch: 23, Step: 339/655, Loss: 2.210924, Accuracy: 18.41%\n",
            "Epoch: 23, Step: 340/655, Loss: 2.211444, Accuracy: 18.38%\n",
            "Epoch: 23, Step: 341/655, Loss: 2.211486, Accuracy: 18.37%\n",
            "Epoch: 23, Step: 342/655, Loss: 2.211622, Accuracy: 18.36%\n",
            "Epoch: 23, Step: 343/655, Loss: 2.211608, Accuracy: 18.36%\n",
            "Epoch: 23, Step: 344/655, Loss: 2.211358, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 345/655, Loss: 2.211379, Accuracy: 18.33%\n",
            "Epoch: 23, Step: 346/655, Loss: 2.211636, Accuracy: 18.32%\n",
            "Epoch: 23, Step: 347/655, Loss: 2.211525, Accuracy: 18.31%\n",
            "Epoch: 23, Step: 348/655, Loss: 2.211342, Accuracy: 18.33%\n",
            "Epoch: 23, Step: 349/655, Loss: 2.211116, Accuracy: 18.34%\n",
            "Epoch: 23, Step: 350/655, Loss: 2.211472, Accuracy: 18.31%\n",
            "Epoch: 23, Step: 351/655, Loss: 2.211525, Accuracy: 18.29%\n",
            "Epoch: 23, Step: 352/655, Loss: 2.211955, Accuracy: 18.28%\n",
            "Epoch: 23, Step: 353/655, Loss: 2.212059, Accuracy: 18.27%\n",
            "Epoch: 23, Step: 354/655, Loss: 2.212323, Accuracy: 18.25%\n",
            "Epoch: 23, Step: 355/655, Loss: 2.212105, Accuracy: 18.25%\n",
            "Epoch: 23, Step: 356/655, Loss: 2.212131, Accuracy: 18.26%\n",
            "Epoch: 23, Step: 357/655, Loss: 2.212174, Accuracy: 18.26%\n",
            "Epoch: 23, Step: 358/655, Loss: 2.212172, Accuracy: 18.25%\n",
            "Epoch: 23, Step: 359/655, Loss: 2.212221, Accuracy: 18.25%\n",
            "Epoch: 23, Step: 360/655, Loss: 2.211792, Accuracy: 18.28%\n",
            "Epoch: 23, Step: 361/655, Loss: 2.211557, Accuracy: 18.27%\n",
            "Epoch: 23, Step: 362/655, Loss: 2.211301, Accuracy: 18.28%\n",
            "Epoch: 23, Step: 363/655, Loss: 2.211458, Accuracy: 18.28%\n",
            "Epoch: 23, Step: 364/655, Loss: 2.211416, Accuracy: 18.29%\n",
            "Epoch: 23, Step: 365/655, Loss: 2.211433, Accuracy: 18.30%\n",
            "Epoch: 23, Step: 366/655, Loss: 2.211392, Accuracy: 18.31%\n",
            "Epoch: 23, Step: 367/655, Loss: 2.211482, Accuracy: 18.31%\n",
            "Epoch: 23, Step: 368/655, Loss: 2.211448, Accuracy: 18.30%\n",
            "Epoch: 23, Step: 369/655, Loss: 2.211798, Accuracy: 18.29%\n",
            "Epoch: 23, Step: 370/655, Loss: 2.211930, Accuracy: 18.29%\n",
            "Epoch: 23, Step: 371/655, Loss: 2.212343, Accuracy: 18.24%\n",
            "Epoch: 23, Step: 372/655, Loss: 2.212728, Accuracy: 18.23%\n",
            "Epoch: 23, Step: 373/655, Loss: 2.212817, Accuracy: 18.23%\n",
            "Epoch: 23, Step: 374/655, Loss: 2.212809, Accuracy: 18.24%\n",
            "Epoch: 23, Step: 375/655, Loss: 2.212844, Accuracy: 18.23%\n",
            "Epoch: 23, Step: 376/655, Loss: 2.212669, Accuracy: 18.23%\n",
            "Epoch: 23, Step: 377/655, Loss: 2.212876, Accuracy: 18.24%\n",
            "Epoch: 23, Step: 378/655, Loss: 2.212583, Accuracy: 18.25%\n",
            "Epoch: 23, Step: 379/655, Loss: 2.212672, Accuracy: 18.28%\n",
            "Epoch: 23, Step: 380/655, Loss: 2.212646, Accuracy: 18.28%\n",
            "Epoch: 23, Step: 381/655, Loss: 2.212671, Accuracy: 18.28%\n",
            "Epoch: 23, Step: 382/655, Loss: 2.212947, Accuracy: 18.28%\n",
            "Epoch: 23, Step: 383/655, Loss: 2.213364, Accuracy: 18.26%\n",
            "Epoch: 23, Step: 384/655, Loss: 2.213260, Accuracy: 18.29%\n",
            "Epoch: 23, Step: 385/655, Loss: 2.213058, Accuracy: 18.28%\n",
            "Epoch: 23, Step: 386/655, Loss: 2.212776, Accuracy: 18.30%\n",
            "Epoch: 23, Step: 387/655, Loss: 2.212564, Accuracy: 18.31%\n",
            "Epoch: 23, Step: 388/655, Loss: 2.212210, Accuracy: 18.35%\n",
            "Epoch: 23, Step: 389/655, Loss: 2.212326, Accuracy: 18.35%\n",
            "Epoch: 23, Step: 390/655, Loss: 2.212423, Accuracy: 18.36%\n",
            "Epoch: 23, Step: 391/655, Loss: 2.212540, Accuracy: 18.37%\n",
            "Epoch: 23, Step: 392/655, Loss: 2.212367, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 393/655, Loss: 2.212445, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 394/655, Loss: 2.212651, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 395/655, Loss: 2.212551, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 396/655, Loss: 2.212661, Accuracy: 18.38%\n",
            "Epoch: 23, Step: 397/655, Loss: 2.212243, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 398/655, Loss: 2.212482, Accuracy: 18.37%\n",
            "Epoch: 23, Step: 399/655, Loss: 2.212081, Accuracy: 18.43%\n",
            "Epoch: 23, Step: 400/655, Loss: 2.212278, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 401/655, Loss: 2.212333, Accuracy: 18.39%\n",
            "Epoch: 23, Step: 402/655, Loss: 2.212176, Accuracy: 18.40%\n",
            "Epoch: 23, Step: 403/655, Loss: 2.211929, Accuracy: 18.42%\n",
            "Epoch: 23, Step: 404/655, Loss: 2.211523, Accuracy: 18.47%\n",
            "Epoch: 23, Step: 405/655, Loss: 2.211223, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 406/655, Loss: 2.211141, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 407/655, Loss: 2.210996, Accuracy: 18.47%\n",
            "Epoch: 23, Step: 408/655, Loss: 2.210673, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 409/655, Loss: 2.210581, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 410/655, Loss: 2.210791, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 411/655, Loss: 2.210926, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 412/655, Loss: 2.210593, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 413/655, Loss: 2.210572, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 414/655, Loss: 2.210307, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 415/655, Loss: 2.210022, Accuracy: 18.58%\n",
            "Epoch: 23, Step: 416/655, Loss: 2.209936, Accuracy: 18.58%\n",
            "Epoch: 23, Step: 417/655, Loss: 2.209714, Accuracy: 18.60%\n",
            "Epoch: 23, Step: 418/655, Loss: 2.209880, Accuracy: 18.59%\n",
            "Epoch: 23, Step: 419/655, Loss: 2.209773, Accuracy: 18.60%\n",
            "Epoch: 23, Step: 420/655, Loss: 2.209995, Accuracy: 18.57%\n",
            "Epoch: 23, Step: 421/655, Loss: 2.210072, Accuracy: 18.56%\n",
            "Epoch: 23, Step: 422/655, Loss: 2.210241, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 423/655, Loss: 2.210148, Accuracy: 18.56%\n",
            "Epoch: 23, Step: 424/655, Loss: 2.210131, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 425/655, Loss: 2.210208, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 426/655, Loss: 2.210000, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 427/655, Loss: 2.210049, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 428/655, Loss: 2.210056, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 429/655, Loss: 2.209726, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 430/655, Loss: 2.209452, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 431/655, Loss: 2.209425, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 432/655, Loss: 2.209451, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 433/655, Loss: 2.209507, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 434/655, Loss: 2.209636, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 435/655, Loss: 2.209491, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 436/655, Loss: 2.209514, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 437/655, Loss: 2.209417, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 438/655, Loss: 2.209545, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 439/655, Loss: 2.209601, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 440/655, Loss: 2.209531, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 441/655, Loss: 2.209740, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 442/655, Loss: 2.209999, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 443/655, Loss: 2.209986, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 444/655, Loss: 2.209918, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 445/655, Loss: 2.210192, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 446/655, Loss: 2.210211, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 447/655, Loss: 2.210172, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 448/655, Loss: 2.210056, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 449/655, Loss: 2.209922, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 450/655, Loss: 2.209720, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 451/655, Loss: 2.209806, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 452/655, Loss: 2.209883, Accuracy: 18.47%\n",
            "Epoch: 23, Step: 453/655, Loss: 2.209754, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 454/655, Loss: 2.209871, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 455/655, Loss: 2.209873, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 456/655, Loss: 2.209770, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 457/655, Loss: 2.209576, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 458/655, Loss: 2.209567, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 459/655, Loss: 2.209295, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 460/655, Loss: 2.209197, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 461/655, Loss: 2.209315, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 462/655, Loss: 2.209090, Accuracy: 18.56%\n",
            "Epoch: 23, Step: 463/655, Loss: 2.209096, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 464/655, Loss: 2.209302, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 465/655, Loss: 2.209025, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 466/655, Loss: 2.208859, Accuracy: 18.58%\n",
            "Epoch: 23, Step: 467/655, Loss: 2.208746, Accuracy: 18.58%\n",
            "Epoch: 23, Step: 468/655, Loss: 2.208929, Accuracy: 18.56%\n",
            "Epoch: 23, Step: 469/655, Loss: 2.209053, Accuracy: 18.56%\n",
            "Epoch: 23, Step: 470/655, Loss: 2.208853, Accuracy: 18.56%\n",
            "Epoch: 23, Step: 471/655, Loss: 2.208600, Accuracy: 18.58%\n",
            "Epoch: 23, Step: 472/655, Loss: 2.208525, Accuracy: 18.58%\n",
            "Epoch: 23, Step: 473/655, Loss: 2.208691, Accuracy: 18.58%\n",
            "Epoch: 23, Step: 474/655, Loss: 2.208518, Accuracy: 18.59%\n",
            "Epoch: 23, Step: 475/655, Loss: 2.208516, Accuracy: 18.61%\n",
            "Epoch: 23, Step: 476/655, Loss: 2.208551, Accuracy: 18.61%\n",
            "Epoch: 23, Step: 477/655, Loss: 2.208405, Accuracy: 18.63%\n",
            "Epoch: 23, Step: 478/655, Loss: 2.208969, Accuracy: 18.59%\n",
            "Epoch: 23, Step: 479/655, Loss: 2.208654, Accuracy: 18.61%\n",
            "Epoch: 23, Step: 480/655, Loss: 2.208504, Accuracy: 18.63%\n",
            "Epoch: 23, Step: 481/655, Loss: 2.208512, Accuracy: 18.61%\n",
            "Epoch: 23, Step: 482/655, Loss: 2.208168, Accuracy: 18.64%\n",
            "Epoch: 23, Step: 483/655, Loss: 2.208180, Accuracy: 18.61%\n",
            "Epoch: 23, Step: 484/655, Loss: 2.208032, Accuracy: 18.63%\n",
            "Epoch: 23, Step: 485/655, Loss: 2.208138, Accuracy: 18.61%\n",
            "Epoch: 23, Step: 486/655, Loss: 2.208094, Accuracy: 18.61%\n",
            "Epoch: 23, Step: 487/655, Loss: 2.208333, Accuracy: 18.61%\n",
            "Epoch: 23, Step: 488/655, Loss: 2.208374, Accuracy: 18.60%\n",
            "Epoch: 23, Step: 489/655, Loss: 2.208580, Accuracy: 18.60%\n",
            "Epoch: 23, Step: 490/655, Loss: 2.208579, Accuracy: 18.58%\n",
            "Epoch: 23, Step: 491/655, Loss: 2.208677, Accuracy: 18.57%\n",
            "Epoch: 23, Step: 492/655, Loss: 2.208756, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 493/655, Loss: 2.208702, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 494/655, Loss: 2.208530, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 495/655, Loss: 2.208245, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 496/655, Loss: 2.208466, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 497/655, Loss: 2.208488, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 498/655, Loss: 2.208411, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 499/655, Loss: 2.208116, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 500/655, Loss: 2.208048, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 501/655, Loss: 2.208008, Accuracy: 18.56%\n",
            "Epoch: 23, Step: 502/655, Loss: 2.208045, Accuracy: 18.56%\n",
            "Epoch: 23, Step: 503/655, Loss: 2.208030, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 504/655, Loss: 2.208064, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 505/655, Loss: 2.208285, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 506/655, Loss: 2.208205, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 507/655, Loss: 2.208454, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 508/655, Loss: 2.208202, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 509/655, Loss: 2.207943, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 510/655, Loss: 2.207841, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 511/655, Loss: 2.207941, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 512/655, Loss: 2.208132, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 513/655, Loss: 2.208031, Accuracy: 18.54%\n",
            "Epoch: 23, Step: 514/655, Loss: 2.207873, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 515/655, Loss: 2.207917, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 516/655, Loss: 2.208104, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 517/655, Loss: 2.208096, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 518/655, Loss: 2.207965, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 519/655, Loss: 2.207780, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 520/655, Loss: 2.208100, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 521/655, Loss: 2.208283, Accuracy: 18.47%\n",
            "Epoch: 23, Step: 522/655, Loss: 2.208150, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 523/655, Loss: 2.208250, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 524/655, Loss: 2.208282, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 525/655, Loss: 2.208498, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 526/655, Loss: 2.208564, Accuracy: 18.45%\n",
            "Epoch: 23, Step: 527/655, Loss: 2.208656, Accuracy: 18.45%\n",
            "Epoch: 23, Step: 528/655, Loss: 2.209025, Accuracy: 18.44%\n",
            "Epoch: 23, Step: 529/655, Loss: 2.208858, Accuracy: 18.45%\n",
            "Epoch: 23, Step: 530/655, Loss: 2.208701, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 531/655, Loss: 2.208974, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 532/655, Loss: 2.208996, Accuracy: 18.47%\n",
            "Epoch: 23, Step: 533/655, Loss: 2.208800, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 534/655, Loss: 2.208829, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 535/655, Loss: 2.208779, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 536/655, Loss: 2.208798, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 537/655, Loss: 2.208950, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 538/655, Loss: 2.208879, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 539/655, Loss: 2.208693, Accuracy: 18.47%\n",
            "Epoch: 23, Step: 540/655, Loss: 2.208560, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 541/655, Loss: 2.208795, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 542/655, Loss: 2.208585, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 543/655, Loss: 2.208672, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 544/655, Loss: 2.208695, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 545/655, Loss: 2.208758, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 546/655, Loss: 2.208653, Accuracy: 18.47%\n",
            "Epoch: 23, Step: 547/655, Loss: 2.208809, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 548/655, Loss: 2.208921, Accuracy: 18.45%\n",
            "Epoch: 23, Step: 549/655, Loss: 2.209089, Accuracy: 18.45%\n",
            "Epoch: 23, Step: 550/655, Loss: 2.209078, Accuracy: 18.45%\n",
            "Epoch: 23, Step: 551/655, Loss: 2.209018, Accuracy: 18.44%\n",
            "Epoch: 23, Step: 552/655, Loss: 2.208856, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 553/655, Loss: 2.208700, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 554/655, Loss: 2.208603, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 555/655, Loss: 2.208759, Accuracy: 18.47%\n",
            "Epoch: 23, Step: 556/655, Loss: 2.208569, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 557/655, Loss: 2.208587, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 558/655, Loss: 2.208672, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 559/655, Loss: 2.208600, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 560/655, Loss: 2.208570, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 561/655, Loss: 2.208472, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 562/655, Loss: 2.208471, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 563/655, Loss: 2.208550, Accuracy: 18.47%\n",
            "Epoch: 23, Step: 564/655, Loss: 2.208410, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 565/655, Loss: 2.208431, Accuracy: 18.47%\n",
            "Epoch: 23, Step: 566/655, Loss: 2.208314, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 567/655, Loss: 2.208250, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 568/655, Loss: 2.207860, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 569/655, Loss: 2.208054, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 570/655, Loss: 2.207853, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 571/655, Loss: 2.207745, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 572/655, Loss: 2.207862, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 573/655, Loss: 2.207958, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 574/655, Loss: 2.207937, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 575/655, Loss: 2.208026, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 576/655, Loss: 2.208047, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 577/655, Loss: 2.207838, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 578/655, Loss: 2.207817, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 579/655, Loss: 2.207999, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 580/655, Loss: 2.208134, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 581/655, Loss: 2.208000, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 582/655, Loss: 2.207818, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 583/655, Loss: 2.207668, Accuracy: 18.55%\n",
            "Epoch: 23, Step: 584/655, Loss: 2.207634, Accuracy: 18.56%\n",
            "Epoch: 23, Step: 585/655, Loss: 2.207835, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 586/655, Loss: 2.208112, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 587/655, Loss: 2.208190, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 588/655, Loss: 2.208107, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 589/655, Loss: 2.208124, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 590/655, Loss: 2.208152, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 591/655, Loss: 2.208349, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 592/655, Loss: 2.208435, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 593/655, Loss: 2.208460, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 594/655, Loss: 2.208383, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 595/655, Loss: 2.208423, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 596/655, Loss: 2.208273, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 597/655, Loss: 2.208255, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 598/655, Loss: 2.208284, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 599/655, Loss: 2.208308, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 600/655, Loss: 2.208359, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 601/655, Loss: 2.208203, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 602/655, Loss: 2.208316, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 603/655, Loss: 2.208448, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 604/655, Loss: 2.208556, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 605/655, Loss: 2.208625, Accuracy: 18.46%\n",
            "Epoch: 23, Step: 606/655, Loss: 2.208578, Accuracy: 18.47%\n",
            "Epoch: 23, Step: 607/655, Loss: 2.208799, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 608/655, Loss: 2.208614, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 609/655, Loss: 2.208752, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 610/655, Loss: 2.208617, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 611/655, Loss: 2.208473, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 612/655, Loss: 2.208586, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 613/655, Loss: 2.208679, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 614/655, Loss: 2.208655, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 615/655, Loss: 2.208588, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 616/655, Loss: 2.208508, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 617/655, Loss: 2.208708, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 618/655, Loss: 2.208528, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 619/655, Loss: 2.208257, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 620/655, Loss: 2.208344, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 621/655, Loss: 2.208554, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 622/655, Loss: 2.208587, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 623/655, Loss: 2.208691, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 624/655, Loss: 2.208618, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 625/655, Loss: 2.208602, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 626/655, Loss: 2.208410, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 627/655, Loss: 2.208491, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 628/655, Loss: 2.208334, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 629/655, Loss: 2.208498, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 630/655, Loss: 2.208470, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 631/655, Loss: 2.208397, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 632/655, Loss: 2.208212, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 633/655, Loss: 2.208294, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 634/655, Loss: 2.208137, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 635/655, Loss: 2.208142, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 636/655, Loss: 2.208352, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 637/655, Loss: 2.208220, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 638/655, Loss: 2.208142, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 639/655, Loss: 2.207930, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 640/655, Loss: 2.207978, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 641/655, Loss: 2.208143, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 642/655, Loss: 2.208273, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 643/655, Loss: 2.208056, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 644/655, Loss: 2.207892, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 645/655, Loss: 2.208041, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 646/655, Loss: 2.208097, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 647/655, Loss: 2.208209, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 648/655, Loss: 2.208061, Accuracy: 18.48%\n",
            "Epoch: 23, Step: 649/655, Loss: 2.208109, Accuracy: 18.49%\n",
            "Epoch: 23, Step: 650/655, Loss: 2.207992, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 651/655, Loss: 2.208030, Accuracy: 18.50%\n",
            "Epoch: 23, Step: 652/655, Loss: 2.208095, Accuracy: 18.51%\n",
            "Epoch: 23, Step: 653/655, Loss: 2.207840, Accuracy: 18.53%\n",
            "Epoch: 23, Step: 654/655, Loss: 2.207837, Accuracy: 18.52%\n",
            "Epoch: 23, Step: 655/655, Loss: 2.207930, Accuracy: 18.53%\n",
            "Epoch: 24, Step: 1/655, Loss: 2.245256, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 2/655, Loss: 2.278571, Accuracy: 17.19%\n",
            "Epoch: 24, Step: 3/655, Loss: 2.241212, Accuracy: 15.62%\n",
            "Epoch: 24, Step: 4/655, Loss: 2.216969, Accuracy: 17.19%\n",
            "Epoch: 24, Step: 5/655, Loss: 2.194247, Accuracy: 15.62%\n",
            "Epoch: 24, Step: 6/655, Loss: 2.219965, Accuracy: 15.10%\n",
            "Epoch: 24, Step: 7/655, Loss: 2.209072, Accuracy: 15.18%\n",
            "Epoch: 24, Step: 8/655, Loss: 2.208518, Accuracy: 15.23%\n",
            "Epoch: 24, Step: 9/655, Loss: 2.209280, Accuracy: 15.28%\n",
            "Epoch: 24, Step: 10/655, Loss: 2.206397, Accuracy: 15.31%\n",
            "Epoch: 24, Step: 11/655, Loss: 2.204240, Accuracy: 15.91%\n",
            "Epoch: 24, Step: 12/655, Loss: 2.208367, Accuracy: 16.15%\n",
            "Epoch: 24, Step: 13/655, Loss: 2.208797, Accuracy: 16.59%\n",
            "Epoch: 24, Step: 14/655, Loss: 2.212264, Accuracy: 16.52%\n",
            "Epoch: 24, Step: 15/655, Loss: 2.209465, Accuracy: 16.88%\n",
            "Epoch: 24, Step: 16/655, Loss: 2.208447, Accuracy: 16.99%\n",
            "Epoch: 24, Step: 17/655, Loss: 2.210657, Accuracy: 17.10%\n",
            "Epoch: 24, Step: 18/655, Loss: 2.208706, Accuracy: 17.36%\n",
            "Epoch: 24, Step: 19/655, Loss: 2.204170, Accuracy: 16.94%\n",
            "Epoch: 24, Step: 20/655, Loss: 2.200190, Accuracy: 17.81%\n",
            "Epoch: 24, Step: 21/655, Loss: 2.199631, Accuracy: 18.15%\n",
            "Epoch: 24, Step: 22/655, Loss: 2.202848, Accuracy: 17.61%\n",
            "Epoch: 24, Step: 23/655, Loss: 2.207963, Accuracy: 17.26%\n",
            "Epoch: 24, Step: 24/655, Loss: 2.203704, Accuracy: 17.45%\n",
            "Epoch: 24, Step: 25/655, Loss: 2.202695, Accuracy: 17.50%\n",
            "Epoch: 24, Step: 26/655, Loss: 2.206009, Accuracy: 16.95%\n",
            "Epoch: 24, Step: 27/655, Loss: 2.202813, Accuracy: 17.36%\n",
            "Epoch: 24, Step: 28/655, Loss: 2.200700, Accuracy: 17.08%\n",
            "Epoch: 24, Step: 29/655, Loss: 2.207905, Accuracy: 16.92%\n",
            "Epoch: 24, Step: 30/655, Loss: 2.204998, Accuracy: 16.67%\n",
            "Epoch: 24, Step: 31/655, Loss: 2.204297, Accuracy: 16.73%\n",
            "Epoch: 24, Step: 32/655, Loss: 2.204233, Accuracy: 16.80%\n",
            "Epoch: 24, Step: 33/655, Loss: 2.200259, Accuracy: 16.86%\n",
            "Epoch: 24, Step: 34/655, Loss: 2.199166, Accuracy: 17.10%\n",
            "Epoch: 24, Step: 35/655, Loss: 2.201820, Accuracy: 17.14%\n",
            "Epoch: 24, Step: 36/655, Loss: 2.203957, Accuracy: 17.10%\n",
            "Epoch: 24, Step: 37/655, Loss: 2.201985, Accuracy: 17.15%\n",
            "Epoch: 24, Step: 38/655, Loss: 2.200408, Accuracy: 17.43%\n",
            "Epoch: 24, Step: 39/655, Loss: 2.200869, Accuracy: 17.31%\n",
            "Epoch: 24, Step: 40/655, Loss: 2.198378, Accuracy: 17.73%\n",
            "Epoch: 24, Step: 41/655, Loss: 2.201527, Accuracy: 17.84%\n",
            "Epoch: 24, Step: 42/655, Loss: 2.201591, Accuracy: 18.08%\n",
            "Epoch: 24, Step: 43/655, Loss: 2.200360, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 44/655, Loss: 2.199958, Accuracy: 18.89%\n",
            "Epoch: 24, Step: 45/655, Loss: 2.197392, Accuracy: 19.17%\n",
            "Epoch: 24, Step: 46/655, Loss: 2.195913, Accuracy: 19.36%\n",
            "Epoch: 24, Step: 47/655, Loss: 2.195418, Accuracy: 19.41%\n",
            "Epoch: 24, Step: 48/655, Loss: 2.195361, Accuracy: 19.27%\n",
            "Epoch: 24, Step: 49/655, Loss: 2.195626, Accuracy: 19.32%\n",
            "Epoch: 24, Step: 50/655, Loss: 2.194528, Accuracy: 19.50%\n",
            "Epoch: 24, Step: 51/655, Loss: 2.194306, Accuracy: 19.55%\n",
            "Epoch: 24, Step: 52/655, Loss: 2.191923, Accuracy: 19.41%\n",
            "Epoch: 24, Step: 53/655, Loss: 2.193141, Accuracy: 19.28%\n",
            "Epoch: 24, Step: 54/655, Loss: 2.193829, Accuracy: 19.21%\n",
            "Epoch: 24, Step: 55/655, Loss: 2.192768, Accuracy: 19.32%\n",
            "Epoch: 24, Step: 56/655, Loss: 2.191389, Accuracy: 19.36%\n",
            "Epoch: 24, Step: 57/655, Loss: 2.193006, Accuracy: 19.24%\n",
            "Epoch: 24, Step: 58/655, Loss: 2.193545, Accuracy: 19.18%\n",
            "Epoch: 24, Step: 59/655, Loss: 2.193474, Accuracy: 19.23%\n",
            "Epoch: 24, Step: 60/655, Loss: 2.195116, Accuracy: 19.27%\n",
            "Epoch: 24, Step: 61/655, Loss: 2.194108, Accuracy: 19.52%\n",
            "Epoch: 24, Step: 62/655, Loss: 2.197765, Accuracy: 19.35%\n",
            "Epoch: 24, Step: 63/655, Loss: 2.199778, Accuracy: 19.20%\n",
            "Epoch: 24, Step: 64/655, Loss: 2.199884, Accuracy: 19.14%\n",
            "Epoch: 24, Step: 65/655, Loss: 2.200177, Accuracy: 19.04%\n",
            "Epoch: 24, Step: 66/655, Loss: 2.200878, Accuracy: 19.03%\n",
            "Epoch: 24, Step: 67/655, Loss: 2.197600, Accuracy: 19.08%\n",
            "Epoch: 24, Step: 68/655, Loss: 2.198257, Accuracy: 19.16%\n",
            "Epoch: 24, Step: 69/655, Loss: 2.199722, Accuracy: 19.07%\n",
            "Epoch: 24, Step: 70/655, Loss: 2.201394, Accuracy: 19.11%\n",
            "Epoch: 24, Step: 71/655, Loss: 2.199295, Accuracy: 19.23%\n",
            "Epoch: 24, Step: 72/655, Loss: 2.200068, Accuracy: 19.10%\n",
            "Epoch: 24, Step: 73/655, Loss: 2.201654, Accuracy: 19.05%\n",
            "Epoch: 24, Step: 74/655, Loss: 2.201172, Accuracy: 19.05%\n",
            "Epoch: 24, Step: 75/655, Loss: 2.202205, Accuracy: 19.04%\n",
            "Epoch: 24, Step: 76/655, Loss: 2.203011, Accuracy: 18.96%\n",
            "Epoch: 24, Step: 77/655, Loss: 2.203471, Accuracy: 18.87%\n",
            "Epoch: 24, Step: 78/655, Loss: 2.203417, Accuracy: 18.99%\n",
            "Epoch: 24, Step: 79/655, Loss: 2.202496, Accuracy: 19.11%\n",
            "Epoch: 24, Step: 80/655, Loss: 2.203762, Accuracy: 19.10%\n",
            "Epoch: 24, Step: 81/655, Loss: 2.203457, Accuracy: 19.17%\n",
            "Epoch: 24, Step: 82/655, Loss: 2.203072, Accuracy: 19.25%\n",
            "Epoch: 24, Step: 83/655, Loss: 2.203574, Accuracy: 19.16%\n",
            "Epoch: 24, Step: 84/655, Loss: 2.204104, Accuracy: 19.16%\n",
            "Epoch: 24, Step: 85/655, Loss: 2.205683, Accuracy: 19.04%\n",
            "Epoch: 24, Step: 86/655, Loss: 2.205588, Accuracy: 19.08%\n",
            "Epoch: 24, Step: 87/655, Loss: 2.205797, Accuracy: 19.04%\n",
            "Epoch: 24, Step: 88/655, Loss: 2.205127, Accuracy: 19.07%\n",
            "Epoch: 24, Step: 89/655, Loss: 2.205699, Accuracy: 19.07%\n",
            "Epoch: 24, Step: 90/655, Loss: 2.205540, Accuracy: 19.17%\n",
            "Epoch: 24, Step: 91/655, Loss: 2.206703, Accuracy: 19.13%\n",
            "Epoch: 24, Step: 92/655, Loss: 2.206872, Accuracy: 19.23%\n",
            "Epoch: 24, Step: 93/655, Loss: 2.206458, Accuracy: 19.15%\n",
            "Epoch: 24, Step: 94/655, Loss: 2.205979, Accuracy: 19.18%\n",
            "Epoch: 24, Step: 95/655, Loss: 2.205287, Accuracy: 19.21%\n",
            "Epoch: 24, Step: 96/655, Loss: 2.204777, Accuracy: 19.21%\n",
            "Epoch: 24, Step: 97/655, Loss: 2.204097, Accuracy: 19.27%\n",
            "Epoch: 24, Step: 98/655, Loss: 2.205692, Accuracy: 19.16%\n",
            "Epoch: 24, Step: 99/655, Loss: 2.205568, Accuracy: 19.16%\n",
            "Epoch: 24, Step: 100/655, Loss: 2.206027, Accuracy: 19.03%\n",
            "Epoch: 24, Step: 101/655, Loss: 2.205878, Accuracy: 19.06%\n",
            "Epoch: 24, Step: 102/655, Loss: 2.205378, Accuracy: 19.18%\n",
            "Epoch: 24, Step: 103/655, Loss: 2.205502, Accuracy: 19.17%\n",
            "Epoch: 24, Step: 104/655, Loss: 2.205465, Accuracy: 19.17%\n",
            "Epoch: 24, Step: 105/655, Loss: 2.206387, Accuracy: 19.14%\n",
            "Epoch: 24, Step: 106/655, Loss: 2.205711, Accuracy: 19.25%\n",
            "Epoch: 24, Step: 107/655, Loss: 2.205211, Accuracy: 19.25%\n",
            "Epoch: 24, Step: 108/655, Loss: 2.205033, Accuracy: 19.24%\n",
            "Epoch: 24, Step: 109/655, Loss: 2.204236, Accuracy: 19.29%\n",
            "Epoch: 24, Step: 110/655, Loss: 2.204167, Accuracy: 19.32%\n",
            "Epoch: 24, Step: 111/655, Loss: 2.204726, Accuracy: 19.28%\n",
            "Epoch: 24, Step: 112/655, Loss: 2.203465, Accuracy: 19.36%\n",
            "Epoch: 24, Step: 113/655, Loss: 2.204260, Accuracy: 19.39%\n",
            "Epoch: 24, Step: 114/655, Loss: 2.204848, Accuracy: 19.35%\n",
            "Epoch: 24, Step: 115/655, Loss: 2.205439, Accuracy: 19.35%\n",
            "Epoch: 24, Step: 116/655, Loss: 2.205772, Accuracy: 19.29%\n",
            "Epoch: 24, Step: 117/655, Loss: 2.205696, Accuracy: 19.26%\n",
            "Epoch: 24, Step: 118/655, Loss: 2.205011, Accuracy: 19.28%\n",
            "Epoch: 24, Step: 119/655, Loss: 2.204703, Accuracy: 19.25%\n",
            "Epoch: 24, Step: 120/655, Loss: 2.205405, Accuracy: 19.27%\n",
            "Epoch: 24, Step: 121/655, Loss: 2.205741, Accuracy: 19.19%\n",
            "Epoch: 24, Step: 122/655, Loss: 2.206331, Accuracy: 19.19%\n",
            "Epoch: 24, Step: 123/655, Loss: 2.205697, Accuracy: 19.21%\n",
            "Epoch: 24, Step: 124/655, Loss: 2.206403, Accuracy: 19.15%\n",
            "Epoch: 24, Step: 125/655, Loss: 2.207398, Accuracy: 19.15%\n",
            "Epoch: 24, Step: 126/655, Loss: 2.207752, Accuracy: 19.15%\n",
            "Epoch: 24, Step: 127/655, Loss: 2.208233, Accuracy: 19.14%\n",
            "Epoch: 24, Step: 128/655, Loss: 2.207623, Accuracy: 19.19%\n",
            "Epoch: 24, Step: 129/655, Loss: 2.208613, Accuracy: 19.06%\n",
            "Epoch: 24, Step: 130/655, Loss: 2.208204, Accuracy: 19.01%\n",
            "Epoch: 24, Step: 131/655, Loss: 2.209133, Accuracy: 18.99%\n",
            "Epoch: 24, Step: 132/655, Loss: 2.208297, Accuracy: 18.99%\n",
            "Epoch: 24, Step: 133/655, Loss: 2.208442, Accuracy: 19.06%\n",
            "Epoch: 24, Step: 134/655, Loss: 2.209107, Accuracy: 19.08%\n",
            "Epoch: 24, Step: 135/655, Loss: 2.209380, Accuracy: 19.07%\n",
            "Epoch: 24, Step: 136/655, Loss: 2.209286, Accuracy: 19.07%\n",
            "Epoch: 24, Step: 137/655, Loss: 2.210631, Accuracy: 19.02%\n",
            "Epoch: 24, Step: 138/655, Loss: 2.210941, Accuracy: 18.95%\n",
            "Epoch: 24, Step: 139/655, Loss: 2.210193, Accuracy: 19.04%\n",
            "Epoch: 24, Step: 140/655, Loss: 2.209825, Accuracy: 19.00%\n",
            "Epoch: 24, Step: 141/655, Loss: 2.210238, Accuracy: 18.93%\n",
            "Epoch: 24, Step: 142/655, Loss: 2.211357, Accuracy: 18.86%\n",
            "Epoch: 24, Step: 143/655, Loss: 2.211381, Accuracy: 18.86%\n",
            "Epoch: 24, Step: 144/655, Loss: 2.210853, Accuracy: 18.84%\n",
            "Epoch: 24, Step: 145/655, Loss: 2.211364, Accuracy: 18.84%\n",
            "Epoch: 24, Step: 146/655, Loss: 2.211077, Accuracy: 18.79%\n",
            "Epoch: 24, Step: 147/655, Loss: 2.210915, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 148/655, Loss: 2.210755, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 149/655, Loss: 2.211079, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 150/655, Loss: 2.210124, Accuracy: 18.77%\n",
            "Epoch: 24, Step: 151/655, Loss: 2.209161, Accuracy: 18.83%\n",
            "Epoch: 24, Step: 152/655, Loss: 2.209534, Accuracy: 18.83%\n",
            "Epoch: 24, Step: 153/655, Loss: 2.209334, Accuracy: 18.81%\n",
            "Epoch: 24, Step: 154/655, Loss: 2.209756, Accuracy: 18.81%\n",
            "Epoch: 24, Step: 155/655, Loss: 2.209666, Accuracy: 18.85%\n",
            "Epoch: 24, Step: 156/655, Loss: 2.209333, Accuracy: 18.83%\n",
            "Epoch: 24, Step: 157/655, Loss: 2.209468, Accuracy: 18.83%\n",
            "Epoch: 24, Step: 158/655, Loss: 2.209530, Accuracy: 18.85%\n",
            "Epoch: 24, Step: 159/655, Loss: 2.208969, Accuracy: 18.89%\n",
            "Epoch: 24, Step: 160/655, Loss: 2.209267, Accuracy: 18.91%\n",
            "Epoch: 24, Step: 161/655, Loss: 2.209331, Accuracy: 18.91%\n",
            "Epoch: 24, Step: 162/655, Loss: 2.209516, Accuracy: 18.87%\n",
            "Epoch: 24, Step: 163/655, Loss: 2.209236, Accuracy: 18.87%\n",
            "Epoch: 24, Step: 164/655, Loss: 2.209648, Accuracy: 18.85%\n",
            "Epoch: 24, Step: 165/655, Loss: 2.209988, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 166/655, Loss: 2.209797, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 167/655, Loss: 2.210141, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 168/655, Loss: 2.209599, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 169/655, Loss: 2.208956, Accuracy: 18.79%\n",
            "Epoch: 24, Step: 170/655, Loss: 2.208776, Accuracy: 18.79%\n",
            "Epoch: 24, Step: 171/655, Loss: 2.209057, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 172/655, Loss: 2.208906, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 173/655, Loss: 2.208597, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 174/655, Loss: 2.209503, Accuracy: 18.77%\n",
            "Epoch: 24, Step: 175/655, Loss: 2.209056, Accuracy: 18.79%\n",
            "Epoch: 24, Step: 176/655, Loss: 2.209302, Accuracy: 18.84%\n",
            "Epoch: 24, Step: 177/655, Loss: 2.209744, Accuracy: 18.77%\n",
            "Epoch: 24, Step: 178/655, Loss: 2.210272, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 179/655, Loss: 2.209547, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 180/655, Loss: 2.209442, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 181/655, Loss: 2.209547, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 182/655, Loss: 2.209342, Accuracy: 18.60%\n",
            "Epoch: 24, Step: 183/655, Loss: 2.209060, Accuracy: 18.60%\n",
            "Epoch: 24, Step: 184/655, Loss: 2.209082, Accuracy: 18.63%\n",
            "Epoch: 24, Step: 185/655, Loss: 2.209463, Accuracy: 18.58%\n",
            "Epoch: 24, Step: 186/655, Loss: 2.209214, Accuracy: 18.58%\n",
            "Epoch: 24, Step: 187/655, Loss: 2.209267, Accuracy: 18.55%\n",
            "Epoch: 24, Step: 188/655, Loss: 2.209051, Accuracy: 18.53%\n",
            "Epoch: 24, Step: 189/655, Loss: 2.208764, Accuracy: 18.55%\n",
            "Epoch: 24, Step: 190/655, Loss: 2.208738, Accuracy: 18.57%\n",
            "Epoch: 24, Step: 191/655, Loss: 2.208866, Accuracy: 18.54%\n",
            "Epoch: 24, Step: 192/655, Loss: 2.208713, Accuracy: 18.54%\n",
            "Epoch: 24, Step: 193/655, Loss: 2.208381, Accuracy: 18.60%\n",
            "Epoch: 24, Step: 194/655, Loss: 2.207758, Accuracy: 18.65%\n",
            "Epoch: 24, Step: 195/655, Loss: 2.208164, Accuracy: 18.62%\n",
            "Epoch: 24, Step: 196/655, Loss: 2.208032, Accuracy: 18.59%\n",
            "Epoch: 24, Step: 197/655, Loss: 2.207747, Accuracy: 18.61%\n",
            "Epoch: 24, Step: 198/655, Loss: 2.207847, Accuracy: 18.58%\n",
            "Epoch: 24, Step: 199/655, Loss: 2.207033, Accuracy: 18.62%\n",
            "Epoch: 24, Step: 200/655, Loss: 2.206587, Accuracy: 18.59%\n",
            "Epoch: 24, Step: 201/655, Loss: 2.206488, Accuracy: 18.64%\n",
            "Epoch: 24, Step: 202/655, Loss: 2.206514, Accuracy: 18.64%\n",
            "Epoch: 24, Step: 203/655, Loss: 2.206620, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 204/655, Loss: 2.206613, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 205/655, Loss: 2.206417, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 206/655, Loss: 2.206149, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 207/655, Loss: 2.206387, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 208/655, Loss: 2.206245, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 209/655, Loss: 2.206643, Accuracy: 18.65%\n",
            "Epoch: 24, Step: 210/655, Loss: 2.206131, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 211/655, Loss: 2.206558, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 212/655, Loss: 2.206497, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 213/655, Loss: 2.206405, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 214/655, Loss: 2.206207, Accuracy: 18.78%\n",
            "Epoch: 24, Step: 215/655, Loss: 2.206362, Accuracy: 18.81%\n",
            "Epoch: 24, Step: 216/655, Loss: 2.206665, Accuracy: 18.82%\n",
            "Epoch: 24, Step: 217/655, Loss: 2.206115, Accuracy: 18.87%\n",
            "Epoch: 24, Step: 218/655, Loss: 2.206025, Accuracy: 18.88%\n",
            "Epoch: 24, Step: 219/655, Loss: 2.205985, Accuracy: 18.86%\n",
            "Epoch: 24, Step: 220/655, Loss: 2.205905, Accuracy: 18.88%\n",
            "Epoch: 24, Step: 221/655, Loss: 2.205806, Accuracy: 18.92%\n",
            "Epoch: 24, Step: 222/655, Loss: 2.206158, Accuracy: 18.88%\n",
            "Epoch: 24, Step: 223/655, Loss: 2.206013, Accuracy: 18.90%\n",
            "Epoch: 24, Step: 224/655, Loss: 2.205620, Accuracy: 18.92%\n",
            "Epoch: 24, Step: 225/655, Loss: 2.205003, Accuracy: 18.96%\n",
            "Epoch: 24, Step: 226/655, Loss: 2.204815, Accuracy: 18.96%\n",
            "Epoch: 24, Step: 227/655, Loss: 2.205032, Accuracy: 18.93%\n",
            "Epoch: 24, Step: 228/655, Loss: 2.205495, Accuracy: 18.90%\n",
            "Epoch: 24, Step: 229/655, Loss: 2.205147, Accuracy: 18.93%\n",
            "Epoch: 24, Step: 230/655, Loss: 2.205176, Accuracy: 18.93%\n",
            "Epoch: 24, Step: 231/655, Loss: 2.205274, Accuracy: 18.95%\n",
            "Epoch: 24, Step: 232/655, Loss: 2.205769, Accuracy: 18.97%\n",
            "Epoch: 24, Step: 233/655, Loss: 2.205967, Accuracy: 18.96%\n",
            "Epoch: 24, Step: 234/655, Loss: 2.205831, Accuracy: 19.06%\n",
            "Epoch: 24, Step: 235/655, Loss: 2.205802, Accuracy: 19.06%\n",
            "Epoch: 24, Step: 236/655, Loss: 2.206015, Accuracy: 19.05%\n",
            "Epoch: 24, Step: 237/655, Loss: 2.205823, Accuracy: 19.00%\n",
            "Epoch: 24, Step: 238/655, Loss: 2.206067, Accuracy: 19.00%\n",
            "Epoch: 24, Step: 239/655, Loss: 2.206254, Accuracy: 19.00%\n",
            "Epoch: 24, Step: 240/655, Loss: 2.206498, Accuracy: 19.01%\n",
            "Epoch: 24, Step: 241/655, Loss: 2.206762, Accuracy: 18.98%\n",
            "Epoch: 24, Step: 242/655, Loss: 2.206791, Accuracy: 18.98%\n",
            "Epoch: 24, Step: 243/655, Loss: 2.206511, Accuracy: 18.98%\n",
            "Epoch: 24, Step: 244/655, Loss: 2.206465, Accuracy: 19.01%\n",
            "Epoch: 24, Step: 245/655, Loss: 2.206302, Accuracy: 18.98%\n",
            "Epoch: 24, Step: 246/655, Loss: 2.206549, Accuracy: 18.95%\n",
            "Epoch: 24, Step: 247/655, Loss: 2.206256, Accuracy: 18.95%\n",
            "Epoch: 24, Step: 248/655, Loss: 2.206483, Accuracy: 18.93%\n",
            "Epoch: 24, Step: 249/655, Loss: 2.206262, Accuracy: 18.98%\n",
            "Epoch: 24, Step: 250/655, Loss: 2.205629, Accuracy: 18.98%\n",
            "Epoch: 24, Step: 251/655, Loss: 2.205932, Accuracy: 18.99%\n",
            "Epoch: 24, Step: 252/655, Loss: 2.205573, Accuracy: 19.04%\n",
            "Epoch: 24, Step: 253/655, Loss: 2.205682, Accuracy: 19.03%\n",
            "Epoch: 24, Step: 254/655, Loss: 2.206006, Accuracy: 19.02%\n",
            "Epoch: 24, Step: 255/655, Loss: 2.206618, Accuracy: 19.00%\n",
            "Epoch: 24, Step: 256/655, Loss: 2.206547, Accuracy: 18.99%\n",
            "Epoch: 24, Step: 257/655, Loss: 2.207015, Accuracy: 18.94%\n",
            "Epoch: 24, Step: 258/655, Loss: 2.206650, Accuracy: 18.92%\n",
            "Epoch: 24, Step: 259/655, Loss: 2.207475, Accuracy: 18.89%\n",
            "Epoch: 24, Step: 260/655, Loss: 2.207667, Accuracy: 18.89%\n",
            "Epoch: 24, Step: 261/655, Loss: 2.207160, Accuracy: 18.94%\n",
            "Epoch: 24, Step: 262/655, Loss: 2.208026, Accuracy: 18.91%\n",
            "Epoch: 24, Step: 263/655, Loss: 2.208110, Accuracy: 18.90%\n",
            "Epoch: 24, Step: 264/655, Loss: 2.207859, Accuracy: 18.92%\n",
            "Epoch: 24, Step: 265/655, Loss: 2.207524, Accuracy: 18.97%\n",
            "Epoch: 24, Step: 266/655, Loss: 2.208094, Accuracy: 18.96%\n",
            "Epoch: 24, Step: 267/655, Loss: 2.208217, Accuracy: 18.95%\n",
            "Epoch: 24, Step: 268/655, Loss: 2.208186, Accuracy: 18.96%\n",
            "Epoch: 24, Step: 269/655, Loss: 2.207947, Accuracy: 18.94%\n",
            "Epoch: 24, Step: 270/655, Loss: 2.207576, Accuracy: 18.94%\n",
            "Epoch: 24, Step: 271/655, Loss: 2.207489, Accuracy: 18.93%\n",
            "Epoch: 24, Step: 272/655, Loss: 2.207446, Accuracy: 18.93%\n",
            "Epoch: 24, Step: 273/655, Loss: 2.207320, Accuracy: 18.96%\n",
            "Epoch: 24, Step: 274/655, Loss: 2.207300, Accuracy: 18.93%\n",
            "Epoch: 24, Step: 275/655, Loss: 2.207144, Accuracy: 18.94%\n",
            "Epoch: 24, Step: 276/655, Loss: 2.207097, Accuracy: 18.97%\n",
            "Epoch: 24, Step: 277/655, Loss: 2.207076, Accuracy: 18.96%\n",
            "Epoch: 24, Step: 278/655, Loss: 2.206950, Accuracy: 18.96%\n",
            "Epoch: 24, Step: 279/655, Loss: 2.207386, Accuracy: 18.94%\n",
            "Epoch: 24, Step: 280/655, Loss: 2.207392, Accuracy: 18.94%\n",
            "Epoch: 24, Step: 281/655, Loss: 2.207304, Accuracy: 18.92%\n",
            "Epoch: 24, Step: 282/655, Loss: 2.207494, Accuracy: 18.91%\n",
            "Epoch: 24, Step: 283/655, Loss: 2.207759, Accuracy: 18.90%\n",
            "Epoch: 24, Step: 284/655, Loss: 2.207647, Accuracy: 18.92%\n",
            "Epoch: 24, Step: 285/655, Loss: 2.207706, Accuracy: 18.88%\n",
            "Epoch: 24, Step: 286/655, Loss: 2.207855, Accuracy: 18.85%\n",
            "Epoch: 24, Step: 287/655, Loss: 2.208081, Accuracy: 18.82%\n",
            "Epoch: 24, Step: 288/655, Loss: 2.208143, Accuracy: 18.80%\n",
            "Epoch: 24, Step: 289/655, Loss: 2.207955, Accuracy: 18.81%\n",
            "Epoch: 24, Step: 290/655, Loss: 2.208295, Accuracy: 18.78%\n",
            "Epoch: 24, Step: 291/655, Loss: 2.208584, Accuracy: 18.78%\n",
            "Epoch: 24, Step: 292/655, Loss: 2.208014, Accuracy: 18.82%\n",
            "Epoch: 24, Step: 293/655, Loss: 2.207598, Accuracy: 18.84%\n",
            "Epoch: 24, Step: 294/655, Loss: 2.207838, Accuracy: 18.84%\n",
            "Epoch: 24, Step: 295/655, Loss: 2.207445, Accuracy: 18.85%\n",
            "Epoch: 24, Step: 296/655, Loss: 2.207683, Accuracy: 18.82%\n",
            "Epoch: 24, Step: 297/655, Loss: 2.207307, Accuracy: 18.83%\n",
            "Epoch: 24, Step: 298/655, Loss: 2.207715, Accuracy: 18.82%\n",
            "Epoch: 24, Step: 299/655, Loss: 2.207441, Accuracy: 18.88%\n",
            "Epoch: 24, Step: 300/655, Loss: 2.207619, Accuracy: 18.88%\n",
            "Epoch: 24, Step: 301/655, Loss: 2.207160, Accuracy: 18.90%\n",
            "Epoch: 24, Step: 302/655, Loss: 2.207194, Accuracy: 18.93%\n",
            "Epoch: 24, Step: 303/655, Loss: 2.207008, Accuracy: 18.94%\n",
            "Epoch: 24, Step: 304/655, Loss: 2.207103, Accuracy: 18.91%\n",
            "Epoch: 24, Step: 305/655, Loss: 2.206713, Accuracy: 18.94%\n",
            "Epoch: 24, Step: 306/655, Loss: 2.207288, Accuracy: 18.91%\n",
            "Epoch: 24, Step: 307/655, Loss: 2.207002, Accuracy: 18.92%\n",
            "Epoch: 24, Step: 308/655, Loss: 2.207396, Accuracy: 18.90%\n",
            "Epoch: 24, Step: 309/655, Loss: 2.207365, Accuracy: 18.91%\n",
            "Epoch: 24, Step: 310/655, Loss: 2.207191, Accuracy: 18.92%\n",
            "Epoch: 24, Step: 311/655, Loss: 2.206451, Accuracy: 18.99%\n",
            "Epoch: 24, Step: 312/655, Loss: 2.206490, Accuracy: 18.95%\n",
            "Epoch: 24, Step: 313/655, Loss: 2.206596, Accuracy: 18.90%\n",
            "Epoch: 24, Step: 314/655, Loss: 2.206479, Accuracy: 18.91%\n",
            "Epoch: 24, Step: 315/655, Loss: 2.206595, Accuracy: 18.93%\n",
            "Epoch: 24, Step: 316/655, Loss: 2.206753, Accuracy: 18.93%\n",
            "Epoch: 24, Step: 317/655, Loss: 2.206966, Accuracy: 18.95%\n",
            "Epoch: 24, Step: 318/655, Loss: 2.206893, Accuracy: 18.98%\n",
            "Epoch: 24, Step: 319/655, Loss: 2.207212, Accuracy: 18.96%\n",
            "Epoch: 24, Step: 320/655, Loss: 2.207222, Accuracy: 18.96%\n",
            "Epoch: 24, Step: 321/655, Loss: 2.207069, Accuracy: 18.95%\n",
            "Epoch: 24, Step: 322/655, Loss: 2.207262, Accuracy: 18.95%\n",
            "Epoch: 24, Step: 323/655, Loss: 2.207392, Accuracy: 18.91%\n",
            "Epoch: 24, Step: 324/655, Loss: 2.207864, Accuracy: 18.89%\n",
            "Epoch: 24, Step: 325/655, Loss: 2.208007, Accuracy: 18.88%\n",
            "Epoch: 24, Step: 326/655, Loss: 2.208330, Accuracy: 18.87%\n",
            "Epoch: 24, Step: 327/655, Loss: 2.208086, Accuracy: 18.85%\n",
            "Epoch: 24, Step: 328/655, Loss: 2.208072, Accuracy: 18.86%\n",
            "Epoch: 24, Step: 329/655, Loss: 2.208504, Accuracy: 18.84%\n",
            "Epoch: 24, Step: 330/655, Loss: 2.208753, Accuracy: 18.84%\n",
            "Epoch: 24, Step: 331/655, Loss: 2.208944, Accuracy: 18.84%\n",
            "Epoch: 24, Step: 332/655, Loss: 2.208683, Accuracy: 18.84%\n",
            "Epoch: 24, Step: 333/655, Loss: 2.208404, Accuracy: 18.87%\n",
            "Epoch: 24, Step: 334/655, Loss: 2.208175, Accuracy: 18.92%\n",
            "Epoch: 24, Step: 335/655, Loss: 2.208119, Accuracy: 18.91%\n",
            "Epoch: 24, Step: 336/655, Loss: 2.208298, Accuracy: 18.89%\n",
            "Epoch: 24, Step: 337/655, Loss: 2.208280, Accuracy: 18.87%\n",
            "Epoch: 24, Step: 338/655, Loss: 2.208163, Accuracy: 18.86%\n",
            "Epoch: 24, Step: 339/655, Loss: 2.208111, Accuracy: 18.85%\n",
            "Epoch: 24, Step: 340/655, Loss: 2.208086, Accuracy: 18.84%\n",
            "Epoch: 24, Step: 341/655, Loss: 2.207752, Accuracy: 18.89%\n",
            "Epoch: 24, Step: 342/655, Loss: 2.207666, Accuracy: 18.91%\n",
            "Epoch: 24, Step: 343/655, Loss: 2.207598, Accuracy: 18.92%\n",
            "Epoch: 24, Step: 344/655, Loss: 2.207529, Accuracy: 18.92%\n",
            "Epoch: 24, Step: 345/655, Loss: 2.207549, Accuracy: 18.91%\n",
            "Epoch: 24, Step: 346/655, Loss: 2.207484, Accuracy: 18.91%\n",
            "Epoch: 24, Step: 347/655, Loss: 2.207334, Accuracy: 18.93%\n",
            "Epoch: 24, Step: 348/655, Loss: 2.207357, Accuracy: 18.93%\n",
            "Epoch: 24, Step: 349/655, Loss: 2.207541, Accuracy: 18.92%\n",
            "Epoch: 24, Step: 350/655, Loss: 2.207407, Accuracy: 18.94%\n",
            "Epoch: 24, Step: 351/655, Loss: 2.207344, Accuracy: 18.95%\n",
            "Epoch: 24, Step: 352/655, Loss: 2.207367, Accuracy: 18.94%\n",
            "Epoch: 24, Step: 353/655, Loss: 2.207304, Accuracy: 18.95%\n",
            "Epoch: 24, Step: 354/655, Loss: 2.207361, Accuracy: 18.94%\n",
            "Epoch: 24, Step: 355/655, Loss: 2.207450, Accuracy: 18.92%\n",
            "Epoch: 24, Step: 356/655, Loss: 2.207589, Accuracy: 18.90%\n",
            "Epoch: 24, Step: 357/655, Loss: 2.207434, Accuracy: 18.92%\n",
            "Epoch: 24, Step: 358/655, Loss: 2.207919, Accuracy: 18.90%\n",
            "Epoch: 24, Step: 359/655, Loss: 2.208016, Accuracy: 18.91%\n",
            "Epoch: 24, Step: 360/655, Loss: 2.207765, Accuracy: 18.91%\n",
            "Epoch: 24, Step: 361/655, Loss: 2.208103, Accuracy: 18.89%\n",
            "Epoch: 24, Step: 362/655, Loss: 2.208134, Accuracy: 18.90%\n",
            "Epoch: 24, Step: 363/655, Loss: 2.208271, Accuracy: 18.87%\n",
            "Epoch: 24, Step: 364/655, Loss: 2.208304, Accuracy: 18.87%\n",
            "Epoch: 24, Step: 365/655, Loss: 2.208133, Accuracy: 18.89%\n",
            "Epoch: 24, Step: 366/655, Loss: 2.208199, Accuracy: 18.86%\n",
            "Epoch: 24, Step: 367/655, Loss: 2.208255, Accuracy: 18.87%\n",
            "Epoch: 24, Step: 368/655, Loss: 2.208585, Accuracy: 18.84%\n",
            "Epoch: 24, Step: 369/655, Loss: 2.208494, Accuracy: 18.83%\n",
            "Epoch: 24, Step: 370/655, Loss: 2.208466, Accuracy: 18.82%\n",
            "Epoch: 24, Step: 371/655, Loss: 2.208313, Accuracy: 18.82%\n",
            "Epoch: 24, Step: 372/655, Loss: 2.208781, Accuracy: 18.79%\n",
            "Epoch: 24, Step: 373/655, Loss: 2.209155, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 374/655, Loss: 2.209246, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 375/655, Loss: 2.209417, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 376/655, Loss: 2.209282, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 377/655, Loss: 2.209316, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 378/655, Loss: 2.209293, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 379/655, Loss: 2.209006, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 380/655, Loss: 2.209257, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 381/655, Loss: 2.209162, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 382/655, Loss: 2.208955, Accuracy: 18.70%\n",
            "Epoch: 24, Step: 383/655, Loss: 2.208442, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 384/655, Loss: 2.208519, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 385/655, Loss: 2.208211, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 386/655, Loss: 2.207944, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 387/655, Loss: 2.208036, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 388/655, Loss: 2.207933, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 389/655, Loss: 2.207814, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 390/655, Loss: 2.207570, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 391/655, Loss: 2.207597, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 392/655, Loss: 2.207493, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 393/655, Loss: 2.207506, Accuracy: 18.77%\n",
            "Epoch: 24, Step: 394/655, Loss: 2.207253, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 395/655, Loss: 2.207738, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 396/655, Loss: 2.207908, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 397/655, Loss: 2.207849, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 398/655, Loss: 2.208319, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 399/655, Loss: 2.208363, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 400/655, Loss: 2.207878, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 401/655, Loss: 2.208055, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 402/655, Loss: 2.208189, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 403/655, Loss: 2.208412, Accuracy: 18.65%\n",
            "Epoch: 24, Step: 404/655, Loss: 2.208282, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 405/655, Loss: 2.208108, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 406/655, Loss: 2.208293, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 407/655, Loss: 2.208288, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 408/655, Loss: 2.208446, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 409/655, Loss: 2.208379, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 410/655, Loss: 2.208274, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 411/655, Loss: 2.208243, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 412/655, Loss: 2.208179, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 413/655, Loss: 2.208426, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 414/655, Loss: 2.208336, Accuracy: 18.70%\n",
            "Epoch: 24, Step: 415/655, Loss: 2.208383, Accuracy: 18.70%\n",
            "Epoch: 24, Step: 416/655, Loss: 2.208645, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 417/655, Loss: 2.208499, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 418/655, Loss: 2.207974, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 419/655, Loss: 2.207556, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 420/655, Loss: 2.207500, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 421/655, Loss: 2.207783, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 422/655, Loss: 2.207935, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 423/655, Loss: 2.208141, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 424/655, Loss: 2.208118, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 425/655, Loss: 2.207936, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 426/655, Loss: 2.207768, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 427/655, Loss: 2.207703, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 428/655, Loss: 2.207504, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 429/655, Loss: 2.207964, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 430/655, Loss: 2.207955, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 431/655, Loss: 2.207806, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 432/655, Loss: 2.207857, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 433/655, Loss: 2.207757, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 434/655, Loss: 2.207788, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 435/655, Loss: 2.207837, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 436/655, Loss: 2.207823, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 437/655, Loss: 2.207705, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 438/655, Loss: 2.207666, Accuracy: 18.79%\n",
            "Epoch: 24, Step: 439/655, Loss: 2.207632, Accuracy: 18.78%\n",
            "Epoch: 24, Step: 440/655, Loss: 2.207528, Accuracy: 18.80%\n",
            "Epoch: 24, Step: 441/655, Loss: 2.207450, Accuracy: 18.81%\n",
            "Epoch: 24, Step: 442/655, Loss: 2.207343, Accuracy: 18.82%\n",
            "Epoch: 24, Step: 443/655, Loss: 2.207089, Accuracy: 18.83%\n",
            "Epoch: 24, Step: 444/655, Loss: 2.206958, Accuracy: 18.83%\n",
            "Epoch: 24, Step: 445/655, Loss: 2.206900, Accuracy: 18.83%\n",
            "Epoch: 24, Step: 446/655, Loss: 2.206838, Accuracy: 18.83%\n",
            "Epoch: 24, Step: 447/655, Loss: 2.207043, Accuracy: 18.81%\n",
            "Epoch: 24, Step: 448/655, Loss: 2.207323, Accuracy: 18.80%\n",
            "Epoch: 24, Step: 449/655, Loss: 2.207120, Accuracy: 18.78%\n",
            "Epoch: 24, Step: 450/655, Loss: 2.207283, Accuracy: 18.78%\n",
            "Epoch: 24, Step: 451/655, Loss: 2.207394, Accuracy: 18.77%\n",
            "Epoch: 24, Step: 452/655, Loss: 2.207281, Accuracy: 18.78%\n",
            "Epoch: 24, Step: 453/655, Loss: 2.207445, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 454/655, Loss: 2.207175, Accuracy: 18.77%\n",
            "Epoch: 24, Step: 455/655, Loss: 2.207244, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 456/655, Loss: 2.207130, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 457/655, Loss: 2.207058, Accuracy: 18.77%\n",
            "Epoch: 24, Step: 458/655, Loss: 2.207132, Accuracy: 18.78%\n",
            "Epoch: 24, Step: 459/655, Loss: 2.207235, Accuracy: 18.77%\n",
            "Epoch: 24, Step: 460/655, Loss: 2.207310, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 461/655, Loss: 2.207319, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 462/655, Loss: 2.207364, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 463/655, Loss: 2.207606, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 464/655, Loss: 2.207834, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 465/655, Loss: 2.207695, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 466/655, Loss: 2.207531, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 467/655, Loss: 2.207725, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 468/655, Loss: 2.207783, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 469/655, Loss: 2.207639, Accuracy: 18.79%\n",
            "Epoch: 24, Step: 470/655, Loss: 2.207706, Accuracy: 18.79%\n",
            "Epoch: 24, Step: 471/655, Loss: 2.207853, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 472/655, Loss: 2.208045, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 473/655, Loss: 2.208022, Accuracy: 18.77%\n",
            "Epoch: 24, Step: 474/655, Loss: 2.208143, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 475/655, Loss: 2.208252, Accuracy: 18.78%\n",
            "Epoch: 24, Step: 476/655, Loss: 2.208282, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 477/655, Loss: 2.208075, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 478/655, Loss: 2.208259, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 479/655, Loss: 2.208471, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 480/655, Loss: 2.208264, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 481/655, Loss: 2.208408, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 482/655, Loss: 2.208370, Accuracy: 18.70%\n",
            "Epoch: 24, Step: 483/655, Loss: 2.208616, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 484/655, Loss: 2.208471, Accuracy: 18.70%\n",
            "Epoch: 24, Step: 485/655, Loss: 2.208572, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 486/655, Loss: 2.208629, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 487/655, Loss: 2.208258, Accuracy: 18.70%\n",
            "Epoch: 24, Step: 488/655, Loss: 2.208271, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 489/655, Loss: 2.208371, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 490/655, Loss: 2.208458, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 491/655, Loss: 2.208408, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 492/655, Loss: 2.208305, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 493/655, Loss: 2.208326, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 494/655, Loss: 2.208314, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 495/655, Loss: 2.208424, Accuracy: 18.70%\n",
            "Epoch: 24, Step: 496/655, Loss: 2.208361, Accuracy: 18.70%\n",
            "Epoch: 24, Step: 497/655, Loss: 2.208227, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 498/655, Loss: 2.208227, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 499/655, Loss: 2.208080, Accuracy: 18.70%\n",
            "Epoch: 24, Step: 500/655, Loss: 2.208386, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 501/655, Loss: 2.208331, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 502/655, Loss: 2.208222, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 503/655, Loss: 2.208309, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 504/655, Loss: 2.208653, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 505/655, Loss: 2.208733, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 506/655, Loss: 2.208580, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 507/655, Loss: 2.208418, Accuracy: 18.70%\n",
            "Epoch: 24, Step: 508/655, Loss: 2.208568, Accuracy: 18.70%\n",
            "Epoch: 24, Step: 509/655, Loss: 2.208666, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 510/655, Loss: 2.208474, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 511/655, Loss: 2.208580, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 512/655, Loss: 2.208471, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 513/655, Loss: 2.208272, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 514/655, Loss: 2.208095, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 515/655, Loss: 2.208418, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 516/655, Loss: 2.208309, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 517/655, Loss: 2.208411, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 518/655, Loss: 2.208457, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 519/655, Loss: 2.208468, Accuracy: 18.65%\n",
            "Epoch: 24, Step: 520/655, Loss: 2.208277, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 521/655, Loss: 2.208412, Accuracy: 18.65%\n",
            "Epoch: 24, Step: 522/655, Loss: 2.208155, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 523/655, Loss: 2.208095, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 524/655, Loss: 2.208044, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 525/655, Loss: 2.208168, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 526/655, Loss: 2.208314, Accuracy: 18.65%\n",
            "Epoch: 24, Step: 527/655, Loss: 2.208275, Accuracy: 18.65%\n",
            "Epoch: 24, Step: 528/655, Loss: 2.208526, Accuracy: 18.64%\n",
            "Epoch: 24, Step: 529/655, Loss: 2.208580, Accuracy: 18.62%\n",
            "Epoch: 24, Step: 530/655, Loss: 2.208227, Accuracy: 18.64%\n",
            "Epoch: 24, Step: 531/655, Loss: 2.208319, Accuracy: 18.64%\n",
            "Epoch: 24, Step: 532/655, Loss: 2.208160, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 533/655, Loss: 2.207982, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 534/655, Loss: 2.207856, Accuracy: 18.65%\n",
            "Epoch: 24, Step: 535/655, Loss: 2.207929, Accuracy: 18.64%\n",
            "Epoch: 24, Step: 536/655, Loss: 2.207647, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 537/655, Loss: 2.207621, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 538/655, Loss: 2.207889, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 539/655, Loss: 2.207786, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 540/655, Loss: 2.207974, Accuracy: 18.65%\n",
            "Epoch: 24, Step: 541/655, Loss: 2.207720, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 542/655, Loss: 2.207712, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 543/655, Loss: 2.207655, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 544/655, Loss: 2.207504, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 545/655, Loss: 2.207483, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 546/655, Loss: 2.207377, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 547/655, Loss: 2.207239, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 548/655, Loss: 2.207057, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 549/655, Loss: 2.206959, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 550/655, Loss: 2.206973, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 551/655, Loss: 2.206851, Accuracy: 18.68%\n",
            "Epoch: 24, Step: 552/655, Loss: 2.206860, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 553/655, Loss: 2.206898, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 554/655, Loss: 2.206731, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 555/655, Loss: 2.207093, Accuracy: 18.66%\n",
            "Epoch: 24, Step: 556/655, Loss: 2.206958, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 557/655, Loss: 2.206559, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 558/655, Loss: 2.206446, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 559/655, Loss: 2.206257, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 560/655, Loss: 2.206286, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 561/655, Loss: 2.205924, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 562/655, Loss: 2.206008, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 563/655, Loss: 2.206079, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 564/655, Loss: 2.206267, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 565/655, Loss: 2.206320, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 566/655, Loss: 2.206296, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 567/655, Loss: 2.206522, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 568/655, Loss: 2.206481, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 569/655, Loss: 2.206657, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 570/655, Loss: 2.206638, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 571/655, Loss: 2.206830, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 572/655, Loss: 2.206765, Accuracy: 18.70%\n",
            "Epoch: 24, Step: 573/655, Loss: 2.206701, Accuracy: 18.70%\n",
            "Epoch: 24, Step: 574/655, Loss: 2.206823, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 575/655, Loss: 2.206813, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 576/655, Loss: 2.206955, Accuracy: 18.70%\n",
            "Epoch: 24, Step: 577/655, Loss: 2.206795, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 578/655, Loss: 2.206890, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 579/655, Loss: 2.206613, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 580/655, Loss: 2.206643, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 581/655, Loss: 2.206789, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 582/655, Loss: 2.206825, Accuracy: 18.77%\n",
            "Epoch: 24, Step: 583/655, Loss: 2.207012, Accuracy: 18.76%\n",
            "Epoch: 24, Step: 584/655, Loss: 2.207026, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 585/655, Loss: 2.207247, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 586/655, Loss: 2.207331, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 587/655, Loss: 2.207202, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 588/655, Loss: 2.207205, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 589/655, Loss: 2.207211, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 590/655, Loss: 2.207343, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 591/655, Loss: 2.207205, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 592/655, Loss: 2.207206, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 593/655, Loss: 2.207352, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 594/655, Loss: 2.207340, Accuracy: 18.70%\n",
            "Epoch: 24, Step: 595/655, Loss: 2.207267, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 596/655, Loss: 2.207179, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 597/655, Loss: 2.207086, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 598/655, Loss: 2.207051, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 599/655, Loss: 2.207014, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 600/655, Loss: 2.207066, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 601/655, Loss: 2.207119, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 602/655, Loss: 2.207068, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 603/655, Loss: 2.206995, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 604/655, Loss: 2.207111, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 605/655, Loss: 2.207017, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 606/655, Loss: 2.207197, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 607/655, Loss: 2.207053, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 608/655, Loss: 2.206771, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 609/655, Loss: 2.206678, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 610/655, Loss: 2.206962, Accuracy: 18.74%\n",
            "Epoch: 24, Step: 611/655, Loss: 2.206937, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 612/655, Loss: 2.207018, Accuracy: 18.75%\n",
            "Epoch: 24, Step: 613/655, Loss: 2.207264, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 614/655, Loss: 2.207226, Accuracy: 18.73%\n",
            "Epoch: 24, Step: 615/655, Loss: 2.207274, Accuracy: 18.72%\n",
            "Epoch: 24, Step: 616/655, Loss: 2.207468, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 617/655, Loss: 2.207546, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 618/655, Loss: 2.207604, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 619/655, Loss: 2.207494, Accuracy: 18.71%\n",
            "Epoch: 24, Step: 620/655, Loss: 2.207411, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 621/655, Loss: 2.207499, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 622/655, Loss: 2.207456, Accuracy: 18.69%\n",
            "Epoch: 24, Step: 623/655, Loss: 2.207614, Accuracy: 18.67%\n",
            "Epoch: 24, Step: 624/655, Loss: 2.207747, Accuracy: 18.65%\n",
            "Epoch: 24, Step: 625/655, Loss: 2.207767, Accuracy: 18.65%\n",
            "Epoch: 24, Step: 626/655, Loss: 2.207641, Accuracy: 18.64%\n",
            "Epoch: 24, Step: 627/655, Loss: 2.207767, Accuracy: 18.63%\n",
            "Epoch: 24, Step: 628/655, Loss: 2.207788, Accuracy: 18.63%\n",
            "Epoch: 24, Step: 629/655, Loss: 2.207810, Accuracy: 18.62%\n",
            "Epoch: 24, Step: 630/655, Loss: 2.207627, Accuracy: 18.63%\n",
            "Epoch: 24, Step: 631/655, Loss: 2.207546, Accuracy: 18.63%\n",
            "Epoch: 24, Step: 632/655, Loss: 2.207718, Accuracy: 18.60%\n",
            "Epoch: 24, Step: 633/655, Loss: 2.207554, Accuracy: 18.61%\n",
            "Epoch: 24, Step: 634/655, Loss: 2.207537, Accuracy: 18.62%\n",
            "Epoch: 24, Step: 635/655, Loss: 2.207528, Accuracy: 18.62%\n",
            "Epoch: 24, Step: 636/655, Loss: 2.207528, Accuracy: 18.62%\n",
            "Epoch: 24, Step: 637/655, Loss: 2.207427, Accuracy: 18.63%\n",
            "Epoch: 24, Step: 638/655, Loss: 2.207348, Accuracy: 18.63%\n",
            "Epoch: 24, Step: 639/655, Loss: 2.207655, Accuracy: 18.62%\n",
            "Epoch: 24, Step: 640/655, Loss: 2.207629, Accuracy: 18.61%\n",
            "Epoch: 24, Step: 641/655, Loss: 2.207590, Accuracy: 18.62%\n",
            "Epoch: 24, Step: 642/655, Loss: 2.207582, Accuracy: 18.63%\n",
            "Epoch: 24, Step: 643/655, Loss: 2.207728, Accuracy: 18.64%\n",
            "Epoch: 24, Step: 644/655, Loss: 2.207701, Accuracy: 18.65%\n",
            "Epoch: 24, Step: 645/655, Loss: 2.207654, Accuracy: 18.64%\n",
            "Epoch: 24, Step: 646/655, Loss: 2.207844, Accuracy: 18.62%\n",
            "Epoch: 24, Step: 647/655, Loss: 2.207995, Accuracy: 18.61%\n",
            "Epoch: 24, Step: 648/655, Loss: 2.208058, Accuracy: 18.61%\n",
            "Epoch: 24, Step: 649/655, Loss: 2.208204, Accuracy: 18.61%\n",
            "Epoch: 24, Step: 650/655, Loss: 2.207990, Accuracy: 18.62%\n",
            "Epoch: 24, Step: 651/655, Loss: 2.208070, Accuracy: 18.62%\n",
            "Epoch: 24, Step: 652/655, Loss: 2.207996, Accuracy: 18.63%\n",
            "Epoch: 24, Step: 653/655, Loss: 2.208007, Accuracy: 18.63%\n",
            "Epoch: 24, Step: 654/655, Loss: 2.207808, Accuracy: 18.64%\n",
            "Epoch: 24, Step: 655/655, Loss: 2.207911, Accuracy: 18.64%\n",
            "Epoch: 25, Step: 1/655, Loss: 2.214138, Accuracy: 18.75%\n",
            "Epoch: 25, Step: 2/655, Loss: 2.180466, Accuracy: 18.75%\n",
            "Epoch: 25, Step: 3/655, Loss: 2.198383, Accuracy: 18.75%\n",
            "Epoch: 25, Step: 4/655, Loss: 2.193652, Accuracy: 18.75%\n",
            "Epoch: 25, Step: 5/655, Loss: 2.179612, Accuracy: 18.12%\n",
            "Epoch: 25, Step: 6/655, Loss: 2.157639, Accuracy: 17.19%\n",
            "Epoch: 25, Step: 7/655, Loss: 2.152488, Accuracy: 18.30%\n",
            "Epoch: 25, Step: 8/655, Loss: 2.161902, Accuracy: 17.97%\n",
            "Epoch: 25, Step: 9/655, Loss: 2.164291, Accuracy: 19.10%\n",
            "Epoch: 25, Step: 10/655, Loss: 2.170806, Accuracy: 19.38%\n",
            "Epoch: 25, Step: 11/655, Loss: 2.181488, Accuracy: 18.47%\n",
            "Epoch: 25, Step: 12/655, Loss: 2.184262, Accuracy: 18.75%\n",
            "Epoch: 25, Step: 13/655, Loss: 2.190480, Accuracy: 18.51%\n",
            "Epoch: 25, Step: 14/655, Loss: 2.191146, Accuracy: 18.53%\n",
            "Epoch: 25, Step: 15/655, Loss: 2.199061, Accuracy: 18.12%\n",
            "Epoch: 25, Step: 16/655, Loss: 2.202563, Accuracy: 18.16%\n",
            "Epoch: 25, Step: 17/655, Loss: 2.206112, Accuracy: 18.75%\n",
            "Epoch: 25, Step: 18/655, Loss: 2.214630, Accuracy: 18.58%\n",
            "Epoch: 25, Step: 19/655, Loss: 2.217310, Accuracy: 18.59%\n",
            "Epoch: 25, Step: 20/655, Loss: 2.223807, Accuracy: 18.12%\n",
            "Epoch: 25, Step: 21/655, Loss: 2.223399, Accuracy: 18.30%\n",
            "Epoch: 25, Step: 22/655, Loss: 2.222778, Accuracy: 18.18%\n",
            "Epoch: 25, Step: 23/655, Loss: 2.223265, Accuracy: 18.21%\n",
            "Epoch: 25, Step: 24/655, Loss: 2.219001, Accuracy: 18.75%\n",
            "Epoch: 25, Step: 25/655, Loss: 2.215718, Accuracy: 18.75%\n",
            "Epoch: 25, Step: 26/655, Loss: 2.219562, Accuracy: 18.27%\n",
            "Epoch: 25, Step: 27/655, Loss: 2.217231, Accuracy: 18.06%\n",
            "Epoch: 25, Step: 28/655, Loss: 2.217530, Accuracy: 17.86%\n",
            "Epoch: 25, Step: 29/655, Loss: 2.216211, Accuracy: 18.00%\n",
            "Epoch: 25, Step: 30/655, Loss: 2.210745, Accuracy: 18.65%\n",
            "Epoch: 25, Step: 31/655, Loss: 2.208714, Accuracy: 18.65%\n",
            "Epoch: 25, Step: 32/655, Loss: 2.209288, Accuracy: 18.75%\n",
            "Epoch: 25, Step: 33/655, Loss: 2.210028, Accuracy: 18.75%\n",
            "Epoch: 25, Step: 34/655, Loss: 2.204359, Accuracy: 19.30%\n",
            "Epoch: 25, Step: 35/655, Loss: 2.205923, Accuracy: 19.29%\n",
            "Epoch: 25, Step: 36/655, Loss: 2.203042, Accuracy: 19.27%\n",
            "Epoch: 25, Step: 37/655, Loss: 2.201969, Accuracy: 19.26%\n",
            "Epoch: 25, Step: 38/655, Loss: 2.203973, Accuracy: 18.83%\n",
            "Epoch: 25, Step: 39/655, Loss: 2.204938, Accuracy: 18.83%\n",
            "Epoch: 25, Step: 40/655, Loss: 2.200171, Accuracy: 18.91%\n",
            "Epoch: 25, Step: 41/655, Loss: 2.202321, Accuracy: 19.05%\n",
            "Epoch: 25, Step: 42/655, Loss: 2.203198, Accuracy: 18.75%\n",
            "Epoch: 25, Step: 43/655, Loss: 2.204843, Accuracy: 18.75%\n",
            "Epoch: 25, Step: 44/655, Loss: 2.202712, Accuracy: 18.89%\n",
            "Epoch: 25, Step: 45/655, Loss: 2.203294, Accuracy: 18.68%\n",
            "Epoch: 25, Step: 46/655, Loss: 2.204347, Accuracy: 18.61%\n",
            "Epoch: 25, Step: 47/655, Loss: 2.201846, Accuracy: 18.68%\n",
            "Epoch: 25, Step: 48/655, Loss: 2.199828, Accuracy: 18.75%\n",
            "Epoch: 25, Step: 49/655, Loss: 2.196540, Accuracy: 18.81%\n",
            "Epoch: 25, Step: 50/655, Loss: 2.196868, Accuracy: 18.94%\n",
            "Epoch: 25, Step: 51/655, Loss: 2.196007, Accuracy: 19.00%\n",
            "Epoch: 25, Step: 52/655, Loss: 2.197241, Accuracy: 18.87%\n",
            "Epoch: 25, Step: 53/655, Loss: 2.200288, Accuracy: 18.63%\n",
            "Epoch: 25, Step: 54/655, Loss: 2.199613, Accuracy: 18.58%\n",
            "Epoch: 25, Step: 55/655, Loss: 2.202641, Accuracy: 18.41%\n",
            "Epoch: 25, Step: 56/655, Loss: 2.203118, Accuracy: 18.36%\n",
            "Epoch: 25, Step: 57/655, Loss: 2.201845, Accuracy: 18.26%\n",
            "Epoch: 25, Step: 58/655, Loss: 2.200710, Accuracy: 18.27%\n",
            "Epoch: 25, Step: 59/655, Loss: 2.201624, Accuracy: 18.22%\n",
            "Epoch: 25, Step: 60/655, Loss: 2.202052, Accuracy: 18.18%\n",
            "Epoch: 25, Step: 61/655, Loss: 2.203138, Accuracy: 18.14%\n",
            "Epoch: 25, Step: 62/655, Loss: 2.203257, Accuracy: 18.30%\n",
            "Epoch: 25, Step: 63/655, Loss: 2.203200, Accuracy: 18.40%\n",
            "Epoch: 25, Step: 64/655, Loss: 2.203581, Accuracy: 18.31%\n",
            "Epoch: 25, Step: 65/655, Loss: 2.205778, Accuracy: 18.32%\n",
            "Epoch: 25, Step: 66/655, Loss: 2.206207, Accuracy: 18.42%\n",
            "Epoch: 25, Step: 67/655, Loss: 2.207904, Accuracy: 18.38%\n",
            "Epoch: 25, Step: 68/655, Loss: 2.205413, Accuracy: 18.70%\n",
            "Epoch: 25, Step: 69/655, Loss: 2.205912, Accuracy: 18.70%\n",
            "Epoch: 25, Step: 70/655, Loss: 2.205588, Accuracy: 18.62%\n",
            "Epoch: 25, Step: 71/655, Loss: 2.205133, Accuracy: 18.66%\n",
            "Epoch: 25, Step: 72/655, Loss: 2.206921, Accuracy: 18.53%\n",
            "Epoch: 25, Step: 73/655, Loss: 2.205451, Accuracy: 18.58%\n",
            "Epoch: 25, Step: 74/655, Loss: 2.204232, Accuracy: 18.67%\n",
            "Epoch: 25, Step: 75/655, Loss: 2.202560, Accuracy: 18.71%\n",
            "Epoch: 25, Step: 76/655, Loss: 2.204124, Accuracy: 18.63%\n",
            "Epoch: 25, Step: 77/655, Loss: 2.205015, Accuracy: 18.51%\n",
            "Epoch: 25, Step: 78/655, Loss: 2.206375, Accuracy: 18.47%\n",
            "Epoch: 25, Step: 79/655, Loss: 2.206156, Accuracy: 18.43%\n",
            "Epoch: 25, Step: 80/655, Loss: 2.206088, Accuracy: 18.36%\n",
            "Epoch: 25, Step: 81/655, Loss: 2.206528, Accuracy: 18.21%\n",
            "Epoch: 25, Step: 82/655, Loss: 2.207806, Accuracy: 18.10%\n",
            "Epoch: 25, Step: 83/655, Loss: 2.207576, Accuracy: 18.11%\n",
            "Epoch: 25, Step: 84/655, Loss: 2.207156, Accuracy: 18.12%\n",
            "Epoch: 25, Step: 85/655, Loss: 2.208367, Accuracy: 18.09%\n",
            "Epoch: 25, Step: 86/655, Loss: 2.207770, Accuracy: 18.24%\n",
            "Epoch: 25, Step: 87/655, Loss: 2.209202, Accuracy: 18.25%\n",
            "Epoch: 25, Step: 88/655, Loss: 2.208296, Accuracy: 18.39%\n",
            "Epoch: 25, Step: 89/655, Loss: 2.207633, Accuracy: 18.47%\n",
            "Epoch: 25, Step: 90/655, Loss: 2.207866, Accuracy: 18.44%\n",
            "Epoch: 25, Step: 91/655, Loss: 2.209133, Accuracy: 18.48%\n",
            "Epoch: 25, Step: 92/655, Loss: 2.211119, Accuracy: 18.41%\n",
            "Epoch: 25, Step: 93/655, Loss: 2.211246, Accuracy: 18.41%\n",
            "Epoch: 25, Step: 94/655, Loss: 2.210377, Accuracy: 18.38%\n",
            "Epoch: 25, Step: 95/655, Loss: 2.211223, Accuracy: 18.29%\n",
            "Epoch: 25, Step: 96/655, Loss: 2.210943, Accuracy: 18.33%\n",
            "Epoch: 25, Step: 97/655, Loss: 2.209799, Accuracy: 18.43%\n",
            "Epoch: 25, Step: 98/655, Loss: 2.211425, Accuracy: 18.30%\n",
            "Epoch: 25, Step: 99/655, Loss: 2.210745, Accuracy: 18.40%\n",
            "Epoch: 25, Step: 100/655, Loss: 2.208556, Accuracy: 18.50%\n",
            "Epoch: 25, Step: 101/655, Loss: 2.208368, Accuracy: 18.53%\n",
            "Epoch: 25, Step: 102/655, Loss: 2.208357, Accuracy: 18.57%\n",
            "Epoch: 25, Step: 103/655, Loss: 2.207914, Accuracy: 18.72%\n",
            "Epoch: 25, Step: 104/655, Loss: 2.209310, Accuracy: 18.66%\n",
            "Epoch: 25, Step: 105/655, Loss: 2.208640, Accuracy: 18.72%\n",
            "Epoch: 25, Step: 106/655, Loss: 2.208815, Accuracy: 18.69%\n",
            "Epoch: 25, Step: 107/655, Loss: 2.208522, Accuracy: 18.72%\n",
            "Epoch: 25, Step: 108/655, Loss: 2.208817, Accuracy: 18.69%\n",
            "Epoch: 25, Step: 109/655, Loss: 2.209257, Accuracy: 18.55%\n",
            "Epoch: 25, Step: 110/655, Loss: 2.209012, Accuracy: 18.55%\n",
            "Epoch: 25, Step: 111/655, Loss: 2.208772, Accuracy: 18.52%\n",
            "Epoch: 25, Step: 112/655, Loss: 2.208515, Accuracy: 18.53%\n",
            "Epoch: 25, Step: 113/655, Loss: 2.208202, Accuracy: 18.58%\n",
            "Epoch: 25, Step: 114/655, Loss: 2.208868, Accuracy: 18.53%\n",
            "Epoch: 25, Step: 115/655, Loss: 2.209218, Accuracy: 18.45%\n",
            "Epoch: 25, Step: 116/655, Loss: 2.208686, Accuracy: 18.43%\n",
            "Epoch: 25, Step: 117/655, Loss: 2.209252, Accuracy: 18.35%\n",
            "Epoch: 25, Step: 118/655, Loss: 2.209173, Accuracy: 18.35%\n",
            "Epoch: 25, Step: 119/655, Loss: 2.208955, Accuracy: 18.49%\n",
            "Epoch: 25, Step: 120/655, Loss: 2.209376, Accuracy: 18.41%\n",
            "Epoch: 25, Step: 121/655, Loss: 2.209424, Accuracy: 18.49%\n",
            "Epoch: 25, Step: 122/655, Loss: 2.209005, Accuracy: 18.55%\n",
            "Epoch: 25, Step: 123/655, Loss: 2.209286, Accuracy: 18.50%\n",
            "Epoch: 25, Step: 124/655, Loss: 2.208871, Accuracy: 18.50%\n",
            "Epoch: 25, Step: 125/655, Loss: 2.208342, Accuracy: 18.55%\n",
            "Epoch: 25, Step: 126/655, Loss: 2.208840, Accuracy: 18.55%\n",
            "Epoch: 25, Step: 127/655, Loss: 2.208259, Accuracy: 18.63%\n",
            "Epoch: 25, Step: 128/655, Loss: 2.209071, Accuracy: 18.63%\n",
            "Epoch: 25, Step: 129/655, Loss: 2.208995, Accuracy: 18.63%\n",
            "Epoch: 25, Step: 130/655, Loss: 2.208968, Accuracy: 18.61%\n",
            "Epoch: 25, Step: 131/655, Loss: 2.208095, Accuracy: 18.70%\n",
            "Epoch: 25, Step: 132/655, Loss: 2.207566, Accuracy: 18.73%\n",
            "Epoch: 25, Step: 133/655, Loss: 2.206569, Accuracy: 18.70%\n",
            "Epoch: 25, Step: 134/655, Loss: 2.206118, Accuracy: 18.66%\n",
            "Epoch: 25, Step: 135/655, Loss: 2.206972, Accuracy: 18.61%\n",
            "Epoch: 25, Step: 136/655, Loss: 2.207812, Accuracy: 18.54%\n",
            "Epoch: 25, Step: 137/655, Loss: 2.207818, Accuracy: 18.50%\n",
            "Epoch: 25, Step: 138/655, Loss: 2.208098, Accuracy: 18.52%\n",
            "Epoch: 25, Step: 139/655, Loss: 2.208829, Accuracy: 18.50%\n",
            "Epoch: 25, Step: 140/655, Loss: 2.208849, Accuracy: 18.48%\n",
            "Epoch: 25, Step: 141/655, Loss: 2.209472, Accuracy: 18.37%\n",
            "Epoch: 25, Step: 142/655, Loss: 2.209244, Accuracy: 18.31%\n",
            "Epoch: 25, Step: 143/655, Loss: 2.208442, Accuracy: 18.31%\n",
            "Epoch: 25, Step: 144/655, Loss: 2.208199, Accuracy: 18.36%\n",
            "Epoch: 25, Step: 145/655, Loss: 2.207634, Accuracy: 18.41%\n",
            "Epoch: 25, Step: 146/655, Loss: 2.207408, Accuracy: 18.43%\n",
            "Epoch: 25, Step: 147/655, Loss: 2.207110, Accuracy: 18.41%\n",
            "Epoch: 25, Step: 148/655, Loss: 2.206594, Accuracy: 18.45%\n",
            "Epoch: 25, Step: 149/655, Loss: 2.207199, Accuracy: 18.35%\n",
            "Epoch: 25, Step: 150/655, Loss: 2.207157, Accuracy: 18.38%\n",
            "Epoch: 25, Step: 151/655, Loss: 2.207305, Accuracy: 18.34%\n",
            "Epoch: 25, Step: 152/655, Loss: 2.208088, Accuracy: 18.34%\n",
            "Epoch: 25, Step: 153/655, Loss: 2.208333, Accuracy: 18.30%\n",
            "Epoch: 25, Step: 154/655, Loss: 2.208316, Accuracy: 18.28%\n",
            "Epoch: 25, Step: 155/655, Loss: 2.208024, Accuracy: 18.29%\n",
            "Epoch: 25, Step: 156/655, Loss: 2.208975, Accuracy: 18.21%\n",
            "Epoch: 25, Step: 157/655, Loss: 2.209167, Accuracy: 18.23%\n",
            "Epoch: 25, Step: 158/655, Loss: 2.209438, Accuracy: 18.22%\n",
            "Epoch: 25, Step: 159/655, Loss: 2.208615, Accuracy: 18.26%\n",
            "Epoch: 25, Step: 160/655, Loss: 2.208538, Accuracy: 18.26%\n",
            "Epoch: 25, Step: 161/655, Loss: 2.208315, Accuracy: 18.25%\n",
            "Epoch: 25, Step: 162/655, Loss: 2.208434, Accuracy: 18.25%\n",
            "Epoch: 25, Step: 163/655, Loss: 2.208289, Accuracy: 18.27%\n",
            "Epoch: 25, Step: 164/655, Loss: 2.208284, Accuracy: 18.25%\n",
            "Epoch: 25, Step: 165/655, Loss: 2.208280, Accuracy: 18.24%\n",
            "Epoch: 25, Step: 166/655, Loss: 2.207521, Accuracy: 18.30%\n",
            "Epoch: 25, Step: 167/655, Loss: 2.207038, Accuracy: 18.36%\n",
            "Epoch: 25, Step: 168/655, Loss: 2.206906, Accuracy: 18.34%\n",
            "Epoch: 25, Step: 169/655, Loss: 2.206479, Accuracy: 18.36%\n",
            "Epoch: 25, Step: 170/655, Loss: 2.206120, Accuracy: 18.36%\n",
            "Epoch: 25, Step: 171/655, Loss: 2.206550, Accuracy: 18.33%\n",
            "Epoch: 25, Step: 172/655, Loss: 2.206532, Accuracy: 18.35%\n",
            "Epoch: 25, Step: 173/655, Loss: 2.206321, Accuracy: 18.33%\n",
            "Epoch: 25, Step: 174/655, Loss: 2.206307, Accuracy: 18.37%\n",
            "Epoch: 25, Step: 175/655, Loss: 2.206036, Accuracy: 18.39%\n",
            "Epoch: 25, Step: 176/655, Loss: 2.205640, Accuracy: 18.39%\n",
            "Epoch: 25, Step: 177/655, Loss: 2.206289, Accuracy: 18.36%\n",
            "Epoch: 25, Step: 178/655, Loss: 2.206494, Accuracy: 18.36%\n",
            "Epoch: 25, Step: 179/655, Loss: 2.206654, Accuracy: 18.40%\n",
            "Epoch: 25, Step: 180/655, Loss: 2.206709, Accuracy: 18.42%\n",
            "Epoch: 25, Step: 181/655, Loss: 2.207509, Accuracy: 18.34%\n",
            "Epoch: 25, Step: 182/655, Loss: 2.206947, Accuracy: 18.32%\n",
            "Epoch: 25, Step: 183/655, Loss: 2.206655, Accuracy: 18.31%\n",
            "Epoch: 25, Step: 184/655, Loss: 2.206125, Accuracy: 18.31%\n",
            "Epoch: 25, Step: 185/655, Loss: 2.206186, Accuracy: 18.31%\n",
            "Epoch: 25, Step: 186/655, Loss: 2.206699, Accuracy: 18.36%\n",
            "Epoch: 25, Step: 187/655, Loss: 2.206585, Accuracy: 18.38%\n",
            "Epoch: 25, Step: 188/655, Loss: 2.205871, Accuracy: 18.47%\n",
            "Epoch: 25, Step: 189/655, Loss: 2.206371, Accuracy: 18.49%\n",
            "Epoch: 25, Step: 190/655, Loss: 2.206882, Accuracy: 18.42%\n",
            "Epoch: 25, Step: 191/655, Loss: 2.207665, Accuracy: 18.37%\n",
            "Epoch: 25, Step: 192/655, Loss: 2.207220, Accuracy: 18.42%\n",
            "Epoch: 25, Step: 193/655, Loss: 2.206854, Accuracy: 18.36%\n",
            "Epoch: 25, Step: 194/655, Loss: 2.207327, Accuracy: 18.32%\n",
            "Epoch: 25, Step: 195/655, Loss: 2.208058, Accuracy: 18.25%\n",
            "Epoch: 25, Step: 196/655, Loss: 2.207796, Accuracy: 18.29%\n",
            "Epoch: 25, Step: 197/655, Loss: 2.208112, Accuracy: 18.27%\n",
            "Epoch: 25, Step: 198/655, Loss: 2.208125, Accuracy: 18.29%\n",
            "Epoch: 25, Step: 199/655, Loss: 2.207726, Accuracy: 18.34%\n",
            "Epoch: 25, Step: 200/655, Loss: 2.208071, Accuracy: 18.31%\n",
            "Epoch: 25, Step: 201/655, Loss: 2.207816, Accuracy: 18.36%\n",
            "Epoch: 25, Step: 202/655, Loss: 2.208062, Accuracy: 18.33%\n",
            "Epoch: 25, Step: 203/655, Loss: 2.208768, Accuracy: 18.27%\n",
            "Epoch: 25, Step: 204/655, Loss: 2.208905, Accuracy: 18.23%\n",
            "Epoch: 25, Step: 205/655, Loss: 2.208290, Accuracy: 18.31%\n",
            "Epoch: 25, Step: 206/655, Loss: 2.208499, Accuracy: 18.29%\n",
            "Epoch: 25, Step: 207/655, Loss: 2.208202, Accuracy: 18.31%\n",
            "Epoch: 25, Step: 208/655, Loss: 2.208257, Accuracy: 18.31%\n",
            "Epoch: 25, Step: 209/655, Loss: 2.208059, Accuracy: 18.32%\n",
            "Epoch: 25, Step: 210/655, Loss: 2.208061, Accuracy: 18.30%\n",
            "Epoch: 25, Step: 211/655, Loss: 2.207599, Accuracy: 18.31%\n",
            "Epoch: 25, Step: 212/655, Loss: 2.207712, Accuracy: 18.31%\n",
            "Epoch: 25, Step: 213/655, Loss: 2.208519, Accuracy: 18.25%\n",
            "Epoch: 25, Step: 214/655, Loss: 2.208058, Accuracy: 18.22%\n",
            "Epoch: 25, Step: 215/655, Loss: 2.208032, Accuracy: 18.24%\n",
            "Epoch: 25, Step: 216/655, Loss: 2.208273, Accuracy: 18.19%\n",
            "Epoch: 25, Step: 217/655, Loss: 2.208520, Accuracy: 18.15%\n",
            "Epoch: 25, Step: 218/655, Loss: 2.208612, Accuracy: 18.09%\n",
            "Epoch: 25, Step: 219/655, Loss: 2.208660, Accuracy: 18.12%\n",
            "Epoch: 25, Step: 220/655, Loss: 2.208159, Accuracy: 18.10%\n",
            "Epoch: 25, Step: 221/655, Loss: 2.207910, Accuracy: 18.10%\n",
            "Epoch: 25, Step: 222/655, Loss: 2.207794, Accuracy: 18.09%\n",
            "Epoch: 25, Step: 223/655, Loss: 2.207801, Accuracy: 18.09%\n",
            "Epoch: 25, Step: 224/655, Loss: 2.207562, Accuracy: 18.11%\n",
            "Epoch: 25, Step: 225/655, Loss: 2.207793, Accuracy: 18.10%\n",
            "Epoch: 25, Step: 226/655, Loss: 2.207872, Accuracy: 18.09%\n",
            "Epoch: 25, Step: 227/655, Loss: 2.207814, Accuracy: 18.08%\n",
            "Epoch: 25, Step: 228/655, Loss: 2.208073, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 229/655, Loss: 2.207848, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 230/655, Loss: 2.208149, Accuracy: 18.07%\n",
            "Epoch: 25, Step: 231/655, Loss: 2.207663, Accuracy: 18.10%\n",
            "Epoch: 25, Step: 232/655, Loss: 2.207218, Accuracy: 18.09%\n",
            "Epoch: 25, Step: 233/655, Loss: 2.207437, Accuracy: 18.09%\n",
            "Epoch: 25, Step: 234/655, Loss: 2.207881, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 235/655, Loss: 2.207568, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 236/655, Loss: 2.207712, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 237/655, Loss: 2.207032, Accuracy: 18.08%\n",
            "Epoch: 25, Step: 238/655, Loss: 2.207254, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 239/655, Loss: 2.207226, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 240/655, Loss: 2.207420, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 241/655, Loss: 2.207715, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 242/655, Loss: 2.208506, Accuracy: 17.95%\n",
            "Epoch: 25, Step: 243/655, Loss: 2.208536, Accuracy: 17.94%\n",
            "Epoch: 25, Step: 244/655, Loss: 2.207958, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 245/655, Loss: 2.208169, Accuracy: 17.95%\n",
            "Epoch: 25, Step: 246/655, Loss: 2.207379, Accuracy: 18.00%\n",
            "Epoch: 25, Step: 247/655, Loss: 2.207223, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 248/655, Loss: 2.207756, Accuracy: 17.98%\n",
            "Epoch: 25, Step: 249/655, Loss: 2.207316, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 250/655, Loss: 2.207869, Accuracy: 17.96%\n",
            "Epoch: 25, Step: 251/655, Loss: 2.207530, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 252/655, Loss: 2.207574, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 253/655, Loss: 2.207416, Accuracy: 17.96%\n",
            "Epoch: 25, Step: 254/655, Loss: 2.207607, Accuracy: 17.97%\n",
            "Epoch: 25, Step: 255/655, Loss: 2.207222, Accuracy: 18.00%\n",
            "Epoch: 25, Step: 256/655, Loss: 2.207513, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 257/655, Loss: 2.207469, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 258/655, Loss: 2.207448, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 259/655, Loss: 2.207985, Accuracy: 18.00%\n",
            "Epoch: 25, Step: 260/655, Loss: 2.208492, Accuracy: 17.98%\n",
            "Epoch: 25, Step: 261/655, Loss: 2.208156, Accuracy: 17.98%\n",
            "Epoch: 25, Step: 262/655, Loss: 2.208746, Accuracy: 17.94%\n",
            "Epoch: 25, Step: 263/655, Loss: 2.208474, Accuracy: 17.95%\n",
            "Epoch: 25, Step: 264/655, Loss: 2.208482, Accuracy: 17.98%\n",
            "Epoch: 25, Step: 265/655, Loss: 2.208482, Accuracy: 17.98%\n",
            "Epoch: 25, Step: 266/655, Loss: 2.208711, Accuracy: 17.96%\n",
            "Epoch: 25, Step: 267/655, Loss: 2.208570, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 268/655, Loss: 2.208758, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 269/655, Loss: 2.208608, Accuracy: 17.95%\n",
            "Epoch: 25, Step: 270/655, Loss: 2.208472, Accuracy: 17.97%\n",
            "Epoch: 25, Step: 271/655, Loss: 2.208646, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 272/655, Loss: 2.209084, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 273/655, Loss: 2.208861, Accuracy: 17.96%\n",
            "Epoch: 25, Step: 274/655, Loss: 2.209149, Accuracy: 17.97%\n",
            "Epoch: 25, Step: 275/655, Loss: 2.209106, Accuracy: 17.99%\n",
            "Epoch: 25, Step: 276/655, Loss: 2.208457, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 277/655, Loss: 2.208488, Accuracy: 17.99%\n",
            "Epoch: 25, Step: 278/655, Loss: 2.207999, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 279/655, Loss: 2.207677, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 280/655, Loss: 2.207594, Accuracy: 18.06%\n",
            "Epoch: 25, Step: 281/655, Loss: 2.207896, Accuracy: 18.06%\n",
            "Epoch: 25, Step: 282/655, Loss: 2.208185, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 283/655, Loss: 2.208253, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 284/655, Loss: 2.208871, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 285/655, Loss: 2.209120, Accuracy: 17.99%\n",
            "Epoch: 25, Step: 286/655, Loss: 2.209391, Accuracy: 17.97%\n",
            "Epoch: 25, Step: 287/655, Loss: 2.209473, Accuracy: 17.94%\n",
            "Epoch: 25, Step: 288/655, Loss: 2.209374, Accuracy: 17.91%\n",
            "Epoch: 25, Step: 289/655, Loss: 2.209643, Accuracy: 17.87%\n",
            "Epoch: 25, Step: 290/655, Loss: 2.209611, Accuracy: 17.88%\n",
            "Epoch: 25, Step: 291/655, Loss: 2.209609, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 292/655, Loss: 2.210007, Accuracy: 17.87%\n",
            "Epoch: 25, Step: 293/655, Loss: 2.210165, Accuracy: 17.85%\n",
            "Epoch: 25, Step: 294/655, Loss: 2.210054, Accuracy: 17.85%\n",
            "Epoch: 25, Step: 295/655, Loss: 2.209696, Accuracy: 17.85%\n",
            "Epoch: 25, Step: 296/655, Loss: 2.209823, Accuracy: 17.82%\n",
            "Epoch: 25, Step: 297/655, Loss: 2.210325, Accuracy: 17.79%\n",
            "Epoch: 25, Step: 298/655, Loss: 2.209887, Accuracy: 17.81%\n",
            "Epoch: 25, Step: 299/655, Loss: 2.210149, Accuracy: 17.78%\n",
            "Epoch: 25, Step: 300/655, Loss: 2.210103, Accuracy: 17.78%\n",
            "Epoch: 25, Step: 301/655, Loss: 2.210152, Accuracy: 17.81%\n",
            "Epoch: 25, Step: 302/655, Loss: 2.210385, Accuracy: 17.76%\n",
            "Epoch: 25, Step: 303/655, Loss: 2.210389, Accuracy: 17.75%\n",
            "Epoch: 25, Step: 304/655, Loss: 2.210402, Accuracy: 17.75%\n",
            "Epoch: 25, Step: 305/655, Loss: 2.210411, Accuracy: 17.79%\n",
            "Epoch: 25, Step: 306/655, Loss: 2.210496, Accuracy: 17.77%\n",
            "Epoch: 25, Step: 307/655, Loss: 2.210246, Accuracy: 17.79%\n",
            "Epoch: 25, Step: 308/655, Loss: 2.210274, Accuracy: 17.80%\n",
            "Epoch: 25, Step: 309/655, Loss: 2.209971, Accuracy: 17.77%\n",
            "Epoch: 25, Step: 310/655, Loss: 2.210235, Accuracy: 17.75%\n",
            "Epoch: 25, Step: 311/655, Loss: 2.210162, Accuracy: 17.75%\n",
            "Epoch: 25, Step: 312/655, Loss: 2.210107, Accuracy: 17.76%\n",
            "Epoch: 25, Step: 313/655, Loss: 2.210497, Accuracy: 17.73%\n",
            "Epoch: 25, Step: 314/655, Loss: 2.210345, Accuracy: 17.73%\n",
            "Epoch: 25, Step: 315/655, Loss: 2.210225, Accuracy: 17.73%\n",
            "Epoch: 25, Step: 316/655, Loss: 2.210333, Accuracy: 17.70%\n",
            "Epoch: 25, Step: 317/655, Loss: 2.210147, Accuracy: 17.68%\n",
            "Epoch: 25, Step: 318/655, Loss: 2.209820, Accuracy: 17.69%\n",
            "Epoch: 25, Step: 319/655, Loss: 2.209825, Accuracy: 17.72%\n",
            "Epoch: 25, Step: 320/655, Loss: 2.209916, Accuracy: 17.71%\n",
            "Epoch: 25, Step: 321/655, Loss: 2.210426, Accuracy: 17.69%\n",
            "Epoch: 25, Step: 322/655, Loss: 2.210737, Accuracy: 17.68%\n",
            "Epoch: 25, Step: 323/655, Loss: 2.210381, Accuracy: 17.69%\n",
            "Epoch: 25, Step: 324/655, Loss: 2.210338, Accuracy: 17.67%\n",
            "Epoch: 25, Step: 325/655, Loss: 2.210562, Accuracy: 17.67%\n",
            "Epoch: 25, Step: 326/655, Loss: 2.210500, Accuracy: 17.63%\n",
            "Epoch: 25, Step: 327/655, Loss: 2.211080, Accuracy: 17.60%\n",
            "Epoch: 25, Step: 328/655, Loss: 2.211396, Accuracy: 17.58%\n",
            "Epoch: 25, Step: 329/655, Loss: 2.211649, Accuracy: 17.56%\n",
            "Epoch: 25, Step: 330/655, Loss: 2.211655, Accuracy: 17.56%\n",
            "Epoch: 25, Step: 331/655, Loss: 2.211354, Accuracy: 17.58%\n",
            "Epoch: 25, Step: 332/655, Loss: 2.211450, Accuracy: 17.58%\n",
            "Epoch: 25, Step: 333/655, Loss: 2.211337, Accuracy: 17.60%\n",
            "Epoch: 25, Step: 334/655, Loss: 2.211118, Accuracy: 17.62%\n",
            "Epoch: 25, Step: 335/655, Loss: 2.210867, Accuracy: 17.60%\n",
            "Epoch: 25, Step: 336/655, Loss: 2.210661, Accuracy: 17.63%\n",
            "Epoch: 25, Step: 337/655, Loss: 2.210654, Accuracy: 17.63%\n",
            "Epoch: 25, Step: 338/655, Loss: 2.210585, Accuracy: 17.63%\n",
            "Epoch: 25, Step: 339/655, Loss: 2.210298, Accuracy: 17.65%\n",
            "Epoch: 25, Step: 340/655, Loss: 2.210676, Accuracy: 17.63%\n",
            "Epoch: 25, Step: 341/655, Loss: 2.210887, Accuracy: 17.62%\n",
            "Epoch: 25, Step: 342/655, Loss: 2.210900, Accuracy: 17.61%\n",
            "Epoch: 25, Step: 343/655, Loss: 2.211032, Accuracy: 17.60%\n",
            "Epoch: 25, Step: 344/655, Loss: 2.211147, Accuracy: 17.61%\n",
            "Epoch: 25, Step: 345/655, Loss: 2.210799, Accuracy: 17.62%\n",
            "Epoch: 25, Step: 346/655, Loss: 2.210557, Accuracy: 17.63%\n",
            "Epoch: 25, Step: 347/655, Loss: 2.210468, Accuracy: 17.62%\n",
            "Epoch: 25, Step: 348/655, Loss: 2.210408, Accuracy: 17.62%\n",
            "Epoch: 25, Step: 349/655, Loss: 2.210482, Accuracy: 17.64%\n",
            "Epoch: 25, Step: 350/655, Loss: 2.210248, Accuracy: 17.65%\n",
            "Epoch: 25, Step: 351/655, Loss: 2.210168, Accuracy: 17.65%\n",
            "Epoch: 25, Step: 352/655, Loss: 2.209725, Accuracy: 17.68%\n",
            "Epoch: 25, Step: 353/655, Loss: 2.209840, Accuracy: 17.69%\n",
            "Epoch: 25, Step: 354/655, Loss: 2.209877, Accuracy: 17.68%\n",
            "Epoch: 25, Step: 355/655, Loss: 2.209849, Accuracy: 17.68%\n",
            "Epoch: 25, Step: 356/655, Loss: 2.209742, Accuracy: 17.69%\n",
            "Epoch: 25, Step: 357/655, Loss: 2.209785, Accuracy: 17.70%\n",
            "Epoch: 25, Step: 358/655, Loss: 2.209688, Accuracy: 17.72%\n",
            "Epoch: 25, Step: 359/655, Loss: 2.209791, Accuracy: 17.72%\n",
            "Epoch: 25, Step: 360/655, Loss: 2.209783, Accuracy: 17.73%\n",
            "Epoch: 25, Step: 361/655, Loss: 2.210024, Accuracy: 17.70%\n",
            "Epoch: 25, Step: 362/655, Loss: 2.210266, Accuracy: 17.71%\n",
            "Epoch: 25, Step: 363/655, Loss: 2.210092, Accuracy: 17.72%\n",
            "Epoch: 25, Step: 364/655, Loss: 2.210347, Accuracy: 17.71%\n",
            "Epoch: 25, Step: 365/655, Loss: 2.210609, Accuracy: 17.70%\n",
            "Epoch: 25, Step: 366/655, Loss: 2.210686, Accuracy: 17.71%\n",
            "Epoch: 25, Step: 367/655, Loss: 2.210381, Accuracy: 17.70%\n",
            "Epoch: 25, Step: 368/655, Loss: 2.210223, Accuracy: 17.74%\n",
            "Epoch: 25, Step: 369/655, Loss: 2.209809, Accuracy: 17.74%\n",
            "Epoch: 25, Step: 370/655, Loss: 2.209883, Accuracy: 17.73%\n",
            "Epoch: 25, Step: 371/655, Loss: 2.209666, Accuracy: 17.75%\n",
            "Epoch: 25, Step: 372/655, Loss: 2.209222, Accuracy: 17.80%\n",
            "Epoch: 25, Step: 373/655, Loss: 2.209268, Accuracy: 17.78%\n",
            "Epoch: 25, Step: 374/655, Loss: 2.209197, Accuracy: 17.77%\n",
            "Epoch: 25, Step: 375/655, Loss: 2.209075, Accuracy: 17.77%\n",
            "Epoch: 25, Step: 376/655, Loss: 2.208763, Accuracy: 17.79%\n",
            "Epoch: 25, Step: 377/655, Loss: 2.208699, Accuracy: 17.81%\n",
            "Epoch: 25, Step: 378/655, Loss: 2.208514, Accuracy: 17.81%\n",
            "Epoch: 25, Step: 379/655, Loss: 2.208127, Accuracy: 17.80%\n",
            "Epoch: 25, Step: 380/655, Loss: 2.208006, Accuracy: 17.80%\n",
            "Epoch: 25, Step: 381/655, Loss: 2.207834, Accuracy: 17.83%\n",
            "Epoch: 25, Step: 382/655, Loss: 2.207737, Accuracy: 17.84%\n",
            "Epoch: 25, Step: 383/655, Loss: 2.207885, Accuracy: 17.84%\n",
            "Epoch: 25, Step: 384/655, Loss: 2.208029, Accuracy: 17.86%\n",
            "Epoch: 25, Step: 385/655, Loss: 2.208122, Accuracy: 17.86%\n",
            "Epoch: 25, Step: 386/655, Loss: 2.207632, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 387/655, Loss: 2.207712, Accuracy: 17.91%\n",
            "Epoch: 25, Step: 388/655, Loss: 2.207410, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 389/655, Loss: 2.207217, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 390/655, Loss: 2.207010, Accuracy: 17.96%\n",
            "Epoch: 25, Step: 391/655, Loss: 2.206944, Accuracy: 17.98%\n",
            "Epoch: 25, Step: 392/655, Loss: 2.206860, Accuracy: 17.98%\n",
            "Epoch: 25, Step: 393/655, Loss: 2.207091, Accuracy: 17.98%\n",
            "Epoch: 25, Step: 394/655, Loss: 2.207422, Accuracy: 17.96%\n",
            "Epoch: 25, Step: 395/655, Loss: 2.207619, Accuracy: 17.95%\n",
            "Epoch: 25, Step: 396/655, Loss: 2.207857, Accuracy: 17.96%\n",
            "Epoch: 25, Step: 397/655, Loss: 2.207636, Accuracy: 17.95%\n",
            "Epoch: 25, Step: 398/655, Loss: 2.207524, Accuracy: 17.98%\n",
            "Epoch: 25, Step: 399/655, Loss: 2.207591, Accuracy: 17.99%\n",
            "Epoch: 25, Step: 400/655, Loss: 2.207802, Accuracy: 17.95%\n",
            "Epoch: 25, Step: 401/655, Loss: 2.207732, Accuracy: 17.95%\n",
            "Epoch: 25, Step: 402/655, Loss: 2.207967, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 403/655, Loss: 2.207698, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 404/655, Loss: 2.207679, Accuracy: 17.91%\n",
            "Epoch: 25, Step: 405/655, Loss: 2.207715, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 406/655, Loss: 2.207434, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 407/655, Loss: 2.207508, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 408/655, Loss: 2.207827, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 409/655, Loss: 2.207967, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 410/655, Loss: 2.208162, Accuracy: 17.87%\n",
            "Epoch: 25, Step: 411/655, Loss: 2.208182, Accuracy: 17.87%\n",
            "Epoch: 25, Step: 412/655, Loss: 2.208121, Accuracy: 17.87%\n",
            "Epoch: 25, Step: 413/655, Loss: 2.207910, Accuracy: 17.86%\n",
            "Epoch: 25, Step: 414/655, Loss: 2.207893, Accuracy: 17.85%\n",
            "Epoch: 25, Step: 415/655, Loss: 2.207832, Accuracy: 17.85%\n",
            "Epoch: 25, Step: 416/655, Loss: 2.207826, Accuracy: 17.84%\n",
            "Epoch: 25, Step: 417/655, Loss: 2.208147, Accuracy: 17.81%\n",
            "Epoch: 25, Step: 418/655, Loss: 2.208447, Accuracy: 17.80%\n",
            "Epoch: 25, Step: 419/655, Loss: 2.208534, Accuracy: 17.80%\n",
            "Epoch: 25, Step: 420/655, Loss: 2.208570, Accuracy: 17.81%\n",
            "Epoch: 25, Step: 421/655, Loss: 2.208337, Accuracy: 17.83%\n",
            "Epoch: 25, Step: 422/655, Loss: 2.208094, Accuracy: 17.85%\n",
            "Epoch: 25, Step: 423/655, Loss: 2.207817, Accuracy: 17.86%\n",
            "Epoch: 25, Step: 424/655, Loss: 2.207602, Accuracy: 17.89%\n",
            "Epoch: 25, Step: 425/655, Loss: 2.207695, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 426/655, Loss: 2.207815, Accuracy: 17.89%\n",
            "Epoch: 25, Step: 427/655, Loss: 2.207692, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 428/655, Loss: 2.207505, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 429/655, Loss: 2.207533, Accuracy: 17.88%\n",
            "Epoch: 25, Step: 430/655, Loss: 2.207407, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 431/655, Loss: 2.207271, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 432/655, Loss: 2.207445, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 433/655, Loss: 2.207505, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 434/655, Loss: 2.207386, Accuracy: 17.91%\n",
            "Epoch: 25, Step: 435/655, Loss: 2.207596, Accuracy: 17.91%\n",
            "Epoch: 25, Step: 436/655, Loss: 2.207552, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 437/655, Loss: 2.207062, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 438/655, Loss: 2.207028, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 439/655, Loss: 2.207308, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 440/655, Loss: 2.207416, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 441/655, Loss: 2.207211, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 442/655, Loss: 2.207311, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 443/655, Loss: 2.207512, Accuracy: 17.89%\n",
            "Epoch: 25, Step: 444/655, Loss: 2.207255, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 445/655, Loss: 2.207148, Accuracy: 17.89%\n",
            "Epoch: 25, Step: 446/655, Loss: 2.206897, Accuracy: 17.87%\n",
            "Epoch: 25, Step: 447/655, Loss: 2.206774, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 448/655, Loss: 2.206602, Accuracy: 17.91%\n",
            "Epoch: 25, Step: 449/655, Loss: 2.206684, Accuracy: 17.88%\n",
            "Epoch: 25, Step: 450/655, Loss: 2.206630, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 451/655, Loss: 2.206567, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 452/655, Loss: 2.207033, Accuracy: 17.89%\n",
            "Epoch: 25, Step: 453/655, Loss: 2.207172, Accuracy: 17.88%\n",
            "Epoch: 25, Step: 454/655, Loss: 2.207126, Accuracy: 17.88%\n",
            "Epoch: 25, Step: 455/655, Loss: 2.206905, Accuracy: 17.91%\n",
            "Epoch: 25, Step: 456/655, Loss: 2.207081, Accuracy: 17.89%\n",
            "Epoch: 25, Step: 457/655, Loss: 2.207277, Accuracy: 17.88%\n",
            "Epoch: 25, Step: 458/655, Loss: 2.207277, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 459/655, Loss: 2.207323, Accuracy: 17.89%\n",
            "Epoch: 25, Step: 460/655, Loss: 2.207381, Accuracy: 17.88%\n",
            "Epoch: 25, Step: 461/655, Loss: 2.207439, Accuracy: 17.89%\n",
            "Epoch: 25, Step: 462/655, Loss: 2.207206, Accuracy: 17.88%\n",
            "Epoch: 25, Step: 463/655, Loss: 2.206968, Accuracy: 17.87%\n",
            "Epoch: 25, Step: 464/655, Loss: 2.207105, Accuracy: 17.87%\n",
            "Epoch: 25, Step: 465/655, Loss: 2.207248, Accuracy: 17.86%\n",
            "Epoch: 25, Step: 466/655, Loss: 2.207331, Accuracy: 17.88%\n",
            "Epoch: 25, Step: 467/655, Loss: 2.207449, Accuracy: 17.88%\n",
            "Epoch: 25, Step: 468/655, Loss: 2.207526, Accuracy: 17.89%\n",
            "Epoch: 25, Step: 469/655, Loss: 2.207728, Accuracy: 17.88%\n",
            "Epoch: 25, Step: 470/655, Loss: 2.207973, Accuracy: 17.85%\n",
            "Epoch: 25, Step: 471/655, Loss: 2.208192, Accuracy: 17.85%\n",
            "Epoch: 25, Step: 472/655, Loss: 2.208127, Accuracy: 17.86%\n",
            "Epoch: 25, Step: 473/655, Loss: 2.207949, Accuracy: 17.86%\n",
            "Epoch: 25, Step: 474/655, Loss: 2.207911, Accuracy: 17.87%\n",
            "Epoch: 25, Step: 475/655, Loss: 2.208133, Accuracy: 17.85%\n",
            "Epoch: 25, Step: 476/655, Loss: 2.208250, Accuracy: 17.85%\n",
            "Epoch: 25, Step: 477/655, Loss: 2.208115, Accuracy: 17.87%\n",
            "Epoch: 25, Step: 478/655, Loss: 2.207895, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 479/655, Loss: 2.207920, Accuracy: 17.89%\n",
            "Epoch: 25, Step: 480/655, Loss: 2.207886, Accuracy: 17.89%\n",
            "Epoch: 25, Step: 481/655, Loss: 2.207841, Accuracy: 17.89%\n",
            "Epoch: 25, Step: 482/655, Loss: 2.207685, Accuracy: 17.89%\n",
            "Epoch: 25, Step: 483/655, Loss: 2.207637, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 484/655, Loss: 2.207419, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 485/655, Loss: 2.207555, Accuracy: 17.91%\n",
            "Epoch: 25, Step: 486/655, Loss: 2.207677, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 487/655, Loss: 2.207729, Accuracy: 17.90%\n",
            "Epoch: 25, Step: 488/655, Loss: 2.208033, Accuracy: 17.91%\n",
            "Epoch: 25, Step: 489/655, Loss: 2.207768, Accuracy: 17.94%\n",
            "Epoch: 25, Step: 490/655, Loss: 2.208010, Accuracy: 17.94%\n",
            "Epoch: 25, Step: 491/655, Loss: 2.208158, Accuracy: 17.94%\n",
            "Epoch: 25, Step: 492/655, Loss: 2.208284, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 493/655, Loss: 2.208121, Accuracy: 17.94%\n",
            "Epoch: 25, Step: 494/655, Loss: 2.208150, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 495/655, Loss: 2.208277, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 496/655, Loss: 2.208277, Accuracy: 17.94%\n",
            "Epoch: 25, Step: 497/655, Loss: 2.208454, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 498/655, Loss: 2.208320, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 499/655, Loss: 2.208305, Accuracy: 17.94%\n",
            "Epoch: 25, Step: 500/655, Loss: 2.208106, Accuracy: 17.94%\n",
            "Epoch: 25, Step: 501/655, Loss: 2.207936, Accuracy: 17.94%\n",
            "Epoch: 25, Step: 502/655, Loss: 2.208028, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 503/655, Loss: 2.208122, Accuracy: 17.91%\n",
            "Epoch: 25, Step: 504/655, Loss: 2.208066, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 505/655, Loss: 2.207879, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 506/655, Loss: 2.207964, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 507/655, Loss: 2.208232, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 508/655, Loss: 2.208354, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 509/655, Loss: 2.208228, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 510/655, Loss: 2.208258, Accuracy: 17.94%\n",
            "Epoch: 25, Step: 511/655, Loss: 2.208247, Accuracy: 17.92%\n",
            "Epoch: 25, Step: 512/655, Loss: 2.208500, Accuracy: 17.93%\n",
            "Epoch: 25, Step: 513/655, Loss: 2.208344, Accuracy: 17.95%\n",
            "Epoch: 25, Step: 514/655, Loss: 2.208416, Accuracy: 17.95%\n",
            "Epoch: 25, Step: 515/655, Loss: 2.208343, Accuracy: 17.96%\n",
            "Epoch: 25, Step: 516/655, Loss: 2.208552, Accuracy: 17.94%\n",
            "Epoch: 25, Step: 517/655, Loss: 2.208323, Accuracy: 17.95%\n",
            "Epoch: 25, Step: 518/655, Loss: 2.208277, Accuracy: 17.94%\n",
            "Epoch: 25, Step: 519/655, Loss: 2.208294, Accuracy: 17.95%\n",
            "Epoch: 25, Step: 520/655, Loss: 2.208245, Accuracy: 17.96%\n",
            "Epoch: 25, Step: 521/655, Loss: 2.208215, Accuracy: 17.97%\n",
            "Epoch: 25, Step: 522/655, Loss: 2.208165, Accuracy: 17.98%\n",
            "Epoch: 25, Step: 523/655, Loss: 2.208220, Accuracy: 17.96%\n",
            "Epoch: 25, Step: 524/655, Loss: 2.208034, Accuracy: 17.99%\n",
            "Epoch: 25, Step: 525/655, Loss: 2.207949, Accuracy: 17.99%\n",
            "Epoch: 25, Step: 526/655, Loss: 2.208005, Accuracy: 17.98%\n",
            "Epoch: 25, Step: 527/655, Loss: 2.208124, Accuracy: 17.99%\n",
            "Epoch: 25, Step: 528/655, Loss: 2.208269, Accuracy: 17.96%\n",
            "Epoch: 25, Step: 529/655, Loss: 2.208099, Accuracy: 17.98%\n",
            "Epoch: 25, Step: 530/655, Loss: 2.207985, Accuracy: 17.98%\n",
            "Epoch: 25, Step: 531/655, Loss: 2.207897, Accuracy: 17.99%\n",
            "Epoch: 25, Step: 532/655, Loss: 2.207628, Accuracy: 18.00%\n",
            "Epoch: 25, Step: 533/655, Loss: 2.207512, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 534/655, Loss: 2.207680, Accuracy: 18.00%\n",
            "Epoch: 25, Step: 535/655, Loss: 2.207611, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 536/655, Loss: 2.207363, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 537/655, Loss: 2.207389, Accuracy: 18.07%\n",
            "Epoch: 25, Step: 538/655, Loss: 2.207381, Accuracy: 18.09%\n",
            "Epoch: 25, Step: 539/655, Loss: 2.207297, Accuracy: 18.10%\n",
            "Epoch: 25, Step: 540/655, Loss: 2.207328, Accuracy: 18.12%\n",
            "Epoch: 25, Step: 541/655, Loss: 2.207228, Accuracy: 18.14%\n",
            "Epoch: 25, Step: 542/655, Loss: 2.207179, Accuracy: 18.14%\n",
            "Epoch: 25, Step: 543/655, Loss: 2.207044, Accuracy: 18.13%\n",
            "Epoch: 25, Step: 544/655, Loss: 2.206910, Accuracy: 18.14%\n",
            "Epoch: 25, Step: 545/655, Loss: 2.206831, Accuracy: 18.14%\n",
            "Epoch: 25, Step: 546/655, Loss: 2.206828, Accuracy: 18.14%\n",
            "Epoch: 25, Step: 547/655, Loss: 2.207085, Accuracy: 18.14%\n",
            "Epoch: 25, Step: 548/655, Loss: 2.207277, Accuracy: 18.13%\n",
            "Epoch: 25, Step: 549/655, Loss: 2.207115, Accuracy: 18.14%\n",
            "Epoch: 25, Step: 550/655, Loss: 2.206930, Accuracy: 18.16%\n",
            "Epoch: 25, Step: 551/655, Loss: 2.206995, Accuracy: 18.14%\n",
            "Epoch: 25, Step: 552/655, Loss: 2.207297, Accuracy: 18.14%\n",
            "Epoch: 25, Step: 553/655, Loss: 2.207311, Accuracy: 18.13%\n",
            "Epoch: 25, Step: 554/655, Loss: 2.207186, Accuracy: 18.14%\n",
            "Epoch: 25, Step: 555/655, Loss: 2.207420, Accuracy: 18.11%\n",
            "Epoch: 25, Step: 556/655, Loss: 2.207758, Accuracy: 18.09%\n",
            "Epoch: 25, Step: 557/655, Loss: 2.207571, Accuracy: 18.12%\n",
            "Epoch: 25, Step: 558/655, Loss: 2.207611, Accuracy: 18.11%\n",
            "Epoch: 25, Step: 559/655, Loss: 2.207460, Accuracy: 18.12%\n",
            "Epoch: 25, Step: 560/655, Loss: 2.207432, Accuracy: 18.13%\n",
            "Epoch: 25, Step: 561/655, Loss: 2.207305, Accuracy: 18.14%\n",
            "Epoch: 25, Step: 562/655, Loss: 2.207307, Accuracy: 18.13%\n",
            "Epoch: 25, Step: 563/655, Loss: 2.207365, Accuracy: 18.11%\n",
            "Epoch: 25, Step: 564/655, Loss: 2.207624, Accuracy: 18.10%\n",
            "Epoch: 25, Step: 565/655, Loss: 2.207621, Accuracy: 18.11%\n",
            "Epoch: 25, Step: 566/655, Loss: 2.207714, Accuracy: 18.10%\n",
            "Epoch: 25, Step: 567/655, Loss: 2.207722, Accuracy: 18.08%\n",
            "Epoch: 25, Step: 568/655, Loss: 2.207622, Accuracy: 18.08%\n",
            "Epoch: 25, Step: 569/655, Loss: 2.207535, Accuracy: 18.07%\n",
            "Epoch: 25, Step: 570/655, Loss: 2.207340, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 571/655, Loss: 2.207332, Accuracy: 18.06%\n",
            "Epoch: 25, Step: 572/655, Loss: 2.207310, Accuracy: 18.06%\n",
            "Epoch: 25, Step: 573/655, Loss: 2.207164, Accuracy: 18.06%\n",
            "Epoch: 25, Step: 574/655, Loss: 2.207200, Accuracy: 18.06%\n",
            "Epoch: 25, Step: 575/655, Loss: 2.207132, Accuracy: 18.07%\n",
            "Epoch: 25, Step: 576/655, Loss: 2.207132, Accuracy: 18.06%\n",
            "Epoch: 25, Step: 577/655, Loss: 2.207039, Accuracy: 18.07%\n",
            "Epoch: 25, Step: 578/655, Loss: 2.206988, Accuracy: 18.07%\n",
            "Epoch: 25, Step: 579/655, Loss: 2.207257, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 580/655, Loss: 2.207452, Accuracy: 18.04%\n",
            "Epoch: 25, Step: 581/655, Loss: 2.207605, Accuracy: 18.04%\n",
            "Epoch: 25, Step: 582/655, Loss: 2.207674, Accuracy: 18.04%\n",
            "Epoch: 25, Step: 583/655, Loss: 2.207656, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 584/655, Loss: 2.207906, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 585/655, Loss: 2.208010, Accuracy: 18.00%\n",
            "Epoch: 25, Step: 586/655, Loss: 2.208276, Accuracy: 18.00%\n",
            "Epoch: 25, Step: 587/655, Loss: 2.208255, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 588/655, Loss: 2.208300, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 589/655, Loss: 2.208269, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 590/655, Loss: 2.208139, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 591/655, Loss: 2.208093, Accuracy: 18.00%\n",
            "Epoch: 25, Step: 592/655, Loss: 2.208125, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 593/655, Loss: 2.208091, Accuracy: 18.00%\n",
            "Epoch: 25, Step: 594/655, Loss: 2.208137, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 595/655, Loss: 2.208116, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 596/655, Loss: 2.208173, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 597/655, Loss: 2.208172, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 598/655, Loss: 2.208077, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 599/655, Loss: 2.208010, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 600/655, Loss: 2.207773, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 601/655, Loss: 2.207711, Accuracy: 18.04%\n",
            "Epoch: 25, Step: 602/655, Loss: 2.207397, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 603/655, Loss: 2.207451, Accuracy: 18.06%\n",
            "Epoch: 25, Step: 604/655, Loss: 2.207625, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 605/655, Loss: 2.207798, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 606/655, Loss: 2.207783, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 607/655, Loss: 2.207787, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 608/655, Loss: 2.207706, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 609/655, Loss: 2.207617, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 610/655, Loss: 2.207625, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 611/655, Loss: 2.207410, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 612/655, Loss: 2.207527, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 613/655, Loss: 2.207491, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 614/655, Loss: 2.207464, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 615/655, Loss: 2.207680, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 616/655, Loss: 2.207604, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 617/655, Loss: 2.207630, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 618/655, Loss: 2.207537, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 619/655, Loss: 2.207634, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 620/655, Loss: 2.207741, Accuracy: 18.00%\n",
            "Epoch: 25, Step: 621/655, Loss: 2.207806, Accuracy: 18.01%\n",
            "Epoch: 25, Step: 622/655, Loss: 2.207942, Accuracy: 18.00%\n",
            "Epoch: 25, Step: 623/655, Loss: 2.207722, Accuracy: 18.04%\n",
            "Epoch: 25, Step: 624/655, Loss: 2.207623, Accuracy: 18.04%\n",
            "Epoch: 25, Step: 625/655, Loss: 2.207774, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 626/655, Loss: 2.207922, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 627/655, Loss: 2.207887, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 628/655, Loss: 2.207935, Accuracy: 18.04%\n",
            "Epoch: 25, Step: 629/655, Loss: 2.208042, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 630/655, Loss: 2.208169, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 631/655, Loss: 2.207897, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 632/655, Loss: 2.207728, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 633/655, Loss: 2.207837, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 634/655, Loss: 2.207859, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 635/655, Loss: 2.207781, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 636/655, Loss: 2.207739, Accuracy: 18.04%\n",
            "Epoch: 25, Step: 637/655, Loss: 2.207480, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 638/655, Loss: 2.207656, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 639/655, Loss: 2.207718, Accuracy: 18.04%\n",
            "Epoch: 25, Step: 640/655, Loss: 2.207787, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 641/655, Loss: 2.207815, Accuracy: 18.04%\n",
            "Epoch: 25, Step: 642/655, Loss: 2.207881, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 643/655, Loss: 2.207939, Accuracy: 18.02%\n",
            "Epoch: 25, Step: 644/655, Loss: 2.207884, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 645/655, Loss: 2.207840, Accuracy: 18.03%\n",
            "Epoch: 25, Step: 646/655, Loss: 2.207825, Accuracy: 18.04%\n",
            "Epoch: 25, Step: 647/655, Loss: 2.207788, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 648/655, Loss: 2.207677, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 649/655, Loss: 2.207774, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 650/655, Loss: 2.207710, Accuracy: 18.05%\n",
            "Epoch: 25, Step: 651/655, Loss: 2.207658, Accuracy: 18.07%\n",
            "Epoch: 25, Step: 652/655, Loss: 2.207731, Accuracy: 18.07%\n",
            "Epoch: 25, Step: 653/655, Loss: 2.207827, Accuracy: 18.07%\n",
            "Epoch: 25, Step: 654/655, Loss: 2.207857, Accuracy: 18.07%\n",
            "Epoch: 25, Step: 655/655, Loss: 2.207526, Accuracy: 18.08%\n",
            "Epoch: 26, Step: 1/655, Loss: 2.136870, Accuracy: 18.75%\n",
            "Epoch: 26, Step: 2/655, Loss: 2.086734, Accuracy: 29.69%\n",
            "Epoch: 26, Step: 3/655, Loss: 2.135371, Accuracy: 25.00%\n",
            "Epoch: 26, Step: 4/655, Loss: 2.169219, Accuracy: 21.88%\n",
            "Epoch: 26, Step: 5/655, Loss: 2.199269, Accuracy: 21.25%\n",
            "Epoch: 26, Step: 6/655, Loss: 2.201581, Accuracy: 21.88%\n",
            "Epoch: 26, Step: 7/655, Loss: 2.202915, Accuracy: 20.98%\n",
            "Epoch: 26, Step: 8/655, Loss: 2.217992, Accuracy: 19.14%\n",
            "Epoch: 26, Step: 9/655, Loss: 2.205928, Accuracy: 18.75%\n",
            "Epoch: 26, Step: 10/655, Loss: 2.197818, Accuracy: 19.38%\n",
            "Epoch: 26, Step: 11/655, Loss: 2.208507, Accuracy: 19.60%\n",
            "Epoch: 26, Step: 12/655, Loss: 2.206791, Accuracy: 19.27%\n",
            "Epoch: 26, Step: 13/655, Loss: 2.200385, Accuracy: 19.47%\n",
            "Epoch: 26, Step: 14/655, Loss: 2.197202, Accuracy: 19.20%\n",
            "Epoch: 26, Step: 15/655, Loss: 2.200258, Accuracy: 19.38%\n",
            "Epoch: 26, Step: 16/655, Loss: 2.194518, Accuracy: 19.53%\n",
            "Epoch: 26, Step: 17/655, Loss: 2.197559, Accuracy: 19.30%\n",
            "Epoch: 26, Step: 18/655, Loss: 2.197180, Accuracy: 19.62%\n",
            "Epoch: 26, Step: 19/655, Loss: 2.200698, Accuracy: 19.08%\n",
            "Epoch: 26, Step: 20/655, Loss: 2.204564, Accuracy: 18.59%\n",
            "Epoch: 26, Step: 21/655, Loss: 2.199550, Accuracy: 19.05%\n",
            "Epoch: 26, Step: 22/655, Loss: 2.198924, Accuracy: 18.75%\n",
            "Epoch: 26, Step: 23/655, Loss: 2.192680, Accuracy: 19.57%\n",
            "Epoch: 26, Step: 24/655, Loss: 2.194875, Accuracy: 19.27%\n",
            "Epoch: 26, Step: 25/655, Loss: 2.198751, Accuracy: 18.88%\n",
            "Epoch: 26, Step: 26/655, Loss: 2.196649, Accuracy: 19.11%\n",
            "Epoch: 26, Step: 27/655, Loss: 2.197664, Accuracy: 19.21%\n",
            "Epoch: 26, Step: 28/655, Loss: 2.199830, Accuracy: 18.64%\n",
            "Epoch: 26, Step: 29/655, Loss: 2.197500, Accuracy: 18.64%\n",
            "Epoch: 26, Step: 30/655, Loss: 2.199738, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 31/655, Loss: 2.202838, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 32/655, Loss: 2.200556, Accuracy: 18.46%\n",
            "Epoch: 26, Step: 33/655, Loss: 2.198497, Accuracy: 18.75%\n",
            "Epoch: 26, Step: 34/655, Loss: 2.203934, Accuracy: 18.57%\n",
            "Epoch: 26, Step: 35/655, Loss: 2.203815, Accuracy: 18.93%\n",
            "Epoch: 26, Step: 36/655, Loss: 2.207696, Accuracy: 18.49%\n",
            "Epoch: 26, Step: 37/655, Loss: 2.206641, Accuracy: 18.58%\n",
            "Epoch: 26, Step: 38/655, Loss: 2.210218, Accuracy: 18.26%\n",
            "Epoch: 26, Step: 39/655, Loss: 2.214751, Accuracy: 18.11%\n",
            "Epoch: 26, Step: 40/655, Loss: 2.217616, Accuracy: 17.97%\n",
            "Epoch: 26, Step: 41/655, Loss: 2.218119, Accuracy: 17.91%\n",
            "Epoch: 26, Step: 42/655, Loss: 2.218814, Accuracy: 18.08%\n",
            "Epoch: 26, Step: 43/655, Loss: 2.220308, Accuracy: 18.02%\n",
            "Epoch: 26, Step: 44/655, Loss: 2.220812, Accuracy: 18.11%\n",
            "Epoch: 26, Step: 45/655, Loss: 2.220584, Accuracy: 18.12%\n",
            "Epoch: 26, Step: 46/655, Loss: 2.216381, Accuracy: 18.55%\n",
            "Epoch: 26, Step: 47/655, Loss: 2.215574, Accuracy: 18.48%\n",
            "Epoch: 26, Step: 48/655, Loss: 2.213810, Accuracy: 18.62%\n",
            "Epoch: 26, Step: 49/655, Loss: 2.214260, Accuracy: 18.37%\n",
            "Epoch: 26, Step: 50/655, Loss: 2.212313, Accuracy: 18.25%\n",
            "Epoch: 26, Step: 51/655, Loss: 2.210355, Accuracy: 18.20%\n",
            "Epoch: 26, Step: 52/655, Loss: 2.210976, Accuracy: 18.03%\n",
            "Epoch: 26, Step: 53/655, Loss: 2.211611, Accuracy: 17.92%\n",
            "Epoch: 26, Step: 54/655, Loss: 2.210066, Accuracy: 18.06%\n",
            "Epoch: 26, Step: 55/655, Loss: 2.212236, Accuracy: 18.12%\n",
            "Epoch: 26, Step: 56/655, Loss: 2.213465, Accuracy: 17.97%\n",
            "Epoch: 26, Step: 57/655, Loss: 2.212838, Accuracy: 17.87%\n",
            "Epoch: 26, Step: 58/655, Loss: 2.214311, Accuracy: 17.83%\n",
            "Epoch: 26, Step: 59/655, Loss: 2.212428, Accuracy: 18.11%\n",
            "Epoch: 26, Step: 60/655, Loss: 2.213397, Accuracy: 18.12%\n",
            "Epoch: 26, Step: 61/655, Loss: 2.212240, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 62/655, Loss: 2.213126, Accuracy: 18.20%\n",
            "Epoch: 26, Step: 63/655, Loss: 2.212882, Accuracy: 18.11%\n",
            "Epoch: 26, Step: 64/655, Loss: 2.211331, Accuracy: 18.16%\n",
            "Epoch: 26, Step: 65/655, Loss: 2.213926, Accuracy: 18.12%\n",
            "Epoch: 26, Step: 66/655, Loss: 2.213584, Accuracy: 18.42%\n",
            "Epoch: 26, Step: 67/655, Loss: 2.212881, Accuracy: 18.42%\n",
            "Epoch: 26, Step: 68/655, Loss: 2.214277, Accuracy: 18.29%\n",
            "Epoch: 26, Step: 69/655, Loss: 2.214312, Accuracy: 18.16%\n",
            "Epoch: 26, Step: 70/655, Loss: 2.213065, Accuracy: 18.21%\n",
            "Epoch: 26, Step: 71/655, Loss: 2.212294, Accuracy: 18.09%\n",
            "Epoch: 26, Step: 72/655, Loss: 2.211012, Accuracy: 18.10%\n",
            "Epoch: 26, Step: 73/655, Loss: 2.211328, Accuracy: 18.15%\n",
            "Epoch: 26, Step: 74/655, Loss: 2.211308, Accuracy: 18.03%\n",
            "Epoch: 26, Step: 75/655, Loss: 2.210648, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 76/655, Loss: 2.209368, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 77/655, Loss: 2.208523, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 78/655, Loss: 2.208859, Accuracy: 18.27%\n",
            "Epoch: 26, Step: 79/655, Loss: 2.207457, Accuracy: 18.28%\n",
            "Epoch: 26, Step: 80/655, Loss: 2.208101, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 81/655, Loss: 2.208862, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 82/655, Loss: 2.208828, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 83/655, Loss: 2.208478, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 84/655, Loss: 2.207986, Accuracy: 18.15%\n",
            "Epoch: 26, Step: 85/655, Loss: 2.206971, Accuracy: 18.24%\n",
            "Epoch: 26, Step: 86/655, Loss: 2.205844, Accuracy: 18.24%\n",
            "Epoch: 26, Step: 87/655, Loss: 2.204909, Accuracy: 18.25%\n",
            "Epoch: 26, Step: 88/655, Loss: 2.205153, Accuracy: 18.15%\n",
            "Epoch: 26, Step: 89/655, Loss: 2.205986, Accuracy: 18.12%\n",
            "Epoch: 26, Step: 90/655, Loss: 2.205994, Accuracy: 18.16%\n",
            "Epoch: 26, Step: 91/655, Loss: 2.206816, Accuracy: 18.13%\n",
            "Epoch: 26, Step: 92/655, Loss: 2.207198, Accuracy: 18.04%\n",
            "Epoch: 26, Step: 93/655, Loss: 2.205703, Accuracy: 18.15%\n",
            "Epoch: 26, Step: 94/655, Loss: 2.206249, Accuracy: 18.15%\n",
            "Epoch: 26, Step: 95/655, Loss: 2.205921, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 96/655, Loss: 2.205539, Accuracy: 18.29%\n",
            "Epoch: 26, Step: 97/655, Loss: 2.205753, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 98/655, Loss: 2.205718, Accuracy: 18.27%\n",
            "Epoch: 26, Step: 99/655, Loss: 2.206563, Accuracy: 18.15%\n",
            "Epoch: 26, Step: 100/655, Loss: 2.206931, Accuracy: 18.09%\n",
            "Epoch: 26, Step: 101/655, Loss: 2.206534, Accuracy: 18.22%\n",
            "Epoch: 26, Step: 102/655, Loss: 2.206358, Accuracy: 18.20%\n",
            "Epoch: 26, Step: 103/655, Loss: 2.206227, Accuracy: 18.20%\n",
            "Epoch: 26, Step: 104/655, Loss: 2.206310, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 105/655, Loss: 2.207312, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 106/655, Loss: 2.206910, Accuracy: 18.16%\n",
            "Epoch: 26, Step: 107/655, Loss: 2.206791, Accuracy: 18.08%\n",
            "Epoch: 26, Step: 108/655, Loss: 2.207695, Accuracy: 18.08%\n",
            "Epoch: 26, Step: 109/655, Loss: 2.207159, Accuracy: 18.23%\n",
            "Epoch: 26, Step: 110/655, Loss: 2.208123, Accuracy: 18.24%\n",
            "Epoch: 26, Step: 111/655, Loss: 2.208702, Accuracy: 18.22%\n",
            "Epoch: 26, Step: 112/655, Loss: 2.210075, Accuracy: 18.11%\n",
            "Epoch: 26, Step: 113/655, Loss: 2.209789, Accuracy: 18.09%\n",
            "Epoch: 26, Step: 114/655, Loss: 2.208842, Accuracy: 18.06%\n",
            "Epoch: 26, Step: 115/655, Loss: 2.208088, Accuracy: 18.21%\n",
            "Epoch: 26, Step: 116/655, Loss: 2.208261, Accuracy: 18.21%\n",
            "Epoch: 26, Step: 117/655, Loss: 2.208437, Accuracy: 18.22%\n",
            "Epoch: 26, Step: 118/655, Loss: 2.210047, Accuracy: 18.11%\n",
            "Epoch: 26, Step: 119/655, Loss: 2.209357, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 120/655, Loss: 2.209580, Accuracy: 18.20%\n",
            "Epoch: 26, Step: 121/655, Loss: 2.209484, Accuracy: 18.16%\n",
            "Epoch: 26, Step: 122/655, Loss: 2.209388, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 123/655, Loss: 2.208770, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 124/655, Loss: 2.208838, Accuracy: 18.20%\n",
            "Epoch: 26, Step: 125/655, Loss: 2.209007, Accuracy: 18.20%\n",
            "Epoch: 26, Step: 126/655, Loss: 2.209379, Accuracy: 18.23%\n",
            "Epoch: 26, Step: 127/655, Loss: 2.209250, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 128/655, Loss: 2.209812, Accuracy: 18.12%\n",
            "Epoch: 26, Step: 129/655, Loss: 2.210887, Accuracy: 18.05%\n",
            "Epoch: 26, Step: 130/655, Loss: 2.211026, Accuracy: 18.05%\n",
            "Epoch: 26, Step: 131/655, Loss: 2.211067, Accuracy: 18.03%\n",
            "Epoch: 26, Step: 132/655, Loss: 2.210433, Accuracy: 18.11%\n",
            "Epoch: 26, Step: 133/655, Loss: 2.210577, Accuracy: 18.09%\n",
            "Epoch: 26, Step: 134/655, Loss: 2.210585, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 135/655, Loss: 2.210816, Accuracy: 18.10%\n",
            "Epoch: 26, Step: 136/655, Loss: 2.210673, Accuracy: 18.06%\n",
            "Epoch: 26, Step: 137/655, Loss: 2.211263, Accuracy: 18.02%\n",
            "Epoch: 26, Step: 138/655, Loss: 2.211685, Accuracy: 18.00%\n",
            "Epoch: 26, Step: 139/655, Loss: 2.212156, Accuracy: 17.94%\n",
            "Epoch: 26, Step: 140/655, Loss: 2.212907, Accuracy: 17.90%\n",
            "Epoch: 26, Step: 141/655, Loss: 2.212736, Accuracy: 17.97%\n",
            "Epoch: 26, Step: 142/655, Loss: 2.212815, Accuracy: 18.00%\n",
            "Epoch: 26, Step: 143/655, Loss: 2.211901, Accuracy: 18.05%\n",
            "Epoch: 26, Step: 144/655, Loss: 2.211731, Accuracy: 18.03%\n",
            "Epoch: 26, Step: 145/655, Loss: 2.211753, Accuracy: 18.04%\n",
            "Epoch: 26, Step: 146/655, Loss: 2.210908, Accuracy: 18.11%\n",
            "Epoch: 26, Step: 147/655, Loss: 2.211142, Accuracy: 18.13%\n",
            "Epoch: 26, Step: 148/655, Loss: 2.211282, Accuracy: 18.16%\n",
            "Epoch: 26, Step: 149/655, Loss: 2.211921, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 150/655, Loss: 2.211764, Accuracy: 18.12%\n",
            "Epoch: 26, Step: 151/655, Loss: 2.212156, Accuracy: 18.11%\n",
            "Epoch: 26, Step: 152/655, Loss: 2.212535, Accuracy: 18.13%\n",
            "Epoch: 26, Step: 153/655, Loss: 2.212704, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 154/655, Loss: 2.212329, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 155/655, Loss: 2.211015, Accuracy: 18.21%\n",
            "Epoch: 26, Step: 156/655, Loss: 2.210931, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 157/655, Loss: 2.210838, Accuracy: 18.25%\n",
            "Epoch: 26, Step: 158/655, Loss: 2.211116, Accuracy: 18.26%\n",
            "Epoch: 26, Step: 159/655, Loss: 2.211245, Accuracy: 18.22%\n",
            "Epoch: 26, Step: 160/655, Loss: 2.211920, Accuracy: 18.26%\n",
            "Epoch: 26, Step: 161/655, Loss: 2.211916, Accuracy: 18.23%\n",
            "Epoch: 26, Step: 162/655, Loss: 2.211930, Accuracy: 18.21%\n",
            "Epoch: 26, Step: 163/655, Loss: 2.212216, Accuracy: 18.25%\n",
            "Epoch: 26, Step: 164/655, Loss: 2.212058, Accuracy: 18.25%\n",
            "Epoch: 26, Step: 165/655, Loss: 2.211737, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 166/655, Loss: 2.212211, Accuracy: 18.28%\n",
            "Epoch: 26, Step: 167/655, Loss: 2.211779, Accuracy: 18.26%\n",
            "Epoch: 26, Step: 168/655, Loss: 2.211277, Accuracy: 18.27%\n",
            "Epoch: 26, Step: 169/655, Loss: 2.211607, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 170/655, Loss: 2.212118, Accuracy: 18.16%\n",
            "Epoch: 26, Step: 171/655, Loss: 2.212264, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 172/655, Loss: 2.212117, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 173/655, Loss: 2.213179, Accuracy: 18.15%\n",
            "Epoch: 26, Step: 174/655, Loss: 2.212318, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 175/655, Loss: 2.212132, Accuracy: 18.21%\n",
            "Epoch: 26, Step: 176/655, Loss: 2.211551, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 177/655, Loss: 2.212191, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 178/655, Loss: 2.211717, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 179/655, Loss: 2.211305, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 180/655, Loss: 2.211416, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 181/655, Loss: 2.211278, Accuracy: 18.20%\n",
            "Epoch: 26, Step: 182/655, Loss: 2.212231, Accuracy: 18.13%\n",
            "Epoch: 26, Step: 183/655, Loss: 2.212257, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 184/655, Loss: 2.211585, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 185/655, Loss: 2.211246, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 186/655, Loss: 2.211382, Accuracy: 18.16%\n",
            "Epoch: 26, Step: 187/655, Loss: 2.210638, Accuracy: 18.23%\n",
            "Epoch: 26, Step: 188/655, Loss: 2.210889, Accuracy: 18.22%\n",
            "Epoch: 26, Step: 189/655, Loss: 2.210607, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 190/655, Loss: 2.210945, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 191/655, Loss: 2.210927, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 192/655, Loss: 2.210887, Accuracy: 18.16%\n",
            "Epoch: 26, Step: 193/655, Loss: 2.210014, Accuracy: 18.13%\n",
            "Epoch: 26, Step: 194/655, Loss: 2.209306, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 195/655, Loss: 2.209192, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 196/655, Loss: 2.209146, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 197/655, Loss: 2.209282, Accuracy: 18.12%\n",
            "Epoch: 26, Step: 198/655, Loss: 2.208642, Accuracy: 18.15%\n",
            "Epoch: 26, Step: 199/655, Loss: 2.208865, Accuracy: 18.12%\n",
            "Epoch: 26, Step: 200/655, Loss: 2.208369, Accuracy: 18.16%\n",
            "Epoch: 26, Step: 201/655, Loss: 2.208725, Accuracy: 18.16%\n",
            "Epoch: 26, Step: 202/655, Loss: 2.208548, Accuracy: 18.21%\n",
            "Epoch: 26, Step: 203/655, Loss: 2.208734, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 204/655, Loss: 2.209024, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 205/655, Loss: 2.209143, Accuracy: 18.16%\n",
            "Epoch: 26, Step: 206/655, Loss: 2.209347, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 207/655, Loss: 2.209250, Accuracy: 18.22%\n",
            "Epoch: 26, Step: 208/655, Loss: 2.209706, Accuracy: 18.22%\n",
            "Epoch: 26, Step: 209/655, Loss: 2.209468, Accuracy: 18.24%\n",
            "Epoch: 26, Step: 210/655, Loss: 2.209344, Accuracy: 18.26%\n",
            "Epoch: 26, Step: 211/655, Loss: 2.209262, Accuracy: 18.28%\n",
            "Epoch: 26, Step: 212/655, Loss: 2.209548, Accuracy: 18.20%\n",
            "Epoch: 26, Step: 213/655, Loss: 2.209116, Accuracy: 18.25%\n",
            "Epoch: 26, Step: 214/655, Loss: 2.208955, Accuracy: 18.25%\n",
            "Epoch: 26, Step: 215/655, Loss: 2.208470, Accuracy: 18.28%\n",
            "Epoch: 26, Step: 216/655, Loss: 2.207434, Accuracy: 18.39%\n",
            "Epoch: 26, Step: 217/655, Loss: 2.207583, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 218/655, Loss: 2.207190, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 219/655, Loss: 2.207065, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 220/655, Loss: 2.206291, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 221/655, Loss: 2.206445, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 222/655, Loss: 2.206285, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 223/655, Loss: 2.206202, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 224/655, Loss: 2.206182, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 225/655, Loss: 2.206113, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 226/655, Loss: 2.206505, Accuracy: 18.29%\n",
            "Epoch: 26, Step: 227/655, Loss: 2.206280, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 228/655, Loss: 2.206098, Accuracy: 18.28%\n",
            "Epoch: 26, Step: 229/655, Loss: 2.206143, Accuracy: 18.27%\n",
            "Epoch: 26, Step: 230/655, Loss: 2.206141, Accuracy: 18.26%\n",
            "Epoch: 26, Step: 231/655, Loss: 2.206846, Accuracy: 18.24%\n",
            "Epoch: 26, Step: 232/655, Loss: 2.207311, Accuracy: 18.22%\n",
            "Epoch: 26, Step: 233/655, Loss: 2.207856, Accuracy: 18.20%\n",
            "Epoch: 26, Step: 234/655, Loss: 2.207904, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 235/655, Loss: 2.207955, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 236/655, Loss: 2.208116, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 237/655, Loss: 2.208250, Accuracy: 18.12%\n",
            "Epoch: 26, Step: 238/655, Loss: 2.208160, Accuracy: 18.12%\n",
            "Epoch: 26, Step: 239/655, Loss: 2.208440, Accuracy: 18.11%\n",
            "Epoch: 26, Step: 240/655, Loss: 2.208943, Accuracy: 18.11%\n",
            "Epoch: 26, Step: 241/655, Loss: 2.208545, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 242/655, Loss: 2.207923, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 243/655, Loss: 2.207818, Accuracy: 18.22%\n",
            "Epoch: 26, Step: 244/655, Loss: 2.207214, Accuracy: 18.28%\n",
            "Epoch: 26, Step: 245/655, Loss: 2.207082, Accuracy: 18.25%\n",
            "Epoch: 26, Step: 246/655, Loss: 2.206712, Accuracy: 18.29%\n",
            "Epoch: 26, Step: 247/655, Loss: 2.206961, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 248/655, Loss: 2.206919, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 249/655, Loss: 2.206772, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 250/655, Loss: 2.207004, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 251/655, Loss: 2.207632, Accuracy: 18.25%\n",
            "Epoch: 26, Step: 252/655, Loss: 2.208247, Accuracy: 18.22%\n",
            "Epoch: 26, Step: 253/655, Loss: 2.208392, Accuracy: 18.22%\n",
            "Epoch: 26, Step: 254/655, Loss: 2.208629, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 255/655, Loss: 2.208756, Accuracy: 18.16%\n",
            "Epoch: 26, Step: 256/655, Loss: 2.208150, Accuracy: 18.21%\n",
            "Epoch: 26, Step: 257/655, Loss: 2.208721, Accuracy: 18.20%\n",
            "Epoch: 26, Step: 258/655, Loss: 2.208653, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 259/655, Loss: 2.208729, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 260/655, Loss: 2.208839, Accuracy: 18.15%\n",
            "Epoch: 26, Step: 261/655, Loss: 2.208595, Accuracy: 18.21%\n",
            "Epoch: 26, Step: 262/655, Loss: 2.208544, Accuracy: 18.23%\n",
            "Epoch: 26, Step: 263/655, Loss: 2.208912, Accuracy: 18.22%\n",
            "Epoch: 26, Step: 264/655, Loss: 2.208615, Accuracy: 18.25%\n",
            "Epoch: 26, Step: 265/655, Loss: 2.208706, Accuracy: 18.23%\n",
            "Epoch: 26, Step: 266/655, Loss: 2.208635, Accuracy: 18.22%\n",
            "Epoch: 26, Step: 267/655, Loss: 2.208444, Accuracy: 18.22%\n",
            "Epoch: 26, Step: 268/655, Loss: 2.208057, Accuracy: 18.23%\n",
            "Epoch: 26, Step: 269/655, Loss: 2.208063, Accuracy: 18.29%\n",
            "Epoch: 26, Step: 270/655, Loss: 2.208317, Accuracy: 18.23%\n",
            "Epoch: 26, Step: 271/655, Loss: 2.208048, Accuracy: 18.23%\n",
            "Epoch: 26, Step: 272/655, Loss: 2.208039, Accuracy: 18.20%\n",
            "Epoch: 26, Step: 273/655, Loss: 2.208703, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 274/655, Loss: 2.208747, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 275/655, Loss: 2.208533, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 276/655, Loss: 2.208811, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 277/655, Loss: 2.208878, Accuracy: 18.15%\n",
            "Epoch: 26, Step: 278/655, Loss: 2.209079, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 279/655, Loss: 2.208952, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 280/655, Loss: 2.208833, Accuracy: 18.15%\n",
            "Epoch: 26, Step: 281/655, Loss: 2.208958, Accuracy: 18.15%\n",
            "Epoch: 26, Step: 282/655, Loss: 2.209161, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 283/655, Loss: 2.209462, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 284/655, Loss: 2.209170, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 285/655, Loss: 2.209488, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 286/655, Loss: 2.209250, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 287/655, Loss: 2.209274, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 288/655, Loss: 2.209543, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 289/655, Loss: 2.209741, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 290/655, Loss: 2.209813, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 291/655, Loss: 2.209886, Accuracy: 18.20%\n",
            "Epoch: 26, Step: 292/655, Loss: 2.210194, Accuracy: 18.20%\n",
            "Epoch: 26, Step: 293/655, Loss: 2.210032, Accuracy: 18.21%\n",
            "Epoch: 26, Step: 294/655, Loss: 2.209807, Accuracy: 18.23%\n",
            "Epoch: 26, Step: 295/655, Loss: 2.209679, Accuracy: 18.21%\n",
            "Epoch: 26, Step: 296/655, Loss: 2.209942, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 297/655, Loss: 2.209880, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 298/655, Loss: 2.209811, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 299/655, Loss: 2.209700, Accuracy: 18.20%\n",
            "Epoch: 26, Step: 300/655, Loss: 2.209815, Accuracy: 18.18%\n",
            "Epoch: 26, Step: 301/655, Loss: 2.209911, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 302/655, Loss: 2.210067, Accuracy: 18.17%\n",
            "Epoch: 26, Step: 303/655, Loss: 2.210102, Accuracy: 18.15%\n",
            "Epoch: 26, Step: 304/655, Loss: 2.210339, Accuracy: 18.11%\n",
            "Epoch: 26, Step: 305/655, Loss: 2.210016, Accuracy: 18.11%\n",
            "Epoch: 26, Step: 306/655, Loss: 2.210507, Accuracy: 18.08%\n",
            "Epoch: 26, Step: 307/655, Loss: 2.210636, Accuracy: 18.09%\n",
            "Epoch: 26, Step: 308/655, Loss: 2.210972, Accuracy: 18.06%\n",
            "Epoch: 26, Step: 309/655, Loss: 2.211046, Accuracy: 18.04%\n",
            "Epoch: 26, Step: 310/655, Loss: 2.211121, Accuracy: 18.04%\n",
            "Epoch: 26, Step: 311/655, Loss: 2.210916, Accuracy: 18.05%\n",
            "Epoch: 26, Step: 312/655, Loss: 2.210944, Accuracy: 18.07%\n",
            "Epoch: 26, Step: 313/655, Loss: 2.210450, Accuracy: 18.08%\n",
            "Epoch: 26, Step: 314/655, Loss: 2.210465, Accuracy: 18.07%\n",
            "Epoch: 26, Step: 315/655, Loss: 2.210382, Accuracy: 18.06%\n",
            "Epoch: 26, Step: 316/655, Loss: 2.210199, Accuracy: 18.06%\n",
            "Epoch: 26, Step: 317/655, Loss: 2.210296, Accuracy: 18.05%\n",
            "Epoch: 26, Step: 318/655, Loss: 2.210422, Accuracy: 18.03%\n",
            "Epoch: 26, Step: 319/655, Loss: 2.210379, Accuracy: 18.05%\n",
            "Epoch: 26, Step: 320/655, Loss: 2.210193, Accuracy: 18.05%\n",
            "Epoch: 26, Step: 321/655, Loss: 2.210285, Accuracy: 18.04%\n",
            "Epoch: 26, Step: 322/655, Loss: 2.210408, Accuracy: 18.03%\n",
            "Epoch: 26, Step: 323/655, Loss: 2.210382, Accuracy: 18.03%\n",
            "Epoch: 26, Step: 324/655, Loss: 2.210233, Accuracy: 18.07%\n",
            "Epoch: 26, Step: 325/655, Loss: 2.210348, Accuracy: 18.07%\n",
            "Epoch: 26, Step: 326/655, Loss: 2.210469, Accuracy: 18.05%\n",
            "Epoch: 26, Step: 327/655, Loss: 2.210691, Accuracy: 18.05%\n",
            "Epoch: 26, Step: 328/655, Loss: 2.211242, Accuracy: 18.04%\n",
            "Epoch: 26, Step: 329/655, Loss: 2.210952, Accuracy: 18.08%\n",
            "Epoch: 26, Step: 330/655, Loss: 2.210797, Accuracy: 18.12%\n",
            "Epoch: 26, Step: 331/655, Loss: 2.210958, Accuracy: 18.10%\n",
            "Epoch: 26, Step: 332/655, Loss: 2.210689, Accuracy: 18.09%\n",
            "Epoch: 26, Step: 333/655, Loss: 2.210841, Accuracy: 18.06%\n",
            "Epoch: 26, Step: 334/655, Loss: 2.210634, Accuracy: 18.05%\n",
            "Epoch: 26, Step: 335/655, Loss: 2.210497, Accuracy: 18.05%\n",
            "Epoch: 26, Step: 336/655, Loss: 2.210123, Accuracy: 18.09%\n",
            "Epoch: 26, Step: 337/655, Loss: 2.210458, Accuracy: 18.08%\n",
            "Epoch: 26, Step: 338/655, Loss: 2.210339, Accuracy: 18.09%\n",
            "Epoch: 26, Step: 339/655, Loss: 2.209990, Accuracy: 18.08%\n",
            "Epoch: 26, Step: 340/655, Loss: 2.210055, Accuracy: 18.07%\n",
            "Epoch: 26, Step: 341/655, Loss: 2.210204, Accuracy: 18.06%\n",
            "Epoch: 26, Step: 342/655, Loss: 2.210390, Accuracy: 18.04%\n",
            "Epoch: 26, Step: 343/655, Loss: 2.210032, Accuracy: 18.04%\n",
            "Epoch: 26, Step: 344/655, Loss: 2.209687, Accuracy: 18.05%\n",
            "Epoch: 26, Step: 345/655, Loss: 2.209335, Accuracy: 18.10%\n",
            "Epoch: 26, Step: 346/655, Loss: 2.209280, Accuracy: 18.11%\n",
            "Epoch: 26, Step: 347/655, Loss: 2.209078, Accuracy: 18.13%\n",
            "Epoch: 26, Step: 348/655, Loss: 2.209062, Accuracy: 18.13%\n",
            "Epoch: 26, Step: 349/655, Loss: 2.208901, Accuracy: 18.14%\n",
            "Epoch: 26, Step: 350/655, Loss: 2.208770, Accuracy: 18.15%\n",
            "Epoch: 26, Step: 351/655, Loss: 2.208787, Accuracy: 18.15%\n",
            "Epoch: 26, Step: 352/655, Loss: 2.208601, Accuracy: 18.19%\n",
            "Epoch: 26, Step: 353/655, Loss: 2.208718, Accuracy: 18.21%\n",
            "Epoch: 26, Step: 354/655, Loss: 2.208523, Accuracy: 18.23%\n",
            "Epoch: 26, Step: 355/655, Loss: 2.208464, Accuracy: 18.23%\n",
            "Epoch: 26, Step: 356/655, Loss: 2.208215, Accuracy: 18.25%\n",
            "Epoch: 26, Step: 357/655, Loss: 2.208164, Accuracy: 18.26%\n",
            "Epoch: 26, Step: 358/655, Loss: 2.207647, Accuracy: 18.29%\n",
            "Epoch: 26, Step: 359/655, Loss: 2.207972, Accuracy: 18.27%\n",
            "Epoch: 26, Step: 360/655, Loss: 2.207832, Accuracy: 18.27%\n",
            "Epoch: 26, Step: 361/655, Loss: 2.208034, Accuracy: 18.26%\n",
            "Epoch: 26, Step: 362/655, Loss: 2.208208, Accuracy: 18.24%\n",
            "Epoch: 26, Step: 363/655, Loss: 2.208277, Accuracy: 18.23%\n",
            "Epoch: 26, Step: 364/655, Loss: 2.208321, Accuracy: 18.24%\n",
            "Epoch: 26, Step: 365/655, Loss: 2.208163, Accuracy: 18.26%\n",
            "Epoch: 26, Step: 366/655, Loss: 2.208087, Accuracy: 18.27%\n",
            "Epoch: 26, Step: 367/655, Loss: 2.208172, Accuracy: 18.26%\n",
            "Epoch: 26, Step: 368/655, Loss: 2.208559, Accuracy: 18.24%\n",
            "Epoch: 26, Step: 369/655, Loss: 2.209002, Accuracy: 18.22%\n",
            "Epoch: 26, Step: 370/655, Loss: 2.208630, Accuracy: 18.25%\n",
            "Epoch: 26, Step: 371/655, Loss: 2.208457, Accuracy: 18.29%\n",
            "Epoch: 26, Step: 372/655, Loss: 2.208436, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 373/655, Loss: 2.208683, Accuracy: 18.28%\n",
            "Epoch: 26, Step: 374/655, Loss: 2.208854, Accuracy: 18.25%\n",
            "Epoch: 26, Step: 375/655, Loss: 2.208686, Accuracy: 18.27%\n",
            "Epoch: 26, Step: 376/655, Loss: 2.208799, Accuracy: 18.24%\n",
            "Epoch: 26, Step: 377/655, Loss: 2.208537, Accuracy: 18.28%\n",
            "Epoch: 26, Step: 378/655, Loss: 2.208558, Accuracy: 18.28%\n",
            "Epoch: 26, Step: 379/655, Loss: 2.208511, Accuracy: 18.26%\n",
            "Epoch: 26, Step: 380/655, Loss: 2.208347, Accuracy: 18.27%\n",
            "Epoch: 26, Step: 381/655, Loss: 2.208329, Accuracy: 18.27%\n",
            "Epoch: 26, Step: 382/655, Loss: 2.208146, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 383/655, Loss: 2.208229, Accuracy: 18.29%\n",
            "Epoch: 26, Step: 384/655, Loss: 2.208305, Accuracy: 18.29%\n",
            "Epoch: 26, Step: 385/655, Loss: 2.208474, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 386/655, Loss: 2.208340, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 387/655, Loss: 2.208007, Accuracy: 18.39%\n",
            "Epoch: 26, Step: 388/655, Loss: 2.208039, Accuracy: 18.39%\n",
            "Epoch: 26, Step: 389/655, Loss: 2.207862, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 390/655, Loss: 2.207588, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 391/655, Loss: 2.207537, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 392/655, Loss: 2.207665, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 393/655, Loss: 2.207633, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 394/655, Loss: 2.207756, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 395/655, Loss: 2.207884, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 396/655, Loss: 2.207998, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 397/655, Loss: 2.208277, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 398/655, Loss: 2.208091, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 399/655, Loss: 2.208371, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 400/655, Loss: 2.208568, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 401/655, Loss: 2.208685, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 402/655, Loss: 2.208535, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 403/655, Loss: 2.208602, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 404/655, Loss: 2.208546, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 405/655, Loss: 2.208335, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 406/655, Loss: 2.208338, Accuracy: 18.27%\n",
            "Epoch: 26, Step: 407/655, Loss: 2.208165, Accuracy: 18.28%\n",
            "Epoch: 26, Step: 408/655, Loss: 2.208002, Accuracy: 18.28%\n",
            "Epoch: 26, Step: 409/655, Loss: 2.207521, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 410/655, Loss: 2.207687, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 411/655, Loss: 2.207463, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 412/655, Loss: 2.207263, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 413/655, Loss: 2.206986, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 414/655, Loss: 2.206824, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 415/655, Loss: 2.207042, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 416/655, Loss: 2.206962, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 417/655, Loss: 2.206984, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 418/655, Loss: 2.207049, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 419/655, Loss: 2.206799, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 420/655, Loss: 2.207105, Accuracy: 18.39%\n",
            "Epoch: 26, Step: 421/655, Loss: 2.207096, Accuracy: 18.42%\n",
            "Epoch: 26, Step: 422/655, Loss: 2.207107, Accuracy: 18.42%\n",
            "Epoch: 26, Step: 423/655, Loss: 2.207115, Accuracy: 18.40%\n",
            "Epoch: 26, Step: 424/655, Loss: 2.207300, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 425/655, Loss: 2.207501, Accuracy: 18.37%\n",
            "Epoch: 26, Step: 426/655, Loss: 2.207501, Accuracy: 18.39%\n",
            "Epoch: 26, Step: 427/655, Loss: 2.207551, Accuracy: 18.39%\n",
            "Epoch: 26, Step: 428/655, Loss: 2.207079, Accuracy: 18.41%\n",
            "Epoch: 26, Step: 429/655, Loss: 2.207036, Accuracy: 18.40%\n",
            "Epoch: 26, Step: 430/655, Loss: 2.207175, Accuracy: 18.39%\n",
            "Epoch: 26, Step: 431/655, Loss: 2.207378, Accuracy: 18.41%\n",
            "Epoch: 26, Step: 432/655, Loss: 2.207364, Accuracy: 18.42%\n",
            "Epoch: 26, Step: 433/655, Loss: 2.207423, Accuracy: 18.44%\n",
            "Epoch: 26, Step: 434/655, Loss: 2.207251, Accuracy: 18.44%\n",
            "Epoch: 26, Step: 435/655, Loss: 2.207208, Accuracy: 18.45%\n",
            "Epoch: 26, Step: 436/655, Loss: 2.207111, Accuracy: 18.44%\n",
            "Epoch: 26, Step: 437/655, Loss: 2.207139, Accuracy: 18.45%\n",
            "Epoch: 26, Step: 438/655, Loss: 2.207102, Accuracy: 18.46%\n",
            "Epoch: 26, Step: 439/655, Loss: 2.207247, Accuracy: 18.46%\n",
            "Epoch: 26, Step: 440/655, Loss: 2.207193, Accuracy: 18.45%\n",
            "Epoch: 26, Step: 441/655, Loss: 2.207235, Accuracy: 18.44%\n",
            "Epoch: 26, Step: 442/655, Loss: 2.207099, Accuracy: 18.45%\n",
            "Epoch: 26, Step: 443/655, Loss: 2.207012, Accuracy: 18.48%\n",
            "Epoch: 26, Step: 444/655, Loss: 2.206984, Accuracy: 18.45%\n",
            "Epoch: 26, Step: 445/655, Loss: 2.206978, Accuracy: 18.44%\n",
            "Epoch: 26, Step: 446/655, Loss: 2.207191, Accuracy: 18.43%\n",
            "Epoch: 26, Step: 447/655, Loss: 2.207353, Accuracy: 18.44%\n",
            "Epoch: 26, Step: 448/655, Loss: 2.207406, Accuracy: 18.44%\n",
            "Epoch: 26, Step: 449/655, Loss: 2.207665, Accuracy: 18.42%\n",
            "Epoch: 26, Step: 450/655, Loss: 2.207704, Accuracy: 18.42%\n",
            "Epoch: 26, Step: 451/655, Loss: 2.207433, Accuracy: 18.43%\n",
            "Epoch: 26, Step: 452/655, Loss: 2.207372, Accuracy: 18.43%\n",
            "Epoch: 26, Step: 453/655, Loss: 2.207440, Accuracy: 18.42%\n",
            "Epoch: 26, Step: 454/655, Loss: 2.207242, Accuracy: 18.43%\n",
            "Epoch: 26, Step: 455/655, Loss: 2.207582, Accuracy: 18.41%\n",
            "Epoch: 26, Step: 456/655, Loss: 2.207776, Accuracy: 18.39%\n",
            "Epoch: 26, Step: 457/655, Loss: 2.207730, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 458/655, Loss: 2.207653, Accuracy: 18.39%\n",
            "Epoch: 26, Step: 459/655, Loss: 2.207728, Accuracy: 18.37%\n",
            "Epoch: 26, Step: 460/655, Loss: 2.207855, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 461/655, Loss: 2.207802, Accuracy: 18.39%\n",
            "Epoch: 26, Step: 462/655, Loss: 2.207912, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 463/655, Loss: 2.207849, Accuracy: 18.39%\n",
            "Epoch: 26, Step: 464/655, Loss: 2.207905, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 465/655, Loss: 2.207918, Accuracy: 18.39%\n",
            "Epoch: 26, Step: 466/655, Loss: 2.207765, Accuracy: 18.40%\n",
            "Epoch: 26, Step: 467/655, Loss: 2.207437, Accuracy: 18.44%\n",
            "Epoch: 26, Step: 468/655, Loss: 2.207154, Accuracy: 18.46%\n",
            "Epoch: 26, Step: 469/655, Loss: 2.206870, Accuracy: 18.47%\n",
            "Epoch: 26, Step: 470/655, Loss: 2.207197, Accuracy: 18.46%\n",
            "Epoch: 26, Step: 471/655, Loss: 2.207254, Accuracy: 18.44%\n",
            "Epoch: 26, Step: 472/655, Loss: 2.207108, Accuracy: 18.44%\n",
            "Epoch: 26, Step: 473/655, Loss: 2.206959, Accuracy: 18.45%\n",
            "Epoch: 26, Step: 474/655, Loss: 2.206972, Accuracy: 18.45%\n",
            "Epoch: 26, Step: 475/655, Loss: 2.206729, Accuracy: 18.46%\n",
            "Epoch: 26, Step: 476/655, Loss: 2.206907, Accuracy: 18.47%\n",
            "Epoch: 26, Step: 477/655, Loss: 2.207015, Accuracy: 18.47%\n",
            "Epoch: 26, Step: 478/655, Loss: 2.207443, Accuracy: 18.46%\n",
            "Epoch: 26, Step: 479/655, Loss: 2.207487, Accuracy: 18.45%\n",
            "Epoch: 26, Step: 480/655, Loss: 2.207601, Accuracy: 18.46%\n",
            "Epoch: 26, Step: 481/655, Loss: 2.207736, Accuracy: 18.45%\n",
            "Epoch: 26, Step: 482/655, Loss: 2.207752, Accuracy: 18.45%\n",
            "Epoch: 26, Step: 483/655, Loss: 2.207701, Accuracy: 18.45%\n",
            "Epoch: 26, Step: 484/655, Loss: 2.207566, Accuracy: 18.47%\n",
            "Epoch: 26, Step: 485/655, Loss: 2.207435, Accuracy: 18.49%\n",
            "Epoch: 26, Step: 486/655, Loss: 2.207558, Accuracy: 18.47%\n",
            "Epoch: 26, Step: 487/655, Loss: 2.207577, Accuracy: 18.47%\n",
            "Epoch: 26, Step: 488/655, Loss: 2.207240, Accuracy: 18.50%\n",
            "Epoch: 26, Step: 489/655, Loss: 2.207107, Accuracy: 18.51%\n",
            "Epoch: 26, Step: 490/655, Loss: 2.207081, Accuracy: 18.49%\n",
            "Epoch: 26, Step: 491/655, Loss: 2.207050, Accuracy: 18.50%\n",
            "Epoch: 26, Step: 492/655, Loss: 2.207183, Accuracy: 18.50%\n",
            "Epoch: 26, Step: 493/655, Loss: 2.207128, Accuracy: 18.53%\n",
            "Epoch: 26, Step: 494/655, Loss: 2.207059, Accuracy: 18.53%\n",
            "Epoch: 26, Step: 495/655, Loss: 2.207460, Accuracy: 18.51%\n",
            "Epoch: 26, Step: 496/655, Loss: 2.207311, Accuracy: 18.53%\n",
            "Epoch: 26, Step: 497/655, Loss: 2.207250, Accuracy: 18.52%\n",
            "Epoch: 26, Step: 498/655, Loss: 2.207328, Accuracy: 18.52%\n",
            "Epoch: 26, Step: 499/655, Loss: 2.207586, Accuracy: 18.51%\n",
            "Epoch: 26, Step: 500/655, Loss: 2.207467, Accuracy: 18.49%\n",
            "Epoch: 26, Step: 501/655, Loss: 2.207403, Accuracy: 18.48%\n",
            "Epoch: 26, Step: 502/655, Loss: 2.207521, Accuracy: 18.49%\n",
            "Epoch: 26, Step: 503/655, Loss: 2.207549, Accuracy: 18.48%\n",
            "Epoch: 26, Step: 504/655, Loss: 2.207474, Accuracy: 18.47%\n",
            "Epoch: 26, Step: 505/655, Loss: 2.207459, Accuracy: 18.45%\n",
            "Epoch: 26, Step: 506/655, Loss: 2.207852, Accuracy: 18.43%\n",
            "Epoch: 26, Step: 507/655, Loss: 2.207939, Accuracy: 18.42%\n",
            "Epoch: 26, Step: 508/655, Loss: 2.207897, Accuracy: 18.41%\n",
            "Epoch: 26, Step: 509/655, Loss: 2.207804, Accuracy: 18.42%\n",
            "Epoch: 26, Step: 510/655, Loss: 2.207891, Accuracy: 18.40%\n",
            "Epoch: 26, Step: 511/655, Loss: 2.207868, Accuracy: 18.41%\n",
            "Epoch: 26, Step: 512/655, Loss: 2.207822, Accuracy: 18.41%\n",
            "Epoch: 26, Step: 513/655, Loss: 2.207601, Accuracy: 18.41%\n",
            "Epoch: 26, Step: 514/655, Loss: 2.207674, Accuracy: 18.42%\n",
            "Epoch: 26, Step: 515/655, Loss: 2.207607, Accuracy: 18.41%\n",
            "Epoch: 26, Step: 516/655, Loss: 2.207526, Accuracy: 18.43%\n",
            "Epoch: 26, Step: 517/655, Loss: 2.207555, Accuracy: 18.44%\n",
            "Epoch: 26, Step: 518/655, Loss: 2.207532, Accuracy: 18.45%\n",
            "Epoch: 26, Step: 519/655, Loss: 2.207704, Accuracy: 18.44%\n",
            "Epoch: 26, Step: 520/655, Loss: 2.207767, Accuracy: 18.43%\n",
            "Epoch: 26, Step: 521/655, Loss: 2.207706, Accuracy: 18.43%\n",
            "Epoch: 26, Step: 522/655, Loss: 2.207770, Accuracy: 18.44%\n",
            "Epoch: 26, Step: 523/655, Loss: 2.207594, Accuracy: 18.45%\n",
            "Epoch: 26, Step: 524/655, Loss: 2.207439, Accuracy: 18.43%\n",
            "Epoch: 26, Step: 525/655, Loss: 2.207365, Accuracy: 18.43%\n",
            "Epoch: 26, Step: 526/655, Loss: 2.207437, Accuracy: 18.41%\n",
            "Epoch: 26, Step: 527/655, Loss: 2.207354, Accuracy: 18.42%\n",
            "Epoch: 26, Step: 528/655, Loss: 2.207479, Accuracy: 18.40%\n",
            "Epoch: 26, Step: 529/655, Loss: 2.207567, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 530/655, Loss: 2.207537, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 531/655, Loss: 2.207826, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 532/655, Loss: 2.207863, Accuracy: 18.37%\n",
            "Epoch: 26, Step: 533/655, Loss: 2.207728, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 534/655, Loss: 2.207750, Accuracy: 18.37%\n",
            "Epoch: 26, Step: 535/655, Loss: 2.207889, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 536/655, Loss: 2.207918, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 537/655, Loss: 2.207829, Accuracy: 18.37%\n",
            "Epoch: 26, Step: 538/655, Loss: 2.207761, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 539/655, Loss: 2.207612, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 540/655, Loss: 2.207721, Accuracy: 18.37%\n",
            "Epoch: 26, Step: 541/655, Loss: 2.207700, Accuracy: 18.37%\n",
            "Epoch: 26, Step: 542/655, Loss: 2.207551, Accuracy: 18.39%\n",
            "Epoch: 26, Step: 543/655, Loss: 2.207750, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 544/655, Loss: 2.207880, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 545/655, Loss: 2.208021, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 546/655, Loss: 2.207938, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 547/655, Loss: 2.207836, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 548/655, Loss: 2.207815, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 549/655, Loss: 2.207761, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 550/655, Loss: 2.207597, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 551/655, Loss: 2.207626, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 552/655, Loss: 2.207899, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 553/655, Loss: 2.207915, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 554/655, Loss: 2.207824, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 555/655, Loss: 2.207921, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 556/655, Loss: 2.207755, Accuracy: 18.37%\n",
            "Epoch: 26, Step: 557/655, Loss: 2.207782, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 558/655, Loss: 2.207767, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 559/655, Loss: 2.207806, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 560/655, Loss: 2.207744, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 561/655, Loss: 2.207548, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 562/655, Loss: 2.207788, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 563/655, Loss: 2.207888, Accuracy: 18.37%\n",
            "Epoch: 26, Step: 564/655, Loss: 2.207774, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 565/655, Loss: 2.207965, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 566/655, Loss: 2.208021, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 567/655, Loss: 2.208132, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 568/655, Loss: 2.208014, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 569/655, Loss: 2.208082, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 570/655, Loss: 2.208173, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 571/655, Loss: 2.208237, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 572/655, Loss: 2.208246, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 573/655, Loss: 2.208366, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 574/655, Loss: 2.208295, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 575/655, Loss: 2.208302, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 576/655, Loss: 2.208194, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 577/655, Loss: 2.207768, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 578/655, Loss: 2.207580, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 579/655, Loss: 2.207494, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 580/655, Loss: 2.207383, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 581/655, Loss: 2.207435, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 582/655, Loss: 2.207340, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 583/655, Loss: 2.207399, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 584/655, Loss: 2.207260, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 585/655, Loss: 2.207332, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 586/655, Loss: 2.207307, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 587/655, Loss: 2.207199, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 588/655, Loss: 2.207222, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 589/655, Loss: 2.207292, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 590/655, Loss: 2.207101, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 591/655, Loss: 2.207164, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 592/655, Loss: 2.207258, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 593/655, Loss: 2.207129, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 594/655, Loss: 2.206956, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 595/655, Loss: 2.207080, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 596/655, Loss: 2.206983, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 597/655, Loss: 2.206845, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 598/655, Loss: 2.206913, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 599/655, Loss: 2.206836, Accuracy: 18.37%\n",
            "Epoch: 26, Step: 600/655, Loss: 2.206676, Accuracy: 18.38%\n",
            "Epoch: 26, Step: 601/655, Loss: 2.206987, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 602/655, Loss: 2.206955, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 603/655, Loss: 2.207104, Accuracy: 18.36%\n",
            "Epoch: 26, Step: 604/655, Loss: 2.207062, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 605/655, Loss: 2.207162, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 606/655, Loss: 2.207305, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 607/655, Loss: 2.207325, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 608/655, Loss: 2.207206, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 609/655, Loss: 2.207087, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 610/655, Loss: 2.207097, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 611/655, Loss: 2.206993, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 612/655, Loss: 2.207097, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 613/655, Loss: 2.207306, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 614/655, Loss: 2.207314, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 615/655, Loss: 2.207317, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 616/655, Loss: 2.207382, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 617/655, Loss: 2.207311, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 618/655, Loss: 2.207229, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 619/655, Loss: 2.207210, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 620/655, Loss: 2.207083, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 621/655, Loss: 2.207118, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 622/655, Loss: 2.207309, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 623/655, Loss: 2.207194, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 624/655, Loss: 2.207331, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 625/655, Loss: 2.207440, Accuracy: 18.29%\n",
            "Epoch: 26, Step: 626/655, Loss: 2.207510, Accuracy: 18.29%\n",
            "Epoch: 26, Step: 627/655, Loss: 2.207422, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 628/655, Loss: 2.207600, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 629/655, Loss: 2.207760, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 630/655, Loss: 2.208019, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 631/655, Loss: 2.207869, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 632/655, Loss: 2.207930, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 633/655, Loss: 2.207991, Accuracy: 18.29%\n",
            "Epoch: 26, Step: 634/655, Loss: 2.207761, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 635/655, Loss: 2.207691, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 636/655, Loss: 2.207777, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 637/655, Loss: 2.207686, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 638/655, Loss: 2.207605, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 639/655, Loss: 2.207611, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 640/655, Loss: 2.207594, Accuracy: 18.30%\n",
            "Epoch: 26, Step: 641/655, Loss: 2.207669, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 642/655, Loss: 2.207576, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 643/655, Loss: 2.207492, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 644/655, Loss: 2.207498, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 645/655, Loss: 2.207695, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 646/655, Loss: 2.207884, Accuracy: 18.31%\n",
            "Epoch: 26, Step: 647/655, Loss: 2.207819, Accuracy: 18.33%\n",
            "Epoch: 26, Step: 648/655, Loss: 2.207818, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 649/655, Loss: 2.207876, Accuracy: 18.35%\n",
            "Epoch: 26, Step: 650/655, Loss: 2.207913, Accuracy: 18.34%\n",
            "Epoch: 26, Step: 651/655, Loss: 2.207957, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 652/655, Loss: 2.207915, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 653/655, Loss: 2.207865, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 654/655, Loss: 2.207854, Accuracy: 18.32%\n",
            "Epoch: 26, Step: 655/655, Loss: 2.207651, Accuracy: 18.33%\n",
            "Epoch: 27, Step: 1/655, Loss: 2.240673, Accuracy: 18.75%\n",
            "Epoch: 27, Step: 2/655, Loss: 2.279091, Accuracy: 15.62%\n",
            "Epoch: 27, Step: 3/655, Loss: 2.229645, Accuracy: 21.88%\n",
            "Epoch: 27, Step: 4/655, Loss: 2.245434, Accuracy: 20.31%\n",
            "Epoch: 27, Step: 5/655, Loss: 2.245368, Accuracy: 18.75%\n",
            "Epoch: 27, Step: 6/655, Loss: 2.266274, Accuracy: 17.19%\n",
            "Epoch: 27, Step: 7/655, Loss: 2.244714, Accuracy: 16.96%\n",
            "Epoch: 27, Step: 8/655, Loss: 2.250516, Accuracy: 17.19%\n",
            "Epoch: 27, Step: 9/655, Loss: 2.241262, Accuracy: 17.71%\n",
            "Epoch: 27, Step: 10/655, Loss: 2.239636, Accuracy: 17.81%\n",
            "Epoch: 27, Step: 11/655, Loss: 2.241000, Accuracy: 17.05%\n",
            "Epoch: 27, Step: 12/655, Loss: 2.233571, Accuracy: 17.97%\n",
            "Epoch: 27, Step: 13/655, Loss: 2.235355, Accuracy: 18.51%\n",
            "Epoch: 27, Step: 14/655, Loss: 2.225795, Accuracy: 18.97%\n",
            "Epoch: 27, Step: 15/655, Loss: 2.231253, Accuracy: 18.75%\n",
            "Epoch: 27, Step: 16/655, Loss: 2.230749, Accuracy: 19.14%\n",
            "Epoch: 27, Step: 17/655, Loss: 2.228553, Accuracy: 19.67%\n",
            "Epoch: 27, Step: 18/655, Loss: 2.231299, Accuracy: 19.62%\n",
            "Epoch: 27, Step: 19/655, Loss: 2.228669, Accuracy: 19.74%\n",
            "Epoch: 27, Step: 20/655, Loss: 2.219826, Accuracy: 20.16%\n",
            "Epoch: 27, Step: 21/655, Loss: 2.215868, Accuracy: 19.64%\n",
            "Epoch: 27, Step: 22/655, Loss: 2.218113, Accuracy: 19.18%\n",
            "Epoch: 27, Step: 23/655, Loss: 2.222619, Accuracy: 19.02%\n",
            "Epoch: 27, Step: 24/655, Loss: 2.227409, Accuracy: 18.62%\n",
            "Epoch: 27, Step: 25/655, Loss: 2.225387, Accuracy: 18.38%\n",
            "Epoch: 27, Step: 26/655, Loss: 2.230927, Accuracy: 17.79%\n",
            "Epoch: 27, Step: 27/655, Loss: 2.228333, Accuracy: 17.94%\n",
            "Epoch: 27, Step: 28/655, Loss: 2.225686, Accuracy: 17.97%\n",
            "Epoch: 27, Step: 29/655, Loss: 2.225195, Accuracy: 18.00%\n",
            "Epoch: 27, Step: 30/655, Loss: 2.226690, Accuracy: 18.02%\n",
            "Epoch: 27, Step: 31/655, Loss: 2.224122, Accuracy: 17.84%\n",
            "Epoch: 27, Step: 32/655, Loss: 2.225503, Accuracy: 17.58%\n",
            "Epoch: 27, Step: 33/655, Loss: 2.221694, Accuracy: 17.71%\n",
            "Epoch: 27, Step: 34/655, Loss: 2.221446, Accuracy: 17.74%\n",
            "Epoch: 27, Step: 35/655, Loss: 2.221397, Accuracy: 17.77%\n",
            "Epoch: 27, Step: 36/655, Loss: 2.223109, Accuracy: 17.62%\n",
            "Epoch: 27, Step: 37/655, Loss: 2.218919, Accuracy: 17.65%\n",
            "Epoch: 27, Step: 38/655, Loss: 2.218675, Accuracy: 17.68%\n",
            "Epoch: 27, Step: 39/655, Loss: 2.218786, Accuracy: 17.39%\n",
            "Epoch: 27, Step: 40/655, Loss: 2.218463, Accuracy: 17.50%\n",
            "Epoch: 27, Step: 41/655, Loss: 2.217623, Accuracy: 17.76%\n",
            "Epoch: 27, Step: 42/655, Loss: 2.217750, Accuracy: 17.78%\n",
            "Epoch: 27, Step: 43/655, Loss: 2.218030, Accuracy: 17.88%\n",
            "Epoch: 27, Step: 44/655, Loss: 2.217221, Accuracy: 18.04%\n",
            "Epoch: 27, Step: 45/655, Loss: 2.217691, Accuracy: 18.12%\n",
            "Epoch: 27, Step: 46/655, Loss: 2.218163, Accuracy: 18.07%\n",
            "Epoch: 27, Step: 47/655, Loss: 2.217081, Accuracy: 18.35%\n",
            "Epoch: 27, Step: 48/655, Loss: 2.216128, Accuracy: 18.36%\n",
            "Epoch: 27, Step: 49/655, Loss: 2.213224, Accuracy: 18.37%\n",
            "Epoch: 27, Step: 50/655, Loss: 2.213258, Accuracy: 18.31%\n",
            "Epoch: 27, Step: 51/655, Loss: 2.213869, Accuracy: 18.26%\n",
            "Epoch: 27, Step: 52/655, Loss: 2.213460, Accuracy: 18.15%\n",
            "Epoch: 27, Step: 53/655, Loss: 2.209458, Accuracy: 18.34%\n",
            "Epoch: 27, Step: 54/655, Loss: 2.207670, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 55/655, Loss: 2.207792, Accuracy: 18.30%\n",
            "Epoch: 27, Step: 56/655, Loss: 2.211002, Accuracy: 18.02%\n",
            "Epoch: 27, Step: 57/655, Loss: 2.209977, Accuracy: 18.09%\n",
            "Epoch: 27, Step: 58/655, Loss: 2.212063, Accuracy: 18.05%\n",
            "Epoch: 27, Step: 59/655, Loss: 2.210983, Accuracy: 18.22%\n",
            "Epoch: 27, Step: 60/655, Loss: 2.209082, Accuracy: 18.33%\n",
            "Epoch: 27, Step: 61/655, Loss: 2.210189, Accuracy: 18.19%\n",
            "Epoch: 27, Step: 62/655, Loss: 2.211473, Accuracy: 18.15%\n",
            "Epoch: 27, Step: 63/655, Loss: 2.210545, Accuracy: 18.11%\n",
            "Epoch: 27, Step: 64/655, Loss: 2.209318, Accuracy: 18.21%\n",
            "Epoch: 27, Step: 65/655, Loss: 2.210130, Accuracy: 18.22%\n",
            "Epoch: 27, Step: 66/655, Loss: 2.209993, Accuracy: 18.37%\n",
            "Epoch: 27, Step: 67/655, Loss: 2.208476, Accuracy: 18.42%\n",
            "Epoch: 27, Step: 68/655, Loss: 2.207884, Accuracy: 18.38%\n",
            "Epoch: 27, Step: 69/655, Loss: 2.208313, Accuracy: 18.16%\n",
            "Epoch: 27, Step: 70/655, Loss: 2.206573, Accuracy: 18.30%\n",
            "Epoch: 27, Step: 71/655, Loss: 2.205736, Accuracy: 18.31%\n",
            "Epoch: 27, Step: 72/655, Loss: 2.203742, Accuracy: 18.53%\n",
            "Epoch: 27, Step: 73/655, Loss: 2.203130, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 74/655, Loss: 2.202314, Accuracy: 18.71%\n",
            "Epoch: 27, Step: 75/655, Loss: 2.204835, Accuracy: 18.54%\n",
            "Epoch: 27, Step: 76/655, Loss: 2.203389, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 77/655, Loss: 2.203498, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 78/655, Loss: 2.203024, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 79/655, Loss: 2.205327, Accuracy: 18.51%\n",
            "Epoch: 27, Step: 80/655, Loss: 2.206162, Accuracy: 18.44%\n",
            "Epoch: 27, Step: 81/655, Loss: 2.206111, Accuracy: 18.36%\n",
            "Epoch: 27, Step: 82/655, Loss: 2.206854, Accuracy: 18.33%\n",
            "Epoch: 27, Step: 83/655, Loss: 2.205835, Accuracy: 18.45%\n",
            "Epoch: 27, Step: 84/655, Loss: 2.205862, Accuracy: 18.45%\n",
            "Epoch: 27, Step: 85/655, Loss: 2.205726, Accuracy: 18.42%\n",
            "Epoch: 27, Step: 86/655, Loss: 2.206489, Accuracy: 18.39%\n",
            "Epoch: 27, Step: 87/655, Loss: 2.205618, Accuracy: 18.46%\n",
            "Epoch: 27, Step: 88/655, Loss: 2.205214, Accuracy: 18.54%\n",
            "Epoch: 27, Step: 89/655, Loss: 2.205891, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 90/655, Loss: 2.206119, Accuracy: 18.51%\n",
            "Epoch: 27, Step: 91/655, Loss: 2.204911, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 92/655, Loss: 2.205721, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 93/655, Loss: 2.206090, Accuracy: 18.45%\n",
            "Epoch: 27, Step: 94/655, Loss: 2.206784, Accuracy: 18.38%\n",
            "Epoch: 27, Step: 95/655, Loss: 2.206571, Accuracy: 18.42%\n",
            "Epoch: 27, Step: 96/655, Loss: 2.206351, Accuracy: 18.42%\n",
            "Epoch: 27, Step: 97/655, Loss: 2.205542, Accuracy: 18.49%\n",
            "Epoch: 27, Step: 98/655, Loss: 2.204783, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 99/655, Loss: 2.204528, Accuracy: 18.53%\n",
            "Epoch: 27, Step: 100/655, Loss: 2.204376, Accuracy: 18.53%\n",
            "Epoch: 27, Step: 101/655, Loss: 2.204076, Accuracy: 18.53%\n",
            "Epoch: 27, Step: 102/655, Loss: 2.204515, Accuracy: 18.54%\n",
            "Epoch: 27, Step: 103/655, Loss: 2.203774, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 104/655, Loss: 2.202932, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 105/655, Loss: 2.203542, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 106/655, Loss: 2.204677, Accuracy: 18.54%\n",
            "Epoch: 27, Step: 107/655, Loss: 2.204440, Accuracy: 18.52%\n",
            "Epoch: 27, Step: 108/655, Loss: 2.203653, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 109/655, Loss: 2.203613, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 110/655, Loss: 2.203075, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 111/655, Loss: 2.204785, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 112/655, Loss: 2.204500, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 113/655, Loss: 2.205426, Accuracy: 18.53%\n",
            "Epoch: 27, Step: 114/655, Loss: 2.204843, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 115/655, Loss: 2.204249, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 116/655, Loss: 2.203996, Accuracy: 18.72%\n",
            "Epoch: 27, Step: 117/655, Loss: 2.204489, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 118/655, Loss: 2.203847, Accuracy: 18.70%\n",
            "Epoch: 27, Step: 119/655, Loss: 2.203342, Accuracy: 18.75%\n",
            "Epoch: 27, Step: 120/655, Loss: 2.204109, Accuracy: 18.70%\n",
            "Epoch: 27, Step: 121/655, Loss: 2.203706, Accuracy: 18.75%\n",
            "Epoch: 27, Step: 122/655, Loss: 2.203939, Accuracy: 18.78%\n",
            "Epoch: 27, Step: 123/655, Loss: 2.203777, Accuracy: 18.83%\n",
            "Epoch: 27, Step: 124/655, Loss: 2.202844, Accuracy: 18.78%\n",
            "Epoch: 27, Step: 125/655, Loss: 2.202168, Accuracy: 18.80%\n",
            "Epoch: 27, Step: 126/655, Loss: 2.201905, Accuracy: 18.80%\n",
            "Epoch: 27, Step: 127/655, Loss: 2.201220, Accuracy: 18.82%\n",
            "Epoch: 27, Step: 128/655, Loss: 2.201160, Accuracy: 18.77%\n",
            "Epoch: 27, Step: 129/655, Loss: 2.200042, Accuracy: 18.82%\n",
            "Epoch: 27, Step: 130/655, Loss: 2.201149, Accuracy: 18.82%\n",
            "Epoch: 27, Step: 131/655, Loss: 2.200446, Accuracy: 18.87%\n",
            "Epoch: 27, Step: 132/655, Loss: 2.200807, Accuracy: 18.89%\n",
            "Epoch: 27, Step: 133/655, Loss: 2.200817, Accuracy: 18.87%\n",
            "Epoch: 27, Step: 134/655, Loss: 2.200732, Accuracy: 18.82%\n",
            "Epoch: 27, Step: 135/655, Loss: 2.201173, Accuracy: 18.75%\n",
            "Epoch: 27, Step: 136/655, Loss: 2.200789, Accuracy: 18.75%\n",
            "Epoch: 27, Step: 137/655, Loss: 2.200330, Accuracy: 18.77%\n",
            "Epoch: 27, Step: 138/655, Loss: 2.199539, Accuracy: 18.84%\n",
            "Epoch: 27, Step: 139/655, Loss: 2.199502, Accuracy: 18.86%\n",
            "Epoch: 27, Step: 140/655, Loss: 2.199284, Accuracy: 18.88%\n",
            "Epoch: 27, Step: 141/655, Loss: 2.200170, Accuracy: 18.91%\n",
            "Epoch: 27, Step: 142/655, Loss: 2.200197, Accuracy: 18.86%\n",
            "Epoch: 27, Step: 143/655, Loss: 2.199296, Accuracy: 18.90%\n",
            "Epoch: 27, Step: 144/655, Loss: 2.199668, Accuracy: 18.84%\n",
            "Epoch: 27, Step: 145/655, Loss: 2.199215, Accuracy: 18.86%\n",
            "Epoch: 27, Step: 146/655, Loss: 2.199126, Accuracy: 18.88%\n",
            "Epoch: 27, Step: 147/655, Loss: 2.197981, Accuracy: 19.01%\n",
            "Epoch: 27, Step: 148/655, Loss: 2.197781, Accuracy: 19.02%\n",
            "Epoch: 27, Step: 149/655, Loss: 2.198251, Accuracy: 18.96%\n",
            "Epoch: 27, Step: 150/655, Loss: 2.198074, Accuracy: 18.98%\n",
            "Epoch: 27, Step: 151/655, Loss: 2.198221, Accuracy: 18.98%\n",
            "Epoch: 27, Step: 152/655, Loss: 2.198359, Accuracy: 19.02%\n",
            "Epoch: 27, Step: 153/655, Loss: 2.198241, Accuracy: 19.04%\n",
            "Epoch: 27, Step: 154/655, Loss: 2.198755, Accuracy: 19.03%\n",
            "Epoch: 27, Step: 155/655, Loss: 2.198686, Accuracy: 19.07%\n",
            "Epoch: 27, Step: 156/655, Loss: 2.198356, Accuracy: 19.09%\n",
            "Epoch: 27, Step: 157/655, Loss: 2.197912, Accuracy: 19.11%\n",
            "Epoch: 27, Step: 158/655, Loss: 2.197662, Accuracy: 19.07%\n",
            "Epoch: 27, Step: 159/655, Loss: 2.198022, Accuracy: 19.06%\n",
            "Epoch: 27, Step: 160/655, Loss: 2.197547, Accuracy: 19.12%\n",
            "Epoch: 27, Step: 161/655, Loss: 2.197357, Accuracy: 19.06%\n",
            "Epoch: 27, Step: 162/655, Loss: 2.197629, Accuracy: 19.04%\n",
            "Epoch: 27, Step: 163/655, Loss: 2.198247, Accuracy: 19.02%\n",
            "Epoch: 27, Step: 164/655, Loss: 2.198267, Accuracy: 19.02%\n",
            "Epoch: 27, Step: 165/655, Loss: 2.197848, Accuracy: 19.03%\n",
            "Epoch: 27, Step: 166/655, Loss: 2.197298, Accuracy: 19.07%\n",
            "Epoch: 27, Step: 167/655, Loss: 2.196935, Accuracy: 19.12%\n",
            "Epoch: 27, Step: 168/655, Loss: 2.196753, Accuracy: 19.14%\n",
            "Epoch: 27, Step: 169/655, Loss: 2.196946, Accuracy: 19.18%\n",
            "Epoch: 27, Step: 170/655, Loss: 2.197532, Accuracy: 19.15%\n",
            "Epoch: 27, Step: 171/655, Loss: 2.198119, Accuracy: 19.12%\n",
            "Epoch: 27, Step: 172/655, Loss: 2.198377, Accuracy: 19.10%\n",
            "Epoch: 27, Step: 173/655, Loss: 2.198625, Accuracy: 19.08%\n",
            "Epoch: 27, Step: 174/655, Loss: 2.198670, Accuracy: 19.06%\n",
            "Epoch: 27, Step: 175/655, Loss: 2.199519, Accuracy: 19.00%\n",
            "Epoch: 27, Step: 176/655, Loss: 2.199484, Accuracy: 18.98%\n",
            "Epoch: 27, Step: 177/655, Loss: 2.199714, Accuracy: 19.00%\n",
            "Epoch: 27, Step: 178/655, Loss: 2.199492, Accuracy: 19.03%\n",
            "Epoch: 27, Step: 179/655, Loss: 2.198934, Accuracy: 19.06%\n",
            "Epoch: 27, Step: 180/655, Loss: 2.199398, Accuracy: 19.06%\n",
            "Epoch: 27, Step: 181/655, Loss: 2.199613, Accuracy: 19.06%\n",
            "Epoch: 27, Step: 182/655, Loss: 2.199549, Accuracy: 19.06%\n",
            "Epoch: 27, Step: 183/655, Loss: 2.199559, Accuracy: 19.04%\n",
            "Epoch: 27, Step: 184/655, Loss: 2.199748, Accuracy: 19.07%\n",
            "Epoch: 27, Step: 185/655, Loss: 2.199883, Accuracy: 19.05%\n",
            "Epoch: 27, Step: 186/655, Loss: 2.199831, Accuracy: 19.05%\n",
            "Epoch: 27, Step: 187/655, Loss: 2.200039, Accuracy: 19.03%\n",
            "Epoch: 27, Step: 188/655, Loss: 2.199631, Accuracy: 19.02%\n",
            "Epoch: 27, Step: 189/655, Loss: 2.200036, Accuracy: 18.96%\n",
            "Epoch: 27, Step: 190/655, Loss: 2.200383, Accuracy: 18.98%\n",
            "Epoch: 27, Step: 191/655, Loss: 2.200866, Accuracy: 19.03%\n",
            "Epoch: 27, Step: 192/655, Loss: 2.200881, Accuracy: 19.06%\n",
            "Epoch: 27, Step: 193/655, Loss: 2.200675, Accuracy: 19.04%\n",
            "Epoch: 27, Step: 194/655, Loss: 2.200899, Accuracy: 19.01%\n",
            "Epoch: 27, Step: 195/655, Loss: 2.200337, Accuracy: 19.04%\n",
            "Epoch: 27, Step: 196/655, Loss: 2.200823, Accuracy: 19.02%\n",
            "Epoch: 27, Step: 197/655, Loss: 2.200037, Accuracy: 19.00%\n",
            "Epoch: 27, Step: 198/655, Loss: 2.199991, Accuracy: 19.03%\n",
            "Epoch: 27, Step: 199/655, Loss: 2.199804, Accuracy: 19.05%\n",
            "Epoch: 27, Step: 200/655, Loss: 2.199831, Accuracy: 19.06%\n",
            "Epoch: 27, Step: 201/655, Loss: 2.200563, Accuracy: 19.01%\n",
            "Epoch: 27, Step: 202/655, Loss: 2.200696, Accuracy: 19.01%\n",
            "Epoch: 27, Step: 203/655, Loss: 2.200650, Accuracy: 19.00%\n",
            "Epoch: 27, Step: 204/655, Loss: 2.200281, Accuracy: 19.00%\n",
            "Epoch: 27, Step: 205/655, Loss: 2.200225, Accuracy: 19.02%\n",
            "Epoch: 27, Step: 206/655, Loss: 2.200911, Accuracy: 18.99%\n",
            "Epoch: 27, Step: 207/655, Loss: 2.201163, Accuracy: 18.99%\n",
            "Epoch: 27, Step: 208/655, Loss: 2.201346, Accuracy: 19.02%\n",
            "Epoch: 27, Step: 209/655, Loss: 2.202126, Accuracy: 18.97%\n",
            "Epoch: 27, Step: 210/655, Loss: 2.202409, Accuracy: 18.99%\n",
            "Epoch: 27, Step: 211/655, Loss: 2.202726, Accuracy: 18.99%\n",
            "Epoch: 27, Step: 212/655, Loss: 2.202731, Accuracy: 18.99%\n",
            "Epoch: 27, Step: 213/655, Loss: 2.202990, Accuracy: 18.98%\n",
            "Epoch: 27, Step: 214/655, Loss: 2.203020, Accuracy: 19.00%\n",
            "Epoch: 27, Step: 215/655, Loss: 2.203020, Accuracy: 18.97%\n",
            "Epoch: 27, Step: 216/655, Loss: 2.203076, Accuracy: 18.97%\n",
            "Epoch: 27, Step: 217/655, Loss: 2.203246, Accuracy: 19.02%\n",
            "Epoch: 27, Step: 218/655, Loss: 2.203453, Accuracy: 18.98%\n",
            "Epoch: 27, Step: 219/655, Loss: 2.203680, Accuracy: 18.96%\n",
            "Epoch: 27, Step: 220/655, Loss: 2.204419, Accuracy: 18.92%\n",
            "Epoch: 27, Step: 221/655, Loss: 2.204712, Accuracy: 18.91%\n",
            "Epoch: 27, Step: 222/655, Loss: 2.204245, Accuracy: 18.92%\n",
            "Epoch: 27, Step: 223/655, Loss: 2.204011, Accuracy: 18.90%\n",
            "Epoch: 27, Step: 224/655, Loss: 2.203856, Accuracy: 18.89%\n",
            "Epoch: 27, Step: 225/655, Loss: 2.204009, Accuracy: 18.93%\n",
            "Epoch: 27, Step: 226/655, Loss: 2.204332, Accuracy: 18.89%\n",
            "Epoch: 27, Step: 227/655, Loss: 2.204287, Accuracy: 18.93%\n",
            "Epoch: 27, Step: 228/655, Loss: 2.204541, Accuracy: 18.87%\n",
            "Epoch: 27, Step: 229/655, Loss: 2.204542, Accuracy: 18.85%\n",
            "Epoch: 27, Step: 230/655, Loss: 2.204676, Accuracy: 18.82%\n",
            "Epoch: 27, Step: 231/655, Loss: 2.204815, Accuracy: 18.82%\n",
            "Epoch: 27, Step: 232/655, Loss: 2.204908, Accuracy: 18.84%\n",
            "Epoch: 27, Step: 233/655, Loss: 2.204514, Accuracy: 18.84%\n",
            "Epoch: 27, Step: 234/655, Loss: 2.204842, Accuracy: 18.83%\n",
            "Epoch: 27, Step: 235/655, Loss: 2.204838, Accuracy: 18.82%\n",
            "Epoch: 27, Step: 236/655, Loss: 2.204841, Accuracy: 18.79%\n",
            "Epoch: 27, Step: 237/655, Loss: 2.205008, Accuracy: 18.74%\n",
            "Epoch: 27, Step: 238/655, Loss: 2.205015, Accuracy: 18.70%\n",
            "Epoch: 27, Step: 239/655, Loss: 2.205019, Accuracy: 18.68%\n",
            "Epoch: 27, Step: 240/655, Loss: 2.205195, Accuracy: 18.70%\n",
            "Epoch: 27, Step: 241/655, Loss: 2.205710, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 242/655, Loss: 2.205666, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 243/655, Loss: 2.205861, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 244/655, Loss: 2.206317, Accuracy: 18.62%\n",
            "Epoch: 27, Step: 245/655, Loss: 2.206029, Accuracy: 18.62%\n",
            "Epoch: 27, Step: 246/655, Loss: 2.206647, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 247/655, Loss: 2.206826, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 248/655, Loss: 2.206823, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 249/655, Loss: 2.206986, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 250/655, Loss: 2.207414, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 251/655, Loss: 2.207699, Accuracy: 18.53%\n",
            "Epoch: 27, Step: 252/655, Loss: 2.207548, Accuracy: 18.53%\n",
            "Epoch: 27, Step: 253/655, Loss: 2.206672, Accuracy: 18.53%\n",
            "Epoch: 27, Step: 254/655, Loss: 2.206226, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 255/655, Loss: 2.206439, Accuracy: 18.53%\n",
            "Epoch: 27, Step: 256/655, Loss: 2.207014, Accuracy: 18.52%\n",
            "Epoch: 27, Step: 257/655, Loss: 2.207292, Accuracy: 18.53%\n",
            "Epoch: 27, Step: 258/655, Loss: 2.207234, Accuracy: 18.54%\n",
            "Epoch: 27, Step: 259/655, Loss: 2.206809, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 260/655, Loss: 2.206699, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 261/655, Loss: 2.207061, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 262/655, Loss: 2.206896, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 263/655, Loss: 2.206693, Accuracy: 18.62%\n",
            "Epoch: 27, Step: 264/655, Loss: 2.206985, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 265/655, Loss: 2.207491, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 266/655, Loss: 2.207577, Accuracy: 18.62%\n",
            "Epoch: 27, Step: 267/655, Loss: 2.207970, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 268/655, Loss: 2.208285, Accuracy: 18.62%\n",
            "Epoch: 27, Step: 269/655, Loss: 2.208078, Accuracy: 18.65%\n",
            "Epoch: 27, Step: 270/655, Loss: 2.208001, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 271/655, Loss: 2.207483, Accuracy: 18.69%\n",
            "Epoch: 27, Step: 272/655, Loss: 2.207524, Accuracy: 18.70%\n",
            "Epoch: 27, Step: 273/655, Loss: 2.207680, Accuracy: 18.68%\n",
            "Epoch: 27, Step: 274/655, Loss: 2.207360, Accuracy: 18.69%\n",
            "Epoch: 27, Step: 275/655, Loss: 2.207511, Accuracy: 18.70%\n",
            "Epoch: 27, Step: 276/655, Loss: 2.207618, Accuracy: 18.73%\n",
            "Epoch: 27, Step: 277/655, Loss: 2.207398, Accuracy: 18.73%\n",
            "Epoch: 27, Step: 278/655, Loss: 2.207668, Accuracy: 18.69%\n",
            "Epoch: 27, Step: 279/655, Loss: 2.207370, Accuracy: 18.72%\n",
            "Epoch: 27, Step: 280/655, Loss: 2.207626, Accuracy: 18.68%\n",
            "Epoch: 27, Step: 281/655, Loss: 2.207393, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 282/655, Loss: 2.207484, Accuracy: 18.65%\n",
            "Epoch: 27, Step: 283/655, Loss: 2.207647, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 284/655, Loss: 2.207298, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 285/655, Loss: 2.207036, Accuracy: 18.67%\n",
            "Epoch: 27, Step: 286/655, Loss: 2.206519, Accuracy: 18.70%\n",
            "Epoch: 27, Step: 287/655, Loss: 2.206436, Accuracy: 18.67%\n",
            "Epoch: 27, Step: 288/655, Loss: 2.206617, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 289/655, Loss: 2.206696, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 290/655, Loss: 2.206730, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 291/655, Loss: 2.206269, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 292/655, Loss: 2.206457, Accuracy: 18.62%\n",
            "Epoch: 27, Step: 293/655, Loss: 2.206484, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 294/655, Loss: 2.206705, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 295/655, Loss: 2.206543, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 296/655, Loss: 2.206216, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 297/655, Loss: 2.206192, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 298/655, Loss: 2.205993, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 299/655, Loss: 2.205864, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 300/655, Loss: 2.205839, Accuracy: 18.54%\n",
            "Epoch: 27, Step: 301/655, Loss: 2.205041, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 302/655, Loss: 2.205057, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 303/655, Loss: 2.204572, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 304/655, Loss: 2.204503, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 305/655, Loss: 2.204766, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 306/655, Loss: 2.204651, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 307/655, Loss: 2.204856, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 308/655, Loss: 2.204542, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 309/655, Loss: 2.204745, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 310/655, Loss: 2.204867, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 311/655, Loss: 2.204867, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 312/655, Loss: 2.204665, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 313/655, Loss: 2.204209, Accuracy: 18.71%\n",
            "Epoch: 27, Step: 314/655, Loss: 2.204220, Accuracy: 18.69%\n",
            "Epoch: 27, Step: 315/655, Loss: 2.204549, Accuracy: 18.67%\n",
            "Epoch: 27, Step: 316/655, Loss: 2.204416, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 317/655, Loss: 2.204276, Accuracy: 18.70%\n",
            "Epoch: 27, Step: 318/655, Loss: 2.204824, Accuracy: 18.67%\n",
            "Epoch: 27, Step: 319/655, Loss: 2.204695, Accuracy: 18.71%\n",
            "Epoch: 27, Step: 320/655, Loss: 2.204858, Accuracy: 18.69%\n",
            "Epoch: 27, Step: 321/655, Loss: 2.204967, Accuracy: 18.68%\n",
            "Epoch: 27, Step: 322/655, Loss: 2.204895, Accuracy: 18.69%\n",
            "Epoch: 27, Step: 323/655, Loss: 2.204726, Accuracy: 18.69%\n",
            "Epoch: 27, Step: 324/655, Loss: 2.204763, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 325/655, Loss: 2.204746, Accuracy: 18.65%\n",
            "Epoch: 27, Step: 326/655, Loss: 2.204859, Accuracy: 18.65%\n",
            "Epoch: 27, Step: 327/655, Loss: 2.205089, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 328/655, Loss: 2.205263, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 329/655, Loss: 2.205160, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 330/655, Loss: 2.205407, Accuracy: 18.62%\n",
            "Epoch: 27, Step: 331/655, Loss: 2.205184, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 332/655, Loss: 2.205155, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 333/655, Loss: 2.205540, Accuracy: 18.67%\n",
            "Epoch: 27, Step: 334/655, Loss: 2.205691, Accuracy: 18.68%\n",
            "Epoch: 27, Step: 335/655, Loss: 2.205648, Accuracy: 18.68%\n",
            "Epoch: 27, Step: 336/655, Loss: 2.205911, Accuracy: 18.70%\n",
            "Epoch: 27, Step: 337/655, Loss: 2.205836, Accuracy: 18.68%\n",
            "Epoch: 27, Step: 338/655, Loss: 2.205765, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 339/655, Loss: 2.205904, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 340/655, Loss: 2.205971, Accuracy: 18.65%\n",
            "Epoch: 27, Step: 341/655, Loss: 2.206211, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 342/655, Loss: 2.206603, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 343/655, Loss: 2.206737, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 344/655, Loss: 2.206374, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 345/655, Loss: 2.206448, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 346/655, Loss: 2.206667, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 347/655, Loss: 2.206495, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 348/655, Loss: 2.206371, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 349/655, Loss: 2.205923, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 350/655, Loss: 2.205853, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 351/655, Loss: 2.205895, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 352/655, Loss: 2.206003, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 353/655, Loss: 2.206281, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 354/655, Loss: 2.206413, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 355/655, Loss: 2.206599, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 356/655, Loss: 2.206765, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 357/655, Loss: 2.206811, Accuracy: 18.62%\n",
            "Epoch: 27, Step: 358/655, Loss: 2.206867, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 359/655, Loss: 2.206878, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 360/655, Loss: 2.206957, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 361/655, Loss: 2.207244, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 362/655, Loss: 2.207074, Accuracy: 18.62%\n",
            "Epoch: 27, Step: 363/655, Loss: 2.207131, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 364/655, Loss: 2.206889, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 365/655, Loss: 2.206363, Accuracy: 18.62%\n",
            "Epoch: 27, Step: 366/655, Loss: 2.206354, Accuracy: 18.65%\n",
            "Epoch: 27, Step: 367/655, Loss: 2.206454, Accuracy: 18.65%\n",
            "Epoch: 27, Step: 368/655, Loss: 2.206315, Accuracy: 18.67%\n",
            "Epoch: 27, Step: 369/655, Loss: 2.206482, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 370/655, Loss: 2.206126, Accuracy: 18.65%\n",
            "Epoch: 27, Step: 371/655, Loss: 2.205875, Accuracy: 18.67%\n",
            "Epoch: 27, Step: 372/655, Loss: 2.205678, Accuracy: 18.70%\n",
            "Epoch: 27, Step: 373/655, Loss: 2.205628, Accuracy: 18.72%\n",
            "Epoch: 27, Step: 374/655, Loss: 2.205659, Accuracy: 18.70%\n",
            "Epoch: 27, Step: 375/655, Loss: 2.205614, Accuracy: 18.70%\n",
            "Epoch: 27, Step: 376/655, Loss: 2.205838, Accuracy: 18.67%\n",
            "Epoch: 27, Step: 377/655, Loss: 2.206351, Accuracy: 18.65%\n",
            "Epoch: 27, Step: 378/655, Loss: 2.206346, Accuracy: 18.68%\n",
            "Epoch: 27, Step: 379/655, Loss: 2.206677, Accuracy: 18.67%\n",
            "Epoch: 27, Step: 380/655, Loss: 2.206715, Accuracy: 18.67%\n",
            "Epoch: 27, Step: 381/655, Loss: 2.206371, Accuracy: 18.67%\n",
            "Epoch: 27, Step: 382/655, Loss: 2.206168, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 383/655, Loss: 2.205935, Accuracy: 18.68%\n",
            "Epoch: 27, Step: 384/655, Loss: 2.206188, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 385/655, Loss: 2.206284, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 386/655, Loss: 2.206033, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 387/655, Loss: 2.206295, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 388/655, Loss: 2.206419, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 389/655, Loss: 2.206736, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 390/655, Loss: 2.206837, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 391/655, Loss: 2.206284, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 392/655, Loss: 2.206361, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 393/655, Loss: 2.206236, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 394/655, Loss: 2.206249, Accuracy: 18.64%\n",
            "Epoch: 27, Step: 395/655, Loss: 2.206475, Accuracy: 18.65%\n",
            "Epoch: 27, Step: 396/655, Loss: 2.206489, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 397/655, Loss: 2.206317, Accuracy: 18.66%\n",
            "Epoch: 27, Step: 398/655, Loss: 2.206383, Accuracy: 18.63%\n",
            "Epoch: 27, Step: 399/655, Loss: 2.206722, Accuracy: 18.61%\n",
            "Epoch: 27, Step: 400/655, Loss: 2.206572, Accuracy: 18.62%\n",
            "Epoch: 27, Step: 401/655, Loss: 2.207030, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 402/655, Loss: 2.206828, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 403/655, Loss: 2.206584, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 404/655, Loss: 2.206547, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 405/655, Loss: 2.206764, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 406/655, Loss: 2.206955, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 407/655, Loss: 2.207343, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 408/655, Loss: 2.207423, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 409/655, Loss: 2.207249, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 410/655, Loss: 2.206980, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 411/655, Loss: 2.207077, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 412/655, Loss: 2.207146, Accuracy: 18.60%\n",
            "Epoch: 27, Step: 413/655, Loss: 2.207508, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 414/655, Loss: 2.207621, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 415/655, Loss: 2.207622, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 416/655, Loss: 2.207561, Accuracy: 18.54%\n",
            "Epoch: 27, Step: 417/655, Loss: 2.207836, Accuracy: 18.53%\n",
            "Epoch: 27, Step: 418/655, Loss: 2.208041, Accuracy: 18.50%\n",
            "Epoch: 27, Step: 419/655, Loss: 2.208543, Accuracy: 18.49%\n",
            "Epoch: 27, Step: 420/655, Loss: 2.208646, Accuracy: 18.50%\n",
            "Epoch: 27, Step: 421/655, Loss: 2.208452, Accuracy: 18.51%\n",
            "Epoch: 27, Step: 422/655, Loss: 2.208434, Accuracy: 18.49%\n",
            "Epoch: 27, Step: 423/655, Loss: 2.208632, Accuracy: 18.48%\n",
            "Epoch: 27, Step: 424/655, Loss: 2.208389, Accuracy: 18.50%\n",
            "Epoch: 27, Step: 425/655, Loss: 2.208461, Accuracy: 18.50%\n",
            "Epoch: 27, Step: 426/655, Loss: 2.208631, Accuracy: 18.49%\n",
            "Epoch: 27, Step: 427/655, Loss: 2.208921, Accuracy: 18.49%\n",
            "Epoch: 27, Step: 428/655, Loss: 2.208889, Accuracy: 18.49%\n",
            "Epoch: 27, Step: 429/655, Loss: 2.209057, Accuracy: 18.51%\n",
            "Epoch: 27, Step: 430/655, Loss: 2.209163, Accuracy: 18.48%\n",
            "Epoch: 27, Step: 431/655, Loss: 2.209198, Accuracy: 18.46%\n",
            "Epoch: 27, Step: 432/655, Loss: 2.209289, Accuracy: 18.47%\n",
            "Epoch: 27, Step: 433/655, Loss: 2.209311, Accuracy: 18.47%\n",
            "Epoch: 27, Step: 434/655, Loss: 2.209449, Accuracy: 18.46%\n",
            "Epoch: 27, Step: 435/655, Loss: 2.209356, Accuracy: 18.44%\n",
            "Epoch: 27, Step: 436/655, Loss: 2.209461, Accuracy: 18.44%\n",
            "Epoch: 27, Step: 437/655, Loss: 2.209518, Accuracy: 18.44%\n",
            "Epoch: 27, Step: 438/655, Loss: 2.209674, Accuracy: 18.44%\n",
            "Epoch: 27, Step: 439/655, Loss: 2.209769, Accuracy: 18.41%\n",
            "Epoch: 27, Step: 440/655, Loss: 2.209873, Accuracy: 18.41%\n",
            "Epoch: 27, Step: 441/655, Loss: 2.209531, Accuracy: 18.42%\n",
            "Epoch: 27, Step: 442/655, Loss: 2.209247, Accuracy: 18.45%\n",
            "Epoch: 27, Step: 443/655, Loss: 2.209069, Accuracy: 18.46%\n",
            "Epoch: 27, Step: 444/655, Loss: 2.208985, Accuracy: 18.45%\n",
            "Epoch: 27, Step: 445/655, Loss: 2.208957, Accuracy: 18.46%\n",
            "Epoch: 27, Step: 446/655, Loss: 2.209032, Accuracy: 18.43%\n",
            "Epoch: 27, Step: 447/655, Loss: 2.209004, Accuracy: 18.44%\n",
            "Epoch: 27, Step: 448/655, Loss: 2.208957, Accuracy: 18.43%\n",
            "Epoch: 27, Step: 449/655, Loss: 2.208982, Accuracy: 18.42%\n",
            "Epoch: 27, Step: 450/655, Loss: 2.208642, Accuracy: 18.44%\n",
            "Epoch: 27, Step: 451/655, Loss: 2.208592, Accuracy: 18.46%\n",
            "Epoch: 27, Step: 452/655, Loss: 2.208480, Accuracy: 18.45%\n",
            "Epoch: 27, Step: 453/655, Loss: 2.208721, Accuracy: 18.43%\n",
            "Epoch: 27, Step: 454/655, Loss: 2.208718, Accuracy: 18.45%\n",
            "Epoch: 27, Step: 455/655, Loss: 2.208913, Accuracy: 18.43%\n",
            "Epoch: 27, Step: 456/655, Loss: 2.208570, Accuracy: 18.44%\n",
            "Epoch: 27, Step: 457/655, Loss: 2.208632, Accuracy: 18.44%\n",
            "Epoch: 27, Step: 458/655, Loss: 2.208668, Accuracy: 18.46%\n",
            "Epoch: 27, Step: 459/655, Loss: 2.208796, Accuracy: 18.45%\n",
            "Epoch: 27, Step: 460/655, Loss: 2.208918, Accuracy: 18.46%\n",
            "Epoch: 27, Step: 461/655, Loss: 2.208563, Accuracy: 18.49%\n",
            "Epoch: 27, Step: 462/655, Loss: 2.208714, Accuracy: 18.50%\n",
            "Epoch: 27, Step: 463/655, Loss: 2.208715, Accuracy: 18.50%\n",
            "Epoch: 27, Step: 464/655, Loss: 2.208907, Accuracy: 18.48%\n",
            "Epoch: 27, Step: 465/655, Loss: 2.209044, Accuracy: 18.47%\n",
            "Epoch: 27, Step: 466/655, Loss: 2.208974, Accuracy: 18.49%\n",
            "Epoch: 27, Step: 467/655, Loss: 2.209273, Accuracy: 18.47%\n",
            "Epoch: 27, Step: 468/655, Loss: 2.209384, Accuracy: 18.48%\n",
            "Epoch: 27, Step: 469/655, Loss: 2.209437, Accuracy: 18.46%\n",
            "Epoch: 27, Step: 470/655, Loss: 2.209344, Accuracy: 18.45%\n",
            "Epoch: 27, Step: 471/655, Loss: 2.209179, Accuracy: 18.47%\n",
            "Epoch: 27, Step: 472/655, Loss: 2.209386, Accuracy: 18.45%\n",
            "Epoch: 27, Step: 473/655, Loss: 2.209439, Accuracy: 18.44%\n",
            "Epoch: 27, Step: 474/655, Loss: 2.209884, Accuracy: 18.41%\n",
            "Epoch: 27, Step: 475/655, Loss: 2.209850, Accuracy: 18.41%\n",
            "Epoch: 27, Step: 476/655, Loss: 2.210034, Accuracy: 18.43%\n",
            "Epoch: 27, Step: 477/655, Loss: 2.209972, Accuracy: 18.43%\n",
            "Epoch: 27, Step: 478/655, Loss: 2.209956, Accuracy: 18.41%\n",
            "Epoch: 27, Step: 479/655, Loss: 2.210117, Accuracy: 18.40%\n",
            "Epoch: 27, Step: 480/655, Loss: 2.209991, Accuracy: 18.39%\n",
            "Epoch: 27, Step: 481/655, Loss: 2.209797, Accuracy: 18.42%\n",
            "Epoch: 27, Step: 482/655, Loss: 2.210007, Accuracy: 18.39%\n",
            "Epoch: 27, Step: 483/655, Loss: 2.209929, Accuracy: 18.39%\n",
            "Epoch: 27, Step: 484/655, Loss: 2.209662, Accuracy: 18.41%\n",
            "Epoch: 27, Step: 485/655, Loss: 2.209964, Accuracy: 18.40%\n",
            "Epoch: 27, Step: 486/655, Loss: 2.209796, Accuracy: 18.42%\n",
            "Epoch: 27, Step: 487/655, Loss: 2.209780, Accuracy: 18.43%\n",
            "Epoch: 27, Step: 488/655, Loss: 2.209501, Accuracy: 18.44%\n",
            "Epoch: 27, Step: 489/655, Loss: 2.209614, Accuracy: 18.44%\n",
            "Epoch: 27, Step: 490/655, Loss: 2.209790, Accuracy: 18.42%\n",
            "Epoch: 27, Step: 491/655, Loss: 2.209880, Accuracy: 18.41%\n",
            "Epoch: 27, Step: 492/655, Loss: 2.209819, Accuracy: 18.40%\n",
            "Epoch: 27, Step: 493/655, Loss: 2.209750, Accuracy: 18.42%\n",
            "Epoch: 27, Step: 494/655, Loss: 2.209885, Accuracy: 18.42%\n",
            "Epoch: 27, Step: 495/655, Loss: 2.210082, Accuracy: 18.42%\n",
            "Epoch: 27, Step: 496/655, Loss: 2.210120, Accuracy: 18.40%\n",
            "Epoch: 27, Step: 497/655, Loss: 2.210240, Accuracy: 18.39%\n",
            "Epoch: 27, Step: 498/655, Loss: 2.210390, Accuracy: 18.41%\n",
            "Epoch: 27, Step: 499/655, Loss: 2.210318, Accuracy: 18.41%\n",
            "Epoch: 27, Step: 500/655, Loss: 2.210132, Accuracy: 18.39%\n",
            "Epoch: 27, Step: 501/655, Loss: 2.210113, Accuracy: 18.39%\n",
            "Epoch: 27, Step: 502/655, Loss: 2.209869, Accuracy: 18.40%\n",
            "Epoch: 27, Step: 503/655, Loss: 2.209900, Accuracy: 18.38%\n",
            "Epoch: 27, Step: 504/655, Loss: 2.209958, Accuracy: 18.39%\n",
            "Epoch: 27, Step: 505/655, Loss: 2.209826, Accuracy: 18.38%\n",
            "Epoch: 27, Step: 506/655, Loss: 2.209835, Accuracy: 18.37%\n",
            "Epoch: 27, Step: 507/655, Loss: 2.209600, Accuracy: 18.37%\n",
            "Epoch: 27, Step: 508/655, Loss: 2.209663, Accuracy: 18.37%\n",
            "Epoch: 27, Step: 509/655, Loss: 2.209761, Accuracy: 18.37%\n",
            "Epoch: 27, Step: 510/655, Loss: 2.209908, Accuracy: 18.36%\n",
            "Epoch: 27, Step: 511/655, Loss: 2.209925, Accuracy: 18.33%\n",
            "Epoch: 27, Step: 512/655, Loss: 2.210067, Accuracy: 18.32%\n",
            "Epoch: 27, Step: 513/655, Loss: 2.210084, Accuracy: 18.32%\n",
            "Epoch: 27, Step: 514/655, Loss: 2.209945, Accuracy: 18.32%\n",
            "Epoch: 27, Step: 515/655, Loss: 2.209917, Accuracy: 18.32%\n",
            "Epoch: 27, Step: 516/655, Loss: 2.210080, Accuracy: 18.31%\n",
            "Epoch: 27, Step: 517/655, Loss: 2.210175, Accuracy: 18.30%\n",
            "Epoch: 27, Step: 518/655, Loss: 2.209863, Accuracy: 18.31%\n",
            "Epoch: 27, Step: 519/655, Loss: 2.209933, Accuracy: 18.33%\n",
            "Epoch: 27, Step: 520/655, Loss: 2.209957, Accuracy: 18.32%\n",
            "Epoch: 27, Step: 521/655, Loss: 2.209801, Accuracy: 18.34%\n",
            "Epoch: 27, Step: 522/655, Loss: 2.209689, Accuracy: 18.35%\n",
            "Epoch: 27, Step: 523/655, Loss: 2.209893, Accuracy: 18.33%\n",
            "Epoch: 27, Step: 524/655, Loss: 2.209740, Accuracy: 18.34%\n",
            "Epoch: 27, Step: 525/655, Loss: 2.209748, Accuracy: 18.33%\n",
            "Epoch: 27, Step: 526/655, Loss: 2.209787, Accuracy: 18.33%\n",
            "Epoch: 27, Step: 527/655, Loss: 2.209933, Accuracy: 18.33%\n",
            "Epoch: 27, Step: 528/655, Loss: 2.209917, Accuracy: 18.33%\n",
            "Epoch: 27, Step: 529/655, Loss: 2.209830, Accuracy: 18.34%\n",
            "Epoch: 27, Step: 530/655, Loss: 2.209815, Accuracy: 18.33%\n",
            "Epoch: 27, Step: 531/655, Loss: 2.209521, Accuracy: 18.37%\n",
            "Epoch: 27, Step: 532/655, Loss: 2.209255, Accuracy: 18.39%\n",
            "Epoch: 27, Step: 533/655, Loss: 2.209192, Accuracy: 18.39%\n",
            "Epoch: 27, Step: 534/655, Loss: 2.209067, Accuracy: 18.40%\n",
            "Epoch: 27, Step: 535/655, Loss: 2.209045, Accuracy: 18.41%\n",
            "Epoch: 27, Step: 536/655, Loss: 2.209147, Accuracy: 18.39%\n",
            "Epoch: 27, Step: 537/655, Loss: 2.209024, Accuracy: 18.41%\n",
            "Epoch: 27, Step: 538/655, Loss: 2.209082, Accuracy: 18.40%\n",
            "Epoch: 27, Step: 539/655, Loss: 2.209045, Accuracy: 18.41%\n",
            "Epoch: 27, Step: 540/655, Loss: 2.208902, Accuracy: 18.41%\n",
            "Epoch: 27, Step: 541/655, Loss: 2.208952, Accuracy: 18.41%\n",
            "Epoch: 27, Step: 542/655, Loss: 2.208958, Accuracy: 18.41%\n",
            "Epoch: 27, Step: 543/655, Loss: 2.208990, Accuracy: 18.42%\n",
            "Epoch: 27, Step: 544/655, Loss: 2.208876, Accuracy: 18.44%\n",
            "Epoch: 27, Step: 545/655, Loss: 2.208701, Accuracy: 18.46%\n",
            "Epoch: 27, Step: 546/655, Loss: 2.208701, Accuracy: 18.48%\n",
            "Epoch: 27, Step: 547/655, Loss: 2.208774, Accuracy: 18.48%\n",
            "Epoch: 27, Step: 548/655, Loss: 2.208614, Accuracy: 18.47%\n",
            "Epoch: 27, Step: 549/655, Loss: 2.208521, Accuracy: 18.48%\n",
            "Epoch: 27, Step: 550/655, Loss: 2.208340, Accuracy: 18.51%\n",
            "Epoch: 27, Step: 551/655, Loss: 2.208305, Accuracy: 18.51%\n",
            "Epoch: 27, Step: 552/655, Loss: 2.208397, Accuracy: 18.52%\n",
            "Epoch: 27, Step: 553/655, Loss: 2.208275, Accuracy: 18.52%\n",
            "Epoch: 27, Step: 554/655, Loss: 2.208280, Accuracy: 18.52%\n",
            "Epoch: 27, Step: 555/655, Loss: 2.208310, Accuracy: 18.53%\n",
            "Epoch: 27, Step: 556/655, Loss: 2.208185, Accuracy: 18.53%\n",
            "Epoch: 27, Step: 557/655, Loss: 2.208294, Accuracy: 18.52%\n",
            "Epoch: 27, Step: 558/655, Loss: 2.208239, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 559/655, Loss: 2.208428, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 560/655, Loss: 2.208543, Accuracy: 18.54%\n",
            "Epoch: 27, Step: 561/655, Loss: 2.208440, Accuracy: 18.54%\n",
            "Epoch: 27, Step: 562/655, Loss: 2.208377, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 563/655, Loss: 2.208395, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 564/655, Loss: 2.208427, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 565/655, Loss: 2.208199, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 566/655, Loss: 2.208269, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 567/655, Loss: 2.208366, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 568/655, Loss: 2.208282, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 569/655, Loss: 2.208256, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 570/655, Loss: 2.208277, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 571/655, Loss: 2.208305, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 572/655, Loss: 2.208345, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 573/655, Loss: 2.208345, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 574/655, Loss: 2.208289, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 575/655, Loss: 2.208148, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 576/655, Loss: 2.208116, Accuracy: 18.54%\n",
            "Epoch: 27, Step: 577/655, Loss: 2.208371, Accuracy: 18.52%\n",
            "Epoch: 27, Step: 578/655, Loss: 2.208399, Accuracy: 18.52%\n",
            "Epoch: 27, Step: 579/655, Loss: 2.208400, Accuracy: 18.51%\n",
            "Epoch: 27, Step: 580/655, Loss: 2.208533, Accuracy: 18.51%\n",
            "Epoch: 27, Step: 581/655, Loss: 2.208578, Accuracy: 18.52%\n",
            "Epoch: 27, Step: 582/655, Loss: 2.208650, Accuracy: 18.51%\n",
            "Epoch: 27, Step: 583/655, Loss: 2.208550, Accuracy: 18.51%\n",
            "Epoch: 27, Step: 584/655, Loss: 2.208405, Accuracy: 18.53%\n",
            "Epoch: 27, Step: 585/655, Loss: 2.208611, Accuracy: 18.52%\n",
            "Epoch: 27, Step: 586/655, Loss: 2.208484, Accuracy: 18.54%\n",
            "Epoch: 27, Step: 587/655, Loss: 2.208554, Accuracy: 18.53%\n",
            "Epoch: 27, Step: 588/655, Loss: 2.208440, Accuracy: 18.52%\n",
            "Epoch: 27, Step: 589/655, Loss: 2.208501, Accuracy: 18.51%\n",
            "Epoch: 27, Step: 590/655, Loss: 2.208490, Accuracy: 18.50%\n",
            "Epoch: 27, Step: 591/655, Loss: 2.208503, Accuracy: 18.49%\n",
            "Epoch: 27, Step: 592/655, Loss: 2.208636, Accuracy: 18.48%\n",
            "Epoch: 27, Step: 593/655, Loss: 2.208558, Accuracy: 18.48%\n",
            "Epoch: 27, Step: 594/655, Loss: 2.208494, Accuracy: 18.49%\n",
            "Epoch: 27, Step: 595/655, Loss: 2.208594, Accuracy: 18.49%\n",
            "Epoch: 27, Step: 596/655, Loss: 2.208596, Accuracy: 18.49%\n",
            "Epoch: 27, Step: 597/655, Loss: 2.208583, Accuracy: 18.50%\n",
            "Epoch: 27, Step: 598/655, Loss: 2.208487, Accuracy: 18.50%\n",
            "Epoch: 27, Step: 599/655, Loss: 2.208426, Accuracy: 18.52%\n",
            "Epoch: 27, Step: 600/655, Loss: 2.208482, Accuracy: 18.51%\n",
            "Epoch: 27, Step: 601/655, Loss: 2.208241, Accuracy: 18.54%\n",
            "Epoch: 27, Step: 602/655, Loss: 2.207911, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 603/655, Loss: 2.207976, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 604/655, Loss: 2.207943, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 605/655, Loss: 2.207884, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 606/655, Loss: 2.207792, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 607/655, Loss: 2.207870, Accuracy: 18.54%\n",
            "Epoch: 27, Step: 608/655, Loss: 2.207624, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 609/655, Loss: 2.207603, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 610/655, Loss: 2.207742, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 611/655, Loss: 2.207778, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 612/655, Loss: 2.207644, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 613/655, Loss: 2.207746, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 614/655, Loss: 2.207836, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 615/655, Loss: 2.207784, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 616/655, Loss: 2.207818, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 617/655, Loss: 2.207867, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 618/655, Loss: 2.207877, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 619/655, Loss: 2.207730, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 620/655, Loss: 2.207711, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 621/655, Loss: 2.207554, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 622/655, Loss: 2.207646, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 623/655, Loss: 2.207681, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 624/655, Loss: 2.207869, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 625/655, Loss: 2.207959, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 626/655, Loss: 2.207852, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 627/655, Loss: 2.207943, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 628/655, Loss: 2.207906, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 629/655, Loss: 2.207896, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 630/655, Loss: 2.207934, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 631/655, Loss: 2.207877, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 632/655, Loss: 2.207962, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 633/655, Loss: 2.207949, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 634/655, Loss: 2.208151, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 635/655, Loss: 2.208126, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 636/655, Loss: 2.208248, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 637/655, Loss: 2.208171, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 638/655, Loss: 2.208298, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 639/655, Loss: 2.208232, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 640/655, Loss: 2.208185, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 641/655, Loss: 2.208196, Accuracy: 18.55%\n",
            "Epoch: 27, Step: 642/655, Loss: 2.208159, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 643/655, Loss: 2.208060, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 644/655, Loss: 2.208001, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 645/655, Loss: 2.208107, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 646/655, Loss: 2.207886, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 647/655, Loss: 2.207741, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 648/655, Loss: 2.207711, Accuracy: 18.59%\n",
            "Epoch: 27, Step: 649/655, Loss: 2.207666, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 650/655, Loss: 2.207646, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 651/655, Loss: 2.207656, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 652/655, Loss: 2.207896, Accuracy: 18.56%\n",
            "Epoch: 27, Step: 653/655, Loss: 2.207817, Accuracy: 18.57%\n",
            "Epoch: 27, Step: 654/655, Loss: 2.207765, Accuracy: 18.58%\n",
            "Epoch: 27, Step: 655/655, Loss: 2.207735, Accuracy: 18.57%\n",
            "Epoch: 28, Step: 1/655, Loss: 2.262232, Accuracy: 15.62%\n",
            "Epoch: 28, Step: 2/655, Loss: 2.246945, Accuracy: 17.19%\n",
            "Epoch: 28, Step: 3/655, Loss: 2.242672, Accuracy: 14.58%\n",
            "Epoch: 28, Step: 4/655, Loss: 2.249410, Accuracy: 13.28%\n",
            "Epoch: 28, Step: 5/655, Loss: 2.256992, Accuracy: 12.50%\n",
            "Epoch: 28, Step: 6/655, Loss: 2.254666, Accuracy: 13.02%\n",
            "Epoch: 28, Step: 7/655, Loss: 2.241656, Accuracy: 13.84%\n",
            "Epoch: 28, Step: 8/655, Loss: 2.240601, Accuracy: 13.28%\n",
            "Epoch: 28, Step: 9/655, Loss: 2.230752, Accuracy: 13.54%\n",
            "Epoch: 28, Step: 10/655, Loss: 2.222966, Accuracy: 14.06%\n",
            "Epoch: 28, Step: 11/655, Loss: 2.215470, Accuracy: 14.77%\n",
            "Epoch: 28, Step: 12/655, Loss: 2.209125, Accuracy: 14.58%\n",
            "Epoch: 28, Step: 13/655, Loss: 2.195054, Accuracy: 15.14%\n",
            "Epoch: 28, Step: 14/655, Loss: 2.199002, Accuracy: 15.18%\n",
            "Epoch: 28, Step: 15/655, Loss: 2.203072, Accuracy: 15.83%\n",
            "Epoch: 28, Step: 16/655, Loss: 2.196640, Accuracy: 15.43%\n",
            "Epoch: 28, Step: 17/655, Loss: 2.201144, Accuracy: 15.26%\n",
            "Epoch: 28, Step: 18/655, Loss: 2.198748, Accuracy: 15.28%\n",
            "Epoch: 28, Step: 19/655, Loss: 2.198573, Accuracy: 14.97%\n",
            "Epoch: 28, Step: 20/655, Loss: 2.202303, Accuracy: 15.31%\n",
            "Epoch: 28, Step: 21/655, Loss: 2.208545, Accuracy: 15.03%\n",
            "Epoch: 28, Step: 22/655, Loss: 2.208387, Accuracy: 15.34%\n",
            "Epoch: 28, Step: 23/655, Loss: 2.202838, Accuracy: 15.76%\n",
            "Epoch: 28, Step: 24/655, Loss: 2.199671, Accuracy: 16.02%\n",
            "Epoch: 28, Step: 25/655, Loss: 2.197348, Accuracy: 16.12%\n",
            "Epoch: 28, Step: 26/655, Loss: 2.194493, Accuracy: 16.35%\n",
            "Epoch: 28, Step: 27/655, Loss: 2.193409, Accuracy: 15.86%\n",
            "Epoch: 28, Step: 28/655, Loss: 2.191928, Accuracy: 15.85%\n",
            "Epoch: 28, Step: 29/655, Loss: 2.190069, Accuracy: 15.95%\n",
            "Epoch: 28, Step: 30/655, Loss: 2.192795, Accuracy: 15.73%\n",
            "Epoch: 28, Step: 31/655, Loss: 2.190133, Accuracy: 16.33%\n",
            "Epoch: 28, Step: 32/655, Loss: 2.194346, Accuracy: 16.31%\n",
            "Epoch: 28, Step: 33/655, Loss: 2.195847, Accuracy: 16.19%\n",
            "Epoch: 28, Step: 34/655, Loss: 2.197327, Accuracy: 16.18%\n",
            "Epoch: 28, Step: 35/655, Loss: 2.195389, Accuracy: 16.25%\n",
            "Epoch: 28, Step: 36/655, Loss: 2.196998, Accuracy: 15.97%\n",
            "Epoch: 28, Step: 37/655, Loss: 2.196029, Accuracy: 15.71%\n",
            "Epoch: 28, Step: 38/655, Loss: 2.198002, Accuracy: 15.71%\n",
            "Epoch: 28, Step: 39/655, Loss: 2.194609, Accuracy: 16.11%\n",
            "Epoch: 28, Step: 40/655, Loss: 2.191198, Accuracy: 16.25%\n",
            "Epoch: 28, Step: 41/655, Loss: 2.190959, Accuracy: 16.16%\n",
            "Epoch: 28, Step: 42/655, Loss: 2.193103, Accuracy: 16.00%\n",
            "Epoch: 28, Step: 43/655, Loss: 2.193143, Accuracy: 16.13%\n",
            "Epoch: 28, Step: 44/655, Loss: 2.195143, Accuracy: 16.19%\n",
            "Epoch: 28, Step: 45/655, Loss: 2.192953, Accuracy: 16.53%\n",
            "Epoch: 28, Step: 46/655, Loss: 2.191052, Accuracy: 16.78%\n",
            "Epoch: 28, Step: 47/655, Loss: 2.191705, Accuracy: 16.89%\n",
            "Epoch: 28, Step: 48/655, Loss: 2.191551, Accuracy: 16.80%\n",
            "Epoch: 28, Step: 49/655, Loss: 2.192837, Accuracy: 16.90%\n",
            "Epoch: 28, Step: 50/655, Loss: 2.193947, Accuracy: 16.94%\n",
            "Epoch: 28, Step: 51/655, Loss: 2.196183, Accuracy: 16.85%\n",
            "Epoch: 28, Step: 52/655, Loss: 2.198601, Accuracy: 16.71%\n",
            "Epoch: 28, Step: 53/655, Loss: 2.197609, Accuracy: 16.69%\n",
            "Epoch: 28, Step: 54/655, Loss: 2.198498, Accuracy: 16.61%\n",
            "Epoch: 28, Step: 55/655, Loss: 2.198024, Accuracy: 16.76%\n",
            "Epoch: 28, Step: 56/655, Loss: 2.197163, Accuracy: 16.74%\n",
            "Epoch: 28, Step: 57/655, Loss: 2.196746, Accuracy: 16.56%\n",
            "Epoch: 28, Step: 58/655, Loss: 2.194746, Accuracy: 16.76%\n",
            "Epoch: 28, Step: 59/655, Loss: 2.194128, Accuracy: 17.06%\n",
            "Epoch: 28, Step: 60/655, Loss: 2.194922, Accuracy: 17.08%\n",
            "Epoch: 28, Step: 61/655, Loss: 2.193128, Accuracy: 17.16%\n",
            "Epoch: 28, Step: 62/655, Loss: 2.191865, Accuracy: 17.39%\n",
            "Epoch: 28, Step: 63/655, Loss: 2.190408, Accuracy: 17.66%\n",
            "Epoch: 28, Step: 64/655, Loss: 2.189983, Accuracy: 17.58%\n",
            "Epoch: 28, Step: 65/655, Loss: 2.190326, Accuracy: 17.60%\n",
            "Epoch: 28, Step: 66/655, Loss: 2.191219, Accuracy: 17.47%\n",
            "Epoch: 28, Step: 67/655, Loss: 2.191113, Accuracy: 17.58%\n",
            "Epoch: 28, Step: 68/655, Loss: 2.192274, Accuracy: 17.42%\n",
            "Epoch: 28, Step: 69/655, Loss: 2.192648, Accuracy: 17.48%\n",
            "Epoch: 28, Step: 70/655, Loss: 2.192538, Accuracy: 17.50%\n",
            "Epoch: 28, Step: 71/655, Loss: 2.192748, Accuracy: 17.61%\n",
            "Epoch: 28, Step: 72/655, Loss: 2.193665, Accuracy: 17.53%\n",
            "Epoch: 28, Step: 73/655, Loss: 2.193725, Accuracy: 17.55%\n",
            "Epoch: 28, Step: 74/655, Loss: 2.194124, Accuracy: 17.48%\n",
            "Epoch: 28, Step: 75/655, Loss: 2.193292, Accuracy: 17.62%\n",
            "Epoch: 28, Step: 76/655, Loss: 2.194218, Accuracy: 17.68%\n",
            "Epoch: 28, Step: 77/655, Loss: 2.194060, Accuracy: 17.74%\n",
            "Epoch: 28, Step: 78/655, Loss: 2.194393, Accuracy: 17.71%\n",
            "Epoch: 28, Step: 79/655, Loss: 2.195045, Accuracy: 17.72%\n",
            "Epoch: 28, Step: 80/655, Loss: 2.195336, Accuracy: 17.66%\n",
            "Epoch: 28, Step: 81/655, Loss: 2.196132, Accuracy: 17.59%\n",
            "Epoch: 28, Step: 82/655, Loss: 2.196193, Accuracy: 17.57%\n",
            "Epoch: 28, Step: 83/655, Loss: 2.196817, Accuracy: 17.70%\n",
            "Epoch: 28, Step: 84/655, Loss: 2.197420, Accuracy: 17.52%\n",
            "Epoch: 28, Step: 85/655, Loss: 2.197296, Accuracy: 17.46%\n",
            "Epoch: 28, Step: 86/655, Loss: 2.195400, Accuracy: 17.73%\n",
            "Epoch: 28, Step: 87/655, Loss: 2.194960, Accuracy: 17.78%\n",
            "Epoch: 28, Step: 88/655, Loss: 2.195265, Accuracy: 17.72%\n",
            "Epoch: 28, Step: 89/655, Loss: 2.194854, Accuracy: 17.80%\n",
            "Epoch: 28, Step: 90/655, Loss: 2.195975, Accuracy: 17.81%\n",
            "Epoch: 28, Step: 91/655, Loss: 2.195149, Accuracy: 17.89%\n",
            "Epoch: 28, Step: 92/655, Loss: 2.195707, Accuracy: 17.90%\n",
            "Epoch: 28, Step: 93/655, Loss: 2.195534, Accuracy: 18.01%\n",
            "Epoch: 28, Step: 94/655, Loss: 2.194095, Accuracy: 18.12%\n",
            "Epoch: 28, Step: 95/655, Loss: 2.193942, Accuracy: 18.22%\n",
            "Epoch: 28, Step: 96/655, Loss: 2.193600, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 97/655, Loss: 2.193916, Accuracy: 18.20%\n",
            "Epoch: 28, Step: 98/655, Loss: 2.194385, Accuracy: 18.11%\n",
            "Epoch: 28, Step: 99/655, Loss: 2.193394, Accuracy: 18.18%\n",
            "Epoch: 28, Step: 100/655, Loss: 2.192364, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 101/655, Loss: 2.192782, Accuracy: 18.25%\n",
            "Epoch: 28, Step: 102/655, Loss: 2.193386, Accuracy: 18.20%\n",
            "Epoch: 28, Step: 103/655, Loss: 2.193618, Accuracy: 18.14%\n",
            "Epoch: 28, Step: 104/655, Loss: 2.194641, Accuracy: 18.18%\n",
            "Epoch: 28, Step: 105/655, Loss: 2.195090, Accuracy: 18.15%\n",
            "Epoch: 28, Step: 106/655, Loss: 2.194653, Accuracy: 18.13%\n",
            "Epoch: 28, Step: 107/655, Loss: 2.194616, Accuracy: 18.08%\n",
            "Epoch: 28, Step: 108/655, Loss: 2.194698, Accuracy: 18.06%\n",
            "Epoch: 28, Step: 109/655, Loss: 2.195329, Accuracy: 18.03%\n",
            "Epoch: 28, Step: 110/655, Loss: 2.195613, Accuracy: 18.07%\n",
            "Epoch: 28, Step: 111/655, Loss: 2.195185, Accuracy: 18.19%\n",
            "Epoch: 28, Step: 112/655, Loss: 2.195130, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 113/655, Loss: 2.195193, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 114/655, Loss: 2.195656, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 115/655, Loss: 2.196012, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 116/655, Loss: 2.196236, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 117/655, Loss: 2.196703, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 118/655, Loss: 2.197405, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 119/655, Loss: 2.197907, Accuracy: 18.25%\n",
            "Epoch: 28, Step: 120/655, Loss: 2.197958, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 121/655, Loss: 2.197724, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 122/655, Loss: 2.195897, Accuracy: 18.24%\n",
            "Epoch: 28, Step: 123/655, Loss: 2.195658, Accuracy: 18.22%\n",
            "Epoch: 28, Step: 124/655, Loss: 2.196329, Accuracy: 18.25%\n",
            "Epoch: 28, Step: 125/655, Loss: 2.195480, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 126/655, Loss: 2.194928, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 127/655, Loss: 2.195221, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 128/655, Loss: 2.195030, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 129/655, Loss: 2.195532, Accuracy: 18.44%\n",
            "Epoch: 28, Step: 130/655, Loss: 2.195410, Accuracy: 18.49%\n",
            "Epoch: 28, Step: 131/655, Loss: 2.194713, Accuracy: 18.51%\n",
            "Epoch: 28, Step: 132/655, Loss: 2.194727, Accuracy: 18.47%\n",
            "Epoch: 28, Step: 133/655, Loss: 2.195334, Accuracy: 18.49%\n",
            "Epoch: 28, Step: 134/655, Loss: 2.195174, Accuracy: 18.49%\n",
            "Epoch: 28, Step: 135/655, Loss: 2.195478, Accuracy: 18.54%\n",
            "Epoch: 28, Step: 136/655, Loss: 2.196599, Accuracy: 18.59%\n",
            "Epoch: 28, Step: 137/655, Loss: 2.195354, Accuracy: 18.70%\n",
            "Epoch: 28, Step: 138/655, Loss: 2.195597, Accuracy: 18.68%\n",
            "Epoch: 28, Step: 139/655, Loss: 2.194980, Accuracy: 18.64%\n",
            "Epoch: 28, Step: 140/655, Loss: 2.195072, Accuracy: 18.57%\n",
            "Epoch: 28, Step: 141/655, Loss: 2.195017, Accuracy: 18.53%\n",
            "Epoch: 28, Step: 142/655, Loss: 2.194574, Accuracy: 18.57%\n",
            "Epoch: 28, Step: 143/655, Loss: 2.193886, Accuracy: 18.51%\n",
            "Epoch: 28, Step: 144/655, Loss: 2.193340, Accuracy: 18.58%\n",
            "Epoch: 28, Step: 145/655, Loss: 2.193903, Accuracy: 18.60%\n",
            "Epoch: 28, Step: 146/655, Loss: 2.194481, Accuracy: 18.58%\n",
            "Epoch: 28, Step: 147/655, Loss: 2.194241, Accuracy: 18.54%\n",
            "Epoch: 28, Step: 148/655, Loss: 2.194645, Accuracy: 18.50%\n",
            "Epoch: 28, Step: 149/655, Loss: 2.194726, Accuracy: 18.50%\n",
            "Epoch: 28, Step: 150/655, Loss: 2.195538, Accuracy: 18.46%\n",
            "Epoch: 28, Step: 151/655, Loss: 2.195117, Accuracy: 18.46%\n",
            "Epoch: 28, Step: 152/655, Loss: 2.194680, Accuracy: 18.44%\n",
            "Epoch: 28, Step: 153/655, Loss: 2.195637, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 154/655, Loss: 2.195444, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 155/655, Loss: 2.195071, Accuracy: 18.47%\n",
            "Epoch: 28, Step: 156/655, Loss: 2.194679, Accuracy: 18.51%\n",
            "Epoch: 28, Step: 157/655, Loss: 2.195500, Accuracy: 18.53%\n",
            "Epoch: 28, Step: 158/655, Loss: 2.195221, Accuracy: 18.53%\n",
            "Epoch: 28, Step: 159/655, Loss: 2.195370, Accuracy: 18.46%\n",
            "Epoch: 28, Step: 160/655, Loss: 2.195025, Accuracy: 18.44%\n",
            "Epoch: 28, Step: 161/655, Loss: 2.194253, Accuracy: 18.52%\n",
            "Epoch: 28, Step: 162/655, Loss: 2.194193, Accuracy: 18.54%\n",
            "Epoch: 28, Step: 163/655, Loss: 2.194026, Accuracy: 18.54%\n",
            "Epoch: 28, Step: 164/655, Loss: 2.194127, Accuracy: 18.54%\n",
            "Epoch: 28, Step: 165/655, Loss: 2.194151, Accuracy: 18.56%\n",
            "Epoch: 28, Step: 166/655, Loss: 2.194340, Accuracy: 18.54%\n",
            "Epoch: 28, Step: 167/655, Loss: 2.194092, Accuracy: 18.56%\n",
            "Epoch: 28, Step: 168/655, Loss: 2.194488, Accuracy: 18.47%\n",
            "Epoch: 28, Step: 169/655, Loss: 2.195097, Accuracy: 18.47%\n",
            "Epoch: 28, Step: 170/655, Loss: 2.194714, Accuracy: 18.57%\n",
            "Epoch: 28, Step: 171/655, Loss: 2.195251, Accuracy: 18.57%\n",
            "Epoch: 28, Step: 172/655, Loss: 2.195638, Accuracy: 18.53%\n",
            "Epoch: 28, Step: 173/655, Loss: 2.195708, Accuracy: 18.50%\n",
            "Epoch: 28, Step: 174/655, Loss: 2.195186, Accuracy: 18.48%\n",
            "Epoch: 28, Step: 175/655, Loss: 2.196025, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 176/655, Loss: 2.196092, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 177/655, Loss: 2.196971, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 178/655, Loss: 2.197327, Accuracy: 18.45%\n",
            "Epoch: 28, Step: 179/655, Loss: 2.197127, Accuracy: 18.45%\n",
            "Epoch: 28, Step: 180/655, Loss: 2.196638, Accuracy: 18.44%\n",
            "Epoch: 28, Step: 181/655, Loss: 2.197639, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 182/655, Loss: 2.197638, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 183/655, Loss: 2.198367, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 184/655, Loss: 2.198099, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 185/655, Loss: 2.198389, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 186/655, Loss: 2.198797, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 187/655, Loss: 2.199308, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 188/655, Loss: 2.199115, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 189/655, Loss: 2.199423, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 190/655, Loss: 2.199398, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 191/655, Loss: 2.199531, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 192/655, Loss: 2.199344, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 193/655, Loss: 2.199546, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 194/655, Loss: 2.198999, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 195/655, Loss: 2.198497, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 196/655, Loss: 2.198000, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 197/655, Loss: 2.198011, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 198/655, Loss: 2.198517, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 199/655, Loss: 2.198995, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 200/655, Loss: 2.199236, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 201/655, Loss: 2.199490, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 202/655, Loss: 2.198987, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 203/655, Loss: 2.199878, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 204/655, Loss: 2.200126, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 205/655, Loss: 2.200008, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 206/655, Loss: 2.199933, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 207/655, Loss: 2.199399, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 208/655, Loss: 2.198865, Accuracy: 18.43%\n",
            "Epoch: 28, Step: 209/655, Loss: 2.199050, Accuracy: 18.42%\n",
            "Epoch: 28, Step: 210/655, Loss: 2.199300, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 211/655, Loss: 2.199232, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 212/655, Loss: 2.199451, Accuracy: 18.44%\n",
            "Epoch: 28, Step: 213/655, Loss: 2.199263, Accuracy: 18.47%\n",
            "Epoch: 28, Step: 214/655, Loss: 2.199074, Accuracy: 18.50%\n",
            "Epoch: 28, Step: 215/655, Loss: 2.198894, Accuracy: 18.49%\n",
            "Epoch: 28, Step: 216/655, Loss: 2.199036, Accuracy: 18.49%\n",
            "Epoch: 28, Step: 217/655, Loss: 2.198873, Accuracy: 18.51%\n",
            "Epoch: 28, Step: 218/655, Loss: 2.199042, Accuracy: 18.45%\n",
            "Epoch: 28, Step: 219/655, Loss: 2.198656, Accuracy: 18.42%\n",
            "Epoch: 28, Step: 220/655, Loss: 2.198646, Accuracy: 18.45%\n",
            "Epoch: 28, Step: 221/655, Loss: 2.198795, Accuracy: 18.45%\n",
            "Epoch: 28, Step: 222/655, Loss: 2.198923, Accuracy: 18.45%\n",
            "Epoch: 28, Step: 223/655, Loss: 2.198691, Accuracy: 18.46%\n",
            "Epoch: 28, Step: 224/655, Loss: 2.198775, Accuracy: 18.50%\n",
            "Epoch: 28, Step: 225/655, Loss: 2.198415, Accuracy: 18.50%\n",
            "Epoch: 28, Step: 226/655, Loss: 2.198814, Accuracy: 18.49%\n",
            "Epoch: 28, Step: 227/655, Loss: 2.198940, Accuracy: 18.47%\n",
            "Epoch: 28, Step: 228/655, Loss: 2.199112, Accuracy: 18.45%\n",
            "Epoch: 28, Step: 229/655, Loss: 2.199176, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 230/655, Loss: 2.199274, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 231/655, Loss: 2.199951, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 232/655, Loss: 2.200612, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 233/655, Loss: 2.200797, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 234/655, Loss: 2.200424, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 235/655, Loss: 2.199721, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 236/655, Loss: 2.200041, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 237/655, Loss: 2.200348, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 238/655, Loss: 2.199811, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 239/655, Loss: 2.199332, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 240/655, Loss: 2.199420, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 241/655, Loss: 2.199543, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 242/655, Loss: 2.199863, Accuracy: 18.23%\n",
            "Epoch: 28, Step: 243/655, Loss: 2.199868, Accuracy: 18.25%\n",
            "Epoch: 28, Step: 244/655, Loss: 2.199840, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 245/655, Loss: 2.200060, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 246/655, Loss: 2.200116, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 247/655, Loss: 2.200196, Accuracy: 18.24%\n",
            "Epoch: 28, Step: 248/655, Loss: 2.199912, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 249/655, Loss: 2.200042, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 250/655, Loss: 2.199938, Accuracy: 18.25%\n",
            "Epoch: 28, Step: 251/655, Loss: 2.199667, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 252/655, Loss: 2.199957, Accuracy: 18.24%\n",
            "Epoch: 28, Step: 253/655, Loss: 2.199691, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 254/655, Loss: 2.199555, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 255/655, Loss: 2.199582, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 256/655, Loss: 2.199900, Accuracy: 18.24%\n",
            "Epoch: 28, Step: 257/655, Loss: 2.200577, Accuracy: 18.20%\n",
            "Epoch: 28, Step: 258/655, Loss: 2.200204, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 259/655, Loss: 2.200267, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 260/655, Loss: 2.200169, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 261/655, Loss: 2.200517, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 262/655, Loss: 2.200753, Accuracy: 18.25%\n",
            "Epoch: 28, Step: 263/655, Loss: 2.201005, Accuracy: 18.24%\n",
            "Epoch: 28, Step: 264/655, Loss: 2.201204, Accuracy: 18.24%\n",
            "Epoch: 28, Step: 265/655, Loss: 2.200892, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 266/655, Loss: 2.200819, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 267/655, Loss: 2.200547, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 268/655, Loss: 2.201266, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 269/655, Loss: 2.200968, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 270/655, Loss: 2.200906, Accuracy: 18.25%\n",
            "Epoch: 28, Step: 271/655, Loss: 2.201269, Accuracy: 18.24%\n",
            "Epoch: 28, Step: 272/655, Loss: 2.201047, Accuracy: 18.23%\n",
            "Epoch: 28, Step: 273/655, Loss: 2.201051, Accuracy: 18.25%\n",
            "Epoch: 28, Step: 274/655, Loss: 2.200973, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 275/655, Loss: 2.200909, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 276/655, Loss: 2.200827, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 277/655, Loss: 2.201020, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 278/655, Loss: 2.201240, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 279/655, Loss: 2.201579, Accuracy: 18.22%\n",
            "Epoch: 28, Step: 280/655, Loss: 2.202070, Accuracy: 18.19%\n",
            "Epoch: 28, Step: 281/655, Loss: 2.202497, Accuracy: 18.15%\n",
            "Epoch: 28, Step: 282/655, Loss: 2.202744, Accuracy: 18.15%\n",
            "Epoch: 28, Step: 283/655, Loss: 2.202334, Accuracy: 18.18%\n",
            "Epoch: 28, Step: 284/655, Loss: 2.202147, Accuracy: 18.20%\n",
            "Epoch: 28, Step: 285/655, Loss: 2.202170, Accuracy: 18.21%\n",
            "Epoch: 28, Step: 286/655, Loss: 2.202486, Accuracy: 18.18%\n",
            "Epoch: 28, Step: 287/655, Loss: 2.202878, Accuracy: 18.13%\n",
            "Epoch: 28, Step: 288/655, Loss: 2.202464, Accuracy: 18.16%\n",
            "Epoch: 28, Step: 289/655, Loss: 2.202494, Accuracy: 18.19%\n",
            "Epoch: 28, Step: 290/655, Loss: 2.202371, Accuracy: 18.20%\n",
            "Epoch: 28, Step: 291/655, Loss: 2.202027, Accuracy: 18.19%\n",
            "Epoch: 28, Step: 292/655, Loss: 2.202441, Accuracy: 18.15%\n",
            "Epoch: 28, Step: 293/655, Loss: 2.202503, Accuracy: 18.16%\n",
            "Epoch: 28, Step: 294/655, Loss: 2.202096, Accuracy: 18.20%\n",
            "Epoch: 28, Step: 295/655, Loss: 2.202227, Accuracy: 18.16%\n",
            "Epoch: 28, Step: 296/655, Loss: 2.202447, Accuracy: 18.16%\n",
            "Epoch: 28, Step: 297/655, Loss: 2.202549, Accuracy: 18.15%\n",
            "Epoch: 28, Step: 298/655, Loss: 2.202711, Accuracy: 18.14%\n",
            "Epoch: 28, Step: 299/655, Loss: 2.202952, Accuracy: 18.16%\n",
            "Epoch: 28, Step: 300/655, Loss: 2.203193, Accuracy: 18.17%\n",
            "Epoch: 28, Step: 301/655, Loss: 2.203129, Accuracy: 18.16%\n",
            "Epoch: 28, Step: 302/655, Loss: 2.203300, Accuracy: 18.15%\n",
            "Epoch: 28, Step: 303/655, Loss: 2.203395, Accuracy: 18.17%\n",
            "Epoch: 28, Step: 304/655, Loss: 2.203611, Accuracy: 18.17%\n",
            "Epoch: 28, Step: 305/655, Loss: 2.203508, Accuracy: 18.17%\n",
            "Epoch: 28, Step: 306/655, Loss: 2.203318, Accuracy: 18.19%\n",
            "Epoch: 28, Step: 307/655, Loss: 2.203386, Accuracy: 18.20%\n",
            "Epoch: 28, Step: 308/655, Loss: 2.203476, Accuracy: 18.21%\n",
            "Epoch: 28, Step: 309/655, Loss: 2.203388, Accuracy: 18.20%\n",
            "Epoch: 28, Step: 310/655, Loss: 2.203299, Accuracy: 18.24%\n",
            "Epoch: 28, Step: 311/655, Loss: 2.202829, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 312/655, Loss: 2.202567, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 313/655, Loss: 2.203102, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 314/655, Loss: 2.203078, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 315/655, Loss: 2.203402, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 316/655, Loss: 2.203471, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 317/655, Loss: 2.203412, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 318/655, Loss: 2.203476, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 319/655, Loss: 2.203467, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 320/655, Loss: 2.203511, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 321/655, Loss: 2.203559, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 322/655, Loss: 2.203993, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 323/655, Loss: 2.203857, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 324/655, Loss: 2.203703, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 325/655, Loss: 2.203423, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 326/655, Loss: 2.203243, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 327/655, Loss: 2.203249, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 328/655, Loss: 2.203359, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 329/655, Loss: 2.203243, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 330/655, Loss: 2.203670, Accuracy: 18.32%\n",
            "Epoch: 28, Step: 331/655, Loss: 2.203868, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 332/655, Loss: 2.203955, Accuracy: 18.32%\n",
            "Epoch: 28, Step: 333/655, Loss: 2.204293, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 334/655, Loss: 2.203808, Accuracy: 18.32%\n",
            "Epoch: 28, Step: 335/655, Loss: 2.203686, Accuracy: 18.32%\n",
            "Epoch: 28, Step: 336/655, Loss: 2.203549, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 337/655, Loss: 2.203683, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 338/655, Loss: 2.203295, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 339/655, Loss: 2.203383, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 340/655, Loss: 2.203719, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 341/655, Loss: 2.204185, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 342/655, Loss: 2.204518, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 343/655, Loss: 2.204585, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 344/655, Loss: 2.204859, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 345/655, Loss: 2.205139, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 346/655, Loss: 2.205398, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 347/655, Loss: 2.205868, Accuracy: 18.32%\n",
            "Epoch: 28, Step: 348/655, Loss: 2.205587, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 349/655, Loss: 2.205799, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 350/655, Loss: 2.205908, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 351/655, Loss: 2.206170, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 352/655, Loss: 2.206188, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 353/655, Loss: 2.206134, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 354/655, Loss: 2.205956, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 355/655, Loss: 2.205945, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 356/655, Loss: 2.205836, Accuracy: 18.32%\n",
            "Epoch: 28, Step: 357/655, Loss: 2.205942, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 358/655, Loss: 2.205895, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 359/655, Loss: 2.205726, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 360/655, Loss: 2.205697, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 361/655, Loss: 2.205676, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 362/655, Loss: 2.205518, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 363/655, Loss: 2.205350, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 364/655, Loss: 2.205450, Accuracy: 18.42%\n",
            "Epoch: 28, Step: 365/655, Loss: 2.205509, Accuracy: 18.43%\n",
            "Epoch: 28, Step: 366/655, Loss: 2.205508, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 367/655, Loss: 2.206067, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 368/655, Loss: 2.206158, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 369/655, Loss: 2.206475, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 370/655, Loss: 2.206126, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 371/655, Loss: 2.205977, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 372/655, Loss: 2.205695, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 373/655, Loss: 2.205803, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 374/655, Loss: 2.206212, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 375/655, Loss: 2.206549, Accuracy: 18.32%\n",
            "Epoch: 28, Step: 376/655, Loss: 2.206783, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 377/655, Loss: 2.207017, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 378/655, Loss: 2.206877, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 379/655, Loss: 2.206905, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 380/655, Loss: 2.206993, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 381/655, Loss: 2.207104, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 382/655, Loss: 2.206697, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 383/655, Loss: 2.206961, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 384/655, Loss: 2.206879, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 385/655, Loss: 2.206757, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 386/655, Loss: 2.206746, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 387/655, Loss: 2.206789, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 388/655, Loss: 2.206655, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 389/655, Loss: 2.206502, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 390/655, Loss: 2.206465, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 391/655, Loss: 2.206297, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 392/655, Loss: 2.206402, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 393/655, Loss: 2.206133, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 394/655, Loss: 2.206050, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 395/655, Loss: 2.206044, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 396/655, Loss: 2.205870, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 397/655, Loss: 2.205606, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 398/655, Loss: 2.205503, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 399/655, Loss: 2.205578, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 400/655, Loss: 2.205740, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 401/655, Loss: 2.205733, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 402/655, Loss: 2.205608, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 403/655, Loss: 2.205375, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 404/655, Loss: 2.205233, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 405/655, Loss: 2.205084, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 406/655, Loss: 2.205066, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 407/655, Loss: 2.204987, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 408/655, Loss: 2.204763, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 409/655, Loss: 2.204723, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 410/655, Loss: 2.204510, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 411/655, Loss: 2.204895, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 412/655, Loss: 2.205162, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 413/655, Loss: 2.205105, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 414/655, Loss: 2.205086, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 415/655, Loss: 2.205195, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 416/655, Loss: 2.205230, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 417/655, Loss: 2.205617, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 418/655, Loss: 2.205429, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 419/655, Loss: 2.205517, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 420/655, Loss: 2.205200, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 421/655, Loss: 2.205083, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 422/655, Loss: 2.204884, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 423/655, Loss: 2.204621, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 424/655, Loss: 2.204621, Accuracy: 18.42%\n",
            "Epoch: 28, Step: 425/655, Loss: 2.204673, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 426/655, Loss: 2.204686, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 427/655, Loss: 2.204541, Accuracy: 18.43%\n",
            "Epoch: 28, Step: 428/655, Loss: 2.204797, Accuracy: 18.42%\n",
            "Epoch: 28, Step: 429/655, Loss: 2.204625, Accuracy: 18.46%\n",
            "Epoch: 28, Step: 430/655, Loss: 2.204300, Accuracy: 18.49%\n",
            "Epoch: 28, Step: 431/655, Loss: 2.204514, Accuracy: 18.50%\n",
            "Epoch: 28, Step: 432/655, Loss: 2.204429, Accuracy: 18.50%\n",
            "Epoch: 28, Step: 433/655, Loss: 2.204302, Accuracy: 18.51%\n",
            "Epoch: 28, Step: 434/655, Loss: 2.204553, Accuracy: 18.51%\n",
            "Epoch: 28, Step: 435/655, Loss: 2.204255, Accuracy: 18.52%\n",
            "Epoch: 28, Step: 436/655, Loss: 2.204351, Accuracy: 18.51%\n",
            "Epoch: 28, Step: 437/655, Loss: 2.204465, Accuracy: 18.49%\n",
            "Epoch: 28, Step: 438/655, Loss: 2.204165, Accuracy: 18.49%\n",
            "Epoch: 28, Step: 439/655, Loss: 2.204328, Accuracy: 18.47%\n",
            "Epoch: 28, Step: 440/655, Loss: 2.204766, Accuracy: 18.44%\n",
            "Epoch: 28, Step: 441/655, Loss: 2.205141, Accuracy: 18.42%\n",
            "Epoch: 28, Step: 442/655, Loss: 2.205046, Accuracy: 18.44%\n",
            "Epoch: 28, Step: 443/655, Loss: 2.204988, Accuracy: 18.45%\n",
            "Epoch: 28, Step: 444/655, Loss: 2.204938, Accuracy: 18.45%\n",
            "Epoch: 28, Step: 445/655, Loss: 2.204923, Accuracy: 18.48%\n",
            "Epoch: 28, Step: 446/655, Loss: 2.205209, Accuracy: 18.45%\n",
            "Epoch: 28, Step: 447/655, Loss: 2.205275, Accuracy: 18.45%\n",
            "Epoch: 28, Step: 448/655, Loss: 2.205447, Accuracy: 18.43%\n",
            "Epoch: 28, Step: 449/655, Loss: 2.205346, Accuracy: 18.43%\n",
            "Epoch: 28, Step: 450/655, Loss: 2.205405, Accuracy: 18.44%\n",
            "Epoch: 28, Step: 451/655, Loss: 2.205624, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 452/655, Loss: 2.205984, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 453/655, Loss: 2.206151, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 454/655, Loss: 2.206471, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 455/655, Loss: 2.206385, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 456/655, Loss: 2.206429, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 457/655, Loss: 2.206325, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 458/655, Loss: 2.206207, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 459/655, Loss: 2.206454, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 460/655, Loss: 2.206441, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 461/655, Loss: 2.206653, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 462/655, Loss: 2.206399, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 463/655, Loss: 2.206400, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 464/655, Loss: 2.206535, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 465/655, Loss: 2.206621, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 466/655, Loss: 2.206695, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 467/655, Loss: 2.206881, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 468/655, Loss: 2.206492, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 469/655, Loss: 2.206414, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 470/655, Loss: 2.206710, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 471/655, Loss: 2.206806, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 472/655, Loss: 2.206705, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 473/655, Loss: 2.206716, Accuracy: 18.32%\n",
            "Epoch: 28, Step: 474/655, Loss: 2.206478, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 475/655, Loss: 2.206605, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 476/655, Loss: 2.206947, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 477/655, Loss: 2.206811, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 478/655, Loss: 2.206954, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 479/655, Loss: 2.206926, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 480/655, Loss: 2.207065, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 481/655, Loss: 2.207375, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 482/655, Loss: 2.207579, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 483/655, Loss: 2.207616, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 484/655, Loss: 2.207660, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 485/655, Loss: 2.207737, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 486/655, Loss: 2.207527, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 487/655, Loss: 2.207688, Accuracy: 18.25%\n",
            "Epoch: 28, Step: 488/655, Loss: 2.207635, Accuracy: 18.23%\n",
            "Epoch: 28, Step: 489/655, Loss: 2.207342, Accuracy: 18.24%\n",
            "Epoch: 28, Step: 490/655, Loss: 2.207378, Accuracy: 18.24%\n",
            "Epoch: 28, Step: 491/655, Loss: 2.207002, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 492/655, Loss: 2.206860, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 493/655, Loss: 2.207227, Accuracy: 18.25%\n",
            "Epoch: 28, Step: 494/655, Loss: 2.207065, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 495/655, Loss: 2.207239, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 496/655, Loss: 2.207045, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 497/655, Loss: 2.207302, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 498/655, Loss: 2.207333, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 499/655, Loss: 2.207402, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 500/655, Loss: 2.207302, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 501/655, Loss: 2.207109, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 502/655, Loss: 2.207160, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 503/655, Loss: 2.207363, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 504/655, Loss: 2.207339, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 505/655, Loss: 2.207554, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 506/655, Loss: 2.207616, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 507/655, Loss: 2.207529, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 508/655, Loss: 2.207606, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 509/655, Loss: 2.207665, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 510/655, Loss: 2.207595, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 511/655, Loss: 2.207663, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 512/655, Loss: 2.207637, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 513/655, Loss: 2.207622, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 514/655, Loss: 2.207811, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 515/655, Loss: 2.208016, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 516/655, Loss: 2.207848, Accuracy: 18.32%\n",
            "Epoch: 28, Step: 517/655, Loss: 2.207852, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 518/655, Loss: 2.207857, Accuracy: 18.32%\n",
            "Epoch: 28, Step: 519/655, Loss: 2.208171, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 520/655, Loss: 2.208065, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 521/655, Loss: 2.207740, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 522/655, Loss: 2.207751, Accuracy: 18.32%\n",
            "Epoch: 28, Step: 523/655, Loss: 2.207746, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 524/655, Loss: 2.207944, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 525/655, Loss: 2.208334, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 526/655, Loss: 2.207966, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 527/655, Loss: 2.207847, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 528/655, Loss: 2.207894, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 529/655, Loss: 2.207611, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 530/655, Loss: 2.207692, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 531/655, Loss: 2.207932, Accuracy: 18.32%\n",
            "Epoch: 28, Step: 532/655, Loss: 2.207983, Accuracy: 18.32%\n",
            "Epoch: 28, Step: 533/655, Loss: 2.208208, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 534/655, Loss: 2.208381, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 535/655, Loss: 2.208321, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 536/655, Loss: 2.208434, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 537/655, Loss: 2.208549, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 538/655, Loss: 2.208807, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 539/655, Loss: 2.208716, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 540/655, Loss: 2.208670, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 541/655, Loss: 2.208551, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 542/655, Loss: 2.208414, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 543/655, Loss: 2.208590, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 544/655, Loss: 2.208864, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 545/655, Loss: 2.208873, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 546/655, Loss: 2.208802, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 547/655, Loss: 2.208638, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 548/655, Loss: 2.208482, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 549/655, Loss: 2.208601, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 550/655, Loss: 2.208551, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 551/655, Loss: 2.208551, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 552/655, Loss: 2.208242, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 553/655, Loss: 2.208466, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 554/655, Loss: 2.208381, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 555/655, Loss: 2.208457, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 556/655, Loss: 2.208682, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 557/655, Loss: 2.208678, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 558/655, Loss: 2.208714, Accuracy: 18.30%\n",
            "Epoch: 28, Step: 559/655, Loss: 2.208794, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 560/655, Loss: 2.208920, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 561/655, Loss: 2.209193, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 562/655, Loss: 2.209341, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 563/655, Loss: 2.209281, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 564/655, Loss: 2.209500, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 565/655, Loss: 2.209626, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 566/655, Loss: 2.209763, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 567/655, Loss: 2.209724, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 568/655, Loss: 2.209793, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 569/655, Loss: 2.209963, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 570/655, Loss: 2.209972, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 571/655, Loss: 2.209944, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 572/655, Loss: 2.209971, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 573/655, Loss: 2.209628, Accuracy: 18.27%\n",
            "Epoch: 28, Step: 574/655, Loss: 2.209942, Accuracy: 18.24%\n",
            "Epoch: 28, Step: 575/655, Loss: 2.209684, Accuracy: 18.25%\n",
            "Epoch: 28, Step: 576/655, Loss: 2.209427, Accuracy: 18.25%\n",
            "Epoch: 28, Step: 577/655, Loss: 2.209404, Accuracy: 18.24%\n",
            "Epoch: 28, Step: 578/655, Loss: 2.209420, Accuracy: 18.26%\n",
            "Epoch: 28, Step: 579/655, Loss: 2.209420, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 580/655, Loss: 2.209522, Accuracy: 18.28%\n",
            "Epoch: 28, Step: 581/655, Loss: 2.209395, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 582/655, Loss: 2.209358, Accuracy: 18.29%\n",
            "Epoch: 28, Step: 583/655, Loss: 2.209382, Accuracy: 18.31%\n",
            "Epoch: 28, Step: 584/655, Loss: 2.209261, Accuracy: 18.32%\n",
            "Epoch: 28, Step: 585/655, Loss: 2.209344, Accuracy: 18.32%\n",
            "Epoch: 28, Step: 586/655, Loss: 2.209301, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 587/655, Loss: 2.209146, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 588/655, Loss: 2.209231, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 589/655, Loss: 2.209451, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 590/655, Loss: 2.209326, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 591/655, Loss: 2.209470, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 592/655, Loss: 2.209537, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 593/655, Loss: 2.209484, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 594/655, Loss: 2.209458, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 595/655, Loss: 2.209422, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 596/655, Loss: 2.209592, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 597/655, Loss: 2.209535, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 598/655, Loss: 2.209525, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 599/655, Loss: 2.209589, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 600/655, Loss: 2.209453, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 601/655, Loss: 2.209270, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 602/655, Loss: 2.209134, Accuracy: 18.33%\n",
            "Epoch: 28, Step: 603/655, Loss: 2.208992, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 604/655, Loss: 2.208880, Accuracy: 18.34%\n",
            "Epoch: 28, Step: 605/655, Loss: 2.208842, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 606/655, Loss: 2.208764, Accuracy: 18.35%\n",
            "Epoch: 28, Step: 607/655, Loss: 2.208604, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 608/655, Loss: 2.208546, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 609/655, Loss: 2.208508, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 610/655, Loss: 2.208647, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 611/655, Loss: 2.208534, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 612/655, Loss: 2.208605, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 613/655, Loss: 2.208576, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 614/655, Loss: 2.208670, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 615/655, Loss: 2.208746, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 616/655, Loss: 2.208889, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 617/655, Loss: 2.208727, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 618/655, Loss: 2.208739, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 619/655, Loss: 2.208849, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 620/655, Loss: 2.208772, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 621/655, Loss: 2.208791, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 622/655, Loss: 2.208897, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 623/655, Loss: 2.208941, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 624/655, Loss: 2.209073, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 625/655, Loss: 2.209259, Accuracy: 18.36%\n",
            "Epoch: 28, Step: 626/655, Loss: 2.209163, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 627/655, Loss: 2.209027, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 628/655, Loss: 2.208941, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 629/655, Loss: 2.208757, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 630/655, Loss: 2.208743, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 631/655, Loss: 2.208714, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 632/655, Loss: 2.208612, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 633/655, Loss: 2.208534, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 634/655, Loss: 2.208484, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 635/655, Loss: 2.208425, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 636/655, Loss: 2.208427, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 637/655, Loss: 2.208188, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 638/655, Loss: 2.208317, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 639/655, Loss: 2.208478, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 640/655, Loss: 2.208383, Accuracy: 18.40%\n",
            "Epoch: 28, Step: 641/655, Loss: 2.208457, Accuracy: 18.39%\n",
            "Epoch: 28, Step: 642/655, Loss: 2.208400, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 643/655, Loss: 2.208298, Accuracy: 18.37%\n",
            "Epoch: 28, Step: 644/655, Loss: 2.208377, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 645/655, Loss: 2.208381, Accuracy: 18.38%\n",
            "Epoch: 28, Step: 646/655, Loss: 2.208164, Accuracy: 18.41%\n",
            "Epoch: 28, Step: 647/655, Loss: 2.208083, Accuracy: 18.43%\n",
            "Epoch: 28, Step: 648/655, Loss: 2.208142, Accuracy: 18.44%\n",
            "Epoch: 28, Step: 649/655, Loss: 2.207826, Accuracy: 18.44%\n",
            "Epoch: 28, Step: 650/655, Loss: 2.207829, Accuracy: 18.46%\n",
            "Epoch: 28, Step: 651/655, Loss: 2.207895, Accuracy: 18.45%\n",
            "Epoch: 28, Step: 652/655, Loss: 2.207899, Accuracy: 18.45%\n",
            "Epoch: 28, Step: 653/655, Loss: 2.207868, Accuracy: 18.46%\n",
            "Epoch: 28, Step: 654/655, Loss: 2.207702, Accuracy: 18.47%\n",
            "Epoch: 28, Step: 655/655, Loss: 2.207577, Accuracy: 18.47%\n",
            "Epoch: 29, Step: 1/655, Loss: 2.307784, Accuracy: 18.75%\n",
            "Epoch: 29, Step: 2/655, Loss: 2.188680, Accuracy: 18.75%\n",
            "Epoch: 29, Step: 3/655, Loss: 2.164445, Accuracy: 23.96%\n",
            "Epoch: 29, Step: 4/655, Loss: 2.180685, Accuracy: 22.66%\n",
            "Epoch: 29, Step: 5/655, Loss: 2.160100, Accuracy: 23.75%\n",
            "Epoch: 29, Step: 6/655, Loss: 2.166473, Accuracy: 22.92%\n",
            "Epoch: 29, Step: 7/655, Loss: 2.180568, Accuracy: 21.43%\n",
            "Epoch: 29, Step: 8/655, Loss: 2.175893, Accuracy: 21.48%\n",
            "Epoch: 29, Step: 9/655, Loss: 2.183730, Accuracy: 20.83%\n",
            "Epoch: 29, Step: 10/655, Loss: 2.194841, Accuracy: 20.31%\n",
            "Epoch: 29, Step: 11/655, Loss: 2.199194, Accuracy: 20.45%\n",
            "Epoch: 29, Step: 12/655, Loss: 2.191449, Accuracy: 20.83%\n",
            "Epoch: 29, Step: 13/655, Loss: 2.190738, Accuracy: 20.67%\n",
            "Epoch: 29, Step: 14/655, Loss: 2.191141, Accuracy: 20.76%\n",
            "Epoch: 29, Step: 15/655, Loss: 2.198690, Accuracy: 20.00%\n",
            "Epoch: 29, Step: 16/655, Loss: 2.199079, Accuracy: 19.53%\n",
            "Epoch: 29, Step: 17/655, Loss: 2.201481, Accuracy: 19.85%\n",
            "Epoch: 29, Step: 18/655, Loss: 2.207001, Accuracy: 19.44%\n",
            "Epoch: 29, Step: 19/655, Loss: 2.207749, Accuracy: 19.57%\n",
            "Epoch: 29, Step: 20/655, Loss: 2.207544, Accuracy: 19.69%\n",
            "Epoch: 29, Step: 21/655, Loss: 2.207912, Accuracy: 19.20%\n",
            "Epoch: 29, Step: 22/655, Loss: 2.209046, Accuracy: 19.32%\n",
            "Epoch: 29, Step: 23/655, Loss: 2.213377, Accuracy: 19.29%\n",
            "Epoch: 29, Step: 24/655, Loss: 2.212998, Accuracy: 19.14%\n",
            "Epoch: 29, Step: 25/655, Loss: 2.214204, Accuracy: 19.00%\n",
            "Epoch: 29, Step: 26/655, Loss: 2.215010, Accuracy: 18.87%\n",
            "Epoch: 29, Step: 27/655, Loss: 2.210276, Accuracy: 19.21%\n",
            "Epoch: 29, Step: 28/655, Loss: 2.213217, Accuracy: 18.97%\n",
            "Epoch: 29, Step: 29/655, Loss: 2.212571, Accuracy: 18.86%\n",
            "Epoch: 29, Step: 30/655, Loss: 2.209643, Accuracy: 19.06%\n",
            "Epoch: 29, Step: 31/655, Loss: 2.213199, Accuracy: 18.65%\n",
            "Epoch: 29, Step: 32/655, Loss: 2.216113, Accuracy: 18.55%\n",
            "Epoch: 29, Step: 33/655, Loss: 2.217560, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 34/655, Loss: 2.215811, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 35/655, Loss: 2.215497, Accuracy: 18.12%\n",
            "Epoch: 29, Step: 36/655, Loss: 2.211969, Accuracy: 17.97%\n",
            "Epoch: 29, Step: 37/655, Loss: 2.214560, Accuracy: 17.65%\n",
            "Epoch: 29, Step: 38/655, Loss: 2.212857, Accuracy: 17.68%\n",
            "Epoch: 29, Step: 39/655, Loss: 2.212304, Accuracy: 17.71%\n",
            "Epoch: 29, Step: 40/655, Loss: 2.215596, Accuracy: 17.58%\n",
            "Epoch: 29, Step: 41/655, Loss: 2.214041, Accuracy: 17.61%\n",
            "Epoch: 29, Step: 42/655, Loss: 2.215528, Accuracy: 17.49%\n",
            "Epoch: 29, Step: 43/655, Loss: 2.214685, Accuracy: 17.73%\n",
            "Epoch: 29, Step: 44/655, Loss: 2.213665, Accuracy: 17.68%\n",
            "Epoch: 29, Step: 45/655, Loss: 2.213446, Accuracy: 17.64%\n",
            "Epoch: 29, Step: 46/655, Loss: 2.214439, Accuracy: 17.66%\n",
            "Epoch: 29, Step: 47/655, Loss: 2.215173, Accuracy: 17.69%\n",
            "Epoch: 29, Step: 48/655, Loss: 2.210988, Accuracy: 17.64%\n",
            "Epoch: 29, Step: 49/655, Loss: 2.209820, Accuracy: 17.60%\n",
            "Epoch: 29, Step: 50/655, Loss: 2.206626, Accuracy: 17.75%\n",
            "Epoch: 29, Step: 51/655, Loss: 2.203958, Accuracy: 17.83%\n",
            "Epoch: 29, Step: 52/655, Loss: 2.203424, Accuracy: 17.61%\n",
            "Epoch: 29, Step: 53/655, Loss: 2.204120, Accuracy: 17.63%\n",
            "Epoch: 29, Step: 54/655, Loss: 2.204690, Accuracy: 17.59%\n",
            "Epoch: 29, Step: 55/655, Loss: 2.204962, Accuracy: 17.73%\n",
            "Epoch: 29, Step: 56/655, Loss: 2.205627, Accuracy: 17.75%\n",
            "Epoch: 29, Step: 57/655, Loss: 2.206153, Accuracy: 17.71%\n",
            "Epoch: 29, Step: 58/655, Loss: 2.209015, Accuracy: 17.56%\n",
            "Epoch: 29, Step: 59/655, Loss: 2.210154, Accuracy: 17.32%\n",
            "Epoch: 29, Step: 60/655, Loss: 2.210645, Accuracy: 17.34%\n",
            "Epoch: 29, Step: 61/655, Loss: 2.211070, Accuracy: 17.42%\n",
            "Epoch: 29, Step: 62/655, Loss: 2.212328, Accuracy: 17.39%\n",
            "Epoch: 29, Step: 63/655, Loss: 2.213480, Accuracy: 17.41%\n",
            "Epoch: 29, Step: 64/655, Loss: 2.213807, Accuracy: 17.38%\n",
            "Epoch: 29, Step: 65/655, Loss: 2.211220, Accuracy: 17.45%\n",
            "Epoch: 29, Step: 66/655, Loss: 2.211796, Accuracy: 17.57%\n",
            "Epoch: 29, Step: 67/655, Loss: 2.213568, Accuracy: 17.44%\n",
            "Epoch: 29, Step: 68/655, Loss: 2.212864, Accuracy: 17.37%\n",
            "Epoch: 29, Step: 69/655, Loss: 2.213382, Accuracy: 17.44%\n",
            "Epoch: 29, Step: 70/655, Loss: 2.211763, Accuracy: 17.59%\n",
            "Epoch: 29, Step: 71/655, Loss: 2.212171, Accuracy: 17.65%\n",
            "Epoch: 29, Step: 72/655, Loss: 2.210564, Accuracy: 17.71%\n",
            "Epoch: 29, Step: 73/655, Loss: 2.210808, Accuracy: 17.64%\n",
            "Epoch: 29, Step: 74/655, Loss: 2.211045, Accuracy: 17.65%\n",
            "Epoch: 29, Step: 75/655, Loss: 2.212509, Accuracy: 17.62%\n",
            "Epoch: 29, Step: 76/655, Loss: 2.211964, Accuracy: 17.60%\n",
            "Epoch: 29, Step: 77/655, Loss: 2.211312, Accuracy: 17.78%\n",
            "Epoch: 29, Step: 78/655, Loss: 2.210701, Accuracy: 17.71%\n",
            "Epoch: 29, Step: 79/655, Loss: 2.212632, Accuracy: 17.68%\n",
            "Epoch: 29, Step: 80/655, Loss: 2.214355, Accuracy: 17.62%\n",
            "Epoch: 29, Step: 81/655, Loss: 2.211860, Accuracy: 17.67%\n",
            "Epoch: 29, Step: 82/655, Loss: 2.212903, Accuracy: 17.61%\n",
            "Epoch: 29, Step: 83/655, Loss: 2.212889, Accuracy: 17.55%\n",
            "Epoch: 29, Step: 84/655, Loss: 2.213739, Accuracy: 17.52%\n",
            "Epoch: 29, Step: 85/655, Loss: 2.213997, Accuracy: 17.39%\n",
            "Epoch: 29, Step: 86/655, Loss: 2.214501, Accuracy: 17.33%\n",
            "Epoch: 29, Step: 87/655, Loss: 2.214417, Accuracy: 17.35%\n",
            "Epoch: 29, Step: 88/655, Loss: 2.215540, Accuracy: 17.26%\n",
            "Epoch: 29, Step: 89/655, Loss: 2.215082, Accuracy: 17.17%\n",
            "Epoch: 29, Step: 90/655, Loss: 2.216083, Accuracy: 17.22%\n",
            "Epoch: 29, Step: 91/655, Loss: 2.216971, Accuracy: 17.20%\n",
            "Epoch: 29, Step: 92/655, Loss: 2.216442, Accuracy: 17.09%\n",
            "Epoch: 29, Step: 93/655, Loss: 2.216139, Accuracy: 17.14%\n",
            "Epoch: 29, Step: 94/655, Loss: 2.216136, Accuracy: 17.22%\n",
            "Epoch: 29, Step: 95/655, Loss: 2.214844, Accuracy: 17.30%\n",
            "Epoch: 29, Step: 96/655, Loss: 2.213907, Accuracy: 17.45%\n",
            "Epoch: 29, Step: 97/655, Loss: 2.212856, Accuracy: 17.59%\n",
            "Epoch: 29, Step: 98/655, Loss: 2.213947, Accuracy: 17.54%\n",
            "Epoch: 29, Step: 99/655, Loss: 2.213067, Accuracy: 17.49%\n",
            "Epoch: 29, Step: 100/655, Loss: 2.212196, Accuracy: 17.59%\n",
            "Epoch: 29, Step: 101/655, Loss: 2.211401, Accuracy: 17.73%\n",
            "Epoch: 29, Step: 102/655, Loss: 2.211966, Accuracy: 17.65%\n",
            "Epoch: 29, Step: 103/655, Loss: 2.211703, Accuracy: 17.69%\n",
            "Epoch: 29, Step: 104/655, Loss: 2.212026, Accuracy: 17.67%\n",
            "Epoch: 29, Step: 105/655, Loss: 2.211964, Accuracy: 17.62%\n",
            "Epoch: 29, Step: 106/655, Loss: 2.212490, Accuracy: 17.60%\n",
            "Epoch: 29, Step: 107/655, Loss: 2.213060, Accuracy: 17.61%\n",
            "Epoch: 29, Step: 108/655, Loss: 2.212253, Accuracy: 17.53%\n",
            "Epoch: 29, Step: 109/655, Loss: 2.211818, Accuracy: 17.63%\n",
            "Epoch: 29, Step: 110/655, Loss: 2.212487, Accuracy: 17.67%\n",
            "Epoch: 29, Step: 111/655, Loss: 2.211197, Accuracy: 17.82%\n",
            "Epoch: 29, Step: 112/655, Loss: 2.211435, Accuracy: 17.72%\n",
            "Epoch: 29, Step: 113/655, Loss: 2.211185, Accuracy: 17.84%\n",
            "Epoch: 29, Step: 114/655, Loss: 2.211631, Accuracy: 17.90%\n",
            "Epoch: 29, Step: 115/655, Loss: 2.212862, Accuracy: 17.80%\n",
            "Epoch: 29, Step: 116/655, Loss: 2.213303, Accuracy: 17.78%\n",
            "Epoch: 29, Step: 117/655, Loss: 2.212848, Accuracy: 17.74%\n",
            "Epoch: 29, Step: 118/655, Loss: 2.213107, Accuracy: 17.74%\n",
            "Epoch: 29, Step: 119/655, Loss: 2.214012, Accuracy: 17.73%\n",
            "Epoch: 29, Step: 120/655, Loss: 2.213832, Accuracy: 17.71%\n",
            "Epoch: 29, Step: 121/655, Loss: 2.213026, Accuracy: 17.72%\n",
            "Epoch: 29, Step: 122/655, Loss: 2.212314, Accuracy: 17.78%\n",
            "Epoch: 29, Step: 123/655, Loss: 2.211548, Accuracy: 17.84%\n",
            "Epoch: 29, Step: 124/655, Loss: 2.209772, Accuracy: 17.82%\n",
            "Epoch: 29, Step: 125/655, Loss: 2.210055, Accuracy: 17.88%\n",
            "Epoch: 29, Step: 126/655, Loss: 2.210494, Accuracy: 17.86%\n",
            "Epoch: 29, Step: 127/655, Loss: 2.209616, Accuracy: 17.94%\n",
            "Epoch: 29, Step: 128/655, Loss: 2.210020, Accuracy: 17.85%\n",
            "Epoch: 29, Step: 129/655, Loss: 2.210643, Accuracy: 17.81%\n",
            "Epoch: 29, Step: 130/655, Loss: 2.210090, Accuracy: 17.93%\n",
            "Epoch: 29, Step: 131/655, Loss: 2.209669, Accuracy: 18.01%\n",
            "Epoch: 29, Step: 132/655, Loss: 2.208342, Accuracy: 18.11%\n",
            "Epoch: 29, Step: 133/655, Loss: 2.208285, Accuracy: 18.02%\n",
            "Epoch: 29, Step: 134/655, Loss: 2.208499, Accuracy: 17.96%\n",
            "Epoch: 29, Step: 135/655, Loss: 2.209140, Accuracy: 17.92%\n",
            "Epoch: 29, Step: 136/655, Loss: 2.208773, Accuracy: 17.99%\n",
            "Epoch: 29, Step: 137/655, Loss: 2.207810, Accuracy: 18.02%\n",
            "Epoch: 29, Step: 138/655, Loss: 2.208188, Accuracy: 18.00%\n",
            "Epoch: 29, Step: 139/655, Loss: 2.209046, Accuracy: 18.01%\n",
            "Epoch: 29, Step: 140/655, Loss: 2.208676, Accuracy: 17.97%\n",
            "Epoch: 29, Step: 141/655, Loss: 2.208096, Accuracy: 17.95%\n",
            "Epoch: 29, Step: 142/655, Loss: 2.207535, Accuracy: 17.89%\n",
            "Epoch: 29, Step: 143/655, Loss: 2.208308, Accuracy: 17.90%\n",
            "Epoch: 29, Step: 144/655, Loss: 2.208351, Accuracy: 17.90%\n",
            "Epoch: 29, Step: 145/655, Loss: 2.208600, Accuracy: 17.89%\n",
            "Epoch: 29, Step: 146/655, Loss: 2.209085, Accuracy: 17.83%\n",
            "Epoch: 29, Step: 147/655, Loss: 2.208390, Accuracy: 17.84%\n",
            "Epoch: 29, Step: 148/655, Loss: 2.208890, Accuracy: 17.86%\n",
            "Epoch: 29, Step: 149/655, Loss: 2.209592, Accuracy: 17.87%\n",
            "Epoch: 29, Step: 150/655, Loss: 2.209204, Accuracy: 17.83%\n",
            "Epoch: 29, Step: 151/655, Loss: 2.209274, Accuracy: 17.82%\n",
            "Epoch: 29, Step: 152/655, Loss: 2.209434, Accuracy: 17.76%\n",
            "Epoch: 29, Step: 153/655, Loss: 2.210444, Accuracy: 17.77%\n",
            "Epoch: 29, Step: 154/655, Loss: 2.210051, Accuracy: 17.76%\n",
            "Epoch: 29, Step: 155/655, Loss: 2.209934, Accuracy: 17.78%\n",
            "Epoch: 29, Step: 156/655, Loss: 2.210310, Accuracy: 17.77%\n",
            "Epoch: 29, Step: 157/655, Loss: 2.210151, Accuracy: 17.75%\n",
            "Epoch: 29, Step: 158/655, Loss: 2.209988, Accuracy: 17.82%\n",
            "Epoch: 29, Step: 159/655, Loss: 2.209825, Accuracy: 17.85%\n",
            "Epoch: 29, Step: 160/655, Loss: 2.210025, Accuracy: 17.79%\n",
            "Epoch: 29, Step: 161/655, Loss: 2.209205, Accuracy: 17.86%\n",
            "Epoch: 29, Step: 162/655, Loss: 2.209891, Accuracy: 17.82%\n",
            "Epoch: 29, Step: 163/655, Loss: 2.210447, Accuracy: 17.81%\n",
            "Epoch: 29, Step: 164/655, Loss: 2.209998, Accuracy: 17.89%\n",
            "Epoch: 29, Step: 165/655, Loss: 2.209708, Accuracy: 17.97%\n",
            "Epoch: 29, Step: 166/655, Loss: 2.209369, Accuracy: 18.00%\n",
            "Epoch: 29, Step: 167/655, Loss: 2.208847, Accuracy: 18.04%\n",
            "Epoch: 29, Step: 168/655, Loss: 2.208888, Accuracy: 18.06%\n",
            "Epoch: 29, Step: 169/655, Loss: 2.208965, Accuracy: 18.08%\n",
            "Epoch: 29, Step: 170/655, Loss: 2.209187, Accuracy: 18.07%\n",
            "Epoch: 29, Step: 171/655, Loss: 2.209091, Accuracy: 18.06%\n",
            "Epoch: 29, Step: 172/655, Loss: 2.209507, Accuracy: 18.02%\n",
            "Epoch: 29, Step: 173/655, Loss: 2.208823, Accuracy: 18.08%\n",
            "Epoch: 29, Step: 174/655, Loss: 2.209152, Accuracy: 18.03%\n",
            "Epoch: 29, Step: 175/655, Loss: 2.209125, Accuracy: 18.05%\n",
            "Epoch: 29, Step: 176/655, Loss: 2.209220, Accuracy: 18.00%\n",
            "Epoch: 29, Step: 177/655, Loss: 2.209400, Accuracy: 18.01%\n",
            "Epoch: 29, Step: 178/655, Loss: 2.208863, Accuracy: 18.01%\n",
            "Epoch: 29, Step: 179/655, Loss: 2.209093, Accuracy: 17.98%\n",
            "Epoch: 29, Step: 180/655, Loss: 2.208854, Accuracy: 18.02%\n",
            "Epoch: 29, Step: 181/655, Loss: 2.209383, Accuracy: 18.01%\n",
            "Epoch: 29, Step: 182/655, Loss: 2.210278, Accuracy: 17.99%\n",
            "Epoch: 29, Step: 183/655, Loss: 2.209813, Accuracy: 17.96%\n",
            "Epoch: 29, Step: 184/655, Loss: 2.209125, Accuracy: 18.02%\n",
            "Epoch: 29, Step: 185/655, Loss: 2.209538, Accuracy: 18.01%\n",
            "Epoch: 29, Step: 186/655, Loss: 2.209951, Accuracy: 17.96%\n",
            "Epoch: 29, Step: 187/655, Loss: 2.209866, Accuracy: 17.91%\n",
            "Epoch: 29, Step: 188/655, Loss: 2.209491, Accuracy: 17.89%\n",
            "Epoch: 29, Step: 189/655, Loss: 2.209379, Accuracy: 17.86%\n",
            "Epoch: 29, Step: 190/655, Loss: 2.209355, Accuracy: 17.85%\n",
            "Epoch: 29, Step: 191/655, Loss: 2.209738, Accuracy: 17.80%\n",
            "Epoch: 29, Step: 192/655, Loss: 2.210019, Accuracy: 17.77%\n",
            "Epoch: 29, Step: 193/655, Loss: 2.209737, Accuracy: 17.76%\n",
            "Epoch: 29, Step: 194/655, Loss: 2.209472, Accuracy: 17.78%\n",
            "Epoch: 29, Step: 195/655, Loss: 2.208961, Accuracy: 17.84%\n",
            "Epoch: 29, Step: 196/655, Loss: 2.209111, Accuracy: 17.86%\n",
            "Epoch: 29, Step: 197/655, Loss: 2.209336, Accuracy: 17.86%\n",
            "Epoch: 29, Step: 198/655, Loss: 2.209363, Accuracy: 17.87%\n",
            "Epoch: 29, Step: 199/655, Loss: 2.209382, Accuracy: 17.89%\n",
            "Epoch: 29, Step: 200/655, Loss: 2.208579, Accuracy: 17.91%\n",
            "Epoch: 29, Step: 201/655, Loss: 2.208645, Accuracy: 17.93%\n",
            "Epoch: 29, Step: 202/655, Loss: 2.208775, Accuracy: 17.98%\n",
            "Epoch: 29, Step: 203/655, Loss: 2.208229, Accuracy: 18.03%\n",
            "Epoch: 29, Step: 204/655, Loss: 2.208799, Accuracy: 18.00%\n",
            "Epoch: 29, Step: 205/655, Loss: 2.209012, Accuracy: 17.99%\n",
            "Epoch: 29, Step: 206/655, Loss: 2.208946, Accuracy: 18.04%\n",
            "Epoch: 29, Step: 207/655, Loss: 2.209141, Accuracy: 17.98%\n",
            "Epoch: 29, Step: 208/655, Loss: 2.208959, Accuracy: 17.97%\n",
            "Epoch: 29, Step: 209/655, Loss: 2.209054, Accuracy: 17.99%\n",
            "Epoch: 29, Step: 210/655, Loss: 2.208736, Accuracy: 18.02%\n",
            "Epoch: 29, Step: 211/655, Loss: 2.208846, Accuracy: 17.99%\n",
            "Epoch: 29, Step: 212/655, Loss: 2.208936, Accuracy: 18.03%\n",
            "Epoch: 29, Step: 213/655, Loss: 2.209159, Accuracy: 18.05%\n",
            "Epoch: 29, Step: 214/655, Loss: 2.209159, Accuracy: 18.05%\n",
            "Epoch: 29, Step: 215/655, Loss: 2.209019, Accuracy: 18.04%\n",
            "Epoch: 29, Step: 216/655, Loss: 2.209660, Accuracy: 18.03%\n",
            "Epoch: 29, Step: 217/655, Loss: 2.209723, Accuracy: 18.04%\n",
            "Epoch: 29, Step: 218/655, Loss: 2.209683, Accuracy: 18.02%\n",
            "Epoch: 29, Step: 219/655, Loss: 2.209184, Accuracy: 18.05%\n",
            "Epoch: 29, Step: 220/655, Loss: 2.209442, Accuracy: 18.07%\n",
            "Epoch: 29, Step: 221/655, Loss: 2.209557, Accuracy: 18.09%\n",
            "Epoch: 29, Step: 222/655, Loss: 2.210329, Accuracy: 18.06%\n",
            "Epoch: 29, Step: 223/655, Loss: 2.210688, Accuracy: 18.05%\n",
            "Epoch: 29, Step: 224/655, Loss: 2.210253, Accuracy: 18.08%\n",
            "Epoch: 29, Step: 225/655, Loss: 2.210192, Accuracy: 18.03%\n",
            "Epoch: 29, Step: 226/655, Loss: 2.210003, Accuracy: 18.06%\n",
            "Epoch: 29, Step: 227/655, Loss: 2.209864, Accuracy: 18.08%\n",
            "Epoch: 29, Step: 228/655, Loss: 2.210190, Accuracy: 18.06%\n",
            "Epoch: 29, Step: 229/655, Loss: 2.210334, Accuracy: 18.04%\n",
            "Epoch: 29, Step: 230/655, Loss: 2.210018, Accuracy: 18.06%\n",
            "Epoch: 29, Step: 231/655, Loss: 2.208802, Accuracy: 18.11%\n",
            "Epoch: 29, Step: 232/655, Loss: 2.208529, Accuracy: 18.13%\n",
            "Epoch: 29, Step: 233/655, Loss: 2.207890, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 234/655, Loss: 2.207889, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 235/655, Loss: 2.207673, Accuracy: 18.23%\n",
            "Epoch: 29, Step: 236/655, Loss: 2.207953, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 237/655, Loss: 2.207622, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 238/655, Loss: 2.207640, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 239/655, Loss: 2.207462, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 240/655, Loss: 2.207587, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 241/655, Loss: 2.207871, Accuracy: 18.21%\n",
            "Epoch: 29, Step: 242/655, Loss: 2.207690, Accuracy: 18.23%\n",
            "Epoch: 29, Step: 243/655, Loss: 2.207695, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 244/655, Loss: 2.207988, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 245/655, Loss: 2.207963, Accuracy: 18.23%\n",
            "Epoch: 29, Step: 246/655, Loss: 2.208356, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 247/655, Loss: 2.208191, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 248/655, Loss: 2.208112, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 249/655, Loss: 2.208383, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 250/655, Loss: 2.208642, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 251/655, Loss: 2.209186, Accuracy: 18.15%\n",
            "Epoch: 29, Step: 252/655, Loss: 2.208665, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 253/655, Loss: 2.208719, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 254/655, Loss: 2.208525, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 255/655, Loss: 2.208447, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 256/655, Loss: 2.209105, Accuracy: 18.13%\n",
            "Epoch: 29, Step: 257/655, Loss: 2.208615, Accuracy: 18.15%\n",
            "Epoch: 29, Step: 258/655, Loss: 2.208050, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 259/655, Loss: 2.207634, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 260/655, Loss: 2.207639, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 261/655, Loss: 2.207696, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 262/655, Loss: 2.207440, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 263/655, Loss: 2.207608, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 264/655, Loss: 2.207441, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 265/655, Loss: 2.207599, Accuracy: 18.23%\n",
            "Epoch: 29, Step: 266/655, Loss: 2.207805, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 267/655, Loss: 2.207167, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 268/655, Loss: 2.207276, Accuracy: 18.21%\n",
            "Epoch: 29, Step: 269/655, Loss: 2.207112, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 270/655, Loss: 2.206878, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 271/655, Loss: 2.206850, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 272/655, Loss: 2.207275, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 273/655, Loss: 2.207405, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 274/655, Loss: 2.207590, Accuracy: 18.18%\n",
            "Epoch: 29, Step: 275/655, Loss: 2.207529, Accuracy: 18.16%\n",
            "Epoch: 29, Step: 276/655, Loss: 2.207268, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 277/655, Loss: 2.206846, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 278/655, Loss: 2.206540, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 279/655, Loss: 2.206214, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 280/655, Loss: 2.206290, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 281/655, Loss: 2.206587, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 282/655, Loss: 2.206676, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 283/655, Loss: 2.206765, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 284/655, Loss: 2.207343, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 285/655, Loss: 2.208021, Accuracy: 18.18%\n",
            "Epoch: 29, Step: 286/655, Loss: 2.208447, Accuracy: 18.18%\n",
            "Epoch: 29, Step: 287/655, Loss: 2.208622, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 288/655, Loss: 2.208690, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 289/655, Loss: 2.208386, Accuracy: 18.18%\n",
            "Epoch: 29, Step: 290/655, Loss: 2.208167, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 291/655, Loss: 2.207344, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 292/655, Loss: 2.207379, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 293/655, Loss: 2.206519, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 294/655, Loss: 2.206678, Accuracy: 18.32%\n",
            "Epoch: 29, Step: 295/655, Loss: 2.206566, Accuracy: 18.34%\n",
            "Epoch: 29, Step: 296/655, Loss: 2.206835, Accuracy: 18.32%\n",
            "Epoch: 29, Step: 297/655, Loss: 2.207283, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 298/655, Loss: 2.207222, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 299/655, Loss: 2.207479, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 300/655, Loss: 2.207612, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 301/655, Loss: 2.207489, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 302/655, Loss: 2.207617, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 303/655, Loss: 2.207863, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 304/655, Loss: 2.208200, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 305/655, Loss: 2.208423, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 306/655, Loss: 2.208716, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 307/655, Loss: 2.208306, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 308/655, Loss: 2.208278, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 309/655, Loss: 2.208451, Accuracy: 18.27%\n",
            "Epoch: 29, Step: 310/655, Loss: 2.208245, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 311/655, Loss: 2.208486, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 312/655, Loss: 2.208421, Accuracy: 18.27%\n",
            "Epoch: 29, Step: 313/655, Loss: 2.208379, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 314/655, Loss: 2.208224, Accuracy: 18.32%\n",
            "Epoch: 29, Step: 315/655, Loss: 2.208412, Accuracy: 18.34%\n",
            "Epoch: 29, Step: 316/655, Loss: 2.208578, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 317/655, Loss: 2.208397, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 318/655, Loss: 2.208391, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 319/655, Loss: 2.208629, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 320/655, Loss: 2.208649, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 321/655, Loss: 2.208928, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 322/655, Loss: 2.209087, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 323/655, Loss: 2.209010, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 324/655, Loss: 2.208707, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 325/655, Loss: 2.208903, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 326/655, Loss: 2.209089, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 327/655, Loss: 2.209022, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 328/655, Loss: 2.209207, Accuracy: 18.23%\n",
            "Epoch: 29, Step: 329/655, Loss: 2.209019, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 330/655, Loss: 2.208600, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 331/655, Loss: 2.209017, Accuracy: 18.21%\n",
            "Epoch: 29, Step: 332/655, Loss: 2.208730, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 333/655, Loss: 2.208787, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 334/655, Loss: 2.209005, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 335/655, Loss: 2.209045, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 336/655, Loss: 2.208973, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 337/655, Loss: 2.208994, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 338/655, Loss: 2.209032, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 339/655, Loss: 2.208463, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 340/655, Loss: 2.208609, Accuracy: 18.27%\n",
            "Epoch: 29, Step: 341/655, Loss: 2.208283, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 342/655, Loss: 2.208226, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 343/655, Loss: 2.208176, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 344/655, Loss: 2.208226, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 345/655, Loss: 2.208090, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 346/655, Loss: 2.208354, Accuracy: 18.27%\n",
            "Epoch: 29, Step: 347/655, Loss: 2.208667, Accuracy: 18.23%\n",
            "Epoch: 29, Step: 348/655, Loss: 2.208855, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 349/655, Loss: 2.209016, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 350/655, Loss: 2.209005, Accuracy: 18.18%\n",
            "Epoch: 29, Step: 351/655, Loss: 2.208742, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 352/655, Loss: 2.208756, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 353/655, Loss: 2.208689, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 354/655, Loss: 2.208721, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 355/655, Loss: 2.209040, Accuracy: 18.14%\n",
            "Epoch: 29, Step: 356/655, Loss: 2.208536, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 357/655, Loss: 2.208553, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 358/655, Loss: 2.208341, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 359/655, Loss: 2.208384, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 360/655, Loss: 2.208569, Accuracy: 18.16%\n",
            "Epoch: 29, Step: 361/655, Loss: 2.208894, Accuracy: 18.15%\n",
            "Epoch: 29, Step: 362/655, Loss: 2.208974, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 363/655, Loss: 2.208926, Accuracy: 18.18%\n",
            "Epoch: 29, Step: 364/655, Loss: 2.209035, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 365/655, Loss: 2.209049, Accuracy: 18.15%\n",
            "Epoch: 29, Step: 366/655, Loss: 2.208897, Accuracy: 18.18%\n",
            "Epoch: 29, Step: 367/655, Loss: 2.209065, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 368/655, Loss: 2.209246, Accuracy: 18.16%\n",
            "Epoch: 29, Step: 369/655, Loss: 2.209559, Accuracy: 18.14%\n",
            "Epoch: 29, Step: 370/655, Loss: 2.209621, Accuracy: 18.18%\n",
            "Epoch: 29, Step: 371/655, Loss: 2.209679, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 372/655, Loss: 2.209413, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 373/655, Loss: 2.209497, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 374/655, Loss: 2.209739, Accuracy: 18.18%\n",
            "Epoch: 29, Step: 375/655, Loss: 2.209827, Accuracy: 18.18%\n",
            "Epoch: 29, Step: 376/655, Loss: 2.210030, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 377/655, Loss: 2.210073, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 378/655, Loss: 2.210437, Accuracy: 18.18%\n",
            "Epoch: 29, Step: 379/655, Loss: 2.210329, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 380/655, Loss: 2.210233, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 381/655, Loss: 2.210420, Accuracy: 18.21%\n",
            "Epoch: 29, Step: 382/655, Loss: 2.210334, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 383/655, Loss: 2.210472, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 384/655, Loss: 2.210522, Accuracy: 18.18%\n",
            "Epoch: 29, Step: 385/655, Loss: 2.210960, Accuracy: 18.15%\n",
            "Epoch: 29, Step: 386/655, Loss: 2.210973, Accuracy: 18.15%\n",
            "Epoch: 29, Step: 387/655, Loss: 2.210961, Accuracy: 18.14%\n",
            "Epoch: 29, Step: 388/655, Loss: 2.210907, Accuracy: 18.14%\n",
            "Epoch: 29, Step: 389/655, Loss: 2.211035, Accuracy: 18.13%\n",
            "Epoch: 29, Step: 390/655, Loss: 2.210738, Accuracy: 18.13%\n",
            "Epoch: 29, Step: 391/655, Loss: 2.210711, Accuracy: 18.14%\n",
            "Epoch: 29, Step: 392/655, Loss: 2.210840, Accuracy: 18.13%\n",
            "Epoch: 29, Step: 393/655, Loss: 2.210348, Accuracy: 18.16%\n",
            "Epoch: 29, Step: 394/655, Loss: 2.210440, Accuracy: 18.16%\n",
            "Epoch: 29, Step: 395/655, Loss: 2.210282, Accuracy: 18.18%\n",
            "Epoch: 29, Step: 396/655, Loss: 2.210058, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 397/655, Loss: 2.209994, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 398/655, Loss: 2.209885, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 399/655, Loss: 2.209857, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 400/655, Loss: 2.209868, Accuracy: 18.21%\n",
            "Epoch: 29, Step: 401/655, Loss: 2.210021, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 402/655, Loss: 2.209992, Accuracy: 18.18%\n",
            "Epoch: 29, Step: 403/655, Loss: 2.209970, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 404/655, Loss: 2.209913, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 405/655, Loss: 2.209607, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 406/655, Loss: 2.209490, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 407/655, Loss: 2.209315, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 408/655, Loss: 2.209455, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 409/655, Loss: 2.209272, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 410/655, Loss: 2.209112, Accuracy: 18.23%\n",
            "Epoch: 29, Step: 411/655, Loss: 2.209340, Accuracy: 18.23%\n",
            "Epoch: 29, Step: 412/655, Loss: 2.209522, Accuracy: 18.23%\n",
            "Epoch: 29, Step: 413/655, Loss: 2.209541, Accuracy: 18.23%\n",
            "Epoch: 29, Step: 414/655, Loss: 2.209885, Accuracy: 18.21%\n",
            "Epoch: 29, Step: 415/655, Loss: 2.210034, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 416/655, Loss: 2.210247, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 417/655, Loss: 2.210415, Accuracy: 18.18%\n",
            "Epoch: 29, Step: 418/655, Loss: 2.210565, Accuracy: 18.14%\n",
            "Epoch: 29, Step: 419/655, Loss: 2.210547, Accuracy: 18.16%\n",
            "Epoch: 29, Step: 420/655, Loss: 2.210623, Accuracy: 18.15%\n",
            "Epoch: 29, Step: 421/655, Loss: 2.210651, Accuracy: 18.15%\n",
            "Epoch: 29, Step: 422/655, Loss: 2.210354, Accuracy: 18.17%\n",
            "Epoch: 29, Step: 423/655, Loss: 2.210067, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 424/655, Loss: 2.210147, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 425/655, Loss: 2.210069, Accuracy: 18.21%\n",
            "Epoch: 29, Step: 426/655, Loss: 2.210019, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 427/655, Loss: 2.210019, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 428/655, Loss: 2.209944, Accuracy: 18.20%\n",
            "Epoch: 29, Step: 429/655, Loss: 2.210082, Accuracy: 18.19%\n",
            "Epoch: 29, Step: 430/655, Loss: 2.209842, Accuracy: 18.22%\n",
            "Epoch: 29, Step: 431/655, Loss: 2.209689, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 432/655, Loss: 2.209833, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 433/655, Loss: 2.209869, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 434/655, Loss: 2.209599, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 435/655, Loss: 2.209495, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 436/655, Loss: 2.209811, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 437/655, Loss: 2.209725, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 438/655, Loss: 2.210003, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 439/655, Loss: 2.209926, Accuracy: 18.27%\n",
            "Epoch: 29, Step: 440/655, Loss: 2.209828, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 441/655, Loss: 2.209969, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 442/655, Loss: 2.210066, Accuracy: 18.27%\n",
            "Epoch: 29, Step: 443/655, Loss: 2.209967, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 444/655, Loss: 2.210032, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 445/655, Loss: 2.210033, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 446/655, Loss: 2.210337, Accuracy: 18.27%\n",
            "Epoch: 29, Step: 447/655, Loss: 2.210384, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 448/655, Loss: 2.210275, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 449/655, Loss: 2.210134, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 450/655, Loss: 2.210177, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 451/655, Loss: 2.210054, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 452/655, Loss: 2.210256, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 453/655, Loss: 2.210223, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 454/655, Loss: 2.210098, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 455/655, Loss: 2.210455, Accuracy: 18.27%\n",
            "Epoch: 29, Step: 456/655, Loss: 2.210482, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 457/655, Loss: 2.210245, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 458/655, Loss: 2.210139, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 459/655, Loss: 2.210238, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 460/655, Loss: 2.210345, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 461/655, Loss: 2.210312, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 462/655, Loss: 2.210574, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 463/655, Loss: 2.210436, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 464/655, Loss: 2.210389, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 465/655, Loss: 2.210417, Accuracy: 18.32%\n",
            "Epoch: 29, Step: 466/655, Loss: 2.210744, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 467/655, Loss: 2.210697, Accuracy: 18.32%\n",
            "Epoch: 29, Step: 468/655, Loss: 2.210405, Accuracy: 18.34%\n",
            "Epoch: 29, Step: 469/655, Loss: 2.210359, Accuracy: 18.35%\n",
            "Epoch: 29, Step: 470/655, Loss: 2.210499, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 471/655, Loss: 2.210697, Accuracy: 18.34%\n",
            "Epoch: 29, Step: 472/655, Loss: 2.210823, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 473/655, Loss: 2.210839, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 474/655, Loss: 2.210875, Accuracy: 18.34%\n",
            "Epoch: 29, Step: 475/655, Loss: 2.210626, Accuracy: 18.36%\n",
            "Epoch: 29, Step: 476/655, Loss: 2.210620, Accuracy: 18.34%\n",
            "Epoch: 29, Step: 477/655, Loss: 2.210375, Accuracy: 18.36%\n",
            "Epoch: 29, Step: 478/655, Loss: 2.210318, Accuracy: 18.36%\n",
            "Epoch: 29, Step: 479/655, Loss: 2.210117, Accuracy: 18.37%\n",
            "Epoch: 29, Step: 480/655, Loss: 2.210211, Accuracy: 18.37%\n",
            "Epoch: 29, Step: 481/655, Loss: 2.210223, Accuracy: 18.37%\n",
            "Epoch: 29, Step: 482/655, Loss: 2.210205, Accuracy: 18.37%\n",
            "Epoch: 29, Step: 483/655, Loss: 2.210403, Accuracy: 18.34%\n",
            "Epoch: 29, Step: 484/655, Loss: 2.210431, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 485/655, Loss: 2.210448, Accuracy: 18.32%\n",
            "Epoch: 29, Step: 486/655, Loss: 2.210589, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 487/655, Loss: 2.210718, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 488/655, Loss: 2.211020, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 489/655, Loss: 2.210823, Accuracy: 18.32%\n",
            "Epoch: 29, Step: 490/655, Loss: 2.210639, Accuracy: 18.34%\n",
            "Epoch: 29, Step: 491/655, Loss: 2.210522, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 492/655, Loss: 2.210414, Accuracy: 18.32%\n",
            "Epoch: 29, Step: 493/655, Loss: 2.210348, Accuracy: 18.34%\n",
            "Epoch: 29, Step: 494/655, Loss: 2.210299, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 495/655, Loss: 2.210369, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 496/655, Loss: 2.210137, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 497/655, Loss: 2.210151, Accuracy: 18.35%\n",
            "Epoch: 29, Step: 498/655, Loss: 2.210048, Accuracy: 18.36%\n",
            "Epoch: 29, Step: 499/655, Loss: 2.209870, Accuracy: 18.35%\n",
            "Epoch: 29, Step: 500/655, Loss: 2.209863, Accuracy: 18.34%\n",
            "Epoch: 29, Step: 501/655, Loss: 2.210024, Accuracy: 18.32%\n",
            "Epoch: 29, Step: 502/655, Loss: 2.210177, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 503/655, Loss: 2.210099, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 504/655, Loss: 2.210209, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 505/655, Loss: 2.210136, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 506/655, Loss: 2.210258, Accuracy: 18.32%\n",
            "Epoch: 29, Step: 507/655, Loss: 2.210278, Accuracy: 18.32%\n",
            "Epoch: 29, Step: 508/655, Loss: 2.210040, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 509/655, Loss: 2.210352, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 510/655, Loss: 2.210476, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 511/655, Loss: 2.210725, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 512/655, Loss: 2.210568, Accuracy: 18.27%\n",
            "Epoch: 29, Step: 513/655, Loss: 2.210352, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 514/655, Loss: 2.210339, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 515/655, Loss: 2.210445, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 516/655, Loss: 2.210255, Accuracy: 18.27%\n",
            "Epoch: 29, Step: 517/655, Loss: 2.210076, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 518/655, Loss: 2.210089, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 519/655, Loss: 2.210274, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 520/655, Loss: 2.210154, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 521/655, Loss: 2.209954, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 522/655, Loss: 2.209872, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 523/655, Loss: 2.209960, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 524/655, Loss: 2.210151, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 525/655, Loss: 2.210353, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 526/655, Loss: 2.210455, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 527/655, Loss: 2.210645, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 528/655, Loss: 2.210138, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 529/655, Loss: 2.210036, Accuracy: 18.34%\n",
            "Epoch: 29, Step: 530/655, Loss: 2.210360, Accuracy: 18.32%\n",
            "Epoch: 29, Step: 531/655, Loss: 2.210392, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 532/655, Loss: 2.210404, Accuracy: 18.32%\n",
            "Epoch: 29, Step: 533/655, Loss: 2.210443, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 534/655, Loss: 2.210527, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 535/655, Loss: 2.210591, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 536/655, Loss: 2.210674, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 537/655, Loss: 2.210833, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 538/655, Loss: 2.210849, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 539/655, Loss: 2.211006, Accuracy: 18.27%\n",
            "Epoch: 29, Step: 540/655, Loss: 2.210786, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 541/655, Loss: 2.211032, Accuracy: 18.27%\n",
            "Epoch: 29, Step: 542/655, Loss: 2.210775, Accuracy: 18.27%\n",
            "Epoch: 29, Step: 543/655, Loss: 2.210757, Accuracy: 18.24%\n",
            "Epoch: 29, Step: 544/655, Loss: 2.210783, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 545/655, Loss: 2.210881, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 546/655, Loss: 2.211075, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 547/655, Loss: 2.210847, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 548/655, Loss: 2.210904, Accuracy: 18.27%\n",
            "Epoch: 29, Step: 549/655, Loss: 2.211086, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 550/655, Loss: 2.210939, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 551/655, Loss: 2.210658, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 552/655, Loss: 2.210548, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 553/655, Loss: 2.210474, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 554/655, Loss: 2.210297, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 555/655, Loss: 2.210386, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 556/655, Loss: 2.210360, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 557/655, Loss: 2.210509, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 558/655, Loss: 2.210575, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 559/655, Loss: 2.210467, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 560/655, Loss: 2.210388, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 561/655, Loss: 2.210399, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 562/655, Loss: 2.210499, Accuracy: 18.28%\n",
            "Epoch: 29, Step: 563/655, Loss: 2.210518, Accuracy: 18.27%\n",
            "Epoch: 29, Step: 564/655, Loss: 2.210410, Accuracy: 18.25%\n",
            "Epoch: 29, Step: 565/655, Loss: 2.210470, Accuracy: 18.26%\n",
            "Epoch: 29, Step: 566/655, Loss: 2.210274, Accuracy: 18.29%\n",
            "Epoch: 29, Step: 567/655, Loss: 2.210160, Accuracy: 18.30%\n",
            "Epoch: 29, Step: 568/655, Loss: 2.210088, Accuracy: 18.31%\n",
            "Epoch: 29, Step: 569/655, Loss: 2.209999, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 570/655, Loss: 2.209884, Accuracy: 18.32%\n",
            "Epoch: 29, Step: 571/655, Loss: 2.209836, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 572/655, Loss: 2.209917, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 573/655, Loss: 2.209844, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 574/655, Loss: 2.209828, Accuracy: 18.33%\n",
            "Epoch: 29, Step: 575/655, Loss: 2.209806, Accuracy: 18.34%\n",
            "Epoch: 29, Step: 576/655, Loss: 2.209606, Accuracy: 18.35%\n",
            "Epoch: 29, Step: 577/655, Loss: 2.209646, Accuracy: 18.35%\n",
            "Epoch: 29, Step: 578/655, Loss: 2.209751, Accuracy: 18.34%\n",
            "Epoch: 29, Step: 579/655, Loss: 2.209490, Accuracy: 18.38%\n",
            "Epoch: 29, Step: 580/655, Loss: 2.209416, Accuracy: 18.39%\n",
            "Epoch: 29, Step: 581/655, Loss: 2.209328, Accuracy: 18.39%\n",
            "Epoch: 29, Step: 582/655, Loss: 2.209265, Accuracy: 18.39%\n",
            "Epoch: 29, Step: 583/655, Loss: 2.209404, Accuracy: 18.37%\n",
            "Epoch: 29, Step: 584/655, Loss: 2.209539, Accuracy: 18.36%\n",
            "Epoch: 29, Step: 585/655, Loss: 2.209528, Accuracy: 18.35%\n",
            "Epoch: 29, Step: 586/655, Loss: 2.209463, Accuracy: 18.36%\n",
            "Epoch: 29, Step: 587/655, Loss: 2.209299, Accuracy: 18.37%\n",
            "Epoch: 29, Step: 588/655, Loss: 2.209429, Accuracy: 18.35%\n",
            "Epoch: 29, Step: 589/655, Loss: 2.209357, Accuracy: 18.36%\n",
            "Epoch: 29, Step: 590/655, Loss: 2.209451, Accuracy: 18.36%\n",
            "Epoch: 29, Step: 591/655, Loss: 2.209265, Accuracy: 18.37%\n",
            "Epoch: 29, Step: 592/655, Loss: 2.209151, Accuracy: 18.38%\n",
            "Epoch: 29, Step: 593/655, Loss: 2.209085, Accuracy: 18.38%\n",
            "Epoch: 29, Step: 594/655, Loss: 2.209208, Accuracy: 18.38%\n",
            "Epoch: 29, Step: 595/655, Loss: 2.209102, Accuracy: 18.39%\n",
            "Epoch: 29, Step: 596/655, Loss: 2.208890, Accuracy: 18.39%\n",
            "Epoch: 29, Step: 597/655, Loss: 2.208911, Accuracy: 18.39%\n",
            "Epoch: 29, Step: 598/655, Loss: 2.208877, Accuracy: 18.39%\n",
            "Epoch: 29, Step: 599/655, Loss: 2.208590, Accuracy: 18.42%\n",
            "Epoch: 29, Step: 600/655, Loss: 2.208439, Accuracy: 18.43%\n",
            "Epoch: 29, Step: 601/655, Loss: 2.208617, Accuracy: 18.42%\n",
            "Epoch: 29, Step: 602/655, Loss: 2.208647, Accuracy: 18.41%\n",
            "Epoch: 29, Step: 603/655, Loss: 2.208564, Accuracy: 18.41%\n",
            "Epoch: 29, Step: 604/655, Loss: 2.208582, Accuracy: 18.39%\n",
            "Epoch: 29, Step: 605/655, Loss: 2.208773, Accuracy: 18.40%\n",
            "Epoch: 29, Step: 606/655, Loss: 2.209032, Accuracy: 18.38%\n",
            "Epoch: 29, Step: 607/655, Loss: 2.209135, Accuracy: 18.39%\n",
            "Epoch: 29, Step: 608/655, Loss: 2.208886, Accuracy: 18.39%\n",
            "Epoch: 29, Step: 609/655, Loss: 2.208885, Accuracy: 18.39%\n",
            "Epoch: 29, Step: 610/655, Loss: 2.208809, Accuracy: 18.40%\n",
            "Epoch: 29, Step: 611/655, Loss: 2.208418, Accuracy: 18.42%\n",
            "Epoch: 29, Step: 612/655, Loss: 2.208510, Accuracy: 18.42%\n",
            "Epoch: 29, Step: 613/655, Loss: 2.208527, Accuracy: 18.42%\n",
            "Epoch: 29, Step: 614/655, Loss: 2.208530, Accuracy: 18.43%\n",
            "Epoch: 29, Step: 615/655, Loss: 2.208365, Accuracy: 18.45%\n",
            "Epoch: 29, Step: 616/655, Loss: 2.208455, Accuracy: 18.45%\n",
            "Epoch: 29, Step: 617/655, Loss: 2.208376, Accuracy: 18.46%\n",
            "Epoch: 29, Step: 618/655, Loss: 2.208413, Accuracy: 18.46%\n",
            "Epoch: 29, Step: 619/655, Loss: 2.208528, Accuracy: 18.46%\n",
            "Epoch: 29, Step: 620/655, Loss: 2.208611, Accuracy: 18.45%\n",
            "Epoch: 29, Step: 621/655, Loss: 2.208819, Accuracy: 18.45%\n",
            "Epoch: 29, Step: 622/655, Loss: 2.208747, Accuracy: 18.45%\n",
            "Epoch: 29, Step: 623/655, Loss: 2.208534, Accuracy: 18.45%\n",
            "Epoch: 29, Step: 624/655, Loss: 2.208514, Accuracy: 18.46%\n",
            "Epoch: 29, Step: 625/655, Loss: 2.208619, Accuracy: 18.46%\n",
            "Epoch: 29, Step: 626/655, Loss: 2.208466, Accuracy: 18.47%\n",
            "Epoch: 29, Step: 627/655, Loss: 2.208395, Accuracy: 18.45%\n",
            "Epoch: 29, Step: 628/655, Loss: 2.208518, Accuracy: 18.44%\n",
            "Epoch: 29, Step: 629/655, Loss: 2.208551, Accuracy: 18.45%\n",
            "Epoch: 29, Step: 630/655, Loss: 2.208274, Accuracy: 18.45%\n",
            "Epoch: 29, Step: 631/655, Loss: 2.208181, Accuracy: 18.47%\n",
            "Epoch: 29, Step: 632/655, Loss: 2.208229, Accuracy: 18.48%\n",
            "Epoch: 29, Step: 633/655, Loss: 2.208408, Accuracy: 18.47%\n",
            "Epoch: 29, Step: 634/655, Loss: 2.208563, Accuracy: 18.46%\n",
            "Epoch: 29, Step: 635/655, Loss: 2.208743, Accuracy: 18.44%\n",
            "Epoch: 29, Step: 636/655, Loss: 2.208838, Accuracy: 18.44%\n",
            "Epoch: 29, Step: 637/655, Loss: 2.208909, Accuracy: 18.44%\n",
            "Epoch: 29, Step: 638/655, Loss: 2.208824, Accuracy: 18.44%\n",
            "Epoch: 29, Step: 639/655, Loss: 2.208759, Accuracy: 18.44%\n",
            "Epoch: 29, Step: 640/655, Loss: 2.208616, Accuracy: 18.44%\n",
            "Epoch: 29, Step: 641/655, Loss: 2.208675, Accuracy: 18.42%\n",
            "Epoch: 29, Step: 642/655, Loss: 2.208548, Accuracy: 18.45%\n",
            "Epoch: 29, Step: 643/655, Loss: 2.208411, Accuracy: 18.45%\n",
            "Epoch: 29, Step: 644/655, Loss: 2.208373, Accuracy: 18.44%\n",
            "Epoch: 29, Step: 645/655, Loss: 2.208312, Accuracy: 18.44%\n",
            "Epoch: 29, Step: 646/655, Loss: 2.208308, Accuracy: 18.43%\n",
            "Epoch: 29, Step: 647/655, Loss: 2.208350, Accuracy: 18.44%\n",
            "Epoch: 29, Step: 648/655, Loss: 2.208115, Accuracy: 18.46%\n",
            "Epoch: 29, Step: 649/655, Loss: 2.208001, Accuracy: 18.46%\n",
            "Epoch: 29, Step: 650/655, Loss: 2.208004, Accuracy: 18.46%\n",
            "Epoch: 29, Step: 651/655, Loss: 2.207786, Accuracy: 18.48%\n",
            "Epoch: 29, Step: 652/655, Loss: 2.207819, Accuracy: 18.46%\n",
            "Epoch: 29, Step: 653/655, Loss: 2.207744, Accuracy: 18.46%\n",
            "Epoch: 29, Step: 654/655, Loss: 2.207735, Accuracy: 18.46%\n",
            "Epoch: 29, Step: 655/655, Loss: 2.207600, Accuracy: 18.46%\n",
            "Epoch: 30, Step: 1/655, Loss: 2.044740, Accuracy: 34.38%\n",
            "Epoch: 30, Step: 2/655, Loss: 2.187556, Accuracy: 23.44%\n",
            "Epoch: 30, Step: 3/655, Loss: 2.216738, Accuracy: 17.71%\n",
            "Epoch: 30, Step: 4/655, Loss: 2.228311, Accuracy: 15.62%\n",
            "Epoch: 30, Step: 5/655, Loss: 2.229903, Accuracy: 16.88%\n",
            "Epoch: 30, Step: 6/655, Loss: 2.259634, Accuracy: 15.62%\n",
            "Epoch: 30, Step: 7/655, Loss: 2.260255, Accuracy: 16.07%\n",
            "Epoch: 30, Step: 8/655, Loss: 2.251812, Accuracy: 17.19%\n",
            "Epoch: 30, Step: 9/655, Loss: 2.252480, Accuracy: 17.01%\n",
            "Epoch: 30, Step: 10/655, Loss: 2.253399, Accuracy: 16.88%\n",
            "Epoch: 30, Step: 11/655, Loss: 2.241305, Accuracy: 17.33%\n",
            "Epoch: 30, Step: 12/655, Loss: 2.246672, Accuracy: 17.19%\n",
            "Epoch: 30, Step: 13/655, Loss: 2.239766, Accuracy: 17.79%\n",
            "Epoch: 30, Step: 14/655, Loss: 2.235997, Accuracy: 18.08%\n",
            "Epoch: 30, Step: 15/655, Loss: 2.238298, Accuracy: 17.92%\n",
            "Epoch: 30, Step: 16/655, Loss: 2.242452, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 17/655, Loss: 2.233590, Accuracy: 18.57%\n",
            "Epoch: 30, Step: 18/655, Loss: 2.236505, Accuracy: 18.06%\n",
            "Epoch: 30, Step: 19/655, Loss: 2.232166, Accuracy: 18.09%\n",
            "Epoch: 30, Step: 20/655, Loss: 2.236692, Accuracy: 17.97%\n",
            "Epoch: 30, Step: 21/655, Loss: 2.234425, Accuracy: 17.86%\n",
            "Epoch: 30, Step: 22/655, Loss: 2.239496, Accuracy: 17.61%\n",
            "Epoch: 30, Step: 23/655, Loss: 2.239383, Accuracy: 17.66%\n",
            "Epoch: 30, Step: 24/655, Loss: 2.235356, Accuracy: 17.58%\n",
            "Epoch: 30, Step: 25/655, Loss: 2.238209, Accuracy: 17.38%\n",
            "Epoch: 30, Step: 26/655, Loss: 2.239354, Accuracy: 17.67%\n",
            "Epoch: 30, Step: 27/655, Loss: 2.235446, Accuracy: 18.17%\n",
            "Epoch: 30, Step: 28/655, Loss: 2.236921, Accuracy: 17.97%\n",
            "Epoch: 30, Step: 29/655, Loss: 2.234153, Accuracy: 18.00%\n",
            "Epoch: 30, Step: 30/655, Loss: 2.233569, Accuracy: 17.81%\n",
            "Epoch: 30, Step: 31/655, Loss: 2.231025, Accuracy: 17.94%\n",
            "Epoch: 30, Step: 32/655, Loss: 2.227938, Accuracy: 18.07%\n",
            "Epoch: 30, Step: 33/655, Loss: 2.226141, Accuracy: 18.28%\n",
            "Epoch: 30, Step: 34/655, Loss: 2.230334, Accuracy: 18.20%\n",
            "Epoch: 30, Step: 35/655, Loss: 2.232180, Accuracy: 18.12%\n",
            "Epoch: 30, Step: 36/655, Loss: 2.229386, Accuracy: 18.23%\n",
            "Epoch: 30, Step: 37/655, Loss: 2.227383, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 38/655, Loss: 2.229907, Accuracy: 18.09%\n",
            "Epoch: 30, Step: 39/655, Loss: 2.229790, Accuracy: 18.11%\n",
            "Epoch: 30, Step: 40/655, Loss: 2.230747, Accuracy: 17.97%\n",
            "Epoch: 30, Step: 41/655, Loss: 2.229407, Accuracy: 17.99%\n",
            "Epoch: 30, Step: 42/655, Loss: 2.230212, Accuracy: 17.86%\n",
            "Epoch: 30, Step: 43/655, Loss: 2.230726, Accuracy: 17.73%\n",
            "Epoch: 30, Step: 44/655, Loss: 2.232231, Accuracy: 17.68%\n",
            "Epoch: 30, Step: 45/655, Loss: 2.230874, Accuracy: 17.64%\n",
            "Epoch: 30, Step: 46/655, Loss: 2.234212, Accuracy: 17.53%\n",
            "Epoch: 30, Step: 47/655, Loss: 2.234751, Accuracy: 17.62%\n",
            "Epoch: 30, Step: 48/655, Loss: 2.230663, Accuracy: 17.77%\n",
            "Epoch: 30, Step: 49/655, Loss: 2.228901, Accuracy: 17.86%\n",
            "Epoch: 30, Step: 50/655, Loss: 2.232600, Accuracy: 17.75%\n",
            "Epoch: 30, Step: 51/655, Loss: 2.233754, Accuracy: 17.59%\n",
            "Epoch: 30, Step: 52/655, Loss: 2.233767, Accuracy: 17.55%\n",
            "Epoch: 30, Step: 53/655, Loss: 2.233238, Accuracy: 17.39%\n",
            "Epoch: 30, Step: 54/655, Loss: 2.233579, Accuracy: 17.42%\n",
            "Epoch: 30, Step: 55/655, Loss: 2.232161, Accuracy: 17.67%\n",
            "Epoch: 30, Step: 56/655, Loss: 2.234498, Accuracy: 17.58%\n",
            "Epoch: 30, Step: 57/655, Loss: 2.235150, Accuracy: 17.60%\n",
            "Epoch: 30, Step: 58/655, Loss: 2.233593, Accuracy: 17.67%\n",
            "Epoch: 30, Step: 59/655, Loss: 2.233777, Accuracy: 17.53%\n",
            "Epoch: 30, Step: 60/655, Loss: 2.234838, Accuracy: 17.45%\n",
            "Epoch: 30, Step: 61/655, Loss: 2.232879, Accuracy: 17.62%\n",
            "Epoch: 30, Step: 62/655, Loss: 2.232308, Accuracy: 17.79%\n",
            "Epoch: 30, Step: 63/655, Loss: 2.232196, Accuracy: 17.81%\n",
            "Epoch: 30, Step: 64/655, Loss: 2.231054, Accuracy: 17.77%\n",
            "Epoch: 30, Step: 65/655, Loss: 2.231432, Accuracy: 17.69%\n",
            "Epoch: 30, Step: 66/655, Loss: 2.231606, Accuracy: 17.71%\n",
            "Epoch: 30, Step: 67/655, Loss: 2.231557, Accuracy: 17.58%\n",
            "Epoch: 30, Step: 68/655, Loss: 2.232210, Accuracy: 17.42%\n",
            "Epoch: 30, Step: 69/655, Loss: 2.232412, Accuracy: 17.39%\n",
            "Epoch: 30, Step: 70/655, Loss: 2.233351, Accuracy: 17.37%\n",
            "Epoch: 30, Step: 71/655, Loss: 2.232179, Accuracy: 17.34%\n",
            "Epoch: 30, Step: 72/655, Loss: 2.232022, Accuracy: 17.45%\n",
            "Epoch: 30, Step: 73/655, Loss: 2.232059, Accuracy: 17.51%\n",
            "Epoch: 30, Step: 74/655, Loss: 2.233956, Accuracy: 17.40%\n",
            "Epoch: 30, Step: 75/655, Loss: 2.233500, Accuracy: 17.38%\n",
            "Epoch: 30, Step: 76/655, Loss: 2.233036, Accuracy: 17.48%\n",
            "Epoch: 30, Step: 77/655, Loss: 2.234051, Accuracy: 17.41%\n",
            "Epoch: 30, Step: 78/655, Loss: 2.233709, Accuracy: 17.35%\n",
            "Epoch: 30, Step: 79/655, Loss: 2.234069, Accuracy: 17.29%\n",
            "Epoch: 30, Step: 80/655, Loss: 2.233880, Accuracy: 17.30%\n",
            "Epoch: 30, Step: 81/655, Loss: 2.234190, Accuracy: 17.25%\n",
            "Epoch: 30, Step: 82/655, Loss: 2.233778, Accuracy: 17.19%\n",
            "Epoch: 30, Step: 83/655, Loss: 2.233014, Accuracy: 17.21%\n",
            "Epoch: 30, Step: 84/655, Loss: 2.233796, Accuracy: 17.19%\n",
            "Epoch: 30, Step: 85/655, Loss: 2.233505, Accuracy: 17.17%\n",
            "Epoch: 30, Step: 86/655, Loss: 2.232862, Accuracy: 17.19%\n",
            "Epoch: 30, Step: 87/655, Loss: 2.233167, Accuracy: 17.21%\n",
            "Epoch: 30, Step: 88/655, Loss: 2.231700, Accuracy: 17.29%\n",
            "Epoch: 30, Step: 89/655, Loss: 2.231246, Accuracy: 17.35%\n",
            "Epoch: 30, Step: 90/655, Loss: 2.231421, Accuracy: 17.33%\n",
            "Epoch: 30, Step: 91/655, Loss: 2.230015, Accuracy: 17.38%\n",
            "Epoch: 30, Step: 92/655, Loss: 2.230567, Accuracy: 17.22%\n",
            "Epoch: 30, Step: 93/655, Loss: 2.229867, Accuracy: 17.34%\n",
            "Epoch: 30, Step: 94/655, Loss: 2.228649, Accuracy: 17.39%\n",
            "Epoch: 30, Step: 95/655, Loss: 2.228453, Accuracy: 17.43%\n",
            "Epoch: 30, Step: 96/655, Loss: 2.228729, Accuracy: 17.45%\n",
            "Epoch: 30, Step: 97/655, Loss: 2.229718, Accuracy: 17.43%\n",
            "Epoch: 30, Step: 98/655, Loss: 2.230741, Accuracy: 17.32%\n",
            "Epoch: 30, Step: 99/655, Loss: 2.230931, Accuracy: 17.30%\n",
            "Epoch: 30, Step: 100/655, Loss: 2.230261, Accuracy: 17.31%\n",
            "Epoch: 30, Step: 101/655, Loss: 2.229780, Accuracy: 17.26%\n",
            "Epoch: 30, Step: 102/655, Loss: 2.229301, Accuracy: 17.25%\n",
            "Epoch: 30, Step: 103/655, Loss: 2.229054, Accuracy: 17.29%\n",
            "Epoch: 30, Step: 104/655, Loss: 2.229609, Accuracy: 17.16%\n",
            "Epoch: 30, Step: 105/655, Loss: 2.229095, Accuracy: 17.29%\n",
            "Epoch: 30, Step: 106/655, Loss: 2.228520, Accuracy: 17.36%\n",
            "Epoch: 30, Step: 107/655, Loss: 2.227912, Accuracy: 17.49%\n",
            "Epoch: 30, Step: 108/655, Loss: 2.228678, Accuracy: 17.39%\n",
            "Epoch: 30, Step: 109/655, Loss: 2.227950, Accuracy: 17.52%\n",
            "Epoch: 30, Step: 110/655, Loss: 2.227080, Accuracy: 17.56%\n",
            "Epoch: 30, Step: 111/655, Loss: 2.227002, Accuracy: 17.60%\n",
            "Epoch: 30, Step: 112/655, Loss: 2.227868, Accuracy: 17.47%\n",
            "Epoch: 30, Step: 113/655, Loss: 2.227487, Accuracy: 17.53%\n",
            "Epoch: 30, Step: 114/655, Loss: 2.227518, Accuracy: 17.49%\n",
            "Epoch: 30, Step: 115/655, Loss: 2.227463, Accuracy: 17.45%\n",
            "Epoch: 30, Step: 116/655, Loss: 2.227417, Accuracy: 17.40%\n",
            "Epoch: 30, Step: 117/655, Loss: 2.227651, Accuracy: 17.36%\n",
            "Epoch: 30, Step: 118/655, Loss: 2.227458, Accuracy: 17.37%\n",
            "Epoch: 30, Step: 119/655, Loss: 2.227677, Accuracy: 17.33%\n",
            "Epoch: 30, Step: 120/655, Loss: 2.226185, Accuracy: 17.37%\n",
            "Epoch: 30, Step: 121/655, Loss: 2.226107, Accuracy: 17.36%\n",
            "Epoch: 30, Step: 122/655, Loss: 2.224652, Accuracy: 17.39%\n",
            "Epoch: 30, Step: 123/655, Loss: 2.223753, Accuracy: 17.38%\n",
            "Epoch: 30, Step: 124/655, Loss: 2.223293, Accuracy: 17.41%\n",
            "Epoch: 30, Step: 125/655, Loss: 2.222040, Accuracy: 17.43%\n",
            "Epoch: 30, Step: 126/655, Loss: 2.221779, Accuracy: 17.44%\n",
            "Epoch: 30, Step: 127/655, Loss: 2.220881, Accuracy: 17.37%\n",
            "Epoch: 30, Step: 128/655, Loss: 2.220799, Accuracy: 17.41%\n",
            "Epoch: 30, Step: 129/655, Loss: 2.221667, Accuracy: 17.39%\n",
            "Epoch: 30, Step: 130/655, Loss: 2.222091, Accuracy: 17.33%\n",
            "Epoch: 30, Step: 131/655, Loss: 2.222738, Accuracy: 17.29%\n",
            "Epoch: 30, Step: 132/655, Loss: 2.223117, Accuracy: 17.31%\n",
            "Epoch: 30, Step: 133/655, Loss: 2.221980, Accuracy: 17.36%\n",
            "Epoch: 30, Step: 134/655, Loss: 2.222480, Accuracy: 17.35%\n",
            "Epoch: 30, Step: 135/655, Loss: 2.222687, Accuracy: 17.41%\n",
            "Epoch: 30, Step: 136/655, Loss: 2.222746, Accuracy: 17.44%\n",
            "Epoch: 30, Step: 137/655, Loss: 2.222723, Accuracy: 17.38%\n",
            "Epoch: 30, Step: 138/655, Loss: 2.221622, Accuracy: 17.37%\n",
            "Epoch: 30, Step: 139/655, Loss: 2.221137, Accuracy: 17.24%\n",
            "Epoch: 30, Step: 140/655, Loss: 2.220393, Accuracy: 17.28%\n",
            "Epoch: 30, Step: 141/655, Loss: 2.220571, Accuracy: 17.24%\n",
            "Epoch: 30, Step: 142/655, Loss: 2.221582, Accuracy: 17.17%\n",
            "Epoch: 30, Step: 143/655, Loss: 2.221465, Accuracy: 17.20%\n",
            "Epoch: 30, Step: 144/655, Loss: 2.221425, Accuracy: 17.23%\n",
            "Epoch: 30, Step: 145/655, Loss: 2.221591, Accuracy: 17.16%\n",
            "Epoch: 30, Step: 146/655, Loss: 2.221804, Accuracy: 17.14%\n",
            "Epoch: 30, Step: 147/655, Loss: 2.222187, Accuracy: 17.13%\n",
            "Epoch: 30, Step: 148/655, Loss: 2.222254, Accuracy: 17.19%\n",
            "Epoch: 30, Step: 149/655, Loss: 2.222230, Accuracy: 17.16%\n",
            "Epoch: 30, Step: 150/655, Loss: 2.222094, Accuracy: 17.19%\n",
            "Epoch: 30, Step: 151/655, Loss: 2.221770, Accuracy: 17.14%\n",
            "Epoch: 30, Step: 152/655, Loss: 2.221356, Accuracy: 17.13%\n",
            "Epoch: 30, Step: 153/655, Loss: 2.220568, Accuracy: 17.20%\n",
            "Epoch: 30, Step: 154/655, Loss: 2.220502, Accuracy: 17.27%\n",
            "Epoch: 30, Step: 155/655, Loss: 2.220730, Accuracy: 17.28%\n",
            "Epoch: 30, Step: 156/655, Loss: 2.220305, Accuracy: 17.27%\n",
            "Epoch: 30, Step: 157/655, Loss: 2.219826, Accuracy: 17.32%\n",
            "Epoch: 30, Step: 158/655, Loss: 2.219663, Accuracy: 17.35%\n",
            "Epoch: 30, Step: 159/655, Loss: 2.219609, Accuracy: 17.33%\n",
            "Epoch: 30, Step: 160/655, Loss: 2.219360, Accuracy: 17.32%\n",
            "Epoch: 30, Step: 161/655, Loss: 2.218831, Accuracy: 17.37%\n",
            "Epoch: 30, Step: 162/655, Loss: 2.218534, Accuracy: 17.48%\n",
            "Epoch: 30, Step: 163/655, Loss: 2.218190, Accuracy: 17.56%\n",
            "Epoch: 30, Step: 164/655, Loss: 2.218843, Accuracy: 17.53%\n",
            "Epoch: 30, Step: 165/655, Loss: 2.219558, Accuracy: 17.52%\n",
            "Epoch: 30, Step: 166/655, Loss: 2.219450, Accuracy: 17.49%\n",
            "Epoch: 30, Step: 167/655, Loss: 2.219043, Accuracy: 17.50%\n",
            "Epoch: 30, Step: 168/655, Loss: 2.219117, Accuracy: 17.49%\n",
            "Epoch: 30, Step: 169/655, Loss: 2.218393, Accuracy: 17.53%\n",
            "Epoch: 30, Step: 170/655, Loss: 2.218719, Accuracy: 17.48%\n",
            "Epoch: 30, Step: 171/655, Loss: 2.218313, Accuracy: 17.51%\n",
            "Epoch: 30, Step: 172/655, Loss: 2.218230, Accuracy: 17.48%\n",
            "Epoch: 30, Step: 173/655, Loss: 2.219203, Accuracy: 17.43%\n",
            "Epoch: 30, Step: 174/655, Loss: 2.218986, Accuracy: 17.44%\n",
            "Epoch: 30, Step: 175/655, Loss: 2.218544, Accuracy: 17.45%\n",
            "Epoch: 30, Step: 176/655, Loss: 2.218560, Accuracy: 17.47%\n",
            "Epoch: 30, Step: 177/655, Loss: 2.218595, Accuracy: 17.53%\n",
            "Epoch: 30, Step: 178/655, Loss: 2.218750, Accuracy: 17.49%\n",
            "Epoch: 30, Step: 179/655, Loss: 2.218515, Accuracy: 17.55%\n",
            "Epoch: 30, Step: 180/655, Loss: 2.218501, Accuracy: 17.55%\n",
            "Epoch: 30, Step: 181/655, Loss: 2.218268, Accuracy: 17.59%\n",
            "Epoch: 30, Step: 182/655, Loss: 2.218991, Accuracy: 17.55%\n",
            "Epoch: 30, Step: 183/655, Loss: 2.219768, Accuracy: 17.52%\n",
            "Epoch: 30, Step: 184/655, Loss: 2.219202, Accuracy: 17.58%\n",
            "Epoch: 30, Step: 185/655, Loss: 2.219184, Accuracy: 17.58%\n",
            "Epoch: 30, Step: 186/655, Loss: 2.219068, Accuracy: 17.59%\n",
            "Epoch: 30, Step: 187/655, Loss: 2.219089, Accuracy: 17.60%\n",
            "Epoch: 30, Step: 188/655, Loss: 2.218734, Accuracy: 17.60%\n",
            "Epoch: 30, Step: 189/655, Loss: 2.218489, Accuracy: 17.59%\n",
            "Epoch: 30, Step: 190/655, Loss: 2.218225, Accuracy: 17.53%\n",
            "Epoch: 30, Step: 191/655, Loss: 2.217964, Accuracy: 17.51%\n",
            "Epoch: 30, Step: 192/655, Loss: 2.218539, Accuracy: 17.46%\n",
            "Epoch: 30, Step: 193/655, Loss: 2.218826, Accuracy: 17.52%\n",
            "Epoch: 30, Step: 194/655, Loss: 2.218766, Accuracy: 17.48%\n",
            "Epoch: 30, Step: 195/655, Loss: 2.218102, Accuracy: 17.48%\n",
            "Epoch: 30, Step: 196/655, Loss: 2.218285, Accuracy: 17.51%\n",
            "Epoch: 30, Step: 197/655, Loss: 2.218709, Accuracy: 17.47%\n",
            "Epoch: 30, Step: 198/655, Loss: 2.219152, Accuracy: 17.44%\n",
            "Epoch: 30, Step: 199/655, Loss: 2.218702, Accuracy: 17.48%\n",
            "Epoch: 30, Step: 200/655, Loss: 2.218758, Accuracy: 17.48%\n",
            "Epoch: 30, Step: 201/655, Loss: 2.218841, Accuracy: 17.43%\n",
            "Epoch: 30, Step: 202/655, Loss: 2.218990, Accuracy: 17.44%\n",
            "Epoch: 30, Step: 203/655, Loss: 2.218739, Accuracy: 17.47%\n",
            "Epoch: 30, Step: 204/655, Loss: 2.219058, Accuracy: 17.45%\n",
            "Epoch: 30, Step: 205/655, Loss: 2.218889, Accuracy: 17.45%\n",
            "Epoch: 30, Step: 206/655, Loss: 2.219046, Accuracy: 17.48%\n",
            "Epoch: 30, Step: 207/655, Loss: 2.219104, Accuracy: 17.45%\n",
            "Epoch: 30, Step: 208/655, Loss: 2.218860, Accuracy: 17.50%\n",
            "Epoch: 30, Step: 209/655, Loss: 2.218645, Accuracy: 17.49%\n",
            "Epoch: 30, Step: 210/655, Loss: 2.218843, Accuracy: 17.49%\n",
            "Epoch: 30, Step: 211/655, Loss: 2.219464, Accuracy: 17.45%\n",
            "Epoch: 30, Step: 212/655, Loss: 2.218984, Accuracy: 17.47%\n",
            "Epoch: 30, Step: 213/655, Loss: 2.218832, Accuracy: 17.52%\n",
            "Epoch: 30, Step: 214/655, Loss: 2.218718, Accuracy: 17.49%\n",
            "Epoch: 30, Step: 215/655, Loss: 2.219085, Accuracy: 17.49%\n",
            "Epoch: 30, Step: 216/655, Loss: 2.219233, Accuracy: 17.49%\n",
            "Epoch: 30, Step: 217/655, Loss: 2.219866, Accuracy: 17.45%\n",
            "Epoch: 30, Step: 218/655, Loss: 2.219955, Accuracy: 17.47%\n",
            "Epoch: 30, Step: 219/655, Loss: 2.220059, Accuracy: 17.48%\n",
            "Epoch: 30, Step: 220/655, Loss: 2.219533, Accuracy: 17.53%\n",
            "Epoch: 30, Step: 221/655, Loss: 2.219541, Accuracy: 17.55%\n",
            "Epoch: 30, Step: 222/655, Loss: 2.219787, Accuracy: 17.55%\n",
            "Epoch: 30, Step: 223/655, Loss: 2.220138, Accuracy: 17.54%\n",
            "Epoch: 30, Step: 224/655, Loss: 2.219759, Accuracy: 17.59%\n",
            "Epoch: 30, Step: 225/655, Loss: 2.220213, Accuracy: 17.57%\n",
            "Epoch: 30, Step: 226/655, Loss: 2.220476, Accuracy: 17.55%\n",
            "Epoch: 30, Step: 227/655, Loss: 2.220244, Accuracy: 17.59%\n",
            "Epoch: 30, Step: 228/655, Loss: 2.219825, Accuracy: 17.57%\n",
            "Epoch: 30, Step: 229/655, Loss: 2.219020, Accuracy: 17.66%\n",
            "Epoch: 30, Step: 230/655, Loss: 2.219057, Accuracy: 17.65%\n",
            "Epoch: 30, Step: 231/655, Loss: 2.219177, Accuracy: 17.65%\n",
            "Epoch: 30, Step: 232/655, Loss: 2.219086, Accuracy: 17.66%\n",
            "Epoch: 30, Step: 233/655, Loss: 2.218545, Accuracy: 17.69%\n",
            "Epoch: 30, Step: 234/655, Loss: 2.218498, Accuracy: 17.69%\n",
            "Epoch: 30, Step: 235/655, Loss: 2.217939, Accuracy: 17.73%\n",
            "Epoch: 30, Step: 236/655, Loss: 2.217350, Accuracy: 17.76%\n",
            "Epoch: 30, Step: 237/655, Loss: 2.216938, Accuracy: 17.75%\n",
            "Epoch: 30, Step: 238/655, Loss: 2.217114, Accuracy: 17.71%\n",
            "Epoch: 30, Step: 239/655, Loss: 2.216991, Accuracy: 17.72%\n",
            "Epoch: 30, Step: 240/655, Loss: 2.217037, Accuracy: 17.67%\n",
            "Epoch: 30, Step: 241/655, Loss: 2.216793, Accuracy: 17.66%\n",
            "Epoch: 30, Step: 242/655, Loss: 2.216975, Accuracy: 17.65%\n",
            "Epoch: 30, Step: 243/655, Loss: 2.217399, Accuracy: 17.64%\n",
            "Epoch: 30, Step: 244/655, Loss: 2.217451, Accuracy: 17.66%\n",
            "Epoch: 30, Step: 245/655, Loss: 2.216936, Accuracy: 17.68%\n",
            "Epoch: 30, Step: 246/655, Loss: 2.217114, Accuracy: 17.68%\n",
            "Epoch: 30, Step: 247/655, Loss: 2.217328, Accuracy: 17.70%\n",
            "Epoch: 30, Step: 248/655, Loss: 2.217267, Accuracy: 17.73%\n",
            "Epoch: 30, Step: 249/655, Loss: 2.217191, Accuracy: 17.71%\n",
            "Epoch: 30, Step: 250/655, Loss: 2.217642, Accuracy: 17.69%\n",
            "Epoch: 30, Step: 251/655, Loss: 2.218277, Accuracy: 17.65%\n",
            "Epoch: 30, Step: 252/655, Loss: 2.218583, Accuracy: 17.63%\n",
            "Epoch: 30, Step: 253/655, Loss: 2.218497, Accuracy: 17.63%\n",
            "Epoch: 30, Step: 254/655, Loss: 2.218486, Accuracy: 17.62%\n",
            "Epoch: 30, Step: 255/655, Loss: 2.218393, Accuracy: 17.62%\n",
            "Epoch: 30, Step: 256/655, Loss: 2.218865, Accuracy: 17.61%\n",
            "Epoch: 30, Step: 257/655, Loss: 2.218903, Accuracy: 17.62%\n",
            "Epoch: 30, Step: 258/655, Loss: 2.218493, Accuracy: 17.60%\n",
            "Epoch: 30, Step: 259/655, Loss: 2.218407, Accuracy: 17.59%\n",
            "Epoch: 30, Step: 260/655, Loss: 2.218348, Accuracy: 17.60%\n",
            "Epoch: 30, Step: 261/655, Loss: 2.218537, Accuracy: 17.60%\n",
            "Epoch: 30, Step: 262/655, Loss: 2.218390, Accuracy: 17.59%\n",
            "Epoch: 30, Step: 263/655, Loss: 2.218248, Accuracy: 17.62%\n",
            "Epoch: 30, Step: 264/655, Loss: 2.218054, Accuracy: 17.61%\n",
            "Epoch: 30, Step: 265/655, Loss: 2.217684, Accuracy: 17.64%\n",
            "Epoch: 30, Step: 266/655, Loss: 2.217474, Accuracy: 17.63%\n",
            "Epoch: 30, Step: 267/655, Loss: 2.217754, Accuracy: 17.60%\n",
            "Epoch: 30, Step: 268/655, Loss: 2.217896, Accuracy: 17.58%\n",
            "Epoch: 30, Step: 269/655, Loss: 2.217467, Accuracy: 17.66%\n",
            "Epoch: 30, Step: 270/655, Loss: 2.217717, Accuracy: 17.66%\n",
            "Epoch: 30, Step: 271/655, Loss: 2.217586, Accuracy: 17.65%\n",
            "Epoch: 30, Step: 272/655, Loss: 2.217729, Accuracy: 17.65%\n",
            "Epoch: 30, Step: 273/655, Loss: 2.217788, Accuracy: 17.62%\n",
            "Epoch: 30, Step: 274/655, Loss: 2.218004, Accuracy: 17.60%\n",
            "Epoch: 30, Step: 275/655, Loss: 2.217509, Accuracy: 17.60%\n",
            "Epoch: 30, Step: 276/655, Loss: 2.217183, Accuracy: 17.62%\n",
            "Epoch: 30, Step: 277/655, Loss: 2.217084, Accuracy: 17.62%\n",
            "Epoch: 30, Step: 278/655, Loss: 2.217209, Accuracy: 17.63%\n",
            "Epoch: 30, Step: 279/655, Loss: 2.216985, Accuracy: 17.64%\n",
            "Epoch: 30, Step: 280/655, Loss: 2.216639, Accuracy: 17.69%\n",
            "Epoch: 30, Step: 281/655, Loss: 2.216734, Accuracy: 17.68%\n",
            "Epoch: 30, Step: 282/655, Loss: 2.216056, Accuracy: 17.74%\n",
            "Epoch: 30, Step: 283/655, Loss: 2.216160, Accuracy: 17.71%\n",
            "Epoch: 30, Step: 284/655, Loss: 2.215897, Accuracy: 17.74%\n",
            "Epoch: 30, Step: 285/655, Loss: 2.216116, Accuracy: 17.71%\n",
            "Epoch: 30, Step: 286/655, Loss: 2.216035, Accuracy: 17.68%\n",
            "Epoch: 30, Step: 287/655, Loss: 2.215699, Accuracy: 17.67%\n",
            "Epoch: 30, Step: 288/655, Loss: 2.215694, Accuracy: 17.65%\n",
            "Epoch: 30, Step: 289/655, Loss: 2.215316, Accuracy: 17.66%\n",
            "Epoch: 30, Step: 290/655, Loss: 2.215514, Accuracy: 17.67%\n",
            "Epoch: 30, Step: 291/655, Loss: 2.215029, Accuracy: 17.69%\n",
            "Epoch: 30, Step: 292/655, Loss: 2.215095, Accuracy: 17.68%\n",
            "Epoch: 30, Step: 293/655, Loss: 2.214573, Accuracy: 17.67%\n",
            "Epoch: 30, Step: 294/655, Loss: 2.214082, Accuracy: 17.73%\n",
            "Epoch: 30, Step: 295/655, Loss: 2.214295, Accuracy: 17.73%\n",
            "Epoch: 30, Step: 296/655, Loss: 2.214071, Accuracy: 17.74%\n",
            "Epoch: 30, Step: 297/655, Loss: 2.214056, Accuracy: 17.75%\n",
            "Epoch: 30, Step: 298/655, Loss: 2.213847, Accuracy: 17.76%\n",
            "Epoch: 30, Step: 299/655, Loss: 2.213804, Accuracy: 17.77%\n",
            "Epoch: 30, Step: 300/655, Loss: 2.213262, Accuracy: 17.80%\n",
            "Epoch: 30, Step: 301/655, Loss: 2.213112, Accuracy: 17.78%\n",
            "Epoch: 30, Step: 302/655, Loss: 2.213156, Accuracy: 17.82%\n",
            "Epoch: 30, Step: 303/655, Loss: 2.212969, Accuracy: 17.84%\n",
            "Epoch: 30, Step: 304/655, Loss: 2.212999, Accuracy: 17.88%\n",
            "Epoch: 30, Step: 305/655, Loss: 2.212969, Accuracy: 17.88%\n",
            "Epoch: 30, Step: 306/655, Loss: 2.213074, Accuracy: 17.88%\n",
            "Epoch: 30, Step: 307/655, Loss: 2.212343, Accuracy: 17.95%\n",
            "Epoch: 30, Step: 308/655, Loss: 2.212471, Accuracy: 17.95%\n",
            "Epoch: 30, Step: 309/655, Loss: 2.212564, Accuracy: 17.92%\n",
            "Epoch: 30, Step: 310/655, Loss: 2.212873, Accuracy: 17.92%\n",
            "Epoch: 30, Step: 311/655, Loss: 2.213046, Accuracy: 17.91%\n",
            "Epoch: 30, Step: 312/655, Loss: 2.212880, Accuracy: 17.93%\n",
            "Epoch: 30, Step: 313/655, Loss: 2.213127, Accuracy: 17.93%\n",
            "Epoch: 30, Step: 314/655, Loss: 2.213409, Accuracy: 17.91%\n",
            "Epoch: 30, Step: 315/655, Loss: 2.213390, Accuracy: 17.91%\n",
            "Epoch: 30, Step: 316/655, Loss: 2.213628, Accuracy: 17.92%\n",
            "Epoch: 30, Step: 317/655, Loss: 2.213373, Accuracy: 17.92%\n",
            "Epoch: 30, Step: 318/655, Loss: 2.213394, Accuracy: 17.93%\n",
            "Epoch: 30, Step: 319/655, Loss: 2.213193, Accuracy: 17.95%\n",
            "Epoch: 30, Step: 320/655, Loss: 2.213383, Accuracy: 17.95%\n",
            "Epoch: 30, Step: 321/655, Loss: 2.213965, Accuracy: 17.92%\n",
            "Epoch: 30, Step: 322/655, Loss: 2.213738, Accuracy: 17.93%\n",
            "Epoch: 30, Step: 323/655, Loss: 2.213631, Accuracy: 17.95%\n",
            "Epoch: 30, Step: 324/655, Loss: 2.213233, Accuracy: 17.95%\n",
            "Epoch: 30, Step: 325/655, Loss: 2.213192, Accuracy: 17.97%\n",
            "Epoch: 30, Step: 326/655, Loss: 2.213216, Accuracy: 17.95%\n",
            "Epoch: 30, Step: 327/655, Loss: 2.213358, Accuracy: 17.95%\n",
            "Epoch: 30, Step: 328/655, Loss: 2.213215, Accuracy: 17.97%\n",
            "Epoch: 30, Step: 329/655, Loss: 2.213297, Accuracy: 17.95%\n",
            "Epoch: 30, Step: 330/655, Loss: 2.213556, Accuracy: 17.95%\n",
            "Epoch: 30, Step: 331/655, Loss: 2.214110, Accuracy: 17.93%\n",
            "Epoch: 30, Step: 332/655, Loss: 2.213933, Accuracy: 17.93%\n",
            "Epoch: 30, Step: 333/655, Loss: 2.213957, Accuracy: 17.94%\n",
            "Epoch: 30, Step: 334/655, Loss: 2.213724, Accuracy: 17.98%\n",
            "Epoch: 30, Step: 335/655, Loss: 2.213820, Accuracy: 17.98%\n",
            "Epoch: 30, Step: 336/655, Loss: 2.213701, Accuracy: 17.96%\n",
            "Epoch: 30, Step: 337/655, Loss: 2.213933, Accuracy: 17.94%\n",
            "Epoch: 30, Step: 338/655, Loss: 2.214118, Accuracy: 17.94%\n",
            "Epoch: 30, Step: 339/655, Loss: 2.214328, Accuracy: 17.93%\n",
            "Epoch: 30, Step: 340/655, Loss: 2.214324, Accuracy: 17.97%\n",
            "Epoch: 30, Step: 341/655, Loss: 2.214533, Accuracy: 17.96%\n",
            "Epoch: 30, Step: 342/655, Loss: 2.214091, Accuracy: 18.00%\n",
            "Epoch: 30, Step: 343/655, Loss: 2.214177, Accuracy: 18.03%\n",
            "Epoch: 30, Step: 344/655, Loss: 2.214487, Accuracy: 18.02%\n",
            "Epoch: 30, Step: 345/655, Loss: 2.214046, Accuracy: 18.01%\n",
            "Epoch: 30, Step: 346/655, Loss: 2.214259, Accuracy: 18.02%\n",
            "Epoch: 30, Step: 347/655, Loss: 2.214383, Accuracy: 18.00%\n",
            "Epoch: 30, Step: 348/655, Loss: 2.213966, Accuracy: 18.07%\n",
            "Epoch: 30, Step: 349/655, Loss: 2.214069, Accuracy: 18.09%\n",
            "Epoch: 30, Step: 350/655, Loss: 2.214233, Accuracy: 18.10%\n",
            "Epoch: 30, Step: 351/655, Loss: 2.214472, Accuracy: 18.08%\n",
            "Epoch: 30, Step: 352/655, Loss: 2.214540, Accuracy: 18.08%\n",
            "Epoch: 30, Step: 353/655, Loss: 2.214658, Accuracy: 18.09%\n",
            "Epoch: 30, Step: 354/655, Loss: 2.214473, Accuracy: 18.09%\n",
            "Epoch: 30, Step: 355/655, Loss: 2.214453, Accuracy: 18.11%\n",
            "Epoch: 30, Step: 356/655, Loss: 2.214506, Accuracy: 18.10%\n",
            "Epoch: 30, Step: 357/655, Loss: 2.214431, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 358/655, Loss: 2.214154, Accuracy: 18.17%\n",
            "Epoch: 30, Step: 359/655, Loss: 2.214172, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 360/655, Loss: 2.213852, Accuracy: 18.16%\n",
            "Epoch: 30, Step: 361/655, Loss: 2.213853, Accuracy: 18.17%\n",
            "Epoch: 30, Step: 362/655, Loss: 2.213975, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 363/655, Loss: 2.213826, Accuracy: 18.16%\n",
            "Epoch: 30, Step: 364/655, Loss: 2.213819, Accuracy: 18.17%\n",
            "Epoch: 30, Step: 365/655, Loss: 2.213740, Accuracy: 18.18%\n",
            "Epoch: 30, Step: 366/655, Loss: 2.213760, Accuracy: 18.14%\n",
            "Epoch: 30, Step: 367/655, Loss: 2.213600, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 368/655, Loss: 2.213414, Accuracy: 18.16%\n",
            "Epoch: 30, Step: 369/655, Loss: 2.213252, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 370/655, Loss: 2.213475, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 371/655, Loss: 2.213702, Accuracy: 18.14%\n",
            "Epoch: 30, Step: 372/655, Loss: 2.213611, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 373/655, Loss: 2.213594, Accuracy: 18.16%\n",
            "Epoch: 30, Step: 374/655, Loss: 2.213829, Accuracy: 18.14%\n",
            "Epoch: 30, Step: 375/655, Loss: 2.213648, Accuracy: 18.16%\n",
            "Epoch: 30, Step: 376/655, Loss: 2.213654, Accuracy: 18.18%\n",
            "Epoch: 30, Step: 377/655, Loss: 2.213465, Accuracy: 18.18%\n",
            "Epoch: 30, Step: 378/655, Loss: 2.213837, Accuracy: 18.16%\n",
            "Epoch: 30, Step: 379/655, Loss: 2.213720, Accuracy: 18.17%\n",
            "Epoch: 30, Step: 380/655, Loss: 2.213675, Accuracy: 18.17%\n",
            "Epoch: 30, Step: 381/655, Loss: 2.213570, Accuracy: 18.18%\n",
            "Epoch: 30, Step: 382/655, Loss: 2.213400, Accuracy: 18.19%\n",
            "Epoch: 30, Step: 383/655, Loss: 2.213405, Accuracy: 18.17%\n",
            "Epoch: 30, Step: 384/655, Loss: 2.213576, Accuracy: 18.16%\n",
            "Epoch: 30, Step: 385/655, Loss: 2.213324, Accuracy: 18.17%\n",
            "Epoch: 30, Step: 386/655, Loss: 2.213494, Accuracy: 18.18%\n",
            "Epoch: 30, Step: 387/655, Loss: 2.213589, Accuracy: 18.18%\n",
            "Epoch: 30, Step: 388/655, Loss: 2.213676, Accuracy: 18.17%\n",
            "Epoch: 30, Step: 389/655, Loss: 2.213790, Accuracy: 18.14%\n",
            "Epoch: 30, Step: 390/655, Loss: 2.213674, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 391/655, Loss: 2.213431, Accuracy: 18.17%\n",
            "Epoch: 30, Step: 392/655, Loss: 2.213536, Accuracy: 18.18%\n",
            "Epoch: 30, Step: 393/655, Loss: 2.213227, Accuracy: 18.19%\n",
            "Epoch: 30, Step: 394/655, Loss: 2.213106, Accuracy: 18.20%\n",
            "Epoch: 30, Step: 395/655, Loss: 2.212918, Accuracy: 18.20%\n",
            "Epoch: 30, Step: 396/655, Loss: 2.212829, Accuracy: 18.18%\n",
            "Epoch: 30, Step: 397/655, Loss: 2.212560, Accuracy: 18.18%\n",
            "Epoch: 30, Step: 398/655, Loss: 2.212726, Accuracy: 18.18%\n",
            "Epoch: 30, Step: 399/655, Loss: 2.212797, Accuracy: 18.17%\n",
            "Epoch: 30, Step: 400/655, Loss: 2.212545, Accuracy: 18.19%\n",
            "Epoch: 30, Step: 401/655, Loss: 2.212639, Accuracy: 18.19%\n",
            "Epoch: 30, Step: 402/655, Loss: 2.212712, Accuracy: 18.19%\n",
            "Epoch: 30, Step: 403/655, Loss: 2.212738, Accuracy: 18.18%\n",
            "Epoch: 30, Step: 404/655, Loss: 2.212651, Accuracy: 18.17%\n",
            "Epoch: 30, Step: 405/655, Loss: 2.212715, Accuracy: 18.13%\n",
            "Epoch: 30, Step: 406/655, Loss: 2.212509, Accuracy: 18.14%\n",
            "Epoch: 30, Step: 407/655, Loss: 2.212723, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 408/655, Loss: 2.212892, Accuracy: 18.14%\n",
            "Epoch: 30, Step: 409/655, Loss: 2.212971, Accuracy: 18.11%\n",
            "Epoch: 30, Step: 410/655, Loss: 2.212626, Accuracy: 18.13%\n",
            "Epoch: 30, Step: 411/655, Loss: 2.212598, Accuracy: 18.14%\n",
            "Epoch: 30, Step: 412/655, Loss: 2.212597, Accuracy: 18.14%\n",
            "Epoch: 30, Step: 413/655, Loss: 2.212870, Accuracy: 18.14%\n",
            "Epoch: 30, Step: 414/655, Loss: 2.212759, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 415/655, Loss: 2.212519, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 416/655, Loss: 2.212395, Accuracy: 18.16%\n",
            "Epoch: 30, Step: 417/655, Loss: 2.212253, Accuracy: 18.17%\n",
            "Epoch: 30, Step: 418/655, Loss: 2.212333, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 419/655, Loss: 2.212515, Accuracy: 18.13%\n",
            "Epoch: 30, Step: 420/655, Loss: 2.212158, Accuracy: 18.14%\n",
            "Epoch: 30, Step: 421/655, Loss: 2.211906, Accuracy: 18.13%\n",
            "Epoch: 30, Step: 422/655, Loss: 2.211689, Accuracy: 18.14%\n",
            "Epoch: 30, Step: 423/655, Loss: 2.211700, Accuracy: 18.16%\n",
            "Epoch: 30, Step: 424/655, Loss: 2.211909, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 425/655, Loss: 2.211692, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 426/655, Loss: 2.211737, Accuracy: 18.13%\n",
            "Epoch: 30, Step: 427/655, Loss: 2.211866, Accuracy: 18.12%\n",
            "Epoch: 30, Step: 428/655, Loss: 2.211569, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 429/655, Loss: 2.211408, Accuracy: 18.16%\n",
            "Epoch: 30, Step: 430/655, Loss: 2.211224, Accuracy: 18.18%\n",
            "Epoch: 30, Step: 431/655, Loss: 2.211062, Accuracy: 18.18%\n",
            "Epoch: 30, Step: 432/655, Loss: 2.211035, Accuracy: 18.16%\n",
            "Epoch: 30, Step: 433/655, Loss: 2.211035, Accuracy: 18.16%\n",
            "Epoch: 30, Step: 434/655, Loss: 2.210915, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 435/655, Loss: 2.210749, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 436/655, Loss: 2.210791, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 437/655, Loss: 2.210878, Accuracy: 18.16%\n",
            "Epoch: 30, Step: 438/655, Loss: 2.211218, Accuracy: 18.14%\n",
            "Epoch: 30, Step: 439/655, Loss: 2.211382, Accuracy: 18.14%\n",
            "Epoch: 30, Step: 440/655, Loss: 2.211699, Accuracy: 18.12%\n",
            "Epoch: 30, Step: 441/655, Loss: 2.211988, Accuracy: 18.11%\n",
            "Epoch: 30, Step: 442/655, Loss: 2.211994, Accuracy: 18.15%\n",
            "Epoch: 30, Step: 443/655, Loss: 2.211925, Accuracy: 18.14%\n",
            "Epoch: 30, Step: 444/655, Loss: 2.211938, Accuracy: 18.17%\n",
            "Epoch: 30, Step: 445/655, Loss: 2.211800, Accuracy: 18.17%\n",
            "Epoch: 30, Step: 446/655, Loss: 2.211684, Accuracy: 18.19%\n",
            "Epoch: 30, Step: 447/655, Loss: 2.211593, Accuracy: 18.20%\n",
            "Epoch: 30, Step: 448/655, Loss: 2.211534, Accuracy: 18.21%\n",
            "Epoch: 30, Step: 449/655, Loss: 2.211558, Accuracy: 18.23%\n",
            "Epoch: 30, Step: 450/655, Loss: 2.211504, Accuracy: 18.26%\n",
            "Epoch: 30, Step: 451/655, Loss: 2.211221, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 452/655, Loss: 2.210865, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 453/655, Loss: 2.210770, Accuracy: 18.31%\n",
            "Epoch: 30, Step: 454/655, Loss: 2.210727, Accuracy: 18.31%\n",
            "Epoch: 30, Step: 455/655, Loss: 2.211005, Accuracy: 18.28%\n",
            "Epoch: 30, Step: 456/655, Loss: 2.210911, Accuracy: 18.27%\n",
            "Epoch: 30, Step: 457/655, Loss: 2.210960, Accuracy: 18.25%\n",
            "Epoch: 30, Step: 458/655, Loss: 2.210598, Accuracy: 18.28%\n",
            "Epoch: 30, Step: 459/655, Loss: 2.210533, Accuracy: 18.26%\n",
            "Epoch: 30, Step: 460/655, Loss: 2.210575, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 461/655, Loss: 2.210611, Accuracy: 18.28%\n",
            "Epoch: 30, Step: 462/655, Loss: 2.210404, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 463/655, Loss: 2.210415, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 464/655, Loss: 2.210434, Accuracy: 18.28%\n",
            "Epoch: 30, Step: 465/655, Loss: 2.210254, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 466/655, Loss: 2.210403, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 467/655, Loss: 2.210278, Accuracy: 18.31%\n",
            "Epoch: 30, Step: 468/655, Loss: 2.210420, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 469/655, Loss: 2.210004, Accuracy: 18.32%\n",
            "Epoch: 30, Step: 470/655, Loss: 2.210093, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 471/655, Loss: 2.209889, Accuracy: 18.32%\n",
            "Epoch: 30, Step: 472/655, Loss: 2.209788, Accuracy: 18.32%\n",
            "Epoch: 30, Step: 473/655, Loss: 2.209925, Accuracy: 18.31%\n",
            "Epoch: 30, Step: 474/655, Loss: 2.209790, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 475/655, Loss: 2.209786, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 476/655, Loss: 2.210143, Accuracy: 18.31%\n",
            "Epoch: 30, Step: 477/655, Loss: 2.210006, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 478/655, Loss: 2.210110, Accuracy: 18.31%\n",
            "Epoch: 30, Step: 479/655, Loss: 2.210097, Accuracy: 18.32%\n",
            "Epoch: 30, Step: 480/655, Loss: 2.210121, Accuracy: 18.31%\n",
            "Epoch: 30, Step: 481/655, Loss: 2.210126, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 482/655, Loss: 2.210146, Accuracy: 18.28%\n",
            "Epoch: 30, Step: 483/655, Loss: 2.210245, Accuracy: 18.27%\n",
            "Epoch: 30, Step: 484/655, Loss: 2.209949, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 485/655, Loss: 2.209828, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 486/655, Loss: 2.209961, Accuracy: 18.31%\n",
            "Epoch: 30, Step: 487/655, Loss: 2.209861, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 488/655, Loss: 2.209656, Accuracy: 18.31%\n",
            "Epoch: 30, Step: 489/655, Loss: 2.209516, Accuracy: 18.31%\n",
            "Epoch: 30, Step: 490/655, Loss: 2.209467, Accuracy: 18.34%\n",
            "Epoch: 30, Step: 491/655, Loss: 2.209588, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 492/655, Loss: 2.209416, Accuracy: 18.35%\n",
            "Epoch: 30, Step: 493/655, Loss: 2.209132, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 494/655, Loss: 2.209126, Accuracy: 18.35%\n",
            "Epoch: 30, Step: 495/655, Loss: 2.209304, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 496/655, Loss: 2.209538, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 497/655, Loss: 2.209849, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 498/655, Loss: 2.209957, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 499/655, Loss: 2.209836, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 500/655, Loss: 2.209938, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 501/655, Loss: 2.209644, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 502/655, Loss: 2.209693, Accuracy: 18.28%\n",
            "Epoch: 30, Step: 503/655, Loss: 2.210009, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 504/655, Loss: 2.209896, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 505/655, Loss: 2.209828, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 506/655, Loss: 2.209851, Accuracy: 18.27%\n",
            "Epoch: 30, Step: 507/655, Loss: 2.209793, Accuracy: 18.27%\n",
            "Epoch: 30, Step: 508/655, Loss: 2.209795, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 509/655, Loss: 2.209826, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 510/655, Loss: 2.209891, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 511/655, Loss: 2.209682, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 512/655, Loss: 2.209652, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 513/655, Loss: 2.209702, Accuracy: 18.31%\n",
            "Epoch: 30, Step: 514/655, Loss: 2.209821, Accuracy: 18.31%\n",
            "Epoch: 30, Step: 515/655, Loss: 2.210032, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 516/655, Loss: 2.209997, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 517/655, Loss: 2.209989, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 518/655, Loss: 2.209873, Accuracy: 18.32%\n",
            "Epoch: 30, Step: 519/655, Loss: 2.210048, Accuracy: 18.31%\n",
            "Epoch: 30, Step: 520/655, Loss: 2.210150, Accuracy: 18.31%\n",
            "Epoch: 30, Step: 521/655, Loss: 2.210488, Accuracy: 18.28%\n",
            "Epoch: 30, Step: 522/655, Loss: 2.210471, Accuracy: 18.28%\n",
            "Epoch: 30, Step: 523/655, Loss: 2.210368, Accuracy: 18.27%\n",
            "Epoch: 30, Step: 524/655, Loss: 2.210445, Accuracy: 18.24%\n",
            "Epoch: 30, Step: 525/655, Loss: 2.210171, Accuracy: 18.27%\n",
            "Epoch: 30, Step: 526/655, Loss: 2.209771, Accuracy: 18.25%\n",
            "Epoch: 30, Step: 527/655, Loss: 2.209799, Accuracy: 18.24%\n",
            "Epoch: 30, Step: 528/655, Loss: 2.209965, Accuracy: 18.24%\n",
            "Epoch: 30, Step: 529/655, Loss: 2.209784, Accuracy: 18.24%\n",
            "Epoch: 30, Step: 530/655, Loss: 2.209883, Accuracy: 18.24%\n",
            "Epoch: 30, Step: 531/655, Loss: 2.209869, Accuracy: 18.23%\n",
            "Epoch: 30, Step: 532/655, Loss: 2.209942, Accuracy: 18.22%\n",
            "Epoch: 30, Step: 533/655, Loss: 2.209766, Accuracy: 18.23%\n",
            "Epoch: 30, Step: 534/655, Loss: 2.209760, Accuracy: 18.22%\n",
            "Epoch: 30, Step: 535/655, Loss: 2.209401, Accuracy: 18.27%\n",
            "Epoch: 30, Step: 536/655, Loss: 2.209313, Accuracy: 18.27%\n",
            "Epoch: 30, Step: 537/655, Loss: 2.209367, Accuracy: 18.26%\n",
            "Epoch: 30, Step: 538/655, Loss: 2.209440, Accuracy: 18.26%\n",
            "Epoch: 30, Step: 539/655, Loss: 2.209354, Accuracy: 18.26%\n",
            "Epoch: 30, Step: 540/655, Loss: 2.209514, Accuracy: 18.26%\n",
            "Epoch: 30, Step: 541/655, Loss: 2.209639, Accuracy: 18.27%\n",
            "Epoch: 30, Step: 542/655, Loss: 2.209659, Accuracy: 18.27%\n",
            "Epoch: 30, Step: 543/655, Loss: 2.209857, Accuracy: 18.25%\n",
            "Epoch: 30, Step: 544/655, Loss: 2.209624, Accuracy: 18.26%\n",
            "Epoch: 30, Step: 545/655, Loss: 2.209615, Accuracy: 18.27%\n",
            "Epoch: 30, Step: 546/655, Loss: 2.209728, Accuracy: 18.27%\n",
            "Epoch: 30, Step: 547/655, Loss: 2.209795, Accuracy: 18.29%\n",
            "Epoch: 30, Step: 548/655, Loss: 2.209547, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 549/655, Loss: 2.209759, Accuracy: 18.28%\n",
            "Epoch: 30, Step: 550/655, Loss: 2.209931, Accuracy: 18.28%\n",
            "Epoch: 30, Step: 551/655, Loss: 2.210196, Accuracy: 18.28%\n",
            "Epoch: 30, Step: 552/655, Loss: 2.210162, Accuracy: 18.30%\n",
            "Epoch: 30, Step: 553/655, Loss: 2.210170, Accuracy: 18.31%\n",
            "Epoch: 30, Step: 554/655, Loss: 2.209955, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 555/655, Loss: 2.209769, Accuracy: 18.32%\n",
            "Epoch: 30, Step: 556/655, Loss: 2.209463, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 557/655, Loss: 2.209332, Accuracy: 18.35%\n",
            "Epoch: 30, Step: 558/655, Loss: 2.209590, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 559/655, Loss: 2.209725, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 560/655, Loss: 2.209724, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 561/655, Loss: 2.209814, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 562/655, Loss: 2.209537, Accuracy: 18.32%\n",
            "Epoch: 30, Step: 563/655, Loss: 2.209494, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 564/655, Loss: 2.209438, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 565/655, Loss: 2.209535, Accuracy: 18.32%\n",
            "Epoch: 30, Step: 566/655, Loss: 2.209239, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 567/655, Loss: 2.209114, Accuracy: 18.34%\n",
            "Epoch: 30, Step: 568/655, Loss: 2.209026, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 569/655, Loss: 2.209158, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 570/655, Loss: 2.208947, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 571/655, Loss: 2.208843, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 572/655, Loss: 2.208894, Accuracy: 18.35%\n",
            "Epoch: 30, Step: 573/655, Loss: 2.208845, Accuracy: 18.34%\n",
            "Epoch: 30, Step: 574/655, Loss: 2.208950, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 575/655, Loss: 2.208860, Accuracy: 18.34%\n",
            "Epoch: 30, Step: 576/655, Loss: 2.208984, Accuracy: 18.34%\n",
            "Epoch: 30, Step: 577/655, Loss: 2.209031, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 578/655, Loss: 2.209005, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 579/655, Loss: 2.209045, Accuracy: 18.34%\n",
            "Epoch: 30, Step: 580/655, Loss: 2.208936, Accuracy: 18.34%\n",
            "Epoch: 30, Step: 581/655, Loss: 2.208726, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 582/655, Loss: 2.208653, Accuracy: 18.35%\n",
            "Epoch: 30, Step: 583/655, Loss: 2.208912, Accuracy: 18.34%\n",
            "Epoch: 30, Step: 584/655, Loss: 2.209037, Accuracy: 18.34%\n",
            "Epoch: 30, Step: 585/655, Loss: 2.209052, Accuracy: 18.34%\n",
            "Epoch: 30, Step: 586/655, Loss: 2.209025, Accuracy: 18.34%\n",
            "Epoch: 30, Step: 587/655, Loss: 2.209062, Accuracy: 18.35%\n",
            "Epoch: 30, Step: 588/655, Loss: 2.208864, Accuracy: 18.35%\n",
            "Epoch: 30, Step: 589/655, Loss: 2.208773, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 590/655, Loss: 2.208811, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 591/655, Loss: 2.208733, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 592/655, Loss: 2.208691, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 593/655, Loss: 2.208695, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 594/655, Loss: 2.208504, Accuracy: 18.38%\n",
            "Epoch: 30, Step: 595/655, Loss: 2.208396, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 596/655, Loss: 2.208345, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 597/655, Loss: 2.208203, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 598/655, Loss: 2.208254, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 599/655, Loss: 2.208250, Accuracy: 18.35%\n",
            "Epoch: 30, Step: 600/655, Loss: 2.208372, Accuracy: 18.35%\n",
            "Epoch: 30, Step: 601/655, Loss: 2.208383, Accuracy: 18.35%\n",
            "Epoch: 30, Step: 602/655, Loss: 2.208469, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 603/655, Loss: 2.208393, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 604/655, Loss: 2.208276, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 605/655, Loss: 2.208210, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 606/655, Loss: 2.208405, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 607/655, Loss: 2.208359, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 608/655, Loss: 2.208242, Accuracy: 18.39%\n",
            "Epoch: 30, Step: 609/655, Loss: 2.208141, Accuracy: 18.40%\n",
            "Epoch: 30, Step: 610/655, Loss: 2.208089, Accuracy: 18.39%\n",
            "Epoch: 30, Step: 611/655, Loss: 2.208124, Accuracy: 18.39%\n",
            "Epoch: 30, Step: 612/655, Loss: 2.208130, Accuracy: 18.38%\n",
            "Epoch: 30, Step: 613/655, Loss: 2.208032, Accuracy: 18.39%\n",
            "Epoch: 30, Step: 614/655, Loss: 2.208149, Accuracy: 18.39%\n",
            "Epoch: 30, Step: 615/655, Loss: 2.208190, Accuracy: 18.38%\n",
            "Epoch: 30, Step: 616/655, Loss: 2.208262, Accuracy: 18.40%\n",
            "Epoch: 30, Step: 617/655, Loss: 2.208129, Accuracy: 18.40%\n",
            "Epoch: 30, Step: 618/655, Loss: 2.208248, Accuracy: 18.40%\n",
            "Epoch: 30, Step: 619/655, Loss: 2.208389, Accuracy: 18.38%\n",
            "Epoch: 30, Step: 620/655, Loss: 2.207966, Accuracy: 18.39%\n",
            "Epoch: 30, Step: 621/655, Loss: 2.208091, Accuracy: 18.38%\n",
            "Epoch: 30, Step: 622/655, Loss: 2.207922, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 623/655, Loss: 2.207859, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 624/655, Loss: 2.207882, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 625/655, Loss: 2.207811, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 626/655, Loss: 2.207842, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 627/655, Loss: 2.207875, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 628/655, Loss: 2.207917, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 629/655, Loss: 2.207872, Accuracy: 18.35%\n",
            "Epoch: 30, Step: 630/655, Loss: 2.207800, Accuracy: 18.38%\n",
            "Epoch: 30, Step: 631/655, Loss: 2.207868, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 632/655, Loss: 2.207752, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 633/655, Loss: 2.207755, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 634/655, Loss: 2.207560, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 635/655, Loss: 2.207607, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 636/655, Loss: 2.207563, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 637/655, Loss: 2.207535, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 638/655, Loss: 2.207631, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 639/655, Loss: 2.207448, Accuracy: 18.39%\n",
            "Epoch: 30, Step: 640/655, Loss: 2.207515, Accuracy: 18.38%\n",
            "Epoch: 30, Step: 641/655, Loss: 2.207558, Accuracy: 18.38%\n",
            "Epoch: 30, Step: 642/655, Loss: 2.207493, Accuracy: 18.38%\n",
            "Epoch: 30, Step: 643/655, Loss: 2.207548, Accuracy: 18.38%\n",
            "Epoch: 30, Step: 644/655, Loss: 2.207498, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 645/655, Loss: 2.207482, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 646/655, Loss: 2.207611, Accuracy: 18.37%\n",
            "Epoch: 30, Step: 647/655, Loss: 2.207867, Accuracy: 18.35%\n",
            "Epoch: 30, Step: 648/655, Loss: 2.207733, Accuracy: 18.36%\n",
            "Epoch: 30, Step: 649/655, Loss: 2.207786, Accuracy: 18.35%\n",
            "Epoch: 30, Step: 650/655, Loss: 2.207564, Accuracy: 18.34%\n",
            "Epoch: 30, Step: 651/655, Loss: 2.207388, Accuracy: 18.34%\n",
            "Epoch: 30, Step: 652/655, Loss: 2.207549, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 653/655, Loss: 2.207641, Accuracy: 18.33%\n",
            "Epoch: 30, Step: 654/655, Loss: 2.207698, Accuracy: 18.32%\n",
            "Epoch: 30, Step: 655/655, Loss: 2.207610, Accuracy: 18.32%\n",
            "Epoch: 31, Step: 1/655, Loss: 2.045292, Accuracy: 28.12%\n",
            "Epoch: 31, Step: 2/655, Loss: 2.059606, Accuracy: 25.00%\n",
            "Epoch: 31, Step: 3/655, Loss: 2.136699, Accuracy: 20.83%\n",
            "Epoch: 31, Step: 4/655, Loss: 2.146889, Accuracy: 21.88%\n",
            "Epoch: 31, Step: 5/655, Loss: 2.167797, Accuracy: 20.62%\n",
            "Epoch: 31, Step: 6/655, Loss: 2.187771, Accuracy: 19.27%\n",
            "Epoch: 31, Step: 7/655, Loss: 2.203308, Accuracy: 17.86%\n",
            "Epoch: 31, Step: 8/655, Loss: 2.211517, Accuracy: 19.14%\n",
            "Epoch: 31, Step: 9/655, Loss: 2.209820, Accuracy: 18.75%\n",
            "Epoch: 31, Step: 10/655, Loss: 2.203262, Accuracy: 19.69%\n",
            "Epoch: 31, Step: 11/655, Loss: 2.195117, Accuracy: 19.60%\n",
            "Epoch: 31, Step: 12/655, Loss: 2.198610, Accuracy: 19.01%\n",
            "Epoch: 31, Step: 13/655, Loss: 2.204979, Accuracy: 18.75%\n",
            "Epoch: 31, Step: 14/655, Loss: 2.202336, Accuracy: 18.53%\n",
            "Epoch: 31, Step: 15/655, Loss: 2.198640, Accuracy: 18.12%\n",
            "Epoch: 31, Step: 16/655, Loss: 2.198761, Accuracy: 17.97%\n",
            "Epoch: 31, Step: 17/655, Loss: 2.201221, Accuracy: 17.46%\n",
            "Epoch: 31, Step: 18/655, Loss: 2.197599, Accuracy: 17.71%\n",
            "Epoch: 31, Step: 19/655, Loss: 2.204160, Accuracy: 17.43%\n",
            "Epoch: 31, Step: 20/655, Loss: 2.207214, Accuracy: 17.03%\n",
            "Epoch: 31, Step: 21/655, Loss: 2.205309, Accuracy: 17.11%\n",
            "Epoch: 31, Step: 22/655, Loss: 2.197118, Accuracy: 17.76%\n",
            "Epoch: 31, Step: 23/655, Loss: 2.198275, Accuracy: 17.93%\n",
            "Epoch: 31, Step: 24/655, Loss: 2.197468, Accuracy: 18.10%\n",
            "Epoch: 31, Step: 25/655, Loss: 2.195183, Accuracy: 18.38%\n",
            "Epoch: 31, Step: 26/655, Loss: 2.193705, Accuracy: 17.91%\n",
            "Epoch: 31, Step: 27/655, Loss: 2.193912, Accuracy: 17.82%\n",
            "Epoch: 31, Step: 28/655, Loss: 2.195397, Accuracy: 17.86%\n",
            "Epoch: 31, Step: 29/655, Loss: 2.199726, Accuracy: 17.67%\n",
            "Epoch: 31, Step: 30/655, Loss: 2.201587, Accuracy: 17.81%\n",
            "Epoch: 31, Step: 31/655, Loss: 2.203068, Accuracy: 17.94%\n",
            "Epoch: 31, Step: 32/655, Loss: 2.202384, Accuracy: 18.36%\n",
            "Epoch: 31, Step: 33/655, Loss: 2.201089, Accuracy: 18.47%\n",
            "Epoch: 31, Step: 34/655, Loss: 2.200761, Accuracy: 18.38%\n",
            "Epoch: 31, Step: 35/655, Loss: 2.200791, Accuracy: 18.57%\n",
            "Epoch: 31, Step: 36/655, Loss: 2.197937, Accuracy: 18.58%\n",
            "Epoch: 31, Step: 37/655, Loss: 2.194664, Accuracy: 18.75%\n",
            "Epoch: 31, Step: 38/655, Loss: 2.191926, Accuracy: 19.08%\n",
            "Epoch: 31, Step: 39/655, Loss: 2.194658, Accuracy: 18.99%\n",
            "Epoch: 31, Step: 40/655, Loss: 2.193050, Accuracy: 19.14%\n",
            "Epoch: 31, Step: 41/655, Loss: 2.196373, Accuracy: 18.98%\n",
            "Epoch: 31, Step: 42/655, Loss: 2.194856, Accuracy: 18.97%\n",
            "Epoch: 31, Step: 43/655, Loss: 2.196753, Accuracy: 18.90%\n",
            "Epoch: 31, Step: 44/655, Loss: 2.197137, Accuracy: 18.82%\n",
            "Epoch: 31, Step: 45/655, Loss: 2.195725, Accuracy: 18.96%\n",
            "Epoch: 31, Step: 46/655, Loss: 2.195937, Accuracy: 19.02%\n",
            "Epoch: 31, Step: 47/655, Loss: 2.195256, Accuracy: 18.88%\n",
            "Epoch: 31, Step: 48/655, Loss: 2.194184, Accuracy: 18.88%\n",
            "Epoch: 31, Step: 49/655, Loss: 2.195414, Accuracy: 19.01%\n",
            "Epoch: 31, Step: 50/655, Loss: 2.195844, Accuracy: 18.88%\n",
            "Epoch: 31, Step: 51/655, Loss: 2.196772, Accuracy: 18.87%\n",
            "Epoch: 31, Step: 52/655, Loss: 2.197572, Accuracy: 18.75%\n",
            "Epoch: 31, Step: 53/655, Loss: 2.198347, Accuracy: 19.04%\n",
            "Epoch: 31, Step: 54/655, Loss: 2.195387, Accuracy: 18.92%\n",
            "Epoch: 31, Step: 55/655, Loss: 2.194858, Accuracy: 18.98%\n",
            "Epoch: 31, Step: 56/655, Loss: 2.193886, Accuracy: 19.14%\n",
            "Epoch: 31, Step: 57/655, Loss: 2.195975, Accuracy: 18.91%\n",
            "Epoch: 31, Step: 58/655, Loss: 2.196781, Accuracy: 18.97%\n",
            "Epoch: 31, Step: 59/655, Loss: 2.197241, Accuracy: 19.07%\n",
            "Epoch: 31, Step: 60/655, Loss: 2.197262, Accuracy: 18.96%\n",
            "Epoch: 31, Step: 61/655, Loss: 2.196657, Accuracy: 19.01%\n",
            "Epoch: 31, Step: 62/655, Loss: 2.194331, Accuracy: 19.30%\n",
            "Epoch: 31, Step: 63/655, Loss: 2.192749, Accuracy: 19.39%\n",
            "Epoch: 31, Step: 64/655, Loss: 2.193807, Accuracy: 19.34%\n",
            "Epoch: 31, Step: 65/655, Loss: 2.192356, Accuracy: 19.57%\n",
            "Epoch: 31, Step: 66/655, Loss: 2.192609, Accuracy: 19.37%\n",
            "Epoch: 31, Step: 67/655, Loss: 2.189789, Accuracy: 19.45%\n",
            "Epoch: 31, Step: 68/655, Loss: 2.188372, Accuracy: 19.58%\n",
            "Epoch: 31, Step: 69/655, Loss: 2.188657, Accuracy: 19.66%\n",
            "Epoch: 31, Step: 70/655, Loss: 2.189099, Accuracy: 19.73%\n",
            "Epoch: 31, Step: 71/655, Loss: 2.190076, Accuracy: 19.59%\n",
            "Epoch: 31, Step: 72/655, Loss: 2.188462, Accuracy: 19.79%\n",
            "Epoch: 31, Step: 73/655, Loss: 2.187926, Accuracy: 19.78%\n",
            "Epoch: 31, Step: 74/655, Loss: 2.188053, Accuracy: 19.81%\n",
            "Epoch: 31, Step: 75/655, Loss: 2.188219, Accuracy: 19.71%\n",
            "Epoch: 31, Step: 76/655, Loss: 2.191065, Accuracy: 19.57%\n",
            "Epoch: 31, Step: 77/655, Loss: 2.189993, Accuracy: 19.68%\n",
            "Epoch: 31, Step: 78/655, Loss: 2.187688, Accuracy: 19.91%\n",
            "Epoch: 31, Step: 79/655, Loss: 2.188100, Accuracy: 19.90%\n",
            "Epoch: 31, Step: 80/655, Loss: 2.188697, Accuracy: 19.92%\n",
            "Epoch: 31, Step: 81/655, Loss: 2.189285, Accuracy: 19.87%\n",
            "Epoch: 31, Step: 82/655, Loss: 2.190490, Accuracy: 19.78%\n",
            "Epoch: 31, Step: 83/655, Loss: 2.190065, Accuracy: 19.84%\n",
            "Epoch: 31, Step: 84/655, Loss: 2.190219, Accuracy: 19.87%\n",
            "Epoch: 31, Step: 85/655, Loss: 2.191592, Accuracy: 19.89%\n",
            "Epoch: 31, Step: 86/655, Loss: 2.192942, Accuracy: 19.84%\n",
            "Epoch: 31, Step: 87/655, Loss: 2.191959, Accuracy: 19.79%\n",
            "Epoch: 31, Step: 88/655, Loss: 2.194730, Accuracy: 19.67%\n",
            "Epoch: 31, Step: 89/655, Loss: 2.193553, Accuracy: 19.63%\n",
            "Epoch: 31, Step: 90/655, Loss: 2.193522, Accuracy: 19.62%\n",
            "Epoch: 31, Step: 91/655, Loss: 2.193454, Accuracy: 19.57%\n",
            "Epoch: 31, Step: 92/655, Loss: 2.193626, Accuracy: 19.53%\n",
            "Epoch: 31, Step: 93/655, Loss: 2.194230, Accuracy: 19.49%\n",
            "Epoch: 31, Step: 94/655, Loss: 2.195346, Accuracy: 19.38%\n",
            "Epoch: 31, Step: 95/655, Loss: 2.196051, Accuracy: 19.34%\n",
            "Epoch: 31, Step: 96/655, Loss: 2.197270, Accuracy: 19.34%\n",
            "Epoch: 31, Step: 97/655, Loss: 2.197431, Accuracy: 19.43%\n",
            "Epoch: 31, Step: 98/655, Loss: 2.196188, Accuracy: 19.39%\n",
            "Epoch: 31, Step: 99/655, Loss: 2.195225, Accuracy: 19.44%\n",
            "Epoch: 31, Step: 100/655, Loss: 2.195479, Accuracy: 19.44%\n",
            "Epoch: 31, Step: 101/655, Loss: 2.195566, Accuracy: 19.55%\n",
            "Epoch: 31, Step: 102/655, Loss: 2.195898, Accuracy: 19.58%\n",
            "Epoch: 31, Step: 103/655, Loss: 2.196153, Accuracy: 19.45%\n",
            "Epoch: 31, Step: 104/655, Loss: 2.196649, Accuracy: 19.41%\n",
            "Epoch: 31, Step: 105/655, Loss: 2.196809, Accuracy: 19.38%\n",
            "Epoch: 31, Step: 106/655, Loss: 2.197100, Accuracy: 19.34%\n",
            "Epoch: 31, Step: 107/655, Loss: 2.197426, Accuracy: 19.25%\n",
            "Epoch: 31, Step: 108/655, Loss: 2.197481, Accuracy: 19.18%\n",
            "Epoch: 31, Step: 109/655, Loss: 2.197179, Accuracy: 19.15%\n",
            "Epoch: 31, Step: 110/655, Loss: 2.197013, Accuracy: 19.26%\n",
            "Epoch: 31, Step: 111/655, Loss: 2.198260, Accuracy: 19.14%\n",
            "Epoch: 31, Step: 112/655, Loss: 2.199460, Accuracy: 19.11%\n",
            "Epoch: 31, Step: 113/655, Loss: 2.199819, Accuracy: 19.14%\n",
            "Epoch: 31, Step: 114/655, Loss: 2.199934, Accuracy: 19.08%\n",
            "Epoch: 31, Step: 115/655, Loss: 2.200249, Accuracy: 19.08%\n",
            "Epoch: 31, Step: 116/655, Loss: 2.200818, Accuracy: 18.97%\n",
            "Epoch: 31, Step: 117/655, Loss: 2.199225, Accuracy: 19.12%\n",
            "Epoch: 31, Step: 118/655, Loss: 2.199979, Accuracy: 19.15%\n",
            "Epoch: 31, Step: 119/655, Loss: 2.201852, Accuracy: 19.04%\n",
            "Epoch: 31, Step: 120/655, Loss: 2.202564, Accuracy: 18.91%\n",
            "Epoch: 31, Step: 121/655, Loss: 2.201593, Accuracy: 18.98%\n",
            "Epoch: 31, Step: 122/655, Loss: 2.201149, Accuracy: 19.08%\n",
            "Epoch: 31, Step: 123/655, Loss: 2.201081, Accuracy: 19.16%\n",
            "Epoch: 31, Step: 124/655, Loss: 2.200395, Accuracy: 19.15%\n",
            "Epoch: 31, Step: 125/655, Loss: 2.202147, Accuracy: 19.10%\n",
            "Epoch: 31, Step: 126/655, Loss: 2.202665, Accuracy: 19.07%\n",
            "Epoch: 31, Step: 127/655, Loss: 2.202482, Accuracy: 19.09%\n",
            "Epoch: 31, Step: 128/655, Loss: 2.202348, Accuracy: 19.07%\n",
            "Epoch: 31, Step: 129/655, Loss: 2.200995, Accuracy: 19.11%\n",
            "Epoch: 31, Step: 130/655, Loss: 2.200866, Accuracy: 19.16%\n",
            "Epoch: 31, Step: 131/655, Loss: 2.200225, Accuracy: 19.18%\n",
            "Epoch: 31, Step: 132/655, Loss: 2.200415, Accuracy: 19.18%\n",
            "Epoch: 31, Step: 133/655, Loss: 2.200414, Accuracy: 19.20%\n",
            "Epoch: 31, Step: 134/655, Loss: 2.200605, Accuracy: 19.10%\n",
            "Epoch: 31, Step: 135/655, Loss: 2.200565, Accuracy: 19.14%\n",
            "Epoch: 31, Step: 136/655, Loss: 2.201126, Accuracy: 19.12%\n",
            "Epoch: 31, Step: 137/655, Loss: 2.201666, Accuracy: 19.07%\n",
            "Epoch: 31, Step: 138/655, Loss: 2.200847, Accuracy: 19.11%\n",
            "Epoch: 31, Step: 139/655, Loss: 2.201182, Accuracy: 19.11%\n",
            "Epoch: 31, Step: 140/655, Loss: 2.200027, Accuracy: 19.13%\n",
            "Epoch: 31, Step: 141/655, Loss: 2.200070, Accuracy: 19.13%\n",
            "Epoch: 31, Step: 142/655, Loss: 2.199366, Accuracy: 19.19%\n",
            "Epoch: 31, Step: 143/655, Loss: 2.198605, Accuracy: 19.25%\n",
            "Epoch: 31, Step: 144/655, Loss: 2.199982, Accuracy: 19.23%\n",
            "Epoch: 31, Step: 145/655, Loss: 2.199997, Accuracy: 19.25%\n",
            "Epoch: 31, Step: 146/655, Loss: 2.200285, Accuracy: 19.26%\n",
            "Epoch: 31, Step: 147/655, Loss: 2.200438, Accuracy: 19.24%\n",
            "Epoch: 31, Step: 148/655, Loss: 2.199844, Accuracy: 19.28%\n",
            "Epoch: 31, Step: 149/655, Loss: 2.200320, Accuracy: 19.27%\n",
            "Epoch: 31, Step: 150/655, Loss: 2.200433, Accuracy: 19.33%\n",
            "Epoch: 31, Step: 151/655, Loss: 2.200648, Accuracy: 19.37%\n",
            "Epoch: 31, Step: 152/655, Loss: 2.200595, Accuracy: 19.35%\n",
            "Epoch: 31, Step: 153/655, Loss: 2.199442, Accuracy: 19.44%\n",
            "Epoch: 31, Step: 154/655, Loss: 2.199477, Accuracy: 19.46%\n",
            "Epoch: 31, Step: 155/655, Loss: 2.200976, Accuracy: 19.33%\n",
            "Epoch: 31, Step: 156/655, Loss: 2.201403, Accuracy: 19.35%\n",
            "Epoch: 31, Step: 157/655, Loss: 2.202336, Accuracy: 19.31%\n",
            "Epoch: 31, Step: 158/655, Loss: 2.202782, Accuracy: 19.28%\n",
            "Epoch: 31, Step: 159/655, Loss: 2.202244, Accuracy: 19.34%\n",
            "Epoch: 31, Step: 160/655, Loss: 2.202411, Accuracy: 19.36%\n",
            "Epoch: 31, Step: 161/655, Loss: 2.203117, Accuracy: 19.31%\n",
            "Epoch: 31, Step: 162/655, Loss: 2.203172, Accuracy: 19.29%\n",
            "Epoch: 31, Step: 163/655, Loss: 2.203354, Accuracy: 19.29%\n",
            "Epoch: 31, Step: 164/655, Loss: 2.202990, Accuracy: 19.26%\n",
            "Epoch: 31, Step: 165/655, Loss: 2.203259, Accuracy: 19.26%\n",
            "Epoch: 31, Step: 166/655, Loss: 2.203718, Accuracy: 19.30%\n",
            "Epoch: 31, Step: 167/655, Loss: 2.203673, Accuracy: 19.26%\n",
            "Epoch: 31, Step: 168/655, Loss: 2.204574, Accuracy: 19.22%\n",
            "Epoch: 31, Step: 169/655, Loss: 2.205174, Accuracy: 19.16%\n",
            "Epoch: 31, Step: 170/655, Loss: 2.204052, Accuracy: 19.21%\n",
            "Epoch: 31, Step: 171/655, Loss: 2.203581, Accuracy: 19.26%\n",
            "Epoch: 31, Step: 172/655, Loss: 2.203481, Accuracy: 19.22%\n",
            "Epoch: 31, Step: 173/655, Loss: 2.204282, Accuracy: 19.15%\n",
            "Epoch: 31, Step: 174/655, Loss: 2.204149, Accuracy: 19.09%\n",
            "Epoch: 31, Step: 175/655, Loss: 2.204566, Accuracy: 19.05%\n",
            "Epoch: 31, Step: 176/655, Loss: 2.204482, Accuracy: 19.07%\n",
            "Epoch: 31, Step: 177/655, Loss: 2.204298, Accuracy: 19.05%\n",
            "Epoch: 31, Step: 178/655, Loss: 2.204165, Accuracy: 19.10%\n",
            "Epoch: 31, Step: 179/655, Loss: 2.204069, Accuracy: 19.06%\n",
            "Epoch: 31, Step: 180/655, Loss: 2.204442, Accuracy: 19.06%\n",
            "Epoch: 31, Step: 181/655, Loss: 2.204548, Accuracy: 19.06%\n",
            "Epoch: 31, Step: 182/655, Loss: 2.204276, Accuracy: 19.08%\n",
            "Epoch: 31, Step: 183/655, Loss: 2.204182, Accuracy: 19.11%\n",
            "Epoch: 31, Step: 184/655, Loss: 2.204931, Accuracy: 19.09%\n",
            "Epoch: 31, Step: 185/655, Loss: 2.205974, Accuracy: 19.02%\n",
            "Epoch: 31, Step: 186/655, Loss: 2.205890, Accuracy: 19.09%\n",
            "Epoch: 31, Step: 187/655, Loss: 2.205644, Accuracy: 19.05%\n",
            "Epoch: 31, Step: 188/655, Loss: 2.205515, Accuracy: 19.10%\n",
            "Epoch: 31, Step: 189/655, Loss: 2.205717, Accuracy: 19.08%\n",
            "Epoch: 31, Step: 190/655, Loss: 2.206298, Accuracy: 19.06%\n",
            "Epoch: 31, Step: 191/655, Loss: 2.207200, Accuracy: 18.98%\n",
            "Epoch: 31, Step: 192/655, Loss: 2.207184, Accuracy: 18.98%\n",
            "Epoch: 31, Step: 193/655, Loss: 2.207349, Accuracy: 18.98%\n",
            "Epoch: 31, Step: 194/655, Loss: 2.207718, Accuracy: 18.96%\n",
            "Epoch: 31, Step: 195/655, Loss: 2.208120, Accuracy: 18.94%\n",
            "Epoch: 31, Step: 196/655, Loss: 2.208176, Accuracy: 18.93%\n",
            "Epoch: 31, Step: 197/655, Loss: 2.207436, Accuracy: 18.97%\n",
            "Epoch: 31, Step: 198/655, Loss: 2.207774, Accuracy: 18.94%\n",
            "Epoch: 31, Step: 199/655, Loss: 2.207470, Accuracy: 18.94%\n",
            "Epoch: 31, Step: 200/655, Loss: 2.207939, Accuracy: 18.92%\n",
            "Epoch: 31, Step: 201/655, Loss: 2.207532, Accuracy: 18.98%\n",
            "Epoch: 31, Step: 202/655, Loss: 2.207147, Accuracy: 19.01%\n",
            "Epoch: 31, Step: 203/655, Loss: 2.207403, Accuracy: 18.93%\n",
            "Epoch: 31, Step: 204/655, Loss: 2.207696, Accuracy: 18.92%\n",
            "Epoch: 31, Step: 205/655, Loss: 2.207623, Accuracy: 18.90%\n",
            "Epoch: 31, Step: 206/655, Loss: 2.207680, Accuracy: 18.90%\n",
            "Epoch: 31, Step: 207/655, Loss: 2.207815, Accuracy: 18.95%\n",
            "Epoch: 31, Step: 208/655, Loss: 2.207734, Accuracy: 18.96%\n",
            "Epoch: 31, Step: 209/655, Loss: 2.207960, Accuracy: 18.97%\n",
            "Epoch: 31, Step: 210/655, Loss: 2.208696, Accuracy: 18.93%\n",
            "Epoch: 31, Step: 211/655, Loss: 2.208866, Accuracy: 18.94%\n",
            "Epoch: 31, Step: 212/655, Loss: 2.208907, Accuracy: 18.93%\n",
            "Epoch: 31, Step: 213/655, Loss: 2.208716, Accuracy: 18.91%\n",
            "Epoch: 31, Step: 214/655, Loss: 2.208358, Accuracy: 18.95%\n",
            "Epoch: 31, Step: 215/655, Loss: 2.209182, Accuracy: 18.92%\n",
            "Epoch: 31, Step: 216/655, Loss: 2.208921, Accuracy: 18.95%\n",
            "Epoch: 31, Step: 217/655, Loss: 2.209117, Accuracy: 18.98%\n",
            "Epoch: 31, Step: 218/655, Loss: 2.208858, Accuracy: 18.99%\n",
            "Epoch: 31, Step: 219/655, Loss: 2.209199, Accuracy: 18.99%\n",
            "Epoch: 31, Step: 220/655, Loss: 2.209670, Accuracy: 18.96%\n",
            "Epoch: 31, Step: 221/655, Loss: 2.209626, Accuracy: 18.98%\n",
            "Epoch: 31, Step: 222/655, Loss: 2.209420, Accuracy: 18.99%\n",
            "Epoch: 31, Step: 223/655, Loss: 2.208795, Accuracy: 19.03%\n",
            "Epoch: 31, Step: 224/655, Loss: 2.208648, Accuracy: 19.03%\n",
            "Epoch: 31, Step: 225/655, Loss: 2.208390, Accuracy: 19.03%\n",
            "Epoch: 31, Step: 226/655, Loss: 2.208685, Accuracy: 19.01%\n",
            "Epoch: 31, Step: 227/655, Loss: 2.208368, Accuracy: 19.04%\n",
            "Epoch: 31, Step: 228/655, Loss: 2.208646, Accuracy: 19.01%\n",
            "Epoch: 31, Step: 229/655, Loss: 2.208831, Accuracy: 18.95%\n",
            "Epoch: 31, Step: 230/655, Loss: 2.208704, Accuracy: 18.94%\n",
            "Epoch: 31, Step: 231/655, Loss: 2.209040, Accuracy: 18.90%\n",
            "Epoch: 31, Step: 232/655, Loss: 2.209017, Accuracy: 18.90%\n",
            "Epoch: 31, Step: 233/655, Loss: 2.209251, Accuracy: 18.88%\n",
            "Epoch: 31, Step: 234/655, Loss: 2.209313, Accuracy: 18.86%\n",
            "Epoch: 31, Step: 235/655, Loss: 2.208965, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 236/655, Loss: 2.209346, Accuracy: 18.78%\n",
            "Epoch: 31, Step: 237/655, Loss: 2.208943, Accuracy: 18.79%\n",
            "Epoch: 31, Step: 238/655, Loss: 2.208728, Accuracy: 18.82%\n",
            "Epoch: 31, Step: 239/655, Loss: 2.208935, Accuracy: 18.80%\n",
            "Epoch: 31, Step: 240/655, Loss: 2.209104, Accuracy: 18.78%\n",
            "Epoch: 31, Step: 241/655, Loss: 2.209241, Accuracy: 18.79%\n",
            "Epoch: 31, Step: 242/655, Loss: 2.209195, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 243/655, Loss: 2.208962, Accuracy: 18.81%\n",
            "Epoch: 31, Step: 244/655, Loss: 2.208472, Accuracy: 18.85%\n",
            "Epoch: 31, Step: 245/655, Loss: 2.208372, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 246/655, Loss: 2.208777, Accuracy: 18.81%\n",
            "Epoch: 31, Step: 247/655, Loss: 2.208329, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 248/655, Loss: 2.208281, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 249/655, Loss: 2.207636, Accuracy: 18.90%\n",
            "Epoch: 31, Step: 250/655, Loss: 2.207286, Accuracy: 18.89%\n",
            "Epoch: 31, Step: 251/655, Loss: 2.207495, Accuracy: 18.89%\n",
            "Epoch: 31, Step: 252/655, Loss: 2.206506, Accuracy: 18.92%\n",
            "Epoch: 31, Step: 253/655, Loss: 2.206389, Accuracy: 18.92%\n",
            "Epoch: 31, Step: 254/655, Loss: 2.206301, Accuracy: 18.96%\n",
            "Epoch: 31, Step: 255/655, Loss: 2.206556, Accuracy: 18.96%\n",
            "Epoch: 31, Step: 256/655, Loss: 2.206235, Accuracy: 18.99%\n",
            "Epoch: 31, Step: 257/655, Loss: 2.206386, Accuracy: 18.99%\n",
            "Epoch: 31, Step: 258/655, Loss: 2.206526, Accuracy: 18.97%\n",
            "Epoch: 31, Step: 259/655, Loss: 2.206765, Accuracy: 18.96%\n",
            "Epoch: 31, Step: 260/655, Loss: 2.206637, Accuracy: 18.97%\n",
            "Epoch: 31, Step: 261/655, Loss: 2.207062, Accuracy: 18.94%\n",
            "Epoch: 31, Step: 262/655, Loss: 2.206688, Accuracy: 18.99%\n",
            "Epoch: 31, Step: 263/655, Loss: 2.206020, Accuracy: 19.07%\n",
            "Epoch: 31, Step: 264/655, Loss: 2.204986, Accuracy: 19.13%\n",
            "Epoch: 31, Step: 265/655, Loss: 2.204871, Accuracy: 19.12%\n",
            "Epoch: 31, Step: 266/655, Loss: 2.204807, Accuracy: 19.14%\n",
            "Epoch: 31, Step: 267/655, Loss: 2.204622, Accuracy: 19.14%\n",
            "Epoch: 31, Step: 268/655, Loss: 2.205091, Accuracy: 19.08%\n",
            "Epoch: 31, Step: 269/655, Loss: 2.205270, Accuracy: 19.05%\n",
            "Epoch: 31, Step: 270/655, Loss: 2.205349, Accuracy: 19.05%\n",
            "Epoch: 31, Step: 271/655, Loss: 2.205676, Accuracy: 19.02%\n",
            "Epoch: 31, Step: 272/655, Loss: 2.205559, Accuracy: 19.00%\n",
            "Epoch: 31, Step: 273/655, Loss: 2.205362, Accuracy: 19.04%\n",
            "Epoch: 31, Step: 274/655, Loss: 2.205664, Accuracy: 19.04%\n",
            "Epoch: 31, Step: 275/655, Loss: 2.204793, Accuracy: 19.08%\n",
            "Epoch: 31, Step: 276/655, Loss: 2.205058, Accuracy: 19.06%\n",
            "Epoch: 31, Step: 277/655, Loss: 2.205313, Accuracy: 19.03%\n",
            "Epoch: 31, Step: 278/655, Loss: 2.205667, Accuracy: 18.99%\n",
            "Epoch: 31, Step: 279/655, Loss: 2.205297, Accuracy: 19.00%\n",
            "Epoch: 31, Step: 280/655, Loss: 2.204710, Accuracy: 19.00%\n",
            "Epoch: 31, Step: 281/655, Loss: 2.204690, Accuracy: 18.98%\n",
            "Epoch: 31, Step: 282/655, Loss: 2.205131, Accuracy: 18.97%\n",
            "Epoch: 31, Step: 283/655, Loss: 2.205370, Accuracy: 18.96%\n",
            "Epoch: 31, Step: 284/655, Loss: 2.205139, Accuracy: 18.97%\n",
            "Epoch: 31, Step: 285/655, Loss: 2.204694, Accuracy: 18.99%\n",
            "Epoch: 31, Step: 286/655, Loss: 2.204523, Accuracy: 19.03%\n",
            "Epoch: 31, Step: 287/655, Loss: 2.204730, Accuracy: 19.02%\n",
            "Epoch: 31, Step: 288/655, Loss: 2.204309, Accuracy: 19.04%\n",
            "Epoch: 31, Step: 289/655, Loss: 2.204187, Accuracy: 19.04%\n",
            "Epoch: 31, Step: 290/655, Loss: 2.204498, Accuracy: 19.01%\n",
            "Epoch: 31, Step: 291/655, Loss: 2.204480, Accuracy: 19.01%\n",
            "Epoch: 31, Step: 292/655, Loss: 2.204474, Accuracy: 19.03%\n",
            "Epoch: 31, Step: 293/655, Loss: 2.204374, Accuracy: 19.04%\n",
            "Epoch: 31, Step: 294/655, Loss: 2.203808, Accuracy: 19.10%\n",
            "Epoch: 31, Step: 295/655, Loss: 2.203400, Accuracy: 19.11%\n",
            "Epoch: 31, Step: 296/655, Loss: 2.203710, Accuracy: 19.12%\n",
            "Epoch: 31, Step: 297/655, Loss: 2.203759, Accuracy: 19.09%\n",
            "Epoch: 31, Step: 298/655, Loss: 2.204035, Accuracy: 19.11%\n",
            "Epoch: 31, Step: 299/655, Loss: 2.203511, Accuracy: 19.14%\n",
            "Epoch: 31, Step: 300/655, Loss: 2.203255, Accuracy: 19.12%\n",
            "Epoch: 31, Step: 301/655, Loss: 2.203210, Accuracy: 19.13%\n",
            "Epoch: 31, Step: 302/655, Loss: 2.203340, Accuracy: 19.14%\n",
            "Epoch: 31, Step: 303/655, Loss: 2.203408, Accuracy: 19.13%\n",
            "Epoch: 31, Step: 304/655, Loss: 2.203786, Accuracy: 19.10%\n",
            "Epoch: 31, Step: 305/655, Loss: 2.203690, Accuracy: 19.08%\n",
            "Epoch: 31, Step: 306/655, Loss: 2.203638, Accuracy: 19.07%\n",
            "Epoch: 31, Step: 307/655, Loss: 2.203680, Accuracy: 19.08%\n",
            "Epoch: 31, Step: 308/655, Loss: 2.204098, Accuracy: 19.07%\n",
            "Epoch: 31, Step: 309/655, Loss: 2.204422, Accuracy: 19.09%\n",
            "Epoch: 31, Step: 310/655, Loss: 2.204469, Accuracy: 19.06%\n",
            "Epoch: 31, Step: 311/655, Loss: 2.204843, Accuracy: 19.03%\n",
            "Epoch: 31, Step: 312/655, Loss: 2.204891, Accuracy: 19.02%\n",
            "Epoch: 31, Step: 313/655, Loss: 2.205011, Accuracy: 19.03%\n",
            "Epoch: 31, Step: 314/655, Loss: 2.204963, Accuracy: 19.01%\n",
            "Epoch: 31, Step: 315/655, Loss: 2.204371, Accuracy: 19.07%\n",
            "Epoch: 31, Step: 316/655, Loss: 2.204562, Accuracy: 19.05%\n",
            "Epoch: 31, Step: 317/655, Loss: 2.204455, Accuracy: 19.08%\n",
            "Epoch: 31, Step: 318/655, Loss: 2.203983, Accuracy: 19.11%\n",
            "Epoch: 31, Step: 319/655, Loss: 2.203549, Accuracy: 19.10%\n",
            "Epoch: 31, Step: 320/655, Loss: 2.203317, Accuracy: 19.12%\n",
            "Epoch: 31, Step: 321/655, Loss: 2.202914, Accuracy: 19.17%\n",
            "Epoch: 31, Step: 322/655, Loss: 2.202652, Accuracy: 19.17%\n",
            "Epoch: 31, Step: 323/655, Loss: 2.202745, Accuracy: 19.17%\n",
            "Epoch: 31, Step: 324/655, Loss: 2.203168, Accuracy: 19.13%\n",
            "Epoch: 31, Step: 325/655, Loss: 2.203080, Accuracy: 19.15%\n",
            "Epoch: 31, Step: 326/655, Loss: 2.203233, Accuracy: 19.15%\n",
            "Epoch: 31, Step: 327/655, Loss: 2.203213, Accuracy: 19.14%\n",
            "Epoch: 31, Step: 328/655, Loss: 2.203505, Accuracy: 19.11%\n",
            "Epoch: 31, Step: 329/655, Loss: 2.203532, Accuracy: 19.10%\n",
            "Epoch: 31, Step: 330/655, Loss: 2.203455, Accuracy: 19.08%\n",
            "Epoch: 31, Step: 331/655, Loss: 2.203388, Accuracy: 19.08%\n",
            "Epoch: 31, Step: 332/655, Loss: 2.203606, Accuracy: 19.04%\n",
            "Epoch: 31, Step: 333/655, Loss: 2.203417, Accuracy: 19.05%\n",
            "Epoch: 31, Step: 334/655, Loss: 2.203359, Accuracy: 19.07%\n",
            "Epoch: 31, Step: 335/655, Loss: 2.203431, Accuracy: 19.09%\n",
            "Epoch: 31, Step: 336/655, Loss: 2.203544, Accuracy: 19.08%\n",
            "Epoch: 31, Step: 337/655, Loss: 2.203714, Accuracy: 19.07%\n",
            "Epoch: 31, Step: 338/655, Loss: 2.203731, Accuracy: 19.05%\n",
            "Epoch: 31, Step: 339/655, Loss: 2.203967, Accuracy: 19.04%\n",
            "Epoch: 31, Step: 340/655, Loss: 2.204093, Accuracy: 19.03%\n",
            "Epoch: 31, Step: 341/655, Loss: 2.204169, Accuracy: 19.02%\n",
            "Epoch: 31, Step: 342/655, Loss: 2.204282, Accuracy: 19.03%\n",
            "Epoch: 31, Step: 343/655, Loss: 2.204559, Accuracy: 19.02%\n",
            "Epoch: 31, Step: 344/655, Loss: 2.204377, Accuracy: 19.00%\n",
            "Epoch: 31, Step: 345/655, Loss: 2.204695, Accuracy: 18.98%\n",
            "Epoch: 31, Step: 346/655, Loss: 2.204756, Accuracy: 18.98%\n",
            "Epoch: 31, Step: 347/655, Loss: 2.204860, Accuracy: 18.96%\n",
            "Epoch: 31, Step: 348/655, Loss: 2.204758, Accuracy: 18.95%\n",
            "Epoch: 31, Step: 349/655, Loss: 2.204952, Accuracy: 18.91%\n",
            "Epoch: 31, Step: 350/655, Loss: 2.204613, Accuracy: 18.94%\n",
            "Epoch: 31, Step: 351/655, Loss: 2.204698, Accuracy: 18.92%\n",
            "Epoch: 31, Step: 352/655, Loss: 2.204340, Accuracy: 18.95%\n",
            "Epoch: 31, Step: 353/655, Loss: 2.204738, Accuracy: 18.92%\n",
            "Epoch: 31, Step: 354/655, Loss: 2.204765, Accuracy: 18.93%\n",
            "Epoch: 31, Step: 355/655, Loss: 2.205023, Accuracy: 18.90%\n",
            "Epoch: 31, Step: 356/655, Loss: 2.205408, Accuracy: 18.90%\n",
            "Epoch: 31, Step: 357/655, Loss: 2.205347, Accuracy: 18.93%\n",
            "Epoch: 31, Step: 358/655, Loss: 2.205088, Accuracy: 18.94%\n",
            "Epoch: 31, Step: 359/655, Loss: 2.205280, Accuracy: 18.91%\n",
            "Epoch: 31, Step: 360/655, Loss: 2.204966, Accuracy: 18.91%\n",
            "Epoch: 31, Step: 361/655, Loss: 2.204851, Accuracy: 18.90%\n",
            "Epoch: 31, Step: 362/655, Loss: 2.205270, Accuracy: 18.89%\n",
            "Epoch: 31, Step: 363/655, Loss: 2.205216, Accuracy: 18.90%\n",
            "Epoch: 31, Step: 364/655, Loss: 2.205131, Accuracy: 18.91%\n",
            "Epoch: 31, Step: 365/655, Loss: 2.205349, Accuracy: 18.90%\n",
            "Epoch: 31, Step: 366/655, Loss: 2.205149, Accuracy: 18.92%\n",
            "Epoch: 31, Step: 367/655, Loss: 2.205191, Accuracy: 18.95%\n",
            "Epoch: 31, Step: 368/655, Loss: 2.205173, Accuracy: 18.95%\n",
            "Epoch: 31, Step: 369/655, Loss: 2.204791, Accuracy: 18.96%\n",
            "Epoch: 31, Step: 370/655, Loss: 2.204719, Accuracy: 18.97%\n",
            "Epoch: 31, Step: 371/655, Loss: 2.204955, Accuracy: 18.94%\n",
            "Epoch: 31, Step: 372/655, Loss: 2.205179, Accuracy: 18.91%\n",
            "Epoch: 31, Step: 373/655, Loss: 2.205222, Accuracy: 18.89%\n",
            "Epoch: 31, Step: 374/655, Loss: 2.205224, Accuracy: 18.89%\n",
            "Epoch: 31, Step: 375/655, Loss: 2.205477, Accuracy: 18.88%\n",
            "Epoch: 31, Step: 376/655, Loss: 2.205473, Accuracy: 18.88%\n",
            "Epoch: 31, Step: 377/655, Loss: 2.205228, Accuracy: 18.87%\n",
            "Epoch: 31, Step: 378/655, Loss: 2.205508, Accuracy: 18.85%\n",
            "Epoch: 31, Step: 379/655, Loss: 2.205663, Accuracy: 18.82%\n",
            "Epoch: 31, Step: 380/655, Loss: 2.205712, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 381/655, Loss: 2.205250, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 382/655, Loss: 2.204954, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 383/655, Loss: 2.205167, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 384/655, Loss: 2.205187, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 385/655, Loss: 2.205155, Accuracy: 18.85%\n",
            "Epoch: 31, Step: 386/655, Loss: 2.204822, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 387/655, Loss: 2.204562, Accuracy: 18.85%\n",
            "Epoch: 31, Step: 388/655, Loss: 2.204273, Accuracy: 18.85%\n",
            "Epoch: 31, Step: 389/655, Loss: 2.204264, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 390/655, Loss: 2.204647, Accuracy: 18.81%\n",
            "Epoch: 31, Step: 391/655, Loss: 2.204361, Accuracy: 18.81%\n",
            "Epoch: 31, Step: 392/655, Loss: 2.204409, Accuracy: 18.81%\n",
            "Epoch: 31, Step: 393/655, Loss: 2.204009, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 394/655, Loss: 2.203668, Accuracy: 18.88%\n",
            "Epoch: 31, Step: 395/655, Loss: 2.203410, Accuracy: 18.87%\n",
            "Epoch: 31, Step: 396/655, Loss: 2.203523, Accuracy: 18.86%\n",
            "Epoch: 31, Step: 397/655, Loss: 2.203643, Accuracy: 18.86%\n",
            "Epoch: 31, Step: 398/655, Loss: 2.203385, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 399/655, Loss: 2.203522, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 400/655, Loss: 2.203360, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 401/655, Loss: 2.203280, Accuracy: 18.85%\n",
            "Epoch: 31, Step: 402/655, Loss: 2.203156, Accuracy: 18.87%\n",
            "Epoch: 31, Step: 403/655, Loss: 2.203359, Accuracy: 18.87%\n",
            "Epoch: 31, Step: 404/655, Loss: 2.203567, Accuracy: 18.86%\n",
            "Epoch: 31, Step: 405/655, Loss: 2.203748, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 406/655, Loss: 2.203973, Accuracy: 18.80%\n",
            "Epoch: 31, Step: 407/655, Loss: 2.204058, Accuracy: 18.78%\n",
            "Epoch: 31, Step: 408/655, Loss: 2.203672, Accuracy: 18.80%\n",
            "Epoch: 31, Step: 409/655, Loss: 2.203670, Accuracy: 18.77%\n",
            "Epoch: 31, Step: 410/655, Loss: 2.203375, Accuracy: 18.79%\n",
            "Epoch: 31, Step: 411/655, Loss: 2.203845, Accuracy: 18.77%\n",
            "Epoch: 31, Step: 412/655, Loss: 2.203943, Accuracy: 18.77%\n",
            "Epoch: 31, Step: 413/655, Loss: 2.204075, Accuracy: 18.77%\n",
            "Epoch: 31, Step: 414/655, Loss: 2.203868, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 415/655, Loss: 2.204218, Accuracy: 18.77%\n",
            "Epoch: 31, Step: 416/655, Loss: 2.204169, Accuracy: 18.75%\n",
            "Epoch: 31, Step: 417/655, Loss: 2.203936, Accuracy: 18.74%\n",
            "Epoch: 31, Step: 418/655, Loss: 2.203885, Accuracy: 18.74%\n",
            "Epoch: 31, Step: 419/655, Loss: 2.204320, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 420/655, Loss: 2.204356, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 421/655, Loss: 2.204440, Accuracy: 18.69%\n",
            "Epoch: 31, Step: 422/655, Loss: 2.204287, Accuracy: 18.68%\n",
            "Epoch: 31, Step: 423/655, Loss: 2.204251, Accuracy: 18.68%\n",
            "Epoch: 31, Step: 424/655, Loss: 2.204216, Accuracy: 18.69%\n",
            "Epoch: 31, Step: 425/655, Loss: 2.204328, Accuracy: 18.69%\n",
            "Epoch: 31, Step: 426/655, Loss: 2.204362, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 427/655, Loss: 2.204395, Accuracy: 18.69%\n",
            "Epoch: 31, Step: 428/655, Loss: 2.204295, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 429/655, Loss: 2.204070, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 430/655, Loss: 2.203944, Accuracy: 18.75%\n",
            "Epoch: 31, Step: 431/655, Loss: 2.203981, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 432/655, Loss: 2.203708, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 433/655, Loss: 2.203865, Accuracy: 18.75%\n",
            "Epoch: 31, Step: 434/655, Loss: 2.203892, Accuracy: 18.77%\n",
            "Epoch: 31, Step: 435/655, Loss: 2.203745, Accuracy: 18.79%\n",
            "Epoch: 31, Step: 436/655, Loss: 2.203852, Accuracy: 18.79%\n",
            "Epoch: 31, Step: 437/655, Loss: 2.204272, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 438/655, Loss: 2.204363, Accuracy: 18.74%\n",
            "Epoch: 31, Step: 439/655, Loss: 2.204321, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 440/655, Loss: 2.204365, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 441/655, Loss: 2.204641, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 442/655, Loss: 2.204688, Accuracy: 18.78%\n",
            "Epoch: 31, Step: 443/655, Loss: 2.205278, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 444/655, Loss: 2.205467, Accuracy: 18.74%\n",
            "Epoch: 31, Step: 445/655, Loss: 2.205484, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 446/655, Loss: 2.205569, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 447/655, Loss: 2.205433, Accuracy: 18.75%\n",
            "Epoch: 31, Step: 448/655, Loss: 2.205222, Accuracy: 18.78%\n",
            "Epoch: 31, Step: 449/655, Loss: 2.205233, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 450/655, Loss: 2.205427, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 451/655, Loss: 2.205651, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 452/655, Loss: 2.205889, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 453/655, Loss: 2.205682, Accuracy: 18.78%\n",
            "Epoch: 31, Step: 454/655, Loss: 2.205904, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 455/655, Loss: 2.205669, Accuracy: 18.78%\n",
            "Epoch: 31, Step: 456/655, Loss: 2.205472, Accuracy: 18.80%\n",
            "Epoch: 31, Step: 457/655, Loss: 2.205578, Accuracy: 18.80%\n",
            "Epoch: 31, Step: 458/655, Loss: 2.205385, Accuracy: 18.81%\n",
            "Epoch: 31, Step: 459/655, Loss: 2.205635, Accuracy: 18.82%\n",
            "Epoch: 31, Step: 460/655, Loss: 2.205384, Accuracy: 18.82%\n",
            "Epoch: 31, Step: 461/655, Loss: 2.205477, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 462/655, Loss: 2.205370, Accuracy: 18.86%\n",
            "Epoch: 31, Step: 463/655, Loss: 2.205417, Accuracy: 18.85%\n",
            "Epoch: 31, Step: 464/655, Loss: 2.205506, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 465/655, Loss: 2.205548, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 466/655, Loss: 2.205841, Accuracy: 18.82%\n",
            "Epoch: 31, Step: 467/655, Loss: 2.205924, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 468/655, Loss: 2.205966, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 469/655, Loss: 2.206053, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 470/655, Loss: 2.205854, Accuracy: 18.85%\n",
            "Epoch: 31, Step: 471/655, Loss: 2.205595, Accuracy: 18.86%\n",
            "Epoch: 31, Step: 472/655, Loss: 2.205781, Accuracy: 18.85%\n",
            "Epoch: 31, Step: 473/655, Loss: 2.205904, Accuracy: 18.82%\n",
            "Epoch: 31, Step: 474/655, Loss: 2.206020, Accuracy: 18.81%\n",
            "Epoch: 31, Step: 475/655, Loss: 2.206073, Accuracy: 18.81%\n",
            "Epoch: 31, Step: 476/655, Loss: 2.206015, Accuracy: 18.80%\n",
            "Epoch: 31, Step: 477/655, Loss: 2.205893, Accuracy: 18.79%\n",
            "Epoch: 31, Step: 478/655, Loss: 2.205936, Accuracy: 18.80%\n",
            "Epoch: 31, Step: 479/655, Loss: 2.206194, Accuracy: 18.78%\n",
            "Epoch: 31, Step: 480/655, Loss: 2.206217, Accuracy: 18.78%\n",
            "Epoch: 31, Step: 481/655, Loss: 2.205916, Accuracy: 18.81%\n",
            "Epoch: 31, Step: 482/655, Loss: 2.205882, Accuracy: 18.80%\n",
            "Epoch: 31, Step: 483/655, Loss: 2.205912, Accuracy: 18.78%\n",
            "Epoch: 31, Step: 484/655, Loss: 2.205943, Accuracy: 18.78%\n",
            "Epoch: 31, Step: 485/655, Loss: 2.205627, Accuracy: 18.81%\n",
            "Epoch: 31, Step: 486/655, Loss: 2.205884, Accuracy: 18.79%\n",
            "Epoch: 31, Step: 487/655, Loss: 2.205979, Accuracy: 18.80%\n",
            "Epoch: 31, Step: 488/655, Loss: 2.205910, Accuracy: 18.81%\n",
            "Epoch: 31, Step: 489/655, Loss: 2.206036, Accuracy: 18.79%\n",
            "Epoch: 31, Step: 490/655, Loss: 2.206025, Accuracy: 18.80%\n",
            "Epoch: 31, Step: 491/655, Loss: 2.206200, Accuracy: 18.79%\n",
            "Epoch: 31, Step: 492/655, Loss: 2.206269, Accuracy: 18.79%\n",
            "Epoch: 31, Step: 493/655, Loss: 2.206625, Accuracy: 18.78%\n",
            "Epoch: 31, Step: 494/655, Loss: 2.206531, Accuracy: 18.80%\n",
            "Epoch: 31, Step: 495/655, Loss: 2.206612, Accuracy: 18.80%\n",
            "Epoch: 31, Step: 496/655, Loss: 2.206816, Accuracy: 18.79%\n",
            "Epoch: 31, Step: 497/655, Loss: 2.207075, Accuracy: 18.77%\n",
            "Epoch: 31, Step: 498/655, Loss: 2.207556, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 499/655, Loss: 2.207425, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 500/655, Loss: 2.207352, Accuracy: 18.77%\n",
            "Epoch: 31, Step: 501/655, Loss: 2.207216, Accuracy: 18.79%\n",
            "Epoch: 31, Step: 502/655, Loss: 2.207085, Accuracy: 18.80%\n",
            "Epoch: 31, Step: 503/655, Loss: 2.207036, Accuracy: 18.81%\n",
            "Epoch: 31, Step: 504/655, Loss: 2.207135, Accuracy: 18.81%\n",
            "Epoch: 31, Step: 505/655, Loss: 2.207231, Accuracy: 18.81%\n",
            "Epoch: 31, Step: 506/655, Loss: 2.207007, Accuracy: 18.85%\n",
            "Epoch: 31, Step: 507/655, Loss: 2.207133, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 508/655, Loss: 2.207215, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 509/655, Loss: 2.207269, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 510/655, Loss: 2.207027, Accuracy: 18.85%\n",
            "Epoch: 31, Step: 511/655, Loss: 2.206880, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 512/655, Loss: 2.206785, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 513/655, Loss: 2.206784, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 514/655, Loss: 2.206767, Accuracy: 18.82%\n",
            "Epoch: 31, Step: 515/655, Loss: 2.206863, Accuracy: 18.81%\n",
            "Epoch: 31, Step: 516/655, Loss: 2.206532, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 517/655, Loss: 2.206553, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 518/655, Loss: 2.206589, Accuracy: 18.84%\n",
            "Epoch: 31, Step: 519/655, Loss: 2.206700, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 520/655, Loss: 2.206736, Accuracy: 18.85%\n",
            "Epoch: 31, Step: 521/655, Loss: 2.206561, Accuracy: 18.85%\n",
            "Epoch: 31, Step: 522/655, Loss: 2.206763, Accuracy: 18.82%\n",
            "Epoch: 31, Step: 523/655, Loss: 2.206827, Accuracy: 18.83%\n",
            "Epoch: 31, Step: 524/655, Loss: 2.206840, Accuracy: 18.82%\n",
            "Epoch: 31, Step: 525/655, Loss: 2.206955, Accuracy: 18.82%\n",
            "Epoch: 31, Step: 526/655, Loss: 2.206904, Accuracy: 18.80%\n",
            "Epoch: 31, Step: 527/655, Loss: 2.206986, Accuracy: 18.78%\n",
            "Epoch: 31, Step: 528/655, Loss: 2.206927, Accuracy: 18.77%\n",
            "Epoch: 31, Step: 529/655, Loss: 2.206699, Accuracy: 18.77%\n",
            "Epoch: 31, Step: 530/655, Loss: 2.206665, Accuracy: 18.77%\n",
            "Epoch: 31, Step: 531/655, Loss: 2.206822, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 532/655, Loss: 2.206897, Accuracy: 18.75%\n",
            "Epoch: 31, Step: 533/655, Loss: 2.206691, Accuracy: 18.77%\n",
            "Epoch: 31, Step: 534/655, Loss: 2.206786, Accuracy: 18.74%\n",
            "Epoch: 31, Step: 535/655, Loss: 2.206967, Accuracy: 18.73%\n",
            "Epoch: 31, Step: 536/655, Loss: 2.206914, Accuracy: 18.74%\n",
            "Epoch: 31, Step: 537/655, Loss: 2.206645, Accuracy: 18.77%\n",
            "Epoch: 31, Step: 538/655, Loss: 2.206668, Accuracy: 18.77%\n",
            "Epoch: 31, Step: 539/655, Loss: 2.206735, Accuracy: 18.77%\n",
            "Epoch: 31, Step: 540/655, Loss: 2.206828, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 541/655, Loss: 2.207002, Accuracy: 18.74%\n",
            "Epoch: 31, Step: 542/655, Loss: 2.206966, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 543/655, Loss: 2.207133, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 544/655, Loss: 2.207108, Accuracy: 18.76%\n",
            "Epoch: 31, Step: 545/655, Loss: 2.207066, Accuracy: 18.75%\n",
            "Epoch: 31, Step: 546/655, Loss: 2.207104, Accuracy: 18.75%\n",
            "Epoch: 31, Step: 547/655, Loss: 2.207313, Accuracy: 18.74%\n",
            "Epoch: 31, Step: 548/655, Loss: 2.207135, Accuracy: 18.73%\n",
            "Epoch: 31, Step: 549/655, Loss: 2.207079, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 550/655, Loss: 2.207191, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 551/655, Loss: 2.207028, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 552/655, Loss: 2.206958, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 553/655, Loss: 2.207110, Accuracy: 18.68%\n",
            "Epoch: 31, Step: 554/655, Loss: 2.207535, Accuracy: 18.67%\n",
            "Epoch: 31, Step: 555/655, Loss: 2.207555, Accuracy: 18.65%\n",
            "Epoch: 31, Step: 556/655, Loss: 2.207668, Accuracy: 18.64%\n",
            "Epoch: 31, Step: 557/655, Loss: 2.207838, Accuracy: 18.63%\n",
            "Epoch: 31, Step: 558/655, Loss: 2.207995, Accuracy: 18.63%\n",
            "Epoch: 31, Step: 559/655, Loss: 2.208030, Accuracy: 18.62%\n",
            "Epoch: 31, Step: 560/655, Loss: 2.208012, Accuracy: 18.64%\n",
            "Epoch: 31, Step: 561/655, Loss: 2.208083, Accuracy: 18.62%\n",
            "Epoch: 31, Step: 562/655, Loss: 2.207997, Accuracy: 18.63%\n",
            "Epoch: 31, Step: 563/655, Loss: 2.207957, Accuracy: 18.64%\n",
            "Epoch: 31, Step: 564/655, Loss: 2.207964, Accuracy: 18.65%\n",
            "Epoch: 31, Step: 565/655, Loss: 2.207816, Accuracy: 18.66%\n",
            "Epoch: 31, Step: 566/655, Loss: 2.207908, Accuracy: 18.66%\n",
            "Epoch: 31, Step: 567/655, Loss: 2.208004, Accuracy: 18.66%\n",
            "Epoch: 31, Step: 568/655, Loss: 2.207929, Accuracy: 18.66%\n",
            "Epoch: 31, Step: 569/655, Loss: 2.207731, Accuracy: 18.68%\n",
            "Epoch: 31, Step: 570/655, Loss: 2.207707, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 571/655, Loss: 2.207803, Accuracy: 18.68%\n",
            "Epoch: 31, Step: 572/655, Loss: 2.207879, Accuracy: 18.67%\n",
            "Epoch: 31, Step: 573/655, Loss: 2.207780, Accuracy: 18.67%\n",
            "Epoch: 31, Step: 574/655, Loss: 2.207589, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 575/655, Loss: 2.207697, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 576/655, Loss: 2.207662, Accuracy: 18.68%\n",
            "Epoch: 31, Step: 577/655, Loss: 2.207723, Accuracy: 18.69%\n",
            "Epoch: 31, Step: 578/655, Loss: 2.207758, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 579/655, Loss: 2.208088, Accuracy: 18.67%\n",
            "Epoch: 31, Step: 580/655, Loss: 2.207985, Accuracy: 18.67%\n",
            "Epoch: 31, Step: 581/655, Loss: 2.208088, Accuracy: 18.65%\n",
            "Epoch: 31, Step: 582/655, Loss: 2.208310, Accuracy: 18.63%\n",
            "Epoch: 31, Step: 583/655, Loss: 2.208132, Accuracy: 18.64%\n",
            "Epoch: 31, Step: 584/655, Loss: 2.207992, Accuracy: 18.66%\n",
            "Epoch: 31, Step: 585/655, Loss: 2.207932, Accuracy: 18.65%\n",
            "Epoch: 31, Step: 586/655, Loss: 2.207952, Accuracy: 18.64%\n",
            "Epoch: 31, Step: 587/655, Loss: 2.207796, Accuracy: 18.66%\n",
            "Epoch: 31, Step: 588/655, Loss: 2.207681, Accuracy: 18.67%\n",
            "Epoch: 31, Step: 589/655, Loss: 2.207449, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 590/655, Loss: 2.207707, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 591/655, Loss: 2.207727, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 592/655, Loss: 2.207773, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 593/655, Loss: 2.207679, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 594/655, Loss: 2.207448, Accuracy: 18.74%\n",
            "Epoch: 31, Step: 595/655, Loss: 2.207397, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 596/655, Loss: 2.207462, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 597/655, Loss: 2.207632, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 598/655, Loss: 2.207605, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 599/655, Loss: 2.207509, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 600/655, Loss: 2.207526, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 601/655, Loss: 2.207576, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 602/655, Loss: 2.207472, Accuracy: 18.74%\n",
            "Epoch: 31, Step: 603/655, Loss: 2.207362, Accuracy: 18.73%\n",
            "Epoch: 31, Step: 604/655, Loss: 2.207173, Accuracy: 18.73%\n",
            "Epoch: 31, Step: 605/655, Loss: 2.207252, Accuracy: 18.73%\n",
            "Epoch: 31, Step: 606/655, Loss: 2.207298, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 607/655, Loss: 2.207307, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 608/655, Loss: 2.207308, Accuracy: 18.73%\n",
            "Epoch: 31, Step: 609/655, Loss: 2.207432, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 610/655, Loss: 2.207366, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 611/655, Loss: 2.207381, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 612/655, Loss: 2.207347, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 613/655, Loss: 2.207496, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 614/655, Loss: 2.207349, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 615/655, Loss: 2.207413, Accuracy: 18.73%\n",
            "Epoch: 31, Step: 616/655, Loss: 2.207605, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 617/655, Loss: 2.207476, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 618/655, Loss: 2.207478, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 619/655, Loss: 2.207390, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 620/655, Loss: 2.207468, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 621/655, Loss: 2.207402, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 622/655, Loss: 2.207339, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 623/655, Loss: 2.207134, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 624/655, Loss: 2.207088, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 625/655, Loss: 2.207079, Accuracy: 18.73%\n",
            "Epoch: 31, Step: 626/655, Loss: 2.206902, Accuracy: 18.73%\n",
            "Epoch: 31, Step: 627/655, Loss: 2.207105, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 628/655, Loss: 2.206939, Accuracy: 18.73%\n",
            "Epoch: 31, Step: 629/655, Loss: 2.207130, Accuracy: 18.73%\n",
            "Epoch: 31, Step: 630/655, Loss: 2.207303, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 631/655, Loss: 2.207254, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 632/655, Loss: 2.207213, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 633/655, Loss: 2.207341, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 634/655, Loss: 2.207443, Accuracy: 18.69%\n",
            "Epoch: 31, Step: 635/655, Loss: 2.207264, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 636/655, Loss: 2.207323, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 637/655, Loss: 2.207445, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 638/655, Loss: 2.207286, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 639/655, Loss: 2.207401, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 640/655, Loss: 2.207262, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 641/655, Loss: 2.207237, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 642/655, Loss: 2.207258, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 643/655, Loss: 2.207382, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 644/655, Loss: 2.207456, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 645/655, Loss: 2.207416, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 646/655, Loss: 2.207176, Accuracy: 18.73%\n",
            "Epoch: 31, Step: 647/655, Loss: 2.207044, Accuracy: 18.73%\n",
            "Epoch: 31, Step: 648/655, Loss: 2.207240, Accuracy: 18.73%\n",
            "Epoch: 31, Step: 649/655, Loss: 2.207185, Accuracy: 18.73%\n",
            "Epoch: 31, Step: 650/655, Loss: 2.207377, Accuracy: 18.72%\n",
            "Epoch: 31, Step: 651/655, Loss: 2.207446, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 652/655, Loss: 2.207498, Accuracy: 18.70%\n",
            "Epoch: 31, Step: 653/655, Loss: 2.207528, Accuracy: 18.71%\n",
            "Epoch: 31, Step: 654/655, Loss: 2.207598, Accuracy: 18.69%\n",
            "Epoch: 31, Step: 655/655, Loss: 2.207563, Accuracy: 18.70%\n",
            "Epoch: 32, Step: 1/655, Loss: 2.172684, Accuracy: 25.00%\n",
            "Epoch: 32, Step: 2/655, Loss: 2.226757, Accuracy: 15.62%\n",
            "Epoch: 32, Step: 3/655, Loss: 2.223521, Accuracy: 15.62%\n",
            "Epoch: 32, Step: 4/655, Loss: 2.244769, Accuracy: 14.06%\n",
            "Epoch: 32, Step: 5/655, Loss: 2.242912, Accuracy: 16.25%\n",
            "Epoch: 32, Step: 6/655, Loss: 2.222945, Accuracy: 15.62%\n",
            "Epoch: 32, Step: 7/655, Loss: 2.208897, Accuracy: 16.07%\n",
            "Epoch: 32, Step: 8/655, Loss: 2.203017, Accuracy: 14.84%\n",
            "Epoch: 32, Step: 9/655, Loss: 2.201652, Accuracy: 14.93%\n",
            "Epoch: 32, Step: 10/655, Loss: 2.193340, Accuracy: 15.94%\n",
            "Epoch: 32, Step: 11/655, Loss: 2.198025, Accuracy: 16.48%\n",
            "Epoch: 32, Step: 12/655, Loss: 2.204427, Accuracy: 16.67%\n",
            "Epoch: 32, Step: 13/655, Loss: 2.206438, Accuracy: 16.35%\n",
            "Epoch: 32, Step: 14/655, Loss: 2.193416, Accuracy: 17.19%\n",
            "Epoch: 32, Step: 15/655, Loss: 2.194812, Accuracy: 17.50%\n",
            "Epoch: 32, Step: 16/655, Loss: 2.199484, Accuracy: 17.58%\n",
            "Epoch: 32, Step: 17/655, Loss: 2.199778, Accuracy: 17.28%\n",
            "Epoch: 32, Step: 18/655, Loss: 2.193749, Accuracy: 17.36%\n",
            "Epoch: 32, Step: 19/655, Loss: 2.198545, Accuracy: 17.60%\n",
            "Epoch: 32, Step: 20/655, Loss: 2.197889, Accuracy: 17.81%\n",
            "Epoch: 32, Step: 21/655, Loss: 2.195327, Accuracy: 17.86%\n",
            "Epoch: 32, Step: 22/655, Loss: 2.197217, Accuracy: 17.90%\n",
            "Epoch: 32, Step: 23/655, Loss: 2.195578, Accuracy: 17.93%\n",
            "Epoch: 32, Step: 24/655, Loss: 2.197278, Accuracy: 17.58%\n",
            "Epoch: 32, Step: 25/655, Loss: 2.197660, Accuracy: 17.50%\n",
            "Epoch: 32, Step: 26/655, Loss: 2.197630, Accuracy: 17.79%\n",
            "Epoch: 32, Step: 27/655, Loss: 2.197993, Accuracy: 17.94%\n",
            "Epoch: 32, Step: 28/655, Loss: 2.196320, Accuracy: 18.19%\n",
            "Epoch: 32, Step: 29/655, Loss: 2.198230, Accuracy: 18.10%\n",
            "Epoch: 32, Step: 30/655, Loss: 2.192797, Accuracy: 18.23%\n",
            "Epoch: 32, Step: 31/655, Loss: 2.190326, Accuracy: 18.45%\n",
            "Epoch: 32, Step: 32/655, Loss: 2.185427, Accuracy: 18.75%\n",
            "Epoch: 32, Step: 33/655, Loss: 2.186451, Accuracy: 19.03%\n",
            "Epoch: 32, Step: 34/655, Loss: 2.189612, Accuracy: 19.03%\n",
            "Epoch: 32, Step: 35/655, Loss: 2.190108, Accuracy: 18.93%\n",
            "Epoch: 32, Step: 36/655, Loss: 2.192361, Accuracy: 18.58%\n",
            "Epoch: 32, Step: 37/655, Loss: 2.191683, Accuracy: 18.75%\n",
            "Epoch: 32, Step: 38/655, Loss: 2.191492, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 39/655, Loss: 2.188375, Accuracy: 18.43%\n",
            "Epoch: 32, Step: 40/655, Loss: 2.189978, Accuracy: 18.52%\n",
            "Epoch: 32, Step: 41/655, Loss: 2.189488, Accuracy: 18.52%\n",
            "Epoch: 32, Step: 42/655, Loss: 2.190221, Accuracy: 18.60%\n",
            "Epoch: 32, Step: 43/655, Loss: 2.191459, Accuracy: 18.68%\n",
            "Epoch: 32, Step: 44/655, Loss: 2.191056, Accuracy: 18.89%\n",
            "Epoch: 32, Step: 45/655, Loss: 2.191593, Accuracy: 19.03%\n",
            "Epoch: 32, Step: 46/655, Loss: 2.194808, Accuracy: 18.95%\n",
            "Epoch: 32, Step: 47/655, Loss: 2.196045, Accuracy: 18.95%\n",
            "Epoch: 32, Step: 48/655, Loss: 2.196819, Accuracy: 18.95%\n",
            "Epoch: 32, Step: 49/655, Loss: 2.197972, Accuracy: 18.94%\n",
            "Epoch: 32, Step: 50/655, Loss: 2.197645, Accuracy: 19.19%\n",
            "Epoch: 32, Step: 51/655, Loss: 2.197557, Accuracy: 19.42%\n",
            "Epoch: 32, Step: 52/655, Loss: 2.196247, Accuracy: 19.41%\n",
            "Epoch: 32, Step: 53/655, Loss: 2.196754, Accuracy: 19.52%\n",
            "Epoch: 32, Step: 54/655, Loss: 2.196109, Accuracy: 19.39%\n",
            "Epoch: 32, Step: 55/655, Loss: 2.195217, Accuracy: 19.43%\n",
            "Epoch: 32, Step: 56/655, Loss: 2.193901, Accuracy: 19.42%\n",
            "Epoch: 32, Step: 57/655, Loss: 2.192086, Accuracy: 19.52%\n",
            "Epoch: 32, Step: 58/655, Loss: 2.189955, Accuracy: 19.72%\n",
            "Epoch: 32, Step: 59/655, Loss: 2.189984, Accuracy: 19.92%\n",
            "Epoch: 32, Step: 60/655, Loss: 2.189515, Accuracy: 19.84%\n",
            "Epoch: 32, Step: 61/655, Loss: 2.188691, Accuracy: 19.72%\n",
            "Epoch: 32, Step: 62/655, Loss: 2.188763, Accuracy: 19.71%\n",
            "Epoch: 32, Step: 63/655, Loss: 2.189026, Accuracy: 19.59%\n",
            "Epoch: 32, Step: 64/655, Loss: 2.187826, Accuracy: 19.73%\n",
            "Epoch: 32, Step: 65/655, Loss: 2.187802, Accuracy: 19.71%\n",
            "Epoch: 32, Step: 66/655, Loss: 2.189082, Accuracy: 19.65%\n",
            "Epoch: 32, Step: 67/655, Loss: 2.188126, Accuracy: 19.68%\n",
            "Epoch: 32, Step: 68/655, Loss: 2.188006, Accuracy: 19.58%\n",
            "Epoch: 32, Step: 69/655, Loss: 2.188448, Accuracy: 19.52%\n",
            "Epoch: 32, Step: 70/655, Loss: 2.189088, Accuracy: 19.60%\n",
            "Epoch: 32, Step: 71/655, Loss: 2.190258, Accuracy: 19.59%\n",
            "Epoch: 32, Step: 72/655, Loss: 2.191901, Accuracy: 19.53%\n",
            "Epoch: 32, Step: 73/655, Loss: 2.192167, Accuracy: 19.39%\n",
            "Epoch: 32, Step: 74/655, Loss: 2.192535, Accuracy: 19.34%\n",
            "Epoch: 32, Step: 75/655, Loss: 2.192916, Accuracy: 19.38%\n",
            "Epoch: 32, Step: 76/655, Loss: 2.194414, Accuracy: 19.33%\n",
            "Epoch: 32, Step: 77/655, Loss: 2.194335, Accuracy: 19.36%\n",
            "Epoch: 32, Step: 78/655, Loss: 2.194352, Accuracy: 19.31%\n",
            "Epoch: 32, Step: 79/655, Loss: 2.196288, Accuracy: 19.15%\n",
            "Epoch: 32, Step: 80/655, Loss: 2.195916, Accuracy: 19.06%\n",
            "Epoch: 32, Step: 81/655, Loss: 2.195233, Accuracy: 18.94%\n",
            "Epoch: 32, Step: 82/655, Loss: 2.195140, Accuracy: 19.05%\n",
            "Epoch: 32, Step: 83/655, Loss: 2.194960, Accuracy: 19.09%\n",
            "Epoch: 32, Step: 84/655, Loss: 2.195722, Accuracy: 19.05%\n",
            "Epoch: 32, Step: 85/655, Loss: 2.197232, Accuracy: 18.93%\n",
            "Epoch: 32, Step: 86/655, Loss: 2.197571, Accuracy: 18.97%\n",
            "Epoch: 32, Step: 87/655, Loss: 2.197048, Accuracy: 18.89%\n",
            "Epoch: 32, Step: 88/655, Loss: 2.196872, Accuracy: 18.96%\n",
            "Epoch: 32, Step: 89/655, Loss: 2.195894, Accuracy: 19.00%\n",
            "Epoch: 32, Step: 90/655, Loss: 2.196954, Accuracy: 18.89%\n",
            "Epoch: 32, Step: 91/655, Loss: 2.198745, Accuracy: 18.75%\n",
            "Epoch: 32, Step: 92/655, Loss: 2.199670, Accuracy: 18.68%\n",
            "Epoch: 32, Step: 93/655, Loss: 2.200332, Accuracy: 18.65%\n",
            "Epoch: 32, Step: 94/655, Loss: 2.200768, Accuracy: 18.58%\n",
            "Epoch: 32, Step: 95/655, Loss: 2.200115, Accuracy: 18.75%\n",
            "Epoch: 32, Step: 96/655, Loss: 2.200663, Accuracy: 18.72%\n",
            "Epoch: 32, Step: 97/655, Loss: 2.200441, Accuracy: 18.69%\n",
            "Epoch: 32, Step: 98/655, Loss: 2.199804, Accuracy: 18.75%\n",
            "Epoch: 32, Step: 99/655, Loss: 2.199310, Accuracy: 18.75%\n",
            "Epoch: 32, Step: 100/655, Loss: 2.199772, Accuracy: 18.78%\n",
            "Epoch: 32, Step: 101/655, Loss: 2.200514, Accuracy: 18.75%\n",
            "Epoch: 32, Step: 102/655, Loss: 2.202020, Accuracy: 18.72%\n",
            "Epoch: 32, Step: 103/655, Loss: 2.203802, Accuracy: 18.60%\n",
            "Epoch: 32, Step: 104/655, Loss: 2.204523, Accuracy: 18.51%\n",
            "Epoch: 32, Step: 105/655, Loss: 2.204554, Accuracy: 18.57%\n",
            "Epoch: 32, Step: 106/655, Loss: 2.204894, Accuracy: 18.60%\n",
            "Epoch: 32, Step: 107/655, Loss: 2.204296, Accuracy: 18.72%\n",
            "Epoch: 32, Step: 108/655, Loss: 2.202994, Accuracy: 18.87%\n",
            "Epoch: 32, Step: 109/655, Loss: 2.202105, Accuracy: 18.89%\n",
            "Epoch: 32, Step: 110/655, Loss: 2.201411, Accuracy: 18.95%\n",
            "Epoch: 32, Step: 111/655, Loss: 2.201900, Accuracy: 18.89%\n",
            "Epoch: 32, Step: 112/655, Loss: 2.202107, Accuracy: 18.92%\n",
            "Epoch: 32, Step: 113/655, Loss: 2.201731, Accuracy: 18.92%\n",
            "Epoch: 32, Step: 114/655, Loss: 2.201185, Accuracy: 18.83%\n",
            "Epoch: 32, Step: 115/655, Loss: 2.201761, Accuracy: 18.83%\n",
            "Epoch: 32, Step: 116/655, Loss: 2.201987, Accuracy: 18.72%\n",
            "Epoch: 32, Step: 117/655, Loss: 2.202003, Accuracy: 18.78%\n",
            "Epoch: 32, Step: 118/655, Loss: 2.202096, Accuracy: 18.80%\n",
            "Epoch: 32, Step: 119/655, Loss: 2.201747, Accuracy: 18.80%\n",
            "Epoch: 32, Step: 120/655, Loss: 2.201152, Accuracy: 18.85%\n",
            "Epoch: 32, Step: 121/655, Loss: 2.200721, Accuracy: 18.83%\n",
            "Epoch: 32, Step: 122/655, Loss: 2.200942, Accuracy: 18.78%\n",
            "Epoch: 32, Step: 123/655, Loss: 2.201127, Accuracy: 18.78%\n",
            "Epoch: 32, Step: 124/655, Loss: 2.201000, Accuracy: 18.85%\n",
            "Epoch: 32, Step: 125/655, Loss: 2.199668, Accuracy: 18.88%\n",
            "Epoch: 32, Step: 126/655, Loss: 2.199600, Accuracy: 18.92%\n",
            "Epoch: 32, Step: 127/655, Loss: 2.199240, Accuracy: 18.97%\n",
            "Epoch: 32, Step: 128/655, Loss: 2.198819, Accuracy: 19.07%\n",
            "Epoch: 32, Step: 129/655, Loss: 2.199261, Accuracy: 19.02%\n",
            "Epoch: 32, Step: 130/655, Loss: 2.199067, Accuracy: 19.04%\n",
            "Epoch: 32, Step: 131/655, Loss: 2.199316, Accuracy: 18.99%\n",
            "Epoch: 32, Step: 132/655, Loss: 2.199734, Accuracy: 18.89%\n",
            "Epoch: 32, Step: 133/655, Loss: 2.198587, Accuracy: 18.94%\n",
            "Epoch: 32, Step: 134/655, Loss: 2.198763, Accuracy: 18.94%\n",
            "Epoch: 32, Step: 135/655, Loss: 2.198507, Accuracy: 18.98%\n",
            "Epoch: 32, Step: 136/655, Loss: 2.197476, Accuracy: 19.07%\n",
            "Epoch: 32, Step: 137/655, Loss: 2.197778, Accuracy: 19.07%\n",
            "Epoch: 32, Step: 138/655, Loss: 2.198836, Accuracy: 19.04%\n",
            "Epoch: 32, Step: 139/655, Loss: 2.198158, Accuracy: 19.04%\n",
            "Epoch: 32, Step: 140/655, Loss: 2.198830, Accuracy: 18.95%\n",
            "Epoch: 32, Step: 141/655, Loss: 2.198108, Accuracy: 18.93%\n",
            "Epoch: 32, Step: 142/655, Loss: 2.198227, Accuracy: 18.95%\n",
            "Epoch: 32, Step: 143/655, Loss: 2.198681, Accuracy: 18.92%\n",
            "Epoch: 32, Step: 144/655, Loss: 2.199147, Accuracy: 18.97%\n",
            "Epoch: 32, Step: 145/655, Loss: 2.200254, Accuracy: 18.92%\n",
            "Epoch: 32, Step: 146/655, Loss: 2.200790, Accuracy: 18.86%\n",
            "Epoch: 32, Step: 147/655, Loss: 2.200772, Accuracy: 18.92%\n",
            "Epoch: 32, Step: 148/655, Loss: 2.200963, Accuracy: 18.88%\n",
            "Epoch: 32, Step: 149/655, Loss: 2.200400, Accuracy: 18.92%\n",
            "Epoch: 32, Step: 150/655, Loss: 2.200708, Accuracy: 18.94%\n",
            "Epoch: 32, Step: 151/655, Loss: 2.200229, Accuracy: 18.89%\n",
            "Epoch: 32, Step: 152/655, Loss: 2.200253, Accuracy: 18.87%\n",
            "Epoch: 32, Step: 153/655, Loss: 2.200247, Accuracy: 18.85%\n",
            "Epoch: 32, Step: 154/655, Loss: 2.199602, Accuracy: 18.89%\n",
            "Epoch: 32, Step: 155/655, Loss: 2.199939, Accuracy: 18.87%\n",
            "Epoch: 32, Step: 156/655, Loss: 2.199745, Accuracy: 18.87%\n",
            "Epoch: 32, Step: 157/655, Loss: 2.199644, Accuracy: 18.87%\n",
            "Epoch: 32, Step: 158/655, Loss: 2.199805, Accuracy: 18.85%\n",
            "Epoch: 32, Step: 159/655, Loss: 2.199901, Accuracy: 18.85%\n",
            "Epoch: 32, Step: 160/655, Loss: 2.199594, Accuracy: 18.87%\n",
            "Epoch: 32, Step: 161/655, Loss: 2.200184, Accuracy: 18.87%\n",
            "Epoch: 32, Step: 162/655, Loss: 2.199674, Accuracy: 18.89%\n",
            "Epoch: 32, Step: 163/655, Loss: 2.200064, Accuracy: 18.85%\n",
            "Epoch: 32, Step: 164/655, Loss: 2.200086, Accuracy: 18.81%\n",
            "Epoch: 32, Step: 165/655, Loss: 2.200613, Accuracy: 18.79%\n",
            "Epoch: 32, Step: 166/655, Loss: 2.201138, Accuracy: 18.71%\n",
            "Epoch: 32, Step: 167/655, Loss: 2.201015, Accuracy: 18.68%\n",
            "Epoch: 32, Step: 168/655, Loss: 2.201195, Accuracy: 18.68%\n",
            "Epoch: 32, Step: 169/655, Loss: 2.199925, Accuracy: 18.71%\n",
            "Epoch: 32, Step: 170/655, Loss: 2.199647, Accuracy: 18.79%\n",
            "Epoch: 32, Step: 171/655, Loss: 2.199697, Accuracy: 18.84%\n",
            "Epoch: 32, Step: 172/655, Loss: 2.199924, Accuracy: 18.84%\n",
            "Epoch: 32, Step: 173/655, Loss: 2.199999, Accuracy: 18.77%\n",
            "Epoch: 32, Step: 174/655, Loss: 2.200605, Accuracy: 18.73%\n",
            "Epoch: 32, Step: 175/655, Loss: 2.201013, Accuracy: 18.71%\n",
            "Epoch: 32, Step: 176/655, Loss: 2.201377, Accuracy: 18.68%\n",
            "Epoch: 32, Step: 177/655, Loss: 2.201113, Accuracy: 18.66%\n",
            "Epoch: 32, Step: 178/655, Loss: 2.201185, Accuracy: 18.71%\n",
            "Epoch: 32, Step: 179/655, Loss: 2.201709, Accuracy: 18.66%\n",
            "Epoch: 32, Step: 180/655, Loss: 2.202151, Accuracy: 18.63%\n",
            "Epoch: 32, Step: 181/655, Loss: 2.201836, Accuracy: 18.61%\n",
            "Epoch: 32, Step: 182/655, Loss: 2.202854, Accuracy: 18.54%\n",
            "Epoch: 32, Step: 183/655, Loss: 2.203247, Accuracy: 18.55%\n",
            "Epoch: 32, Step: 184/655, Loss: 2.203477, Accuracy: 18.53%\n",
            "Epoch: 32, Step: 185/655, Loss: 2.203209, Accuracy: 18.58%\n",
            "Epoch: 32, Step: 186/655, Loss: 2.203377, Accuracy: 18.57%\n",
            "Epoch: 32, Step: 187/655, Loss: 2.204045, Accuracy: 18.55%\n",
            "Epoch: 32, Step: 188/655, Loss: 2.204415, Accuracy: 18.55%\n",
            "Epoch: 32, Step: 189/655, Loss: 2.204278, Accuracy: 18.54%\n",
            "Epoch: 32, Step: 190/655, Loss: 2.204256, Accuracy: 18.50%\n",
            "Epoch: 32, Step: 191/655, Loss: 2.204922, Accuracy: 18.50%\n",
            "Epoch: 32, Step: 192/655, Loss: 2.204817, Accuracy: 18.46%\n",
            "Epoch: 32, Step: 193/655, Loss: 2.204924, Accuracy: 18.47%\n",
            "Epoch: 32, Step: 194/655, Loss: 2.204903, Accuracy: 18.49%\n",
            "Epoch: 32, Step: 195/655, Loss: 2.204738, Accuracy: 18.53%\n",
            "Epoch: 32, Step: 196/655, Loss: 2.204852, Accuracy: 18.53%\n",
            "Epoch: 32, Step: 197/655, Loss: 2.204466, Accuracy: 18.54%\n",
            "Epoch: 32, Step: 198/655, Loss: 2.203656, Accuracy: 18.61%\n",
            "Epoch: 32, Step: 199/655, Loss: 2.203979, Accuracy: 18.62%\n",
            "Epoch: 32, Step: 200/655, Loss: 2.204224, Accuracy: 18.59%\n",
            "Epoch: 32, Step: 201/655, Loss: 2.203963, Accuracy: 18.64%\n",
            "Epoch: 32, Step: 202/655, Loss: 2.204638, Accuracy: 18.61%\n",
            "Epoch: 32, Step: 203/655, Loss: 2.204853, Accuracy: 18.63%\n",
            "Epoch: 32, Step: 204/655, Loss: 2.205680, Accuracy: 18.57%\n",
            "Epoch: 32, Step: 205/655, Loss: 2.205720, Accuracy: 18.55%\n",
            "Epoch: 32, Step: 206/655, Loss: 2.205732, Accuracy: 18.52%\n",
            "Epoch: 32, Step: 207/655, Loss: 2.205919, Accuracy: 18.49%\n",
            "Epoch: 32, Step: 208/655, Loss: 2.206385, Accuracy: 18.45%\n",
            "Epoch: 32, Step: 209/655, Loss: 2.206032, Accuracy: 18.51%\n",
            "Epoch: 32, Step: 210/655, Loss: 2.205696, Accuracy: 18.59%\n",
            "Epoch: 32, Step: 211/655, Loss: 2.205311, Accuracy: 18.60%\n",
            "Epoch: 32, Step: 212/655, Loss: 2.205208, Accuracy: 18.56%\n",
            "Epoch: 32, Step: 213/655, Loss: 2.204920, Accuracy: 18.57%\n",
            "Epoch: 32, Step: 214/655, Loss: 2.204837, Accuracy: 18.59%\n",
            "Epoch: 32, Step: 215/655, Loss: 2.205074, Accuracy: 18.55%\n",
            "Epoch: 32, Step: 216/655, Loss: 2.204797, Accuracy: 18.61%\n",
            "Epoch: 32, Step: 217/655, Loss: 2.205456, Accuracy: 18.55%\n",
            "Epoch: 32, Step: 218/655, Loss: 2.205441, Accuracy: 18.55%\n",
            "Epoch: 32, Step: 219/655, Loss: 2.205217, Accuracy: 18.59%\n",
            "Epoch: 32, Step: 220/655, Loss: 2.204993, Accuracy: 18.66%\n",
            "Epoch: 32, Step: 221/655, Loss: 2.205316, Accuracy: 18.64%\n",
            "Epoch: 32, Step: 222/655, Loss: 2.205446, Accuracy: 18.64%\n",
            "Epoch: 32, Step: 223/655, Loss: 2.205477, Accuracy: 18.64%\n",
            "Epoch: 32, Step: 224/655, Loss: 2.205703, Accuracy: 18.61%\n",
            "Epoch: 32, Step: 225/655, Loss: 2.206464, Accuracy: 18.60%\n",
            "Epoch: 32, Step: 226/655, Loss: 2.206566, Accuracy: 18.61%\n",
            "Epoch: 32, Step: 227/655, Loss: 2.206707, Accuracy: 18.61%\n",
            "Epoch: 32, Step: 228/655, Loss: 2.206327, Accuracy: 18.67%\n",
            "Epoch: 32, Step: 229/655, Loss: 2.206096, Accuracy: 18.64%\n",
            "Epoch: 32, Step: 230/655, Loss: 2.206324, Accuracy: 18.65%\n",
            "Epoch: 32, Step: 231/655, Loss: 2.206519, Accuracy: 18.63%\n",
            "Epoch: 32, Step: 232/655, Loss: 2.206039, Accuracy: 18.60%\n",
            "Epoch: 32, Step: 233/655, Loss: 2.205261, Accuracy: 18.70%\n",
            "Epoch: 32, Step: 234/655, Loss: 2.205167, Accuracy: 18.70%\n",
            "Epoch: 32, Step: 235/655, Loss: 2.204926, Accuracy: 18.68%\n",
            "Epoch: 32, Step: 236/655, Loss: 2.204424, Accuracy: 18.68%\n",
            "Epoch: 32, Step: 237/655, Loss: 2.204032, Accuracy: 18.70%\n",
            "Epoch: 32, Step: 238/655, Loss: 2.204038, Accuracy: 18.71%\n",
            "Epoch: 32, Step: 239/655, Loss: 2.204371, Accuracy: 18.71%\n",
            "Epoch: 32, Step: 240/655, Loss: 2.204521, Accuracy: 18.74%\n",
            "Epoch: 32, Step: 241/655, Loss: 2.204640, Accuracy: 18.70%\n",
            "Epoch: 32, Step: 242/655, Loss: 2.204536, Accuracy: 18.67%\n",
            "Epoch: 32, Step: 243/655, Loss: 2.204593, Accuracy: 18.66%\n",
            "Epoch: 32, Step: 244/655, Loss: 2.204632, Accuracy: 18.63%\n",
            "Epoch: 32, Step: 245/655, Loss: 2.204384, Accuracy: 18.64%\n",
            "Epoch: 32, Step: 246/655, Loss: 2.204010, Accuracy: 18.60%\n",
            "Epoch: 32, Step: 247/655, Loss: 2.204410, Accuracy: 18.56%\n",
            "Epoch: 32, Step: 248/655, Loss: 2.203774, Accuracy: 18.59%\n",
            "Epoch: 32, Step: 249/655, Loss: 2.203316, Accuracy: 18.65%\n",
            "Epoch: 32, Step: 250/655, Loss: 2.203606, Accuracy: 18.61%\n",
            "Epoch: 32, Step: 251/655, Loss: 2.203647, Accuracy: 18.59%\n",
            "Epoch: 32, Step: 252/655, Loss: 2.203447, Accuracy: 18.59%\n",
            "Epoch: 32, Step: 253/655, Loss: 2.203064, Accuracy: 18.61%\n",
            "Epoch: 32, Step: 254/655, Loss: 2.203100, Accuracy: 18.61%\n",
            "Epoch: 32, Step: 255/655, Loss: 2.202825, Accuracy: 18.64%\n",
            "Epoch: 32, Step: 256/655, Loss: 2.202998, Accuracy: 18.64%\n",
            "Epoch: 32, Step: 257/655, Loss: 2.203360, Accuracy: 18.65%\n",
            "Epoch: 32, Step: 258/655, Loss: 2.203013, Accuracy: 18.63%\n",
            "Epoch: 32, Step: 259/655, Loss: 2.203221, Accuracy: 18.63%\n",
            "Epoch: 32, Step: 260/655, Loss: 2.203564, Accuracy: 18.61%\n",
            "Epoch: 32, Step: 261/655, Loss: 2.203662, Accuracy: 18.58%\n",
            "Epoch: 32, Step: 262/655, Loss: 2.203858, Accuracy: 18.57%\n",
            "Epoch: 32, Step: 263/655, Loss: 2.204688, Accuracy: 18.52%\n",
            "Epoch: 32, Step: 264/655, Loss: 2.204252, Accuracy: 18.60%\n",
            "Epoch: 32, Step: 265/655, Loss: 2.204270, Accuracy: 18.60%\n",
            "Epoch: 32, Step: 266/655, Loss: 2.204432, Accuracy: 18.62%\n",
            "Epoch: 32, Step: 267/655, Loss: 2.204035, Accuracy: 18.60%\n",
            "Epoch: 32, Step: 268/655, Loss: 2.204180, Accuracy: 18.61%\n",
            "Epoch: 32, Step: 269/655, Loss: 2.204316, Accuracy: 18.61%\n",
            "Epoch: 32, Step: 270/655, Loss: 2.204104, Accuracy: 18.60%\n",
            "Epoch: 32, Step: 271/655, Loss: 2.204088, Accuracy: 18.59%\n",
            "Epoch: 32, Step: 272/655, Loss: 2.204321, Accuracy: 18.57%\n",
            "Epoch: 32, Step: 273/655, Loss: 2.204347, Accuracy: 18.58%\n",
            "Epoch: 32, Step: 274/655, Loss: 2.204292, Accuracy: 18.56%\n",
            "Epoch: 32, Step: 275/655, Loss: 2.204883, Accuracy: 18.51%\n",
            "Epoch: 32, Step: 276/655, Loss: 2.204984, Accuracy: 18.50%\n",
            "Epoch: 32, Step: 277/655, Loss: 2.204504, Accuracy: 18.55%\n",
            "Epoch: 32, Step: 278/655, Loss: 2.204517, Accuracy: 18.53%\n",
            "Epoch: 32, Step: 279/655, Loss: 2.204660, Accuracy: 18.51%\n",
            "Epoch: 32, Step: 280/655, Loss: 2.204074, Accuracy: 18.53%\n",
            "Epoch: 32, Step: 281/655, Loss: 2.203799, Accuracy: 18.52%\n",
            "Epoch: 32, Step: 282/655, Loss: 2.203695, Accuracy: 18.52%\n",
            "Epoch: 32, Step: 283/655, Loss: 2.203957, Accuracy: 18.50%\n",
            "Epoch: 32, Step: 284/655, Loss: 2.204270, Accuracy: 18.46%\n",
            "Epoch: 32, Step: 285/655, Loss: 2.204601, Accuracy: 18.44%\n",
            "Epoch: 32, Step: 286/655, Loss: 2.204551, Accuracy: 18.47%\n",
            "Epoch: 32, Step: 287/655, Loss: 2.204829, Accuracy: 18.45%\n",
            "Epoch: 32, Step: 288/655, Loss: 2.204718, Accuracy: 18.46%\n",
            "Epoch: 32, Step: 289/655, Loss: 2.204901, Accuracy: 18.44%\n",
            "Epoch: 32, Step: 290/655, Loss: 2.204747, Accuracy: 18.45%\n",
            "Epoch: 32, Step: 291/655, Loss: 2.204798, Accuracy: 18.45%\n",
            "Epoch: 32, Step: 292/655, Loss: 2.204506, Accuracy: 18.47%\n",
            "Epoch: 32, Step: 293/655, Loss: 2.204504, Accuracy: 18.43%\n",
            "Epoch: 32, Step: 294/655, Loss: 2.204835, Accuracy: 18.40%\n",
            "Epoch: 32, Step: 295/655, Loss: 2.204600, Accuracy: 18.39%\n",
            "Epoch: 32, Step: 296/655, Loss: 2.204845, Accuracy: 18.39%\n",
            "Epoch: 32, Step: 297/655, Loss: 2.204945, Accuracy: 18.38%\n",
            "Epoch: 32, Step: 298/655, Loss: 2.204645, Accuracy: 18.41%\n",
            "Epoch: 32, Step: 299/655, Loss: 2.204871, Accuracy: 18.42%\n",
            "Epoch: 32, Step: 300/655, Loss: 2.205128, Accuracy: 18.42%\n",
            "Epoch: 32, Step: 301/655, Loss: 2.204786, Accuracy: 18.43%\n",
            "Epoch: 32, Step: 302/655, Loss: 2.204858, Accuracy: 18.46%\n",
            "Epoch: 32, Step: 303/655, Loss: 2.205263, Accuracy: 18.45%\n",
            "Epoch: 32, Step: 304/655, Loss: 2.204968, Accuracy: 18.47%\n",
            "Epoch: 32, Step: 305/655, Loss: 2.204613, Accuracy: 18.45%\n",
            "Epoch: 32, Step: 306/655, Loss: 2.204609, Accuracy: 18.46%\n",
            "Epoch: 32, Step: 307/655, Loss: 2.204667, Accuracy: 18.43%\n",
            "Epoch: 32, Step: 308/655, Loss: 2.204485, Accuracy: 18.39%\n",
            "Epoch: 32, Step: 309/655, Loss: 2.204270, Accuracy: 18.38%\n",
            "Epoch: 32, Step: 310/655, Loss: 2.204024, Accuracy: 18.37%\n",
            "Epoch: 32, Step: 311/655, Loss: 2.203977, Accuracy: 18.38%\n",
            "Epoch: 32, Step: 312/655, Loss: 2.204461, Accuracy: 18.37%\n",
            "Epoch: 32, Step: 313/655, Loss: 2.204240, Accuracy: 18.36%\n",
            "Epoch: 32, Step: 314/655, Loss: 2.204190, Accuracy: 18.34%\n",
            "Epoch: 32, Step: 315/655, Loss: 2.204644, Accuracy: 18.31%\n",
            "Epoch: 32, Step: 316/655, Loss: 2.204395, Accuracy: 18.33%\n",
            "Epoch: 32, Step: 317/655, Loss: 2.204544, Accuracy: 18.33%\n",
            "Epoch: 32, Step: 318/655, Loss: 2.204641, Accuracy: 18.32%\n",
            "Epoch: 32, Step: 319/655, Loss: 2.204516, Accuracy: 18.33%\n",
            "Epoch: 32, Step: 320/655, Loss: 2.204522, Accuracy: 18.35%\n",
            "Epoch: 32, Step: 321/655, Loss: 2.204636, Accuracy: 18.36%\n",
            "Epoch: 32, Step: 322/655, Loss: 2.204576, Accuracy: 18.34%\n",
            "Epoch: 32, Step: 323/655, Loss: 2.204763, Accuracy: 18.31%\n",
            "Epoch: 32, Step: 324/655, Loss: 2.204736, Accuracy: 18.34%\n",
            "Epoch: 32, Step: 325/655, Loss: 2.205060, Accuracy: 18.33%\n",
            "Epoch: 32, Step: 326/655, Loss: 2.204672, Accuracy: 18.35%\n",
            "Epoch: 32, Step: 327/655, Loss: 2.204924, Accuracy: 18.33%\n",
            "Epoch: 32, Step: 328/655, Loss: 2.204600, Accuracy: 18.33%\n",
            "Epoch: 32, Step: 329/655, Loss: 2.204789, Accuracy: 18.32%\n",
            "Epoch: 32, Step: 330/655, Loss: 2.205061, Accuracy: 18.30%\n",
            "Epoch: 32, Step: 331/655, Loss: 2.205269, Accuracy: 18.30%\n",
            "Epoch: 32, Step: 332/655, Loss: 2.205404, Accuracy: 18.31%\n",
            "Epoch: 32, Step: 333/655, Loss: 2.205326, Accuracy: 18.34%\n",
            "Epoch: 32, Step: 334/655, Loss: 2.205313, Accuracy: 18.34%\n",
            "Epoch: 32, Step: 335/655, Loss: 2.205197, Accuracy: 18.35%\n",
            "Epoch: 32, Step: 336/655, Loss: 2.205774, Accuracy: 18.32%\n",
            "Epoch: 32, Step: 337/655, Loss: 2.206088, Accuracy: 18.28%\n",
            "Epoch: 32, Step: 338/655, Loss: 2.205605, Accuracy: 18.31%\n",
            "Epoch: 32, Step: 339/655, Loss: 2.205453, Accuracy: 18.34%\n",
            "Epoch: 32, Step: 340/655, Loss: 2.205281, Accuracy: 18.35%\n",
            "Epoch: 32, Step: 341/655, Loss: 2.205172, Accuracy: 18.37%\n",
            "Epoch: 32, Step: 342/655, Loss: 2.205372, Accuracy: 18.37%\n",
            "Epoch: 32, Step: 343/655, Loss: 2.205315, Accuracy: 18.35%\n",
            "Epoch: 32, Step: 344/655, Loss: 2.205433, Accuracy: 18.32%\n",
            "Epoch: 32, Step: 345/655, Loss: 2.205618, Accuracy: 18.30%\n",
            "Epoch: 32, Step: 346/655, Loss: 2.205416, Accuracy: 18.31%\n",
            "Epoch: 32, Step: 347/655, Loss: 2.205055, Accuracy: 18.34%\n",
            "Epoch: 32, Step: 348/655, Loss: 2.205535, Accuracy: 18.32%\n",
            "Epoch: 32, Step: 349/655, Loss: 2.205777, Accuracy: 18.29%\n",
            "Epoch: 32, Step: 350/655, Loss: 2.205796, Accuracy: 18.28%\n",
            "Epoch: 32, Step: 351/655, Loss: 2.205671, Accuracy: 18.32%\n",
            "Epoch: 32, Step: 352/655, Loss: 2.205375, Accuracy: 18.31%\n",
            "Epoch: 32, Step: 353/655, Loss: 2.205179, Accuracy: 18.32%\n",
            "Epoch: 32, Step: 354/655, Loss: 2.205341, Accuracy: 18.30%\n",
            "Epoch: 32, Step: 355/655, Loss: 2.205426, Accuracy: 18.27%\n",
            "Epoch: 32, Step: 356/655, Loss: 2.205490, Accuracy: 18.29%\n",
            "Epoch: 32, Step: 357/655, Loss: 2.205651, Accuracy: 18.28%\n",
            "Epoch: 32, Step: 358/655, Loss: 2.205334, Accuracy: 18.28%\n",
            "Epoch: 32, Step: 359/655, Loss: 2.205299, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 360/655, Loss: 2.205188, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 361/655, Loss: 2.205483, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 362/655, Loss: 2.205895, Accuracy: 18.22%\n",
            "Epoch: 32, Step: 363/655, Loss: 2.205660, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 364/655, Loss: 2.205351, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 365/655, Loss: 2.205293, Accuracy: 18.27%\n",
            "Epoch: 32, Step: 366/655, Loss: 2.205607, Accuracy: 18.27%\n",
            "Epoch: 32, Step: 367/655, Loss: 2.205591, Accuracy: 18.28%\n",
            "Epoch: 32, Step: 368/655, Loss: 2.205894, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 369/655, Loss: 2.205902, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 370/655, Loss: 2.205922, Accuracy: 18.27%\n",
            "Epoch: 32, Step: 371/655, Loss: 2.206015, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 372/655, Loss: 2.206095, Accuracy: 18.21%\n",
            "Epoch: 32, Step: 373/655, Loss: 2.206060, Accuracy: 18.21%\n",
            "Epoch: 32, Step: 374/655, Loss: 2.206163, Accuracy: 18.21%\n",
            "Epoch: 32, Step: 375/655, Loss: 2.206360, Accuracy: 18.18%\n",
            "Epoch: 32, Step: 376/655, Loss: 2.206401, Accuracy: 18.17%\n",
            "Epoch: 32, Step: 377/655, Loss: 2.206496, Accuracy: 18.14%\n",
            "Epoch: 32, Step: 378/655, Loss: 2.206151, Accuracy: 18.20%\n",
            "Epoch: 32, Step: 379/655, Loss: 2.205852, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 380/655, Loss: 2.206284, Accuracy: 18.21%\n",
            "Epoch: 32, Step: 381/655, Loss: 2.206449, Accuracy: 18.21%\n",
            "Epoch: 32, Step: 382/655, Loss: 2.206278, Accuracy: 18.21%\n",
            "Epoch: 32, Step: 383/655, Loss: 2.205963, Accuracy: 18.22%\n",
            "Epoch: 32, Step: 384/655, Loss: 2.205918, Accuracy: 18.22%\n",
            "Epoch: 32, Step: 385/655, Loss: 2.205868, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 386/655, Loss: 2.205666, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 387/655, Loss: 2.205789, Accuracy: 18.23%\n",
            "Epoch: 32, Step: 388/655, Loss: 2.205652, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 389/655, Loss: 2.205620, Accuracy: 18.23%\n",
            "Epoch: 32, Step: 390/655, Loss: 2.205172, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 391/655, Loss: 2.205596, Accuracy: 18.21%\n",
            "Epoch: 32, Step: 392/655, Loss: 2.205548, Accuracy: 18.19%\n",
            "Epoch: 32, Step: 393/655, Loss: 2.205593, Accuracy: 18.20%\n",
            "Epoch: 32, Step: 394/655, Loss: 2.205647, Accuracy: 18.19%\n",
            "Epoch: 32, Step: 395/655, Loss: 2.205863, Accuracy: 18.19%\n",
            "Epoch: 32, Step: 396/655, Loss: 2.205941, Accuracy: 18.18%\n",
            "Epoch: 32, Step: 397/655, Loss: 2.205859, Accuracy: 18.17%\n",
            "Epoch: 32, Step: 398/655, Loss: 2.205882, Accuracy: 18.19%\n",
            "Epoch: 32, Step: 399/655, Loss: 2.205673, Accuracy: 18.19%\n",
            "Epoch: 32, Step: 400/655, Loss: 2.205615, Accuracy: 18.18%\n",
            "Epoch: 32, Step: 401/655, Loss: 2.205169, Accuracy: 18.18%\n",
            "Epoch: 32, Step: 402/655, Loss: 2.204746, Accuracy: 18.21%\n",
            "Epoch: 32, Step: 403/655, Loss: 2.204751, Accuracy: 18.19%\n",
            "Epoch: 32, Step: 404/655, Loss: 2.204787, Accuracy: 18.18%\n",
            "Epoch: 32, Step: 405/655, Loss: 2.205285, Accuracy: 18.16%\n",
            "Epoch: 32, Step: 406/655, Loss: 2.205112, Accuracy: 18.17%\n",
            "Epoch: 32, Step: 407/655, Loss: 2.204867, Accuracy: 18.19%\n",
            "Epoch: 32, Step: 408/655, Loss: 2.204829, Accuracy: 18.19%\n",
            "Epoch: 32, Step: 409/655, Loss: 2.205174, Accuracy: 18.18%\n",
            "Epoch: 32, Step: 410/655, Loss: 2.205543, Accuracy: 18.16%\n",
            "Epoch: 32, Step: 411/655, Loss: 2.205656, Accuracy: 18.14%\n",
            "Epoch: 32, Step: 412/655, Loss: 2.205688, Accuracy: 18.15%\n",
            "Epoch: 32, Step: 413/655, Loss: 2.205940, Accuracy: 18.15%\n",
            "Epoch: 32, Step: 414/655, Loss: 2.206010, Accuracy: 18.15%\n",
            "Epoch: 32, Step: 415/655, Loss: 2.206111, Accuracy: 18.15%\n",
            "Epoch: 32, Step: 416/655, Loss: 2.206394, Accuracy: 18.12%\n",
            "Epoch: 32, Step: 417/655, Loss: 2.206532, Accuracy: 18.11%\n",
            "Epoch: 32, Step: 418/655, Loss: 2.206688, Accuracy: 18.11%\n",
            "Epoch: 32, Step: 419/655, Loss: 2.206620, Accuracy: 18.10%\n",
            "Epoch: 32, Step: 420/655, Loss: 2.206716, Accuracy: 18.08%\n",
            "Epoch: 32, Step: 421/655, Loss: 2.206645, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 422/655, Loss: 2.206834, Accuracy: 18.08%\n",
            "Epoch: 32, Step: 423/655, Loss: 2.206943, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 424/655, Loss: 2.207085, Accuracy: 18.06%\n",
            "Epoch: 32, Step: 425/655, Loss: 2.207495, Accuracy: 18.04%\n",
            "Epoch: 32, Step: 426/655, Loss: 2.207536, Accuracy: 18.06%\n",
            "Epoch: 32, Step: 427/655, Loss: 2.207666, Accuracy: 18.05%\n",
            "Epoch: 32, Step: 428/655, Loss: 2.207928, Accuracy: 18.04%\n",
            "Epoch: 32, Step: 429/655, Loss: 2.208258, Accuracy: 18.02%\n",
            "Epoch: 32, Step: 430/655, Loss: 2.208364, Accuracy: 18.01%\n",
            "Epoch: 32, Step: 431/655, Loss: 2.208401, Accuracy: 18.00%\n",
            "Epoch: 32, Step: 432/655, Loss: 2.208221, Accuracy: 18.00%\n",
            "Epoch: 32, Step: 433/655, Loss: 2.208367, Accuracy: 17.97%\n",
            "Epoch: 32, Step: 434/655, Loss: 2.208225, Accuracy: 17.99%\n",
            "Epoch: 32, Step: 435/655, Loss: 2.207984, Accuracy: 18.02%\n",
            "Epoch: 32, Step: 436/655, Loss: 2.207964, Accuracy: 18.02%\n",
            "Epoch: 32, Step: 437/655, Loss: 2.208005, Accuracy: 18.02%\n",
            "Epoch: 32, Step: 438/655, Loss: 2.208445, Accuracy: 18.00%\n",
            "Epoch: 32, Step: 439/655, Loss: 2.208509, Accuracy: 18.00%\n",
            "Epoch: 32, Step: 440/655, Loss: 2.208796, Accuracy: 17.99%\n",
            "Epoch: 32, Step: 441/655, Loss: 2.208611, Accuracy: 18.01%\n",
            "Epoch: 32, Step: 442/655, Loss: 2.208354, Accuracy: 18.00%\n",
            "Epoch: 32, Step: 443/655, Loss: 2.208565, Accuracy: 18.00%\n",
            "Epoch: 32, Step: 444/655, Loss: 2.208348, Accuracy: 18.00%\n",
            "Epoch: 32, Step: 445/655, Loss: 2.208349, Accuracy: 18.03%\n",
            "Epoch: 32, Step: 446/655, Loss: 2.208276, Accuracy: 18.05%\n",
            "Epoch: 32, Step: 447/655, Loss: 2.208396, Accuracy: 18.04%\n",
            "Epoch: 32, Step: 448/655, Loss: 2.208630, Accuracy: 18.05%\n",
            "Epoch: 32, Step: 449/655, Loss: 2.208542, Accuracy: 18.07%\n",
            "Epoch: 32, Step: 450/655, Loss: 2.208377, Accuracy: 18.06%\n",
            "Epoch: 32, Step: 451/655, Loss: 2.208513, Accuracy: 18.05%\n",
            "Epoch: 32, Step: 452/655, Loss: 2.208285, Accuracy: 18.06%\n",
            "Epoch: 32, Step: 453/655, Loss: 2.208257, Accuracy: 18.07%\n",
            "Epoch: 32, Step: 454/655, Loss: 2.208498, Accuracy: 18.05%\n",
            "Epoch: 32, Step: 455/655, Loss: 2.208745, Accuracy: 18.03%\n",
            "Epoch: 32, Step: 456/655, Loss: 2.208687, Accuracy: 18.04%\n",
            "Epoch: 32, Step: 457/655, Loss: 2.208423, Accuracy: 18.05%\n",
            "Epoch: 32, Step: 458/655, Loss: 2.208469, Accuracy: 18.06%\n",
            "Epoch: 32, Step: 459/655, Loss: 2.208429, Accuracy: 18.07%\n",
            "Epoch: 32, Step: 460/655, Loss: 2.208269, Accuracy: 18.08%\n",
            "Epoch: 32, Step: 461/655, Loss: 2.208575, Accuracy: 18.06%\n",
            "Epoch: 32, Step: 462/655, Loss: 2.208525, Accuracy: 18.06%\n",
            "Epoch: 32, Step: 463/655, Loss: 2.208771, Accuracy: 18.05%\n",
            "Epoch: 32, Step: 464/655, Loss: 2.208780, Accuracy: 18.06%\n",
            "Epoch: 32, Step: 465/655, Loss: 2.208969, Accuracy: 18.06%\n",
            "Epoch: 32, Step: 466/655, Loss: 2.208650, Accuracy: 18.07%\n",
            "Epoch: 32, Step: 467/655, Loss: 2.208739, Accuracy: 18.07%\n",
            "Epoch: 32, Step: 468/655, Loss: 2.208663, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 469/655, Loss: 2.208609, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 470/655, Loss: 2.208494, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 471/655, Loss: 2.208779, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 472/655, Loss: 2.208762, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 473/655, Loss: 2.208604, Accuracy: 18.10%\n",
            "Epoch: 32, Step: 474/655, Loss: 2.208763, Accuracy: 18.10%\n",
            "Epoch: 32, Step: 475/655, Loss: 2.208843, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 476/655, Loss: 2.208720, Accuracy: 18.08%\n",
            "Epoch: 32, Step: 477/655, Loss: 2.208675, Accuracy: 18.08%\n",
            "Epoch: 32, Step: 478/655, Loss: 2.208678, Accuracy: 18.08%\n",
            "Epoch: 32, Step: 479/655, Loss: 2.208766, Accuracy: 18.05%\n",
            "Epoch: 32, Step: 480/655, Loss: 2.208724, Accuracy: 18.07%\n",
            "Epoch: 32, Step: 481/655, Loss: 2.208706, Accuracy: 18.07%\n",
            "Epoch: 32, Step: 482/655, Loss: 2.208733, Accuracy: 18.07%\n",
            "Epoch: 32, Step: 483/655, Loss: 2.209021, Accuracy: 18.06%\n",
            "Epoch: 32, Step: 484/655, Loss: 2.209028, Accuracy: 18.08%\n",
            "Epoch: 32, Step: 485/655, Loss: 2.208831, Accuracy: 18.11%\n",
            "Epoch: 32, Step: 486/655, Loss: 2.208986, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 487/655, Loss: 2.208934, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 488/655, Loss: 2.209138, Accuracy: 18.08%\n",
            "Epoch: 32, Step: 489/655, Loss: 2.209017, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 490/655, Loss: 2.209020, Accuracy: 18.11%\n",
            "Epoch: 32, Step: 491/655, Loss: 2.209112, Accuracy: 18.11%\n",
            "Epoch: 32, Step: 492/655, Loss: 2.209153, Accuracy: 18.10%\n",
            "Epoch: 32, Step: 493/655, Loss: 2.209154, Accuracy: 18.10%\n",
            "Epoch: 32, Step: 494/655, Loss: 2.209192, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 495/655, Loss: 2.209041, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 496/655, Loss: 2.209004, Accuracy: 18.08%\n",
            "Epoch: 32, Step: 497/655, Loss: 2.209136, Accuracy: 18.08%\n",
            "Epoch: 32, Step: 498/655, Loss: 2.209540, Accuracy: 18.06%\n",
            "Epoch: 32, Step: 499/655, Loss: 2.209566, Accuracy: 18.04%\n",
            "Epoch: 32, Step: 500/655, Loss: 2.209509, Accuracy: 18.04%\n",
            "Epoch: 32, Step: 501/655, Loss: 2.209259, Accuracy: 18.05%\n",
            "Epoch: 32, Step: 502/655, Loss: 2.209346, Accuracy: 18.05%\n",
            "Epoch: 32, Step: 503/655, Loss: 2.209433, Accuracy: 18.05%\n",
            "Epoch: 32, Step: 504/655, Loss: 2.209356, Accuracy: 18.05%\n",
            "Epoch: 32, Step: 505/655, Loss: 2.209180, Accuracy: 18.06%\n",
            "Epoch: 32, Step: 506/655, Loss: 2.209294, Accuracy: 18.06%\n",
            "Epoch: 32, Step: 507/655, Loss: 2.209218, Accuracy: 18.07%\n",
            "Epoch: 32, Step: 508/655, Loss: 2.209052, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 509/655, Loss: 2.209013, Accuracy: 18.10%\n",
            "Epoch: 32, Step: 510/655, Loss: 2.208802, Accuracy: 18.13%\n",
            "Epoch: 32, Step: 511/655, Loss: 2.208846, Accuracy: 18.13%\n",
            "Epoch: 32, Step: 512/655, Loss: 2.208667, Accuracy: 18.14%\n",
            "Epoch: 32, Step: 513/655, Loss: 2.208522, Accuracy: 18.14%\n",
            "Epoch: 32, Step: 514/655, Loss: 2.208374, Accuracy: 18.15%\n",
            "Epoch: 32, Step: 515/655, Loss: 2.208444, Accuracy: 18.14%\n",
            "Epoch: 32, Step: 516/655, Loss: 2.208554, Accuracy: 18.14%\n",
            "Epoch: 32, Step: 517/655, Loss: 2.208567, Accuracy: 18.12%\n",
            "Epoch: 32, Step: 518/655, Loss: 2.208551, Accuracy: 18.12%\n",
            "Epoch: 32, Step: 519/655, Loss: 2.208507, Accuracy: 18.11%\n",
            "Epoch: 32, Step: 520/655, Loss: 2.208630, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 521/655, Loss: 2.208692, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 522/655, Loss: 2.208876, Accuracy: 18.10%\n",
            "Epoch: 32, Step: 523/655, Loss: 2.208757, Accuracy: 18.10%\n",
            "Epoch: 32, Step: 524/655, Loss: 2.208712, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 525/655, Loss: 2.208876, Accuracy: 18.08%\n",
            "Epoch: 32, Step: 526/655, Loss: 2.208958, Accuracy: 18.08%\n",
            "Epoch: 32, Step: 527/655, Loss: 2.209050, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 528/655, Loss: 2.209288, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 529/655, Loss: 2.209170, Accuracy: 18.08%\n",
            "Epoch: 32, Step: 530/655, Loss: 2.209044, Accuracy: 18.09%\n",
            "Epoch: 32, Step: 531/655, Loss: 2.208840, Accuracy: 18.10%\n",
            "Epoch: 32, Step: 532/655, Loss: 2.208677, Accuracy: 18.10%\n",
            "Epoch: 32, Step: 533/655, Loss: 2.208867, Accuracy: 18.11%\n",
            "Epoch: 32, Step: 534/655, Loss: 2.208908, Accuracy: 18.11%\n",
            "Epoch: 32, Step: 535/655, Loss: 2.209109, Accuracy: 18.10%\n",
            "Epoch: 32, Step: 536/655, Loss: 2.209086, Accuracy: 18.12%\n",
            "Epoch: 32, Step: 537/655, Loss: 2.209055, Accuracy: 18.11%\n",
            "Epoch: 32, Step: 538/655, Loss: 2.209131, Accuracy: 18.11%\n",
            "Epoch: 32, Step: 539/655, Loss: 2.209038, Accuracy: 18.11%\n",
            "Epoch: 32, Step: 540/655, Loss: 2.208992, Accuracy: 18.12%\n",
            "Epoch: 32, Step: 541/655, Loss: 2.209169, Accuracy: 18.11%\n",
            "Epoch: 32, Step: 542/655, Loss: 2.209210, Accuracy: 18.13%\n",
            "Epoch: 32, Step: 543/655, Loss: 2.209405, Accuracy: 18.12%\n",
            "Epoch: 32, Step: 544/655, Loss: 2.209630, Accuracy: 18.11%\n",
            "Epoch: 32, Step: 545/655, Loss: 2.209507, Accuracy: 18.12%\n",
            "Epoch: 32, Step: 546/655, Loss: 2.209285, Accuracy: 18.15%\n",
            "Epoch: 32, Step: 547/655, Loss: 2.209322, Accuracy: 18.13%\n",
            "Epoch: 32, Step: 548/655, Loss: 2.209183, Accuracy: 18.16%\n",
            "Epoch: 32, Step: 549/655, Loss: 2.209215, Accuracy: 18.16%\n",
            "Epoch: 32, Step: 550/655, Loss: 2.209234, Accuracy: 18.16%\n",
            "Epoch: 32, Step: 551/655, Loss: 2.209186, Accuracy: 18.17%\n",
            "Epoch: 32, Step: 552/655, Loss: 2.209058, Accuracy: 18.16%\n",
            "Epoch: 32, Step: 553/655, Loss: 2.208945, Accuracy: 18.17%\n",
            "Epoch: 32, Step: 554/655, Loss: 2.208989, Accuracy: 18.17%\n",
            "Epoch: 32, Step: 555/655, Loss: 2.208855, Accuracy: 18.19%\n",
            "Epoch: 32, Step: 556/655, Loss: 2.208866, Accuracy: 18.20%\n",
            "Epoch: 32, Step: 557/655, Loss: 2.208834, Accuracy: 18.21%\n",
            "Epoch: 32, Step: 558/655, Loss: 2.208971, Accuracy: 18.21%\n",
            "Epoch: 32, Step: 559/655, Loss: 2.209061, Accuracy: 18.20%\n",
            "Epoch: 32, Step: 560/655, Loss: 2.208921, Accuracy: 18.19%\n",
            "Epoch: 32, Step: 561/655, Loss: 2.208577, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 562/655, Loss: 2.208749, Accuracy: 18.22%\n",
            "Epoch: 32, Step: 563/655, Loss: 2.208631, Accuracy: 18.21%\n",
            "Epoch: 32, Step: 564/655, Loss: 2.208703, Accuracy: 18.22%\n",
            "Epoch: 32, Step: 565/655, Loss: 2.208681, Accuracy: 18.21%\n",
            "Epoch: 32, Step: 566/655, Loss: 2.208357, Accuracy: 18.22%\n",
            "Epoch: 32, Step: 567/655, Loss: 2.208140, Accuracy: 18.23%\n",
            "Epoch: 32, Step: 568/655, Loss: 2.208178, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 569/655, Loss: 2.208147, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 570/655, Loss: 2.208198, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 571/655, Loss: 2.208050, Accuracy: 18.27%\n",
            "Epoch: 32, Step: 572/655, Loss: 2.208236, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 573/655, Loss: 2.208296, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 574/655, Loss: 2.208453, Accuracy: 18.23%\n",
            "Epoch: 32, Step: 575/655, Loss: 2.208538, Accuracy: 18.23%\n",
            "Epoch: 32, Step: 576/655, Loss: 2.208321, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 577/655, Loss: 2.208249, Accuracy: 18.23%\n",
            "Epoch: 32, Step: 578/655, Loss: 2.208149, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 579/655, Loss: 2.208055, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 580/655, Loss: 2.208197, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 581/655, Loss: 2.208118, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 582/655, Loss: 2.208203, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 583/655, Loss: 2.208249, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 584/655, Loss: 2.207958, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 585/655, Loss: 2.207798, Accuracy: 18.27%\n",
            "Epoch: 32, Step: 586/655, Loss: 2.207890, Accuracy: 18.28%\n",
            "Epoch: 32, Step: 587/655, Loss: 2.207874, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 588/655, Loss: 2.207961, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 589/655, Loss: 2.207899, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 590/655, Loss: 2.207743, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 591/655, Loss: 2.207612, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 592/655, Loss: 2.207570, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 593/655, Loss: 2.207752, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 594/655, Loss: 2.207783, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 595/655, Loss: 2.207736, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 596/655, Loss: 2.207959, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 597/655, Loss: 2.207932, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 598/655, Loss: 2.207924, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 599/655, Loss: 2.207873, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 600/655, Loss: 2.207759, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 601/655, Loss: 2.207933, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 602/655, Loss: 2.207892, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 603/655, Loss: 2.207883, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 604/655, Loss: 2.207983, Accuracy: 18.27%\n",
            "Epoch: 32, Step: 605/655, Loss: 2.208089, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 606/655, Loss: 2.207964, Accuracy: 18.27%\n",
            "Epoch: 32, Step: 607/655, Loss: 2.207973, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 608/655, Loss: 2.207919, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 609/655, Loss: 2.208057, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 610/655, Loss: 2.207776, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 611/655, Loss: 2.207793, Accuracy: 18.24%\n",
            "Epoch: 32, Step: 612/655, Loss: 2.207944, Accuracy: 18.23%\n",
            "Epoch: 32, Step: 613/655, Loss: 2.207728, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 614/655, Loss: 2.207950, Accuracy: 18.23%\n",
            "Epoch: 32, Step: 615/655, Loss: 2.208051, Accuracy: 18.23%\n",
            "Epoch: 32, Step: 616/655, Loss: 2.207821, Accuracy: 18.23%\n",
            "Epoch: 32, Step: 617/655, Loss: 2.207805, Accuracy: 18.23%\n",
            "Epoch: 32, Step: 618/655, Loss: 2.207652, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 619/655, Loss: 2.207727, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 620/655, Loss: 2.207457, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 621/655, Loss: 2.207586, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 622/655, Loss: 2.207626, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 623/655, Loss: 2.207823, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 624/655, Loss: 2.208025, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 625/655, Loss: 2.208253, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 626/655, Loss: 2.208216, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 627/655, Loss: 2.208249, Accuracy: 18.25%\n",
            "Epoch: 32, Step: 628/655, Loss: 2.208204, Accuracy: 18.27%\n",
            "Epoch: 32, Step: 629/655, Loss: 2.208364, Accuracy: 18.26%\n",
            "Epoch: 32, Step: 630/655, Loss: 2.208256, Accuracy: 18.27%\n",
            "Epoch: 32, Step: 631/655, Loss: 2.208169, Accuracy: 18.27%\n",
            "Epoch: 32, Step: 632/655, Loss: 2.208044, Accuracy: 18.28%\n",
            "Epoch: 32, Step: 633/655, Loss: 2.207966, Accuracy: 18.28%\n",
            "Epoch: 32, Step: 634/655, Loss: 2.207681, Accuracy: 18.29%\n",
            "Epoch: 32, Step: 635/655, Loss: 2.207717, Accuracy: 18.30%\n",
            "Epoch: 32, Step: 636/655, Loss: 2.207671, Accuracy: 18.31%\n",
            "Epoch: 32, Step: 637/655, Loss: 2.207557, Accuracy: 18.31%\n",
            "Epoch: 32, Step: 638/655, Loss: 2.207663, Accuracy: 18.30%\n",
            "Epoch: 32, Step: 639/655, Loss: 2.207626, Accuracy: 18.30%\n",
            "Epoch: 32, Step: 640/655, Loss: 2.207562, Accuracy: 18.33%\n",
            "Epoch: 32, Step: 641/655, Loss: 2.207511, Accuracy: 18.33%\n",
            "Epoch: 32, Step: 642/655, Loss: 2.207600, Accuracy: 18.33%\n",
            "Epoch: 32, Step: 643/655, Loss: 2.207478, Accuracy: 18.32%\n",
            "Epoch: 32, Step: 644/655, Loss: 2.207282, Accuracy: 18.32%\n",
            "Epoch: 32, Step: 645/655, Loss: 2.207380, Accuracy: 18.33%\n",
            "Epoch: 32, Step: 646/655, Loss: 2.207393, Accuracy: 18.33%\n",
            "Epoch: 32, Step: 647/655, Loss: 2.207276, Accuracy: 18.34%\n",
            "Epoch: 32, Step: 648/655, Loss: 2.207469, Accuracy: 18.34%\n",
            "Epoch: 32, Step: 649/655, Loss: 2.207358, Accuracy: 18.33%\n",
            "Epoch: 32, Step: 650/655, Loss: 2.207453, Accuracy: 18.33%\n",
            "Epoch: 32, Step: 651/655, Loss: 2.207450, Accuracy: 18.31%\n",
            "Epoch: 32, Step: 652/655, Loss: 2.207408, Accuracy: 18.30%\n",
            "Epoch: 32, Step: 653/655, Loss: 2.207319, Accuracy: 18.32%\n",
            "Epoch: 32, Step: 654/655, Loss: 2.207519, Accuracy: 18.33%\n",
            "Epoch: 32, Step: 655/655, Loss: 2.207765, Accuracy: 18.34%\n",
            "Epoch: 33, Step: 1/655, Loss: 2.124528, Accuracy: 28.12%\n",
            "Epoch: 33, Step: 2/655, Loss: 2.136842, Accuracy: 21.88%\n",
            "Epoch: 33, Step: 3/655, Loss: 2.157933, Accuracy: 20.83%\n",
            "Epoch: 33, Step: 4/655, Loss: 2.186716, Accuracy: 17.97%\n",
            "Epoch: 33, Step: 5/655, Loss: 2.214462, Accuracy: 16.88%\n",
            "Epoch: 33, Step: 6/655, Loss: 2.225038, Accuracy: 16.15%\n",
            "Epoch: 33, Step: 7/655, Loss: 2.207177, Accuracy: 18.30%\n",
            "Epoch: 33, Step: 8/655, Loss: 2.210950, Accuracy: 17.97%\n",
            "Epoch: 33, Step: 9/655, Loss: 2.195703, Accuracy: 18.40%\n",
            "Epoch: 33, Step: 10/655, Loss: 2.193196, Accuracy: 18.75%\n",
            "Epoch: 33, Step: 11/655, Loss: 2.198320, Accuracy: 18.75%\n",
            "Epoch: 33, Step: 12/655, Loss: 2.205502, Accuracy: 18.23%\n",
            "Epoch: 33, Step: 13/655, Loss: 2.209362, Accuracy: 17.55%\n",
            "Epoch: 33, Step: 14/655, Loss: 2.208580, Accuracy: 17.63%\n",
            "Epoch: 33, Step: 15/655, Loss: 2.207226, Accuracy: 18.12%\n",
            "Epoch: 33, Step: 16/655, Loss: 2.199412, Accuracy: 18.55%\n",
            "Epoch: 33, Step: 17/655, Loss: 2.193620, Accuracy: 18.57%\n",
            "Epoch: 33, Step: 18/655, Loss: 2.195287, Accuracy: 18.40%\n",
            "Epoch: 33, Step: 19/655, Loss: 2.193102, Accuracy: 18.42%\n",
            "Epoch: 33, Step: 20/655, Loss: 2.195356, Accuracy: 18.28%\n",
            "Epoch: 33, Step: 21/655, Loss: 2.199488, Accuracy: 18.30%\n",
            "Epoch: 33, Step: 22/655, Loss: 2.199783, Accuracy: 19.03%\n",
            "Epoch: 33, Step: 23/655, Loss: 2.201176, Accuracy: 19.16%\n",
            "Epoch: 33, Step: 24/655, Loss: 2.204015, Accuracy: 19.66%\n",
            "Epoch: 33, Step: 25/655, Loss: 2.206763, Accuracy: 19.12%\n",
            "Epoch: 33, Step: 26/655, Loss: 2.204628, Accuracy: 19.23%\n",
            "Epoch: 33, Step: 27/655, Loss: 2.200908, Accuracy: 19.44%\n",
            "Epoch: 33, Step: 28/655, Loss: 2.195859, Accuracy: 20.20%\n",
            "Epoch: 33, Step: 29/655, Loss: 2.195358, Accuracy: 20.37%\n",
            "Epoch: 33, Step: 30/655, Loss: 2.195641, Accuracy: 20.10%\n",
            "Epoch: 33, Step: 31/655, Loss: 2.196018, Accuracy: 20.06%\n",
            "Epoch: 33, Step: 32/655, Loss: 2.198639, Accuracy: 19.82%\n",
            "Epoch: 33, Step: 33/655, Loss: 2.197798, Accuracy: 19.98%\n",
            "Epoch: 33, Step: 34/655, Loss: 2.197640, Accuracy: 19.76%\n",
            "Epoch: 33, Step: 35/655, Loss: 2.197323, Accuracy: 19.73%\n",
            "Epoch: 33, Step: 36/655, Loss: 2.196384, Accuracy: 19.62%\n",
            "Epoch: 33, Step: 37/655, Loss: 2.194654, Accuracy: 19.85%\n",
            "Epoch: 33, Step: 38/655, Loss: 2.195756, Accuracy: 19.98%\n",
            "Epoch: 33, Step: 39/655, Loss: 2.195184, Accuracy: 20.03%\n",
            "Epoch: 33, Step: 40/655, Loss: 2.196907, Accuracy: 20.16%\n",
            "Epoch: 33, Step: 41/655, Loss: 2.198003, Accuracy: 20.12%\n",
            "Epoch: 33, Step: 42/655, Loss: 2.199691, Accuracy: 20.01%\n",
            "Epoch: 33, Step: 43/655, Loss: 2.197762, Accuracy: 20.06%\n",
            "Epoch: 33, Step: 44/655, Loss: 2.198539, Accuracy: 20.03%\n",
            "Epoch: 33, Step: 45/655, Loss: 2.197917, Accuracy: 20.21%\n",
            "Epoch: 33, Step: 46/655, Loss: 2.197743, Accuracy: 20.18%\n",
            "Epoch: 33, Step: 47/655, Loss: 2.196024, Accuracy: 20.15%\n",
            "Epoch: 33, Step: 48/655, Loss: 2.195202, Accuracy: 20.31%\n",
            "Epoch: 33, Step: 49/655, Loss: 2.193109, Accuracy: 20.34%\n",
            "Epoch: 33, Step: 50/655, Loss: 2.193010, Accuracy: 20.38%\n",
            "Epoch: 33, Step: 51/655, Loss: 2.194686, Accuracy: 20.16%\n",
            "Epoch: 33, Step: 52/655, Loss: 2.193781, Accuracy: 20.31%\n",
            "Epoch: 33, Step: 53/655, Loss: 2.194933, Accuracy: 20.17%\n",
            "Epoch: 33, Step: 54/655, Loss: 2.196174, Accuracy: 20.08%\n",
            "Epoch: 33, Step: 55/655, Loss: 2.197203, Accuracy: 20.00%\n",
            "Epoch: 33, Step: 56/655, Loss: 2.198427, Accuracy: 19.87%\n",
            "Epoch: 33, Step: 57/655, Loss: 2.198256, Accuracy: 19.68%\n",
            "Epoch: 33, Step: 58/655, Loss: 2.197066, Accuracy: 19.72%\n",
            "Epoch: 33, Step: 59/655, Loss: 2.196441, Accuracy: 19.70%\n",
            "Epoch: 33, Step: 60/655, Loss: 2.198597, Accuracy: 19.64%\n",
            "Epoch: 33, Step: 61/655, Loss: 2.199977, Accuracy: 19.47%\n",
            "Epoch: 33, Step: 62/655, Loss: 2.200239, Accuracy: 19.66%\n",
            "Epoch: 33, Step: 63/655, Loss: 2.198770, Accuracy: 19.64%\n",
            "Epoch: 33, Step: 64/655, Loss: 2.199066, Accuracy: 19.63%\n",
            "Epoch: 33, Step: 65/655, Loss: 2.198615, Accuracy: 19.71%\n",
            "Epoch: 33, Step: 66/655, Loss: 2.198273, Accuracy: 19.74%\n",
            "Epoch: 33, Step: 67/655, Loss: 2.198221, Accuracy: 19.68%\n",
            "Epoch: 33, Step: 68/655, Loss: 2.197256, Accuracy: 19.62%\n",
            "Epoch: 33, Step: 69/655, Loss: 2.198269, Accuracy: 19.57%\n",
            "Epoch: 33, Step: 70/655, Loss: 2.196563, Accuracy: 19.82%\n",
            "Epoch: 33, Step: 71/655, Loss: 2.196738, Accuracy: 19.85%\n",
            "Epoch: 33, Step: 72/655, Loss: 2.198006, Accuracy: 19.75%\n",
            "Epoch: 33, Step: 73/655, Loss: 2.197493, Accuracy: 19.65%\n",
            "Epoch: 33, Step: 74/655, Loss: 2.197069, Accuracy: 19.55%\n",
            "Epoch: 33, Step: 75/655, Loss: 2.196841, Accuracy: 19.46%\n",
            "Epoch: 33, Step: 76/655, Loss: 2.197052, Accuracy: 19.45%\n",
            "Epoch: 33, Step: 77/655, Loss: 2.196850, Accuracy: 19.44%\n",
            "Epoch: 33, Step: 78/655, Loss: 2.195863, Accuracy: 19.59%\n",
            "Epoch: 33, Step: 79/655, Loss: 2.197480, Accuracy: 19.54%\n",
            "Epoch: 33, Step: 80/655, Loss: 2.197159, Accuracy: 19.49%\n",
            "Epoch: 33, Step: 81/655, Loss: 2.195840, Accuracy: 19.56%\n",
            "Epoch: 33, Step: 82/655, Loss: 2.194993, Accuracy: 19.51%\n",
            "Epoch: 33, Step: 83/655, Loss: 2.194839, Accuracy: 19.54%\n",
            "Epoch: 33, Step: 84/655, Loss: 2.196280, Accuracy: 19.49%\n",
            "Epoch: 33, Step: 85/655, Loss: 2.196416, Accuracy: 19.56%\n",
            "Epoch: 33, Step: 86/655, Loss: 2.196692, Accuracy: 19.62%\n",
            "Epoch: 33, Step: 87/655, Loss: 2.196000, Accuracy: 19.68%\n",
            "Epoch: 33, Step: 88/655, Loss: 2.195271, Accuracy: 19.64%\n",
            "Epoch: 33, Step: 89/655, Loss: 2.194249, Accuracy: 19.63%\n",
            "Epoch: 33, Step: 90/655, Loss: 2.193371, Accuracy: 19.58%\n",
            "Epoch: 33, Step: 91/655, Loss: 2.191915, Accuracy: 19.71%\n",
            "Epoch: 33, Step: 92/655, Loss: 2.193450, Accuracy: 19.63%\n",
            "Epoch: 33, Step: 93/655, Loss: 2.192663, Accuracy: 19.56%\n",
            "Epoch: 33, Step: 94/655, Loss: 2.192927, Accuracy: 19.45%\n",
            "Epoch: 33, Step: 95/655, Loss: 2.192896, Accuracy: 19.47%\n",
            "Epoch: 33, Step: 96/655, Loss: 2.192567, Accuracy: 19.56%\n",
            "Epoch: 33, Step: 97/655, Loss: 2.193649, Accuracy: 19.49%\n",
            "Epoch: 33, Step: 98/655, Loss: 2.193104, Accuracy: 19.55%\n",
            "Epoch: 33, Step: 99/655, Loss: 2.192822, Accuracy: 19.67%\n",
            "Epoch: 33, Step: 100/655, Loss: 2.194400, Accuracy: 19.62%\n",
            "Epoch: 33, Step: 101/655, Loss: 2.194382, Accuracy: 19.55%\n",
            "Epoch: 33, Step: 102/655, Loss: 2.194341, Accuracy: 19.52%\n",
            "Epoch: 33, Step: 103/655, Loss: 2.193815, Accuracy: 19.54%\n",
            "Epoch: 33, Step: 104/655, Loss: 2.192117, Accuracy: 19.62%\n",
            "Epoch: 33, Step: 105/655, Loss: 2.192624, Accuracy: 19.73%\n",
            "Epoch: 33, Step: 106/655, Loss: 2.192628, Accuracy: 19.78%\n",
            "Epoch: 33, Step: 107/655, Loss: 2.192070, Accuracy: 19.68%\n",
            "Epoch: 33, Step: 108/655, Loss: 2.192326, Accuracy: 19.65%\n",
            "Epoch: 33, Step: 109/655, Loss: 2.192236, Accuracy: 19.64%\n",
            "Epoch: 33, Step: 110/655, Loss: 2.192662, Accuracy: 19.57%\n",
            "Epoch: 33, Step: 111/655, Loss: 2.192970, Accuracy: 19.65%\n",
            "Epoch: 33, Step: 112/655, Loss: 2.193929, Accuracy: 19.53%\n",
            "Epoch: 33, Step: 113/655, Loss: 2.194312, Accuracy: 19.50%\n",
            "Epoch: 33, Step: 114/655, Loss: 2.193230, Accuracy: 19.52%\n",
            "Epoch: 33, Step: 115/655, Loss: 2.193370, Accuracy: 19.46%\n",
            "Epoch: 33, Step: 116/655, Loss: 2.192419, Accuracy: 19.59%\n",
            "Epoch: 33, Step: 117/655, Loss: 2.193247, Accuracy: 19.60%\n",
            "Epoch: 33, Step: 118/655, Loss: 2.192223, Accuracy: 19.62%\n",
            "Epoch: 33, Step: 119/655, Loss: 2.192187, Accuracy: 19.56%\n",
            "Epoch: 33, Step: 120/655, Loss: 2.191746, Accuracy: 19.53%\n",
            "Epoch: 33, Step: 121/655, Loss: 2.191639, Accuracy: 19.52%\n",
            "Epoch: 33, Step: 122/655, Loss: 2.191706, Accuracy: 19.47%\n",
            "Epoch: 33, Step: 123/655, Loss: 2.192918, Accuracy: 19.41%\n",
            "Epoch: 33, Step: 124/655, Loss: 2.194126, Accuracy: 19.33%\n",
            "Epoch: 33, Step: 125/655, Loss: 2.193077, Accuracy: 19.43%\n",
            "Epoch: 33, Step: 126/655, Loss: 2.192662, Accuracy: 19.47%\n",
            "Epoch: 33, Step: 127/655, Loss: 2.192915, Accuracy: 19.54%\n",
            "Epoch: 33, Step: 128/655, Loss: 2.193342, Accuracy: 19.51%\n",
            "Epoch: 33, Step: 129/655, Loss: 2.193703, Accuracy: 19.38%\n",
            "Epoch: 33, Step: 130/655, Loss: 2.193598, Accuracy: 19.35%\n",
            "Epoch: 33, Step: 131/655, Loss: 2.193850, Accuracy: 19.39%\n",
            "Epoch: 33, Step: 132/655, Loss: 2.194673, Accuracy: 19.37%\n",
            "Epoch: 33, Step: 133/655, Loss: 2.195157, Accuracy: 19.43%\n",
            "Epoch: 33, Step: 134/655, Loss: 2.194895, Accuracy: 19.43%\n",
            "Epoch: 33, Step: 135/655, Loss: 2.195712, Accuracy: 19.35%\n",
            "Epoch: 33, Step: 136/655, Loss: 2.195800, Accuracy: 19.39%\n",
            "Epoch: 33, Step: 137/655, Loss: 2.196167, Accuracy: 19.27%\n",
            "Epoch: 33, Step: 138/655, Loss: 2.196212, Accuracy: 19.20%\n",
            "Epoch: 33, Step: 139/655, Loss: 2.196194, Accuracy: 19.24%\n",
            "Epoch: 33, Step: 140/655, Loss: 2.197372, Accuracy: 19.22%\n",
            "Epoch: 33, Step: 141/655, Loss: 2.197359, Accuracy: 19.15%\n",
            "Epoch: 33, Step: 142/655, Loss: 2.197926, Accuracy: 19.08%\n",
            "Epoch: 33, Step: 143/655, Loss: 2.197963, Accuracy: 19.08%\n",
            "Epoch: 33, Step: 144/655, Loss: 2.197634, Accuracy: 19.10%\n",
            "Epoch: 33, Step: 145/655, Loss: 2.197823, Accuracy: 19.05%\n",
            "Epoch: 33, Step: 146/655, Loss: 2.198109, Accuracy: 18.99%\n",
            "Epoch: 33, Step: 147/655, Loss: 2.198602, Accuracy: 18.98%\n",
            "Epoch: 33, Step: 148/655, Loss: 2.198370, Accuracy: 19.00%\n",
            "Epoch: 33, Step: 149/655, Loss: 2.198146, Accuracy: 18.98%\n",
            "Epoch: 33, Step: 150/655, Loss: 2.197347, Accuracy: 19.02%\n",
            "Epoch: 33, Step: 151/655, Loss: 2.198069, Accuracy: 18.96%\n",
            "Epoch: 33, Step: 152/655, Loss: 2.198578, Accuracy: 18.94%\n",
            "Epoch: 33, Step: 153/655, Loss: 2.198296, Accuracy: 18.93%\n",
            "Epoch: 33, Step: 154/655, Loss: 2.199621, Accuracy: 18.89%\n",
            "Epoch: 33, Step: 155/655, Loss: 2.199672, Accuracy: 18.91%\n",
            "Epoch: 33, Step: 156/655, Loss: 2.200162, Accuracy: 18.95%\n",
            "Epoch: 33, Step: 157/655, Loss: 2.199998, Accuracy: 19.01%\n",
            "Epoch: 33, Step: 158/655, Loss: 2.200359, Accuracy: 18.93%\n",
            "Epoch: 33, Step: 159/655, Loss: 2.199699, Accuracy: 18.99%\n",
            "Epoch: 33, Step: 160/655, Loss: 2.199985, Accuracy: 19.00%\n",
            "Epoch: 33, Step: 161/655, Loss: 2.200778, Accuracy: 18.94%\n",
            "Epoch: 33, Step: 162/655, Loss: 2.201353, Accuracy: 18.87%\n",
            "Epoch: 33, Step: 163/655, Loss: 2.200562, Accuracy: 18.92%\n",
            "Epoch: 33, Step: 164/655, Loss: 2.200099, Accuracy: 19.00%\n",
            "Epoch: 33, Step: 165/655, Loss: 2.200866, Accuracy: 18.92%\n",
            "Epoch: 33, Step: 166/655, Loss: 2.201002, Accuracy: 18.96%\n",
            "Epoch: 33, Step: 167/655, Loss: 2.200757, Accuracy: 18.99%\n",
            "Epoch: 33, Step: 168/655, Loss: 2.200988, Accuracy: 18.95%\n",
            "Epoch: 33, Step: 169/655, Loss: 2.201071, Accuracy: 18.92%\n",
            "Epoch: 33, Step: 170/655, Loss: 2.201280, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 171/655, Loss: 2.200623, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 172/655, Loss: 2.200824, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 173/655, Loss: 2.201251, Accuracy: 18.79%\n",
            "Epoch: 33, Step: 174/655, Loss: 2.201786, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 175/655, Loss: 2.201486, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 176/655, Loss: 2.201196, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 177/655, Loss: 2.201881, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 178/655, Loss: 2.202323, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 179/655, Loss: 2.202732, Accuracy: 18.73%\n",
            "Epoch: 33, Step: 180/655, Loss: 2.203614, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 181/655, Loss: 2.203504, Accuracy: 18.65%\n",
            "Epoch: 33, Step: 182/655, Loss: 2.203705, Accuracy: 18.65%\n",
            "Epoch: 33, Step: 183/655, Loss: 2.203359, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 184/655, Loss: 2.203348, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 185/655, Loss: 2.202661, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 186/655, Loss: 2.203142, Accuracy: 18.73%\n",
            "Epoch: 33, Step: 187/655, Loss: 2.203178, Accuracy: 18.73%\n",
            "Epoch: 33, Step: 188/655, Loss: 2.203107, Accuracy: 18.75%\n",
            "Epoch: 33, Step: 189/655, Loss: 2.202713, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 190/655, Loss: 2.202527, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 191/655, Loss: 2.202284, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 192/655, Loss: 2.201562, Accuracy: 18.90%\n",
            "Epoch: 33, Step: 193/655, Loss: 2.201854, Accuracy: 18.91%\n",
            "Epoch: 33, Step: 194/655, Loss: 2.201820, Accuracy: 18.91%\n",
            "Epoch: 33, Step: 195/655, Loss: 2.201400, Accuracy: 18.91%\n",
            "Epoch: 33, Step: 196/655, Loss: 2.201598, Accuracy: 18.91%\n",
            "Epoch: 33, Step: 197/655, Loss: 2.202078, Accuracy: 18.88%\n",
            "Epoch: 33, Step: 198/655, Loss: 2.201952, Accuracy: 18.89%\n",
            "Epoch: 33, Step: 199/655, Loss: 2.202691, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 200/655, Loss: 2.203175, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 201/655, Loss: 2.202900, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 202/655, Loss: 2.202828, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 203/655, Loss: 2.201973, Accuracy: 18.95%\n",
            "Epoch: 33, Step: 204/655, Loss: 2.202293, Accuracy: 18.89%\n",
            "Epoch: 33, Step: 205/655, Loss: 2.202730, Accuracy: 18.89%\n",
            "Epoch: 33, Step: 206/655, Loss: 2.202474, Accuracy: 18.90%\n",
            "Epoch: 33, Step: 207/655, Loss: 2.202197, Accuracy: 18.90%\n",
            "Epoch: 33, Step: 208/655, Loss: 2.202638, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 209/655, Loss: 2.202931, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 210/655, Loss: 2.203031, Accuracy: 18.81%\n",
            "Epoch: 33, Step: 211/655, Loss: 2.202572, Accuracy: 18.79%\n",
            "Epoch: 33, Step: 212/655, Loss: 2.202686, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 213/655, Loss: 2.201837, Accuracy: 18.81%\n",
            "Epoch: 33, Step: 214/655, Loss: 2.201608, Accuracy: 18.90%\n",
            "Epoch: 33, Step: 215/655, Loss: 2.201825, Accuracy: 18.90%\n",
            "Epoch: 33, Step: 216/655, Loss: 2.201740, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 217/655, Loss: 2.201725, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 218/655, Loss: 2.201454, Accuracy: 18.89%\n",
            "Epoch: 33, Step: 219/655, Loss: 2.202264, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 220/655, Loss: 2.202154, Accuracy: 18.88%\n",
            "Epoch: 33, Step: 221/655, Loss: 2.202443, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 222/655, Loss: 2.202505, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 223/655, Loss: 2.202579, Accuracy: 18.89%\n",
            "Epoch: 33, Step: 224/655, Loss: 2.202985, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 225/655, Loss: 2.202404, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 226/655, Loss: 2.202774, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 227/655, Loss: 2.202857, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 228/655, Loss: 2.203232, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 229/655, Loss: 2.203092, Accuracy: 18.90%\n",
            "Epoch: 33, Step: 230/655, Loss: 2.203659, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 231/655, Loss: 2.203763, Accuracy: 18.87%\n",
            "Epoch: 33, Step: 232/655, Loss: 2.203456, Accuracy: 18.90%\n",
            "Epoch: 33, Step: 233/655, Loss: 2.203091, Accuracy: 18.91%\n",
            "Epoch: 33, Step: 234/655, Loss: 2.203177, Accuracy: 18.91%\n",
            "Epoch: 33, Step: 235/655, Loss: 2.203408, Accuracy: 18.92%\n",
            "Epoch: 33, Step: 236/655, Loss: 2.203089, Accuracy: 18.94%\n",
            "Epoch: 33, Step: 237/655, Loss: 2.202894, Accuracy: 18.93%\n",
            "Epoch: 33, Step: 238/655, Loss: 2.202866, Accuracy: 18.95%\n",
            "Epoch: 33, Step: 239/655, Loss: 2.202651, Accuracy: 18.92%\n",
            "Epoch: 33, Step: 240/655, Loss: 2.202297, Accuracy: 18.92%\n",
            "Epoch: 33, Step: 241/655, Loss: 2.202392, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 242/655, Loss: 2.202386, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 243/655, Loss: 2.202613, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 244/655, Loss: 2.203238, Accuracy: 18.74%\n",
            "Epoch: 33, Step: 245/655, Loss: 2.203544, Accuracy: 18.71%\n",
            "Epoch: 33, Step: 246/655, Loss: 2.203030, Accuracy: 18.74%\n",
            "Epoch: 33, Step: 247/655, Loss: 2.202734, Accuracy: 18.71%\n",
            "Epoch: 33, Step: 248/655, Loss: 2.203301, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 249/655, Loss: 2.203182, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 250/655, Loss: 2.203495, Accuracy: 18.71%\n",
            "Epoch: 33, Step: 251/655, Loss: 2.203759, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 252/655, Loss: 2.204011, Accuracy: 18.69%\n",
            "Epoch: 33, Step: 253/655, Loss: 2.204133, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 254/655, Loss: 2.204131, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 255/655, Loss: 2.203614, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 256/655, Loss: 2.203551, Accuracy: 18.66%\n",
            "Epoch: 33, Step: 257/655, Loss: 2.203480, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 258/655, Loss: 2.203279, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 259/655, Loss: 2.203659, Accuracy: 18.65%\n",
            "Epoch: 33, Step: 260/655, Loss: 2.203246, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 261/655, Loss: 2.203158, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 262/655, Loss: 2.203493, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 263/655, Loss: 2.203651, Accuracy: 18.74%\n",
            "Epoch: 33, Step: 264/655, Loss: 2.203864, Accuracy: 18.73%\n",
            "Epoch: 33, Step: 265/655, Loss: 2.203819, Accuracy: 18.71%\n",
            "Epoch: 33, Step: 266/655, Loss: 2.203879, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 267/655, Loss: 2.204118, Accuracy: 18.76%\n",
            "Epoch: 33, Step: 268/655, Loss: 2.204175, Accuracy: 18.75%\n",
            "Epoch: 33, Step: 269/655, Loss: 2.204277, Accuracy: 18.76%\n",
            "Epoch: 33, Step: 270/655, Loss: 2.204061, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 271/655, Loss: 2.203922, Accuracy: 18.81%\n",
            "Epoch: 33, Step: 272/655, Loss: 2.203843, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 273/655, Loss: 2.204111, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 274/655, Loss: 2.203899, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 275/655, Loss: 2.204325, Accuracy: 18.81%\n",
            "Epoch: 33, Step: 276/655, Loss: 2.203908, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 277/655, Loss: 2.203641, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 278/655, Loss: 2.203731, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 279/655, Loss: 2.203780, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 280/655, Loss: 2.203481, Accuracy: 18.87%\n",
            "Epoch: 33, Step: 281/655, Loss: 2.203682, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 282/655, Loss: 2.203512, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 283/655, Loss: 2.203186, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 284/655, Loss: 2.202973, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 285/655, Loss: 2.202999, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 286/655, Loss: 2.203121, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 287/655, Loss: 2.202890, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 288/655, Loss: 2.202958, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 289/655, Loss: 2.202972, Accuracy: 18.81%\n",
            "Epoch: 33, Step: 290/655, Loss: 2.203161, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 291/655, Loss: 2.203405, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 292/655, Loss: 2.203545, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 293/655, Loss: 2.203801, Accuracy: 18.74%\n",
            "Epoch: 33, Step: 294/655, Loss: 2.203979, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 295/655, Loss: 2.204024, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 296/655, Loss: 2.203721, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 297/655, Loss: 2.203743, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 298/655, Loss: 2.203542, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 299/655, Loss: 2.203607, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 300/655, Loss: 2.203772, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 301/655, Loss: 2.203752, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 302/655, Loss: 2.203733, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 303/655, Loss: 2.203822, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 304/655, Loss: 2.203843, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 305/655, Loss: 2.203361, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 306/655, Loss: 2.203922, Accuracy: 18.81%\n",
            "Epoch: 33, Step: 307/655, Loss: 2.204479, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 308/655, Loss: 2.204394, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 309/655, Loss: 2.204069, Accuracy: 18.81%\n",
            "Epoch: 33, Step: 310/655, Loss: 2.203817, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 311/655, Loss: 2.204173, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 312/655, Loss: 2.204224, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 313/655, Loss: 2.204418, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 314/655, Loss: 2.204156, Accuracy: 18.87%\n",
            "Epoch: 33, Step: 315/655, Loss: 2.203977, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 316/655, Loss: 2.203854, Accuracy: 18.88%\n",
            "Epoch: 33, Step: 317/655, Loss: 2.203561, Accuracy: 18.87%\n",
            "Epoch: 33, Step: 318/655, Loss: 2.204164, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 319/655, Loss: 2.204092, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 320/655, Loss: 2.204369, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 321/655, Loss: 2.204558, Accuracy: 18.79%\n",
            "Epoch: 33, Step: 322/655, Loss: 2.204335, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 323/655, Loss: 2.204194, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 324/655, Loss: 2.204517, Accuracy: 18.81%\n",
            "Epoch: 33, Step: 325/655, Loss: 2.204580, Accuracy: 18.81%\n",
            "Epoch: 33, Step: 326/655, Loss: 2.204261, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 327/655, Loss: 2.204155, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 328/655, Loss: 2.203802, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 329/655, Loss: 2.203958, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 330/655, Loss: 2.204044, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 331/655, Loss: 2.204004, Accuracy: 18.75%\n",
            "Epoch: 33, Step: 332/655, Loss: 2.203792, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 333/655, Loss: 2.203524, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 334/655, Loss: 2.203466, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 335/655, Loss: 2.203669, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 336/655, Loss: 2.203725, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 337/655, Loss: 2.203941, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 338/655, Loss: 2.203964, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 339/655, Loss: 2.203622, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 340/655, Loss: 2.203798, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 341/655, Loss: 2.203638, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 342/655, Loss: 2.203774, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 343/655, Loss: 2.203778, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 344/655, Loss: 2.203800, Accuracy: 18.76%\n",
            "Epoch: 33, Step: 345/655, Loss: 2.203809, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 346/655, Loss: 2.204063, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 347/655, Loss: 2.204053, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 348/655, Loss: 2.204091, Accuracy: 18.76%\n",
            "Epoch: 33, Step: 349/655, Loss: 2.203787, Accuracy: 18.76%\n",
            "Epoch: 33, Step: 350/655, Loss: 2.203723, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 351/655, Loss: 2.203323, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 352/655, Loss: 2.203230, Accuracy: 18.79%\n",
            "Epoch: 33, Step: 353/655, Loss: 2.203133, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 354/655, Loss: 2.202923, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 355/655, Loss: 2.203299, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 356/655, Loss: 2.203158, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 357/655, Loss: 2.203242, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 358/655, Loss: 2.203278, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 359/655, Loss: 2.203379, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 360/655, Loss: 2.203386, Accuracy: 18.79%\n",
            "Epoch: 33, Step: 361/655, Loss: 2.203048, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 362/655, Loss: 2.202883, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 363/655, Loss: 2.203111, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 364/655, Loss: 2.202972, Accuracy: 18.76%\n",
            "Epoch: 33, Step: 365/655, Loss: 2.203289, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 366/655, Loss: 2.203244, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 367/655, Loss: 2.203264, Accuracy: 18.75%\n",
            "Epoch: 33, Step: 368/655, Loss: 2.203009, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 369/655, Loss: 2.203279, Accuracy: 18.76%\n",
            "Epoch: 33, Step: 370/655, Loss: 2.203044, Accuracy: 18.76%\n",
            "Epoch: 33, Step: 371/655, Loss: 2.203101, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 372/655, Loss: 2.203287, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 373/655, Loss: 2.203062, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 374/655, Loss: 2.203204, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 375/655, Loss: 2.203217, Accuracy: 18.81%\n",
            "Epoch: 33, Step: 376/655, Loss: 2.203384, Accuracy: 18.81%\n",
            "Epoch: 33, Step: 377/655, Loss: 2.203740, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 378/655, Loss: 2.203485, Accuracy: 18.81%\n",
            "Epoch: 33, Step: 379/655, Loss: 2.203597, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 380/655, Loss: 2.203436, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 381/655, Loss: 2.203553, Accuracy: 18.79%\n",
            "Epoch: 33, Step: 382/655, Loss: 2.203295, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 383/655, Loss: 2.203070, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 384/655, Loss: 2.202977, Accuracy: 18.81%\n",
            "Epoch: 33, Step: 385/655, Loss: 2.202425, Accuracy: 18.81%\n",
            "Epoch: 33, Step: 386/655, Loss: 2.202532, Accuracy: 18.81%\n",
            "Epoch: 33, Step: 387/655, Loss: 2.202889, Accuracy: 18.79%\n",
            "Epoch: 33, Step: 388/655, Loss: 2.202680, Accuracy: 18.79%\n",
            "Epoch: 33, Step: 389/655, Loss: 2.202494, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 390/655, Loss: 2.202676, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 391/655, Loss: 2.202674, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 392/655, Loss: 2.202866, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 393/655, Loss: 2.202963, Accuracy: 18.75%\n",
            "Epoch: 33, Step: 394/655, Loss: 2.202975, Accuracy: 18.73%\n",
            "Epoch: 33, Step: 395/655, Loss: 2.202951, Accuracy: 18.73%\n",
            "Epoch: 33, Step: 396/655, Loss: 2.202876, Accuracy: 18.75%\n",
            "Epoch: 33, Step: 397/655, Loss: 2.202367, Accuracy: 18.79%\n",
            "Epoch: 33, Step: 398/655, Loss: 2.202334, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 399/655, Loss: 2.202249, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 400/655, Loss: 2.202093, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 401/655, Loss: 2.202091, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 402/655, Loss: 2.202124, Accuracy: 18.77%\n",
            "Epoch: 33, Step: 403/655, Loss: 2.202048, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 404/655, Loss: 2.201926, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 405/655, Loss: 2.201823, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 406/655, Loss: 2.201677, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 407/655, Loss: 2.201239, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 408/655, Loss: 2.201478, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 409/655, Loss: 2.201665, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 410/655, Loss: 2.201748, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 411/655, Loss: 2.201821, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 412/655, Loss: 2.202165, Accuracy: 18.82%\n",
            "Epoch: 33, Step: 413/655, Loss: 2.202076, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 414/655, Loss: 2.201974, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 415/655, Loss: 2.201977, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 416/655, Loss: 2.202046, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 417/655, Loss: 2.202242, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 418/655, Loss: 2.202179, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 419/655, Loss: 2.201557, Accuracy: 18.90%\n",
            "Epoch: 33, Step: 420/655, Loss: 2.201751, Accuracy: 18.89%\n",
            "Epoch: 33, Step: 421/655, Loss: 2.201820, Accuracy: 18.88%\n",
            "Epoch: 33, Step: 422/655, Loss: 2.201600, Accuracy: 18.88%\n",
            "Epoch: 33, Step: 423/655, Loss: 2.201491, Accuracy: 18.87%\n",
            "Epoch: 33, Step: 424/655, Loss: 2.201609, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 425/655, Loss: 2.201730, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 426/655, Loss: 2.201878, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 427/655, Loss: 2.201898, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 428/655, Loss: 2.201459, Accuracy: 18.88%\n",
            "Epoch: 33, Step: 429/655, Loss: 2.201302, Accuracy: 18.90%\n",
            "Epoch: 33, Step: 430/655, Loss: 2.201292, Accuracy: 18.88%\n",
            "Epoch: 33, Step: 431/655, Loss: 2.201116, Accuracy: 18.87%\n",
            "Epoch: 33, Step: 432/655, Loss: 2.201252, Accuracy: 18.87%\n",
            "Epoch: 33, Step: 433/655, Loss: 2.201159, Accuracy: 18.88%\n",
            "Epoch: 33, Step: 434/655, Loss: 2.201344, Accuracy: 18.87%\n",
            "Epoch: 33, Step: 435/655, Loss: 2.201515, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 436/655, Loss: 2.201477, Accuracy: 18.86%\n",
            "Epoch: 33, Step: 437/655, Loss: 2.201547, Accuracy: 18.88%\n",
            "Epoch: 33, Step: 438/655, Loss: 2.201731, Accuracy: 18.89%\n",
            "Epoch: 33, Step: 439/655, Loss: 2.201898, Accuracy: 18.91%\n",
            "Epoch: 33, Step: 440/655, Loss: 2.202151, Accuracy: 18.88%\n",
            "Epoch: 33, Step: 441/655, Loss: 2.202460, Accuracy: 18.88%\n",
            "Epoch: 33, Step: 442/655, Loss: 2.202344, Accuracy: 18.85%\n",
            "Epoch: 33, Step: 443/655, Loss: 2.202427, Accuracy: 18.84%\n",
            "Epoch: 33, Step: 444/655, Loss: 2.202584, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 445/655, Loss: 2.202664, Accuracy: 18.83%\n",
            "Epoch: 33, Step: 446/655, Loss: 2.202762, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 447/655, Loss: 2.202840, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 448/655, Loss: 2.202691, Accuracy: 18.79%\n",
            "Epoch: 33, Step: 449/655, Loss: 2.202672, Accuracy: 18.80%\n",
            "Epoch: 33, Step: 450/655, Loss: 2.202821, Accuracy: 18.78%\n",
            "Epoch: 33, Step: 451/655, Loss: 2.202789, Accuracy: 18.76%\n",
            "Epoch: 33, Step: 452/655, Loss: 2.202812, Accuracy: 18.75%\n",
            "Epoch: 33, Step: 453/655, Loss: 2.202612, Accuracy: 18.75%\n",
            "Epoch: 33, Step: 454/655, Loss: 2.202790, Accuracy: 18.73%\n",
            "Epoch: 33, Step: 455/655, Loss: 2.202905, Accuracy: 18.72%\n",
            "Epoch: 33, Step: 456/655, Loss: 2.203366, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 457/655, Loss: 2.203278, Accuracy: 18.72%\n",
            "Epoch: 33, Step: 458/655, Loss: 2.203445, Accuracy: 18.72%\n",
            "Epoch: 33, Step: 459/655, Loss: 2.203236, Accuracy: 18.76%\n",
            "Epoch: 33, Step: 460/655, Loss: 2.203046, Accuracy: 18.76%\n",
            "Epoch: 33, Step: 461/655, Loss: 2.203076, Accuracy: 18.73%\n",
            "Epoch: 33, Step: 462/655, Loss: 2.203144, Accuracy: 18.72%\n",
            "Epoch: 33, Step: 463/655, Loss: 2.203529, Accuracy: 18.71%\n",
            "Epoch: 33, Step: 464/655, Loss: 2.203589, Accuracy: 18.72%\n",
            "Epoch: 33, Step: 465/655, Loss: 2.203921, Accuracy: 18.72%\n",
            "Epoch: 33, Step: 466/655, Loss: 2.203831, Accuracy: 18.72%\n",
            "Epoch: 33, Step: 467/655, Loss: 2.203763, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 468/655, Loss: 2.203562, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 469/655, Loss: 2.203628, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 470/655, Loss: 2.203386, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 471/655, Loss: 2.203299, Accuracy: 18.69%\n",
            "Epoch: 33, Step: 472/655, Loss: 2.203216, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 473/655, Loss: 2.203207, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 474/655, Loss: 2.203211, Accuracy: 18.71%\n",
            "Epoch: 33, Step: 475/655, Loss: 2.203015, Accuracy: 18.74%\n",
            "Epoch: 33, Step: 476/655, Loss: 2.203062, Accuracy: 18.74%\n",
            "Epoch: 33, Step: 477/655, Loss: 2.203366, Accuracy: 18.73%\n",
            "Epoch: 33, Step: 478/655, Loss: 2.203143, Accuracy: 18.72%\n",
            "Epoch: 33, Step: 479/655, Loss: 2.203304, Accuracy: 18.72%\n",
            "Epoch: 33, Step: 480/655, Loss: 2.203650, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 481/655, Loss: 2.203711, Accuracy: 18.69%\n",
            "Epoch: 33, Step: 482/655, Loss: 2.203490, Accuracy: 18.72%\n",
            "Epoch: 33, Step: 483/655, Loss: 2.203344, Accuracy: 18.72%\n",
            "Epoch: 33, Step: 484/655, Loss: 2.203511, Accuracy: 18.69%\n",
            "Epoch: 33, Step: 485/655, Loss: 2.203484, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 486/655, Loss: 2.203246, Accuracy: 18.73%\n",
            "Epoch: 33, Step: 487/655, Loss: 2.203157, Accuracy: 18.74%\n",
            "Epoch: 33, Step: 488/655, Loss: 2.203401, Accuracy: 18.73%\n",
            "Epoch: 33, Step: 489/655, Loss: 2.203514, Accuracy: 18.72%\n",
            "Epoch: 33, Step: 490/655, Loss: 2.203601, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 491/655, Loss: 2.203573, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 492/655, Loss: 2.203630, Accuracy: 18.69%\n",
            "Epoch: 33, Step: 493/655, Loss: 2.203729, Accuracy: 18.66%\n",
            "Epoch: 33, Step: 494/655, Loss: 2.203732, Accuracy: 18.66%\n",
            "Epoch: 33, Step: 495/655, Loss: 2.203902, Accuracy: 18.66%\n",
            "Epoch: 33, Step: 496/655, Loss: 2.203543, Accuracy: 18.69%\n",
            "Epoch: 33, Step: 497/655, Loss: 2.203867, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 498/655, Loss: 2.204036, Accuracy: 18.69%\n",
            "Epoch: 33, Step: 499/655, Loss: 2.204007, Accuracy: 18.69%\n",
            "Epoch: 33, Step: 500/655, Loss: 2.204121, Accuracy: 18.69%\n",
            "Epoch: 33, Step: 501/655, Loss: 2.204273, Accuracy: 18.67%\n",
            "Epoch: 33, Step: 502/655, Loss: 2.204060, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 503/655, Loss: 2.204125, Accuracy: 18.69%\n",
            "Epoch: 33, Step: 504/655, Loss: 2.204136, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 505/655, Loss: 2.204303, Accuracy: 18.69%\n",
            "Epoch: 33, Step: 506/655, Loss: 2.204336, Accuracy: 18.69%\n",
            "Epoch: 33, Step: 507/655, Loss: 2.204374, Accuracy: 18.69%\n",
            "Epoch: 33, Step: 508/655, Loss: 2.204638, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 509/655, Loss: 2.204568, Accuracy: 18.71%\n",
            "Epoch: 33, Step: 510/655, Loss: 2.204453, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 511/655, Loss: 2.204545, Accuracy: 18.69%\n",
            "Epoch: 33, Step: 512/655, Loss: 2.204644, Accuracy: 18.70%\n",
            "Epoch: 33, Step: 513/655, Loss: 2.204815, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 514/655, Loss: 2.204848, Accuracy: 18.66%\n",
            "Epoch: 33, Step: 515/655, Loss: 2.204968, Accuracy: 18.66%\n",
            "Epoch: 33, Step: 516/655, Loss: 2.205150, Accuracy: 18.65%\n",
            "Epoch: 33, Step: 517/655, Loss: 2.204947, Accuracy: 18.67%\n",
            "Epoch: 33, Step: 518/655, Loss: 2.204906, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 519/655, Loss: 2.205102, Accuracy: 18.68%\n",
            "Epoch: 33, Step: 520/655, Loss: 2.204973, Accuracy: 18.67%\n",
            "Epoch: 33, Step: 521/655, Loss: 2.205133, Accuracy: 18.65%\n",
            "Epoch: 33, Step: 522/655, Loss: 2.205086, Accuracy: 18.63%\n",
            "Epoch: 33, Step: 523/655, Loss: 2.205148, Accuracy: 18.61%\n",
            "Epoch: 33, Step: 524/655, Loss: 2.205118, Accuracy: 18.61%\n",
            "Epoch: 33, Step: 525/655, Loss: 2.205073, Accuracy: 18.61%\n",
            "Epoch: 33, Step: 526/655, Loss: 2.205180, Accuracy: 18.61%\n",
            "Epoch: 33, Step: 527/655, Loss: 2.205138, Accuracy: 18.62%\n",
            "Epoch: 33, Step: 528/655, Loss: 2.205350, Accuracy: 18.61%\n",
            "Epoch: 33, Step: 529/655, Loss: 2.205419, Accuracy: 18.61%\n",
            "Epoch: 33, Step: 530/655, Loss: 2.205249, Accuracy: 18.63%\n",
            "Epoch: 33, Step: 531/655, Loss: 2.205450, Accuracy: 18.63%\n",
            "Epoch: 33, Step: 532/655, Loss: 2.205609, Accuracy: 18.63%\n",
            "Epoch: 33, Step: 533/655, Loss: 2.205404, Accuracy: 18.62%\n",
            "Epoch: 33, Step: 534/655, Loss: 2.205186, Accuracy: 18.63%\n",
            "Epoch: 33, Step: 535/655, Loss: 2.205038, Accuracy: 18.62%\n",
            "Epoch: 33, Step: 536/655, Loss: 2.205431, Accuracy: 18.59%\n",
            "Epoch: 33, Step: 537/655, Loss: 2.205244, Accuracy: 18.62%\n",
            "Epoch: 33, Step: 538/655, Loss: 2.205094, Accuracy: 18.62%\n",
            "Epoch: 33, Step: 539/655, Loss: 2.205089, Accuracy: 18.61%\n",
            "Epoch: 33, Step: 540/655, Loss: 2.205095, Accuracy: 18.62%\n",
            "Epoch: 33, Step: 541/655, Loss: 2.205269, Accuracy: 18.60%\n",
            "Epoch: 33, Step: 542/655, Loss: 2.205189, Accuracy: 18.59%\n",
            "Epoch: 33, Step: 543/655, Loss: 2.205503, Accuracy: 18.58%\n",
            "Epoch: 33, Step: 544/655, Loss: 2.205507, Accuracy: 18.57%\n",
            "Epoch: 33, Step: 545/655, Loss: 2.205303, Accuracy: 18.58%\n",
            "Epoch: 33, Step: 546/655, Loss: 2.205215, Accuracy: 18.60%\n",
            "Epoch: 33, Step: 547/655, Loss: 2.205089, Accuracy: 18.60%\n",
            "Epoch: 33, Step: 548/655, Loss: 2.204811, Accuracy: 18.63%\n",
            "Epoch: 33, Step: 549/655, Loss: 2.204955, Accuracy: 18.62%\n",
            "Epoch: 33, Step: 550/655, Loss: 2.205364, Accuracy: 18.61%\n",
            "Epoch: 33, Step: 551/655, Loss: 2.205518, Accuracy: 18.60%\n",
            "Epoch: 33, Step: 552/655, Loss: 2.205428, Accuracy: 18.61%\n",
            "Epoch: 33, Step: 553/655, Loss: 2.205300, Accuracy: 18.63%\n",
            "Epoch: 33, Step: 554/655, Loss: 2.205475, Accuracy: 18.62%\n",
            "Epoch: 33, Step: 555/655, Loss: 2.205438, Accuracy: 18.62%\n",
            "Epoch: 33, Step: 556/655, Loss: 2.205324, Accuracy: 18.63%\n",
            "Epoch: 33, Step: 557/655, Loss: 2.205194, Accuracy: 18.63%\n",
            "Epoch: 33, Step: 558/655, Loss: 2.205282, Accuracy: 18.62%\n",
            "Epoch: 33, Step: 559/655, Loss: 2.205187, Accuracy: 18.61%\n",
            "Epoch: 33, Step: 560/655, Loss: 2.205178, Accuracy: 18.63%\n",
            "Epoch: 33, Step: 561/655, Loss: 2.205179, Accuracy: 18.62%\n",
            "Epoch: 33, Step: 562/655, Loss: 2.205370, Accuracy: 18.59%\n",
            "Epoch: 33, Step: 563/655, Loss: 2.205376, Accuracy: 18.59%\n",
            "Epoch: 33, Step: 564/655, Loss: 2.205441, Accuracy: 18.59%\n",
            "Epoch: 33, Step: 565/655, Loss: 2.205409, Accuracy: 18.58%\n",
            "Epoch: 33, Step: 566/655, Loss: 2.205284, Accuracy: 18.61%\n",
            "Epoch: 33, Step: 567/655, Loss: 2.205542, Accuracy: 18.61%\n",
            "Epoch: 33, Step: 568/655, Loss: 2.205294, Accuracy: 18.63%\n",
            "Epoch: 33, Step: 569/655, Loss: 2.205410, Accuracy: 18.62%\n",
            "Epoch: 33, Step: 570/655, Loss: 2.205398, Accuracy: 18.63%\n",
            "Epoch: 33, Step: 571/655, Loss: 2.205301, Accuracy: 18.64%\n",
            "Epoch: 33, Step: 572/655, Loss: 2.205454, Accuracy: 18.64%\n",
            "Epoch: 33, Step: 573/655, Loss: 2.205458, Accuracy: 18.62%\n",
            "Epoch: 33, Step: 574/655, Loss: 2.205368, Accuracy: 18.63%\n",
            "Epoch: 33, Step: 575/655, Loss: 2.205609, Accuracy: 18.62%\n",
            "Epoch: 33, Step: 576/655, Loss: 2.205746, Accuracy: 18.62%\n",
            "Epoch: 33, Step: 577/655, Loss: 2.205715, Accuracy: 18.63%\n",
            "Epoch: 33, Step: 578/655, Loss: 2.205878, Accuracy: 18.61%\n",
            "Epoch: 33, Step: 579/655, Loss: 2.205975, Accuracy: 18.60%\n",
            "Epoch: 33, Step: 580/655, Loss: 2.206163, Accuracy: 18.59%\n",
            "Epoch: 33, Step: 581/655, Loss: 2.206162, Accuracy: 18.59%\n",
            "Epoch: 33, Step: 582/655, Loss: 2.206026, Accuracy: 18.58%\n",
            "Epoch: 33, Step: 583/655, Loss: 2.205969, Accuracy: 18.58%\n",
            "Epoch: 33, Step: 584/655, Loss: 2.206102, Accuracy: 18.57%\n",
            "Epoch: 33, Step: 585/655, Loss: 2.206139, Accuracy: 18.56%\n",
            "Epoch: 33, Step: 586/655, Loss: 2.206163, Accuracy: 18.56%\n",
            "Epoch: 33, Step: 587/655, Loss: 2.206139, Accuracy: 18.56%\n",
            "Epoch: 33, Step: 588/655, Loss: 2.206221, Accuracy: 18.55%\n",
            "Epoch: 33, Step: 589/655, Loss: 2.205981, Accuracy: 18.58%\n",
            "Epoch: 33, Step: 590/655, Loss: 2.206090, Accuracy: 18.58%\n",
            "Epoch: 33, Step: 591/655, Loss: 2.205998, Accuracy: 18.57%\n",
            "Epoch: 33, Step: 592/655, Loss: 2.206090, Accuracy: 18.56%\n",
            "Epoch: 33, Step: 593/655, Loss: 2.206187, Accuracy: 18.55%\n",
            "Epoch: 33, Step: 594/655, Loss: 2.206156, Accuracy: 18.56%\n",
            "Epoch: 33, Step: 595/655, Loss: 2.206394, Accuracy: 18.54%\n",
            "Epoch: 33, Step: 596/655, Loss: 2.206295, Accuracy: 18.55%\n",
            "Epoch: 33, Step: 597/655, Loss: 2.206156, Accuracy: 18.56%\n",
            "Epoch: 33, Step: 598/655, Loss: 2.206123, Accuracy: 18.55%\n",
            "Epoch: 33, Step: 599/655, Loss: 2.206243, Accuracy: 18.55%\n",
            "Epoch: 33, Step: 600/655, Loss: 2.206344, Accuracy: 18.53%\n",
            "Epoch: 33, Step: 601/655, Loss: 2.206145, Accuracy: 18.53%\n",
            "Epoch: 33, Step: 602/655, Loss: 2.206189, Accuracy: 18.53%\n",
            "Epoch: 33, Step: 603/655, Loss: 2.206304, Accuracy: 18.52%\n",
            "Epoch: 33, Step: 604/655, Loss: 2.206447, Accuracy: 18.50%\n",
            "Epoch: 33, Step: 605/655, Loss: 2.206646, Accuracy: 18.47%\n",
            "Epoch: 33, Step: 606/655, Loss: 2.206776, Accuracy: 18.46%\n",
            "Epoch: 33, Step: 607/655, Loss: 2.206926, Accuracy: 18.46%\n",
            "Epoch: 33, Step: 608/655, Loss: 2.206995, Accuracy: 18.46%\n",
            "Epoch: 33, Step: 609/655, Loss: 2.207138, Accuracy: 18.47%\n",
            "Epoch: 33, Step: 610/655, Loss: 2.207232, Accuracy: 18.45%\n",
            "Epoch: 33, Step: 611/655, Loss: 2.207365, Accuracy: 18.43%\n",
            "Epoch: 33, Step: 612/655, Loss: 2.207357, Accuracy: 18.44%\n",
            "Epoch: 33, Step: 613/655, Loss: 2.207447, Accuracy: 18.43%\n",
            "Epoch: 33, Step: 614/655, Loss: 2.207336, Accuracy: 18.45%\n",
            "Epoch: 33, Step: 615/655, Loss: 2.207300, Accuracy: 18.46%\n",
            "Epoch: 33, Step: 616/655, Loss: 2.207580, Accuracy: 18.44%\n",
            "Epoch: 33, Step: 617/655, Loss: 2.207607, Accuracy: 18.44%\n",
            "Epoch: 33, Step: 618/655, Loss: 2.207724, Accuracy: 18.42%\n",
            "Epoch: 33, Step: 619/655, Loss: 2.207904, Accuracy: 18.41%\n",
            "Epoch: 33, Step: 620/655, Loss: 2.207790, Accuracy: 18.41%\n",
            "Epoch: 33, Step: 621/655, Loss: 2.207805, Accuracy: 18.42%\n",
            "Epoch: 33, Step: 622/655, Loss: 2.207661, Accuracy: 18.43%\n",
            "Epoch: 33, Step: 623/655, Loss: 2.207646, Accuracy: 18.43%\n",
            "Epoch: 33, Step: 624/655, Loss: 2.207685, Accuracy: 18.43%\n",
            "Epoch: 33, Step: 625/655, Loss: 2.207622, Accuracy: 18.44%\n",
            "Epoch: 33, Step: 626/655, Loss: 2.207503, Accuracy: 18.46%\n",
            "Epoch: 33, Step: 627/655, Loss: 2.207415, Accuracy: 18.46%\n",
            "Epoch: 33, Step: 628/655, Loss: 2.207456, Accuracy: 18.47%\n",
            "Epoch: 33, Step: 629/655, Loss: 2.207486, Accuracy: 18.47%\n",
            "Epoch: 33, Step: 630/655, Loss: 2.207640, Accuracy: 18.45%\n",
            "Epoch: 33, Step: 631/655, Loss: 2.207864, Accuracy: 18.44%\n",
            "Epoch: 33, Step: 632/655, Loss: 2.207911, Accuracy: 18.44%\n",
            "Epoch: 33, Step: 633/655, Loss: 2.207984, Accuracy: 18.43%\n",
            "Epoch: 33, Step: 634/655, Loss: 2.207927, Accuracy: 18.43%\n",
            "Epoch: 33, Step: 635/655, Loss: 2.207629, Accuracy: 18.46%\n",
            "Epoch: 33, Step: 636/655, Loss: 2.207550, Accuracy: 18.47%\n",
            "Epoch: 33, Step: 637/655, Loss: 2.207559, Accuracy: 18.49%\n",
            "Epoch: 33, Step: 638/655, Loss: 2.207444, Accuracy: 18.49%\n",
            "Epoch: 33, Step: 639/655, Loss: 2.207410, Accuracy: 18.50%\n",
            "Epoch: 33, Step: 640/655, Loss: 2.207500, Accuracy: 18.50%\n",
            "Epoch: 33, Step: 641/655, Loss: 2.207515, Accuracy: 18.49%\n",
            "Epoch: 33, Step: 642/655, Loss: 2.207487, Accuracy: 18.50%\n",
            "Epoch: 33, Step: 643/655, Loss: 2.207123, Accuracy: 18.51%\n",
            "Epoch: 33, Step: 644/655, Loss: 2.207131, Accuracy: 18.51%\n",
            "Epoch: 33, Step: 645/655, Loss: 2.207313, Accuracy: 18.49%\n",
            "Epoch: 33, Step: 646/655, Loss: 2.207350, Accuracy: 18.48%\n",
            "Epoch: 33, Step: 647/655, Loss: 2.207591, Accuracy: 18.47%\n",
            "Epoch: 33, Step: 648/655, Loss: 2.207473, Accuracy: 18.48%\n",
            "Epoch: 33, Step: 649/655, Loss: 2.207331, Accuracy: 18.49%\n",
            "Epoch: 33, Step: 650/655, Loss: 2.207360, Accuracy: 18.48%\n",
            "Epoch: 33, Step: 651/655, Loss: 2.207490, Accuracy: 18.47%\n",
            "Epoch: 33, Step: 652/655, Loss: 2.207536, Accuracy: 18.47%\n",
            "Epoch: 33, Step: 653/655, Loss: 2.207566, Accuracy: 18.48%\n",
            "Epoch: 33, Step: 654/655, Loss: 2.207611, Accuracy: 18.47%\n",
            "Epoch: 33, Step: 655/655, Loss: 2.207598, Accuracy: 18.47%\n",
            "Epoch: 34, Step: 1/655, Loss: 2.191420, Accuracy: 15.62%\n",
            "Epoch: 34, Step: 2/655, Loss: 2.205154, Accuracy: 17.19%\n",
            "Epoch: 34, Step: 3/655, Loss: 2.252591, Accuracy: 16.67%\n",
            "Epoch: 34, Step: 4/655, Loss: 2.269291, Accuracy: 14.06%\n",
            "Epoch: 34, Step: 5/655, Loss: 2.256270, Accuracy: 17.50%\n",
            "Epoch: 34, Step: 6/655, Loss: 2.250556, Accuracy: 16.67%\n",
            "Epoch: 34, Step: 7/655, Loss: 2.247205, Accuracy: 16.07%\n",
            "Epoch: 34, Step: 8/655, Loss: 2.258968, Accuracy: 15.23%\n",
            "Epoch: 34, Step: 9/655, Loss: 2.254800, Accuracy: 15.28%\n",
            "Epoch: 34, Step: 10/655, Loss: 2.242829, Accuracy: 16.25%\n",
            "Epoch: 34, Step: 11/655, Loss: 2.241025, Accuracy: 16.19%\n",
            "Epoch: 34, Step: 12/655, Loss: 2.227760, Accuracy: 16.67%\n",
            "Epoch: 34, Step: 13/655, Loss: 2.231743, Accuracy: 15.87%\n",
            "Epoch: 34, Step: 14/655, Loss: 2.232427, Accuracy: 15.62%\n",
            "Epoch: 34, Step: 15/655, Loss: 2.216021, Accuracy: 17.08%\n",
            "Epoch: 34, Step: 16/655, Loss: 2.215932, Accuracy: 17.19%\n",
            "Epoch: 34, Step: 17/655, Loss: 2.210750, Accuracy: 18.01%\n",
            "Epoch: 34, Step: 18/655, Loss: 2.209762, Accuracy: 18.06%\n",
            "Epoch: 34, Step: 19/655, Loss: 2.216515, Accuracy: 17.43%\n",
            "Epoch: 34, Step: 20/655, Loss: 2.215600, Accuracy: 17.03%\n",
            "Epoch: 34, Step: 21/655, Loss: 2.217032, Accuracy: 17.11%\n",
            "Epoch: 34, Step: 22/655, Loss: 2.215683, Accuracy: 17.19%\n",
            "Epoch: 34, Step: 23/655, Loss: 2.214429, Accuracy: 17.39%\n",
            "Epoch: 34, Step: 24/655, Loss: 2.214141, Accuracy: 17.19%\n",
            "Epoch: 34, Step: 25/655, Loss: 2.209537, Accuracy: 17.75%\n",
            "Epoch: 34, Step: 26/655, Loss: 2.209559, Accuracy: 17.67%\n",
            "Epoch: 34, Step: 27/655, Loss: 2.210792, Accuracy: 17.59%\n",
            "Epoch: 34, Step: 28/655, Loss: 2.211749, Accuracy: 17.52%\n",
            "Epoch: 34, Step: 29/655, Loss: 2.209790, Accuracy: 17.89%\n",
            "Epoch: 34, Step: 30/655, Loss: 2.212548, Accuracy: 17.50%\n",
            "Epoch: 34, Step: 31/655, Loss: 2.210924, Accuracy: 17.44%\n",
            "Epoch: 34, Step: 32/655, Loss: 2.211428, Accuracy: 17.29%\n",
            "Epoch: 34, Step: 33/655, Loss: 2.214983, Accuracy: 16.95%\n",
            "Epoch: 34, Step: 34/655, Loss: 2.208058, Accuracy: 17.10%\n",
            "Epoch: 34, Step: 35/655, Loss: 2.209807, Accuracy: 17.41%\n",
            "Epoch: 34, Step: 36/655, Loss: 2.212900, Accuracy: 17.27%\n",
            "Epoch: 34, Step: 37/655, Loss: 2.216040, Accuracy: 17.23%\n",
            "Epoch: 34, Step: 38/655, Loss: 2.217113, Accuracy: 17.27%\n",
            "Epoch: 34, Step: 39/655, Loss: 2.214911, Accuracy: 17.71%\n",
            "Epoch: 34, Step: 40/655, Loss: 2.214606, Accuracy: 17.81%\n",
            "Epoch: 34, Step: 41/655, Loss: 2.215717, Accuracy: 17.76%\n",
            "Epoch: 34, Step: 42/655, Loss: 2.216874, Accuracy: 17.93%\n",
            "Epoch: 34, Step: 43/655, Loss: 2.216773, Accuracy: 17.88%\n",
            "Epoch: 34, Step: 44/655, Loss: 2.217259, Accuracy: 17.76%\n",
            "Epoch: 34, Step: 45/655, Loss: 2.214523, Accuracy: 18.19%\n",
            "Epoch: 34, Step: 46/655, Loss: 2.215595, Accuracy: 18.07%\n",
            "Epoch: 34, Step: 47/655, Loss: 2.216735, Accuracy: 18.02%\n",
            "Epoch: 34, Step: 48/655, Loss: 2.214762, Accuracy: 18.23%\n",
            "Epoch: 34, Step: 49/655, Loss: 2.212945, Accuracy: 18.30%\n",
            "Epoch: 34, Step: 50/655, Loss: 2.215182, Accuracy: 18.12%\n",
            "Epoch: 34, Step: 51/655, Loss: 2.213754, Accuracy: 18.32%\n",
            "Epoch: 34, Step: 52/655, Loss: 2.214366, Accuracy: 18.33%\n",
            "Epoch: 34, Step: 53/655, Loss: 2.212393, Accuracy: 18.46%\n",
            "Epoch: 34, Step: 54/655, Loss: 2.211895, Accuracy: 18.40%\n",
            "Epoch: 34, Step: 55/655, Loss: 2.211328, Accuracy: 18.52%\n",
            "Epoch: 34, Step: 56/655, Loss: 2.211970, Accuracy: 18.53%\n",
            "Epoch: 34, Step: 57/655, Loss: 2.210633, Accuracy: 18.80%\n",
            "Epoch: 34, Step: 58/655, Loss: 2.211749, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 59/655, Loss: 2.212258, Accuracy: 18.43%\n",
            "Epoch: 34, Step: 60/655, Loss: 2.212496, Accuracy: 18.65%\n",
            "Epoch: 34, Step: 61/655, Loss: 2.210196, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 62/655, Loss: 2.209949, Accuracy: 18.70%\n",
            "Epoch: 34, Step: 63/655, Loss: 2.211902, Accuracy: 18.50%\n",
            "Epoch: 34, Step: 64/655, Loss: 2.212817, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 65/655, Loss: 2.213683, Accuracy: 18.37%\n",
            "Epoch: 34, Step: 66/655, Loss: 2.215584, Accuracy: 18.32%\n",
            "Epoch: 34, Step: 67/655, Loss: 2.215908, Accuracy: 18.38%\n",
            "Epoch: 34, Step: 68/655, Loss: 2.216756, Accuracy: 18.24%\n",
            "Epoch: 34, Step: 69/655, Loss: 2.214595, Accuracy: 18.34%\n",
            "Epoch: 34, Step: 70/655, Loss: 2.215878, Accuracy: 18.26%\n",
            "Epoch: 34, Step: 71/655, Loss: 2.216522, Accuracy: 18.27%\n",
            "Epoch: 34, Step: 72/655, Loss: 2.216188, Accuracy: 18.45%\n",
            "Epoch: 34, Step: 73/655, Loss: 2.218449, Accuracy: 18.28%\n",
            "Epoch: 34, Step: 74/655, Loss: 2.219742, Accuracy: 18.29%\n",
            "Epoch: 34, Step: 75/655, Loss: 2.219726, Accuracy: 18.33%\n",
            "Epoch: 34, Step: 76/655, Loss: 2.219792, Accuracy: 18.26%\n",
            "Epoch: 34, Step: 77/655, Loss: 2.219420, Accuracy: 18.30%\n",
            "Epoch: 34, Step: 78/655, Loss: 2.221317, Accuracy: 18.19%\n",
            "Epoch: 34, Step: 79/655, Loss: 2.221533, Accuracy: 18.04%\n",
            "Epoch: 34, Step: 80/655, Loss: 2.220839, Accuracy: 18.09%\n",
            "Epoch: 34, Step: 81/655, Loss: 2.221450, Accuracy: 18.06%\n",
            "Epoch: 34, Step: 82/655, Loss: 2.220886, Accuracy: 18.06%\n",
            "Epoch: 34, Step: 83/655, Loss: 2.219809, Accuracy: 18.19%\n",
            "Epoch: 34, Step: 84/655, Loss: 2.221017, Accuracy: 18.12%\n",
            "Epoch: 34, Step: 85/655, Loss: 2.221265, Accuracy: 18.16%\n",
            "Epoch: 34, Step: 86/655, Loss: 2.222094, Accuracy: 18.10%\n",
            "Epoch: 34, Step: 87/655, Loss: 2.219584, Accuracy: 18.18%\n",
            "Epoch: 34, Step: 88/655, Loss: 2.219450, Accuracy: 18.22%\n",
            "Epoch: 34, Step: 89/655, Loss: 2.219008, Accuracy: 18.26%\n",
            "Epoch: 34, Step: 90/655, Loss: 2.219052, Accuracy: 18.33%\n",
            "Epoch: 34, Step: 91/655, Loss: 2.218823, Accuracy: 18.37%\n",
            "Epoch: 34, Step: 92/655, Loss: 2.218920, Accuracy: 18.34%\n",
            "Epoch: 34, Step: 93/655, Loss: 2.217480, Accuracy: 18.51%\n",
            "Epoch: 34, Step: 94/655, Loss: 2.217222, Accuracy: 18.52%\n",
            "Epoch: 34, Step: 95/655, Loss: 2.219151, Accuracy: 18.39%\n",
            "Epoch: 34, Step: 96/655, Loss: 2.218438, Accuracy: 18.36%\n",
            "Epoch: 34, Step: 97/655, Loss: 2.217492, Accuracy: 18.30%\n",
            "Epoch: 34, Step: 98/655, Loss: 2.218870, Accuracy: 18.24%\n",
            "Epoch: 34, Step: 99/655, Loss: 2.218268, Accuracy: 18.18%\n",
            "Epoch: 34, Step: 100/655, Loss: 2.217457, Accuracy: 18.22%\n",
            "Epoch: 34, Step: 101/655, Loss: 2.217867, Accuracy: 18.19%\n",
            "Epoch: 34, Step: 102/655, Loss: 2.218080, Accuracy: 18.23%\n",
            "Epoch: 34, Step: 103/655, Loss: 2.216983, Accuracy: 18.20%\n",
            "Epoch: 34, Step: 104/655, Loss: 2.217874, Accuracy: 18.18%\n",
            "Epoch: 34, Step: 105/655, Loss: 2.217327, Accuracy: 18.27%\n",
            "Epoch: 34, Step: 106/655, Loss: 2.217007, Accuracy: 18.22%\n",
            "Epoch: 34, Step: 107/655, Loss: 2.216112, Accuracy: 18.22%\n",
            "Epoch: 34, Step: 108/655, Loss: 2.215355, Accuracy: 18.14%\n",
            "Epoch: 34, Step: 109/655, Loss: 2.215538, Accuracy: 18.12%\n",
            "Epoch: 34, Step: 110/655, Loss: 2.216000, Accuracy: 18.15%\n",
            "Epoch: 34, Step: 111/655, Loss: 2.215505, Accuracy: 18.22%\n",
            "Epoch: 34, Step: 112/655, Loss: 2.215632, Accuracy: 18.25%\n",
            "Epoch: 34, Step: 113/655, Loss: 2.213602, Accuracy: 18.34%\n",
            "Epoch: 34, Step: 114/655, Loss: 2.213679, Accuracy: 18.31%\n",
            "Epoch: 34, Step: 115/655, Loss: 2.213655, Accuracy: 18.32%\n",
            "Epoch: 34, Step: 116/655, Loss: 2.213863, Accuracy: 18.29%\n",
            "Epoch: 34, Step: 117/655, Loss: 2.215253, Accuracy: 18.22%\n",
            "Epoch: 34, Step: 118/655, Loss: 2.216065, Accuracy: 18.17%\n",
            "Epoch: 34, Step: 119/655, Loss: 2.215983, Accuracy: 18.17%\n",
            "Epoch: 34, Step: 120/655, Loss: 2.215126, Accuracy: 18.23%\n",
            "Epoch: 34, Step: 121/655, Loss: 2.215012, Accuracy: 18.29%\n",
            "Epoch: 34, Step: 122/655, Loss: 2.215330, Accuracy: 18.39%\n",
            "Epoch: 34, Step: 123/655, Loss: 2.214852, Accuracy: 18.42%\n",
            "Epoch: 34, Step: 124/655, Loss: 2.215523, Accuracy: 18.37%\n",
            "Epoch: 34, Step: 125/655, Loss: 2.214199, Accuracy: 18.40%\n",
            "Epoch: 34, Step: 126/655, Loss: 2.213531, Accuracy: 18.43%\n",
            "Epoch: 34, Step: 127/655, Loss: 2.213749, Accuracy: 18.36%\n",
            "Epoch: 34, Step: 128/655, Loss: 2.213720, Accuracy: 18.33%\n",
            "Epoch: 34, Step: 129/655, Loss: 2.214862, Accuracy: 18.24%\n",
            "Epoch: 34, Step: 130/655, Loss: 2.214084, Accuracy: 18.27%\n",
            "Epoch: 34, Step: 131/655, Loss: 2.214987, Accuracy: 18.23%\n",
            "Epoch: 34, Step: 132/655, Loss: 2.214281, Accuracy: 18.23%\n",
            "Epoch: 34, Step: 133/655, Loss: 2.213823, Accuracy: 18.23%\n",
            "Epoch: 34, Step: 134/655, Loss: 2.213251, Accuracy: 18.28%\n",
            "Epoch: 34, Step: 135/655, Loss: 2.213355, Accuracy: 18.31%\n",
            "Epoch: 34, Step: 136/655, Loss: 2.212874, Accuracy: 18.29%\n",
            "Epoch: 34, Step: 137/655, Loss: 2.212440, Accuracy: 18.43%\n",
            "Epoch: 34, Step: 138/655, Loss: 2.212584, Accuracy: 18.41%\n",
            "Epoch: 34, Step: 139/655, Loss: 2.212374, Accuracy: 18.50%\n",
            "Epoch: 34, Step: 140/655, Loss: 2.212896, Accuracy: 18.44%\n",
            "Epoch: 34, Step: 141/655, Loss: 2.212128, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 142/655, Loss: 2.212077, Accuracy: 18.62%\n",
            "Epoch: 34, Step: 143/655, Loss: 2.212531, Accuracy: 18.66%\n",
            "Epoch: 34, Step: 144/655, Loss: 2.212587, Accuracy: 18.68%\n",
            "Epoch: 34, Step: 145/655, Loss: 2.212008, Accuracy: 18.64%\n",
            "Epoch: 34, Step: 146/655, Loss: 2.211641, Accuracy: 18.66%\n",
            "Epoch: 34, Step: 147/655, Loss: 2.211447, Accuracy: 18.69%\n",
            "Epoch: 34, Step: 148/655, Loss: 2.211417, Accuracy: 18.62%\n",
            "Epoch: 34, Step: 149/655, Loss: 2.211638, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 150/655, Loss: 2.211467, Accuracy: 18.65%\n",
            "Epoch: 34, Step: 151/655, Loss: 2.211049, Accuracy: 18.65%\n",
            "Epoch: 34, Step: 152/655, Loss: 2.211500, Accuracy: 18.65%\n",
            "Epoch: 34, Step: 153/655, Loss: 2.210938, Accuracy: 18.73%\n",
            "Epoch: 34, Step: 154/655, Loss: 2.211009, Accuracy: 18.69%\n",
            "Epoch: 34, Step: 155/655, Loss: 2.210903, Accuracy: 18.69%\n",
            "Epoch: 34, Step: 156/655, Loss: 2.210230, Accuracy: 18.75%\n",
            "Epoch: 34, Step: 157/655, Loss: 2.210859, Accuracy: 18.71%\n",
            "Epoch: 34, Step: 158/655, Loss: 2.210188, Accuracy: 18.77%\n",
            "Epoch: 34, Step: 159/655, Loss: 2.209914, Accuracy: 18.77%\n",
            "Epoch: 34, Step: 160/655, Loss: 2.210226, Accuracy: 18.77%\n",
            "Epoch: 34, Step: 161/655, Loss: 2.209881, Accuracy: 18.83%\n",
            "Epoch: 34, Step: 162/655, Loss: 2.209873, Accuracy: 18.79%\n",
            "Epoch: 34, Step: 163/655, Loss: 2.209545, Accuracy: 18.83%\n",
            "Epoch: 34, Step: 164/655, Loss: 2.209527, Accuracy: 18.75%\n",
            "Epoch: 34, Step: 165/655, Loss: 2.210512, Accuracy: 18.73%\n",
            "Epoch: 34, Step: 166/655, Loss: 2.210937, Accuracy: 18.69%\n",
            "Epoch: 34, Step: 167/655, Loss: 2.211846, Accuracy: 18.62%\n",
            "Epoch: 34, Step: 168/655, Loss: 2.211930, Accuracy: 18.56%\n",
            "Epoch: 34, Step: 169/655, Loss: 2.210980, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 170/655, Loss: 2.211783, Accuracy: 18.53%\n",
            "Epoch: 34, Step: 171/655, Loss: 2.211953, Accuracy: 18.51%\n",
            "Epoch: 34, Step: 172/655, Loss: 2.212147, Accuracy: 18.46%\n",
            "Epoch: 34, Step: 173/655, Loss: 2.211694, Accuracy: 18.53%\n",
            "Epoch: 34, Step: 174/655, Loss: 2.211722, Accuracy: 18.50%\n",
            "Epoch: 34, Step: 175/655, Loss: 2.211823, Accuracy: 18.48%\n",
            "Epoch: 34, Step: 176/655, Loss: 2.212083, Accuracy: 18.47%\n",
            "Epoch: 34, Step: 177/655, Loss: 2.211873, Accuracy: 18.47%\n",
            "Epoch: 34, Step: 178/655, Loss: 2.211779, Accuracy: 18.49%\n",
            "Epoch: 34, Step: 179/655, Loss: 2.211962, Accuracy: 18.47%\n",
            "Epoch: 34, Step: 180/655, Loss: 2.211691, Accuracy: 18.52%\n",
            "Epoch: 34, Step: 181/655, Loss: 2.211868, Accuracy: 18.49%\n",
            "Epoch: 34, Step: 182/655, Loss: 2.211915, Accuracy: 18.49%\n",
            "Epoch: 34, Step: 183/655, Loss: 2.212045, Accuracy: 18.56%\n",
            "Epoch: 34, Step: 184/655, Loss: 2.212137, Accuracy: 18.51%\n",
            "Epoch: 34, Step: 185/655, Loss: 2.212043, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 186/655, Loss: 2.212411, Accuracy: 18.50%\n",
            "Epoch: 34, Step: 187/655, Loss: 2.212366, Accuracy: 18.48%\n",
            "Epoch: 34, Step: 188/655, Loss: 2.212051, Accuracy: 18.43%\n",
            "Epoch: 34, Step: 189/655, Loss: 2.211604, Accuracy: 18.47%\n",
            "Epoch: 34, Step: 190/655, Loss: 2.211616, Accuracy: 18.44%\n",
            "Epoch: 34, Step: 191/655, Loss: 2.211939, Accuracy: 18.42%\n",
            "Epoch: 34, Step: 192/655, Loss: 2.212232, Accuracy: 18.41%\n",
            "Epoch: 34, Step: 193/655, Loss: 2.212233, Accuracy: 18.36%\n",
            "Epoch: 34, Step: 194/655, Loss: 2.211650, Accuracy: 18.43%\n",
            "Epoch: 34, Step: 195/655, Loss: 2.211869, Accuracy: 18.40%\n",
            "Epoch: 34, Step: 196/655, Loss: 2.211731, Accuracy: 18.38%\n",
            "Epoch: 34, Step: 197/655, Loss: 2.211509, Accuracy: 18.43%\n",
            "Epoch: 34, Step: 198/655, Loss: 2.210930, Accuracy: 18.50%\n",
            "Epoch: 34, Step: 199/655, Loss: 2.210731, Accuracy: 18.51%\n",
            "Epoch: 34, Step: 200/655, Loss: 2.210427, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 201/655, Loss: 2.211306, Accuracy: 18.50%\n",
            "Epoch: 34, Step: 202/655, Loss: 2.210636, Accuracy: 18.53%\n",
            "Epoch: 34, Step: 203/655, Loss: 2.210574, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 204/655, Loss: 2.210181, Accuracy: 18.52%\n",
            "Epoch: 34, Step: 205/655, Loss: 2.210415, Accuracy: 18.49%\n",
            "Epoch: 34, Step: 206/655, Loss: 2.210945, Accuracy: 18.48%\n",
            "Epoch: 34, Step: 207/655, Loss: 2.210415, Accuracy: 18.49%\n",
            "Epoch: 34, Step: 208/655, Loss: 2.210433, Accuracy: 18.52%\n",
            "Epoch: 34, Step: 209/655, Loss: 2.210488, Accuracy: 18.53%\n",
            "Epoch: 34, Step: 210/655, Loss: 2.209933, Accuracy: 18.53%\n",
            "Epoch: 34, Step: 211/655, Loss: 2.209765, Accuracy: 18.48%\n",
            "Epoch: 34, Step: 212/655, Loss: 2.210009, Accuracy: 18.48%\n",
            "Epoch: 34, Step: 213/655, Loss: 2.210052, Accuracy: 18.52%\n",
            "Epoch: 34, Step: 214/655, Loss: 2.209878, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 215/655, Loss: 2.209818, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 216/655, Loss: 2.209703, Accuracy: 18.61%\n",
            "Epoch: 34, Step: 217/655, Loss: 2.209088, Accuracy: 18.63%\n",
            "Epoch: 34, Step: 218/655, Loss: 2.208866, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 219/655, Loss: 2.208659, Accuracy: 18.61%\n",
            "Epoch: 34, Step: 220/655, Loss: 2.208623, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 221/655, Loss: 2.208803, Accuracy: 18.62%\n",
            "Epoch: 34, Step: 222/655, Loss: 2.208795, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 223/655, Loss: 2.208779, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 224/655, Loss: 2.208469, Accuracy: 18.61%\n",
            "Epoch: 34, Step: 225/655, Loss: 2.208524, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 226/655, Loss: 2.208756, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 227/655, Loss: 2.208335, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 228/655, Loss: 2.208596, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 229/655, Loss: 2.208447, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 230/655, Loss: 2.208441, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 231/655, Loss: 2.208945, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 232/655, Loss: 2.209637, Accuracy: 18.51%\n",
            "Epoch: 34, Step: 233/655, Loss: 2.209440, Accuracy: 18.54%\n",
            "Epoch: 34, Step: 234/655, Loss: 2.209970, Accuracy: 18.54%\n",
            "Epoch: 34, Step: 235/655, Loss: 2.209336, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 236/655, Loss: 2.209348, Accuracy: 18.54%\n",
            "Epoch: 34, Step: 237/655, Loss: 2.209059, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 238/655, Loss: 2.209048, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 239/655, Loss: 2.208722, Accuracy: 18.65%\n",
            "Epoch: 34, Step: 240/655, Loss: 2.208456, Accuracy: 18.63%\n",
            "Epoch: 34, Step: 241/655, Loss: 2.208753, Accuracy: 18.62%\n",
            "Epoch: 34, Step: 242/655, Loss: 2.208664, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 243/655, Loss: 2.208600, Accuracy: 18.62%\n",
            "Epoch: 34, Step: 244/655, Loss: 2.208774, Accuracy: 18.63%\n",
            "Epoch: 34, Step: 245/655, Loss: 2.209667, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 246/655, Loss: 2.209394, Accuracy: 18.56%\n",
            "Epoch: 34, Step: 247/655, Loss: 2.209395, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 248/655, Loss: 2.209364, Accuracy: 18.65%\n",
            "Epoch: 34, Step: 249/655, Loss: 2.208963, Accuracy: 18.66%\n",
            "Epoch: 34, Step: 250/655, Loss: 2.208462, Accuracy: 18.70%\n",
            "Epoch: 34, Step: 251/655, Loss: 2.208342, Accuracy: 18.70%\n",
            "Epoch: 34, Step: 252/655, Loss: 2.207828, Accuracy: 18.75%\n",
            "Epoch: 34, Step: 253/655, Loss: 2.207475, Accuracy: 18.75%\n",
            "Epoch: 34, Step: 254/655, Loss: 2.207329, Accuracy: 18.70%\n",
            "Epoch: 34, Step: 255/655, Loss: 2.207628, Accuracy: 18.68%\n",
            "Epoch: 34, Step: 256/655, Loss: 2.207366, Accuracy: 18.68%\n",
            "Epoch: 34, Step: 257/655, Loss: 2.207805, Accuracy: 18.64%\n",
            "Epoch: 34, Step: 258/655, Loss: 2.207710, Accuracy: 18.69%\n",
            "Epoch: 34, Step: 259/655, Loss: 2.207242, Accuracy: 18.74%\n",
            "Epoch: 34, Step: 260/655, Loss: 2.207528, Accuracy: 18.75%\n",
            "Epoch: 34, Step: 261/655, Loss: 2.207546, Accuracy: 18.74%\n",
            "Epoch: 34, Step: 262/655, Loss: 2.207763, Accuracy: 18.74%\n",
            "Epoch: 34, Step: 263/655, Loss: 2.207924, Accuracy: 18.71%\n",
            "Epoch: 34, Step: 264/655, Loss: 2.207723, Accuracy: 18.71%\n",
            "Epoch: 34, Step: 265/655, Loss: 2.207831, Accuracy: 18.71%\n",
            "Epoch: 34, Step: 266/655, Loss: 2.207752, Accuracy: 18.73%\n",
            "Epoch: 34, Step: 267/655, Loss: 2.207660, Accuracy: 18.73%\n",
            "Epoch: 34, Step: 268/655, Loss: 2.207249, Accuracy: 18.76%\n",
            "Epoch: 34, Step: 269/655, Loss: 2.207503, Accuracy: 18.77%\n",
            "Epoch: 34, Step: 270/655, Loss: 2.207266, Accuracy: 18.77%\n",
            "Epoch: 34, Step: 271/655, Loss: 2.206720, Accuracy: 18.82%\n",
            "Epoch: 34, Step: 272/655, Loss: 2.206871, Accuracy: 18.81%\n",
            "Epoch: 34, Step: 273/655, Loss: 2.206811, Accuracy: 18.78%\n",
            "Epoch: 34, Step: 274/655, Loss: 2.206554, Accuracy: 18.77%\n",
            "Epoch: 34, Step: 275/655, Loss: 2.206667, Accuracy: 18.80%\n",
            "Epoch: 34, Step: 276/655, Loss: 2.206473, Accuracy: 18.84%\n",
            "Epoch: 34, Step: 277/655, Loss: 2.206099, Accuracy: 18.83%\n",
            "Epoch: 34, Step: 278/655, Loss: 2.206187, Accuracy: 18.81%\n",
            "Epoch: 34, Step: 279/655, Loss: 2.206650, Accuracy: 18.77%\n",
            "Epoch: 34, Step: 280/655, Loss: 2.207005, Accuracy: 18.76%\n",
            "Epoch: 34, Step: 281/655, Loss: 2.206810, Accuracy: 18.79%\n",
            "Epoch: 34, Step: 282/655, Loss: 2.206760, Accuracy: 18.79%\n",
            "Epoch: 34, Step: 283/655, Loss: 2.206978, Accuracy: 18.76%\n",
            "Epoch: 34, Step: 284/655, Loss: 2.206614, Accuracy: 18.79%\n",
            "Epoch: 34, Step: 285/655, Loss: 2.206290, Accuracy: 18.78%\n",
            "Epoch: 34, Step: 286/655, Loss: 2.206576, Accuracy: 18.75%\n",
            "Epoch: 34, Step: 287/655, Loss: 2.206578, Accuracy: 18.74%\n",
            "Epoch: 34, Step: 288/655, Loss: 2.206422, Accuracy: 18.79%\n",
            "Epoch: 34, Step: 289/655, Loss: 2.206676, Accuracy: 18.79%\n",
            "Epoch: 34, Step: 290/655, Loss: 2.206401, Accuracy: 18.81%\n",
            "Epoch: 34, Step: 291/655, Loss: 2.206465, Accuracy: 18.79%\n",
            "Epoch: 34, Step: 292/655, Loss: 2.206292, Accuracy: 18.81%\n",
            "Epoch: 34, Step: 293/655, Loss: 2.206120, Accuracy: 18.86%\n",
            "Epoch: 34, Step: 294/655, Loss: 2.206140, Accuracy: 18.89%\n",
            "Epoch: 34, Step: 295/655, Loss: 2.205921, Accuracy: 18.91%\n",
            "Epoch: 34, Step: 296/655, Loss: 2.205429, Accuracy: 18.92%\n",
            "Epoch: 34, Step: 297/655, Loss: 2.205177, Accuracy: 18.96%\n",
            "Epoch: 34, Step: 298/655, Loss: 2.205714, Accuracy: 18.93%\n",
            "Epoch: 34, Step: 299/655, Loss: 2.205674, Accuracy: 18.93%\n",
            "Epoch: 34, Step: 300/655, Loss: 2.205555, Accuracy: 18.94%\n",
            "Epoch: 34, Step: 301/655, Loss: 2.205574, Accuracy: 18.96%\n",
            "Epoch: 34, Step: 302/655, Loss: 2.205424, Accuracy: 18.98%\n",
            "Epoch: 34, Step: 303/655, Loss: 2.205629, Accuracy: 18.95%\n",
            "Epoch: 34, Step: 304/655, Loss: 2.205898, Accuracy: 18.94%\n",
            "Epoch: 34, Step: 305/655, Loss: 2.206004, Accuracy: 18.97%\n",
            "Epoch: 34, Step: 306/655, Loss: 2.205884, Accuracy: 18.97%\n",
            "Epoch: 34, Step: 307/655, Loss: 2.206091, Accuracy: 18.94%\n",
            "Epoch: 34, Step: 308/655, Loss: 2.206020, Accuracy: 18.95%\n",
            "Epoch: 34, Step: 309/655, Loss: 2.206017, Accuracy: 18.96%\n",
            "Epoch: 34, Step: 310/655, Loss: 2.205715, Accuracy: 18.98%\n",
            "Epoch: 34, Step: 311/655, Loss: 2.205948, Accuracy: 18.97%\n",
            "Epoch: 34, Step: 312/655, Loss: 2.206072, Accuracy: 18.95%\n",
            "Epoch: 34, Step: 313/655, Loss: 2.205867, Accuracy: 18.98%\n",
            "Epoch: 34, Step: 314/655, Loss: 2.205881, Accuracy: 19.00%\n",
            "Epoch: 34, Step: 315/655, Loss: 2.205309, Accuracy: 19.04%\n",
            "Epoch: 34, Step: 316/655, Loss: 2.205144, Accuracy: 19.06%\n",
            "Epoch: 34, Step: 317/655, Loss: 2.205294, Accuracy: 19.09%\n",
            "Epoch: 34, Step: 318/655, Loss: 2.205291, Accuracy: 19.09%\n",
            "Epoch: 34, Step: 319/655, Loss: 2.205456, Accuracy: 19.09%\n",
            "Epoch: 34, Step: 320/655, Loss: 2.205355, Accuracy: 19.09%\n",
            "Epoch: 34, Step: 321/655, Loss: 2.205484, Accuracy: 19.08%\n",
            "Epoch: 34, Step: 322/655, Loss: 2.205640, Accuracy: 19.05%\n",
            "Epoch: 34, Step: 323/655, Loss: 2.206245, Accuracy: 19.03%\n",
            "Epoch: 34, Step: 324/655, Loss: 2.206205, Accuracy: 19.05%\n",
            "Epoch: 34, Step: 325/655, Loss: 2.206040, Accuracy: 19.03%\n",
            "Epoch: 34, Step: 326/655, Loss: 2.206021, Accuracy: 19.02%\n",
            "Epoch: 34, Step: 327/655, Loss: 2.206108, Accuracy: 18.98%\n",
            "Epoch: 34, Step: 328/655, Loss: 2.205920, Accuracy: 19.02%\n",
            "Epoch: 34, Step: 329/655, Loss: 2.206037, Accuracy: 19.03%\n",
            "Epoch: 34, Step: 330/655, Loss: 2.206252, Accuracy: 19.01%\n",
            "Epoch: 34, Step: 331/655, Loss: 2.206373, Accuracy: 18.99%\n",
            "Epoch: 34, Step: 332/655, Loss: 2.206454, Accuracy: 18.96%\n",
            "Epoch: 34, Step: 333/655, Loss: 2.206542, Accuracy: 18.98%\n",
            "Epoch: 34, Step: 334/655, Loss: 2.206857, Accuracy: 18.98%\n",
            "Epoch: 34, Step: 335/655, Loss: 2.206711, Accuracy: 19.03%\n",
            "Epoch: 34, Step: 336/655, Loss: 2.206754, Accuracy: 19.05%\n",
            "Epoch: 34, Step: 337/655, Loss: 2.206743, Accuracy: 19.06%\n",
            "Epoch: 34, Step: 338/655, Loss: 2.206327, Accuracy: 19.06%\n",
            "Epoch: 34, Step: 339/655, Loss: 2.206240, Accuracy: 19.07%\n",
            "Epoch: 34, Step: 340/655, Loss: 2.206316, Accuracy: 19.05%\n",
            "Epoch: 34, Step: 341/655, Loss: 2.206742, Accuracy: 19.01%\n",
            "Epoch: 34, Step: 342/655, Loss: 2.206535, Accuracy: 19.01%\n",
            "Epoch: 34, Step: 343/655, Loss: 2.206290, Accuracy: 19.01%\n",
            "Epoch: 34, Step: 344/655, Loss: 2.206355, Accuracy: 19.00%\n",
            "Epoch: 34, Step: 345/655, Loss: 2.206494, Accuracy: 18.99%\n",
            "Epoch: 34, Step: 346/655, Loss: 2.206142, Accuracy: 19.03%\n",
            "Epoch: 34, Step: 347/655, Loss: 2.205833, Accuracy: 19.06%\n",
            "Epoch: 34, Step: 348/655, Loss: 2.205914, Accuracy: 19.06%\n",
            "Epoch: 34, Step: 349/655, Loss: 2.206115, Accuracy: 19.06%\n",
            "Epoch: 34, Step: 350/655, Loss: 2.205970, Accuracy: 19.07%\n",
            "Epoch: 34, Step: 351/655, Loss: 2.206106, Accuracy: 19.07%\n",
            "Epoch: 34, Step: 352/655, Loss: 2.206488, Accuracy: 19.03%\n",
            "Epoch: 34, Step: 353/655, Loss: 2.206665, Accuracy: 19.02%\n",
            "Epoch: 34, Step: 354/655, Loss: 2.206683, Accuracy: 19.02%\n",
            "Epoch: 34, Step: 355/655, Loss: 2.206591, Accuracy: 19.01%\n",
            "Epoch: 34, Step: 356/655, Loss: 2.206634, Accuracy: 19.02%\n",
            "Epoch: 34, Step: 357/655, Loss: 2.206668, Accuracy: 19.00%\n",
            "Epoch: 34, Step: 358/655, Loss: 2.206374, Accuracy: 19.00%\n",
            "Epoch: 34, Step: 359/655, Loss: 2.206315, Accuracy: 18.99%\n",
            "Epoch: 34, Step: 360/655, Loss: 2.206164, Accuracy: 18.98%\n",
            "Epoch: 34, Step: 361/655, Loss: 2.206363, Accuracy: 18.97%\n",
            "Epoch: 34, Step: 362/655, Loss: 2.206461, Accuracy: 18.96%\n",
            "Epoch: 34, Step: 363/655, Loss: 2.206300, Accuracy: 18.97%\n",
            "Epoch: 34, Step: 364/655, Loss: 2.206259, Accuracy: 18.98%\n",
            "Epoch: 34, Step: 365/655, Loss: 2.206463, Accuracy: 18.96%\n",
            "Epoch: 34, Step: 366/655, Loss: 2.206557, Accuracy: 18.96%\n",
            "Epoch: 34, Step: 367/655, Loss: 2.206460, Accuracy: 18.95%\n",
            "Epoch: 34, Step: 368/655, Loss: 2.206499, Accuracy: 18.94%\n",
            "Epoch: 34, Step: 369/655, Loss: 2.206527, Accuracy: 18.93%\n",
            "Epoch: 34, Step: 370/655, Loss: 2.206845, Accuracy: 18.90%\n",
            "Epoch: 34, Step: 371/655, Loss: 2.206698, Accuracy: 18.90%\n",
            "Epoch: 34, Step: 372/655, Loss: 2.206770, Accuracy: 18.88%\n",
            "Epoch: 34, Step: 373/655, Loss: 2.206482, Accuracy: 18.92%\n",
            "Epoch: 34, Step: 374/655, Loss: 2.206806, Accuracy: 18.90%\n",
            "Epoch: 34, Step: 375/655, Loss: 2.206735, Accuracy: 18.93%\n",
            "Epoch: 34, Step: 376/655, Loss: 2.206699, Accuracy: 18.92%\n",
            "Epoch: 34, Step: 377/655, Loss: 2.206900, Accuracy: 18.93%\n",
            "Epoch: 34, Step: 378/655, Loss: 2.206889, Accuracy: 18.94%\n",
            "Epoch: 34, Step: 379/655, Loss: 2.207057, Accuracy: 18.93%\n",
            "Epoch: 34, Step: 380/655, Loss: 2.206958, Accuracy: 18.91%\n",
            "Epoch: 34, Step: 381/655, Loss: 2.206780, Accuracy: 18.88%\n",
            "Epoch: 34, Step: 382/655, Loss: 2.206701, Accuracy: 18.88%\n",
            "Epoch: 34, Step: 383/655, Loss: 2.206809, Accuracy: 18.89%\n",
            "Epoch: 34, Step: 384/655, Loss: 2.206655, Accuracy: 18.86%\n",
            "Epoch: 34, Step: 385/655, Loss: 2.206709, Accuracy: 18.87%\n",
            "Epoch: 34, Step: 386/655, Loss: 2.206295, Accuracy: 18.91%\n",
            "Epoch: 34, Step: 387/655, Loss: 2.206068, Accuracy: 18.94%\n",
            "Epoch: 34, Step: 388/655, Loss: 2.205978, Accuracy: 18.93%\n",
            "Epoch: 34, Step: 389/655, Loss: 2.206005, Accuracy: 18.93%\n",
            "Epoch: 34, Step: 390/655, Loss: 2.205910, Accuracy: 18.97%\n",
            "Epoch: 34, Step: 391/655, Loss: 2.205945, Accuracy: 18.97%\n",
            "Epoch: 34, Step: 392/655, Loss: 2.206083, Accuracy: 18.98%\n",
            "Epoch: 34, Step: 393/655, Loss: 2.206344, Accuracy: 18.95%\n",
            "Epoch: 34, Step: 394/655, Loss: 2.206288, Accuracy: 18.94%\n",
            "Epoch: 34, Step: 395/655, Loss: 2.206417, Accuracy: 18.95%\n",
            "Epoch: 34, Step: 396/655, Loss: 2.206338, Accuracy: 18.97%\n",
            "Epoch: 34, Step: 397/655, Loss: 2.206624, Accuracy: 18.97%\n",
            "Epoch: 34, Step: 398/655, Loss: 2.206719, Accuracy: 18.95%\n",
            "Epoch: 34, Step: 399/655, Loss: 2.206498, Accuracy: 18.95%\n",
            "Epoch: 34, Step: 400/655, Loss: 2.206393, Accuracy: 18.94%\n",
            "Epoch: 34, Step: 401/655, Loss: 2.206829, Accuracy: 18.90%\n",
            "Epoch: 34, Step: 402/655, Loss: 2.206717, Accuracy: 18.91%\n",
            "Epoch: 34, Step: 403/655, Loss: 2.206832, Accuracy: 18.91%\n",
            "Epoch: 34, Step: 404/655, Loss: 2.206971, Accuracy: 18.90%\n",
            "Epoch: 34, Step: 405/655, Loss: 2.206879, Accuracy: 18.90%\n",
            "Epoch: 34, Step: 406/655, Loss: 2.206812, Accuracy: 18.90%\n",
            "Epoch: 34, Step: 407/655, Loss: 2.206910, Accuracy: 18.89%\n",
            "Epoch: 34, Step: 408/655, Loss: 2.206830, Accuracy: 18.90%\n",
            "Epoch: 34, Step: 409/655, Loss: 2.206974, Accuracy: 18.89%\n",
            "Epoch: 34, Step: 410/655, Loss: 2.206801, Accuracy: 18.89%\n",
            "Epoch: 34, Step: 411/655, Loss: 2.207215, Accuracy: 18.88%\n",
            "Epoch: 34, Step: 412/655, Loss: 2.207220, Accuracy: 18.89%\n",
            "Epoch: 34, Step: 413/655, Loss: 2.207275, Accuracy: 18.88%\n",
            "Epoch: 34, Step: 414/655, Loss: 2.207140, Accuracy: 18.91%\n",
            "Epoch: 34, Step: 415/655, Loss: 2.207107, Accuracy: 18.90%\n",
            "Epoch: 34, Step: 416/655, Loss: 2.207147, Accuracy: 18.88%\n",
            "Epoch: 34, Step: 417/655, Loss: 2.207180, Accuracy: 18.85%\n",
            "Epoch: 34, Step: 418/655, Loss: 2.207128, Accuracy: 18.87%\n",
            "Epoch: 34, Step: 419/655, Loss: 2.207205, Accuracy: 18.86%\n",
            "Epoch: 34, Step: 420/655, Loss: 2.206995, Accuracy: 18.91%\n",
            "Epoch: 34, Step: 421/655, Loss: 2.206823, Accuracy: 18.93%\n",
            "Epoch: 34, Step: 422/655, Loss: 2.207077, Accuracy: 18.91%\n",
            "Epoch: 34, Step: 423/655, Loss: 2.207232, Accuracy: 18.89%\n",
            "Epoch: 34, Step: 424/655, Loss: 2.207528, Accuracy: 18.89%\n",
            "Epoch: 34, Step: 425/655, Loss: 2.207079, Accuracy: 18.90%\n",
            "Epoch: 34, Step: 426/655, Loss: 2.207237, Accuracy: 18.91%\n",
            "Epoch: 34, Step: 427/655, Loss: 2.207355, Accuracy: 18.90%\n",
            "Epoch: 34, Step: 428/655, Loss: 2.207604, Accuracy: 18.89%\n",
            "Epoch: 34, Step: 429/655, Loss: 2.207778, Accuracy: 18.90%\n",
            "Epoch: 34, Step: 430/655, Loss: 2.207508, Accuracy: 18.90%\n",
            "Epoch: 34, Step: 431/655, Loss: 2.207621, Accuracy: 18.92%\n",
            "Epoch: 34, Step: 432/655, Loss: 2.207656, Accuracy: 18.89%\n",
            "Epoch: 34, Step: 433/655, Loss: 2.207438, Accuracy: 18.92%\n",
            "Epoch: 34, Step: 434/655, Loss: 2.207374, Accuracy: 18.92%\n",
            "Epoch: 34, Step: 435/655, Loss: 2.207120, Accuracy: 18.92%\n",
            "Epoch: 34, Step: 436/655, Loss: 2.207267, Accuracy: 18.89%\n",
            "Epoch: 34, Step: 437/655, Loss: 2.207025, Accuracy: 18.89%\n",
            "Epoch: 34, Step: 438/655, Loss: 2.207459, Accuracy: 18.86%\n",
            "Epoch: 34, Step: 439/655, Loss: 2.207289, Accuracy: 18.86%\n",
            "Epoch: 34, Step: 440/655, Loss: 2.207748, Accuracy: 18.84%\n",
            "Epoch: 34, Step: 441/655, Loss: 2.207675, Accuracy: 18.86%\n",
            "Epoch: 34, Step: 442/655, Loss: 2.207711, Accuracy: 18.84%\n",
            "Epoch: 34, Step: 443/655, Loss: 2.207577, Accuracy: 18.87%\n",
            "Epoch: 34, Step: 444/655, Loss: 2.207520, Accuracy: 18.85%\n",
            "Epoch: 34, Step: 445/655, Loss: 2.207639, Accuracy: 18.86%\n",
            "Epoch: 34, Step: 446/655, Loss: 2.207249, Accuracy: 18.87%\n",
            "Epoch: 34, Step: 447/655, Loss: 2.207323, Accuracy: 18.86%\n",
            "Epoch: 34, Step: 448/655, Loss: 2.207350, Accuracy: 18.87%\n",
            "Epoch: 34, Step: 449/655, Loss: 2.207525, Accuracy: 18.85%\n",
            "Epoch: 34, Step: 450/655, Loss: 2.207684, Accuracy: 18.83%\n",
            "Epoch: 34, Step: 451/655, Loss: 2.207448, Accuracy: 18.83%\n",
            "Epoch: 34, Step: 452/655, Loss: 2.207527, Accuracy: 18.84%\n",
            "Epoch: 34, Step: 453/655, Loss: 2.207481, Accuracy: 18.83%\n",
            "Epoch: 34, Step: 454/655, Loss: 2.207316, Accuracy: 18.82%\n",
            "Epoch: 34, Step: 455/655, Loss: 2.207267, Accuracy: 18.83%\n",
            "Epoch: 34, Step: 456/655, Loss: 2.207007, Accuracy: 18.85%\n",
            "Epoch: 34, Step: 457/655, Loss: 2.206974, Accuracy: 18.87%\n",
            "Epoch: 34, Step: 458/655, Loss: 2.206808, Accuracy: 18.87%\n",
            "Epoch: 34, Step: 459/655, Loss: 2.207012, Accuracy: 18.87%\n",
            "Epoch: 34, Step: 460/655, Loss: 2.207123, Accuracy: 18.87%\n",
            "Epoch: 34, Step: 461/655, Loss: 2.207420, Accuracy: 18.86%\n",
            "Epoch: 34, Step: 462/655, Loss: 2.207402, Accuracy: 18.85%\n",
            "Epoch: 34, Step: 463/655, Loss: 2.207534, Accuracy: 18.84%\n",
            "Epoch: 34, Step: 464/655, Loss: 2.207413, Accuracy: 18.83%\n",
            "Epoch: 34, Step: 465/655, Loss: 2.207429, Accuracy: 18.82%\n",
            "Epoch: 34, Step: 466/655, Loss: 2.207518, Accuracy: 18.82%\n",
            "Epoch: 34, Step: 467/655, Loss: 2.207600, Accuracy: 18.80%\n",
            "Epoch: 34, Step: 468/655, Loss: 2.207741, Accuracy: 18.77%\n",
            "Epoch: 34, Step: 469/655, Loss: 2.207674, Accuracy: 18.77%\n",
            "Epoch: 34, Step: 470/655, Loss: 2.207554, Accuracy: 18.78%\n",
            "Epoch: 34, Step: 471/655, Loss: 2.207787, Accuracy: 18.77%\n",
            "Epoch: 34, Step: 472/655, Loss: 2.207702, Accuracy: 18.76%\n",
            "Epoch: 34, Step: 473/655, Loss: 2.207553, Accuracy: 18.76%\n",
            "Epoch: 34, Step: 474/655, Loss: 2.207961, Accuracy: 18.75%\n",
            "Epoch: 34, Step: 475/655, Loss: 2.208001, Accuracy: 18.76%\n",
            "Epoch: 34, Step: 476/655, Loss: 2.207684, Accuracy: 18.75%\n",
            "Epoch: 34, Step: 477/655, Loss: 2.207337, Accuracy: 18.75%\n",
            "Epoch: 34, Step: 478/655, Loss: 2.207671, Accuracy: 18.74%\n",
            "Epoch: 34, Step: 479/655, Loss: 2.207640, Accuracy: 18.72%\n",
            "Epoch: 34, Step: 480/655, Loss: 2.207809, Accuracy: 18.70%\n",
            "Epoch: 34, Step: 481/655, Loss: 2.207961, Accuracy: 18.71%\n",
            "Epoch: 34, Step: 482/655, Loss: 2.207686, Accuracy: 18.74%\n",
            "Epoch: 34, Step: 483/655, Loss: 2.207727, Accuracy: 18.72%\n",
            "Epoch: 34, Step: 484/655, Loss: 2.207755, Accuracy: 18.70%\n",
            "Epoch: 34, Step: 485/655, Loss: 2.207747, Accuracy: 18.70%\n",
            "Epoch: 34, Step: 486/655, Loss: 2.207558, Accuracy: 18.70%\n",
            "Epoch: 34, Step: 487/655, Loss: 2.207631, Accuracy: 18.69%\n",
            "Epoch: 34, Step: 488/655, Loss: 2.207716, Accuracy: 18.68%\n",
            "Epoch: 34, Step: 489/655, Loss: 2.207802, Accuracy: 18.69%\n",
            "Epoch: 34, Step: 490/655, Loss: 2.207594, Accuracy: 18.70%\n",
            "Epoch: 34, Step: 491/655, Loss: 2.207657, Accuracy: 18.69%\n",
            "Epoch: 34, Step: 492/655, Loss: 2.207449, Accuracy: 18.72%\n",
            "Epoch: 34, Step: 493/655, Loss: 2.207079, Accuracy: 18.74%\n",
            "Epoch: 34, Step: 494/655, Loss: 2.206951, Accuracy: 18.74%\n",
            "Epoch: 34, Step: 495/655, Loss: 2.206920, Accuracy: 18.74%\n",
            "Epoch: 34, Step: 496/655, Loss: 2.206947, Accuracy: 18.74%\n",
            "Epoch: 34, Step: 497/655, Loss: 2.207029, Accuracy: 18.74%\n",
            "Epoch: 34, Step: 498/655, Loss: 2.207108, Accuracy: 18.72%\n",
            "Epoch: 34, Step: 499/655, Loss: 2.207260, Accuracy: 18.71%\n",
            "Epoch: 34, Step: 500/655, Loss: 2.206984, Accuracy: 18.71%\n",
            "Epoch: 34, Step: 501/655, Loss: 2.207071, Accuracy: 18.71%\n",
            "Epoch: 34, Step: 502/655, Loss: 2.207121, Accuracy: 18.71%\n",
            "Epoch: 34, Step: 503/655, Loss: 2.207254, Accuracy: 18.69%\n",
            "Epoch: 34, Step: 504/655, Loss: 2.207322, Accuracy: 18.69%\n",
            "Epoch: 34, Step: 505/655, Loss: 2.207429, Accuracy: 18.70%\n",
            "Epoch: 34, Step: 506/655, Loss: 2.207488, Accuracy: 18.68%\n",
            "Epoch: 34, Step: 507/655, Loss: 2.207354, Accuracy: 18.69%\n",
            "Epoch: 34, Step: 508/655, Loss: 2.207261, Accuracy: 18.70%\n",
            "Epoch: 34, Step: 509/655, Loss: 2.207365, Accuracy: 18.69%\n",
            "Epoch: 34, Step: 510/655, Loss: 2.207547, Accuracy: 18.67%\n",
            "Epoch: 34, Step: 511/655, Loss: 2.207551, Accuracy: 18.68%\n",
            "Epoch: 34, Step: 512/655, Loss: 2.207676, Accuracy: 18.66%\n",
            "Epoch: 34, Step: 513/655, Loss: 2.207682, Accuracy: 18.65%\n",
            "Epoch: 34, Step: 514/655, Loss: 2.207702, Accuracy: 18.66%\n",
            "Epoch: 34, Step: 515/655, Loss: 2.207539, Accuracy: 18.66%\n",
            "Epoch: 34, Step: 516/655, Loss: 2.207523, Accuracy: 18.65%\n",
            "Epoch: 34, Step: 517/655, Loss: 2.207241, Accuracy: 18.66%\n",
            "Epoch: 34, Step: 518/655, Loss: 2.207414, Accuracy: 18.67%\n",
            "Epoch: 34, Step: 519/655, Loss: 2.207708, Accuracy: 18.65%\n",
            "Epoch: 34, Step: 520/655, Loss: 2.207710, Accuracy: 18.65%\n",
            "Epoch: 34, Step: 521/655, Loss: 2.207828, Accuracy: 18.64%\n",
            "Epoch: 34, Step: 522/655, Loss: 2.207919, Accuracy: 18.65%\n",
            "Epoch: 34, Step: 523/655, Loss: 2.207939, Accuracy: 18.64%\n",
            "Epoch: 34, Step: 524/655, Loss: 2.207833, Accuracy: 18.65%\n",
            "Epoch: 34, Step: 525/655, Loss: 2.207979, Accuracy: 18.63%\n",
            "Epoch: 34, Step: 526/655, Loss: 2.208063, Accuracy: 18.62%\n",
            "Epoch: 34, Step: 527/655, Loss: 2.208151, Accuracy: 18.63%\n",
            "Epoch: 34, Step: 528/655, Loss: 2.208285, Accuracy: 18.61%\n",
            "Epoch: 34, Step: 529/655, Loss: 2.208078, Accuracy: 18.62%\n",
            "Epoch: 34, Step: 530/655, Loss: 2.208043, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 531/655, Loss: 2.208006, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 532/655, Loss: 2.207901, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 533/655, Loss: 2.207908, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 534/655, Loss: 2.208058, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 535/655, Loss: 2.207994, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 536/655, Loss: 2.207971, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 537/655, Loss: 2.208064, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 538/655, Loss: 2.208106, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 539/655, Loss: 2.207923, Accuracy: 18.56%\n",
            "Epoch: 34, Step: 540/655, Loss: 2.207613, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 541/655, Loss: 2.207640, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 542/655, Loss: 2.207587, Accuracy: 18.56%\n",
            "Epoch: 34, Step: 543/655, Loss: 2.207532, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 544/655, Loss: 2.207413, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 545/655, Loss: 2.207357, Accuracy: 18.56%\n",
            "Epoch: 34, Step: 546/655, Loss: 2.207524, Accuracy: 18.54%\n",
            "Epoch: 34, Step: 547/655, Loss: 2.207716, Accuracy: 18.54%\n",
            "Epoch: 34, Step: 548/655, Loss: 2.207664, Accuracy: 18.56%\n",
            "Epoch: 34, Step: 549/655, Loss: 2.207887, Accuracy: 18.56%\n",
            "Epoch: 34, Step: 550/655, Loss: 2.208048, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 551/655, Loss: 2.208019, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 552/655, Loss: 2.208048, Accuracy: 18.56%\n",
            "Epoch: 34, Step: 553/655, Loss: 2.207949, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 554/655, Loss: 2.207571, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 555/655, Loss: 2.207311, Accuracy: 18.63%\n",
            "Epoch: 34, Step: 556/655, Loss: 2.207188, Accuracy: 18.62%\n",
            "Epoch: 34, Step: 557/655, Loss: 2.207286, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 558/655, Loss: 2.207526, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 559/655, Loss: 2.207411, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 560/655, Loss: 2.207513, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 561/655, Loss: 2.207545, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 562/655, Loss: 2.207718, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 563/655, Loss: 2.207908, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 564/655, Loss: 2.208037, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 565/655, Loss: 2.207886, Accuracy: 18.56%\n",
            "Epoch: 34, Step: 566/655, Loss: 2.207925, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 567/655, Loss: 2.208008, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 568/655, Loss: 2.207928, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 569/655, Loss: 2.207723, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 570/655, Loss: 2.207743, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 571/655, Loss: 2.207734, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 572/655, Loss: 2.207686, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 573/655, Loss: 2.207469, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 574/655, Loss: 2.207334, Accuracy: 18.61%\n",
            "Epoch: 34, Step: 575/655, Loss: 2.207407, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 576/655, Loss: 2.207299, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 577/655, Loss: 2.207229, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 578/655, Loss: 2.207325, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 579/655, Loss: 2.207384, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 580/655, Loss: 2.207501, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 581/655, Loss: 2.207509, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 582/655, Loss: 2.207521, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 583/655, Loss: 2.207508, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 584/655, Loss: 2.207558, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 585/655, Loss: 2.207478, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 586/655, Loss: 2.207516, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 587/655, Loss: 2.207505, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 588/655, Loss: 2.207330, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 589/655, Loss: 2.207178, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 590/655, Loss: 2.207318, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 591/655, Loss: 2.207176, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 592/655, Loss: 2.207221, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 593/655, Loss: 2.207027, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 594/655, Loss: 2.206881, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 595/655, Loss: 2.206816, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 596/655, Loss: 2.206731, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 597/655, Loss: 2.206701, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 598/655, Loss: 2.206780, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 599/655, Loss: 2.206711, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 600/655, Loss: 2.206558, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 601/655, Loss: 2.206510, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 602/655, Loss: 2.206453, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 603/655, Loss: 2.206430, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 604/655, Loss: 2.206553, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 605/655, Loss: 2.206738, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 606/655, Loss: 2.206766, Accuracy: 18.60%\n",
            "Epoch: 34, Step: 607/655, Loss: 2.206752, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 608/655, Loss: 2.207108, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 609/655, Loss: 2.206832, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 610/655, Loss: 2.206802, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 611/655, Loss: 2.206659, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 612/655, Loss: 2.206811, Accuracy: 18.57%\n",
            "Epoch: 34, Step: 613/655, Loss: 2.206512, Accuracy: 18.59%\n",
            "Epoch: 34, Step: 614/655, Loss: 2.206432, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 615/655, Loss: 2.206482, Accuracy: 18.58%\n",
            "Epoch: 34, Step: 616/655, Loss: 2.206653, Accuracy: 18.56%\n",
            "Epoch: 34, Step: 617/655, Loss: 2.206671, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 618/655, Loss: 2.206643, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 619/655, Loss: 2.206550, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 620/655, Loss: 2.206588, Accuracy: 18.56%\n",
            "Epoch: 34, Step: 621/655, Loss: 2.206628, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 622/655, Loss: 2.206676, Accuracy: 18.53%\n",
            "Epoch: 34, Step: 623/655, Loss: 2.206718, Accuracy: 18.53%\n",
            "Epoch: 34, Step: 624/655, Loss: 2.206350, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 625/655, Loss: 2.206380, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 626/655, Loss: 2.206252, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 627/655, Loss: 2.206398, Accuracy: 18.55%\n",
            "Epoch: 34, Step: 628/655, Loss: 2.206637, Accuracy: 18.53%\n",
            "Epoch: 34, Step: 629/655, Loss: 2.206780, Accuracy: 18.52%\n",
            "Epoch: 34, Step: 630/655, Loss: 2.206891, Accuracy: 18.51%\n",
            "Epoch: 34, Step: 631/655, Loss: 2.206917, Accuracy: 18.51%\n",
            "Epoch: 34, Step: 632/655, Loss: 2.207084, Accuracy: 18.50%\n",
            "Epoch: 34, Step: 633/655, Loss: 2.207061, Accuracy: 18.51%\n",
            "Epoch: 34, Step: 634/655, Loss: 2.207004, Accuracy: 18.51%\n",
            "Epoch: 34, Step: 635/655, Loss: 2.207103, Accuracy: 18.50%\n",
            "Epoch: 34, Step: 636/655, Loss: 2.207236, Accuracy: 18.49%\n",
            "Epoch: 34, Step: 637/655, Loss: 2.207345, Accuracy: 18.49%\n",
            "Epoch: 34, Step: 638/655, Loss: 2.207277, Accuracy: 18.48%\n",
            "Epoch: 34, Step: 639/655, Loss: 2.207366, Accuracy: 18.47%\n",
            "Epoch: 34, Step: 640/655, Loss: 2.207462, Accuracy: 18.47%\n",
            "Epoch: 34, Step: 641/655, Loss: 2.207490, Accuracy: 18.47%\n",
            "Epoch: 34, Step: 642/655, Loss: 2.207614, Accuracy: 18.46%\n",
            "Epoch: 34, Step: 643/655, Loss: 2.207511, Accuracy: 18.47%\n",
            "Epoch: 34, Step: 644/655, Loss: 2.207649, Accuracy: 18.45%\n",
            "Epoch: 34, Step: 645/655, Loss: 2.207896, Accuracy: 18.44%\n",
            "Epoch: 34, Step: 646/655, Loss: 2.207569, Accuracy: 18.46%\n",
            "Epoch: 34, Step: 647/655, Loss: 2.207493, Accuracy: 18.47%\n",
            "Epoch: 34, Step: 648/655, Loss: 2.207384, Accuracy: 18.50%\n",
            "Epoch: 34, Step: 649/655, Loss: 2.207638, Accuracy: 18.49%\n",
            "Epoch: 34, Step: 650/655, Loss: 2.207537, Accuracy: 18.49%\n",
            "Epoch: 34, Step: 651/655, Loss: 2.207484, Accuracy: 18.49%\n",
            "Epoch: 34, Step: 652/655, Loss: 2.207520, Accuracy: 18.49%\n",
            "Epoch: 34, Step: 653/655, Loss: 2.207456, Accuracy: 18.49%\n",
            "Epoch: 34, Step: 654/655, Loss: 2.207515, Accuracy: 18.50%\n",
            "Epoch: 34, Step: 655/655, Loss: 2.207600, Accuracy: 18.50%\n",
            "Epoch: 35, Step: 1/655, Loss: 2.207459, Accuracy: 15.62%\n",
            "Epoch: 35, Step: 2/655, Loss: 2.177390, Accuracy: 20.31%\n",
            "Epoch: 35, Step: 3/655, Loss: 2.203133, Accuracy: 18.75%\n",
            "Epoch: 35, Step: 4/655, Loss: 2.168187, Accuracy: 21.09%\n",
            "Epoch: 35, Step: 5/655, Loss: 2.205898, Accuracy: 18.12%\n",
            "Epoch: 35, Step: 6/655, Loss: 2.197764, Accuracy: 19.79%\n",
            "Epoch: 35, Step: 7/655, Loss: 2.183413, Accuracy: 21.43%\n",
            "Epoch: 35, Step: 8/655, Loss: 2.174346, Accuracy: 21.09%\n",
            "Epoch: 35, Step: 9/655, Loss: 2.186073, Accuracy: 20.83%\n",
            "Epoch: 35, Step: 10/655, Loss: 2.184256, Accuracy: 21.56%\n",
            "Epoch: 35, Step: 11/655, Loss: 2.187327, Accuracy: 20.45%\n",
            "Epoch: 35, Step: 12/655, Loss: 2.187360, Accuracy: 21.35%\n",
            "Epoch: 35, Step: 13/655, Loss: 2.182277, Accuracy: 21.63%\n",
            "Epoch: 35, Step: 14/655, Loss: 2.183408, Accuracy: 21.21%\n",
            "Epoch: 35, Step: 15/655, Loss: 2.179965, Accuracy: 21.25%\n",
            "Epoch: 35, Step: 16/655, Loss: 2.184064, Accuracy: 20.90%\n",
            "Epoch: 35, Step: 17/655, Loss: 2.189082, Accuracy: 20.77%\n",
            "Epoch: 35, Step: 18/655, Loss: 2.193587, Accuracy: 20.66%\n",
            "Epoch: 35, Step: 19/655, Loss: 2.193084, Accuracy: 21.05%\n",
            "Epoch: 35, Step: 20/655, Loss: 2.189793, Accuracy: 21.72%\n",
            "Epoch: 35, Step: 21/655, Loss: 2.191174, Accuracy: 22.02%\n",
            "Epoch: 35, Step: 22/655, Loss: 2.189544, Accuracy: 21.73%\n",
            "Epoch: 35, Step: 23/655, Loss: 2.183290, Accuracy: 21.60%\n",
            "Epoch: 35, Step: 24/655, Loss: 2.175165, Accuracy: 21.88%\n",
            "Epoch: 35, Step: 25/655, Loss: 2.177366, Accuracy: 21.88%\n",
            "Epoch: 35, Step: 26/655, Loss: 2.179088, Accuracy: 21.75%\n",
            "Epoch: 35, Step: 27/655, Loss: 2.177672, Accuracy: 22.11%\n",
            "Epoch: 35, Step: 28/655, Loss: 2.174625, Accuracy: 22.10%\n",
            "Epoch: 35, Step: 29/655, Loss: 2.176763, Accuracy: 22.09%\n",
            "Epoch: 35, Step: 30/655, Loss: 2.176837, Accuracy: 21.88%\n",
            "Epoch: 35, Step: 31/655, Loss: 2.175223, Accuracy: 21.67%\n",
            "Epoch: 35, Step: 32/655, Loss: 2.176770, Accuracy: 21.68%\n",
            "Epoch: 35, Step: 33/655, Loss: 2.178146, Accuracy: 21.59%\n",
            "Epoch: 35, Step: 34/655, Loss: 2.180541, Accuracy: 21.60%\n",
            "Epoch: 35, Step: 35/655, Loss: 2.178754, Accuracy: 21.79%\n",
            "Epoch: 35, Step: 36/655, Loss: 2.181316, Accuracy: 21.79%\n",
            "Epoch: 35, Step: 37/655, Loss: 2.187528, Accuracy: 21.54%\n",
            "Epoch: 35, Step: 38/655, Loss: 2.190428, Accuracy: 21.22%\n",
            "Epoch: 35, Step: 39/655, Loss: 2.191253, Accuracy: 21.31%\n",
            "Epoch: 35, Step: 40/655, Loss: 2.192022, Accuracy: 21.33%\n",
            "Epoch: 35, Step: 41/655, Loss: 2.194463, Accuracy: 21.19%\n",
            "Epoch: 35, Step: 42/655, Loss: 2.195994, Accuracy: 21.06%\n",
            "Epoch: 35, Step: 43/655, Loss: 2.195942, Accuracy: 21.00%\n",
            "Epoch: 35, Step: 44/655, Loss: 2.200939, Accuracy: 20.60%\n",
            "Epoch: 35, Step: 45/655, Loss: 2.201365, Accuracy: 20.49%\n",
            "Epoch: 35, Step: 46/655, Loss: 2.201089, Accuracy: 20.52%\n",
            "Epoch: 35, Step: 47/655, Loss: 2.202015, Accuracy: 20.48%\n",
            "Epoch: 35, Step: 48/655, Loss: 2.204169, Accuracy: 20.44%\n",
            "Epoch: 35, Step: 49/655, Loss: 2.205014, Accuracy: 20.34%\n",
            "Epoch: 35, Step: 50/655, Loss: 2.203543, Accuracy: 20.38%\n",
            "Epoch: 35, Step: 51/655, Loss: 2.205472, Accuracy: 20.34%\n",
            "Epoch: 35, Step: 52/655, Loss: 2.205450, Accuracy: 20.25%\n",
            "Epoch: 35, Step: 53/655, Loss: 2.204814, Accuracy: 20.28%\n",
            "Epoch: 35, Step: 54/655, Loss: 2.203470, Accuracy: 20.20%\n",
            "Epoch: 35, Step: 55/655, Loss: 2.205145, Accuracy: 20.00%\n",
            "Epoch: 35, Step: 56/655, Loss: 2.206722, Accuracy: 19.87%\n",
            "Epoch: 35, Step: 57/655, Loss: 2.210442, Accuracy: 19.63%\n",
            "Epoch: 35, Step: 58/655, Loss: 2.211402, Accuracy: 19.67%\n",
            "Epoch: 35, Step: 59/655, Loss: 2.209322, Accuracy: 19.92%\n",
            "Epoch: 35, Step: 60/655, Loss: 2.208140, Accuracy: 20.10%\n",
            "Epoch: 35, Step: 61/655, Loss: 2.209183, Accuracy: 19.98%\n",
            "Epoch: 35, Step: 62/655, Loss: 2.208926, Accuracy: 20.01%\n",
            "Epoch: 35, Step: 63/655, Loss: 2.210922, Accuracy: 19.84%\n",
            "Epoch: 35, Step: 64/655, Loss: 2.210681, Accuracy: 19.82%\n",
            "Epoch: 35, Step: 65/655, Loss: 2.209523, Accuracy: 19.95%\n",
            "Epoch: 35, Step: 66/655, Loss: 2.209970, Accuracy: 19.98%\n",
            "Epoch: 35, Step: 67/655, Loss: 2.208043, Accuracy: 20.06%\n",
            "Epoch: 35, Step: 68/655, Loss: 2.207200, Accuracy: 20.22%\n",
            "Epoch: 35, Step: 69/655, Loss: 2.207771, Accuracy: 20.11%\n",
            "Epoch: 35, Step: 70/655, Loss: 2.206851, Accuracy: 20.04%\n",
            "Epoch: 35, Step: 71/655, Loss: 2.207443, Accuracy: 19.94%\n",
            "Epoch: 35, Step: 72/655, Loss: 2.207010, Accuracy: 19.84%\n",
            "Epoch: 35, Step: 73/655, Loss: 2.207784, Accuracy: 19.73%\n",
            "Epoch: 35, Step: 74/655, Loss: 2.206140, Accuracy: 19.85%\n",
            "Epoch: 35, Step: 75/655, Loss: 2.207869, Accuracy: 19.79%\n",
            "Epoch: 35, Step: 76/655, Loss: 2.208249, Accuracy: 19.57%\n",
            "Epoch: 35, Step: 77/655, Loss: 2.208956, Accuracy: 19.56%\n",
            "Epoch: 35, Step: 78/655, Loss: 2.209848, Accuracy: 19.43%\n",
            "Epoch: 35, Step: 79/655, Loss: 2.209045, Accuracy: 19.42%\n",
            "Epoch: 35, Step: 80/655, Loss: 2.209091, Accuracy: 19.38%\n",
            "Epoch: 35, Step: 81/655, Loss: 2.209373, Accuracy: 19.37%\n",
            "Epoch: 35, Step: 82/655, Loss: 2.209754, Accuracy: 19.36%\n",
            "Epoch: 35, Step: 83/655, Loss: 2.209440, Accuracy: 19.50%\n",
            "Epoch: 35, Step: 84/655, Loss: 2.210012, Accuracy: 19.42%\n",
            "Epoch: 35, Step: 85/655, Loss: 2.210084, Accuracy: 19.34%\n",
            "Epoch: 35, Step: 86/655, Loss: 2.210061, Accuracy: 19.33%\n",
            "Epoch: 35, Step: 87/655, Loss: 2.209334, Accuracy: 19.36%\n",
            "Epoch: 35, Step: 88/655, Loss: 2.208245, Accuracy: 19.35%\n",
            "Epoch: 35, Step: 89/655, Loss: 2.208120, Accuracy: 19.38%\n",
            "Epoch: 35, Step: 90/655, Loss: 2.208045, Accuracy: 19.34%\n",
            "Epoch: 35, Step: 91/655, Loss: 2.209046, Accuracy: 19.37%\n",
            "Epoch: 35, Step: 92/655, Loss: 2.209608, Accuracy: 19.46%\n",
            "Epoch: 35, Step: 93/655, Loss: 2.209690, Accuracy: 19.56%\n",
            "Epoch: 35, Step: 94/655, Loss: 2.209212, Accuracy: 19.58%\n",
            "Epoch: 35, Step: 95/655, Loss: 2.208873, Accuracy: 19.57%\n",
            "Epoch: 35, Step: 96/655, Loss: 2.209156, Accuracy: 19.63%\n",
            "Epoch: 35, Step: 97/655, Loss: 2.207377, Accuracy: 19.78%\n",
            "Epoch: 35, Step: 98/655, Loss: 2.207213, Accuracy: 19.77%\n",
            "Epoch: 35, Step: 99/655, Loss: 2.206780, Accuracy: 19.92%\n",
            "Epoch: 35, Step: 100/655, Loss: 2.207866, Accuracy: 19.75%\n",
            "Epoch: 35, Step: 101/655, Loss: 2.208311, Accuracy: 19.77%\n",
            "Epoch: 35, Step: 102/655, Loss: 2.208176, Accuracy: 19.76%\n",
            "Epoch: 35, Step: 103/655, Loss: 2.207269, Accuracy: 19.75%\n",
            "Epoch: 35, Step: 104/655, Loss: 2.207340, Accuracy: 19.77%\n",
            "Epoch: 35, Step: 105/655, Loss: 2.207407, Accuracy: 19.82%\n",
            "Epoch: 35, Step: 106/655, Loss: 2.206260, Accuracy: 19.81%\n",
            "Epoch: 35, Step: 107/655, Loss: 2.204687, Accuracy: 19.86%\n",
            "Epoch: 35, Step: 108/655, Loss: 2.204625, Accuracy: 19.91%\n",
            "Epoch: 35, Step: 109/655, Loss: 2.205030, Accuracy: 19.90%\n",
            "Epoch: 35, Step: 110/655, Loss: 2.205825, Accuracy: 19.80%\n",
            "Epoch: 35, Step: 111/655, Loss: 2.205875, Accuracy: 19.79%\n",
            "Epoch: 35, Step: 112/655, Loss: 2.206767, Accuracy: 19.78%\n",
            "Epoch: 35, Step: 113/655, Loss: 2.206101, Accuracy: 19.86%\n",
            "Epoch: 35, Step: 114/655, Loss: 2.206545, Accuracy: 19.85%\n",
            "Epoch: 35, Step: 115/655, Loss: 2.206705, Accuracy: 19.73%\n",
            "Epoch: 35, Step: 116/655, Loss: 2.205877, Accuracy: 19.67%\n",
            "Epoch: 35, Step: 117/655, Loss: 2.205176, Accuracy: 19.68%\n",
            "Epoch: 35, Step: 118/655, Loss: 2.204675, Accuracy: 19.65%\n",
            "Epoch: 35, Step: 119/655, Loss: 2.205557, Accuracy: 19.62%\n",
            "Epoch: 35, Step: 120/655, Loss: 2.205969, Accuracy: 19.58%\n",
            "Epoch: 35, Step: 121/655, Loss: 2.206406, Accuracy: 19.52%\n",
            "Epoch: 35, Step: 122/655, Loss: 2.205870, Accuracy: 19.54%\n",
            "Epoch: 35, Step: 123/655, Loss: 2.206093, Accuracy: 19.59%\n",
            "Epoch: 35, Step: 124/655, Loss: 2.205023, Accuracy: 19.68%\n",
            "Epoch: 35, Step: 125/655, Loss: 2.204712, Accuracy: 19.80%\n",
            "Epoch: 35, Step: 126/655, Loss: 2.204079, Accuracy: 19.84%\n",
            "Epoch: 35, Step: 127/655, Loss: 2.203531, Accuracy: 19.86%\n",
            "Epoch: 35, Step: 128/655, Loss: 2.203828, Accuracy: 19.82%\n",
            "Epoch: 35, Step: 129/655, Loss: 2.203773, Accuracy: 19.91%\n",
            "Epoch: 35, Step: 130/655, Loss: 2.204855, Accuracy: 19.86%\n",
            "Epoch: 35, Step: 131/655, Loss: 2.204671, Accuracy: 19.90%\n",
            "Epoch: 35, Step: 132/655, Loss: 2.204537, Accuracy: 19.89%\n",
            "Epoch: 35, Step: 133/655, Loss: 2.203994, Accuracy: 19.85%\n",
            "Epoch: 35, Step: 134/655, Loss: 2.204331, Accuracy: 19.80%\n",
            "Epoch: 35, Step: 135/655, Loss: 2.204720, Accuracy: 19.77%\n",
            "Epoch: 35, Step: 136/655, Loss: 2.204815, Accuracy: 19.72%\n",
            "Epoch: 35, Step: 137/655, Loss: 2.204561, Accuracy: 19.66%\n",
            "Epoch: 35, Step: 138/655, Loss: 2.205440, Accuracy: 19.61%\n",
            "Epoch: 35, Step: 139/655, Loss: 2.205673, Accuracy: 19.58%\n",
            "Epoch: 35, Step: 140/655, Loss: 2.205079, Accuracy: 19.60%\n",
            "Epoch: 35, Step: 141/655, Loss: 2.205057, Accuracy: 19.57%\n",
            "Epoch: 35, Step: 142/655, Loss: 2.205565, Accuracy: 19.59%\n",
            "Epoch: 35, Step: 143/655, Loss: 2.205882, Accuracy: 19.58%\n",
            "Epoch: 35, Step: 144/655, Loss: 2.206206, Accuracy: 19.51%\n",
            "Epoch: 35, Step: 145/655, Loss: 2.206277, Accuracy: 19.55%\n",
            "Epoch: 35, Step: 146/655, Loss: 2.206957, Accuracy: 19.41%\n",
            "Epoch: 35, Step: 147/655, Loss: 2.207136, Accuracy: 19.39%\n",
            "Epoch: 35, Step: 148/655, Loss: 2.206876, Accuracy: 19.45%\n",
            "Epoch: 35, Step: 149/655, Loss: 2.206884, Accuracy: 19.38%\n",
            "Epoch: 35, Step: 150/655, Loss: 2.205345, Accuracy: 19.46%\n",
            "Epoch: 35, Step: 151/655, Loss: 2.205028, Accuracy: 19.41%\n",
            "Epoch: 35, Step: 152/655, Loss: 2.205536, Accuracy: 19.47%\n",
            "Epoch: 35, Step: 153/655, Loss: 2.205328, Accuracy: 19.44%\n",
            "Epoch: 35, Step: 154/655, Loss: 2.205886, Accuracy: 19.40%\n",
            "Epoch: 35, Step: 155/655, Loss: 2.205261, Accuracy: 19.38%\n",
            "Epoch: 35, Step: 156/655, Loss: 2.204920, Accuracy: 19.39%\n",
            "Epoch: 35, Step: 157/655, Loss: 2.205100, Accuracy: 19.35%\n",
            "Epoch: 35, Step: 158/655, Loss: 2.204752, Accuracy: 19.34%\n",
            "Epoch: 35, Step: 159/655, Loss: 2.205130, Accuracy: 19.36%\n",
            "Epoch: 35, Step: 160/655, Loss: 2.205002, Accuracy: 19.38%\n",
            "Epoch: 35, Step: 161/655, Loss: 2.205146, Accuracy: 19.39%\n",
            "Epoch: 35, Step: 162/655, Loss: 2.204731, Accuracy: 19.44%\n",
            "Epoch: 35, Step: 163/655, Loss: 2.204563, Accuracy: 19.44%\n",
            "Epoch: 35, Step: 164/655, Loss: 2.204685, Accuracy: 19.46%\n",
            "Epoch: 35, Step: 165/655, Loss: 2.204699, Accuracy: 19.47%\n",
            "Epoch: 35, Step: 166/655, Loss: 2.204092, Accuracy: 19.47%\n",
            "Epoch: 35, Step: 167/655, Loss: 2.202763, Accuracy: 19.52%\n",
            "Epoch: 35, Step: 168/655, Loss: 2.202636, Accuracy: 19.53%\n",
            "Epoch: 35, Step: 169/655, Loss: 2.202009, Accuracy: 19.53%\n",
            "Epoch: 35, Step: 170/655, Loss: 2.203143, Accuracy: 19.47%\n",
            "Epoch: 35, Step: 171/655, Loss: 2.202974, Accuracy: 19.50%\n",
            "Epoch: 35, Step: 172/655, Loss: 2.202273, Accuracy: 19.59%\n",
            "Epoch: 35, Step: 173/655, Loss: 2.202402, Accuracy: 19.60%\n",
            "Epoch: 35, Step: 174/655, Loss: 2.201702, Accuracy: 19.63%\n",
            "Epoch: 35, Step: 175/655, Loss: 2.201207, Accuracy: 19.68%\n",
            "Epoch: 35, Step: 176/655, Loss: 2.201512, Accuracy: 19.67%\n",
            "Epoch: 35, Step: 177/655, Loss: 2.201893, Accuracy: 19.63%\n",
            "Epoch: 35, Step: 178/655, Loss: 2.202249, Accuracy: 19.65%\n",
            "Epoch: 35, Step: 179/655, Loss: 2.202857, Accuracy: 19.61%\n",
            "Epoch: 35, Step: 180/655, Loss: 2.203085, Accuracy: 19.57%\n",
            "Epoch: 35, Step: 181/655, Loss: 2.203651, Accuracy: 19.60%\n",
            "Epoch: 35, Step: 182/655, Loss: 2.203170, Accuracy: 19.56%\n",
            "Epoch: 35, Step: 183/655, Loss: 2.203441, Accuracy: 19.54%\n",
            "Epoch: 35, Step: 184/655, Loss: 2.202966, Accuracy: 19.50%\n",
            "Epoch: 35, Step: 185/655, Loss: 2.203264, Accuracy: 19.49%\n",
            "Epoch: 35, Step: 186/655, Loss: 2.202751, Accuracy: 19.56%\n",
            "Epoch: 35, Step: 187/655, Loss: 2.202140, Accuracy: 19.59%\n",
            "Epoch: 35, Step: 188/655, Loss: 2.201818, Accuracy: 19.61%\n",
            "Epoch: 35, Step: 189/655, Loss: 2.201867, Accuracy: 19.63%\n",
            "Epoch: 35, Step: 190/655, Loss: 2.202641, Accuracy: 19.62%\n",
            "Epoch: 35, Step: 191/655, Loss: 2.203425, Accuracy: 19.57%\n",
            "Epoch: 35, Step: 192/655, Loss: 2.203668, Accuracy: 19.58%\n",
            "Epoch: 35, Step: 193/655, Loss: 2.203532, Accuracy: 19.56%\n",
            "Epoch: 35, Step: 194/655, Loss: 2.202748, Accuracy: 19.65%\n",
            "Epoch: 35, Step: 195/655, Loss: 2.202775, Accuracy: 19.66%\n",
            "Epoch: 35, Step: 196/655, Loss: 2.202654, Accuracy: 19.67%\n",
            "Epoch: 35, Step: 197/655, Loss: 2.202985, Accuracy: 19.67%\n",
            "Epoch: 35, Step: 198/655, Loss: 2.202667, Accuracy: 19.68%\n",
            "Epoch: 35, Step: 199/655, Loss: 2.202722, Accuracy: 19.69%\n",
            "Epoch: 35, Step: 200/655, Loss: 2.202926, Accuracy: 19.67%\n",
            "Epoch: 35, Step: 201/655, Loss: 2.203424, Accuracy: 19.65%\n",
            "Epoch: 35, Step: 202/655, Loss: 2.202718, Accuracy: 19.72%\n",
            "Epoch: 35, Step: 203/655, Loss: 2.202753, Accuracy: 19.72%\n",
            "Epoch: 35, Step: 204/655, Loss: 2.202976, Accuracy: 19.67%\n",
            "Epoch: 35, Step: 205/655, Loss: 2.203215, Accuracy: 19.62%\n",
            "Epoch: 35, Step: 206/655, Loss: 2.202952, Accuracy: 19.63%\n",
            "Epoch: 35, Step: 207/655, Loss: 2.203485, Accuracy: 19.64%\n",
            "Epoch: 35, Step: 208/655, Loss: 2.203618, Accuracy: 19.59%\n",
            "Epoch: 35, Step: 209/655, Loss: 2.203595, Accuracy: 19.57%\n",
            "Epoch: 35, Step: 210/655, Loss: 2.203947, Accuracy: 19.49%\n",
            "Epoch: 35, Step: 211/655, Loss: 2.203769, Accuracy: 19.53%\n",
            "Epoch: 35, Step: 212/655, Loss: 2.204014, Accuracy: 19.53%\n",
            "Epoch: 35, Step: 213/655, Loss: 2.204331, Accuracy: 19.48%\n",
            "Epoch: 35, Step: 214/655, Loss: 2.204569, Accuracy: 19.48%\n",
            "Epoch: 35, Step: 215/655, Loss: 2.204661, Accuracy: 19.49%\n",
            "Epoch: 35, Step: 216/655, Loss: 2.204862, Accuracy: 19.44%\n",
            "Epoch: 35, Step: 217/655, Loss: 2.205332, Accuracy: 19.40%\n",
            "Epoch: 35, Step: 218/655, Loss: 2.205523, Accuracy: 19.37%\n",
            "Epoch: 35, Step: 219/655, Loss: 2.205736, Accuracy: 19.36%\n",
            "Epoch: 35, Step: 220/655, Loss: 2.205177, Accuracy: 19.36%\n",
            "Epoch: 35, Step: 221/655, Loss: 2.205478, Accuracy: 19.36%\n",
            "Epoch: 35, Step: 222/655, Loss: 2.205717, Accuracy: 19.33%\n",
            "Epoch: 35, Step: 223/655, Loss: 2.205109, Accuracy: 19.39%\n",
            "Epoch: 35, Step: 224/655, Loss: 2.205267, Accuracy: 19.39%\n",
            "Epoch: 35, Step: 225/655, Loss: 2.205191, Accuracy: 19.39%\n",
            "Epoch: 35, Step: 226/655, Loss: 2.205098, Accuracy: 19.40%\n",
            "Epoch: 35, Step: 227/655, Loss: 2.205013, Accuracy: 19.38%\n",
            "Epoch: 35, Step: 228/655, Loss: 2.205483, Accuracy: 19.38%\n",
            "Epoch: 35, Step: 229/655, Loss: 2.205415, Accuracy: 19.35%\n",
            "Epoch: 35, Step: 230/655, Loss: 2.205687, Accuracy: 19.35%\n",
            "Epoch: 35, Step: 231/655, Loss: 2.205766, Accuracy: 19.30%\n",
            "Epoch: 35, Step: 232/655, Loss: 2.205711, Accuracy: 19.32%\n",
            "Epoch: 35, Step: 233/655, Loss: 2.205956, Accuracy: 19.33%\n",
            "Epoch: 35, Step: 234/655, Loss: 2.205626, Accuracy: 19.30%\n",
            "Epoch: 35, Step: 235/655, Loss: 2.205132, Accuracy: 19.31%\n",
            "Epoch: 35, Step: 236/655, Loss: 2.205181, Accuracy: 19.31%\n",
            "Epoch: 35, Step: 237/655, Loss: 2.205698, Accuracy: 19.28%\n",
            "Epoch: 35, Step: 238/655, Loss: 2.205982, Accuracy: 19.25%\n",
            "Epoch: 35, Step: 239/655, Loss: 2.206188, Accuracy: 19.22%\n",
            "Epoch: 35, Step: 240/655, Loss: 2.206339, Accuracy: 19.24%\n",
            "Epoch: 35, Step: 241/655, Loss: 2.206650, Accuracy: 19.19%\n",
            "Epoch: 35, Step: 242/655, Loss: 2.206748, Accuracy: 19.21%\n",
            "Epoch: 35, Step: 243/655, Loss: 2.206147, Accuracy: 19.19%\n",
            "Epoch: 35, Step: 244/655, Loss: 2.206714, Accuracy: 19.13%\n",
            "Epoch: 35, Step: 245/655, Loss: 2.206497, Accuracy: 19.15%\n",
            "Epoch: 35, Step: 246/655, Loss: 2.206952, Accuracy: 19.11%\n",
            "Epoch: 35, Step: 247/655, Loss: 2.207035, Accuracy: 19.10%\n",
            "Epoch: 35, Step: 248/655, Loss: 2.206789, Accuracy: 19.10%\n",
            "Epoch: 35, Step: 249/655, Loss: 2.206804, Accuracy: 19.09%\n",
            "Epoch: 35, Step: 250/655, Loss: 2.206990, Accuracy: 19.09%\n",
            "Epoch: 35, Step: 251/655, Loss: 2.206838, Accuracy: 19.07%\n",
            "Epoch: 35, Step: 252/655, Loss: 2.206542, Accuracy: 19.08%\n",
            "Epoch: 35, Step: 253/655, Loss: 2.206498, Accuracy: 19.12%\n",
            "Epoch: 35, Step: 254/655, Loss: 2.206316, Accuracy: 19.12%\n",
            "Epoch: 35, Step: 255/655, Loss: 2.206197, Accuracy: 19.14%\n",
            "Epoch: 35, Step: 256/655, Loss: 2.205706, Accuracy: 19.14%\n",
            "Epoch: 35, Step: 257/655, Loss: 2.205333, Accuracy: 19.14%\n",
            "Epoch: 35, Step: 258/655, Loss: 2.205401, Accuracy: 19.15%\n",
            "Epoch: 35, Step: 259/655, Loss: 2.206125, Accuracy: 19.11%\n",
            "Epoch: 35, Step: 260/655, Loss: 2.206359, Accuracy: 19.07%\n",
            "Epoch: 35, Step: 261/655, Loss: 2.206682, Accuracy: 19.07%\n",
            "Epoch: 35, Step: 262/655, Loss: 2.206831, Accuracy: 19.05%\n",
            "Epoch: 35, Step: 263/655, Loss: 2.207011, Accuracy: 19.00%\n",
            "Epoch: 35, Step: 264/655, Loss: 2.206612, Accuracy: 19.01%\n",
            "Epoch: 35, Step: 265/655, Loss: 2.206660, Accuracy: 19.01%\n",
            "Epoch: 35, Step: 266/655, Loss: 2.206818, Accuracy: 19.01%\n",
            "Epoch: 35, Step: 267/655, Loss: 2.206737, Accuracy: 19.00%\n",
            "Epoch: 35, Step: 268/655, Loss: 2.206934, Accuracy: 18.98%\n",
            "Epoch: 35, Step: 269/655, Loss: 2.206646, Accuracy: 18.97%\n",
            "Epoch: 35, Step: 270/655, Loss: 2.205938, Accuracy: 19.04%\n",
            "Epoch: 35, Step: 271/655, Loss: 2.205970, Accuracy: 19.04%\n",
            "Epoch: 35, Step: 272/655, Loss: 2.205974, Accuracy: 19.05%\n",
            "Epoch: 35, Step: 273/655, Loss: 2.205951, Accuracy: 19.09%\n",
            "Epoch: 35, Step: 274/655, Loss: 2.206065, Accuracy: 19.05%\n",
            "Epoch: 35, Step: 275/655, Loss: 2.206702, Accuracy: 19.01%\n",
            "Epoch: 35, Step: 276/655, Loss: 2.206962, Accuracy: 18.99%\n",
            "Epoch: 35, Step: 277/655, Loss: 2.207004, Accuracy: 19.02%\n",
            "Epoch: 35, Step: 278/655, Loss: 2.207324, Accuracy: 18.99%\n",
            "Epoch: 35, Step: 279/655, Loss: 2.207358, Accuracy: 18.97%\n",
            "Epoch: 35, Step: 280/655, Loss: 2.207222, Accuracy: 18.98%\n",
            "Epoch: 35, Step: 281/655, Loss: 2.206711, Accuracy: 19.02%\n",
            "Epoch: 35, Step: 282/655, Loss: 2.206899, Accuracy: 19.00%\n",
            "Epoch: 35, Step: 283/655, Loss: 2.206917, Accuracy: 18.97%\n",
            "Epoch: 35, Step: 284/655, Loss: 2.206462, Accuracy: 18.97%\n",
            "Epoch: 35, Step: 285/655, Loss: 2.206196, Accuracy: 18.98%\n",
            "Epoch: 35, Step: 286/655, Loss: 2.205860, Accuracy: 19.02%\n",
            "Epoch: 35, Step: 287/655, Loss: 2.205725, Accuracy: 19.00%\n",
            "Epoch: 35, Step: 288/655, Loss: 2.205775, Accuracy: 19.00%\n",
            "Epoch: 35, Step: 289/655, Loss: 2.205530, Accuracy: 19.00%\n",
            "Epoch: 35, Step: 290/655, Loss: 2.205688, Accuracy: 18.97%\n",
            "Epoch: 35, Step: 291/655, Loss: 2.205679, Accuracy: 19.00%\n",
            "Epoch: 35, Step: 292/655, Loss: 2.205407, Accuracy: 19.02%\n",
            "Epoch: 35, Step: 293/655, Loss: 2.205629, Accuracy: 19.03%\n",
            "Epoch: 35, Step: 294/655, Loss: 2.205510, Accuracy: 19.02%\n",
            "Epoch: 35, Step: 295/655, Loss: 2.205622, Accuracy: 19.01%\n",
            "Epoch: 35, Step: 296/655, Loss: 2.205739, Accuracy: 19.01%\n",
            "Epoch: 35, Step: 297/655, Loss: 2.205837, Accuracy: 19.01%\n",
            "Epoch: 35, Step: 298/655, Loss: 2.205771, Accuracy: 19.02%\n",
            "Epoch: 35, Step: 299/655, Loss: 2.205828, Accuracy: 19.00%\n",
            "Epoch: 35, Step: 300/655, Loss: 2.205951, Accuracy: 19.03%\n",
            "Epoch: 35, Step: 301/655, Loss: 2.205813, Accuracy: 19.02%\n",
            "Epoch: 35, Step: 302/655, Loss: 2.206170, Accuracy: 18.99%\n",
            "Epoch: 35, Step: 303/655, Loss: 2.206279, Accuracy: 19.01%\n",
            "Epoch: 35, Step: 304/655, Loss: 2.206175, Accuracy: 19.00%\n",
            "Epoch: 35, Step: 305/655, Loss: 2.206069, Accuracy: 19.00%\n",
            "Epoch: 35, Step: 306/655, Loss: 2.206457, Accuracy: 18.96%\n",
            "Epoch: 35, Step: 307/655, Loss: 2.206340, Accuracy: 18.97%\n",
            "Epoch: 35, Step: 308/655, Loss: 2.206918, Accuracy: 18.97%\n",
            "Epoch: 35, Step: 309/655, Loss: 2.206564, Accuracy: 19.02%\n",
            "Epoch: 35, Step: 310/655, Loss: 2.206574, Accuracy: 19.05%\n",
            "Epoch: 35, Step: 311/655, Loss: 2.206556, Accuracy: 19.04%\n",
            "Epoch: 35, Step: 312/655, Loss: 2.206480, Accuracy: 19.02%\n",
            "Epoch: 35, Step: 313/655, Loss: 2.206565, Accuracy: 19.04%\n",
            "Epoch: 35, Step: 314/655, Loss: 2.206676, Accuracy: 19.02%\n",
            "Epoch: 35, Step: 315/655, Loss: 2.206596, Accuracy: 19.01%\n",
            "Epoch: 35, Step: 316/655, Loss: 2.206684, Accuracy: 19.01%\n",
            "Epoch: 35, Step: 317/655, Loss: 2.206977, Accuracy: 18.99%\n",
            "Epoch: 35, Step: 318/655, Loss: 2.207000, Accuracy: 19.03%\n",
            "Epoch: 35, Step: 319/655, Loss: 2.207201, Accuracy: 19.01%\n",
            "Epoch: 35, Step: 320/655, Loss: 2.207003, Accuracy: 19.00%\n",
            "Epoch: 35, Step: 321/655, Loss: 2.207392, Accuracy: 18.98%\n",
            "Epoch: 35, Step: 322/655, Loss: 2.207713, Accuracy: 18.96%\n",
            "Epoch: 35, Step: 323/655, Loss: 2.207669, Accuracy: 18.97%\n",
            "Epoch: 35, Step: 324/655, Loss: 2.208050, Accuracy: 18.95%\n",
            "Epoch: 35, Step: 325/655, Loss: 2.207794, Accuracy: 18.96%\n",
            "Epoch: 35, Step: 326/655, Loss: 2.208316, Accuracy: 18.93%\n",
            "Epoch: 35, Step: 327/655, Loss: 2.208183, Accuracy: 18.93%\n",
            "Epoch: 35, Step: 328/655, Loss: 2.208236, Accuracy: 18.94%\n",
            "Epoch: 35, Step: 329/655, Loss: 2.208073, Accuracy: 18.94%\n",
            "Epoch: 35, Step: 330/655, Loss: 2.207531, Accuracy: 18.97%\n",
            "Epoch: 35, Step: 331/655, Loss: 2.207324, Accuracy: 18.98%\n",
            "Epoch: 35, Step: 332/655, Loss: 2.207388, Accuracy: 18.94%\n",
            "Epoch: 35, Step: 333/655, Loss: 2.207390, Accuracy: 18.94%\n",
            "Epoch: 35, Step: 334/655, Loss: 2.207649, Accuracy: 18.92%\n",
            "Epoch: 35, Step: 335/655, Loss: 2.207244, Accuracy: 18.94%\n",
            "Epoch: 35, Step: 336/655, Loss: 2.207386, Accuracy: 18.91%\n",
            "Epoch: 35, Step: 337/655, Loss: 2.207590, Accuracy: 18.92%\n",
            "Epoch: 35, Step: 338/655, Loss: 2.207403, Accuracy: 18.92%\n",
            "Epoch: 35, Step: 339/655, Loss: 2.207475, Accuracy: 18.89%\n",
            "Epoch: 35, Step: 340/655, Loss: 2.207492, Accuracy: 18.88%\n",
            "Epoch: 35, Step: 341/655, Loss: 2.207548, Accuracy: 18.87%\n",
            "Epoch: 35, Step: 342/655, Loss: 2.207468, Accuracy: 18.89%\n",
            "Epoch: 35, Step: 343/655, Loss: 2.207617, Accuracy: 18.90%\n",
            "Epoch: 35, Step: 344/655, Loss: 2.207342, Accuracy: 18.92%\n",
            "Epoch: 35, Step: 345/655, Loss: 2.207617, Accuracy: 18.90%\n",
            "Epoch: 35, Step: 346/655, Loss: 2.207517, Accuracy: 18.89%\n",
            "Epoch: 35, Step: 347/655, Loss: 2.207058, Accuracy: 18.90%\n",
            "Epoch: 35, Step: 348/655, Loss: 2.207321, Accuracy: 18.88%\n",
            "Epoch: 35, Step: 349/655, Loss: 2.207164, Accuracy: 18.88%\n",
            "Epoch: 35, Step: 350/655, Loss: 2.207220, Accuracy: 18.88%\n",
            "Epoch: 35, Step: 351/655, Loss: 2.206990, Accuracy: 18.89%\n",
            "Epoch: 35, Step: 352/655, Loss: 2.206817, Accuracy: 18.89%\n",
            "Epoch: 35, Step: 353/655, Loss: 2.206733, Accuracy: 18.91%\n",
            "Epoch: 35, Step: 354/655, Loss: 2.206629, Accuracy: 18.88%\n",
            "Epoch: 35, Step: 355/655, Loss: 2.206822, Accuracy: 18.87%\n",
            "Epoch: 35, Step: 356/655, Loss: 2.206875, Accuracy: 18.88%\n",
            "Epoch: 35, Step: 357/655, Loss: 2.206669, Accuracy: 18.93%\n",
            "Epoch: 35, Step: 358/655, Loss: 2.206639, Accuracy: 18.94%\n",
            "Epoch: 35, Step: 359/655, Loss: 2.206667, Accuracy: 18.92%\n",
            "Epoch: 35, Step: 360/655, Loss: 2.206656, Accuracy: 18.93%\n",
            "Epoch: 35, Step: 361/655, Loss: 2.206757, Accuracy: 18.91%\n",
            "Epoch: 35, Step: 362/655, Loss: 2.207144, Accuracy: 18.90%\n",
            "Epoch: 35, Step: 363/655, Loss: 2.207410, Accuracy: 18.89%\n",
            "Epoch: 35, Step: 364/655, Loss: 2.207338, Accuracy: 18.90%\n",
            "Epoch: 35, Step: 365/655, Loss: 2.207303, Accuracy: 18.89%\n",
            "Epoch: 35, Step: 366/655, Loss: 2.207026, Accuracy: 18.91%\n",
            "Epoch: 35, Step: 367/655, Loss: 2.206991, Accuracy: 18.88%\n",
            "Epoch: 35, Step: 368/655, Loss: 2.206949, Accuracy: 18.89%\n",
            "Epoch: 35, Step: 369/655, Loss: 2.206941, Accuracy: 18.88%\n",
            "Epoch: 35, Step: 370/655, Loss: 2.206979, Accuracy: 18.87%\n",
            "Epoch: 35, Step: 371/655, Loss: 2.207223, Accuracy: 18.82%\n",
            "Epoch: 35, Step: 372/655, Loss: 2.207056, Accuracy: 18.85%\n",
            "Epoch: 35, Step: 373/655, Loss: 2.207171, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 374/655, Loss: 2.207206, Accuracy: 18.85%\n",
            "Epoch: 35, Step: 375/655, Loss: 2.206951, Accuracy: 18.85%\n",
            "Epoch: 35, Step: 376/655, Loss: 2.206894, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 377/655, Loss: 2.206885, Accuracy: 18.82%\n",
            "Epoch: 35, Step: 378/655, Loss: 2.206889, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 379/655, Loss: 2.206569, Accuracy: 18.86%\n",
            "Epoch: 35, Step: 380/655, Loss: 2.206617, Accuracy: 18.86%\n",
            "Epoch: 35, Step: 381/655, Loss: 2.206529, Accuracy: 18.89%\n",
            "Epoch: 35, Step: 382/655, Loss: 2.206403, Accuracy: 18.92%\n",
            "Epoch: 35, Step: 383/655, Loss: 2.206355, Accuracy: 18.91%\n",
            "Epoch: 35, Step: 384/655, Loss: 2.206215, Accuracy: 18.90%\n",
            "Epoch: 35, Step: 385/655, Loss: 2.206298, Accuracy: 18.90%\n",
            "Epoch: 35, Step: 386/655, Loss: 2.206634, Accuracy: 18.86%\n",
            "Epoch: 35, Step: 387/655, Loss: 2.206781, Accuracy: 18.86%\n",
            "Epoch: 35, Step: 388/655, Loss: 2.206828, Accuracy: 18.88%\n",
            "Epoch: 35, Step: 389/655, Loss: 2.207207, Accuracy: 18.86%\n",
            "Epoch: 35, Step: 390/655, Loss: 2.207136, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 391/655, Loss: 2.207352, Accuracy: 18.83%\n",
            "Epoch: 35, Step: 392/655, Loss: 2.207110, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 393/655, Loss: 2.207181, Accuracy: 18.85%\n",
            "Epoch: 35, Step: 394/655, Loss: 2.207136, Accuracy: 18.83%\n",
            "Epoch: 35, Step: 395/655, Loss: 2.206987, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 396/655, Loss: 2.206711, Accuracy: 18.88%\n",
            "Epoch: 35, Step: 397/655, Loss: 2.206437, Accuracy: 18.91%\n",
            "Epoch: 35, Step: 398/655, Loss: 2.206666, Accuracy: 18.90%\n",
            "Epoch: 35, Step: 399/655, Loss: 2.206446, Accuracy: 18.90%\n",
            "Epoch: 35, Step: 400/655, Loss: 2.206727, Accuracy: 18.86%\n",
            "Epoch: 35, Step: 401/655, Loss: 2.206519, Accuracy: 18.91%\n",
            "Epoch: 35, Step: 402/655, Loss: 2.206581, Accuracy: 18.91%\n",
            "Epoch: 35, Step: 403/655, Loss: 2.206872, Accuracy: 18.89%\n",
            "Epoch: 35, Step: 404/655, Loss: 2.207336, Accuracy: 18.87%\n",
            "Epoch: 35, Step: 405/655, Loss: 2.207428, Accuracy: 18.86%\n",
            "Epoch: 35, Step: 406/655, Loss: 2.207411, Accuracy: 18.86%\n",
            "Epoch: 35, Step: 407/655, Loss: 2.207456, Accuracy: 18.83%\n",
            "Epoch: 35, Step: 408/655, Loss: 2.207368, Accuracy: 18.83%\n",
            "Epoch: 35, Step: 409/655, Loss: 2.207666, Accuracy: 18.83%\n",
            "Epoch: 35, Step: 410/655, Loss: 2.207593, Accuracy: 18.85%\n",
            "Epoch: 35, Step: 411/655, Loss: 2.207452, Accuracy: 18.85%\n",
            "Epoch: 35, Step: 412/655, Loss: 2.207347, Accuracy: 18.83%\n",
            "Epoch: 35, Step: 413/655, Loss: 2.207375, Accuracy: 18.82%\n",
            "Epoch: 35, Step: 414/655, Loss: 2.207288, Accuracy: 18.81%\n",
            "Epoch: 35, Step: 415/655, Loss: 2.206979, Accuracy: 18.83%\n",
            "Epoch: 35, Step: 416/655, Loss: 2.207052, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 417/655, Loss: 2.206856, Accuracy: 18.83%\n",
            "Epoch: 35, Step: 418/655, Loss: 2.206819, Accuracy: 18.82%\n",
            "Epoch: 35, Step: 419/655, Loss: 2.206455, Accuracy: 18.86%\n",
            "Epoch: 35, Step: 420/655, Loss: 2.206644, Accuracy: 18.85%\n",
            "Epoch: 35, Step: 421/655, Loss: 2.206753, Accuracy: 18.85%\n",
            "Epoch: 35, Step: 422/655, Loss: 2.206767, Accuracy: 18.85%\n",
            "Epoch: 35, Step: 423/655, Loss: 2.206763, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 424/655, Loss: 2.207006, Accuracy: 18.82%\n",
            "Epoch: 35, Step: 425/655, Loss: 2.207152, Accuracy: 18.82%\n",
            "Epoch: 35, Step: 426/655, Loss: 2.206991, Accuracy: 18.82%\n",
            "Epoch: 35, Step: 427/655, Loss: 2.207004, Accuracy: 18.83%\n",
            "Epoch: 35, Step: 428/655, Loss: 2.206726, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 429/655, Loss: 2.206765, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 430/655, Loss: 2.206666, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 431/655, Loss: 2.206847, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 432/655, Loss: 2.206919, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 433/655, Loss: 2.206401, Accuracy: 18.88%\n",
            "Epoch: 35, Step: 434/655, Loss: 2.206481, Accuracy: 18.87%\n",
            "Epoch: 35, Step: 435/655, Loss: 2.206547, Accuracy: 18.85%\n",
            "Epoch: 35, Step: 436/655, Loss: 2.206805, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 437/655, Loss: 2.206775, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 438/655, Loss: 2.206994, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 439/655, Loss: 2.206819, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 440/655, Loss: 2.206771, Accuracy: 18.83%\n",
            "Epoch: 35, Step: 441/655, Loss: 2.206875, Accuracy: 18.83%\n",
            "Epoch: 35, Step: 442/655, Loss: 2.206983, Accuracy: 18.81%\n",
            "Epoch: 35, Step: 443/655, Loss: 2.207151, Accuracy: 18.79%\n",
            "Epoch: 35, Step: 444/655, Loss: 2.206938, Accuracy: 18.81%\n",
            "Epoch: 35, Step: 445/655, Loss: 2.206760, Accuracy: 18.82%\n",
            "Epoch: 35, Step: 446/655, Loss: 2.207054, Accuracy: 18.83%\n",
            "Epoch: 35, Step: 447/655, Loss: 2.207009, Accuracy: 18.83%\n",
            "Epoch: 35, Step: 448/655, Loss: 2.207010, Accuracy: 18.83%\n",
            "Epoch: 35, Step: 449/655, Loss: 2.206730, Accuracy: 18.88%\n",
            "Epoch: 35, Step: 450/655, Loss: 2.206962, Accuracy: 18.88%\n",
            "Epoch: 35, Step: 451/655, Loss: 2.207097, Accuracy: 18.85%\n",
            "Epoch: 35, Step: 452/655, Loss: 2.207328, Accuracy: 18.87%\n",
            "Epoch: 35, Step: 453/655, Loss: 2.207370, Accuracy: 18.86%\n",
            "Epoch: 35, Step: 454/655, Loss: 2.207507, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 455/655, Loss: 2.207227, Accuracy: 18.85%\n",
            "Epoch: 35, Step: 456/655, Loss: 2.207200, Accuracy: 18.85%\n",
            "Epoch: 35, Step: 457/655, Loss: 2.207369, Accuracy: 18.85%\n",
            "Epoch: 35, Step: 458/655, Loss: 2.207375, Accuracy: 18.86%\n",
            "Epoch: 35, Step: 459/655, Loss: 2.207536, Accuracy: 18.84%\n",
            "Epoch: 35, Step: 460/655, Loss: 2.207681, Accuracy: 18.82%\n",
            "Epoch: 35, Step: 461/655, Loss: 2.207744, Accuracy: 18.81%\n",
            "Epoch: 35, Step: 462/655, Loss: 2.207693, Accuracy: 18.79%\n",
            "Epoch: 35, Step: 463/655, Loss: 2.207813, Accuracy: 18.80%\n",
            "Epoch: 35, Step: 464/655, Loss: 2.207739, Accuracy: 18.80%\n",
            "Epoch: 35, Step: 465/655, Loss: 2.207719, Accuracy: 18.80%\n",
            "Epoch: 35, Step: 466/655, Loss: 2.207759, Accuracy: 18.80%\n",
            "Epoch: 35, Step: 467/655, Loss: 2.207812, Accuracy: 18.80%\n",
            "Epoch: 35, Step: 468/655, Loss: 2.207836, Accuracy: 18.78%\n",
            "Epoch: 35, Step: 469/655, Loss: 2.208163, Accuracy: 18.76%\n",
            "Epoch: 35, Step: 470/655, Loss: 2.208161, Accuracy: 18.76%\n",
            "Epoch: 35, Step: 471/655, Loss: 2.208231, Accuracy: 18.76%\n",
            "Epoch: 35, Step: 472/655, Loss: 2.208203, Accuracy: 18.77%\n",
            "Epoch: 35, Step: 473/655, Loss: 2.207881, Accuracy: 18.78%\n",
            "Epoch: 35, Step: 474/655, Loss: 2.207997, Accuracy: 18.77%\n",
            "Epoch: 35, Step: 475/655, Loss: 2.207873, Accuracy: 18.76%\n",
            "Epoch: 35, Step: 476/655, Loss: 2.207783, Accuracy: 18.75%\n",
            "Epoch: 35, Step: 477/655, Loss: 2.207714, Accuracy: 18.76%\n",
            "Epoch: 35, Step: 478/655, Loss: 2.207639, Accuracy: 18.76%\n",
            "Epoch: 35, Step: 479/655, Loss: 2.207681, Accuracy: 18.74%\n",
            "Epoch: 35, Step: 480/655, Loss: 2.207754, Accuracy: 18.75%\n",
            "Epoch: 35, Step: 481/655, Loss: 2.207943, Accuracy: 18.72%\n",
            "Epoch: 35, Step: 482/655, Loss: 2.207968, Accuracy: 18.72%\n",
            "Epoch: 35, Step: 483/655, Loss: 2.207897, Accuracy: 18.74%\n",
            "Epoch: 35, Step: 484/655, Loss: 2.208090, Accuracy: 18.75%\n",
            "Epoch: 35, Step: 485/655, Loss: 2.207719, Accuracy: 18.76%\n",
            "Epoch: 35, Step: 486/655, Loss: 2.207956, Accuracy: 18.75%\n",
            "Epoch: 35, Step: 487/655, Loss: 2.207820, Accuracy: 18.76%\n",
            "Epoch: 35, Step: 488/655, Loss: 2.207763, Accuracy: 18.75%\n",
            "Epoch: 35, Step: 489/655, Loss: 2.207701, Accuracy: 18.74%\n",
            "Epoch: 35, Step: 490/655, Loss: 2.207551, Accuracy: 18.75%\n",
            "Epoch: 35, Step: 491/655, Loss: 2.207807, Accuracy: 18.73%\n",
            "Epoch: 35, Step: 492/655, Loss: 2.207950, Accuracy: 18.73%\n",
            "Epoch: 35, Step: 493/655, Loss: 2.207877, Accuracy: 18.72%\n",
            "Epoch: 35, Step: 494/655, Loss: 2.207937, Accuracy: 18.72%\n",
            "Epoch: 35, Step: 495/655, Loss: 2.207890, Accuracy: 18.72%\n",
            "Epoch: 35, Step: 496/655, Loss: 2.207893, Accuracy: 18.73%\n",
            "Epoch: 35, Step: 497/655, Loss: 2.207706, Accuracy: 18.74%\n",
            "Epoch: 35, Step: 498/655, Loss: 2.207741, Accuracy: 18.74%\n",
            "Epoch: 35, Step: 499/655, Loss: 2.207732, Accuracy: 18.73%\n",
            "Epoch: 35, Step: 500/655, Loss: 2.207730, Accuracy: 18.73%\n",
            "Epoch: 35, Step: 501/655, Loss: 2.207972, Accuracy: 18.71%\n",
            "Epoch: 35, Step: 502/655, Loss: 2.207947, Accuracy: 18.70%\n",
            "Epoch: 35, Step: 503/655, Loss: 2.207934, Accuracy: 18.70%\n",
            "Epoch: 35, Step: 504/655, Loss: 2.208187, Accuracy: 18.69%\n",
            "Epoch: 35, Step: 505/655, Loss: 2.208288, Accuracy: 18.69%\n",
            "Epoch: 35, Step: 506/655, Loss: 2.208061, Accuracy: 18.70%\n",
            "Epoch: 35, Step: 507/655, Loss: 2.208091, Accuracy: 18.70%\n",
            "Epoch: 35, Step: 508/655, Loss: 2.208315, Accuracy: 18.69%\n",
            "Epoch: 35, Step: 509/655, Loss: 2.208616, Accuracy: 18.68%\n",
            "Epoch: 35, Step: 510/655, Loss: 2.208484, Accuracy: 18.68%\n",
            "Epoch: 35, Step: 511/655, Loss: 2.208267, Accuracy: 18.68%\n",
            "Epoch: 35, Step: 512/655, Loss: 2.208367, Accuracy: 18.67%\n",
            "Epoch: 35, Step: 513/655, Loss: 2.208224, Accuracy: 18.68%\n",
            "Epoch: 35, Step: 514/655, Loss: 2.208400, Accuracy: 18.65%\n",
            "Epoch: 35, Step: 515/655, Loss: 2.208488, Accuracy: 18.62%\n",
            "Epoch: 35, Step: 516/655, Loss: 2.208581, Accuracy: 18.61%\n",
            "Epoch: 35, Step: 517/655, Loss: 2.208584, Accuracy: 18.63%\n",
            "Epoch: 35, Step: 518/655, Loss: 2.208572, Accuracy: 18.65%\n",
            "Epoch: 35, Step: 519/655, Loss: 2.208500, Accuracy: 18.64%\n",
            "Epoch: 35, Step: 520/655, Loss: 2.208415, Accuracy: 18.66%\n",
            "Epoch: 35, Step: 521/655, Loss: 2.208567, Accuracy: 18.65%\n",
            "Epoch: 35, Step: 522/655, Loss: 2.208770, Accuracy: 18.62%\n",
            "Epoch: 35, Step: 523/655, Loss: 2.208937, Accuracy: 18.63%\n",
            "Epoch: 35, Step: 524/655, Loss: 2.209034, Accuracy: 18.63%\n",
            "Epoch: 35, Step: 525/655, Loss: 2.209129, Accuracy: 18.62%\n",
            "Epoch: 35, Step: 526/655, Loss: 2.208830, Accuracy: 18.64%\n",
            "Epoch: 35, Step: 527/655, Loss: 2.208943, Accuracy: 18.64%\n",
            "Epoch: 35, Step: 528/655, Loss: 2.209006, Accuracy: 18.65%\n",
            "Epoch: 35, Step: 529/655, Loss: 2.209230, Accuracy: 18.64%\n",
            "Epoch: 35, Step: 530/655, Loss: 2.209135, Accuracy: 18.65%\n",
            "Epoch: 35, Step: 531/655, Loss: 2.209308, Accuracy: 18.64%\n",
            "Epoch: 35, Step: 532/655, Loss: 2.209144, Accuracy: 18.64%\n",
            "Epoch: 35, Step: 533/655, Loss: 2.209169, Accuracy: 18.64%\n",
            "Epoch: 35, Step: 534/655, Loss: 2.208875, Accuracy: 18.65%\n",
            "Epoch: 35, Step: 535/655, Loss: 2.208620, Accuracy: 18.65%\n",
            "Epoch: 35, Step: 536/655, Loss: 2.209009, Accuracy: 18.63%\n",
            "Epoch: 35, Step: 537/655, Loss: 2.209226, Accuracy: 18.60%\n",
            "Epoch: 35, Step: 538/655, Loss: 2.209201, Accuracy: 18.60%\n",
            "Epoch: 35, Step: 539/655, Loss: 2.209223, Accuracy: 18.59%\n",
            "Epoch: 35, Step: 540/655, Loss: 2.209294, Accuracy: 18.59%\n",
            "Epoch: 35, Step: 541/655, Loss: 2.209241, Accuracy: 18.59%\n",
            "Epoch: 35, Step: 542/655, Loss: 2.209427, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 543/655, Loss: 2.209552, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 544/655, Loss: 2.209657, Accuracy: 18.54%\n",
            "Epoch: 35, Step: 545/655, Loss: 2.209748, Accuracy: 18.53%\n",
            "Epoch: 35, Step: 546/655, Loss: 2.209800, Accuracy: 18.54%\n",
            "Epoch: 35, Step: 547/655, Loss: 2.209847, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 548/655, Loss: 2.209908, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 549/655, Loss: 2.209965, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 550/655, Loss: 2.210036, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 551/655, Loss: 2.209740, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 552/655, Loss: 2.209791, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 553/655, Loss: 2.209537, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 554/655, Loss: 2.209519, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 555/655, Loss: 2.209345, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 556/655, Loss: 2.209417, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 557/655, Loss: 2.209398, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 558/655, Loss: 2.209370, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 559/655, Loss: 2.209221, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 560/655, Loss: 2.208959, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 561/655, Loss: 2.209090, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 562/655, Loss: 2.209055, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 563/655, Loss: 2.209065, Accuracy: 18.54%\n",
            "Epoch: 35, Step: 564/655, Loss: 2.209089, Accuracy: 18.54%\n",
            "Epoch: 35, Step: 565/655, Loss: 2.208966, Accuracy: 18.53%\n",
            "Epoch: 35, Step: 566/655, Loss: 2.208846, Accuracy: 18.52%\n",
            "Epoch: 35, Step: 567/655, Loss: 2.208764, Accuracy: 18.52%\n",
            "Epoch: 35, Step: 568/655, Loss: 2.208685, Accuracy: 18.54%\n",
            "Epoch: 35, Step: 569/655, Loss: 2.208863, Accuracy: 18.52%\n",
            "Epoch: 35, Step: 570/655, Loss: 2.208915, Accuracy: 18.54%\n",
            "Epoch: 35, Step: 571/655, Loss: 2.209065, Accuracy: 18.52%\n",
            "Epoch: 35, Step: 572/655, Loss: 2.208964, Accuracy: 18.53%\n",
            "Epoch: 35, Step: 573/655, Loss: 2.208738, Accuracy: 18.53%\n",
            "Epoch: 35, Step: 574/655, Loss: 2.208651, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 575/655, Loss: 2.208594, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 576/655, Loss: 2.208594, Accuracy: 18.54%\n",
            "Epoch: 35, Step: 577/655, Loss: 2.208872, Accuracy: 18.51%\n",
            "Epoch: 35, Step: 578/655, Loss: 2.208836, Accuracy: 18.53%\n",
            "Epoch: 35, Step: 579/655, Loss: 2.208757, Accuracy: 18.53%\n",
            "Epoch: 35, Step: 580/655, Loss: 2.208635, Accuracy: 18.53%\n",
            "Epoch: 35, Step: 581/655, Loss: 2.208470, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 582/655, Loss: 2.208395, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 583/655, Loss: 2.208409, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 584/655, Loss: 2.208554, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 585/655, Loss: 2.208551, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 586/655, Loss: 2.208607, Accuracy: 18.53%\n",
            "Epoch: 35, Step: 587/655, Loss: 2.208495, Accuracy: 18.54%\n",
            "Epoch: 35, Step: 588/655, Loss: 2.208522, Accuracy: 18.54%\n",
            "Epoch: 35, Step: 589/655, Loss: 2.208411, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 590/655, Loss: 2.208132, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 591/655, Loss: 2.208122, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 592/655, Loss: 2.207933, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 593/655, Loss: 2.207835, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 594/655, Loss: 2.207635, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 595/655, Loss: 2.207563, Accuracy: 18.58%\n",
            "Epoch: 35, Step: 596/655, Loss: 2.207644, Accuracy: 18.58%\n",
            "Epoch: 35, Step: 597/655, Loss: 2.207872, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 598/655, Loss: 2.207820, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 599/655, Loss: 2.207877, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 600/655, Loss: 2.208220, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 601/655, Loss: 2.208156, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 602/655, Loss: 2.208257, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 603/655, Loss: 2.208126, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 604/655, Loss: 2.207921, Accuracy: 18.58%\n",
            "Epoch: 35, Step: 605/655, Loss: 2.207945, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 606/655, Loss: 2.207899, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 607/655, Loss: 2.208078, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 608/655, Loss: 2.208119, Accuracy: 18.54%\n",
            "Epoch: 35, Step: 609/655, Loss: 2.208144, Accuracy: 18.54%\n",
            "Epoch: 35, Step: 610/655, Loss: 2.208226, Accuracy: 18.54%\n",
            "Epoch: 35, Step: 611/655, Loss: 2.207875, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 612/655, Loss: 2.208111, Accuracy: 18.53%\n",
            "Epoch: 35, Step: 613/655, Loss: 2.208013, Accuracy: 18.53%\n",
            "Epoch: 35, Step: 614/655, Loss: 2.208195, Accuracy: 18.53%\n",
            "Epoch: 35, Step: 615/655, Loss: 2.207951, Accuracy: 18.53%\n",
            "Epoch: 35, Step: 616/655, Loss: 2.207876, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 617/655, Loss: 2.207701, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 618/655, Loss: 2.207720, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 619/655, Loss: 2.207726, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 620/655, Loss: 2.207889, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 621/655, Loss: 2.207539, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 622/655, Loss: 2.207716, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 623/655, Loss: 2.207535, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 624/655, Loss: 2.207621, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 625/655, Loss: 2.207570, Accuracy: 18.58%\n",
            "Epoch: 35, Step: 626/655, Loss: 2.207682, Accuracy: 18.58%\n",
            "Epoch: 35, Step: 627/655, Loss: 2.207955, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 628/655, Loss: 2.207926, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 629/655, Loss: 2.208148, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 630/655, Loss: 2.207949, Accuracy: 18.58%\n",
            "Epoch: 35, Step: 631/655, Loss: 2.208058, Accuracy: 18.58%\n",
            "Epoch: 35, Step: 632/655, Loss: 2.208235, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 633/655, Loss: 2.208026, Accuracy: 18.59%\n",
            "Epoch: 35, Step: 634/655, Loss: 2.207995, Accuracy: 18.59%\n",
            "Epoch: 35, Step: 635/655, Loss: 2.207983, Accuracy: 18.60%\n",
            "Epoch: 35, Step: 636/655, Loss: 2.207673, Accuracy: 18.62%\n",
            "Epoch: 35, Step: 637/655, Loss: 2.207603, Accuracy: 18.60%\n",
            "Epoch: 35, Step: 638/655, Loss: 2.207562, Accuracy: 18.59%\n",
            "Epoch: 35, Step: 639/655, Loss: 2.207467, Accuracy: 18.60%\n",
            "Epoch: 35, Step: 640/655, Loss: 2.207322, Accuracy: 18.60%\n",
            "Epoch: 35, Step: 641/655, Loss: 2.207419, Accuracy: 18.61%\n",
            "Epoch: 35, Step: 642/655, Loss: 2.207494, Accuracy: 18.61%\n",
            "Epoch: 35, Step: 643/655, Loss: 2.207308, Accuracy: 18.59%\n",
            "Epoch: 35, Step: 644/655, Loss: 2.207374, Accuracy: 18.58%\n",
            "Epoch: 35, Step: 645/655, Loss: 2.207290, Accuracy: 18.58%\n",
            "Epoch: 35, Step: 646/655, Loss: 2.207331, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 647/655, Loss: 2.207482, Accuracy: 18.56%\n",
            "Epoch: 35, Step: 648/655, Loss: 2.207593, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 649/655, Loss: 2.207632, Accuracy: 18.58%\n",
            "Epoch: 35, Step: 650/655, Loss: 2.207699, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 651/655, Loss: 2.207764, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 652/655, Loss: 2.207779, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 653/655, Loss: 2.207640, Accuracy: 18.55%\n",
            "Epoch: 35, Step: 654/655, Loss: 2.207479, Accuracy: 18.57%\n",
            "Epoch: 35, Step: 655/655, Loss: 2.207692, Accuracy: 18.57%\n",
            "Epoch: 36, Step: 1/655, Loss: 2.188311, Accuracy: 15.62%\n",
            "Epoch: 36, Step: 2/655, Loss: 2.165547, Accuracy: 15.62%\n",
            "Epoch: 36, Step: 3/655, Loss: 2.151839, Accuracy: 19.79%\n",
            "Epoch: 36, Step: 4/655, Loss: 2.138427, Accuracy: 19.53%\n",
            "Epoch: 36, Step: 5/655, Loss: 2.171109, Accuracy: 20.00%\n",
            "Epoch: 36, Step: 6/655, Loss: 2.158865, Accuracy: 21.88%\n",
            "Epoch: 36, Step: 7/655, Loss: 2.167098, Accuracy: 20.98%\n",
            "Epoch: 36, Step: 8/655, Loss: 2.164125, Accuracy: 19.92%\n",
            "Epoch: 36, Step: 9/655, Loss: 2.181041, Accuracy: 19.44%\n",
            "Epoch: 36, Step: 10/655, Loss: 2.185433, Accuracy: 18.44%\n",
            "Epoch: 36, Step: 11/655, Loss: 2.191310, Accuracy: 17.90%\n",
            "Epoch: 36, Step: 12/655, Loss: 2.200942, Accuracy: 17.45%\n",
            "Epoch: 36, Step: 13/655, Loss: 2.201504, Accuracy: 17.79%\n",
            "Epoch: 36, Step: 14/655, Loss: 2.202899, Accuracy: 17.63%\n",
            "Epoch: 36, Step: 15/655, Loss: 2.202101, Accuracy: 17.71%\n",
            "Epoch: 36, Step: 16/655, Loss: 2.205356, Accuracy: 17.97%\n",
            "Epoch: 36, Step: 17/655, Loss: 2.211883, Accuracy: 17.65%\n",
            "Epoch: 36, Step: 18/655, Loss: 2.214329, Accuracy: 18.06%\n",
            "Epoch: 36, Step: 19/655, Loss: 2.222776, Accuracy: 17.76%\n",
            "Epoch: 36, Step: 20/655, Loss: 2.223966, Accuracy: 17.34%\n",
            "Epoch: 36, Step: 21/655, Loss: 2.222050, Accuracy: 17.71%\n",
            "Epoch: 36, Step: 22/655, Loss: 2.226755, Accuracy: 17.47%\n",
            "Epoch: 36, Step: 23/655, Loss: 2.223936, Accuracy: 17.93%\n",
            "Epoch: 36, Step: 24/655, Loss: 2.218589, Accuracy: 18.62%\n",
            "Epoch: 36, Step: 25/655, Loss: 2.221043, Accuracy: 18.00%\n",
            "Epoch: 36, Step: 26/655, Loss: 2.221793, Accuracy: 17.91%\n",
            "Epoch: 36, Step: 27/655, Loss: 2.221471, Accuracy: 18.06%\n",
            "Epoch: 36, Step: 28/655, Loss: 2.221703, Accuracy: 18.19%\n",
            "Epoch: 36, Step: 29/655, Loss: 2.220904, Accuracy: 18.32%\n",
            "Epoch: 36, Step: 30/655, Loss: 2.219596, Accuracy: 18.44%\n",
            "Epoch: 36, Step: 31/655, Loss: 2.218191, Accuracy: 18.55%\n",
            "Epoch: 36, Step: 32/655, Loss: 2.219949, Accuracy: 18.55%\n",
            "Epoch: 36, Step: 33/655, Loss: 2.217643, Accuracy: 18.84%\n",
            "Epoch: 36, Step: 34/655, Loss: 2.218241, Accuracy: 18.66%\n",
            "Epoch: 36, Step: 35/655, Loss: 2.220326, Accuracy: 18.48%\n",
            "Epoch: 36, Step: 36/655, Loss: 2.222978, Accuracy: 18.32%\n",
            "Epoch: 36, Step: 37/655, Loss: 2.219915, Accuracy: 18.16%\n",
            "Epoch: 36, Step: 38/655, Loss: 2.219199, Accuracy: 18.42%\n",
            "Epoch: 36, Step: 39/655, Loss: 2.216983, Accuracy: 18.51%\n",
            "Epoch: 36, Step: 40/655, Loss: 2.218894, Accuracy: 18.59%\n",
            "Epoch: 36, Step: 41/655, Loss: 2.219411, Accuracy: 18.67%\n",
            "Epoch: 36, Step: 42/655, Loss: 2.218972, Accuracy: 18.45%\n",
            "Epoch: 36, Step: 43/655, Loss: 2.218664, Accuracy: 18.39%\n",
            "Epoch: 36, Step: 44/655, Loss: 2.219053, Accuracy: 18.47%\n",
            "Epoch: 36, Step: 45/655, Loss: 2.217582, Accuracy: 18.47%\n",
            "Epoch: 36, Step: 46/655, Loss: 2.219022, Accuracy: 18.27%\n",
            "Epoch: 36, Step: 47/655, Loss: 2.216764, Accuracy: 18.55%\n",
            "Epoch: 36, Step: 48/655, Loss: 2.216425, Accuracy: 18.68%\n",
            "Epoch: 36, Step: 49/655, Loss: 2.218993, Accuracy: 18.43%\n",
            "Epoch: 36, Step: 50/655, Loss: 2.221304, Accuracy: 18.38%\n",
            "Epoch: 36, Step: 51/655, Loss: 2.218779, Accuracy: 18.44%\n",
            "Epoch: 36, Step: 52/655, Loss: 2.218714, Accuracy: 18.57%\n",
            "Epoch: 36, Step: 53/655, Loss: 2.217173, Accuracy: 18.75%\n",
            "Epoch: 36, Step: 54/655, Loss: 2.216752, Accuracy: 18.87%\n",
            "Epoch: 36, Step: 55/655, Loss: 2.216739, Accuracy: 18.98%\n",
            "Epoch: 36, Step: 56/655, Loss: 2.215756, Accuracy: 18.86%\n",
            "Epoch: 36, Step: 57/655, Loss: 2.216094, Accuracy: 18.75%\n",
            "Epoch: 36, Step: 58/655, Loss: 2.215366, Accuracy: 18.75%\n",
            "Epoch: 36, Step: 59/655, Loss: 2.214509, Accuracy: 18.75%\n",
            "Epoch: 36, Step: 60/655, Loss: 2.213112, Accuracy: 18.70%\n",
            "Epoch: 36, Step: 61/655, Loss: 2.212519, Accuracy: 18.60%\n",
            "Epoch: 36, Step: 62/655, Loss: 2.210516, Accuracy: 18.80%\n",
            "Epoch: 36, Step: 63/655, Loss: 2.209593, Accuracy: 18.85%\n",
            "Epoch: 36, Step: 64/655, Loss: 2.210687, Accuracy: 18.65%\n",
            "Epoch: 36, Step: 65/655, Loss: 2.210144, Accuracy: 18.70%\n",
            "Epoch: 36, Step: 66/655, Loss: 2.208848, Accuracy: 18.70%\n",
            "Epoch: 36, Step: 67/655, Loss: 2.209593, Accuracy: 18.61%\n",
            "Epoch: 36, Step: 68/655, Loss: 2.208901, Accuracy: 18.66%\n",
            "Epoch: 36, Step: 69/655, Loss: 2.208698, Accuracy: 18.61%\n",
            "Epoch: 36, Step: 70/655, Loss: 2.208910, Accuracy: 18.79%\n",
            "Epoch: 36, Step: 71/655, Loss: 2.208831, Accuracy: 18.75%\n",
            "Epoch: 36, Step: 72/655, Loss: 2.209002, Accuracy: 18.79%\n",
            "Epoch: 36, Step: 73/655, Loss: 2.209296, Accuracy: 18.62%\n",
            "Epoch: 36, Step: 74/655, Loss: 2.208249, Accuracy: 18.67%\n",
            "Epoch: 36, Step: 75/655, Loss: 2.208041, Accuracy: 18.67%\n",
            "Epoch: 36, Step: 76/655, Loss: 2.207832, Accuracy: 18.63%\n",
            "Epoch: 36, Step: 77/655, Loss: 2.207631, Accuracy: 18.67%\n",
            "Epoch: 36, Step: 78/655, Loss: 2.207123, Accuracy: 18.79%\n",
            "Epoch: 36, Step: 79/655, Loss: 2.207244, Accuracy: 18.87%\n",
            "Epoch: 36, Step: 80/655, Loss: 2.206189, Accuracy: 18.91%\n",
            "Epoch: 36, Step: 81/655, Loss: 2.207681, Accuracy: 18.94%\n",
            "Epoch: 36, Step: 82/655, Loss: 2.206240, Accuracy: 18.98%\n",
            "Epoch: 36, Step: 83/655, Loss: 2.205737, Accuracy: 19.05%\n",
            "Epoch: 36, Step: 84/655, Loss: 2.207871, Accuracy: 18.94%\n",
            "Epoch: 36, Step: 85/655, Loss: 2.209318, Accuracy: 18.86%\n",
            "Epoch: 36, Step: 86/655, Loss: 2.208993, Accuracy: 18.86%\n",
            "Epoch: 36, Step: 87/655, Loss: 2.208996, Accuracy: 18.93%\n",
            "Epoch: 36, Step: 88/655, Loss: 2.208640, Accuracy: 18.89%\n",
            "Epoch: 36, Step: 89/655, Loss: 2.208542, Accuracy: 18.82%\n",
            "Epoch: 36, Step: 90/655, Loss: 2.208664, Accuracy: 18.75%\n",
            "Epoch: 36, Step: 91/655, Loss: 2.208495, Accuracy: 18.78%\n",
            "Epoch: 36, Step: 92/655, Loss: 2.207398, Accuracy: 18.89%\n",
            "Epoch: 36, Step: 93/655, Loss: 2.206678, Accuracy: 18.92%\n",
            "Epoch: 36, Step: 94/655, Loss: 2.207683, Accuracy: 18.92%\n",
            "Epoch: 36, Step: 95/655, Loss: 2.207701, Accuracy: 18.88%\n",
            "Epoch: 36, Step: 96/655, Loss: 2.206585, Accuracy: 18.98%\n",
            "Epoch: 36, Step: 97/655, Loss: 2.206715, Accuracy: 18.98%\n",
            "Epoch: 36, Step: 98/655, Loss: 2.207058, Accuracy: 18.97%\n",
            "Epoch: 36, Step: 99/655, Loss: 2.207912, Accuracy: 18.91%\n",
            "Epoch: 36, Step: 100/655, Loss: 2.208204, Accuracy: 18.97%\n",
            "Epoch: 36, Step: 101/655, Loss: 2.207131, Accuracy: 18.87%\n",
            "Epoch: 36, Step: 102/655, Loss: 2.207825, Accuracy: 18.78%\n",
            "Epoch: 36, Step: 103/655, Loss: 2.208834, Accuracy: 18.69%\n",
            "Epoch: 36, Step: 104/655, Loss: 2.210020, Accuracy: 18.63%\n",
            "Epoch: 36, Step: 105/655, Loss: 2.210911, Accuracy: 18.51%\n",
            "Epoch: 36, Step: 106/655, Loss: 2.210257, Accuracy: 18.57%\n",
            "Epoch: 36, Step: 107/655, Loss: 2.210052, Accuracy: 18.57%\n",
            "Epoch: 36, Step: 108/655, Loss: 2.209027, Accuracy: 18.66%\n",
            "Epoch: 36, Step: 109/655, Loss: 2.209973, Accuracy: 18.61%\n",
            "Epoch: 36, Step: 110/655, Loss: 2.210070, Accuracy: 18.49%\n",
            "Epoch: 36, Step: 111/655, Loss: 2.210191, Accuracy: 18.47%\n",
            "Epoch: 36, Step: 112/655, Loss: 2.210390, Accuracy: 18.53%\n",
            "Epoch: 36, Step: 113/655, Loss: 2.209922, Accuracy: 18.47%\n",
            "Epoch: 36, Step: 114/655, Loss: 2.208569, Accuracy: 18.53%\n",
            "Epoch: 36, Step: 115/655, Loss: 2.207782, Accuracy: 18.53%\n",
            "Epoch: 36, Step: 116/655, Loss: 2.207526, Accuracy: 18.59%\n",
            "Epoch: 36, Step: 117/655, Loss: 2.208083, Accuracy: 18.67%\n",
            "Epoch: 36, Step: 118/655, Loss: 2.208991, Accuracy: 18.59%\n",
            "Epoch: 36, Step: 119/655, Loss: 2.210022, Accuracy: 18.57%\n",
            "Epoch: 36, Step: 120/655, Loss: 2.210112, Accuracy: 18.57%\n",
            "Epoch: 36, Step: 121/655, Loss: 2.209820, Accuracy: 18.60%\n",
            "Epoch: 36, Step: 122/655, Loss: 2.211105, Accuracy: 18.49%\n",
            "Epoch: 36, Step: 123/655, Loss: 2.211364, Accuracy: 18.52%\n",
            "Epoch: 36, Step: 124/655, Loss: 2.211001, Accuracy: 18.47%\n",
            "Epoch: 36, Step: 125/655, Loss: 2.210602, Accuracy: 18.52%\n",
            "Epoch: 36, Step: 126/655, Loss: 2.210689, Accuracy: 18.55%\n",
            "Epoch: 36, Step: 127/655, Loss: 2.211105, Accuracy: 18.53%\n",
            "Epoch: 36, Step: 128/655, Loss: 2.211339, Accuracy: 18.46%\n",
            "Epoch: 36, Step: 129/655, Loss: 2.212093, Accuracy: 18.36%\n",
            "Epoch: 36, Step: 130/655, Loss: 2.211027, Accuracy: 18.39%\n",
            "Epoch: 36, Step: 131/655, Loss: 2.210922, Accuracy: 18.34%\n",
            "Epoch: 36, Step: 132/655, Loss: 2.211229, Accuracy: 18.39%\n",
            "Epoch: 36, Step: 133/655, Loss: 2.210971, Accuracy: 18.42%\n",
            "Epoch: 36, Step: 134/655, Loss: 2.211547, Accuracy: 18.45%\n",
            "Epoch: 36, Step: 135/655, Loss: 2.210489, Accuracy: 18.45%\n",
            "Epoch: 36, Step: 136/655, Loss: 2.211614, Accuracy: 18.45%\n",
            "Epoch: 36, Step: 137/655, Loss: 2.211358, Accuracy: 18.41%\n",
            "Epoch: 36, Step: 138/655, Loss: 2.211063, Accuracy: 18.41%\n",
            "Epoch: 36, Step: 139/655, Loss: 2.211055, Accuracy: 18.44%\n",
            "Epoch: 36, Step: 140/655, Loss: 2.209675, Accuracy: 18.50%\n",
            "Epoch: 36, Step: 141/655, Loss: 2.210304, Accuracy: 18.40%\n",
            "Epoch: 36, Step: 142/655, Loss: 2.210252, Accuracy: 18.33%\n",
            "Epoch: 36, Step: 143/655, Loss: 2.210301, Accuracy: 18.27%\n",
            "Epoch: 36, Step: 144/655, Loss: 2.210630, Accuracy: 18.32%\n",
            "Epoch: 36, Step: 145/655, Loss: 2.210978, Accuracy: 18.30%\n",
            "Epoch: 36, Step: 146/655, Loss: 2.212041, Accuracy: 18.30%\n",
            "Epoch: 36, Step: 147/655, Loss: 2.211873, Accuracy: 18.37%\n",
            "Epoch: 36, Step: 148/655, Loss: 2.212238, Accuracy: 18.39%\n",
            "Epoch: 36, Step: 149/655, Loss: 2.212377, Accuracy: 18.41%\n",
            "Epoch: 36, Step: 150/655, Loss: 2.212386, Accuracy: 18.40%\n",
            "Epoch: 36, Step: 151/655, Loss: 2.213194, Accuracy: 18.36%\n",
            "Epoch: 36, Step: 152/655, Loss: 2.213513, Accuracy: 18.38%\n",
            "Epoch: 36, Step: 153/655, Loss: 2.213512, Accuracy: 18.32%\n",
            "Epoch: 36, Step: 154/655, Loss: 2.212526, Accuracy: 18.41%\n",
            "Epoch: 36, Step: 155/655, Loss: 2.211728, Accuracy: 18.51%\n",
            "Epoch: 36, Step: 156/655, Loss: 2.212137, Accuracy: 18.45%\n",
            "Epoch: 36, Step: 157/655, Loss: 2.211474, Accuracy: 18.45%\n",
            "Epoch: 36, Step: 158/655, Loss: 2.211540, Accuracy: 18.45%\n",
            "Epoch: 36, Step: 159/655, Loss: 2.211633, Accuracy: 18.47%\n",
            "Epoch: 36, Step: 160/655, Loss: 2.211324, Accuracy: 18.52%\n",
            "Epoch: 36, Step: 161/655, Loss: 2.211763, Accuracy: 18.52%\n",
            "Epoch: 36, Step: 162/655, Loss: 2.211509, Accuracy: 18.48%\n",
            "Epoch: 36, Step: 163/655, Loss: 2.211091, Accuracy: 18.56%\n",
            "Epoch: 36, Step: 164/655, Loss: 2.211094, Accuracy: 18.52%\n",
            "Epoch: 36, Step: 165/655, Loss: 2.210921, Accuracy: 18.56%\n",
            "Epoch: 36, Step: 166/655, Loss: 2.210626, Accuracy: 18.60%\n",
            "Epoch: 36, Step: 167/655, Loss: 2.210618, Accuracy: 18.54%\n",
            "Epoch: 36, Step: 168/655, Loss: 2.211077, Accuracy: 18.55%\n",
            "Epoch: 36, Step: 169/655, Loss: 2.211107, Accuracy: 18.53%\n",
            "Epoch: 36, Step: 170/655, Loss: 2.211393, Accuracy: 18.51%\n",
            "Epoch: 36, Step: 171/655, Loss: 2.211177, Accuracy: 18.48%\n",
            "Epoch: 36, Step: 172/655, Loss: 2.211290, Accuracy: 18.46%\n",
            "Epoch: 36, Step: 173/655, Loss: 2.211860, Accuracy: 18.44%\n",
            "Epoch: 36, Step: 174/655, Loss: 2.211764, Accuracy: 18.46%\n",
            "Epoch: 36, Step: 175/655, Loss: 2.212285, Accuracy: 18.41%\n",
            "Epoch: 36, Step: 176/655, Loss: 2.212288, Accuracy: 18.39%\n",
            "Epoch: 36, Step: 177/655, Loss: 2.212086, Accuracy: 18.41%\n",
            "Epoch: 36, Step: 178/655, Loss: 2.212448, Accuracy: 18.36%\n",
            "Epoch: 36, Step: 179/655, Loss: 2.212691, Accuracy: 18.38%\n",
            "Epoch: 36, Step: 180/655, Loss: 2.212546, Accuracy: 18.40%\n",
            "Epoch: 36, Step: 181/655, Loss: 2.212044, Accuracy: 18.42%\n",
            "Epoch: 36, Step: 182/655, Loss: 2.211797, Accuracy: 18.37%\n",
            "Epoch: 36, Step: 183/655, Loss: 2.211540, Accuracy: 18.41%\n",
            "Epoch: 36, Step: 184/655, Loss: 2.210853, Accuracy: 18.46%\n",
            "Epoch: 36, Step: 185/655, Loss: 2.210560, Accuracy: 18.50%\n",
            "Epoch: 36, Step: 186/655, Loss: 2.210827, Accuracy: 18.46%\n",
            "Epoch: 36, Step: 187/655, Loss: 2.210321, Accuracy: 18.45%\n",
            "Epoch: 36, Step: 188/655, Loss: 2.210768, Accuracy: 18.43%\n",
            "Epoch: 36, Step: 189/655, Loss: 2.211363, Accuracy: 18.40%\n",
            "Epoch: 36, Step: 190/655, Loss: 2.210881, Accuracy: 18.47%\n",
            "Epoch: 36, Step: 191/655, Loss: 2.210650, Accuracy: 18.55%\n",
            "Epoch: 36, Step: 192/655, Loss: 2.210730, Accuracy: 18.59%\n",
            "Epoch: 36, Step: 193/655, Loss: 2.211314, Accuracy: 18.57%\n",
            "Epoch: 36, Step: 194/655, Loss: 2.211468, Accuracy: 18.51%\n",
            "Epoch: 36, Step: 195/655, Loss: 2.211446, Accuracy: 18.54%\n",
            "Epoch: 36, Step: 196/655, Loss: 2.211773, Accuracy: 18.51%\n",
            "Epoch: 36, Step: 197/655, Loss: 2.211515, Accuracy: 18.50%\n",
            "Epoch: 36, Step: 198/655, Loss: 2.211589, Accuracy: 18.50%\n",
            "Epoch: 36, Step: 199/655, Loss: 2.211025, Accuracy: 18.51%\n",
            "Epoch: 36, Step: 200/655, Loss: 2.211354, Accuracy: 18.50%\n",
            "Epoch: 36, Step: 201/655, Loss: 2.211680, Accuracy: 18.49%\n",
            "Epoch: 36, Step: 202/655, Loss: 2.212243, Accuracy: 18.43%\n",
            "Epoch: 36, Step: 203/655, Loss: 2.212890, Accuracy: 18.38%\n",
            "Epoch: 36, Step: 204/655, Loss: 2.212658, Accuracy: 18.41%\n",
            "Epoch: 36, Step: 205/655, Loss: 2.212606, Accuracy: 18.38%\n",
            "Epoch: 36, Step: 206/655, Loss: 2.212906, Accuracy: 18.37%\n",
            "Epoch: 36, Step: 207/655, Loss: 2.212568, Accuracy: 18.39%\n",
            "Epoch: 36, Step: 208/655, Loss: 2.211646, Accuracy: 18.37%\n",
            "Epoch: 36, Step: 209/655, Loss: 2.211720, Accuracy: 18.41%\n",
            "Epoch: 36, Step: 210/655, Loss: 2.211367, Accuracy: 18.44%\n",
            "Epoch: 36, Step: 211/655, Loss: 2.211128, Accuracy: 18.42%\n",
            "Epoch: 36, Step: 212/655, Loss: 2.211358, Accuracy: 18.44%\n",
            "Epoch: 36, Step: 213/655, Loss: 2.210973, Accuracy: 18.50%\n",
            "Epoch: 36, Step: 214/655, Loss: 2.210370, Accuracy: 18.56%\n",
            "Epoch: 36, Step: 215/655, Loss: 2.210892, Accuracy: 18.53%\n",
            "Epoch: 36, Step: 216/655, Loss: 2.210264, Accuracy: 18.56%\n",
            "Epoch: 36, Step: 217/655, Loss: 2.210065, Accuracy: 18.58%\n",
            "Epoch: 36, Step: 218/655, Loss: 2.209942, Accuracy: 18.61%\n",
            "Epoch: 36, Step: 219/655, Loss: 2.210707, Accuracy: 18.55%\n",
            "Epoch: 36, Step: 220/655, Loss: 2.210204, Accuracy: 18.51%\n",
            "Epoch: 36, Step: 221/655, Loss: 2.210550, Accuracy: 18.52%\n",
            "Epoch: 36, Step: 222/655, Loss: 2.210449, Accuracy: 18.57%\n",
            "Epoch: 36, Step: 223/655, Loss: 2.209766, Accuracy: 18.58%\n",
            "Epoch: 36, Step: 224/655, Loss: 2.210302, Accuracy: 18.55%\n",
            "Epoch: 36, Step: 225/655, Loss: 2.210843, Accuracy: 18.53%\n",
            "Epoch: 36, Step: 226/655, Loss: 2.210950, Accuracy: 18.50%\n",
            "Epoch: 36, Step: 227/655, Loss: 2.210668, Accuracy: 18.53%\n",
            "Epoch: 36, Step: 228/655, Loss: 2.209786, Accuracy: 18.59%\n",
            "Epoch: 36, Step: 229/655, Loss: 2.209063, Accuracy: 18.63%\n",
            "Epoch: 36, Step: 230/655, Loss: 2.209123, Accuracy: 18.63%\n",
            "Epoch: 36, Step: 231/655, Loss: 2.209008, Accuracy: 18.67%\n",
            "Epoch: 36, Step: 232/655, Loss: 2.209098, Accuracy: 18.66%\n",
            "Epoch: 36, Step: 233/655, Loss: 2.208716, Accuracy: 18.70%\n",
            "Epoch: 36, Step: 234/655, Loss: 2.208143, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 235/655, Loss: 2.207836, Accuracy: 18.75%\n",
            "Epoch: 36, Step: 236/655, Loss: 2.207204, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 237/655, Loss: 2.207459, Accuracy: 18.79%\n",
            "Epoch: 36, Step: 238/655, Loss: 2.207673, Accuracy: 18.84%\n",
            "Epoch: 36, Step: 239/655, Loss: 2.207613, Accuracy: 18.83%\n",
            "Epoch: 36, Step: 240/655, Loss: 2.207765, Accuracy: 18.84%\n",
            "Epoch: 36, Step: 241/655, Loss: 2.207861, Accuracy: 18.84%\n",
            "Epoch: 36, Step: 242/655, Loss: 2.208055, Accuracy: 18.87%\n",
            "Epoch: 36, Step: 243/655, Loss: 2.208533, Accuracy: 18.84%\n",
            "Epoch: 36, Step: 244/655, Loss: 2.208482, Accuracy: 18.88%\n",
            "Epoch: 36, Step: 245/655, Loss: 2.208297, Accuracy: 18.89%\n",
            "Epoch: 36, Step: 246/655, Loss: 2.208182, Accuracy: 18.88%\n",
            "Epoch: 36, Step: 247/655, Loss: 2.208195, Accuracy: 18.86%\n",
            "Epoch: 36, Step: 248/655, Loss: 2.208071, Accuracy: 18.86%\n",
            "Epoch: 36, Step: 249/655, Loss: 2.207441, Accuracy: 18.89%\n",
            "Epoch: 36, Step: 250/655, Loss: 2.207195, Accuracy: 18.91%\n",
            "Epoch: 36, Step: 251/655, Loss: 2.206895, Accuracy: 18.94%\n",
            "Epoch: 36, Step: 252/655, Loss: 2.206517, Accuracy: 19.00%\n",
            "Epoch: 36, Step: 253/655, Loss: 2.206108, Accuracy: 19.03%\n",
            "Epoch: 36, Step: 254/655, Loss: 2.205834, Accuracy: 19.05%\n",
            "Epoch: 36, Step: 255/655, Loss: 2.205694, Accuracy: 19.08%\n",
            "Epoch: 36, Step: 256/655, Loss: 2.206103, Accuracy: 19.08%\n",
            "Epoch: 36, Step: 257/655, Loss: 2.206175, Accuracy: 19.08%\n",
            "Epoch: 36, Step: 258/655, Loss: 2.205796, Accuracy: 19.13%\n",
            "Epoch: 36, Step: 259/655, Loss: 2.205723, Accuracy: 19.16%\n",
            "Epoch: 36, Step: 260/655, Loss: 2.205594, Accuracy: 19.16%\n",
            "Epoch: 36, Step: 261/655, Loss: 2.205865, Accuracy: 19.13%\n",
            "Epoch: 36, Step: 262/655, Loss: 2.205701, Accuracy: 19.14%\n",
            "Epoch: 36, Step: 263/655, Loss: 2.205004, Accuracy: 19.17%\n",
            "Epoch: 36, Step: 264/655, Loss: 2.204708, Accuracy: 19.21%\n",
            "Epoch: 36, Step: 265/655, Loss: 2.204772, Accuracy: 19.20%\n",
            "Epoch: 36, Step: 266/655, Loss: 2.204451, Accuracy: 19.21%\n",
            "Epoch: 36, Step: 267/655, Loss: 2.204200, Accuracy: 19.21%\n",
            "Epoch: 36, Step: 268/655, Loss: 2.203602, Accuracy: 19.22%\n",
            "Epoch: 36, Step: 269/655, Loss: 2.203894, Accuracy: 19.20%\n",
            "Epoch: 36, Step: 270/655, Loss: 2.204179, Accuracy: 19.16%\n",
            "Epoch: 36, Step: 271/655, Loss: 2.204101, Accuracy: 19.18%\n",
            "Epoch: 36, Step: 272/655, Loss: 2.203901, Accuracy: 19.18%\n",
            "Epoch: 36, Step: 273/655, Loss: 2.204294, Accuracy: 19.13%\n",
            "Epoch: 36, Step: 274/655, Loss: 2.204637, Accuracy: 19.13%\n",
            "Epoch: 36, Step: 275/655, Loss: 2.204438, Accuracy: 19.17%\n",
            "Epoch: 36, Step: 276/655, Loss: 2.204085, Accuracy: 19.18%\n",
            "Epoch: 36, Step: 277/655, Loss: 2.204297, Accuracy: 19.16%\n",
            "Epoch: 36, Step: 278/655, Loss: 2.204587, Accuracy: 19.14%\n",
            "Epoch: 36, Step: 279/655, Loss: 2.204307, Accuracy: 19.18%\n",
            "Epoch: 36, Step: 280/655, Loss: 2.204507, Accuracy: 19.15%\n",
            "Epoch: 36, Step: 281/655, Loss: 2.204750, Accuracy: 19.14%\n",
            "Epoch: 36, Step: 282/655, Loss: 2.204308, Accuracy: 19.16%\n",
            "Epoch: 36, Step: 283/655, Loss: 2.204733, Accuracy: 19.13%\n",
            "Epoch: 36, Step: 284/655, Loss: 2.204981, Accuracy: 19.10%\n",
            "Epoch: 36, Step: 285/655, Loss: 2.205266, Accuracy: 19.09%\n",
            "Epoch: 36, Step: 286/655, Loss: 2.205235, Accuracy: 19.09%\n",
            "Epoch: 36, Step: 287/655, Loss: 2.205432, Accuracy: 19.09%\n",
            "Epoch: 36, Step: 288/655, Loss: 2.206093, Accuracy: 19.04%\n",
            "Epoch: 36, Step: 289/655, Loss: 2.206420, Accuracy: 19.00%\n",
            "Epoch: 36, Step: 290/655, Loss: 2.206414, Accuracy: 19.00%\n",
            "Epoch: 36, Step: 291/655, Loss: 2.206162, Accuracy: 19.01%\n",
            "Epoch: 36, Step: 292/655, Loss: 2.205804, Accuracy: 19.03%\n",
            "Epoch: 36, Step: 293/655, Loss: 2.205743, Accuracy: 19.02%\n",
            "Epoch: 36, Step: 294/655, Loss: 2.206092, Accuracy: 19.02%\n",
            "Epoch: 36, Step: 295/655, Loss: 2.206141, Accuracy: 19.01%\n",
            "Epoch: 36, Step: 296/655, Loss: 2.206338, Accuracy: 19.02%\n",
            "Epoch: 36, Step: 297/655, Loss: 2.206064, Accuracy: 19.03%\n",
            "Epoch: 36, Step: 298/655, Loss: 2.206300, Accuracy: 19.04%\n",
            "Epoch: 36, Step: 299/655, Loss: 2.205717, Accuracy: 19.07%\n",
            "Epoch: 36, Step: 300/655, Loss: 2.205529, Accuracy: 19.06%\n",
            "Epoch: 36, Step: 301/655, Loss: 2.205400, Accuracy: 19.04%\n",
            "Epoch: 36, Step: 302/655, Loss: 2.205516, Accuracy: 19.05%\n",
            "Epoch: 36, Step: 303/655, Loss: 2.205456, Accuracy: 19.08%\n",
            "Epoch: 36, Step: 304/655, Loss: 2.205310, Accuracy: 19.10%\n",
            "Epoch: 36, Step: 305/655, Loss: 2.205122, Accuracy: 19.12%\n",
            "Epoch: 36, Step: 306/655, Loss: 2.204861, Accuracy: 19.11%\n",
            "Epoch: 36, Step: 307/655, Loss: 2.204846, Accuracy: 19.11%\n",
            "Epoch: 36, Step: 308/655, Loss: 2.204699, Accuracy: 19.08%\n",
            "Epoch: 36, Step: 309/655, Loss: 2.205184, Accuracy: 19.06%\n",
            "Epoch: 36, Step: 310/655, Loss: 2.205285, Accuracy: 19.07%\n",
            "Epoch: 36, Step: 311/655, Loss: 2.205053, Accuracy: 19.06%\n",
            "Epoch: 36, Step: 312/655, Loss: 2.205376, Accuracy: 19.06%\n",
            "Epoch: 36, Step: 313/655, Loss: 2.205545, Accuracy: 19.03%\n",
            "Epoch: 36, Step: 314/655, Loss: 2.205229, Accuracy: 19.04%\n",
            "Epoch: 36, Step: 315/655, Loss: 2.205137, Accuracy: 19.03%\n",
            "Epoch: 36, Step: 316/655, Loss: 2.205129, Accuracy: 19.00%\n",
            "Epoch: 36, Step: 317/655, Loss: 2.205127, Accuracy: 18.99%\n",
            "Epoch: 36, Step: 318/655, Loss: 2.204948, Accuracy: 18.98%\n",
            "Epoch: 36, Step: 319/655, Loss: 2.204737, Accuracy: 18.99%\n",
            "Epoch: 36, Step: 320/655, Loss: 2.204699, Accuracy: 19.00%\n",
            "Epoch: 36, Step: 321/655, Loss: 2.204591, Accuracy: 19.02%\n",
            "Epoch: 36, Step: 322/655, Loss: 2.204660, Accuracy: 19.02%\n",
            "Epoch: 36, Step: 323/655, Loss: 2.204880, Accuracy: 19.00%\n",
            "Epoch: 36, Step: 324/655, Loss: 2.204621, Accuracy: 18.98%\n",
            "Epoch: 36, Step: 325/655, Loss: 2.204671, Accuracy: 18.97%\n",
            "Epoch: 36, Step: 326/655, Loss: 2.204321, Accuracy: 18.98%\n",
            "Epoch: 36, Step: 327/655, Loss: 2.204411, Accuracy: 18.97%\n",
            "Epoch: 36, Step: 328/655, Loss: 2.204661, Accuracy: 18.99%\n",
            "Epoch: 36, Step: 329/655, Loss: 2.204769, Accuracy: 19.00%\n",
            "Epoch: 36, Step: 330/655, Loss: 2.204270, Accuracy: 19.01%\n",
            "Epoch: 36, Step: 331/655, Loss: 2.204439, Accuracy: 19.00%\n",
            "Epoch: 36, Step: 332/655, Loss: 2.204629, Accuracy: 18.99%\n",
            "Epoch: 36, Step: 333/655, Loss: 2.205000, Accuracy: 18.97%\n",
            "Epoch: 36, Step: 334/655, Loss: 2.204803, Accuracy: 18.97%\n",
            "Epoch: 36, Step: 335/655, Loss: 2.204828, Accuracy: 18.99%\n",
            "Epoch: 36, Step: 336/655, Loss: 2.204770, Accuracy: 18.99%\n",
            "Epoch: 36, Step: 337/655, Loss: 2.204571, Accuracy: 19.02%\n",
            "Epoch: 36, Step: 338/655, Loss: 2.204735, Accuracy: 19.02%\n",
            "Epoch: 36, Step: 339/655, Loss: 2.204610, Accuracy: 19.04%\n",
            "Epoch: 36, Step: 340/655, Loss: 2.204555, Accuracy: 19.02%\n",
            "Epoch: 36, Step: 341/655, Loss: 2.204694, Accuracy: 19.01%\n",
            "Epoch: 36, Step: 342/655, Loss: 2.204655, Accuracy: 19.01%\n",
            "Epoch: 36, Step: 343/655, Loss: 2.204769, Accuracy: 19.02%\n",
            "Epoch: 36, Step: 344/655, Loss: 2.204956, Accuracy: 19.00%\n",
            "Epoch: 36, Step: 345/655, Loss: 2.205027, Accuracy: 18.99%\n",
            "Epoch: 36, Step: 346/655, Loss: 2.204904, Accuracy: 18.99%\n",
            "Epoch: 36, Step: 347/655, Loss: 2.205248, Accuracy: 18.99%\n",
            "Epoch: 36, Step: 348/655, Loss: 2.205228, Accuracy: 18.98%\n",
            "Epoch: 36, Step: 349/655, Loss: 2.205326, Accuracy: 18.96%\n",
            "Epoch: 36, Step: 350/655, Loss: 2.205579, Accuracy: 18.96%\n",
            "Epoch: 36, Step: 351/655, Loss: 2.205504, Accuracy: 18.95%\n",
            "Epoch: 36, Step: 352/655, Loss: 2.205344, Accuracy: 18.96%\n",
            "Epoch: 36, Step: 353/655, Loss: 2.205727, Accuracy: 18.94%\n",
            "Epoch: 36, Step: 354/655, Loss: 2.205892, Accuracy: 18.92%\n",
            "Epoch: 36, Step: 355/655, Loss: 2.205850, Accuracy: 18.88%\n",
            "Epoch: 36, Step: 356/655, Loss: 2.205931, Accuracy: 18.88%\n",
            "Epoch: 36, Step: 357/655, Loss: 2.206131, Accuracy: 18.86%\n",
            "Epoch: 36, Step: 358/655, Loss: 2.205851, Accuracy: 18.87%\n",
            "Epoch: 36, Step: 359/655, Loss: 2.205551, Accuracy: 18.88%\n",
            "Epoch: 36, Step: 360/655, Loss: 2.205432, Accuracy: 18.89%\n",
            "Epoch: 36, Step: 361/655, Loss: 2.205349, Accuracy: 18.88%\n",
            "Epoch: 36, Step: 362/655, Loss: 2.205539, Accuracy: 18.89%\n",
            "Epoch: 36, Step: 363/655, Loss: 2.205505, Accuracy: 18.89%\n",
            "Epoch: 36, Step: 364/655, Loss: 2.205898, Accuracy: 18.84%\n",
            "Epoch: 36, Step: 365/655, Loss: 2.205760, Accuracy: 18.85%\n",
            "Epoch: 36, Step: 366/655, Loss: 2.205897, Accuracy: 18.87%\n",
            "Epoch: 36, Step: 367/655, Loss: 2.205835, Accuracy: 18.87%\n",
            "Epoch: 36, Step: 368/655, Loss: 2.205832, Accuracy: 18.88%\n",
            "Epoch: 36, Step: 369/655, Loss: 2.205533, Accuracy: 18.89%\n",
            "Epoch: 36, Step: 370/655, Loss: 2.205383, Accuracy: 18.88%\n",
            "Epoch: 36, Step: 371/655, Loss: 2.205437, Accuracy: 18.86%\n",
            "Epoch: 36, Step: 372/655, Loss: 2.205247, Accuracy: 18.89%\n",
            "Epoch: 36, Step: 373/655, Loss: 2.205480, Accuracy: 18.89%\n",
            "Epoch: 36, Step: 374/655, Loss: 2.205380, Accuracy: 18.92%\n",
            "Epoch: 36, Step: 375/655, Loss: 2.205452, Accuracy: 18.93%\n",
            "Epoch: 36, Step: 376/655, Loss: 2.205317, Accuracy: 18.94%\n",
            "Epoch: 36, Step: 377/655, Loss: 2.205366, Accuracy: 18.93%\n",
            "Epoch: 36, Step: 378/655, Loss: 2.205485, Accuracy: 18.94%\n",
            "Epoch: 36, Step: 379/655, Loss: 2.205454, Accuracy: 18.92%\n",
            "Epoch: 36, Step: 380/655, Loss: 2.205762, Accuracy: 18.88%\n",
            "Epoch: 36, Step: 381/655, Loss: 2.205621, Accuracy: 18.89%\n",
            "Epoch: 36, Step: 382/655, Loss: 2.205205, Accuracy: 18.93%\n",
            "Epoch: 36, Step: 383/655, Loss: 2.205378, Accuracy: 18.91%\n",
            "Epoch: 36, Step: 384/655, Loss: 2.205470, Accuracy: 18.93%\n",
            "Epoch: 36, Step: 385/655, Loss: 2.205332, Accuracy: 18.93%\n",
            "Epoch: 36, Step: 386/655, Loss: 2.205672, Accuracy: 18.91%\n",
            "Epoch: 36, Step: 387/655, Loss: 2.205769, Accuracy: 18.92%\n",
            "Epoch: 36, Step: 388/655, Loss: 2.205737, Accuracy: 18.92%\n",
            "Epoch: 36, Step: 389/655, Loss: 2.205781, Accuracy: 18.93%\n",
            "Epoch: 36, Step: 390/655, Loss: 2.205946, Accuracy: 18.89%\n",
            "Epoch: 36, Step: 391/655, Loss: 2.205804, Accuracy: 18.89%\n",
            "Epoch: 36, Step: 392/655, Loss: 2.205626, Accuracy: 18.88%\n",
            "Epoch: 36, Step: 393/655, Loss: 2.205558, Accuracy: 18.87%\n",
            "Epoch: 36, Step: 394/655, Loss: 2.205756, Accuracy: 18.86%\n",
            "Epoch: 36, Step: 395/655, Loss: 2.206060, Accuracy: 18.83%\n",
            "Epoch: 36, Step: 396/655, Loss: 2.206552, Accuracy: 18.79%\n",
            "Epoch: 36, Step: 397/655, Loss: 2.206691, Accuracy: 18.79%\n",
            "Epoch: 36, Step: 398/655, Loss: 2.207173, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 399/655, Loss: 2.207207, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 400/655, Loss: 2.207495, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 401/655, Loss: 2.207307, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 402/655, Loss: 2.207441, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 403/655, Loss: 2.207475, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 404/655, Loss: 2.207245, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 405/655, Loss: 2.207040, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 406/655, Loss: 2.206987, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 407/655, Loss: 2.206784, Accuracy: 18.75%\n",
            "Epoch: 36, Step: 408/655, Loss: 2.206803, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 409/655, Loss: 2.206597, Accuracy: 18.75%\n",
            "Epoch: 36, Step: 410/655, Loss: 2.206356, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 411/655, Loss: 2.206383, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 412/655, Loss: 2.206472, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 413/655, Loss: 2.206354, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 414/655, Loss: 2.206400, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 415/655, Loss: 2.206148, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 416/655, Loss: 2.206468, Accuracy: 18.75%\n",
            "Epoch: 36, Step: 417/655, Loss: 2.206331, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 418/655, Loss: 2.206403, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 419/655, Loss: 2.206509, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 420/655, Loss: 2.206454, Accuracy: 18.75%\n",
            "Epoch: 36, Step: 421/655, Loss: 2.206616, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 422/655, Loss: 2.206940, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 423/655, Loss: 2.207178, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 424/655, Loss: 2.206937, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 425/655, Loss: 2.206991, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 426/655, Loss: 2.206977, Accuracy: 18.75%\n",
            "Epoch: 36, Step: 427/655, Loss: 2.207138, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 428/655, Loss: 2.206721, Accuracy: 18.79%\n",
            "Epoch: 36, Step: 429/655, Loss: 2.206610, Accuracy: 18.81%\n",
            "Epoch: 36, Step: 430/655, Loss: 2.206311, Accuracy: 18.83%\n",
            "Epoch: 36, Step: 431/655, Loss: 2.206328, Accuracy: 18.82%\n",
            "Epoch: 36, Step: 432/655, Loss: 2.206005, Accuracy: 18.84%\n",
            "Epoch: 36, Step: 433/655, Loss: 2.206041, Accuracy: 18.82%\n",
            "Epoch: 36, Step: 434/655, Loss: 2.206075, Accuracy: 18.81%\n",
            "Epoch: 36, Step: 435/655, Loss: 2.206244, Accuracy: 18.81%\n",
            "Epoch: 36, Step: 436/655, Loss: 2.206467, Accuracy: 18.81%\n",
            "Epoch: 36, Step: 437/655, Loss: 2.206669, Accuracy: 18.81%\n",
            "Epoch: 36, Step: 438/655, Loss: 2.206429, Accuracy: 18.79%\n",
            "Epoch: 36, Step: 439/655, Loss: 2.206469, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 440/655, Loss: 2.206439, Accuracy: 18.80%\n",
            "Epoch: 36, Step: 441/655, Loss: 2.206362, Accuracy: 18.79%\n",
            "Epoch: 36, Step: 442/655, Loss: 2.206463, Accuracy: 18.78%\n",
            "Epoch: 36, Step: 443/655, Loss: 2.206256, Accuracy: 18.78%\n",
            "Epoch: 36, Step: 444/655, Loss: 2.206283, Accuracy: 18.79%\n",
            "Epoch: 36, Step: 445/655, Loss: 2.206152, Accuracy: 18.81%\n",
            "Epoch: 36, Step: 446/655, Loss: 2.205975, Accuracy: 18.84%\n",
            "Epoch: 36, Step: 447/655, Loss: 2.205856, Accuracy: 18.85%\n",
            "Epoch: 36, Step: 448/655, Loss: 2.206080, Accuracy: 18.83%\n",
            "Epoch: 36, Step: 449/655, Loss: 2.205999, Accuracy: 18.81%\n",
            "Epoch: 36, Step: 450/655, Loss: 2.206126, Accuracy: 18.83%\n",
            "Epoch: 36, Step: 451/655, Loss: 2.205905, Accuracy: 18.83%\n",
            "Epoch: 36, Step: 452/655, Loss: 2.205775, Accuracy: 18.83%\n",
            "Epoch: 36, Step: 453/655, Loss: 2.205628, Accuracy: 18.85%\n",
            "Epoch: 36, Step: 454/655, Loss: 2.205735, Accuracy: 18.85%\n",
            "Epoch: 36, Step: 455/655, Loss: 2.205710, Accuracy: 18.84%\n",
            "Epoch: 36, Step: 456/655, Loss: 2.205677, Accuracy: 18.84%\n",
            "Epoch: 36, Step: 457/655, Loss: 2.205726, Accuracy: 18.83%\n",
            "Epoch: 36, Step: 458/655, Loss: 2.205910, Accuracy: 18.82%\n",
            "Epoch: 36, Step: 459/655, Loss: 2.206040, Accuracy: 18.82%\n",
            "Epoch: 36, Step: 460/655, Loss: 2.206155, Accuracy: 18.80%\n",
            "Epoch: 36, Step: 461/655, Loss: 2.206185, Accuracy: 18.78%\n",
            "Epoch: 36, Step: 462/655, Loss: 2.206146, Accuracy: 18.78%\n",
            "Epoch: 36, Step: 463/655, Loss: 2.206235, Accuracy: 18.78%\n",
            "Epoch: 36, Step: 464/655, Loss: 2.206218, Accuracy: 18.78%\n",
            "Epoch: 36, Step: 465/655, Loss: 2.206059, Accuracy: 18.78%\n",
            "Epoch: 36, Step: 466/655, Loss: 2.206276, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 467/655, Loss: 2.206445, Accuracy: 18.75%\n",
            "Epoch: 36, Step: 468/655, Loss: 2.206539, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 469/655, Loss: 2.206536, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 470/655, Loss: 2.206718, Accuracy: 18.69%\n",
            "Epoch: 36, Step: 471/655, Loss: 2.206429, Accuracy: 18.68%\n",
            "Epoch: 36, Step: 472/655, Loss: 2.206408, Accuracy: 18.68%\n",
            "Epoch: 36, Step: 473/655, Loss: 2.206345, Accuracy: 18.68%\n",
            "Epoch: 36, Step: 474/655, Loss: 2.206261, Accuracy: 18.67%\n",
            "Epoch: 36, Step: 475/655, Loss: 2.206112, Accuracy: 18.68%\n",
            "Epoch: 36, Step: 476/655, Loss: 2.206440, Accuracy: 18.68%\n",
            "Epoch: 36, Step: 477/655, Loss: 2.206506, Accuracy: 18.66%\n",
            "Epoch: 36, Step: 478/655, Loss: 2.206592, Accuracy: 18.67%\n",
            "Epoch: 36, Step: 479/655, Loss: 2.206375, Accuracy: 18.67%\n",
            "Epoch: 36, Step: 480/655, Loss: 2.206357, Accuracy: 18.68%\n",
            "Epoch: 36, Step: 481/655, Loss: 2.206377, Accuracy: 18.65%\n",
            "Epoch: 36, Step: 482/655, Loss: 2.206184, Accuracy: 18.67%\n",
            "Epoch: 36, Step: 483/655, Loss: 2.206244, Accuracy: 18.65%\n",
            "Epoch: 36, Step: 484/655, Loss: 2.206103, Accuracy: 18.66%\n",
            "Epoch: 36, Step: 485/655, Loss: 2.205969, Accuracy: 18.68%\n",
            "Epoch: 36, Step: 486/655, Loss: 2.205749, Accuracy: 18.69%\n",
            "Epoch: 36, Step: 487/655, Loss: 2.205675, Accuracy: 18.70%\n",
            "Epoch: 36, Step: 488/655, Loss: 2.205462, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 489/655, Loss: 2.205399, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 490/655, Loss: 2.205750, Accuracy: 18.69%\n",
            "Epoch: 36, Step: 491/655, Loss: 2.205599, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 492/655, Loss: 2.205322, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 493/655, Loss: 2.205329, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 494/655, Loss: 2.205432, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 495/655, Loss: 2.205631, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 496/655, Loss: 2.205596, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 497/655, Loss: 2.205381, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 498/655, Loss: 2.205163, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 499/655, Loss: 2.204938, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 500/655, Loss: 2.204866, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 501/655, Loss: 2.204981, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 502/655, Loss: 2.204976, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 503/655, Loss: 2.205055, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 504/655, Loss: 2.204923, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 505/655, Loss: 2.204895, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 506/655, Loss: 2.204850, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 507/655, Loss: 2.204831, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 508/655, Loss: 2.205050, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 509/655, Loss: 2.205167, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 510/655, Loss: 2.205036, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 511/655, Loss: 2.204910, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 512/655, Loss: 2.204927, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 513/655, Loss: 2.205322, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 514/655, Loss: 2.205240, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 515/655, Loss: 2.205205, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 516/655, Loss: 2.205265, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 517/655, Loss: 2.205235, Accuracy: 18.70%\n",
            "Epoch: 36, Step: 518/655, Loss: 2.205519, Accuracy: 18.68%\n",
            "Epoch: 36, Step: 519/655, Loss: 2.205500, Accuracy: 18.68%\n",
            "Epoch: 36, Step: 520/655, Loss: 2.205354, Accuracy: 18.70%\n",
            "Epoch: 36, Step: 521/655, Loss: 2.205543, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 522/655, Loss: 2.205684, Accuracy: 18.69%\n",
            "Epoch: 36, Step: 523/655, Loss: 2.205421, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 524/655, Loss: 2.205537, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 525/655, Loss: 2.205405, Accuracy: 18.75%\n",
            "Epoch: 36, Step: 526/655, Loss: 2.205262, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 527/655, Loss: 2.205423, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 528/655, Loss: 2.205380, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 529/655, Loss: 2.205279, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 530/655, Loss: 2.205319, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 531/655, Loss: 2.205144, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 532/655, Loss: 2.205154, Accuracy: 18.79%\n",
            "Epoch: 36, Step: 533/655, Loss: 2.204998, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 534/655, Loss: 2.204952, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 535/655, Loss: 2.205175, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 536/655, Loss: 2.205171, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 537/655, Loss: 2.205189, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 538/655, Loss: 2.205366, Accuracy: 18.78%\n",
            "Epoch: 36, Step: 539/655, Loss: 2.205513, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 540/655, Loss: 2.205577, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 541/655, Loss: 2.205483, Accuracy: 18.78%\n",
            "Epoch: 36, Step: 542/655, Loss: 2.205398, Accuracy: 18.78%\n",
            "Epoch: 36, Step: 543/655, Loss: 2.205466, Accuracy: 18.79%\n",
            "Epoch: 36, Step: 544/655, Loss: 2.205320, Accuracy: 18.80%\n",
            "Epoch: 36, Step: 545/655, Loss: 2.205308, Accuracy: 18.80%\n",
            "Epoch: 36, Step: 546/655, Loss: 2.205183, Accuracy: 18.80%\n",
            "Epoch: 36, Step: 547/655, Loss: 2.205160, Accuracy: 18.81%\n",
            "Epoch: 36, Step: 548/655, Loss: 2.205069, Accuracy: 18.81%\n",
            "Epoch: 36, Step: 549/655, Loss: 2.205277, Accuracy: 18.81%\n",
            "Epoch: 36, Step: 550/655, Loss: 2.205199, Accuracy: 18.83%\n",
            "Epoch: 36, Step: 551/655, Loss: 2.205017, Accuracy: 18.83%\n",
            "Epoch: 36, Step: 552/655, Loss: 2.205179, Accuracy: 18.82%\n",
            "Epoch: 36, Step: 553/655, Loss: 2.205234, Accuracy: 18.82%\n",
            "Epoch: 36, Step: 554/655, Loss: 2.205264, Accuracy: 18.82%\n",
            "Epoch: 36, Step: 555/655, Loss: 2.205151, Accuracy: 18.82%\n",
            "Epoch: 36, Step: 556/655, Loss: 2.205132, Accuracy: 18.82%\n",
            "Epoch: 36, Step: 557/655, Loss: 2.205260, Accuracy: 18.81%\n",
            "Epoch: 36, Step: 558/655, Loss: 2.205213, Accuracy: 18.81%\n",
            "Epoch: 36, Step: 559/655, Loss: 2.205221, Accuracy: 18.82%\n",
            "Epoch: 36, Step: 560/655, Loss: 2.205244, Accuracy: 18.81%\n",
            "Epoch: 36, Step: 561/655, Loss: 2.205258, Accuracy: 18.82%\n",
            "Epoch: 36, Step: 562/655, Loss: 2.205447, Accuracy: 18.81%\n",
            "Epoch: 36, Step: 563/655, Loss: 2.205692, Accuracy: 18.79%\n",
            "Epoch: 36, Step: 564/655, Loss: 2.205427, Accuracy: 18.80%\n",
            "Epoch: 36, Step: 565/655, Loss: 2.205634, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 566/655, Loss: 2.205402, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 567/655, Loss: 2.205315, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 568/655, Loss: 2.205270, Accuracy: 18.78%\n",
            "Epoch: 36, Step: 569/655, Loss: 2.205414, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 570/655, Loss: 2.205284, Accuracy: 18.79%\n",
            "Epoch: 36, Step: 571/655, Loss: 2.205562, Accuracy: 18.78%\n",
            "Epoch: 36, Step: 572/655, Loss: 2.205796, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 573/655, Loss: 2.205662, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 574/655, Loss: 2.205627, Accuracy: 18.77%\n",
            "Epoch: 36, Step: 575/655, Loss: 2.205797, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 576/655, Loss: 2.205670, Accuracy: 18.76%\n",
            "Epoch: 36, Step: 577/655, Loss: 2.205802, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 578/655, Loss: 2.205707, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 579/655, Loss: 2.205760, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 580/655, Loss: 2.205844, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 581/655, Loss: 2.205947, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 582/655, Loss: 2.206203, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 583/655, Loss: 2.206163, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 584/655, Loss: 2.206366, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 585/655, Loss: 2.206480, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 586/655, Loss: 2.206524, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 587/655, Loss: 2.206346, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 588/655, Loss: 2.206463, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 589/655, Loss: 2.206300, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 590/655, Loss: 2.206321, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 591/655, Loss: 2.206460, Accuracy: 18.69%\n",
            "Epoch: 36, Step: 592/655, Loss: 2.206501, Accuracy: 18.70%\n",
            "Epoch: 36, Step: 593/655, Loss: 2.206421, Accuracy: 18.69%\n",
            "Epoch: 36, Step: 594/655, Loss: 2.206431, Accuracy: 18.69%\n",
            "Epoch: 36, Step: 595/655, Loss: 2.206460, Accuracy: 18.70%\n",
            "Epoch: 36, Step: 596/655, Loss: 2.206660, Accuracy: 18.70%\n",
            "Epoch: 36, Step: 597/655, Loss: 2.206664, Accuracy: 18.70%\n",
            "Epoch: 36, Step: 598/655, Loss: 2.206611, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 599/655, Loss: 2.206430, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 600/655, Loss: 2.206572, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 601/655, Loss: 2.206597, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 602/655, Loss: 2.206881, Accuracy: 18.70%\n",
            "Epoch: 36, Step: 603/655, Loss: 2.206984, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 604/655, Loss: 2.207017, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 605/655, Loss: 2.206973, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 606/655, Loss: 2.206928, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 607/655, Loss: 2.206854, Accuracy: 18.74%\n",
            "Epoch: 36, Step: 608/655, Loss: 2.206721, Accuracy: 18.75%\n",
            "Epoch: 36, Step: 609/655, Loss: 2.206880, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 610/655, Loss: 2.207080, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 611/655, Loss: 2.207191, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 612/655, Loss: 2.207098, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 613/655, Loss: 2.207149, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 614/655, Loss: 2.207002, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 615/655, Loss: 2.206799, Accuracy: 18.73%\n",
            "Epoch: 36, Step: 616/655, Loss: 2.207040, Accuracy: 18.72%\n",
            "Epoch: 36, Step: 617/655, Loss: 2.207070, Accuracy: 18.71%\n",
            "Epoch: 36, Step: 618/655, Loss: 2.207151, Accuracy: 18.70%\n",
            "Epoch: 36, Step: 619/655, Loss: 2.207087, Accuracy: 18.68%\n",
            "Epoch: 36, Step: 620/655, Loss: 2.207126, Accuracy: 18.67%\n",
            "Epoch: 36, Step: 621/655, Loss: 2.207131, Accuracy: 18.67%\n",
            "Epoch: 36, Step: 622/655, Loss: 2.207229, Accuracy: 18.66%\n",
            "Epoch: 36, Step: 623/655, Loss: 2.206913, Accuracy: 18.68%\n",
            "Epoch: 36, Step: 624/655, Loss: 2.206841, Accuracy: 18.67%\n",
            "Epoch: 36, Step: 625/655, Loss: 2.206809, Accuracy: 18.66%\n",
            "Epoch: 36, Step: 626/655, Loss: 2.206995, Accuracy: 18.65%\n",
            "Epoch: 36, Step: 627/655, Loss: 2.207074, Accuracy: 18.64%\n",
            "Epoch: 36, Step: 628/655, Loss: 2.207211, Accuracy: 18.63%\n",
            "Epoch: 36, Step: 629/655, Loss: 2.207153, Accuracy: 18.62%\n",
            "Epoch: 36, Step: 630/655, Loss: 2.207068, Accuracy: 18.62%\n",
            "Epoch: 36, Step: 631/655, Loss: 2.207147, Accuracy: 18.61%\n",
            "Epoch: 36, Step: 632/655, Loss: 2.207334, Accuracy: 18.60%\n",
            "Epoch: 36, Step: 633/655, Loss: 2.207276, Accuracy: 18.61%\n",
            "Epoch: 36, Step: 634/655, Loss: 2.207486, Accuracy: 18.59%\n",
            "Epoch: 36, Step: 635/655, Loss: 2.207660, Accuracy: 18.57%\n",
            "Epoch: 36, Step: 636/655, Loss: 2.207819, Accuracy: 18.54%\n",
            "Epoch: 36, Step: 637/655, Loss: 2.207634, Accuracy: 18.54%\n",
            "Epoch: 36, Step: 638/655, Loss: 2.207659, Accuracy: 18.54%\n",
            "Epoch: 36, Step: 639/655, Loss: 2.207669, Accuracy: 18.55%\n",
            "Epoch: 36, Step: 640/655, Loss: 2.207669, Accuracy: 18.54%\n",
            "Epoch: 36, Step: 641/655, Loss: 2.207610, Accuracy: 18.54%\n",
            "Epoch: 36, Step: 642/655, Loss: 2.207632, Accuracy: 18.53%\n",
            "Epoch: 36, Step: 643/655, Loss: 2.207548, Accuracy: 18.52%\n",
            "Epoch: 36, Step: 644/655, Loss: 2.207728, Accuracy: 18.51%\n",
            "Epoch: 36, Step: 645/655, Loss: 2.207868, Accuracy: 18.49%\n",
            "Epoch: 36, Step: 646/655, Loss: 2.207903, Accuracy: 18.47%\n",
            "Epoch: 36, Step: 647/655, Loss: 2.207866, Accuracy: 18.47%\n",
            "Epoch: 36, Step: 648/655, Loss: 2.207954, Accuracy: 18.46%\n",
            "Epoch: 36, Step: 649/655, Loss: 2.207794, Accuracy: 18.46%\n",
            "Epoch: 36, Step: 650/655, Loss: 2.207555, Accuracy: 18.48%\n",
            "Epoch: 36, Step: 651/655, Loss: 2.207695, Accuracy: 18.49%\n",
            "Epoch: 36, Step: 652/655, Loss: 2.207754, Accuracy: 18.48%\n",
            "Epoch: 36, Step: 653/655, Loss: 2.207691, Accuracy: 18.49%\n",
            "Epoch: 36, Step: 654/655, Loss: 2.207538, Accuracy: 18.50%\n",
            "Epoch: 36, Step: 655/655, Loss: 2.207573, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 1/655, Loss: 2.312416, Accuracy: 9.38%\n",
            "Epoch: 37, Step: 2/655, Loss: 2.181902, Accuracy: 18.75%\n",
            "Epoch: 37, Step: 3/655, Loss: 2.255838, Accuracy: 15.62%\n",
            "Epoch: 37, Step: 4/655, Loss: 2.236513, Accuracy: 16.41%\n",
            "Epoch: 37, Step: 5/655, Loss: 2.213465, Accuracy: 16.88%\n",
            "Epoch: 37, Step: 6/655, Loss: 2.212351, Accuracy: 18.23%\n",
            "Epoch: 37, Step: 7/655, Loss: 2.246042, Accuracy: 16.07%\n",
            "Epoch: 37, Step: 8/655, Loss: 2.241979, Accuracy: 14.84%\n",
            "Epoch: 37, Step: 9/655, Loss: 2.221773, Accuracy: 16.32%\n",
            "Epoch: 37, Step: 10/655, Loss: 2.214525, Accuracy: 16.88%\n",
            "Epoch: 37, Step: 11/655, Loss: 2.206772, Accuracy: 17.33%\n",
            "Epoch: 37, Step: 12/655, Loss: 2.203077, Accuracy: 16.67%\n",
            "Epoch: 37, Step: 13/655, Loss: 2.196424, Accuracy: 17.07%\n",
            "Epoch: 37, Step: 14/655, Loss: 2.203074, Accuracy: 16.74%\n",
            "Epoch: 37, Step: 15/655, Loss: 2.212684, Accuracy: 16.25%\n",
            "Epoch: 37, Step: 16/655, Loss: 2.204819, Accuracy: 17.19%\n",
            "Epoch: 37, Step: 17/655, Loss: 2.210280, Accuracy: 16.54%\n",
            "Epoch: 37, Step: 18/655, Loss: 2.214276, Accuracy: 16.32%\n",
            "Epoch: 37, Step: 19/655, Loss: 2.211051, Accuracy: 16.78%\n",
            "Epoch: 37, Step: 20/655, Loss: 2.214844, Accuracy: 16.72%\n",
            "Epoch: 37, Step: 21/655, Loss: 2.218474, Accuracy: 16.67%\n",
            "Epoch: 37, Step: 22/655, Loss: 2.220627, Accuracy: 16.62%\n",
            "Epoch: 37, Step: 23/655, Loss: 2.221568, Accuracy: 16.58%\n",
            "Epoch: 37, Step: 24/655, Loss: 2.216778, Accuracy: 17.06%\n",
            "Epoch: 37, Step: 25/655, Loss: 2.216084, Accuracy: 16.75%\n",
            "Epoch: 37, Step: 26/655, Loss: 2.212227, Accuracy: 16.95%\n",
            "Epoch: 37, Step: 27/655, Loss: 2.214696, Accuracy: 16.78%\n",
            "Epoch: 37, Step: 28/655, Loss: 2.207450, Accuracy: 17.41%\n",
            "Epoch: 37, Step: 29/655, Loss: 2.210729, Accuracy: 17.03%\n",
            "Epoch: 37, Step: 30/655, Loss: 2.209668, Accuracy: 17.29%\n",
            "Epoch: 37, Step: 31/655, Loss: 2.204500, Accuracy: 18.15%\n",
            "Epoch: 37, Step: 32/655, Loss: 2.205741, Accuracy: 18.07%\n",
            "Epoch: 37, Step: 33/655, Loss: 2.203420, Accuracy: 18.37%\n",
            "Epoch: 37, Step: 34/655, Loss: 2.205155, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 35/655, Loss: 2.205549, Accuracy: 18.12%\n",
            "Epoch: 37, Step: 36/655, Loss: 2.204413, Accuracy: 18.06%\n",
            "Epoch: 37, Step: 37/655, Loss: 2.202236, Accuracy: 18.33%\n",
            "Epoch: 37, Step: 38/655, Loss: 2.198852, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 39/655, Loss: 2.200359, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 40/655, Loss: 2.202187, Accuracy: 18.20%\n",
            "Epoch: 37, Step: 41/655, Loss: 2.201462, Accuracy: 18.52%\n",
            "Epoch: 37, Step: 42/655, Loss: 2.201993, Accuracy: 18.53%\n",
            "Epoch: 37, Step: 43/655, Loss: 2.202954, Accuracy: 18.46%\n",
            "Epoch: 37, Step: 44/655, Loss: 2.201614, Accuracy: 18.54%\n",
            "Epoch: 37, Step: 45/655, Loss: 2.200304, Accuracy: 18.75%\n",
            "Epoch: 37, Step: 46/655, Loss: 2.199900, Accuracy: 18.68%\n",
            "Epoch: 37, Step: 47/655, Loss: 2.198496, Accuracy: 19.02%\n",
            "Epoch: 37, Step: 48/655, Loss: 2.194214, Accuracy: 19.40%\n",
            "Epoch: 37, Step: 49/655, Loss: 2.193380, Accuracy: 19.45%\n",
            "Epoch: 37, Step: 50/655, Loss: 2.190735, Accuracy: 19.69%\n",
            "Epoch: 37, Step: 51/655, Loss: 2.191898, Accuracy: 19.67%\n",
            "Epoch: 37, Step: 52/655, Loss: 2.192100, Accuracy: 19.65%\n",
            "Epoch: 37, Step: 53/655, Loss: 2.190324, Accuracy: 19.63%\n",
            "Epoch: 37, Step: 54/655, Loss: 2.192340, Accuracy: 19.50%\n",
            "Epoch: 37, Step: 55/655, Loss: 2.192350, Accuracy: 19.38%\n",
            "Epoch: 37, Step: 56/655, Loss: 2.193763, Accuracy: 19.25%\n",
            "Epoch: 37, Step: 57/655, Loss: 2.195357, Accuracy: 19.02%\n",
            "Epoch: 37, Step: 58/655, Loss: 2.194568, Accuracy: 18.86%\n",
            "Epoch: 37, Step: 59/655, Loss: 2.195274, Accuracy: 18.86%\n",
            "Epoch: 37, Step: 60/655, Loss: 2.194782, Accuracy: 18.80%\n",
            "Epoch: 37, Step: 61/655, Loss: 2.192612, Accuracy: 18.90%\n",
            "Epoch: 37, Step: 62/655, Loss: 2.192394, Accuracy: 18.95%\n",
            "Epoch: 37, Step: 63/655, Loss: 2.193750, Accuracy: 19.00%\n",
            "Epoch: 37, Step: 64/655, Loss: 2.192334, Accuracy: 18.99%\n",
            "Epoch: 37, Step: 65/655, Loss: 2.192056, Accuracy: 18.99%\n",
            "Epoch: 37, Step: 66/655, Loss: 2.192869, Accuracy: 18.89%\n",
            "Epoch: 37, Step: 67/655, Loss: 2.192283, Accuracy: 18.80%\n",
            "Epoch: 37, Step: 68/655, Loss: 2.194632, Accuracy: 18.66%\n",
            "Epoch: 37, Step: 69/655, Loss: 2.194148, Accuracy: 18.70%\n",
            "Epoch: 37, Step: 70/655, Loss: 2.194832, Accuracy: 18.57%\n",
            "Epoch: 37, Step: 71/655, Loss: 2.194573, Accuracy: 18.53%\n",
            "Epoch: 37, Step: 72/655, Loss: 2.194117, Accuracy: 18.45%\n",
            "Epoch: 37, Step: 73/655, Loss: 2.192953, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 74/655, Loss: 2.191770, Accuracy: 18.50%\n",
            "Epoch: 37, Step: 75/655, Loss: 2.193004, Accuracy: 18.42%\n",
            "Epoch: 37, Step: 76/655, Loss: 2.195064, Accuracy: 18.42%\n",
            "Epoch: 37, Step: 77/655, Loss: 2.196576, Accuracy: 18.38%\n",
            "Epoch: 37, Step: 78/655, Loss: 2.197897, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 79/655, Loss: 2.196931, Accuracy: 18.43%\n",
            "Epoch: 37, Step: 80/655, Loss: 2.198190, Accuracy: 18.32%\n",
            "Epoch: 37, Step: 81/655, Loss: 2.199487, Accuracy: 18.21%\n",
            "Epoch: 37, Step: 82/655, Loss: 2.199306, Accuracy: 18.18%\n",
            "Epoch: 37, Step: 83/655, Loss: 2.198044, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 84/655, Loss: 2.197944, Accuracy: 18.30%\n",
            "Epoch: 37, Step: 85/655, Loss: 2.198185, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 86/655, Loss: 2.199188, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 87/655, Loss: 2.198669, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 88/655, Loss: 2.199976, Accuracy: 18.18%\n",
            "Epoch: 37, Step: 89/655, Loss: 2.201457, Accuracy: 18.12%\n",
            "Epoch: 37, Step: 90/655, Loss: 2.201611, Accuracy: 18.02%\n",
            "Epoch: 37, Step: 91/655, Loss: 2.200999, Accuracy: 18.06%\n",
            "Epoch: 37, Step: 92/655, Loss: 2.200502, Accuracy: 18.17%\n",
            "Epoch: 37, Step: 93/655, Loss: 2.201458, Accuracy: 18.18%\n",
            "Epoch: 37, Step: 94/655, Loss: 2.201573, Accuracy: 18.12%\n",
            "Epoch: 37, Step: 95/655, Loss: 2.201516, Accuracy: 18.16%\n",
            "Epoch: 37, Step: 96/655, Loss: 2.202552, Accuracy: 18.07%\n",
            "Epoch: 37, Step: 97/655, Loss: 2.202716, Accuracy: 18.01%\n",
            "Epoch: 37, Step: 98/655, Loss: 2.202889, Accuracy: 18.05%\n",
            "Epoch: 37, Step: 99/655, Loss: 2.202740, Accuracy: 18.02%\n",
            "Epoch: 37, Step: 100/655, Loss: 2.202757, Accuracy: 18.06%\n",
            "Epoch: 37, Step: 101/655, Loss: 2.203093, Accuracy: 18.10%\n",
            "Epoch: 37, Step: 102/655, Loss: 2.201786, Accuracy: 18.14%\n",
            "Epoch: 37, Step: 103/655, Loss: 2.202371, Accuracy: 18.11%\n",
            "Epoch: 37, Step: 104/655, Loss: 2.203058, Accuracy: 18.09%\n",
            "Epoch: 37, Step: 105/655, Loss: 2.203590, Accuracy: 18.07%\n",
            "Epoch: 37, Step: 106/655, Loss: 2.203029, Accuracy: 18.07%\n",
            "Epoch: 37, Step: 107/655, Loss: 2.203378, Accuracy: 18.11%\n",
            "Epoch: 37, Step: 108/655, Loss: 2.202647, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 109/655, Loss: 2.203315, Accuracy: 18.21%\n",
            "Epoch: 37, Step: 110/655, Loss: 2.203668, Accuracy: 18.15%\n",
            "Epoch: 37, Step: 111/655, Loss: 2.203617, Accuracy: 18.19%\n",
            "Epoch: 37, Step: 112/655, Loss: 2.204351, Accuracy: 18.16%\n",
            "Epoch: 37, Step: 113/655, Loss: 2.204639, Accuracy: 18.17%\n",
            "Epoch: 37, Step: 114/655, Loss: 2.204991, Accuracy: 18.15%\n",
            "Epoch: 37, Step: 115/655, Loss: 2.204279, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 116/655, Loss: 2.203565, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 117/655, Loss: 2.204965, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 118/655, Loss: 2.205220, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 119/655, Loss: 2.205236, Accuracy: 18.30%\n",
            "Epoch: 37, Step: 120/655, Loss: 2.204621, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 121/655, Loss: 2.203157, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 122/655, Loss: 2.202857, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 123/655, Loss: 2.202964, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 124/655, Loss: 2.203411, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 125/655, Loss: 2.203887, Accuracy: 18.20%\n",
            "Epoch: 37, Step: 126/655, Loss: 2.203486, Accuracy: 18.23%\n",
            "Epoch: 37, Step: 127/655, Loss: 2.204584, Accuracy: 18.21%\n",
            "Epoch: 37, Step: 128/655, Loss: 2.204277, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 129/655, Loss: 2.203722, Accuracy: 18.31%\n",
            "Epoch: 37, Step: 130/655, Loss: 2.203487, Accuracy: 18.32%\n",
            "Epoch: 37, Step: 131/655, Loss: 2.204982, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 132/655, Loss: 2.205617, Accuracy: 18.21%\n",
            "Epoch: 37, Step: 133/655, Loss: 2.206202, Accuracy: 18.23%\n",
            "Epoch: 37, Step: 134/655, Loss: 2.205845, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 135/655, Loss: 2.204511, Accuracy: 18.40%\n",
            "Epoch: 37, Step: 136/655, Loss: 2.205334, Accuracy: 18.38%\n",
            "Epoch: 37, Step: 137/655, Loss: 2.205151, Accuracy: 18.36%\n",
            "Epoch: 37, Step: 138/655, Loss: 2.205573, Accuracy: 18.39%\n",
            "Epoch: 37, Step: 139/655, Loss: 2.206074, Accuracy: 18.32%\n",
            "Epoch: 37, Step: 140/655, Loss: 2.206147, Accuracy: 18.39%\n",
            "Epoch: 37, Step: 141/655, Loss: 2.206806, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 142/655, Loss: 2.206837, Accuracy: 18.38%\n",
            "Epoch: 37, Step: 143/655, Loss: 2.205767, Accuracy: 18.36%\n",
            "Epoch: 37, Step: 144/655, Loss: 2.205245, Accuracy: 18.42%\n",
            "Epoch: 37, Step: 145/655, Loss: 2.206249, Accuracy: 18.38%\n",
            "Epoch: 37, Step: 146/655, Loss: 2.206413, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 147/655, Loss: 2.206939, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 148/655, Loss: 2.206308, Accuracy: 18.39%\n",
            "Epoch: 37, Step: 149/655, Loss: 2.206798, Accuracy: 18.37%\n",
            "Epoch: 37, Step: 150/655, Loss: 2.205761, Accuracy: 18.44%\n",
            "Epoch: 37, Step: 151/655, Loss: 2.205570, Accuracy: 18.44%\n",
            "Epoch: 37, Step: 152/655, Loss: 2.205544, Accuracy: 18.42%\n",
            "Epoch: 37, Step: 153/655, Loss: 2.205220, Accuracy: 18.42%\n",
            "Epoch: 37, Step: 154/655, Loss: 2.205545, Accuracy: 18.38%\n",
            "Epoch: 37, Step: 155/655, Loss: 2.206138, Accuracy: 18.43%\n",
            "Epoch: 37, Step: 156/655, Loss: 2.206092, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 157/655, Loss: 2.206610, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 158/655, Loss: 2.206041, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 159/655, Loss: 2.206584, Accuracy: 18.46%\n",
            "Epoch: 37, Step: 160/655, Loss: 2.205671, Accuracy: 18.52%\n",
            "Epoch: 37, Step: 161/655, Loss: 2.206670, Accuracy: 18.50%\n",
            "Epoch: 37, Step: 162/655, Loss: 2.207162, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 163/655, Loss: 2.206661, Accuracy: 18.54%\n",
            "Epoch: 37, Step: 164/655, Loss: 2.206392, Accuracy: 18.54%\n",
            "Epoch: 37, Step: 165/655, Loss: 2.206768, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 166/655, Loss: 2.206019, Accuracy: 18.56%\n",
            "Epoch: 37, Step: 167/655, Loss: 2.205367, Accuracy: 18.60%\n",
            "Epoch: 37, Step: 168/655, Loss: 2.205174, Accuracy: 18.58%\n",
            "Epoch: 37, Step: 169/655, Loss: 2.204775, Accuracy: 18.64%\n",
            "Epoch: 37, Step: 170/655, Loss: 2.204850, Accuracy: 18.60%\n",
            "Epoch: 37, Step: 171/655, Loss: 2.205186, Accuracy: 18.59%\n",
            "Epoch: 37, Step: 172/655, Loss: 2.204960, Accuracy: 18.60%\n",
            "Epoch: 37, Step: 173/655, Loss: 2.204151, Accuracy: 18.64%\n",
            "Epoch: 37, Step: 174/655, Loss: 2.204485, Accuracy: 18.62%\n",
            "Epoch: 37, Step: 175/655, Loss: 2.204389, Accuracy: 18.64%\n",
            "Epoch: 37, Step: 176/655, Loss: 2.203920, Accuracy: 18.64%\n",
            "Epoch: 37, Step: 177/655, Loss: 2.203921, Accuracy: 18.63%\n",
            "Epoch: 37, Step: 178/655, Loss: 2.204293, Accuracy: 18.63%\n",
            "Epoch: 37, Step: 179/655, Loss: 2.204876, Accuracy: 18.56%\n",
            "Epoch: 37, Step: 180/655, Loss: 2.204637, Accuracy: 18.61%\n",
            "Epoch: 37, Step: 181/655, Loss: 2.205630, Accuracy: 18.56%\n",
            "Epoch: 37, Step: 182/655, Loss: 2.205584, Accuracy: 18.56%\n",
            "Epoch: 37, Step: 183/655, Loss: 2.205602, Accuracy: 18.56%\n",
            "Epoch: 37, Step: 184/655, Loss: 2.205746, Accuracy: 18.56%\n",
            "Epoch: 37, Step: 185/655, Loss: 2.205740, Accuracy: 18.60%\n",
            "Epoch: 37, Step: 186/655, Loss: 2.205787, Accuracy: 18.53%\n",
            "Epoch: 37, Step: 187/655, Loss: 2.206624, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 188/655, Loss: 2.206955, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 189/655, Loss: 2.207569, Accuracy: 18.45%\n",
            "Epoch: 37, Step: 190/655, Loss: 2.207362, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 191/655, Loss: 2.207553, Accuracy: 18.46%\n",
            "Epoch: 37, Step: 192/655, Loss: 2.207061, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 193/655, Loss: 2.206760, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 194/655, Loss: 2.207679, Accuracy: 18.41%\n",
            "Epoch: 37, Step: 195/655, Loss: 2.208041, Accuracy: 18.38%\n",
            "Epoch: 37, Step: 196/655, Loss: 2.207622, Accuracy: 18.40%\n",
            "Epoch: 37, Step: 197/655, Loss: 2.207296, Accuracy: 18.42%\n",
            "Epoch: 37, Step: 198/655, Loss: 2.207002, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 199/655, Loss: 2.206975, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 200/655, Loss: 2.206634, Accuracy: 18.53%\n",
            "Epoch: 37, Step: 201/655, Loss: 2.206270, Accuracy: 18.53%\n",
            "Epoch: 37, Step: 202/655, Loss: 2.205597, Accuracy: 18.60%\n",
            "Epoch: 37, Step: 203/655, Loss: 2.206234, Accuracy: 18.58%\n",
            "Epoch: 37, Step: 204/655, Loss: 2.205977, Accuracy: 18.66%\n",
            "Epoch: 37, Step: 205/655, Loss: 2.206196, Accuracy: 18.64%\n",
            "Epoch: 37, Step: 206/655, Loss: 2.206365, Accuracy: 18.63%\n",
            "Epoch: 37, Step: 207/655, Loss: 2.205701, Accuracy: 18.67%\n",
            "Epoch: 37, Step: 208/655, Loss: 2.205067, Accuracy: 18.72%\n",
            "Epoch: 37, Step: 209/655, Loss: 2.205604, Accuracy: 18.71%\n",
            "Epoch: 37, Step: 210/655, Loss: 2.205992, Accuracy: 18.69%\n",
            "Epoch: 37, Step: 211/655, Loss: 2.206738, Accuracy: 18.63%\n",
            "Epoch: 37, Step: 212/655, Loss: 2.206867, Accuracy: 18.63%\n",
            "Epoch: 37, Step: 213/655, Loss: 2.207981, Accuracy: 18.60%\n",
            "Epoch: 37, Step: 214/655, Loss: 2.207972, Accuracy: 18.57%\n",
            "Epoch: 37, Step: 215/655, Loss: 2.207632, Accuracy: 18.59%\n",
            "Epoch: 37, Step: 216/655, Loss: 2.207376, Accuracy: 18.63%\n",
            "Epoch: 37, Step: 217/655, Loss: 2.207570, Accuracy: 18.62%\n",
            "Epoch: 37, Step: 218/655, Loss: 2.207519, Accuracy: 18.61%\n",
            "Epoch: 37, Step: 219/655, Loss: 2.207530, Accuracy: 18.58%\n",
            "Epoch: 37, Step: 220/655, Loss: 2.207395, Accuracy: 18.54%\n",
            "Epoch: 37, Step: 221/655, Loss: 2.207107, Accuracy: 18.55%\n",
            "Epoch: 37, Step: 222/655, Loss: 2.206995, Accuracy: 18.57%\n",
            "Epoch: 37, Step: 223/655, Loss: 2.206886, Accuracy: 18.51%\n",
            "Epoch: 37, Step: 224/655, Loss: 2.206928, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 225/655, Loss: 2.207083, Accuracy: 18.44%\n",
            "Epoch: 37, Step: 226/655, Loss: 2.206859, Accuracy: 18.43%\n",
            "Epoch: 37, Step: 227/655, Loss: 2.206871, Accuracy: 18.43%\n",
            "Epoch: 37, Step: 228/655, Loss: 2.206673, Accuracy: 18.45%\n",
            "Epoch: 37, Step: 229/655, Loss: 2.206471, Accuracy: 18.46%\n",
            "Epoch: 37, Step: 230/655, Loss: 2.206266, Accuracy: 18.46%\n",
            "Epoch: 37, Step: 231/655, Loss: 2.205820, Accuracy: 18.51%\n",
            "Epoch: 37, Step: 232/655, Loss: 2.205644, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 233/655, Loss: 2.205180, Accuracy: 18.55%\n",
            "Epoch: 37, Step: 234/655, Loss: 2.205215, Accuracy: 18.60%\n",
            "Epoch: 37, Step: 235/655, Loss: 2.205417, Accuracy: 18.58%\n",
            "Epoch: 37, Step: 236/655, Loss: 2.205170, Accuracy: 18.62%\n",
            "Epoch: 37, Step: 237/655, Loss: 2.205011, Accuracy: 18.64%\n",
            "Epoch: 37, Step: 238/655, Loss: 2.205175, Accuracy: 18.62%\n",
            "Epoch: 37, Step: 239/655, Loss: 2.205350, Accuracy: 18.59%\n",
            "Epoch: 37, Step: 240/655, Loss: 2.205123, Accuracy: 18.61%\n",
            "Epoch: 37, Step: 241/655, Loss: 2.205341, Accuracy: 18.63%\n",
            "Epoch: 37, Step: 242/655, Loss: 2.204607, Accuracy: 18.69%\n",
            "Epoch: 37, Step: 243/655, Loss: 2.204691, Accuracy: 18.69%\n",
            "Epoch: 37, Step: 244/655, Loss: 2.204956, Accuracy: 18.71%\n",
            "Epoch: 37, Step: 245/655, Loss: 2.205242, Accuracy: 18.72%\n",
            "Epoch: 37, Step: 246/655, Loss: 2.205344, Accuracy: 18.72%\n",
            "Epoch: 37, Step: 247/655, Loss: 2.205690, Accuracy: 18.72%\n",
            "Epoch: 37, Step: 248/655, Loss: 2.206253, Accuracy: 18.66%\n",
            "Epoch: 37, Step: 249/655, Loss: 2.206541, Accuracy: 18.67%\n",
            "Epoch: 37, Step: 250/655, Loss: 2.207062, Accuracy: 18.66%\n",
            "Epoch: 37, Step: 251/655, Loss: 2.207230, Accuracy: 18.64%\n",
            "Epoch: 37, Step: 252/655, Loss: 2.207055, Accuracy: 18.60%\n",
            "Epoch: 37, Step: 253/655, Loss: 2.206564, Accuracy: 18.59%\n",
            "Epoch: 37, Step: 254/655, Loss: 2.206284, Accuracy: 18.54%\n",
            "Epoch: 37, Step: 255/655, Loss: 2.206596, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 256/655, Loss: 2.206846, Accuracy: 18.44%\n",
            "Epoch: 37, Step: 257/655, Loss: 2.206526, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 258/655, Loss: 2.207109, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 259/655, Loss: 2.207232, Accuracy: 18.45%\n",
            "Epoch: 37, Step: 260/655, Loss: 2.207034, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 261/655, Loss: 2.207456, Accuracy: 18.45%\n",
            "Epoch: 37, Step: 262/655, Loss: 2.207448, Accuracy: 18.44%\n",
            "Epoch: 37, Step: 263/655, Loss: 2.207499, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 264/655, Loss: 2.207997, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 265/655, Loss: 2.208150, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 266/655, Loss: 2.208685, Accuracy: 18.46%\n",
            "Epoch: 37, Step: 267/655, Loss: 2.208686, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 268/655, Loss: 2.208488, Accuracy: 18.51%\n",
            "Epoch: 37, Step: 269/655, Loss: 2.208515, Accuracy: 18.52%\n",
            "Epoch: 37, Step: 270/655, Loss: 2.208728, Accuracy: 18.53%\n",
            "Epoch: 37, Step: 271/655, Loss: 2.208990, Accuracy: 18.52%\n",
            "Epoch: 37, Step: 272/655, Loss: 2.208523, Accuracy: 18.50%\n",
            "Epoch: 37, Step: 273/655, Loss: 2.208457, Accuracy: 18.51%\n",
            "Epoch: 37, Step: 274/655, Loss: 2.208463, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 275/655, Loss: 2.208513, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 276/655, Loss: 2.208934, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 277/655, Loss: 2.208953, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 278/655, Loss: 2.209105, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 279/655, Loss: 2.208992, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 280/655, Loss: 2.209350, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 281/655, Loss: 2.208991, Accuracy: 18.53%\n",
            "Epoch: 37, Step: 282/655, Loss: 2.208956, Accuracy: 18.53%\n",
            "Epoch: 37, Step: 283/655, Loss: 2.209219, Accuracy: 18.51%\n",
            "Epoch: 37, Step: 284/655, Loss: 2.209464, Accuracy: 18.54%\n",
            "Epoch: 37, Step: 285/655, Loss: 2.209546, Accuracy: 18.53%\n",
            "Epoch: 37, Step: 286/655, Loss: 2.209339, Accuracy: 18.53%\n",
            "Epoch: 37, Step: 287/655, Loss: 2.209673, Accuracy: 18.51%\n",
            "Epoch: 37, Step: 288/655, Loss: 2.209801, Accuracy: 18.50%\n",
            "Epoch: 37, Step: 289/655, Loss: 2.209521, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 290/655, Loss: 2.209406, Accuracy: 18.52%\n",
            "Epoch: 37, Step: 291/655, Loss: 2.209131, Accuracy: 18.55%\n",
            "Epoch: 37, Step: 292/655, Loss: 2.209016, Accuracy: 18.57%\n",
            "Epoch: 37, Step: 293/655, Loss: 2.209037, Accuracy: 18.57%\n",
            "Epoch: 37, Step: 294/655, Loss: 2.208887, Accuracy: 18.57%\n",
            "Epoch: 37, Step: 295/655, Loss: 2.208687, Accuracy: 18.58%\n",
            "Epoch: 37, Step: 296/655, Loss: 2.209118, Accuracy: 18.57%\n",
            "Epoch: 37, Step: 297/655, Loss: 2.209155, Accuracy: 18.59%\n",
            "Epoch: 37, Step: 298/655, Loss: 2.209228, Accuracy: 18.57%\n",
            "Epoch: 37, Step: 299/655, Loss: 2.209157, Accuracy: 18.58%\n",
            "Epoch: 37, Step: 300/655, Loss: 2.208747, Accuracy: 18.62%\n",
            "Epoch: 37, Step: 301/655, Loss: 2.208527, Accuracy: 18.62%\n",
            "Epoch: 37, Step: 302/655, Loss: 2.208593, Accuracy: 18.63%\n",
            "Epoch: 37, Step: 303/655, Loss: 2.208805, Accuracy: 18.60%\n",
            "Epoch: 37, Step: 304/655, Loss: 2.208746, Accuracy: 18.62%\n",
            "Epoch: 37, Step: 305/655, Loss: 2.208768, Accuracy: 18.61%\n",
            "Epoch: 37, Step: 306/655, Loss: 2.209046, Accuracy: 18.57%\n",
            "Epoch: 37, Step: 307/655, Loss: 2.208977, Accuracy: 18.57%\n",
            "Epoch: 37, Step: 308/655, Loss: 2.209026, Accuracy: 18.55%\n",
            "Epoch: 37, Step: 309/655, Loss: 2.208911, Accuracy: 18.56%\n",
            "Epoch: 37, Step: 310/655, Loss: 2.208594, Accuracy: 18.54%\n",
            "Epoch: 37, Step: 311/655, Loss: 2.208890, Accuracy: 18.53%\n",
            "Epoch: 37, Step: 312/655, Loss: 2.208777, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 313/655, Loss: 2.208666, Accuracy: 18.46%\n",
            "Epoch: 37, Step: 314/655, Loss: 2.208649, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 315/655, Loss: 2.208290, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 316/655, Loss: 2.208225, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 317/655, Loss: 2.208405, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 318/655, Loss: 2.208395, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 319/655, Loss: 2.208351, Accuracy: 18.46%\n",
            "Epoch: 37, Step: 320/655, Loss: 2.208302, Accuracy: 18.46%\n",
            "Epoch: 37, Step: 321/655, Loss: 2.207685, Accuracy: 18.50%\n",
            "Epoch: 37, Step: 322/655, Loss: 2.207798, Accuracy: 18.50%\n",
            "Epoch: 37, Step: 323/655, Loss: 2.207705, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 324/655, Loss: 2.207803, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 325/655, Loss: 2.207698, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 326/655, Loss: 2.207499, Accuracy: 18.46%\n",
            "Epoch: 37, Step: 327/655, Loss: 2.207336, Accuracy: 18.46%\n",
            "Epoch: 37, Step: 328/655, Loss: 2.206926, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 329/655, Loss: 2.206923, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 330/655, Loss: 2.206856, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 331/655, Loss: 2.207391, Accuracy: 18.43%\n",
            "Epoch: 37, Step: 332/655, Loss: 2.207563, Accuracy: 18.41%\n",
            "Epoch: 37, Step: 333/655, Loss: 2.207591, Accuracy: 18.41%\n",
            "Epoch: 37, Step: 334/655, Loss: 2.207729, Accuracy: 18.39%\n",
            "Epoch: 37, Step: 335/655, Loss: 2.207846, Accuracy: 18.38%\n",
            "Epoch: 37, Step: 336/655, Loss: 2.207480, Accuracy: 18.38%\n",
            "Epoch: 37, Step: 337/655, Loss: 2.207433, Accuracy: 18.36%\n",
            "Epoch: 37, Step: 338/655, Loss: 2.207575, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 339/655, Loss: 2.207276, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 340/655, Loss: 2.207016, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 341/655, Loss: 2.207039, Accuracy: 18.32%\n",
            "Epoch: 37, Step: 342/655, Loss: 2.206635, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 343/655, Loss: 2.206598, Accuracy: 18.36%\n",
            "Epoch: 37, Step: 344/655, Loss: 2.206827, Accuracy: 18.33%\n",
            "Epoch: 37, Step: 345/655, Loss: 2.206871, Accuracy: 18.32%\n",
            "Epoch: 37, Step: 346/655, Loss: 2.206763, Accuracy: 18.33%\n",
            "Epoch: 37, Step: 347/655, Loss: 2.206690, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 348/655, Loss: 2.206623, Accuracy: 18.36%\n",
            "Epoch: 37, Step: 349/655, Loss: 2.206930, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 350/655, Loss: 2.206612, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 351/655, Loss: 2.206783, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 352/655, Loss: 2.206284, Accuracy: 18.37%\n",
            "Epoch: 37, Step: 353/655, Loss: 2.206447, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 354/655, Loss: 2.206105, Accuracy: 18.37%\n",
            "Epoch: 37, Step: 355/655, Loss: 2.206197, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 356/655, Loss: 2.206440, Accuracy: 18.33%\n",
            "Epoch: 37, Step: 357/655, Loss: 2.206556, Accuracy: 18.33%\n",
            "Epoch: 37, Step: 358/655, Loss: 2.206702, Accuracy: 18.31%\n",
            "Epoch: 37, Step: 359/655, Loss: 2.207102, Accuracy: 18.31%\n",
            "Epoch: 37, Step: 360/655, Loss: 2.206920, Accuracy: 18.32%\n",
            "Epoch: 37, Step: 361/655, Loss: 2.206576, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 362/655, Loss: 2.206620, Accuracy: 18.38%\n",
            "Epoch: 37, Step: 363/655, Loss: 2.206533, Accuracy: 18.40%\n",
            "Epoch: 37, Step: 364/655, Loss: 2.206954, Accuracy: 18.37%\n",
            "Epoch: 37, Step: 365/655, Loss: 2.206767, Accuracy: 18.38%\n",
            "Epoch: 37, Step: 366/655, Loss: 2.206520, Accuracy: 18.39%\n",
            "Epoch: 37, Step: 367/655, Loss: 2.206695, Accuracy: 18.38%\n",
            "Epoch: 37, Step: 368/655, Loss: 2.206353, Accuracy: 18.41%\n",
            "Epoch: 37, Step: 369/655, Loss: 2.206252, Accuracy: 18.41%\n",
            "Epoch: 37, Step: 370/655, Loss: 2.206162, Accuracy: 18.44%\n",
            "Epoch: 37, Step: 371/655, Loss: 2.206473, Accuracy: 18.41%\n",
            "Epoch: 37, Step: 372/655, Loss: 2.206274, Accuracy: 18.41%\n",
            "Epoch: 37, Step: 373/655, Loss: 2.206126, Accuracy: 18.44%\n",
            "Epoch: 37, Step: 374/655, Loss: 2.206151, Accuracy: 18.43%\n",
            "Epoch: 37, Step: 375/655, Loss: 2.206194, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 376/655, Loss: 2.206283, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 377/655, Loss: 2.206015, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 378/655, Loss: 2.206458, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 379/655, Loss: 2.206727, Accuracy: 18.44%\n",
            "Epoch: 37, Step: 380/655, Loss: 2.207016, Accuracy: 18.41%\n",
            "Epoch: 37, Step: 381/655, Loss: 2.206943, Accuracy: 18.42%\n",
            "Epoch: 37, Step: 382/655, Loss: 2.207104, Accuracy: 18.42%\n",
            "Epoch: 37, Step: 383/655, Loss: 2.207046, Accuracy: 18.40%\n",
            "Epoch: 37, Step: 384/655, Loss: 2.207117, Accuracy: 18.41%\n",
            "Epoch: 37, Step: 385/655, Loss: 2.206852, Accuracy: 18.44%\n",
            "Epoch: 37, Step: 386/655, Loss: 2.206811, Accuracy: 18.43%\n",
            "Epoch: 37, Step: 387/655, Loss: 2.206991, Accuracy: 18.43%\n",
            "Epoch: 37, Step: 388/655, Loss: 2.206984, Accuracy: 18.42%\n",
            "Epoch: 37, Step: 389/655, Loss: 2.206984, Accuracy: 18.41%\n",
            "Epoch: 37, Step: 390/655, Loss: 2.207120, Accuracy: 18.41%\n",
            "Epoch: 37, Step: 391/655, Loss: 2.207160, Accuracy: 18.41%\n",
            "Epoch: 37, Step: 392/655, Loss: 2.207256, Accuracy: 18.42%\n",
            "Epoch: 37, Step: 393/655, Loss: 2.206793, Accuracy: 18.45%\n",
            "Epoch: 37, Step: 394/655, Loss: 2.206749, Accuracy: 18.45%\n",
            "Epoch: 37, Step: 395/655, Loss: 2.206784, Accuracy: 18.44%\n",
            "Epoch: 37, Step: 396/655, Loss: 2.206862, Accuracy: 18.44%\n",
            "Epoch: 37, Step: 397/655, Loss: 2.206950, Accuracy: 18.44%\n",
            "Epoch: 37, Step: 398/655, Loss: 2.207218, Accuracy: 18.44%\n",
            "Epoch: 37, Step: 399/655, Loss: 2.207180, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 400/655, Loss: 2.206644, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 401/655, Loss: 2.206181, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 402/655, Loss: 2.206097, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 403/655, Loss: 2.205639, Accuracy: 18.50%\n",
            "Epoch: 37, Step: 404/655, Loss: 2.205872, Accuracy: 18.50%\n",
            "Epoch: 37, Step: 405/655, Loss: 2.205888, Accuracy: 18.53%\n",
            "Epoch: 37, Step: 406/655, Loss: 2.205887, Accuracy: 18.52%\n",
            "Epoch: 37, Step: 407/655, Loss: 2.206161, Accuracy: 18.54%\n",
            "Epoch: 37, Step: 408/655, Loss: 2.206011, Accuracy: 18.54%\n",
            "Epoch: 37, Step: 409/655, Loss: 2.205946, Accuracy: 18.54%\n",
            "Epoch: 37, Step: 410/655, Loss: 2.205795, Accuracy: 18.54%\n",
            "Epoch: 37, Step: 411/655, Loss: 2.206060, Accuracy: 18.54%\n",
            "Epoch: 37, Step: 412/655, Loss: 2.205959, Accuracy: 18.51%\n",
            "Epoch: 37, Step: 413/655, Loss: 2.206214, Accuracy: 18.50%\n",
            "Epoch: 37, Step: 414/655, Loss: 2.206308, Accuracy: 18.50%\n",
            "Epoch: 37, Step: 415/655, Loss: 2.206242, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 416/655, Loss: 2.206207, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 417/655, Loss: 2.206019, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 418/655, Loss: 2.206325, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 419/655, Loss: 2.206396, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 420/655, Loss: 2.206361, Accuracy: 18.45%\n",
            "Epoch: 37, Step: 421/655, Loss: 2.206317, Accuracy: 18.49%\n",
            "Epoch: 37, Step: 422/655, Loss: 2.206292, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 423/655, Loss: 2.206155, Accuracy: 18.48%\n",
            "Epoch: 37, Step: 424/655, Loss: 2.206193, Accuracy: 18.47%\n",
            "Epoch: 37, Step: 425/655, Loss: 2.206606, Accuracy: 18.44%\n",
            "Epoch: 37, Step: 426/655, Loss: 2.206836, Accuracy: 18.41%\n",
            "Epoch: 37, Step: 427/655, Loss: 2.206893, Accuracy: 18.40%\n",
            "Epoch: 37, Step: 428/655, Loss: 2.206902, Accuracy: 18.38%\n",
            "Epoch: 37, Step: 429/655, Loss: 2.206935, Accuracy: 18.36%\n",
            "Epoch: 37, Step: 430/655, Loss: 2.207043, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 431/655, Loss: 2.206785, Accuracy: 18.36%\n",
            "Epoch: 37, Step: 432/655, Loss: 2.206735, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 433/655, Loss: 2.206560, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 434/655, Loss: 2.206510, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 435/655, Loss: 2.206400, Accuracy: 18.38%\n",
            "Epoch: 37, Step: 436/655, Loss: 2.206211, Accuracy: 18.39%\n",
            "Epoch: 37, Step: 437/655, Loss: 2.206431, Accuracy: 18.37%\n",
            "Epoch: 37, Step: 438/655, Loss: 2.206284, Accuracy: 18.40%\n",
            "Epoch: 37, Step: 439/655, Loss: 2.206401, Accuracy: 18.39%\n",
            "Epoch: 37, Step: 440/655, Loss: 2.206430, Accuracy: 18.39%\n",
            "Epoch: 37, Step: 441/655, Loss: 2.206647, Accuracy: 18.39%\n",
            "Epoch: 37, Step: 442/655, Loss: 2.206662, Accuracy: 18.40%\n",
            "Epoch: 37, Step: 443/655, Loss: 2.206848, Accuracy: 18.38%\n",
            "Epoch: 37, Step: 444/655, Loss: 2.206868, Accuracy: 18.36%\n",
            "Epoch: 37, Step: 445/655, Loss: 2.207068, Accuracy: 18.36%\n",
            "Epoch: 37, Step: 446/655, Loss: 2.206783, Accuracy: 18.37%\n",
            "Epoch: 37, Step: 447/655, Loss: 2.206730, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 448/655, Loss: 2.206633, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 449/655, Loss: 2.206666, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 450/655, Loss: 2.206418, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 451/655, Loss: 2.206388, Accuracy: 18.33%\n",
            "Epoch: 37, Step: 452/655, Loss: 2.206242, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 453/655, Loss: 2.206346, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 454/655, Loss: 2.206205, Accuracy: 18.32%\n",
            "Epoch: 37, Step: 455/655, Loss: 2.206456, Accuracy: 18.30%\n",
            "Epoch: 37, Step: 456/655, Loss: 2.206646, Accuracy: 18.33%\n",
            "Epoch: 37, Step: 457/655, Loss: 2.206550, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 458/655, Loss: 2.206613, Accuracy: 18.31%\n",
            "Epoch: 37, Step: 459/655, Loss: 2.206569, Accuracy: 18.33%\n",
            "Epoch: 37, Step: 460/655, Loss: 2.206744, Accuracy: 18.32%\n",
            "Epoch: 37, Step: 461/655, Loss: 2.206515, Accuracy: 18.33%\n",
            "Epoch: 37, Step: 462/655, Loss: 2.206425, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 463/655, Loss: 2.206699, Accuracy: 18.32%\n",
            "Epoch: 37, Step: 464/655, Loss: 2.206219, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 465/655, Loss: 2.206345, Accuracy: 18.32%\n",
            "Epoch: 37, Step: 466/655, Loss: 2.206314, Accuracy: 18.32%\n",
            "Epoch: 37, Step: 467/655, Loss: 2.206050, Accuracy: 18.33%\n",
            "Epoch: 37, Step: 468/655, Loss: 2.205994, Accuracy: 18.32%\n",
            "Epoch: 37, Step: 469/655, Loss: 2.205757, Accuracy: 18.36%\n",
            "Epoch: 37, Step: 470/655, Loss: 2.205669, Accuracy: 18.38%\n",
            "Epoch: 37, Step: 471/655, Loss: 2.205904, Accuracy: 18.37%\n",
            "Epoch: 37, Step: 472/655, Loss: 2.205849, Accuracy: 18.37%\n",
            "Epoch: 37, Step: 473/655, Loss: 2.205991, Accuracy: 18.36%\n",
            "Epoch: 37, Step: 474/655, Loss: 2.206109, Accuracy: 18.34%\n",
            "Epoch: 37, Step: 475/655, Loss: 2.206445, Accuracy: 18.33%\n",
            "Epoch: 37, Step: 476/655, Loss: 2.206430, Accuracy: 18.35%\n",
            "Epoch: 37, Step: 477/655, Loss: 2.206548, Accuracy: 18.32%\n",
            "Epoch: 37, Step: 478/655, Loss: 2.206660, Accuracy: 18.33%\n",
            "Epoch: 37, Step: 479/655, Loss: 2.206886, Accuracy: 18.31%\n",
            "Epoch: 37, Step: 480/655, Loss: 2.206739, Accuracy: 18.31%\n",
            "Epoch: 37, Step: 481/655, Loss: 2.206577, Accuracy: 18.31%\n",
            "Epoch: 37, Step: 482/655, Loss: 2.206859, Accuracy: 18.31%\n",
            "Epoch: 37, Step: 483/655, Loss: 2.206705, Accuracy: 18.32%\n",
            "Epoch: 37, Step: 484/655, Loss: 2.206952, Accuracy: 18.30%\n",
            "Epoch: 37, Step: 485/655, Loss: 2.206872, Accuracy: 18.31%\n",
            "Epoch: 37, Step: 486/655, Loss: 2.206952, Accuracy: 18.31%\n",
            "Epoch: 37, Step: 487/655, Loss: 2.206839, Accuracy: 18.33%\n",
            "Epoch: 37, Step: 488/655, Loss: 2.206706, Accuracy: 18.31%\n",
            "Epoch: 37, Step: 489/655, Loss: 2.206722, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 490/655, Loss: 2.206746, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 491/655, Loss: 2.206761, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 492/655, Loss: 2.206842, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 493/655, Loss: 2.206797, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 494/655, Loss: 2.206757, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 495/655, Loss: 2.207182, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 496/655, Loss: 2.207140, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 497/655, Loss: 2.207338, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 498/655, Loss: 2.207146, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 499/655, Loss: 2.206926, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 500/655, Loss: 2.206976, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 501/655, Loss: 2.206902, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 502/655, Loss: 2.207022, Accuracy: 18.23%\n",
            "Epoch: 37, Step: 503/655, Loss: 2.207215, Accuracy: 18.22%\n",
            "Epoch: 37, Step: 504/655, Loss: 2.207140, Accuracy: 18.21%\n",
            "Epoch: 37, Step: 505/655, Loss: 2.207173, Accuracy: 18.21%\n",
            "Epoch: 37, Step: 506/655, Loss: 2.207009, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 507/655, Loss: 2.207027, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 508/655, Loss: 2.206872, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 509/655, Loss: 2.206727, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 510/655, Loss: 2.206473, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 511/655, Loss: 2.206492, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 512/655, Loss: 2.206445, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 513/655, Loss: 2.206293, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 514/655, Loss: 2.206267, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 515/655, Loss: 2.206087, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 516/655, Loss: 2.206226, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 517/655, Loss: 2.206319, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 518/655, Loss: 2.206179, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 519/655, Loss: 2.206251, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 520/655, Loss: 2.206205, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 521/655, Loss: 2.206293, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 522/655, Loss: 2.206447, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 523/655, Loss: 2.206631, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 524/655, Loss: 2.206593, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 525/655, Loss: 2.206506, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 526/655, Loss: 2.206534, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 527/655, Loss: 2.206491, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 528/655, Loss: 2.206394, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 529/655, Loss: 2.206402, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 530/655, Loss: 2.206446, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 531/655, Loss: 2.206509, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 532/655, Loss: 2.206316, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 533/655, Loss: 2.206408, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 534/655, Loss: 2.206185, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 535/655, Loss: 2.206225, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 536/655, Loss: 2.206378, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 537/655, Loss: 2.206500, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 538/655, Loss: 2.206440, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 539/655, Loss: 2.206453, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 540/655, Loss: 2.206546, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 541/655, Loss: 2.206492, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 542/655, Loss: 2.206433, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 543/655, Loss: 2.206755, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 544/655, Loss: 2.206482, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 545/655, Loss: 2.206381, Accuracy: 18.30%\n",
            "Epoch: 37, Step: 546/655, Loss: 2.206354, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 547/655, Loss: 2.206245, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 548/655, Loss: 2.206341, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 549/655, Loss: 2.206200, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 550/655, Loss: 2.206205, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 551/655, Loss: 2.206199, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 552/655, Loss: 2.206092, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 553/655, Loss: 2.206004, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 554/655, Loss: 2.205938, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 555/655, Loss: 2.205883, Accuracy: 18.31%\n",
            "Epoch: 37, Step: 556/655, Loss: 2.205854, Accuracy: 18.31%\n",
            "Epoch: 37, Step: 557/655, Loss: 2.205703, Accuracy: 18.31%\n",
            "Epoch: 37, Step: 558/655, Loss: 2.205774, Accuracy: 18.30%\n",
            "Epoch: 37, Step: 559/655, Loss: 2.205778, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 560/655, Loss: 2.205744, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 561/655, Loss: 2.205816, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 562/655, Loss: 2.205815, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 563/655, Loss: 2.205876, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 564/655, Loss: 2.205753, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 565/655, Loss: 2.205672, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 566/655, Loss: 2.205639, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 567/655, Loss: 2.205586, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 568/655, Loss: 2.205469, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 569/655, Loss: 2.205495, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 570/655, Loss: 2.205674, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 571/655, Loss: 2.205802, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 572/655, Loss: 2.205926, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 573/655, Loss: 2.205916, Accuracy: 18.28%\n",
            "Epoch: 37, Step: 574/655, Loss: 2.206157, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 575/655, Loss: 2.206321, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 576/655, Loss: 2.206282, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 577/655, Loss: 2.206246, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 578/655, Loss: 2.206345, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 579/655, Loss: 2.206438, Accuracy: 18.23%\n",
            "Epoch: 37, Step: 580/655, Loss: 2.206708, Accuracy: 18.22%\n",
            "Epoch: 37, Step: 581/655, Loss: 2.206781, Accuracy: 18.21%\n",
            "Epoch: 37, Step: 582/655, Loss: 2.206651, Accuracy: 18.23%\n",
            "Epoch: 37, Step: 583/655, Loss: 2.206756, Accuracy: 18.22%\n",
            "Epoch: 37, Step: 584/655, Loss: 2.206640, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 585/655, Loss: 2.206605, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 586/655, Loss: 2.206619, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 587/655, Loss: 2.206565, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 588/655, Loss: 2.206383, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 589/655, Loss: 2.206318, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 590/655, Loss: 2.206239, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 591/655, Loss: 2.206400, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 592/655, Loss: 2.206290, Accuracy: 18.29%\n",
            "Epoch: 37, Step: 593/655, Loss: 2.206369, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 594/655, Loss: 2.206459, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 595/655, Loss: 2.206443, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 596/655, Loss: 2.206416, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 597/655, Loss: 2.206560, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 598/655, Loss: 2.206588, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 599/655, Loss: 2.206765, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 600/655, Loss: 2.206803, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 601/655, Loss: 2.206794, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 602/655, Loss: 2.206779, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 603/655, Loss: 2.206788, Accuracy: 18.27%\n",
            "Epoch: 37, Step: 604/655, Loss: 2.206967, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 605/655, Loss: 2.206870, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 606/655, Loss: 2.206650, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 607/655, Loss: 2.206846, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 608/655, Loss: 2.206919, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 609/655, Loss: 2.207087, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 610/655, Loss: 2.207305, Accuracy: 18.23%\n",
            "Epoch: 37, Step: 611/655, Loss: 2.207363, Accuracy: 18.23%\n",
            "Epoch: 37, Step: 612/655, Loss: 2.207513, Accuracy: 18.22%\n",
            "Epoch: 37, Step: 613/655, Loss: 2.207663, Accuracy: 18.23%\n",
            "Epoch: 37, Step: 614/655, Loss: 2.207824, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 615/655, Loss: 2.207770, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 616/655, Loss: 2.207844, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 617/655, Loss: 2.207476, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 618/655, Loss: 2.207429, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 619/655, Loss: 2.207610, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 620/655, Loss: 2.207884, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 621/655, Loss: 2.207819, Accuracy: 18.23%\n",
            "Epoch: 37, Step: 622/655, Loss: 2.207393, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 623/655, Loss: 2.207548, Accuracy: 18.23%\n",
            "Epoch: 37, Step: 624/655, Loss: 2.207537, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 625/655, Loss: 2.207466, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 626/655, Loss: 2.207241, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 627/655, Loss: 2.207087, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 628/655, Loss: 2.207266, Accuracy: 18.23%\n",
            "Epoch: 37, Step: 629/655, Loss: 2.207398, Accuracy: 18.21%\n",
            "Epoch: 37, Step: 630/655, Loss: 2.207326, Accuracy: 18.20%\n",
            "Epoch: 37, Step: 631/655, Loss: 2.207514, Accuracy: 18.21%\n",
            "Epoch: 37, Step: 632/655, Loss: 2.207491, Accuracy: 18.20%\n",
            "Epoch: 37, Step: 633/655, Loss: 2.207628, Accuracy: 18.19%\n",
            "Epoch: 37, Step: 634/655, Loss: 2.207817, Accuracy: 18.19%\n",
            "Epoch: 37, Step: 635/655, Loss: 2.207823, Accuracy: 18.20%\n",
            "Epoch: 37, Step: 636/655, Loss: 2.207808, Accuracy: 18.21%\n",
            "Epoch: 37, Step: 637/655, Loss: 2.207563, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 638/655, Loss: 2.207759, Accuracy: 18.23%\n",
            "Epoch: 37, Step: 639/655, Loss: 2.207778, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 640/655, Loss: 2.207953, Accuracy: 18.23%\n",
            "Epoch: 37, Step: 641/655, Loss: 2.207628, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 642/655, Loss: 2.207497, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 643/655, Loss: 2.207599, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 644/655, Loss: 2.207545, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 645/655, Loss: 2.207595, Accuracy: 18.26%\n",
            "Epoch: 37, Step: 646/655, Loss: 2.207759, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 647/655, Loss: 2.207908, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 648/655, Loss: 2.207810, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 649/655, Loss: 2.207912, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 650/655, Loss: 2.207747, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 651/655, Loss: 2.207675, Accuracy: 18.24%\n",
            "Epoch: 37, Step: 652/655, Loss: 2.207602, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 653/655, Loss: 2.207444, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 654/655, Loss: 2.207393, Accuracy: 18.25%\n",
            "Epoch: 37, Step: 655/655, Loss: 2.207781, Accuracy: 18.25%\n",
            "Epoch: 38, Step: 1/655, Loss: 2.090575, Accuracy: 21.88%\n",
            "Epoch: 38, Step: 2/655, Loss: 2.117249, Accuracy: 23.44%\n",
            "Epoch: 38, Step: 3/655, Loss: 2.171671, Accuracy: 19.79%\n",
            "Epoch: 38, Step: 4/655, Loss: 2.207447, Accuracy: 16.41%\n",
            "Epoch: 38, Step: 5/655, Loss: 2.189182, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 6/655, Loss: 2.184070, Accuracy: 19.79%\n",
            "Epoch: 38, Step: 7/655, Loss: 2.157463, Accuracy: 21.88%\n",
            "Epoch: 38, Step: 8/655, Loss: 2.146231, Accuracy: 21.88%\n",
            "Epoch: 38, Step: 9/655, Loss: 2.157420, Accuracy: 21.53%\n",
            "Epoch: 38, Step: 10/655, Loss: 2.165574, Accuracy: 20.00%\n",
            "Epoch: 38, Step: 11/655, Loss: 2.177641, Accuracy: 19.03%\n",
            "Epoch: 38, Step: 12/655, Loss: 2.178986, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 13/655, Loss: 2.169096, Accuracy: 19.47%\n",
            "Epoch: 38, Step: 14/655, Loss: 2.174326, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 15/655, Loss: 2.170294, Accuracy: 19.58%\n",
            "Epoch: 38, Step: 16/655, Loss: 2.171358, Accuracy: 19.73%\n",
            "Epoch: 38, Step: 17/655, Loss: 2.172979, Accuracy: 19.67%\n",
            "Epoch: 38, Step: 18/655, Loss: 2.173018, Accuracy: 19.27%\n",
            "Epoch: 38, Step: 19/655, Loss: 2.167576, Accuracy: 19.74%\n",
            "Epoch: 38, Step: 20/655, Loss: 2.165074, Accuracy: 20.16%\n",
            "Epoch: 38, Step: 21/655, Loss: 2.169064, Accuracy: 20.39%\n",
            "Epoch: 38, Step: 22/655, Loss: 2.173363, Accuracy: 20.31%\n",
            "Epoch: 38, Step: 23/655, Loss: 2.173350, Accuracy: 20.52%\n",
            "Epoch: 38, Step: 24/655, Loss: 2.173646, Accuracy: 20.83%\n",
            "Epoch: 38, Step: 25/655, Loss: 2.176813, Accuracy: 20.75%\n",
            "Epoch: 38, Step: 26/655, Loss: 2.178693, Accuracy: 20.91%\n",
            "Epoch: 38, Step: 27/655, Loss: 2.183508, Accuracy: 20.83%\n",
            "Epoch: 38, Step: 28/655, Loss: 2.184298, Accuracy: 20.54%\n",
            "Epoch: 38, Step: 29/655, Loss: 2.180916, Accuracy: 20.47%\n",
            "Epoch: 38, Step: 30/655, Loss: 2.181010, Accuracy: 20.94%\n",
            "Epoch: 38, Step: 31/655, Loss: 2.184887, Accuracy: 20.77%\n",
            "Epoch: 38, Step: 32/655, Loss: 2.184282, Accuracy: 20.90%\n",
            "Epoch: 38, Step: 33/655, Loss: 2.185073, Accuracy: 20.83%\n",
            "Epoch: 38, Step: 34/655, Loss: 2.186290, Accuracy: 20.77%\n",
            "Epoch: 38, Step: 35/655, Loss: 2.189090, Accuracy: 20.54%\n",
            "Epoch: 38, Step: 36/655, Loss: 2.188475, Accuracy: 20.57%\n",
            "Epoch: 38, Step: 37/655, Loss: 2.191626, Accuracy: 20.61%\n",
            "Epoch: 38, Step: 38/655, Loss: 2.190366, Accuracy: 20.48%\n",
            "Epoch: 38, Step: 39/655, Loss: 2.189740, Accuracy: 20.51%\n",
            "Epoch: 38, Step: 40/655, Loss: 2.186701, Accuracy: 20.70%\n",
            "Epoch: 38, Step: 41/655, Loss: 2.189371, Accuracy: 20.58%\n",
            "Epoch: 38, Step: 42/655, Loss: 2.187949, Accuracy: 20.54%\n",
            "Epoch: 38, Step: 43/655, Loss: 2.187828, Accuracy: 20.13%\n",
            "Epoch: 38, Step: 44/655, Loss: 2.188870, Accuracy: 20.03%\n",
            "Epoch: 38, Step: 45/655, Loss: 2.186442, Accuracy: 20.35%\n",
            "Epoch: 38, Step: 46/655, Loss: 2.188431, Accuracy: 20.24%\n",
            "Epoch: 38, Step: 47/655, Loss: 2.189321, Accuracy: 20.28%\n",
            "Epoch: 38, Step: 48/655, Loss: 2.189344, Accuracy: 20.25%\n",
            "Epoch: 38, Step: 49/655, Loss: 2.189186, Accuracy: 20.22%\n",
            "Epoch: 38, Step: 50/655, Loss: 2.194291, Accuracy: 19.81%\n",
            "Epoch: 38, Step: 51/655, Loss: 2.196743, Accuracy: 19.91%\n",
            "Epoch: 38, Step: 52/655, Loss: 2.196924, Accuracy: 19.71%\n",
            "Epoch: 38, Step: 53/655, Loss: 2.196911, Accuracy: 19.75%\n",
            "Epoch: 38, Step: 54/655, Loss: 2.198001, Accuracy: 19.68%\n",
            "Epoch: 38, Step: 55/655, Loss: 2.198662, Accuracy: 19.55%\n",
            "Epoch: 38, Step: 56/655, Loss: 2.201623, Accuracy: 19.36%\n",
            "Epoch: 38, Step: 57/655, Loss: 2.201480, Accuracy: 19.57%\n",
            "Epoch: 38, Step: 58/655, Loss: 2.200616, Accuracy: 19.88%\n",
            "Epoch: 38, Step: 59/655, Loss: 2.201931, Accuracy: 19.76%\n",
            "Epoch: 38, Step: 60/655, Loss: 2.202824, Accuracy: 19.69%\n",
            "Epoch: 38, Step: 61/655, Loss: 2.205097, Accuracy: 19.62%\n",
            "Epoch: 38, Step: 62/655, Loss: 2.205935, Accuracy: 19.76%\n",
            "Epoch: 38, Step: 63/655, Loss: 2.206511, Accuracy: 19.59%\n",
            "Epoch: 38, Step: 64/655, Loss: 2.205228, Accuracy: 19.73%\n",
            "Epoch: 38, Step: 65/655, Loss: 2.205302, Accuracy: 19.76%\n",
            "Epoch: 38, Step: 66/655, Loss: 2.206542, Accuracy: 19.79%\n",
            "Epoch: 38, Step: 67/655, Loss: 2.205130, Accuracy: 19.92%\n",
            "Epoch: 38, Step: 68/655, Loss: 2.203539, Accuracy: 20.08%\n",
            "Epoch: 38, Step: 69/655, Loss: 2.201607, Accuracy: 20.15%\n",
            "Epoch: 38, Step: 70/655, Loss: 2.203548, Accuracy: 20.04%\n",
            "Epoch: 38, Step: 71/655, Loss: 2.203928, Accuracy: 19.94%\n",
            "Epoch: 38, Step: 72/655, Loss: 2.203631, Accuracy: 20.10%\n",
            "Epoch: 38, Step: 73/655, Loss: 2.203561, Accuracy: 20.16%\n",
            "Epoch: 38, Step: 74/655, Loss: 2.204691, Accuracy: 20.10%\n",
            "Epoch: 38, Step: 75/655, Loss: 2.205809, Accuracy: 19.96%\n",
            "Epoch: 38, Step: 76/655, Loss: 2.207535, Accuracy: 19.78%\n",
            "Epoch: 38, Step: 77/655, Loss: 2.206522, Accuracy: 19.68%\n",
            "Epoch: 38, Step: 78/655, Loss: 2.207420, Accuracy: 19.43%\n",
            "Epoch: 38, Step: 79/655, Loss: 2.209575, Accuracy: 19.30%\n",
            "Epoch: 38, Step: 80/655, Loss: 2.210135, Accuracy: 19.34%\n",
            "Epoch: 38, Step: 81/655, Loss: 2.209888, Accuracy: 19.33%\n",
            "Epoch: 38, Step: 82/655, Loss: 2.211812, Accuracy: 19.25%\n",
            "Epoch: 38, Step: 83/655, Loss: 2.212950, Accuracy: 19.16%\n",
            "Epoch: 38, Step: 84/655, Loss: 2.213681, Accuracy: 19.08%\n",
            "Epoch: 38, Step: 85/655, Loss: 2.213547, Accuracy: 19.04%\n",
            "Epoch: 38, Step: 86/655, Loss: 2.214850, Accuracy: 18.86%\n",
            "Epoch: 38, Step: 87/655, Loss: 2.215731, Accuracy: 18.82%\n",
            "Epoch: 38, Step: 88/655, Loss: 2.216189, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 89/655, Loss: 2.216036, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 90/655, Loss: 2.216316, Accuracy: 18.54%\n",
            "Epoch: 38, Step: 91/655, Loss: 2.215728, Accuracy: 18.48%\n",
            "Epoch: 38, Step: 92/655, Loss: 2.215807, Accuracy: 18.48%\n",
            "Epoch: 38, Step: 93/655, Loss: 2.215481, Accuracy: 18.51%\n",
            "Epoch: 38, Step: 94/655, Loss: 2.216063, Accuracy: 18.52%\n",
            "Epoch: 38, Step: 95/655, Loss: 2.215143, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 96/655, Loss: 2.215484, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 97/655, Loss: 2.215742, Accuracy: 18.59%\n",
            "Epoch: 38, Step: 98/655, Loss: 2.216488, Accuracy: 18.59%\n",
            "Epoch: 38, Step: 99/655, Loss: 2.216564, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 100/655, Loss: 2.216216, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 101/655, Loss: 2.216147, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 102/655, Loss: 2.216654, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 103/655, Loss: 2.217314, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 104/655, Loss: 2.216439, Accuracy: 18.57%\n",
            "Epoch: 38, Step: 105/655, Loss: 2.217260, Accuracy: 18.54%\n",
            "Epoch: 38, Step: 106/655, Loss: 2.216473, Accuracy: 18.57%\n",
            "Epoch: 38, Step: 107/655, Loss: 2.216700, Accuracy: 18.49%\n",
            "Epoch: 38, Step: 108/655, Loss: 2.215523, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 109/655, Loss: 2.215315, Accuracy: 18.69%\n",
            "Epoch: 38, Step: 110/655, Loss: 2.214913, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 111/655, Loss: 2.215105, Accuracy: 18.69%\n",
            "Epoch: 38, Step: 112/655, Loss: 2.215272, Accuracy: 18.72%\n",
            "Epoch: 38, Step: 113/655, Loss: 2.214208, Accuracy: 18.72%\n",
            "Epoch: 38, Step: 114/655, Loss: 2.213520, Accuracy: 18.80%\n",
            "Epoch: 38, Step: 115/655, Loss: 2.212394, Accuracy: 18.89%\n",
            "Epoch: 38, Step: 116/655, Loss: 2.212559, Accuracy: 18.86%\n",
            "Epoch: 38, Step: 117/655, Loss: 2.213345, Accuracy: 18.83%\n",
            "Epoch: 38, Step: 118/655, Loss: 2.212994, Accuracy: 18.83%\n",
            "Epoch: 38, Step: 119/655, Loss: 2.213181, Accuracy: 18.88%\n",
            "Epoch: 38, Step: 120/655, Loss: 2.213406, Accuracy: 18.91%\n",
            "Epoch: 38, Step: 121/655, Loss: 2.212787, Accuracy: 18.90%\n",
            "Epoch: 38, Step: 122/655, Loss: 2.213156, Accuracy: 18.95%\n",
            "Epoch: 38, Step: 123/655, Loss: 2.212768, Accuracy: 18.90%\n",
            "Epoch: 38, Step: 124/655, Loss: 2.213007, Accuracy: 18.88%\n",
            "Epoch: 38, Step: 125/655, Loss: 2.214297, Accuracy: 18.85%\n",
            "Epoch: 38, Step: 126/655, Loss: 2.212973, Accuracy: 18.97%\n",
            "Epoch: 38, Step: 127/655, Loss: 2.213502, Accuracy: 18.95%\n",
            "Epoch: 38, Step: 128/655, Loss: 2.214237, Accuracy: 18.87%\n",
            "Epoch: 38, Step: 129/655, Loss: 2.214176, Accuracy: 18.87%\n",
            "Epoch: 38, Step: 130/655, Loss: 2.214210, Accuracy: 18.82%\n",
            "Epoch: 38, Step: 131/655, Loss: 2.213852, Accuracy: 18.87%\n",
            "Epoch: 38, Step: 132/655, Loss: 2.214377, Accuracy: 18.80%\n",
            "Epoch: 38, Step: 133/655, Loss: 2.213806, Accuracy: 18.77%\n",
            "Epoch: 38, Step: 134/655, Loss: 2.214315, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 135/655, Loss: 2.214082, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 136/655, Loss: 2.215440, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 137/655, Loss: 2.214698, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 138/655, Loss: 2.215558, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 139/655, Loss: 2.215328, Accuracy: 18.57%\n",
            "Epoch: 38, Step: 140/655, Loss: 2.215477, Accuracy: 18.55%\n",
            "Epoch: 38, Step: 141/655, Loss: 2.215850, Accuracy: 18.53%\n",
            "Epoch: 38, Step: 142/655, Loss: 2.216400, Accuracy: 18.49%\n",
            "Epoch: 38, Step: 143/655, Loss: 2.216441, Accuracy: 18.47%\n",
            "Epoch: 38, Step: 144/655, Loss: 2.216002, Accuracy: 18.47%\n",
            "Epoch: 38, Step: 145/655, Loss: 2.215698, Accuracy: 18.51%\n",
            "Epoch: 38, Step: 146/655, Loss: 2.215652, Accuracy: 18.49%\n",
            "Epoch: 38, Step: 147/655, Loss: 2.216220, Accuracy: 18.49%\n",
            "Epoch: 38, Step: 148/655, Loss: 2.217448, Accuracy: 18.45%\n",
            "Epoch: 38, Step: 149/655, Loss: 2.216987, Accuracy: 18.54%\n",
            "Epoch: 38, Step: 150/655, Loss: 2.216481, Accuracy: 18.58%\n",
            "Epoch: 38, Step: 151/655, Loss: 2.215661, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 152/655, Loss: 2.216272, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 153/655, Loss: 2.216287, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 154/655, Loss: 2.216515, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 155/655, Loss: 2.215998, Accuracy: 18.69%\n",
            "Epoch: 38, Step: 156/655, Loss: 2.216298, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 157/655, Loss: 2.216194, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 158/655, Loss: 2.216539, Accuracy: 18.59%\n",
            "Epoch: 38, Step: 159/655, Loss: 2.217051, Accuracy: 18.51%\n",
            "Epoch: 38, Step: 160/655, Loss: 2.217645, Accuracy: 18.54%\n",
            "Epoch: 38, Step: 161/655, Loss: 2.217755, Accuracy: 18.48%\n",
            "Epoch: 38, Step: 162/655, Loss: 2.217545, Accuracy: 18.46%\n",
            "Epoch: 38, Step: 163/655, Loss: 2.217719, Accuracy: 18.50%\n",
            "Epoch: 38, Step: 164/655, Loss: 2.217689, Accuracy: 18.54%\n",
            "Epoch: 38, Step: 165/655, Loss: 2.217656, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 166/655, Loss: 2.217102, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 167/655, Loss: 2.216891, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 168/655, Loss: 2.216796, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 169/655, Loss: 2.217455, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 170/655, Loss: 2.217814, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 171/655, Loss: 2.218415, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 172/655, Loss: 2.218741, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 173/655, Loss: 2.217988, Accuracy: 18.71%\n",
            "Epoch: 38, Step: 174/655, Loss: 2.217211, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 175/655, Loss: 2.216606, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 176/655, Loss: 2.216357, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 177/655, Loss: 2.215925, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 178/655, Loss: 2.214925, Accuracy: 18.70%\n",
            "Epoch: 38, Step: 179/655, Loss: 2.214683, Accuracy: 18.72%\n",
            "Epoch: 38, Step: 180/655, Loss: 2.214415, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 181/655, Loss: 2.215421, Accuracy: 18.73%\n",
            "Epoch: 38, Step: 182/655, Loss: 2.215165, Accuracy: 18.73%\n",
            "Epoch: 38, Step: 183/655, Loss: 2.214829, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 184/655, Loss: 2.214718, Accuracy: 18.70%\n",
            "Epoch: 38, Step: 185/655, Loss: 2.214655, Accuracy: 18.73%\n",
            "Epoch: 38, Step: 186/655, Loss: 2.214780, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 187/655, Loss: 2.215206, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 188/655, Loss: 2.216012, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 189/655, Loss: 2.216127, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 190/655, Loss: 2.215838, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 191/655, Loss: 2.215822, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 192/655, Loss: 2.215676, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 193/655, Loss: 2.216140, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 194/655, Loss: 2.216686, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 195/655, Loss: 2.216121, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 196/655, Loss: 2.216431, Accuracy: 18.69%\n",
            "Epoch: 38, Step: 197/655, Loss: 2.216630, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 198/655, Loss: 2.216443, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 199/655, Loss: 2.216278, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 200/655, Loss: 2.216309, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 201/655, Loss: 2.216245, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 202/655, Loss: 2.216048, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 203/655, Loss: 2.215639, Accuracy: 18.72%\n",
            "Epoch: 38, Step: 204/655, Loss: 2.216092, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 205/655, Loss: 2.216216, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 206/655, Loss: 2.215900, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 207/655, Loss: 2.216102, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 208/655, Loss: 2.216209, Accuracy: 18.69%\n",
            "Epoch: 38, Step: 209/655, Loss: 2.216864, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 210/655, Loss: 2.216126, Accuracy: 18.72%\n",
            "Epoch: 38, Step: 211/655, Loss: 2.215923, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 212/655, Loss: 2.215729, Accuracy: 18.71%\n",
            "Epoch: 38, Step: 213/655, Loss: 2.215863, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 214/655, Loss: 2.215283, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 215/655, Loss: 2.215517, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 216/655, Loss: 2.215128, Accuracy: 18.72%\n",
            "Epoch: 38, Step: 217/655, Loss: 2.215385, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 218/655, Loss: 2.215286, Accuracy: 18.72%\n",
            "Epoch: 38, Step: 219/655, Loss: 2.214948, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 220/655, Loss: 2.214493, Accuracy: 18.74%\n",
            "Epoch: 38, Step: 221/655, Loss: 2.214764, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 222/655, Loss: 2.214912, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 223/655, Loss: 2.215053, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 224/655, Loss: 2.215645, Accuracy: 18.58%\n",
            "Epoch: 38, Step: 225/655, Loss: 2.215349, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 226/655, Loss: 2.215429, Accuracy: 18.56%\n",
            "Epoch: 38, Step: 227/655, Loss: 2.215325, Accuracy: 18.58%\n",
            "Epoch: 38, Step: 228/655, Loss: 2.215480, Accuracy: 18.57%\n",
            "Epoch: 38, Step: 229/655, Loss: 2.215591, Accuracy: 18.59%\n",
            "Epoch: 38, Step: 230/655, Loss: 2.215934, Accuracy: 18.56%\n",
            "Epoch: 38, Step: 231/655, Loss: 2.216022, Accuracy: 18.53%\n",
            "Epoch: 38, Step: 232/655, Loss: 2.215886, Accuracy: 18.51%\n",
            "Epoch: 38, Step: 233/655, Loss: 2.215725, Accuracy: 18.52%\n",
            "Epoch: 38, Step: 234/655, Loss: 2.215549, Accuracy: 18.48%\n",
            "Epoch: 38, Step: 235/655, Loss: 2.215377, Accuracy: 18.52%\n",
            "Epoch: 38, Step: 236/655, Loss: 2.215166, Accuracy: 18.51%\n",
            "Epoch: 38, Step: 237/655, Loss: 2.215338, Accuracy: 18.53%\n",
            "Epoch: 38, Step: 238/655, Loss: 2.214816, Accuracy: 18.54%\n",
            "Epoch: 38, Step: 239/655, Loss: 2.215046, Accuracy: 18.51%\n",
            "Epoch: 38, Step: 240/655, Loss: 2.215380, Accuracy: 18.48%\n",
            "Epoch: 38, Step: 241/655, Loss: 2.215356, Accuracy: 18.49%\n",
            "Epoch: 38, Step: 242/655, Loss: 2.215217, Accuracy: 18.48%\n",
            "Epoch: 38, Step: 243/655, Loss: 2.215255, Accuracy: 18.47%\n",
            "Epoch: 38, Step: 244/655, Loss: 2.215405, Accuracy: 18.44%\n",
            "Epoch: 38, Step: 245/655, Loss: 2.215278, Accuracy: 18.46%\n",
            "Epoch: 38, Step: 246/655, Loss: 2.214600, Accuracy: 18.51%\n",
            "Epoch: 38, Step: 247/655, Loss: 2.214534, Accuracy: 18.51%\n",
            "Epoch: 38, Step: 248/655, Loss: 2.214458, Accuracy: 18.54%\n",
            "Epoch: 38, Step: 249/655, Loss: 2.214230, Accuracy: 18.52%\n",
            "Epoch: 38, Step: 250/655, Loss: 2.214262, Accuracy: 18.59%\n",
            "Epoch: 38, Step: 251/655, Loss: 2.214544, Accuracy: 18.59%\n",
            "Epoch: 38, Step: 252/655, Loss: 2.214769, Accuracy: 18.59%\n",
            "Epoch: 38, Step: 253/655, Loss: 2.214188, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 254/655, Loss: 2.213542, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 255/655, Loss: 2.214017, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 256/655, Loss: 2.213925, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 257/655, Loss: 2.214012, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 258/655, Loss: 2.213562, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 259/655, Loss: 2.213882, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 260/655, Loss: 2.213569, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 261/655, Loss: 2.213729, Accuracy: 18.59%\n",
            "Epoch: 38, Step: 262/655, Loss: 2.213741, Accuracy: 18.57%\n",
            "Epoch: 38, Step: 263/655, Loss: 2.213194, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 264/655, Loss: 2.213532, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 265/655, Loss: 2.213148, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 266/655, Loss: 2.213038, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 267/655, Loss: 2.213049, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 268/655, Loss: 2.212838, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 269/655, Loss: 2.213205, Accuracy: 18.58%\n",
            "Epoch: 38, Step: 270/655, Loss: 2.212918, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 271/655, Loss: 2.212620, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 272/655, Loss: 2.212648, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 273/655, Loss: 2.213187, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 274/655, Loss: 2.213182, Accuracy: 18.59%\n",
            "Epoch: 38, Step: 275/655, Loss: 2.213290, Accuracy: 18.57%\n",
            "Epoch: 38, Step: 276/655, Loss: 2.213108, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 277/655, Loss: 2.213271, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 278/655, Loss: 2.213084, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 279/655, Loss: 2.213062, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 280/655, Loss: 2.213059, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 281/655, Loss: 2.213123, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 282/655, Loss: 2.213300, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 283/655, Loss: 2.213054, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 284/655, Loss: 2.212659, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 285/655, Loss: 2.212550, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 286/655, Loss: 2.212499, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 287/655, Loss: 2.212303, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 288/655, Loss: 2.212273, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 289/655, Loss: 2.212162, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 290/655, Loss: 2.211872, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 291/655, Loss: 2.212018, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 292/655, Loss: 2.212329, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 293/655, Loss: 2.212174, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 294/655, Loss: 2.212792, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 295/655, Loss: 2.213044, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 296/655, Loss: 2.212832, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 297/655, Loss: 2.213071, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 298/655, Loss: 2.212744, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 299/655, Loss: 2.212218, Accuracy: 18.69%\n",
            "Epoch: 38, Step: 300/655, Loss: 2.211967, Accuracy: 18.70%\n",
            "Epoch: 38, Step: 301/655, Loss: 2.211909, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 302/655, Loss: 2.211987, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 303/655, Loss: 2.212021, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 304/655, Loss: 2.212311, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 305/655, Loss: 2.212444, Accuracy: 18.58%\n",
            "Epoch: 38, Step: 306/655, Loss: 2.212305, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 307/655, Loss: 2.212048, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 308/655, Loss: 2.212321, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 309/655, Loss: 2.212450, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 310/655, Loss: 2.212574, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 311/655, Loss: 2.212336, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 312/655, Loss: 2.212181, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 313/655, Loss: 2.211904, Accuracy: 18.69%\n",
            "Epoch: 38, Step: 314/655, Loss: 2.211721, Accuracy: 18.69%\n",
            "Epoch: 38, Step: 315/655, Loss: 2.211442, Accuracy: 18.74%\n",
            "Epoch: 38, Step: 316/655, Loss: 2.210837, Accuracy: 18.80%\n",
            "Epoch: 38, Step: 317/655, Loss: 2.211052, Accuracy: 18.80%\n",
            "Epoch: 38, Step: 318/655, Loss: 2.210849, Accuracy: 18.81%\n",
            "Epoch: 38, Step: 319/655, Loss: 2.211040, Accuracy: 18.80%\n",
            "Epoch: 38, Step: 320/655, Loss: 2.211088, Accuracy: 18.81%\n",
            "Epoch: 38, Step: 321/655, Loss: 2.210987, Accuracy: 18.78%\n",
            "Epoch: 38, Step: 322/655, Loss: 2.210763, Accuracy: 18.79%\n",
            "Epoch: 38, Step: 323/655, Loss: 2.210967, Accuracy: 18.82%\n",
            "Epoch: 38, Step: 324/655, Loss: 2.211208, Accuracy: 18.81%\n",
            "Epoch: 38, Step: 325/655, Loss: 2.211379, Accuracy: 18.81%\n",
            "Epoch: 38, Step: 326/655, Loss: 2.211222, Accuracy: 18.84%\n",
            "Epoch: 38, Step: 327/655, Loss: 2.210911, Accuracy: 18.85%\n",
            "Epoch: 38, Step: 328/655, Loss: 2.211227, Accuracy: 18.85%\n",
            "Epoch: 38, Step: 329/655, Loss: 2.210973, Accuracy: 18.88%\n",
            "Epoch: 38, Step: 330/655, Loss: 2.211109, Accuracy: 18.88%\n",
            "Epoch: 38, Step: 331/655, Loss: 2.210994, Accuracy: 18.90%\n",
            "Epoch: 38, Step: 332/655, Loss: 2.211298, Accuracy: 18.89%\n",
            "Epoch: 38, Step: 333/655, Loss: 2.211145, Accuracy: 18.91%\n",
            "Epoch: 38, Step: 334/655, Loss: 2.210804, Accuracy: 18.93%\n",
            "Epoch: 38, Step: 335/655, Loss: 2.210660, Accuracy: 18.93%\n",
            "Epoch: 38, Step: 336/655, Loss: 2.210122, Accuracy: 18.95%\n",
            "Epoch: 38, Step: 337/655, Loss: 2.210093, Accuracy: 18.94%\n",
            "Epoch: 38, Step: 338/655, Loss: 2.209949, Accuracy: 18.94%\n",
            "Epoch: 38, Step: 339/655, Loss: 2.209520, Accuracy: 18.98%\n",
            "Epoch: 38, Step: 340/655, Loss: 2.209254, Accuracy: 19.00%\n",
            "Epoch: 38, Step: 341/655, Loss: 2.209785, Accuracy: 18.98%\n",
            "Epoch: 38, Step: 342/655, Loss: 2.209524, Accuracy: 18.99%\n",
            "Epoch: 38, Step: 343/655, Loss: 2.208962, Accuracy: 19.03%\n",
            "Epoch: 38, Step: 344/655, Loss: 2.209086, Accuracy: 18.99%\n",
            "Epoch: 38, Step: 345/655, Loss: 2.208915, Accuracy: 19.03%\n",
            "Epoch: 38, Step: 346/655, Loss: 2.208834, Accuracy: 19.03%\n",
            "Epoch: 38, Step: 347/655, Loss: 2.209035, Accuracy: 19.02%\n",
            "Epoch: 38, Step: 348/655, Loss: 2.208904, Accuracy: 19.03%\n",
            "Epoch: 38, Step: 349/655, Loss: 2.208700, Accuracy: 19.03%\n",
            "Epoch: 38, Step: 350/655, Loss: 2.208864, Accuracy: 19.01%\n",
            "Epoch: 38, Step: 351/655, Loss: 2.208863, Accuracy: 19.03%\n",
            "Epoch: 38, Step: 352/655, Loss: 2.208998, Accuracy: 19.05%\n",
            "Epoch: 38, Step: 353/655, Loss: 2.208738, Accuracy: 19.05%\n",
            "Epoch: 38, Step: 354/655, Loss: 2.208702, Accuracy: 19.07%\n",
            "Epoch: 38, Step: 355/655, Loss: 2.208874, Accuracy: 19.05%\n",
            "Epoch: 38, Step: 356/655, Loss: 2.208899, Accuracy: 19.04%\n",
            "Epoch: 38, Step: 357/655, Loss: 2.208653, Accuracy: 19.02%\n",
            "Epoch: 38, Step: 358/655, Loss: 2.208687, Accuracy: 19.01%\n",
            "Epoch: 38, Step: 359/655, Loss: 2.208670, Accuracy: 19.02%\n",
            "Epoch: 38, Step: 360/655, Loss: 2.208807, Accuracy: 18.98%\n",
            "Epoch: 38, Step: 361/655, Loss: 2.208700, Accuracy: 18.98%\n",
            "Epoch: 38, Step: 362/655, Loss: 2.208250, Accuracy: 19.03%\n",
            "Epoch: 38, Step: 363/655, Loss: 2.208399, Accuracy: 19.03%\n",
            "Epoch: 38, Step: 364/655, Loss: 2.208212, Accuracy: 19.04%\n",
            "Epoch: 38, Step: 365/655, Loss: 2.208362, Accuracy: 19.05%\n",
            "Epoch: 38, Step: 366/655, Loss: 2.208283, Accuracy: 19.07%\n",
            "Epoch: 38, Step: 367/655, Loss: 2.208083, Accuracy: 19.07%\n",
            "Epoch: 38, Step: 368/655, Loss: 2.207868, Accuracy: 19.10%\n",
            "Epoch: 38, Step: 369/655, Loss: 2.208061, Accuracy: 19.09%\n",
            "Epoch: 38, Step: 370/655, Loss: 2.207959, Accuracy: 19.07%\n",
            "Epoch: 38, Step: 371/655, Loss: 2.207777, Accuracy: 19.08%\n",
            "Epoch: 38, Step: 372/655, Loss: 2.207686, Accuracy: 19.05%\n",
            "Epoch: 38, Step: 373/655, Loss: 2.207673, Accuracy: 19.05%\n",
            "Epoch: 38, Step: 374/655, Loss: 2.207690, Accuracy: 19.03%\n",
            "Epoch: 38, Step: 375/655, Loss: 2.207724, Accuracy: 19.03%\n",
            "Epoch: 38, Step: 376/655, Loss: 2.207866, Accuracy: 19.00%\n",
            "Epoch: 38, Step: 377/655, Loss: 2.207743, Accuracy: 19.02%\n",
            "Epoch: 38, Step: 378/655, Loss: 2.207850, Accuracy: 19.00%\n",
            "Epoch: 38, Step: 379/655, Loss: 2.208016, Accuracy: 18.97%\n",
            "Epoch: 38, Step: 380/655, Loss: 2.208255, Accuracy: 18.97%\n",
            "Epoch: 38, Step: 381/655, Loss: 2.208148, Accuracy: 18.98%\n",
            "Epoch: 38, Step: 382/655, Loss: 2.207973, Accuracy: 18.97%\n",
            "Epoch: 38, Step: 383/655, Loss: 2.208310, Accuracy: 18.95%\n",
            "Epoch: 38, Step: 384/655, Loss: 2.208430, Accuracy: 18.94%\n",
            "Epoch: 38, Step: 385/655, Loss: 2.208333, Accuracy: 18.94%\n",
            "Epoch: 38, Step: 386/655, Loss: 2.208278, Accuracy: 18.94%\n",
            "Epoch: 38, Step: 387/655, Loss: 2.208195, Accuracy: 18.91%\n",
            "Epoch: 38, Step: 388/655, Loss: 2.207990, Accuracy: 18.92%\n",
            "Epoch: 38, Step: 389/655, Loss: 2.207925, Accuracy: 18.90%\n",
            "Epoch: 38, Step: 390/655, Loss: 2.207355, Accuracy: 18.90%\n",
            "Epoch: 38, Step: 391/655, Loss: 2.207104, Accuracy: 18.92%\n",
            "Epoch: 38, Step: 392/655, Loss: 2.206926, Accuracy: 18.93%\n",
            "Epoch: 38, Step: 393/655, Loss: 2.206989, Accuracy: 18.92%\n",
            "Epoch: 38, Step: 394/655, Loss: 2.206812, Accuracy: 18.92%\n",
            "Epoch: 38, Step: 395/655, Loss: 2.207076, Accuracy: 18.92%\n",
            "Epoch: 38, Step: 396/655, Loss: 2.207349, Accuracy: 18.90%\n",
            "Epoch: 38, Step: 397/655, Loss: 2.207207, Accuracy: 18.90%\n",
            "Epoch: 38, Step: 398/655, Loss: 2.206920, Accuracy: 18.91%\n",
            "Epoch: 38, Step: 399/655, Loss: 2.206995, Accuracy: 18.91%\n",
            "Epoch: 38, Step: 400/655, Loss: 2.206865, Accuracy: 18.91%\n",
            "Epoch: 38, Step: 401/655, Loss: 2.206940, Accuracy: 18.91%\n",
            "Epoch: 38, Step: 402/655, Loss: 2.207387, Accuracy: 18.88%\n",
            "Epoch: 38, Step: 403/655, Loss: 2.207582, Accuracy: 18.88%\n",
            "Epoch: 38, Step: 404/655, Loss: 2.207822, Accuracy: 18.88%\n",
            "Epoch: 38, Step: 405/655, Loss: 2.207717, Accuracy: 18.86%\n",
            "Epoch: 38, Step: 406/655, Loss: 2.207868, Accuracy: 18.87%\n",
            "Epoch: 38, Step: 407/655, Loss: 2.208199, Accuracy: 18.83%\n",
            "Epoch: 38, Step: 408/655, Loss: 2.207966, Accuracy: 18.86%\n",
            "Epoch: 38, Step: 409/655, Loss: 2.208153, Accuracy: 18.85%\n",
            "Epoch: 38, Step: 410/655, Loss: 2.208189, Accuracy: 18.85%\n",
            "Epoch: 38, Step: 411/655, Loss: 2.208264, Accuracy: 18.85%\n",
            "Epoch: 38, Step: 412/655, Loss: 2.208030, Accuracy: 18.86%\n",
            "Epoch: 38, Step: 413/655, Loss: 2.207677, Accuracy: 18.86%\n",
            "Epoch: 38, Step: 414/655, Loss: 2.207969, Accuracy: 18.85%\n",
            "Epoch: 38, Step: 415/655, Loss: 2.208160, Accuracy: 18.84%\n",
            "Epoch: 38, Step: 416/655, Loss: 2.208180, Accuracy: 18.86%\n",
            "Epoch: 38, Step: 417/655, Loss: 2.208082, Accuracy: 18.85%\n",
            "Epoch: 38, Step: 418/655, Loss: 2.207795, Accuracy: 18.83%\n",
            "Epoch: 38, Step: 419/655, Loss: 2.208058, Accuracy: 18.82%\n",
            "Epoch: 38, Step: 420/655, Loss: 2.208381, Accuracy: 18.82%\n",
            "Epoch: 38, Step: 421/655, Loss: 2.208468, Accuracy: 18.80%\n",
            "Epoch: 38, Step: 422/655, Loss: 2.208401, Accuracy: 18.80%\n",
            "Epoch: 38, Step: 423/655, Loss: 2.208781, Accuracy: 18.79%\n",
            "Epoch: 38, Step: 424/655, Loss: 2.208726, Accuracy: 18.79%\n",
            "Epoch: 38, Step: 425/655, Loss: 2.208688, Accuracy: 18.80%\n",
            "Epoch: 38, Step: 426/655, Loss: 2.208354, Accuracy: 18.81%\n",
            "Epoch: 38, Step: 427/655, Loss: 2.208373, Accuracy: 18.81%\n",
            "Epoch: 38, Step: 428/655, Loss: 2.208420, Accuracy: 18.83%\n",
            "Epoch: 38, Step: 429/655, Loss: 2.208552, Accuracy: 18.82%\n",
            "Epoch: 38, Step: 430/655, Loss: 2.208293, Accuracy: 18.83%\n",
            "Epoch: 38, Step: 431/655, Loss: 2.208387, Accuracy: 18.84%\n",
            "Epoch: 38, Step: 432/655, Loss: 2.208328, Accuracy: 18.84%\n",
            "Epoch: 38, Step: 433/655, Loss: 2.208280, Accuracy: 18.84%\n",
            "Epoch: 38, Step: 434/655, Loss: 2.208383, Accuracy: 18.84%\n",
            "Epoch: 38, Step: 435/655, Loss: 2.208263, Accuracy: 18.84%\n",
            "Epoch: 38, Step: 436/655, Loss: 2.208074, Accuracy: 18.84%\n",
            "Epoch: 38, Step: 437/655, Loss: 2.208119, Accuracy: 18.82%\n",
            "Epoch: 38, Step: 438/655, Loss: 2.208027, Accuracy: 18.82%\n",
            "Epoch: 38, Step: 439/655, Loss: 2.207810, Accuracy: 18.84%\n",
            "Epoch: 38, Step: 440/655, Loss: 2.207630, Accuracy: 18.84%\n",
            "Epoch: 38, Step: 441/655, Loss: 2.207577, Accuracy: 18.83%\n",
            "Epoch: 38, Step: 442/655, Loss: 2.207166, Accuracy: 18.84%\n",
            "Epoch: 38, Step: 443/655, Loss: 2.207234, Accuracy: 18.84%\n",
            "Epoch: 38, Step: 444/655, Loss: 2.207275, Accuracy: 18.83%\n",
            "Epoch: 38, Step: 445/655, Loss: 2.207231, Accuracy: 18.85%\n",
            "Epoch: 38, Step: 446/655, Loss: 2.207570, Accuracy: 18.85%\n",
            "Epoch: 38, Step: 447/655, Loss: 2.207563, Accuracy: 18.84%\n",
            "Epoch: 38, Step: 448/655, Loss: 2.207585, Accuracy: 18.84%\n",
            "Epoch: 38, Step: 449/655, Loss: 2.208062, Accuracy: 18.81%\n",
            "Epoch: 38, Step: 450/655, Loss: 2.208055, Accuracy: 18.78%\n",
            "Epoch: 38, Step: 451/655, Loss: 2.208140, Accuracy: 18.79%\n",
            "Epoch: 38, Step: 452/655, Loss: 2.207940, Accuracy: 18.78%\n",
            "Epoch: 38, Step: 453/655, Loss: 2.207803, Accuracy: 18.77%\n",
            "Epoch: 38, Step: 454/655, Loss: 2.207503, Accuracy: 18.81%\n",
            "Epoch: 38, Step: 455/655, Loss: 2.207439, Accuracy: 18.79%\n",
            "Epoch: 38, Step: 456/655, Loss: 2.207708, Accuracy: 18.77%\n",
            "Epoch: 38, Step: 457/655, Loss: 2.207859, Accuracy: 18.78%\n",
            "Epoch: 38, Step: 458/655, Loss: 2.207811, Accuracy: 18.79%\n",
            "Epoch: 38, Step: 459/655, Loss: 2.207934, Accuracy: 18.79%\n",
            "Epoch: 38, Step: 460/655, Loss: 2.207903, Accuracy: 18.79%\n",
            "Epoch: 38, Step: 461/655, Loss: 2.207986, Accuracy: 18.80%\n",
            "Epoch: 38, Step: 462/655, Loss: 2.208056, Accuracy: 18.78%\n",
            "Epoch: 38, Step: 463/655, Loss: 2.208321, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 464/655, Loss: 2.208161, Accuracy: 18.78%\n",
            "Epoch: 38, Step: 465/655, Loss: 2.208296, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 466/655, Loss: 2.208273, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 467/655, Loss: 2.208350, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 468/655, Loss: 2.208326, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 469/655, Loss: 2.207961, Accuracy: 18.78%\n",
            "Epoch: 38, Step: 470/655, Loss: 2.207969, Accuracy: 18.80%\n",
            "Epoch: 38, Step: 471/655, Loss: 2.207850, Accuracy: 18.79%\n",
            "Epoch: 38, Step: 472/655, Loss: 2.207795, Accuracy: 18.79%\n",
            "Epoch: 38, Step: 473/655, Loss: 2.207778, Accuracy: 18.79%\n",
            "Epoch: 38, Step: 474/655, Loss: 2.207599, Accuracy: 18.80%\n",
            "Epoch: 38, Step: 475/655, Loss: 2.207463, Accuracy: 18.80%\n",
            "Epoch: 38, Step: 476/655, Loss: 2.207397, Accuracy: 18.80%\n",
            "Epoch: 38, Step: 477/655, Loss: 2.207580, Accuracy: 18.78%\n",
            "Epoch: 38, Step: 478/655, Loss: 2.207531, Accuracy: 18.77%\n",
            "Epoch: 38, Step: 479/655, Loss: 2.207814, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 480/655, Loss: 2.208054, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 481/655, Loss: 2.208347, Accuracy: 18.74%\n",
            "Epoch: 38, Step: 482/655, Loss: 2.208467, Accuracy: 18.72%\n",
            "Epoch: 38, Step: 483/655, Loss: 2.208170, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 484/655, Loss: 2.208170, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 485/655, Loss: 2.207986, Accuracy: 18.78%\n",
            "Epoch: 38, Step: 486/655, Loss: 2.208116, Accuracy: 18.77%\n",
            "Epoch: 38, Step: 487/655, Loss: 2.208063, Accuracy: 18.78%\n",
            "Epoch: 38, Step: 488/655, Loss: 2.208318, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 489/655, Loss: 2.208351, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 490/655, Loss: 2.208369, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 491/655, Loss: 2.208358, Accuracy: 18.74%\n",
            "Epoch: 38, Step: 492/655, Loss: 2.208114, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 493/655, Loss: 2.208273, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 494/655, Loss: 2.208573, Accuracy: 18.74%\n",
            "Epoch: 38, Step: 495/655, Loss: 2.208686, Accuracy: 18.74%\n",
            "Epoch: 38, Step: 496/655, Loss: 2.208658, Accuracy: 18.73%\n",
            "Epoch: 38, Step: 497/655, Loss: 2.208535, Accuracy: 18.72%\n",
            "Epoch: 38, Step: 498/655, Loss: 2.208491, Accuracy: 18.73%\n",
            "Epoch: 38, Step: 499/655, Loss: 2.208418, Accuracy: 18.73%\n",
            "Epoch: 38, Step: 500/655, Loss: 2.208665, Accuracy: 18.73%\n",
            "Epoch: 38, Step: 501/655, Loss: 2.208588, Accuracy: 18.74%\n",
            "Epoch: 38, Step: 502/655, Loss: 2.208579, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 503/655, Loss: 2.208144, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 504/655, Loss: 2.207938, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 505/655, Loss: 2.207806, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 506/655, Loss: 2.208105, Accuracy: 18.74%\n",
            "Epoch: 38, Step: 507/655, Loss: 2.208128, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 508/655, Loss: 2.208036, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 509/655, Loss: 2.208035, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 510/655, Loss: 2.208029, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 511/655, Loss: 2.207786, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 512/655, Loss: 2.207684, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 513/655, Loss: 2.207642, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 514/655, Loss: 2.207938, Accuracy: 18.74%\n",
            "Epoch: 38, Step: 515/655, Loss: 2.207697, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 516/655, Loss: 2.207855, Accuracy: 18.74%\n",
            "Epoch: 38, Step: 517/655, Loss: 2.207841, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 518/655, Loss: 2.207989, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 519/655, Loss: 2.207978, Accuracy: 18.74%\n",
            "Epoch: 38, Step: 520/655, Loss: 2.207924, Accuracy: 18.74%\n",
            "Epoch: 38, Step: 521/655, Loss: 2.208079, Accuracy: 18.73%\n",
            "Epoch: 38, Step: 522/655, Loss: 2.207901, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 523/655, Loss: 2.208064, Accuracy: 18.75%\n",
            "Epoch: 38, Step: 524/655, Loss: 2.208191, Accuracy: 18.74%\n",
            "Epoch: 38, Step: 525/655, Loss: 2.208050, Accuracy: 18.77%\n",
            "Epoch: 38, Step: 526/655, Loss: 2.207805, Accuracy: 18.77%\n",
            "Epoch: 38, Step: 527/655, Loss: 2.207865, Accuracy: 18.76%\n",
            "Epoch: 38, Step: 528/655, Loss: 2.208144, Accuracy: 18.73%\n",
            "Epoch: 38, Step: 529/655, Loss: 2.207969, Accuracy: 18.74%\n",
            "Epoch: 38, Step: 530/655, Loss: 2.207845, Accuracy: 18.73%\n",
            "Epoch: 38, Step: 531/655, Loss: 2.208008, Accuracy: 18.72%\n",
            "Epoch: 38, Step: 532/655, Loss: 2.208157, Accuracy: 18.71%\n",
            "Epoch: 38, Step: 533/655, Loss: 2.208151, Accuracy: 18.71%\n",
            "Epoch: 38, Step: 534/655, Loss: 2.207939, Accuracy: 18.72%\n",
            "Epoch: 38, Step: 535/655, Loss: 2.207941, Accuracy: 18.73%\n",
            "Epoch: 38, Step: 536/655, Loss: 2.207784, Accuracy: 18.72%\n",
            "Epoch: 38, Step: 537/655, Loss: 2.208048, Accuracy: 18.70%\n",
            "Epoch: 38, Step: 538/655, Loss: 2.208002, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 539/655, Loss: 2.207924, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 540/655, Loss: 2.208075, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 541/655, Loss: 2.208040, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 542/655, Loss: 2.208079, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 543/655, Loss: 2.208073, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 544/655, Loss: 2.208072, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 545/655, Loss: 2.207927, Accuracy: 18.69%\n",
            "Epoch: 38, Step: 546/655, Loss: 2.208002, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 547/655, Loss: 2.208134, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 548/655, Loss: 2.208396, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 549/655, Loss: 2.208275, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 550/655, Loss: 2.207994, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 551/655, Loss: 2.208027, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 552/655, Loss: 2.207971, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 553/655, Loss: 2.207953, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 554/655, Loss: 2.207942, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 555/655, Loss: 2.207726, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 556/655, Loss: 2.207723, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 557/655, Loss: 2.207672, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 558/655, Loss: 2.207695, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 559/655, Loss: 2.207584, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 560/655, Loss: 2.207354, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 561/655, Loss: 2.207224, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 562/655, Loss: 2.207479, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 563/655, Loss: 2.207529, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 564/655, Loss: 2.207436, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 565/655, Loss: 2.207353, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 566/655, Loss: 2.207628, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 567/655, Loss: 2.207941, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 568/655, Loss: 2.207968, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 569/655, Loss: 2.207926, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 570/655, Loss: 2.207829, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 571/655, Loss: 2.207975, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 572/655, Loss: 2.207918, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 573/655, Loss: 2.207757, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 574/655, Loss: 2.207715, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 575/655, Loss: 2.207507, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 576/655, Loss: 2.207345, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 577/655, Loss: 2.207148, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 578/655, Loss: 2.207262, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 579/655, Loss: 2.207420, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 580/655, Loss: 2.207549, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 581/655, Loss: 2.207568, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 582/655, Loss: 2.207612, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 583/655, Loss: 2.207710, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 584/655, Loss: 2.207383, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 585/655, Loss: 2.207174, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 586/655, Loss: 2.207159, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 587/655, Loss: 2.207089, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 588/655, Loss: 2.207078, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 589/655, Loss: 2.206966, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 590/655, Loss: 2.206842, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 591/655, Loss: 2.206837, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 592/655, Loss: 2.206530, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 593/655, Loss: 2.206550, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 594/655, Loss: 2.206422, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 595/655, Loss: 2.206267, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 596/655, Loss: 2.206083, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 597/655, Loss: 2.206107, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 598/655, Loss: 2.205907, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 599/655, Loss: 2.205812, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 600/655, Loss: 2.205732, Accuracy: 18.69%\n",
            "Epoch: 38, Step: 601/655, Loss: 2.205611, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 602/655, Loss: 2.205527, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 603/655, Loss: 2.205656, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 604/655, Loss: 2.205408, Accuracy: 18.69%\n",
            "Epoch: 38, Step: 605/655, Loss: 2.205216, Accuracy: 18.70%\n",
            "Epoch: 38, Step: 606/655, Loss: 2.205299, Accuracy: 18.70%\n",
            "Epoch: 38, Step: 607/655, Loss: 2.205463, Accuracy: 18.70%\n",
            "Epoch: 38, Step: 608/655, Loss: 2.205660, Accuracy: 18.69%\n",
            "Epoch: 38, Step: 609/655, Loss: 2.205795, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 610/655, Loss: 2.205921, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 611/655, Loss: 2.206093, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 612/655, Loss: 2.206314, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 613/655, Loss: 2.206440, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 614/655, Loss: 2.206520, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 615/655, Loss: 2.206521, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 616/655, Loss: 2.206398, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 617/655, Loss: 2.206357, Accuracy: 18.68%\n",
            "Epoch: 38, Step: 618/655, Loss: 2.206436, Accuracy: 18.67%\n",
            "Epoch: 38, Step: 619/655, Loss: 2.206738, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 620/655, Loss: 2.206669, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 621/655, Loss: 2.206722, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 622/655, Loss: 2.206857, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 623/655, Loss: 2.206979, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 624/655, Loss: 2.206840, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 625/655, Loss: 2.206848, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 626/655, Loss: 2.206954, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 627/655, Loss: 2.206946, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 628/655, Loss: 2.206873, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 629/655, Loss: 2.206763, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 630/655, Loss: 2.206918, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 631/655, Loss: 2.207035, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 632/655, Loss: 2.207194, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 633/655, Loss: 2.207088, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 634/655, Loss: 2.206868, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 635/655, Loss: 2.206812, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 636/655, Loss: 2.206696, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 637/655, Loss: 2.206630, Accuracy: 18.66%\n",
            "Epoch: 38, Step: 638/655, Loss: 2.206736, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 639/655, Loss: 2.206674, Accuracy: 18.65%\n",
            "Epoch: 38, Step: 640/655, Loss: 2.206722, Accuracy: 18.64%\n",
            "Epoch: 38, Step: 641/655, Loss: 2.206824, Accuracy: 18.63%\n",
            "Epoch: 38, Step: 642/655, Loss: 2.206817, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 643/655, Loss: 2.206831, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 644/655, Loss: 2.207142, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 645/655, Loss: 2.207371, Accuracy: 18.59%\n",
            "Epoch: 38, Step: 646/655, Loss: 2.207207, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 647/655, Loss: 2.207349, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 648/655, Loss: 2.207431, Accuracy: 18.61%\n",
            "Epoch: 38, Step: 649/655, Loss: 2.207300, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 650/655, Loss: 2.207074, Accuracy: 18.62%\n",
            "Epoch: 38, Step: 651/655, Loss: 2.207364, Accuracy: 18.59%\n",
            "Epoch: 38, Step: 652/655, Loss: 2.207397, Accuracy: 18.59%\n",
            "Epoch: 38, Step: 653/655, Loss: 2.207364, Accuracy: 18.60%\n",
            "Epoch: 38, Step: 654/655, Loss: 2.207531, Accuracy: 18.58%\n",
            "Epoch: 38, Step: 655/655, Loss: 2.207482, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 1/655, Loss: 2.274269, Accuracy: 28.12%\n",
            "Epoch: 39, Step: 2/655, Loss: 2.223089, Accuracy: 23.44%\n",
            "Epoch: 39, Step: 3/655, Loss: 2.231825, Accuracy: 20.83%\n",
            "Epoch: 39, Step: 4/655, Loss: 2.213303, Accuracy: 21.88%\n",
            "Epoch: 39, Step: 5/655, Loss: 2.222594, Accuracy: 18.75%\n",
            "Epoch: 39, Step: 6/655, Loss: 2.237602, Accuracy: 18.75%\n",
            "Epoch: 39, Step: 7/655, Loss: 2.232567, Accuracy: 18.30%\n",
            "Epoch: 39, Step: 8/655, Loss: 2.221307, Accuracy: 19.53%\n",
            "Epoch: 39, Step: 9/655, Loss: 2.205869, Accuracy: 20.14%\n",
            "Epoch: 39, Step: 10/655, Loss: 2.215974, Accuracy: 18.75%\n",
            "Epoch: 39, Step: 11/655, Loss: 2.213592, Accuracy: 18.75%\n",
            "Epoch: 39, Step: 12/655, Loss: 2.210573, Accuracy: 18.75%\n",
            "Epoch: 39, Step: 13/655, Loss: 2.213553, Accuracy: 18.27%\n",
            "Epoch: 39, Step: 14/655, Loss: 2.207990, Accuracy: 18.75%\n",
            "Epoch: 39, Step: 15/655, Loss: 2.212177, Accuracy: 18.75%\n",
            "Epoch: 39, Step: 16/655, Loss: 2.216963, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 17/655, Loss: 2.214506, Accuracy: 18.93%\n",
            "Epoch: 39, Step: 18/655, Loss: 2.212389, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 19/655, Loss: 2.212447, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 20/655, Loss: 2.215332, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 21/655, Loss: 2.223752, Accuracy: 18.01%\n",
            "Epoch: 39, Step: 22/655, Loss: 2.226795, Accuracy: 17.33%\n",
            "Epoch: 39, Step: 23/655, Loss: 2.229358, Accuracy: 17.12%\n",
            "Epoch: 39, Step: 24/655, Loss: 2.228664, Accuracy: 17.32%\n",
            "Epoch: 39, Step: 25/655, Loss: 2.217388, Accuracy: 17.75%\n",
            "Epoch: 39, Step: 26/655, Loss: 2.219610, Accuracy: 17.79%\n",
            "Epoch: 39, Step: 27/655, Loss: 2.222603, Accuracy: 17.82%\n",
            "Epoch: 39, Step: 28/655, Loss: 2.221904, Accuracy: 17.75%\n",
            "Epoch: 39, Step: 29/655, Loss: 2.216534, Accuracy: 17.78%\n",
            "Epoch: 39, Step: 30/655, Loss: 2.214220, Accuracy: 18.02%\n",
            "Epoch: 39, Step: 31/655, Loss: 2.216722, Accuracy: 17.74%\n",
            "Epoch: 39, Step: 32/655, Loss: 2.219715, Accuracy: 17.68%\n",
            "Epoch: 39, Step: 33/655, Loss: 2.217170, Accuracy: 17.71%\n",
            "Epoch: 39, Step: 34/655, Loss: 2.213709, Accuracy: 17.92%\n",
            "Epoch: 39, Step: 35/655, Loss: 2.209499, Accuracy: 17.86%\n",
            "Epoch: 39, Step: 36/655, Loss: 2.212224, Accuracy: 17.80%\n",
            "Epoch: 39, Step: 37/655, Loss: 2.214495, Accuracy: 17.48%\n",
            "Epoch: 39, Step: 38/655, Loss: 2.212714, Accuracy: 17.76%\n",
            "Epoch: 39, Step: 39/655, Loss: 2.212754, Accuracy: 17.95%\n",
            "Epoch: 39, Step: 40/655, Loss: 2.212642, Accuracy: 17.89%\n",
            "Epoch: 39, Step: 41/655, Loss: 2.215281, Accuracy: 17.91%\n",
            "Epoch: 39, Step: 42/655, Loss: 2.217660, Accuracy: 18.15%\n",
            "Epoch: 39, Step: 43/655, Loss: 2.219334, Accuracy: 17.95%\n",
            "Epoch: 39, Step: 44/655, Loss: 2.217626, Accuracy: 18.11%\n",
            "Epoch: 39, Step: 45/655, Loss: 2.216975, Accuracy: 18.12%\n",
            "Epoch: 39, Step: 46/655, Loss: 2.217539, Accuracy: 18.14%\n",
            "Epoch: 39, Step: 47/655, Loss: 2.214824, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 48/655, Loss: 2.211139, Accuracy: 18.75%\n",
            "Epoch: 39, Step: 49/655, Loss: 2.208080, Accuracy: 18.75%\n",
            "Epoch: 39, Step: 50/655, Loss: 2.210234, Accuracy: 18.62%\n",
            "Epoch: 39, Step: 51/655, Loss: 2.211377, Accuracy: 18.50%\n",
            "Epoch: 39, Step: 52/655, Loss: 2.211622, Accuracy: 18.63%\n",
            "Epoch: 39, Step: 53/655, Loss: 2.210968, Accuracy: 18.81%\n",
            "Epoch: 39, Step: 54/655, Loss: 2.208903, Accuracy: 18.87%\n",
            "Epoch: 39, Step: 55/655, Loss: 2.210711, Accuracy: 18.81%\n",
            "Epoch: 39, Step: 56/655, Loss: 2.212064, Accuracy: 18.69%\n",
            "Epoch: 39, Step: 57/655, Loss: 2.211697, Accuracy: 18.86%\n",
            "Epoch: 39, Step: 58/655, Loss: 2.209609, Accuracy: 18.80%\n",
            "Epoch: 39, Step: 59/655, Loss: 2.208964, Accuracy: 18.86%\n",
            "Epoch: 39, Step: 60/655, Loss: 2.206620, Accuracy: 18.80%\n",
            "Epoch: 39, Step: 61/655, Loss: 2.206674, Accuracy: 18.80%\n",
            "Epoch: 39, Step: 62/655, Loss: 2.205282, Accuracy: 19.05%\n",
            "Epoch: 39, Step: 63/655, Loss: 2.205966, Accuracy: 18.90%\n",
            "Epoch: 39, Step: 64/655, Loss: 2.205593, Accuracy: 18.90%\n",
            "Epoch: 39, Step: 65/655, Loss: 2.204871, Accuracy: 18.89%\n",
            "Epoch: 39, Step: 66/655, Loss: 2.206256, Accuracy: 18.80%\n",
            "Epoch: 39, Step: 67/655, Loss: 2.205880, Accuracy: 18.66%\n",
            "Epoch: 39, Step: 68/655, Loss: 2.205122, Accuracy: 18.66%\n",
            "Epoch: 39, Step: 69/655, Loss: 2.202869, Accuracy: 18.84%\n",
            "Epoch: 39, Step: 70/655, Loss: 2.201573, Accuracy: 18.84%\n",
            "Epoch: 39, Step: 71/655, Loss: 2.202869, Accuracy: 18.93%\n",
            "Epoch: 39, Step: 72/655, Loss: 2.202729, Accuracy: 18.97%\n",
            "Epoch: 39, Step: 73/655, Loss: 2.199541, Accuracy: 19.26%\n",
            "Epoch: 39, Step: 74/655, Loss: 2.198971, Accuracy: 19.30%\n",
            "Epoch: 39, Step: 75/655, Loss: 2.200613, Accuracy: 19.17%\n",
            "Epoch: 39, Step: 76/655, Loss: 2.202022, Accuracy: 19.16%\n",
            "Epoch: 39, Step: 77/655, Loss: 2.201174, Accuracy: 19.24%\n",
            "Epoch: 39, Step: 78/655, Loss: 2.200456, Accuracy: 19.27%\n",
            "Epoch: 39, Step: 79/655, Loss: 2.201578, Accuracy: 19.26%\n",
            "Epoch: 39, Step: 80/655, Loss: 2.200734, Accuracy: 19.34%\n",
            "Epoch: 39, Step: 81/655, Loss: 2.200699, Accuracy: 19.29%\n",
            "Epoch: 39, Step: 82/655, Loss: 2.201118, Accuracy: 19.25%\n",
            "Epoch: 39, Step: 83/655, Loss: 2.202348, Accuracy: 19.05%\n",
            "Epoch: 39, Step: 84/655, Loss: 2.202862, Accuracy: 19.08%\n",
            "Epoch: 39, Step: 85/655, Loss: 2.203657, Accuracy: 19.04%\n",
            "Epoch: 39, Step: 86/655, Loss: 2.203046, Accuracy: 19.11%\n",
            "Epoch: 39, Step: 87/655, Loss: 2.202339, Accuracy: 19.00%\n",
            "Epoch: 39, Step: 88/655, Loss: 2.202464, Accuracy: 18.96%\n",
            "Epoch: 39, Step: 89/655, Loss: 2.201154, Accuracy: 19.03%\n",
            "Epoch: 39, Step: 90/655, Loss: 2.202303, Accuracy: 19.03%\n",
            "Epoch: 39, Step: 91/655, Loss: 2.203399, Accuracy: 18.96%\n",
            "Epoch: 39, Step: 92/655, Loss: 2.203827, Accuracy: 18.92%\n",
            "Epoch: 39, Step: 93/655, Loss: 2.204580, Accuracy: 18.95%\n",
            "Epoch: 39, Step: 94/655, Loss: 2.204764, Accuracy: 18.98%\n",
            "Epoch: 39, Step: 95/655, Loss: 2.203896, Accuracy: 18.98%\n",
            "Epoch: 39, Step: 96/655, Loss: 2.204849, Accuracy: 18.95%\n",
            "Epoch: 39, Step: 97/655, Loss: 2.204328, Accuracy: 18.98%\n",
            "Epoch: 39, Step: 98/655, Loss: 2.204047, Accuracy: 19.04%\n",
            "Epoch: 39, Step: 99/655, Loss: 2.203471, Accuracy: 19.07%\n",
            "Epoch: 39, Step: 100/655, Loss: 2.203128, Accuracy: 19.03%\n",
            "Epoch: 39, Step: 101/655, Loss: 2.204554, Accuracy: 18.94%\n",
            "Epoch: 39, Step: 102/655, Loss: 2.204479, Accuracy: 18.96%\n",
            "Epoch: 39, Step: 103/655, Loss: 2.204697, Accuracy: 18.99%\n",
            "Epoch: 39, Step: 104/655, Loss: 2.205544, Accuracy: 18.93%\n",
            "Epoch: 39, Step: 105/655, Loss: 2.205469, Accuracy: 18.96%\n",
            "Epoch: 39, Step: 106/655, Loss: 2.205242, Accuracy: 18.93%\n",
            "Epoch: 39, Step: 107/655, Loss: 2.205434, Accuracy: 18.93%\n",
            "Epoch: 39, Step: 108/655, Loss: 2.205135, Accuracy: 18.92%\n",
            "Epoch: 39, Step: 109/655, Loss: 2.205851, Accuracy: 18.86%\n",
            "Epoch: 39, Step: 110/655, Loss: 2.205481, Accuracy: 18.78%\n",
            "Epoch: 39, Step: 111/655, Loss: 2.205042, Accuracy: 18.72%\n",
            "Epoch: 39, Step: 112/655, Loss: 2.205920, Accuracy: 18.78%\n",
            "Epoch: 39, Step: 113/655, Loss: 2.206938, Accuracy: 18.67%\n",
            "Epoch: 39, Step: 114/655, Loss: 2.207201, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 115/655, Loss: 2.207557, Accuracy: 18.67%\n",
            "Epoch: 39, Step: 116/655, Loss: 2.206415, Accuracy: 18.72%\n",
            "Epoch: 39, Step: 117/655, Loss: 2.206006, Accuracy: 18.70%\n",
            "Epoch: 39, Step: 118/655, Loss: 2.206230, Accuracy: 18.72%\n",
            "Epoch: 39, Step: 119/655, Loss: 2.205866, Accuracy: 18.80%\n",
            "Epoch: 39, Step: 120/655, Loss: 2.205305, Accuracy: 18.75%\n",
            "Epoch: 39, Step: 121/655, Loss: 2.205021, Accuracy: 18.70%\n",
            "Epoch: 39, Step: 122/655, Loss: 2.205402, Accuracy: 18.72%\n",
            "Epoch: 39, Step: 123/655, Loss: 2.206182, Accuracy: 18.67%\n",
            "Epoch: 39, Step: 124/655, Loss: 2.207257, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 125/655, Loss: 2.208470, Accuracy: 18.57%\n",
            "Epoch: 39, Step: 126/655, Loss: 2.208478, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 127/655, Loss: 2.208785, Accuracy: 18.53%\n",
            "Epoch: 39, Step: 128/655, Loss: 2.208976, Accuracy: 18.63%\n",
            "Epoch: 39, Step: 129/655, Loss: 2.208297, Accuracy: 18.68%\n",
            "Epoch: 39, Step: 130/655, Loss: 2.207560, Accuracy: 18.68%\n",
            "Epoch: 39, Step: 131/655, Loss: 2.207213, Accuracy: 18.75%\n",
            "Epoch: 39, Step: 132/655, Loss: 2.208123, Accuracy: 18.75%\n",
            "Epoch: 39, Step: 133/655, Loss: 2.209077, Accuracy: 18.66%\n",
            "Epoch: 39, Step: 134/655, Loss: 2.209675, Accuracy: 18.63%\n",
            "Epoch: 39, Step: 135/655, Loss: 2.208912, Accuracy: 18.70%\n",
            "Epoch: 39, Step: 136/655, Loss: 2.209387, Accuracy: 18.68%\n",
            "Epoch: 39, Step: 137/655, Loss: 2.209753, Accuracy: 18.70%\n",
            "Epoch: 39, Step: 138/655, Loss: 2.210129, Accuracy: 18.68%\n",
            "Epoch: 39, Step: 139/655, Loss: 2.210481, Accuracy: 18.68%\n",
            "Epoch: 39, Step: 140/655, Loss: 2.210882, Accuracy: 18.71%\n",
            "Epoch: 39, Step: 141/655, Loss: 2.210715, Accuracy: 18.71%\n",
            "Epoch: 39, Step: 142/655, Loss: 2.210159, Accuracy: 18.77%\n",
            "Epoch: 39, Step: 143/655, Loss: 2.210588, Accuracy: 18.77%\n",
            "Epoch: 39, Step: 144/655, Loss: 2.210764, Accuracy: 18.71%\n",
            "Epoch: 39, Step: 145/655, Loss: 2.210220, Accuracy: 18.73%\n",
            "Epoch: 39, Step: 146/655, Loss: 2.209931, Accuracy: 18.69%\n",
            "Epoch: 39, Step: 147/655, Loss: 2.210175, Accuracy: 18.66%\n",
            "Epoch: 39, Step: 148/655, Loss: 2.209784, Accuracy: 18.67%\n",
            "Epoch: 39, Step: 149/655, Loss: 2.209761, Accuracy: 18.65%\n",
            "Epoch: 39, Step: 150/655, Loss: 2.209452, Accuracy: 18.65%\n",
            "Epoch: 39, Step: 151/655, Loss: 2.209110, Accuracy: 18.69%\n",
            "Epoch: 39, Step: 152/655, Loss: 2.209175, Accuracy: 18.67%\n",
            "Epoch: 39, Step: 153/655, Loss: 2.208887, Accuracy: 18.63%\n",
            "Epoch: 39, Step: 154/655, Loss: 2.208577, Accuracy: 18.65%\n",
            "Epoch: 39, Step: 155/655, Loss: 2.208846, Accuracy: 18.63%\n",
            "Epoch: 39, Step: 156/655, Loss: 2.209474, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 157/655, Loss: 2.210463, Accuracy: 18.53%\n",
            "Epoch: 39, Step: 158/655, Loss: 2.210565, Accuracy: 18.49%\n",
            "Epoch: 39, Step: 159/655, Loss: 2.211024, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 160/655, Loss: 2.211646, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 161/655, Loss: 2.211074, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 162/655, Loss: 2.211306, Accuracy: 18.46%\n",
            "Epoch: 39, Step: 163/655, Loss: 2.211085, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 164/655, Loss: 2.211335, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 165/655, Loss: 2.211252, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 166/655, Loss: 2.211139, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 167/655, Loss: 2.211442, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 168/655, Loss: 2.210507, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 169/655, Loss: 2.209906, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 170/655, Loss: 2.209505, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 171/655, Loss: 2.209897, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 172/655, Loss: 2.210376, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 173/655, Loss: 2.210835, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 174/655, Loss: 2.210764, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 175/655, Loss: 2.211057, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 176/655, Loss: 2.210688, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 177/655, Loss: 2.210455, Accuracy: 18.49%\n",
            "Epoch: 39, Step: 178/655, Loss: 2.211045, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 179/655, Loss: 2.211813, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 180/655, Loss: 2.211444, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 181/655, Loss: 2.211680, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 182/655, Loss: 2.212870, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 183/655, Loss: 2.213875, Accuracy: 18.29%\n",
            "Epoch: 39, Step: 184/655, Loss: 2.213033, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 185/655, Loss: 2.213245, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 186/655, Loss: 2.212715, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 187/655, Loss: 2.212807, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 188/655, Loss: 2.213228, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 189/655, Loss: 2.213831, Accuracy: 18.34%\n",
            "Epoch: 39, Step: 190/655, Loss: 2.213839, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 191/655, Loss: 2.213814, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 192/655, Loss: 2.214049, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 193/655, Loss: 2.213836, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 194/655, Loss: 2.213768, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 195/655, Loss: 2.214019, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 196/655, Loss: 2.213652, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 197/655, Loss: 2.213927, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 198/655, Loss: 2.213250, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 199/655, Loss: 2.213306, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 200/655, Loss: 2.213043, Accuracy: 18.34%\n",
            "Epoch: 39, Step: 201/655, Loss: 2.212810, Accuracy: 18.31%\n",
            "Epoch: 39, Step: 202/655, Loss: 2.213486, Accuracy: 18.33%\n",
            "Epoch: 39, Step: 203/655, Loss: 2.213839, Accuracy: 18.30%\n",
            "Epoch: 39, Step: 204/655, Loss: 2.213423, Accuracy: 18.32%\n",
            "Epoch: 39, Step: 205/655, Loss: 2.213552, Accuracy: 18.34%\n",
            "Epoch: 39, Step: 206/655, Loss: 2.213397, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 207/655, Loss: 2.214021, Accuracy: 18.30%\n",
            "Epoch: 39, Step: 208/655, Loss: 2.213643, Accuracy: 18.31%\n",
            "Epoch: 39, Step: 209/655, Loss: 2.213853, Accuracy: 18.32%\n",
            "Epoch: 39, Step: 210/655, Loss: 2.213603, Accuracy: 18.33%\n",
            "Epoch: 39, Step: 211/655, Loss: 2.213209, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 212/655, Loss: 2.212869, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 213/655, Loss: 2.212842, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 214/655, Loss: 2.212965, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 215/655, Loss: 2.212782, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 216/655, Loss: 2.212201, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 217/655, Loss: 2.211876, Accuracy: 18.46%\n",
            "Epoch: 39, Step: 218/655, Loss: 2.212162, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 219/655, Loss: 2.212223, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 220/655, Loss: 2.212133, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 221/655, Loss: 2.211977, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 222/655, Loss: 2.212769, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 223/655, Loss: 2.213097, Accuracy: 18.34%\n",
            "Epoch: 39, Step: 224/655, Loss: 2.212677, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 225/655, Loss: 2.213248, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 226/655, Loss: 2.213032, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 227/655, Loss: 2.212962, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 228/655, Loss: 2.212425, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 229/655, Loss: 2.211874, Accuracy: 18.50%\n",
            "Epoch: 39, Step: 230/655, Loss: 2.212297, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 231/655, Loss: 2.212318, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 232/655, Loss: 2.212343, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 233/655, Loss: 2.212195, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 234/655, Loss: 2.211312, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 235/655, Loss: 2.212025, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 236/655, Loss: 2.211475, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 237/655, Loss: 2.211177, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 238/655, Loss: 2.210800, Accuracy: 18.57%\n",
            "Epoch: 39, Step: 239/655, Loss: 2.211269, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 240/655, Loss: 2.211050, Accuracy: 18.52%\n",
            "Epoch: 39, Step: 241/655, Loss: 2.210598, Accuracy: 18.57%\n",
            "Epoch: 39, Step: 242/655, Loss: 2.210896, Accuracy: 18.53%\n",
            "Epoch: 39, Step: 243/655, Loss: 2.211197, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 244/655, Loss: 2.211389, Accuracy: 18.46%\n",
            "Epoch: 39, Step: 245/655, Loss: 2.211144, Accuracy: 18.49%\n",
            "Epoch: 39, Step: 246/655, Loss: 2.210832, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 247/655, Loss: 2.210431, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 248/655, Loss: 2.209835, Accuracy: 18.52%\n",
            "Epoch: 39, Step: 249/655, Loss: 2.209699, Accuracy: 18.54%\n",
            "Epoch: 39, Step: 250/655, Loss: 2.210027, Accuracy: 18.54%\n",
            "Epoch: 39, Step: 251/655, Loss: 2.209625, Accuracy: 18.55%\n",
            "Epoch: 39, Step: 252/655, Loss: 2.209604, Accuracy: 18.56%\n",
            "Epoch: 39, Step: 253/655, Loss: 2.209937, Accuracy: 18.55%\n",
            "Epoch: 39, Step: 254/655, Loss: 2.210383, Accuracy: 18.53%\n",
            "Epoch: 39, Step: 255/655, Loss: 2.210228, Accuracy: 18.49%\n",
            "Epoch: 39, Step: 256/655, Loss: 2.210875, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 257/655, Loss: 2.211117, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 258/655, Loss: 2.211149, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 259/655, Loss: 2.211475, Accuracy: 18.35%\n",
            "Epoch: 39, Step: 260/655, Loss: 2.211759, Accuracy: 18.35%\n",
            "Epoch: 39, Step: 261/655, Loss: 2.212493, Accuracy: 18.33%\n",
            "Epoch: 39, Step: 262/655, Loss: 2.212477, Accuracy: 18.32%\n",
            "Epoch: 39, Step: 263/655, Loss: 2.212188, Accuracy: 18.35%\n",
            "Epoch: 39, Step: 264/655, Loss: 2.212089, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 265/655, Loss: 2.212010, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 266/655, Loss: 2.212048, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 267/655, Loss: 2.211969, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 268/655, Loss: 2.211755, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 269/655, Loss: 2.212101, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 270/655, Loss: 2.212467, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 271/655, Loss: 2.212486, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 272/655, Loss: 2.212338, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 273/655, Loss: 2.212095, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 274/655, Loss: 2.212141, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 275/655, Loss: 2.212102, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 276/655, Loss: 2.212389, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 277/655, Loss: 2.212118, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 278/655, Loss: 2.212200, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 279/655, Loss: 2.212644, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 280/655, Loss: 2.212782, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 281/655, Loss: 2.212677, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 282/655, Loss: 2.212536, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 283/655, Loss: 2.212717, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 284/655, Loss: 2.212770, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 285/655, Loss: 2.212455, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 286/655, Loss: 2.212239, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 287/655, Loss: 2.212629, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 288/655, Loss: 2.213069, Accuracy: 18.35%\n",
            "Epoch: 39, Step: 289/655, Loss: 2.213108, Accuracy: 18.34%\n",
            "Epoch: 39, Step: 290/655, Loss: 2.212792, Accuracy: 18.34%\n",
            "Epoch: 39, Step: 291/655, Loss: 2.212867, Accuracy: 18.35%\n",
            "Epoch: 39, Step: 292/655, Loss: 2.212537, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 293/655, Loss: 2.212472, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 294/655, Loss: 2.212587, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 295/655, Loss: 2.212541, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 296/655, Loss: 2.212643, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 297/655, Loss: 2.212965, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 298/655, Loss: 2.213209, Accuracy: 18.34%\n",
            "Epoch: 39, Step: 299/655, Loss: 2.213153, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 300/655, Loss: 2.212605, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 301/655, Loss: 2.212550, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 302/655, Loss: 2.212569, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 303/655, Loss: 2.213047, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 304/655, Loss: 2.212828, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 305/655, Loss: 2.212784, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 306/655, Loss: 2.212782, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 307/655, Loss: 2.212535, Accuracy: 18.50%\n",
            "Epoch: 39, Step: 308/655, Loss: 2.212654, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 309/655, Loss: 2.212722, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 310/655, Loss: 2.213265, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 311/655, Loss: 2.213358, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 312/655, Loss: 2.213372, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 313/655, Loss: 2.213363, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 314/655, Loss: 2.213222, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 315/655, Loss: 2.212985, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 316/655, Loss: 2.212943, Accuracy: 18.46%\n",
            "Epoch: 39, Step: 317/655, Loss: 2.213183, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 318/655, Loss: 2.213452, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 319/655, Loss: 2.213376, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 320/655, Loss: 2.213177, Accuracy: 18.46%\n",
            "Epoch: 39, Step: 321/655, Loss: 2.213598, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 322/655, Loss: 2.213658, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 323/655, Loss: 2.213810, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 324/655, Loss: 2.213581, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 325/655, Loss: 2.213570, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 326/655, Loss: 2.212936, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 327/655, Loss: 2.212660, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 328/655, Loss: 2.212193, Accuracy: 18.49%\n",
            "Epoch: 39, Step: 329/655, Loss: 2.211813, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 330/655, Loss: 2.212000, Accuracy: 18.50%\n",
            "Epoch: 39, Step: 331/655, Loss: 2.212225, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 332/655, Loss: 2.212279, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 333/655, Loss: 2.212200, Accuracy: 18.50%\n",
            "Epoch: 39, Step: 334/655, Loss: 2.212214, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 335/655, Loss: 2.212412, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 336/655, Loss: 2.212471, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 337/655, Loss: 2.212035, Accuracy: 18.52%\n",
            "Epoch: 39, Step: 338/655, Loss: 2.212081, Accuracy: 18.50%\n",
            "Epoch: 39, Step: 339/655, Loss: 2.211970, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 340/655, Loss: 2.211863, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 341/655, Loss: 2.211925, Accuracy: 18.52%\n",
            "Epoch: 39, Step: 342/655, Loss: 2.211692, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 343/655, Loss: 2.211352, Accuracy: 18.55%\n",
            "Epoch: 39, Step: 344/655, Loss: 2.211206, Accuracy: 18.55%\n",
            "Epoch: 39, Step: 345/655, Loss: 2.211301, Accuracy: 18.53%\n",
            "Epoch: 39, Step: 346/655, Loss: 2.211314, Accuracy: 18.53%\n",
            "Epoch: 39, Step: 347/655, Loss: 2.211126, Accuracy: 18.54%\n",
            "Epoch: 39, Step: 348/655, Loss: 2.211410, Accuracy: 18.53%\n",
            "Epoch: 39, Step: 349/655, Loss: 2.211229, Accuracy: 18.55%\n",
            "Epoch: 39, Step: 350/655, Loss: 2.210969, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 351/655, Loss: 2.210947, Accuracy: 18.62%\n",
            "Epoch: 39, Step: 352/655, Loss: 2.211252, Accuracy: 18.59%\n",
            "Epoch: 39, Step: 353/655, Loss: 2.210928, Accuracy: 18.62%\n",
            "Epoch: 39, Step: 354/655, Loss: 2.210908, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 355/655, Loss: 2.210730, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 356/655, Loss: 2.210779, Accuracy: 18.57%\n",
            "Epoch: 39, Step: 357/655, Loss: 2.210431, Accuracy: 18.56%\n",
            "Epoch: 39, Step: 358/655, Loss: 2.210579, Accuracy: 18.54%\n",
            "Epoch: 39, Step: 359/655, Loss: 2.210919, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 360/655, Loss: 2.210481, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 361/655, Loss: 2.210095, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 362/655, Loss: 2.210269, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 363/655, Loss: 2.210304, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 364/655, Loss: 2.210803, Accuracy: 18.59%\n",
            "Epoch: 39, Step: 365/655, Loss: 2.211013, Accuracy: 18.57%\n",
            "Epoch: 39, Step: 366/655, Loss: 2.210903, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 367/655, Loss: 2.211024, Accuracy: 18.62%\n",
            "Epoch: 39, Step: 368/655, Loss: 2.211151, Accuracy: 18.63%\n",
            "Epoch: 39, Step: 369/655, Loss: 2.210992, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 370/655, Loss: 2.210948, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 371/655, Loss: 2.211017, Accuracy: 18.62%\n",
            "Epoch: 39, Step: 372/655, Loss: 2.210873, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 373/655, Loss: 2.210719, Accuracy: 18.62%\n",
            "Epoch: 39, Step: 374/655, Loss: 2.210919, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 375/655, Loss: 2.210665, Accuracy: 18.59%\n",
            "Epoch: 39, Step: 376/655, Loss: 2.210872, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 377/655, Loss: 2.210785, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 378/655, Loss: 2.211144, Accuracy: 18.56%\n",
            "Epoch: 39, Step: 379/655, Loss: 2.211160, Accuracy: 18.55%\n",
            "Epoch: 39, Step: 380/655, Loss: 2.211171, Accuracy: 18.54%\n",
            "Epoch: 39, Step: 381/655, Loss: 2.211346, Accuracy: 18.57%\n",
            "Epoch: 39, Step: 382/655, Loss: 2.211583, Accuracy: 18.54%\n",
            "Epoch: 39, Step: 383/655, Loss: 2.211521, Accuracy: 18.54%\n",
            "Epoch: 39, Step: 384/655, Loss: 2.211685, Accuracy: 18.55%\n",
            "Epoch: 39, Step: 385/655, Loss: 2.211486, Accuracy: 18.56%\n",
            "Epoch: 39, Step: 386/655, Loss: 2.211496, Accuracy: 18.56%\n",
            "Epoch: 39, Step: 387/655, Loss: 2.211338, Accuracy: 18.56%\n",
            "Epoch: 39, Step: 388/655, Loss: 2.211506, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 389/655, Loss: 2.211607, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 390/655, Loss: 2.211432, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 391/655, Loss: 2.211305, Accuracy: 18.59%\n",
            "Epoch: 39, Step: 392/655, Loss: 2.211359, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 393/655, Loss: 2.211146, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 394/655, Loss: 2.211020, Accuracy: 18.63%\n",
            "Epoch: 39, Step: 395/655, Loss: 2.210959, Accuracy: 18.62%\n",
            "Epoch: 39, Step: 396/655, Loss: 2.210785, Accuracy: 18.62%\n",
            "Epoch: 39, Step: 397/655, Loss: 2.210633, Accuracy: 18.65%\n",
            "Epoch: 39, Step: 398/655, Loss: 2.210461, Accuracy: 18.65%\n",
            "Epoch: 39, Step: 399/655, Loss: 2.210184, Accuracy: 18.66%\n",
            "Epoch: 39, Step: 400/655, Loss: 2.210183, Accuracy: 18.65%\n",
            "Epoch: 39, Step: 401/655, Loss: 2.210146, Accuracy: 18.63%\n",
            "Epoch: 39, Step: 402/655, Loss: 2.209806, Accuracy: 18.63%\n",
            "Epoch: 39, Step: 403/655, Loss: 2.209571, Accuracy: 18.64%\n",
            "Epoch: 39, Step: 404/655, Loss: 2.209724, Accuracy: 18.62%\n",
            "Epoch: 39, Step: 405/655, Loss: 2.209591, Accuracy: 18.62%\n",
            "Epoch: 39, Step: 406/655, Loss: 2.209698, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 407/655, Loss: 2.209554, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 408/655, Loss: 2.209378, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 409/655, Loss: 2.209596, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 410/655, Loss: 2.209482, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 411/655, Loss: 2.209495, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 412/655, Loss: 2.209395, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 413/655, Loss: 2.209508, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 414/655, Loss: 2.209247, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 415/655, Loss: 2.209089, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 416/655, Loss: 2.209292, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 417/655, Loss: 2.208880, Accuracy: 18.59%\n",
            "Epoch: 39, Step: 418/655, Loss: 2.209031, Accuracy: 18.59%\n",
            "Epoch: 39, Step: 419/655, Loss: 2.208615, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 420/655, Loss: 2.208392, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 421/655, Loss: 2.208454, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 422/655, Loss: 2.208562, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 423/655, Loss: 2.208477, Accuracy: 18.62%\n",
            "Epoch: 39, Step: 424/655, Loss: 2.208516, Accuracy: 18.63%\n",
            "Epoch: 39, Step: 425/655, Loss: 2.208411, Accuracy: 18.62%\n",
            "Epoch: 39, Step: 426/655, Loss: 2.208541, Accuracy: 18.63%\n",
            "Epoch: 39, Step: 427/655, Loss: 2.208504, Accuracy: 18.63%\n",
            "Epoch: 39, Step: 428/655, Loss: 2.208366, Accuracy: 18.63%\n",
            "Epoch: 39, Step: 429/655, Loss: 2.208505, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 430/655, Loss: 2.208500, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 431/655, Loss: 2.208605, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 432/655, Loss: 2.208558, Accuracy: 18.59%\n",
            "Epoch: 39, Step: 433/655, Loss: 2.208536, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 434/655, Loss: 2.208301, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 435/655, Loss: 2.208402, Accuracy: 18.62%\n",
            "Epoch: 39, Step: 436/655, Loss: 2.208495, Accuracy: 18.62%\n",
            "Epoch: 39, Step: 437/655, Loss: 2.208176, Accuracy: 18.65%\n",
            "Epoch: 39, Step: 438/655, Loss: 2.208195, Accuracy: 18.68%\n",
            "Epoch: 39, Step: 439/655, Loss: 2.208416, Accuracy: 18.66%\n",
            "Epoch: 39, Step: 440/655, Loss: 2.208425, Accuracy: 18.68%\n",
            "Epoch: 39, Step: 441/655, Loss: 2.208329, Accuracy: 18.69%\n",
            "Epoch: 39, Step: 442/655, Loss: 2.208110, Accuracy: 18.68%\n",
            "Epoch: 39, Step: 443/655, Loss: 2.208192, Accuracy: 18.68%\n",
            "Epoch: 39, Step: 444/655, Loss: 2.208126, Accuracy: 18.70%\n",
            "Epoch: 39, Step: 445/655, Loss: 2.208153, Accuracy: 18.69%\n",
            "Epoch: 39, Step: 446/655, Loss: 2.208189, Accuracy: 18.68%\n",
            "Epoch: 39, Step: 447/655, Loss: 2.208247, Accuracy: 18.68%\n",
            "Epoch: 39, Step: 448/655, Loss: 2.208425, Accuracy: 18.67%\n",
            "Epoch: 39, Step: 449/655, Loss: 2.208292, Accuracy: 18.65%\n",
            "Epoch: 39, Step: 450/655, Loss: 2.208344, Accuracy: 18.65%\n",
            "Epoch: 39, Step: 451/655, Loss: 2.208416, Accuracy: 18.67%\n",
            "Epoch: 39, Step: 452/655, Loss: 2.208486, Accuracy: 18.67%\n",
            "Epoch: 39, Step: 453/655, Loss: 2.208923, Accuracy: 18.63%\n",
            "Epoch: 39, Step: 454/655, Loss: 2.209228, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 455/655, Loss: 2.209286, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 456/655, Loss: 2.209316, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 457/655, Loss: 2.209072, Accuracy: 18.62%\n",
            "Epoch: 39, Step: 458/655, Loss: 2.208978, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 459/655, Loss: 2.208903, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 460/655, Loss: 2.208951, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 461/655, Loss: 2.208867, Accuracy: 18.60%\n",
            "Epoch: 39, Step: 462/655, Loss: 2.208806, Accuracy: 18.61%\n",
            "Epoch: 39, Step: 463/655, Loss: 2.209011, Accuracy: 18.59%\n",
            "Epoch: 39, Step: 464/655, Loss: 2.208922, Accuracy: 18.57%\n",
            "Epoch: 39, Step: 465/655, Loss: 2.208738, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 466/655, Loss: 2.208745, Accuracy: 18.59%\n",
            "Epoch: 39, Step: 467/655, Loss: 2.208565, Accuracy: 18.58%\n",
            "Epoch: 39, Step: 468/655, Loss: 2.208649, Accuracy: 18.57%\n",
            "Epoch: 39, Step: 469/655, Loss: 2.208770, Accuracy: 18.55%\n",
            "Epoch: 39, Step: 470/655, Loss: 2.208798, Accuracy: 18.56%\n",
            "Epoch: 39, Step: 471/655, Loss: 2.208717, Accuracy: 18.55%\n",
            "Epoch: 39, Step: 472/655, Loss: 2.208747, Accuracy: 18.54%\n",
            "Epoch: 39, Step: 473/655, Loss: 2.208852, Accuracy: 18.54%\n",
            "Epoch: 39, Step: 474/655, Loss: 2.208811, Accuracy: 18.55%\n",
            "Epoch: 39, Step: 475/655, Loss: 2.208704, Accuracy: 18.56%\n",
            "Epoch: 39, Step: 476/655, Loss: 2.208468, Accuracy: 18.57%\n",
            "Epoch: 39, Step: 477/655, Loss: 2.208668, Accuracy: 18.53%\n",
            "Epoch: 39, Step: 478/655, Loss: 2.208383, Accuracy: 18.55%\n",
            "Epoch: 39, Step: 479/655, Loss: 2.208573, Accuracy: 18.54%\n",
            "Epoch: 39, Step: 480/655, Loss: 2.208912, Accuracy: 18.53%\n",
            "Epoch: 39, Step: 481/655, Loss: 2.208917, Accuracy: 18.54%\n",
            "Epoch: 39, Step: 482/655, Loss: 2.209046, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 483/655, Loss: 2.209073, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 484/655, Loss: 2.209019, Accuracy: 18.50%\n",
            "Epoch: 39, Step: 485/655, Loss: 2.209284, Accuracy: 18.49%\n",
            "Epoch: 39, Step: 486/655, Loss: 2.209163, Accuracy: 18.49%\n",
            "Epoch: 39, Step: 487/655, Loss: 2.209284, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 488/655, Loss: 2.209103, Accuracy: 18.52%\n",
            "Epoch: 39, Step: 489/655, Loss: 2.209041, Accuracy: 18.53%\n",
            "Epoch: 39, Step: 490/655, Loss: 2.208964, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 491/655, Loss: 2.209183, Accuracy: 18.50%\n",
            "Epoch: 39, Step: 492/655, Loss: 2.209188, Accuracy: 18.50%\n",
            "Epoch: 39, Step: 493/655, Loss: 2.209205, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 494/655, Loss: 2.209283, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 495/655, Loss: 2.209147, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 496/655, Loss: 2.209107, Accuracy: 18.49%\n",
            "Epoch: 39, Step: 497/655, Loss: 2.209175, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 498/655, Loss: 2.209265, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 499/655, Loss: 2.209220, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 500/655, Loss: 2.209172, Accuracy: 18.49%\n",
            "Epoch: 39, Step: 501/655, Loss: 2.209032, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 502/655, Loss: 2.208954, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 503/655, Loss: 2.209016, Accuracy: 18.50%\n",
            "Epoch: 39, Step: 504/655, Loss: 2.209058, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 505/655, Loss: 2.209073, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 506/655, Loss: 2.209249, Accuracy: 18.46%\n",
            "Epoch: 39, Step: 507/655, Loss: 2.209315, Accuracy: 18.46%\n",
            "Epoch: 39, Step: 508/655, Loss: 2.209370, Accuracy: 18.46%\n",
            "Epoch: 39, Step: 509/655, Loss: 2.209422, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 510/655, Loss: 2.209583, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 511/655, Loss: 2.209460, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 512/655, Loss: 2.209858, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 513/655, Loss: 2.209605, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 514/655, Loss: 2.209764, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 515/655, Loss: 2.209784, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 516/655, Loss: 2.209860, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 517/655, Loss: 2.209976, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 518/655, Loss: 2.209969, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 519/655, Loss: 2.209815, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 520/655, Loss: 2.209533, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 521/655, Loss: 2.209499, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 522/655, Loss: 2.209512, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 523/655, Loss: 2.209481, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 524/655, Loss: 2.209629, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 525/655, Loss: 2.209660, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 526/655, Loss: 2.209825, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 527/655, Loss: 2.209882, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 528/655, Loss: 2.209751, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 529/655, Loss: 2.209858, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 530/655, Loss: 2.209898, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 531/655, Loss: 2.209721, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 532/655, Loss: 2.209553, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 533/655, Loss: 2.209738, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 534/655, Loss: 2.209627, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 535/655, Loss: 2.209599, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 536/655, Loss: 2.209564, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 537/655, Loss: 2.209713, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 538/655, Loss: 2.209578, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 539/655, Loss: 2.209656, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 540/655, Loss: 2.209761, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 541/655, Loss: 2.209800, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 542/655, Loss: 2.209893, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 543/655, Loss: 2.209717, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 544/655, Loss: 2.209524, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 545/655, Loss: 2.209676, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 546/655, Loss: 2.209605, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 547/655, Loss: 2.209298, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 548/655, Loss: 2.209346, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 549/655, Loss: 2.209744, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 550/655, Loss: 2.209567, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 551/655, Loss: 2.209587, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 552/655, Loss: 2.209747, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 553/655, Loss: 2.209622, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 554/655, Loss: 2.209792, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 555/655, Loss: 2.209876, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 556/655, Loss: 2.209646, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 557/655, Loss: 2.209568, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 558/655, Loss: 2.209572, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 559/655, Loss: 2.209614, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 560/655, Loss: 2.209856, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 561/655, Loss: 2.209780, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 562/655, Loss: 2.209601, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 563/655, Loss: 2.209585, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 564/655, Loss: 2.209411, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 565/655, Loss: 2.209426, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 566/655, Loss: 2.209575, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 567/655, Loss: 2.209749, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 568/655, Loss: 2.209795, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 569/655, Loss: 2.209818, Accuracy: 18.36%\n",
            "Epoch: 39, Step: 570/655, Loss: 2.209807, Accuracy: 18.37%\n",
            "Epoch: 39, Step: 571/655, Loss: 2.209674, Accuracy: 18.38%\n",
            "Epoch: 39, Step: 572/655, Loss: 2.209710, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 573/655, Loss: 2.209766, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 574/655, Loss: 2.209690, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 575/655, Loss: 2.209608, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 576/655, Loss: 2.209599, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 577/655, Loss: 2.209786, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 578/655, Loss: 2.209759, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 579/655, Loss: 2.209771, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 580/655, Loss: 2.209874, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 581/655, Loss: 2.209825, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 582/655, Loss: 2.209913, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 583/655, Loss: 2.209921, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 584/655, Loss: 2.209633, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 585/655, Loss: 2.209553, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 586/655, Loss: 2.209849, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 587/655, Loss: 2.209859, Accuracy: 18.39%\n",
            "Epoch: 39, Step: 588/655, Loss: 2.209568, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 589/655, Loss: 2.209518, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 590/655, Loss: 2.209384, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 591/655, Loss: 2.209428, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 592/655, Loss: 2.209555, Accuracy: 18.40%\n",
            "Epoch: 39, Step: 593/655, Loss: 2.209469, Accuracy: 18.41%\n",
            "Epoch: 39, Step: 594/655, Loss: 2.209294, Accuracy: 18.42%\n",
            "Epoch: 39, Step: 595/655, Loss: 2.209082, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 596/655, Loss: 2.209071, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 597/655, Loss: 2.209005, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 598/655, Loss: 2.209141, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 599/655, Loss: 2.209209, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 600/655, Loss: 2.208977, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 601/655, Loss: 2.208927, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 602/655, Loss: 2.209025, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 603/655, Loss: 2.208978, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 604/655, Loss: 2.208840, Accuracy: 18.46%\n",
            "Epoch: 39, Step: 605/655, Loss: 2.208796, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 606/655, Loss: 2.208700, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 607/655, Loss: 2.208667, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 608/655, Loss: 2.208757, Accuracy: 18.46%\n",
            "Epoch: 39, Step: 609/655, Loss: 2.208772, Accuracy: 18.46%\n",
            "Epoch: 39, Step: 610/655, Loss: 2.208652, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 611/655, Loss: 2.208552, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 612/655, Loss: 2.208564, Accuracy: 18.46%\n",
            "Epoch: 39, Step: 613/655, Loss: 2.208466, Accuracy: 18.46%\n",
            "Epoch: 39, Step: 614/655, Loss: 2.208229, Accuracy: 18.49%\n",
            "Epoch: 39, Step: 615/655, Loss: 2.208174, Accuracy: 18.50%\n",
            "Epoch: 39, Step: 616/655, Loss: 2.208052, Accuracy: 18.52%\n",
            "Epoch: 39, Step: 617/655, Loss: 2.208183, Accuracy: 18.52%\n",
            "Epoch: 39, Step: 618/655, Loss: 2.208180, Accuracy: 18.53%\n",
            "Epoch: 39, Step: 619/655, Loss: 2.208141, Accuracy: 18.52%\n",
            "Epoch: 39, Step: 620/655, Loss: 2.208228, Accuracy: 18.52%\n",
            "Epoch: 39, Step: 621/655, Loss: 2.208060, Accuracy: 18.52%\n",
            "Epoch: 39, Step: 622/655, Loss: 2.208222, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 623/655, Loss: 2.208118, Accuracy: 18.53%\n",
            "Epoch: 39, Step: 624/655, Loss: 2.208068, Accuracy: 18.52%\n",
            "Epoch: 39, Step: 625/655, Loss: 2.207956, Accuracy: 18.52%\n",
            "Epoch: 39, Step: 626/655, Loss: 2.207858, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 627/655, Loss: 2.207974, Accuracy: 18.50%\n",
            "Epoch: 39, Step: 628/655, Loss: 2.207909, Accuracy: 18.49%\n",
            "Epoch: 39, Step: 629/655, Loss: 2.208050, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 630/655, Loss: 2.208191, Accuracy: 18.46%\n",
            "Epoch: 39, Step: 631/655, Loss: 2.208195, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 632/655, Loss: 2.208213, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 633/655, Loss: 2.208109, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 634/655, Loss: 2.208076, Accuracy: 18.43%\n",
            "Epoch: 39, Step: 635/655, Loss: 2.208120, Accuracy: 18.44%\n",
            "Epoch: 39, Step: 636/655, Loss: 2.208235, Accuracy: 18.45%\n",
            "Epoch: 39, Step: 637/655, Loss: 2.208120, Accuracy: 18.46%\n",
            "Epoch: 39, Step: 638/655, Loss: 2.207931, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 639/655, Loss: 2.207948, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 640/655, Loss: 2.208008, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 641/655, Loss: 2.208106, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 642/655, Loss: 2.208066, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 643/655, Loss: 2.208066, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 644/655, Loss: 2.207806, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 645/655, Loss: 2.207796, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 646/655, Loss: 2.207831, Accuracy: 18.48%\n",
            "Epoch: 39, Step: 647/655, Loss: 2.207901, Accuracy: 18.47%\n",
            "Epoch: 39, Step: 648/655, Loss: 2.207846, Accuracy: 18.49%\n",
            "Epoch: 39, Step: 649/655, Loss: 2.207751, Accuracy: 18.49%\n",
            "Epoch: 39, Step: 650/655, Loss: 2.207695, Accuracy: 18.50%\n",
            "Epoch: 39, Step: 651/655, Loss: 2.207752, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 652/655, Loss: 2.207730, Accuracy: 18.51%\n",
            "Epoch: 39, Step: 653/655, Loss: 2.207771, Accuracy: 18.52%\n",
            "Epoch: 39, Step: 654/655, Loss: 2.207519, Accuracy: 18.53%\n",
            "Epoch: 39, Step: 655/655, Loss: 2.207456, Accuracy: 18.52%\n",
            "Epoch: 40, Step: 1/655, Loss: 2.241261, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 2/655, Loss: 2.202289, Accuracy: 25.00%\n",
            "Epoch: 40, Step: 3/655, Loss: 2.202064, Accuracy: 21.88%\n",
            "Epoch: 40, Step: 4/655, Loss: 2.214736, Accuracy: 20.31%\n",
            "Epoch: 40, Step: 5/655, Loss: 2.221780, Accuracy: 19.38%\n",
            "Epoch: 40, Step: 6/655, Loss: 2.194907, Accuracy: 18.23%\n",
            "Epoch: 40, Step: 7/655, Loss: 2.192251, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 8/655, Loss: 2.180221, Accuracy: 19.53%\n",
            "Epoch: 40, Step: 9/655, Loss: 2.183007, Accuracy: 19.10%\n",
            "Epoch: 40, Step: 10/655, Loss: 2.200544, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 11/655, Loss: 2.203230, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 12/655, Loss: 2.202600, Accuracy: 17.71%\n",
            "Epoch: 40, Step: 13/655, Loss: 2.189805, Accuracy: 18.99%\n",
            "Epoch: 40, Step: 14/655, Loss: 2.189846, Accuracy: 18.97%\n",
            "Epoch: 40, Step: 15/655, Loss: 2.187756, Accuracy: 19.17%\n",
            "Epoch: 40, Step: 16/655, Loss: 2.191040, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 17/655, Loss: 2.185716, Accuracy: 19.49%\n",
            "Epoch: 40, Step: 18/655, Loss: 2.189695, Accuracy: 19.62%\n",
            "Epoch: 40, Step: 19/655, Loss: 2.192573, Accuracy: 20.07%\n",
            "Epoch: 40, Step: 20/655, Loss: 2.189573, Accuracy: 20.47%\n",
            "Epoch: 40, Step: 21/655, Loss: 2.188820, Accuracy: 20.24%\n",
            "Epoch: 40, Step: 22/655, Loss: 2.195870, Accuracy: 19.89%\n",
            "Epoch: 40, Step: 23/655, Loss: 2.193972, Accuracy: 19.84%\n",
            "Epoch: 40, Step: 24/655, Loss: 2.198840, Accuracy: 19.53%\n",
            "Epoch: 40, Step: 25/655, Loss: 2.203174, Accuracy: 19.25%\n",
            "Epoch: 40, Step: 26/655, Loss: 2.204088, Accuracy: 19.11%\n",
            "Epoch: 40, Step: 27/655, Loss: 2.206794, Accuracy: 18.52%\n",
            "Epoch: 40, Step: 28/655, Loss: 2.209201, Accuracy: 18.53%\n",
            "Epoch: 40, Step: 29/655, Loss: 2.208030, Accuracy: 18.86%\n",
            "Epoch: 40, Step: 30/655, Loss: 2.211825, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 31/655, Loss: 2.209235, Accuracy: 18.95%\n",
            "Epoch: 40, Step: 32/655, Loss: 2.208020, Accuracy: 18.95%\n",
            "Epoch: 40, Step: 33/655, Loss: 2.204989, Accuracy: 19.13%\n",
            "Epoch: 40, Step: 34/655, Loss: 2.207478, Accuracy: 18.84%\n",
            "Epoch: 40, Step: 35/655, Loss: 2.203699, Accuracy: 18.93%\n",
            "Epoch: 40, Step: 36/655, Loss: 2.205087, Accuracy: 18.92%\n",
            "Epoch: 40, Step: 37/655, Loss: 2.203141, Accuracy: 18.92%\n",
            "Epoch: 40, Step: 38/655, Loss: 2.204250, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 39/655, Loss: 2.201703, Accuracy: 18.91%\n",
            "Epoch: 40, Step: 40/655, Loss: 2.203149, Accuracy: 18.91%\n",
            "Epoch: 40, Step: 41/655, Loss: 2.202933, Accuracy: 19.05%\n",
            "Epoch: 40, Step: 42/655, Loss: 2.204149, Accuracy: 19.12%\n",
            "Epoch: 40, Step: 43/655, Loss: 2.204809, Accuracy: 19.26%\n",
            "Epoch: 40, Step: 44/655, Loss: 2.207185, Accuracy: 19.25%\n",
            "Epoch: 40, Step: 45/655, Loss: 2.206245, Accuracy: 19.03%\n",
            "Epoch: 40, Step: 46/655, Loss: 2.205845, Accuracy: 19.09%\n",
            "Epoch: 40, Step: 47/655, Loss: 2.205393, Accuracy: 19.02%\n",
            "Epoch: 40, Step: 48/655, Loss: 2.205005, Accuracy: 19.08%\n",
            "Epoch: 40, Step: 49/655, Loss: 2.206294, Accuracy: 19.13%\n",
            "Epoch: 40, Step: 50/655, Loss: 2.204846, Accuracy: 19.19%\n",
            "Epoch: 40, Step: 51/655, Loss: 2.205057, Accuracy: 19.00%\n",
            "Epoch: 40, Step: 52/655, Loss: 2.202959, Accuracy: 19.11%\n",
            "Epoch: 40, Step: 53/655, Loss: 2.204360, Accuracy: 18.99%\n",
            "Epoch: 40, Step: 54/655, Loss: 2.202198, Accuracy: 19.10%\n",
            "Epoch: 40, Step: 55/655, Loss: 2.201144, Accuracy: 19.20%\n",
            "Epoch: 40, Step: 56/655, Loss: 2.202046, Accuracy: 19.14%\n",
            "Epoch: 40, Step: 57/655, Loss: 2.199793, Accuracy: 19.19%\n",
            "Epoch: 40, Step: 58/655, Loss: 2.201863, Accuracy: 19.13%\n",
            "Epoch: 40, Step: 59/655, Loss: 2.201364, Accuracy: 19.17%\n",
            "Epoch: 40, Step: 60/655, Loss: 2.202497, Accuracy: 19.06%\n",
            "Epoch: 40, Step: 61/655, Loss: 2.201613, Accuracy: 19.26%\n",
            "Epoch: 40, Step: 62/655, Loss: 2.199772, Accuracy: 19.30%\n",
            "Epoch: 40, Step: 63/655, Loss: 2.199941, Accuracy: 19.20%\n",
            "Epoch: 40, Step: 64/655, Loss: 2.201379, Accuracy: 19.09%\n",
            "Epoch: 40, Step: 65/655, Loss: 2.202792, Accuracy: 19.04%\n",
            "Epoch: 40, Step: 66/655, Loss: 2.200819, Accuracy: 19.22%\n",
            "Epoch: 40, Step: 67/655, Loss: 2.203184, Accuracy: 19.08%\n",
            "Epoch: 40, Step: 68/655, Loss: 2.203068, Accuracy: 19.07%\n",
            "Epoch: 40, Step: 69/655, Loss: 2.201936, Accuracy: 18.93%\n",
            "Epoch: 40, Step: 70/655, Loss: 2.203294, Accuracy: 18.88%\n",
            "Epoch: 40, Step: 71/655, Loss: 2.201375, Accuracy: 19.06%\n",
            "Epoch: 40, Step: 72/655, Loss: 2.201368, Accuracy: 19.10%\n",
            "Epoch: 40, Step: 73/655, Loss: 2.203220, Accuracy: 19.01%\n",
            "Epoch: 40, Step: 74/655, Loss: 2.203986, Accuracy: 19.00%\n",
            "Epoch: 40, Step: 75/655, Loss: 2.202302, Accuracy: 19.00%\n",
            "Epoch: 40, Step: 76/655, Loss: 2.201465, Accuracy: 19.04%\n",
            "Epoch: 40, Step: 77/655, Loss: 2.202037, Accuracy: 18.87%\n",
            "Epoch: 40, Step: 78/655, Loss: 2.202703, Accuracy: 18.87%\n",
            "Epoch: 40, Step: 79/655, Loss: 2.202392, Accuracy: 18.79%\n",
            "Epoch: 40, Step: 80/655, Loss: 2.202611, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 81/655, Loss: 2.201853, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 82/655, Loss: 2.203378, Accuracy: 18.71%\n",
            "Epoch: 40, Step: 83/655, Loss: 2.202759, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 84/655, Loss: 2.202734, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 85/655, Loss: 2.202766, Accuracy: 18.64%\n",
            "Epoch: 40, Step: 86/655, Loss: 2.202821, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 87/655, Loss: 2.203231, Accuracy: 18.46%\n",
            "Epoch: 40, Step: 88/655, Loss: 2.202812, Accuracy: 18.36%\n",
            "Epoch: 40, Step: 89/655, Loss: 2.202410, Accuracy: 18.36%\n",
            "Epoch: 40, Step: 90/655, Loss: 2.201449, Accuracy: 18.51%\n",
            "Epoch: 40, Step: 91/655, Loss: 2.202240, Accuracy: 18.51%\n",
            "Epoch: 40, Step: 92/655, Loss: 2.201889, Accuracy: 18.51%\n",
            "Epoch: 40, Step: 93/655, Loss: 2.202321, Accuracy: 18.51%\n",
            "Epoch: 40, Step: 94/655, Loss: 2.202620, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 95/655, Loss: 2.202662, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 96/655, Loss: 2.202868, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 97/655, Loss: 2.203359, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 98/655, Loss: 2.203074, Accuracy: 18.53%\n",
            "Epoch: 40, Step: 99/655, Loss: 2.203399, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 100/655, Loss: 2.202801, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 101/655, Loss: 2.203335, Accuracy: 18.44%\n",
            "Epoch: 40, Step: 102/655, Loss: 2.203483, Accuracy: 18.54%\n",
            "Epoch: 40, Step: 103/655, Loss: 2.202409, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 104/655, Loss: 2.202705, Accuracy: 18.57%\n",
            "Epoch: 40, Step: 105/655, Loss: 2.201878, Accuracy: 18.69%\n",
            "Epoch: 40, Step: 106/655, Loss: 2.201782, Accuracy: 18.72%\n",
            "Epoch: 40, Step: 107/655, Loss: 2.202795, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 108/655, Loss: 2.202233, Accuracy: 18.69%\n",
            "Epoch: 40, Step: 109/655, Loss: 2.201366, Accuracy: 18.69%\n",
            "Epoch: 40, Step: 110/655, Loss: 2.202390, Accuracy: 18.66%\n",
            "Epoch: 40, Step: 111/655, Loss: 2.202268, Accuracy: 18.58%\n",
            "Epoch: 40, Step: 112/655, Loss: 2.202134, Accuracy: 18.50%\n",
            "Epoch: 40, Step: 113/655, Loss: 2.202399, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 114/655, Loss: 2.202879, Accuracy: 18.42%\n",
            "Epoch: 40, Step: 115/655, Loss: 2.202335, Accuracy: 18.48%\n",
            "Epoch: 40, Step: 116/655, Loss: 2.202996, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 117/655, Loss: 2.203193, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 118/655, Loss: 2.203225, Accuracy: 18.38%\n",
            "Epoch: 40, Step: 119/655, Loss: 2.203344, Accuracy: 18.41%\n",
            "Epoch: 40, Step: 120/655, Loss: 2.203444, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 121/655, Loss: 2.204156, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 122/655, Loss: 2.203782, Accuracy: 18.44%\n",
            "Epoch: 40, Step: 123/655, Loss: 2.204347, Accuracy: 18.52%\n",
            "Epoch: 40, Step: 124/655, Loss: 2.203864, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 125/655, Loss: 2.204829, Accuracy: 18.57%\n",
            "Epoch: 40, Step: 126/655, Loss: 2.205382, Accuracy: 18.55%\n",
            "Epoch: 40, Step: 127/655, Loss: 2.205421, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 128/655, Loss: 2.205517, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 129/655, Loss: 2.205911, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 130/655, Loss: 2.204756, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 131/655, Loss: 2.204827, Accuracy: 18.80%\n",
            "Epoch: 40, Step: 132/655, Loss: 2.204538, Accuracy: 18.82%\n",
            "Epoch: 40, Step: 133/655, Loss: 2.204626, Accuracy: 18.77%\n",
            "Epoch: 40, Step: 134/655, Loss: 2.204821, Accuracy: 18.73%\n",
            "Epoch: 40, Step: 135/655, Loss: 2.205997, Accuracy: 18.66%\n",
            "Epoch: 40, Step: 136/655, Loss: 2.205980, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 137/655, Loss: 2.205246, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 138/655, Loss: 2.205003, Accuracy: 18.61%\n",
            "Epoch: 40, Step: 139/655, Loss: 2.204393, Accuracy: 18.59%\n",
            "Epoch: 40, Step: 140/655, Loss: 2.205326, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 141/655, Loss: 2.204127, Accuracy: 18.71%\n",
            "Epoch: 40, Step: 142/655, Loss: 2.204430, Accuracy: 18.71%\n",
            "Epoch: 40, Step: 143/655, Loss: 2.203617, Accuracy: 18.77%\n",
            "Epoch: 40, Step: 144/655, Loss: 2.203562, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 145/655, Loss: 2.202711, Accuracy: 18.81%\n",
            "Epoch: 40, Step: 146/655, Loss: 2.202344, Accuracy: 18.86%\n",
            "Epoch: 40, Step: 147/655, Loss: 2.202307, Accuracy: 18.77%\n",
            "Epoch: 40, Step: 148/655, Loss: 2.202431, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 149/655, Loss: 2.202037, Accuracy: 18.79%\n",
            "Epoch: 40, Step: 150/655, Loss: 2.201588, Accuracy: 18.79%\n",
            "Epoch: 40, Step: 151/655, Loss: 2.201221, Accuracy: 18.83%\n",
            "Epoch: 40, Step: 152/655, Loss: 2.201124, Accuracy: 18.89%\n",
            "Epoch: 40, Step: 153/655, Loss: 2.200706, Accuracy: 18.95%\n",
            "Epoch: 40, Step: 154/655, Loss: 2.202073, Accuracy: 18.89%\n",
            "Epoch: 40, Step: 155/655, Loss: 2.202421, Accuracy: 18.87%\n",
            "Epoch: 40, Step: 156/655, Loss: 2.201979, Accuracy: 18.91%\n",
            "Epoch: 40, Step: 157/655, Loss: 2.202691, Accuracy: 18.89%\n",
            "Epoch: 40, Step: 158/655, Loss: 2.202523, Accuracy: 18.91%\n",
            "Epoch: 40, Step: 159/655, Loss: 2.201863, Accuracy: 18.89%\n",
            "Epoch: 40, Step: 160/655, Loss: 2.200747, Accuracy: 18.91%\n",
            "Epoch: 40, Step: 161/655, Loss: 2.201055, Accuracy: 18.91%\n",
            "Epoch: 40, Step: 162/655, Loss: 2.201007, Accuracy: 18.90%\n",
            "Epoch: 40, Step: 163/655, Loss: 2.202010, Accuracy: 18.87%\n",
            "Epoch: 40, Step: 164/655, Loss: 2.201876, Accuracy: 18.92%\n",
            "Epoch: 40, Step: 165/655, Loss: 2.202369, Accuracy: 18.92%\n",
            "Epoch: 40, Step: 166/655, Loss: 2.202835, Accuracy: 18.86%\n",
            "Epoch: 40, Step: 167/655, Loss: 2.203184, Accuracy: 18.86%\n",
            "Epoch: 40, Step: 168/655, Loss: 2.202649, Accuracy: 18.88%\n",
            "Epoch: 40, Step: 169/655, Loss: 2.202744, Accuracy: 18.86%\n",
            "Epoch: 40, Step: 170/655, Loss: 2.203899, Accuracy: 18.81%\n",
            "Epoch: 40, Step: 171/655, Loss: 2.205205, Accuracy: 18.73%\n",
            "Epoch: 40, Step: 172/655, Loss: 2.205282, Accuracy: 18.73%\n",
            "Epoch: 40, Step: 173/655, Loss: 2.204323, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 174/655, Loss: 2.204753, Accuracy: 18.73%\n",
            "Epoch: 40, Step: 175/655, Loss: 2.204987, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 176/655, Loss: 2.204871, Accuracy: 18.80%\n",
            "Epoch: 40, Step: 177/655, Loss: 2.204108, Accuracy: 18.84%\n",
            "Epoch: 40, Step: 178/655, Loss: 2.204382, Accuracy: 18.80%\n",
            "Epoch: 40, Step: 179/655, Loss: 2.205053, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 180/655, Loss: 2.205109, Accuracy: 18.73%\n",
            "Epoch: 40, Step: 181/655, Loss: 2.204693, Accuracy: 18.73%\n",
            "Epoch: 40, Step: 182/655, Loss: 2.204741, Accuracy: 18.73%\n",
            "Epoch: 40, Step: 183/655, Loss: 2.204752, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 184/655, Loss: 2.205001, Accuracy: 18.72%\n",
            "Epoch: 40, Step: 185/655, Loss: 2.205369, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 186/655, Loss: 2.205951, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 187/655, Loss: 2.205487, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 188/655, Loss: 2.205955, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 189/655, Loss: 2.205717, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 190/655, Loss: 2.206007, Accuracy: 18.59%\n",
            "Epoch: 40, Step: 191/655, Loss: 2.205186, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 192/655, Loss: 2.204740, Accuracy: 18.73%\n",
            "Epoch: 40, Step: 193/655, Loss: 2.205117, Accuracy: 18.77%\n",
            "Epoch: 40, Step: 194/655, Loss: 2.204937, Accuracy: 18.83%\n",
            "Epoch: 40, Step: 195/655, Loss: 2.205633, Accuracy: 18.80%\n",
            "Epoch: 40, Step: 196/655, Loss: 2.205115, Accuracy: 18.83%\n",
            "Epoch: 40, Step: 197/655, Loss: 2.205529, Accuracy: 18.78%\n",
            "Epoch: 40, Step: 198/655, Loss: 2.205752, Accuracy: 18.80%\n",
            "Epoch: 40, Step: 199/655, Loss: 2.205365, Accuracy: 18.81%\n",
            "Epoch: 40, Step: 200/655, Loss: 2.205114, Accuracy: 18.80%\n",
            "Epoch: 40, Step: 201/655, Loss: 2.205160, Accuracy: 18.80%\n",
            "Epoch: 40, Step: 202/655, Loss: 2.205262, Accuracy: 18.81%\n",
            "Epoch: 40, Step: 203/655, Loss: 2.204221, Accuracy: 18.87%\n",
            "Epoch: 40, Step: 204/655, Loss: 2.204490, Accuracy: 18.83%\n",
            "Epoch: 40, Step: 205/655, Loss: 2.204983, Accuracy: 18.78%\n",
            "Epoch: 40, Step: 206/655, Loss: 2.204455, Accuracy: 18.81%\n",
            "Epoch: 40, Step: 207/655, Loss: 2.204791, Accuracy: 18.80%\n",
            "Epoch: 40, Step: 208/655, Loss: 2.205011, Accuracy: 18.78%\n",
            "Epoch: 40, Step: 209/655, Loss: 2.204720, Accuracy: 18.81%\n",
            "Epoch: 40, Step: 210/655, Loss: 2.204722, Accuracy: 18.87%\n",
            "Epoch: 40, Step: 211/655, Loss: 2.204592, Accuracy: 18.81%\n",
            "Epoch: 40, Step: 212/655, Loss: 2.204449, Accuracy: 18.82%\n",
            "Epoch: 40, Step: 213/655, Loss: 2.204875, Accuracy: 18.78%\n",
            "Epoch: 40, Step: 214/655, Loss: 2.204282, Accuracy: 18.81%\n",
            "Epoch: 40, Step: 215/655, Loss: 2.204344, Accuracy: 18.76%\n",
            "Epoch: 40, Step: 216/655, Loss: 2.204426, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 217/655, Loss: 2.204603, Accuracy: 18.72%\n",
            "Epoch: 40, Step: 218/655, Loss: 2.204901, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 219/655, Loss: 2.204893, Accuracy: 18.72%\n",
            "Epoch: 40, Step: 220/655, Loss: 2.204578, Accuracy: 18.74%\n",
            "Epoch: 40, Step: 221/655, Loss: 2.204178, Accuracy: 18.76%\n",
            "Epoch: 40, Step: 222/655, Loss: 2.204724, Accuracy: 18.69%\n",
            "Epoch: 40, Step: 223/655, Loss: 2.204451, Accuracy: 18.72%\n",
            "Epoch: 40, Step: 224/655, Loss: 2.203747, Accuracy: 18.79%\n",
            "Epoch: 40, Step: 225/655, Loss: 2.203666, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 226/655, Loss: 2.203407, Accuracy: 18.74%\n",
            "Epoch: 40, Step: 227/655, Loss: 2.203328, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 228/655, Loss: 2.203261, Accuracy: 18.78%\n",
            "Epoch: 40, Step: 229/655, Loss: 2.203534, Accuracy: 18.80%\n",
            "Epoch: 40, Step: 230/655, Loss: 2.202572, Accuracy: 18.83%\n",
            "Epoch: 40, Step: 231/655, Loss: 2.202294, Accuracy: 18.80%\n",
            "Epoch: 40, Step: 232/655, Loss: 2.202891, Accuracy: 18.76%\n",
            "Epoch: 40, Step: 233/655, Loss: 2.202589, Accuracy: 18.78%\n",
            "Epoch: 40, Step: 234/655, Loss: 2.202624, Accuracy: 18.78%\n",
            "Epoch: 40, Step: 235/655, Loss: 2.202459, Accuracy: 18.78%\n",
            "Epoch: 40, Step: 236/655, Loss: 2.202449, Accuracy: 18.74%\n",
            "Epoch: 40, Step: 237/655, Loss: 2.202318, Accuracy: 18.76%\n",
            "Epoch: 40, Step: 238/655, Loss: 2.202747, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 239/655, Loss: 2.203329, Accuracy: 18.71%\n",
            "Epoch: 40, Step: 240/655, Loss: 2.203040, Accuracy: 18.71%\n",
            "Epoch: 40, Step: 241/655, Loss: 2.203277, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 242/655, Loss: 2.203255, Accuracy: 18.66%\n",
            "Epoch: 40, Step: 243/655, Loss: 2.203008, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 244/655, Loss: 2.203197, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 245/655, Loss: 2.202734, Accuracy: 18.61%\n",
            "Epoch: 40, Step: 246/655, Loss: 2.202773, Accuracy: 18.58%\n",
            "Epoch: 40, Step: 247/655, Loss: 2.202971, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 248/655, Loss: 2.203262, Accuracy: 18.59%\n",
            "Epoch: 40, Step: 249/655, Loss: 2.203695, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 250/655, Loss: 2.203640, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 251/655, Loss: 2.203916, Accuracy: 18.50%\n",
            "Epoch: 40, Step: 252/655, Loss: 2.204292, Accuracy: 18.51%\n",
            "Epoch: 40, Step: 253/655, Loss: 2.204367, Accuracy: 18.50%\n",
            "Epoch: 40, Step: 254/655, Loss: 2.203890, Accuracy: 18.52%\n",
            "Epoch: 40, Step: 255/655, Loss: 2.203958, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 256/655, Loss: 2.204022, Accuracy: 18.52%\n",
            "Epoch: 40, Step: 257/655, Loss: 2.204014, Accuracy: 18.54%\n",
            "Epoch: 40, Step: 258/655, Loss: 2.203844, Accuracy: 18.54%\n",
            "Epoch: 40, Step: 259/655, Loss: 2.204381, Accuracy: 18.52%\n",
            "Epoch: 40, Step: 260/655, Loss: 2.204371, Accuracy: 18.53%\n",
            "Epoch: 40, Step: 261/655, Loss: 2.204532, Accuracy: 18.57%\n",
            "Epoch: 40, Step: 262/655, Loss: 2.204193, Accuracy: 18.58%\n",
            "Epoch: 40, Step: 263/655, Loss: 2.204266, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 264/655, Loss: 2.204419, Accuracy: 18.54%\n",
            "Epoch: 40, Step: 265/655, Loss: 2.203744, Accuracy: 18.57%\n",
            "Epoch: 40, Step: 266/655, Loss: 2.203521, Accuracy: 18.59%\n",
            "Epoch: 40, Step: 267/655, Loss: 2.203453, Accuracy: 18.59%\n",
            "Epoch: 40, Step: 268/655, Loss: 2.203010, Accuracy: 18.66%\n",
            "Epoch: 40, Step: 269/655, Loss: 2.202891, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 270/655, Loss: 2.203067, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 271/655, Loss: 2.203512, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 272/655, Loss: 2.203165, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 273/655, Loss: 2.203462, Accuracy: 18.66%\n",
            "Epoch: 40, Step: 274/655, Loss: 2.202766, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 275/655, Loss: 2.202700, Accuracy: 18.72%\n",
            "Epoch: 40, Step: 276/655, Loss: 2.202974, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 277/655, Loss: 2.202743, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 278/655, Loss: 2.202267, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 279/655, Loss: 2.202806, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 280/655, Loss: 2.202547, Accuracy: 18.64%\n",
            "Epoch: 40, Step: 281/655, Loss: 2.202044, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 282/655, Loss: 2.201997, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 283/655, Loss: 2.202328, Accuracy: 18.57%\n",
            "Epoch: 40, Step: 284/655, Loss: 2.202156, Accuracy: 18.61%\n",
            "Epoch: 40, Step: 285/655, Loss: 2.202045, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 286/655, Loss: 2.202061, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 287/655, Loss: 2.202369, Accuracy: 18.55%\n",
            "Epoch: 40, Step: 288/655, Loss: 2.202287, Accuracy: 18.59%\n",
            "Epoch: 40, Step: 289/655, Loss: 2.202173, Accuracy: 18.58%\n",
            "Epoch: 40, Step: 290/655, Loss: 2.202388, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 291/655, Loss: 2.202219, Accuracy: 18.57%\n",
            "Epoch: 40, Step: 292/655, Loss: 2.202715, Accuracy: 18.55%\n",
            "Epoch: 40, Step: 293/655, Loss: 2.202955, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 294/655, Loss: 2.202720, Accuracy: 18.57%\n",
            "Epoch: 40, Step: 295/655, Loss: 2.202838, Accuracy: 18.58%\n",
            "Epoch: 40, Step: 296/655, Loss: 2.202529, Accuracy: 18.57%\n",
            "Epoch: 40, Step: 297/655, Loss: 2.202556, Accuracy: 18.58%\n",
            "Epoch: 40, Step: 298/655, Loss: 2.202864, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 299/655, Loss: 2.203511, Accuracy: 18.55%\n",
            "Epoch: 40, Step: 300/655, Loss: 2.203544, Accuracy: 18.54%\n",
            "Epoch: 40, Step: 301/655, Loss: 2.203355, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 302/655, Loss: 2.203285, Accuracy: 18.59%\n",
            "Epoch: 40, Step: 303/655, Loss: 2.203470, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 304/655, Loss: 2.203332, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 305/655, Loss: 2.203317, Accuracy: 18.59%\n",
            "Epoch: 40, Step: 306/655, Loss: 2.203406, Accuracy: 18.61%\n",
            "Epoch: 40, Step: 307/655, Loss: 2.203275, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 308/655, Loss: 2.203626, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 309/655, Loss: 2.203624, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 310/655, Loss: 2.203749, Accuracy: 18.61%\n",
            "Epoch: 40, Step: 311/655, Loss: 2.203868, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 312/655, Loss: 2.203784, Accuracy: 18.61%\n",
            "Epoch: 40, Step: 313/655, Loss: 2.203670, Accuracy: 18.61%\n",
            "Epoch: 40, Step: 314/655, Loss: 2.203670, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 315/655, Loss: 2.203584, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 316/655, Loss: 2.203568, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 317/655, Loss: 2.203577, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 318/655, Loss: 2.203603, Accuracy: 18.57%\n",
            "Epoch: 40, Step: 319/655, Loss: 2.203223, Accuracy: 18.58%\n",
            "Epoch: 40, Step: 320/655, Loss: 2.202944, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 321/655, Loss: 2.202916, Accuracy: 18.61%\n",
            "Epoch: 40, Step: 322/655, Loss: 2.203707, Accuracy: 18.58%\n",
            "Epoch: 40, Step: 323/655, Loss: 2.203665, Accuracy: 18.57%\n",
            "Epoch: 40, Step: 324/655, Loss: 2.203605, Accuracy: 18.59%\n",
            "Epoch: 40, Step: 325/655, Loss: 2.203158, Accuracy: 18.61%\n",
            "Epoch: 40, Step: 326/655, Loss: 2.203156, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 327/655, Loss: 2.203282, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 328/655, Loss: 2.203137, Accuracy: 18.61%\n",
            "Epoch: 40, Step: 329/655, Loss: 2.203125, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 330/655, Loss: 2.203084, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 331/655, Loss: 2.203398, Accuracy: 18.58%\n",
            "Epoch: 40, Step: 332/655, Loss: 2.203733, Accuracy: 18.55%\n",
            "Epoch: 40, Step: 333/655, Loss: 2.204021, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 334/655, Loss: 2.203832, Accuracy: 18.55%\n",
            "Epoch: 40, Step: 335/655, Loss: 2.203613, Accuracy: 18.59%\n",
            "Epoch: 40, Step: 336/655, Loss: 2.203736, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 337/655, Loss: 2.203652, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 338/655, Loss: 2.203504, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 339/655, Loss: 2.203833, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 340/655, Loss: 2.204034, Accuracy: 18.58%\n",
            "Epoch: 40, Step: 341/655, Loss: 2.204029, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 342/655, Loss: 2.203674, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 343/655, Loss: 2.203427, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 344/655, Loss: 2.203097, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 345/655, Loss: 2.203205, Accuracy: 18.69%\n",
            "Epoch: 40, Step: 346/655, Loss: 2.203162, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 347/655, Loss: 2.203321, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 348/655, Loss: 2.203269, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 349/655, Loss: 2.203402, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 350/655, Loss: 2.203492, Accuracy: 18.72%\n",
            "Epoch: 40, Step: 351/655, Loss: 2.204007, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 352/655, Loss: 2.204337, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 353/655, Loss: 2.204175, Accuracy: 18.72%\n",
            "Epoch: 40, Step: 354/655, Loss: 2.204090, Accuracy: 18.73%\n",
            "Epoch: 40, Step: 355/655, Loss: 2.203969, Accuracy: 18.71%\n",
            "Epoch: 40, Step: 356/655, Loss: 2.204053, Accuracy: 18.71%\n",
            "Epoch: 40, Step: 357/655, Loss: 2.204157, Accuracy: 18.71%\n",
            "Epoch: 40, Step: 358/655, Loss: 2.204263, Accuracy: 18.69%\n",
            "Epoch: 40, Step: 359/655, Loss: 2.204298, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 360/655, Loss: 2.204367, Accuracy: 18.66%\n",
            "Epoch: 40, Step: 361/655, Loss: 2.204333, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 362/655, Loss: 2.204190, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 363/655, Loss: 2.204394, Accuracy: 18.66%\n",
            "Epoch: 40, Step: 364/655, Loss: 2.204145, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 365/655, Loss: 2.204082, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 366/655, Loss: 2.204284, Accuracy: 18.66%\n",
            "Epoch: 40, Step: 367/655, Loss: 2.204287, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 368/655, Loss: 2.204705, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 369/655, Loss: 2.204510, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 370/655, Loss: 2.204529, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 371/655, Loss: 2.204757, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 372/655, Loss: 2.204812, Accuracy: 18.66%\n",
            "Epoch: 40, Step: 373/655, Loss: 2.204892, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 374/655, Loss: 2.204467, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 375/655, Loss: 2.204823, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 376/655, Loss: 2.204539, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 377/655, Loss: 2.204543, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 378/655, Loss: 2.203938, Accuracy: 18.72%\n",
            "Epoch: 40, Step: 379/655, Loss: 2.204160, Accuracy: 18.72%\n",
            "Epoch: 40, Step: 380/655, Loss: 2.204153, Accuracy: 18.73%\n",
            "Epoch: 40, Step: 381/655, Loss: 2.204176, Accuracy: 18.74%\n",
            "Epoch: 40, Step: 382/655, Loss: 2.204013, Accuracy: 18.75%\n",
            "Epoch: 40, Step: 383/655, Loss: 2.203869, Accuracy: 18.72%\n",
            "Epoch: 40, Step: 384/655, Loss: 2.203684, Accuracy: 18.73%\n",
            "Epoch: 40, Step: 385/655, Loss: 2.203637, Accuracy: 18.73%\n",
            "Epoch: 40, Step: 386/655, Loss: 2.203697, Accuracy: 18.73%\n",
            "Epoch: 40, Step: 387/655, Loss: 2.203940, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 388/655, Loss: 2.204411, Accuracy: 18.69%\n",
            "Epoch: 40, Step: 389/655, Loss: 2.204406, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 390/655, Loss: 2.204534, Accuracy: 18.66%\n",
            "Epoch: 40, Step: 391/655, Loss: 2.204613, Accuracy: 18.66%\n",
            "Epoch: 40, Step: 392/655, Loss: 2.204717, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 393/655, Loss: 2.204902, Accuracy: 18.66%\n",
            "Epoch: 40, Step: 394/655, Loss: 2.205315, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 395/655, Loss: 2.205575, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 396/655, Loss: 2.205784, Accuracy: 18.64%\n",
            "Epoch: 40, Step: 397/655, Loss: 2.205820, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 398/655, Loss: 2.205605, Accuracy: 18.64%\n",
            "Epoch: 40, Step: 399/655, Loss: 2.205462, Accuracy: 18.66%\n",
            "Epoch: 40, Step: 400/655, Loss: 2.205397, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 401/655, Loss: 2.205644, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 402/655, Loss: 2.205599, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 403/655, Loss: 2.205588, Accuracy: 18.66%\n",
            "Epoch: 40, Step: 404/655, Loss: 2.205090, Accuracy: 18.71%\n",
            "Epoch: 40, Step: 405/655, Loss: 2.205229, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 406/655, Loss: 2.205353, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 407/655, Loss: 2.205629, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 408/655, Loss: 2.205887, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 409/655, Loss: 2.205684, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 410/655, Loss: 2.205743, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 411/655, Loss: 2.205553, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 412/655, Loss: 2.205828, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 413/655, Loss: 2.205658, Accuracy: 18.69%\n",
            "Epoch: 40, Step: 414/655, Loss: 2.205908, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 415/655, Loss: 2.205919, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 416/655, Loss: 2.206009, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 417/655, Loss: 2.206144, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 418/655, Loss: 2.206335, Accuracy: 18.68%\n",
            "Epoch: 40, Step: 419/655, Loss: 2.206344, Accuracy: 18.71%\n",
            "Epoch: 40, Step: 420/655, Loss: 2.206517, Accuracy: 18.71%\n",
            "Epoch: 40, Step: 421/655, Loss: 2.206596, Accuracy: 18.70%\n",
            "Epoch: 40, Step: 422/655, Loss: 2.206759, Accuracy: 18.67%\n",
            "Epoch: 40, Step: 423/655, Loss: 2.206889, Accuracy: 18.66%\n",
            "Epoch: 40, Step: 424/655, Loss: 2.206832, Accuracy: 18.65%\n",
            "Epoch: 40, Step: 425/655, Loss: 2.206988, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 426/655, Loss: 2.206974, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 427/655, Loss: 2.207146, Accuracy: 18.59%\n",
            "Epoch: 40, Step: 428/655, Loss: 2.206780, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 429/655, Loss: 2.207156, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 430/655, Loss: 2.206912, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 431/655, Loss: 2.207109, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 432/655, Loss: 2.207205, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 433/655, Loss: 2.206982, Accuracy: 18.59%\n",
            "Epoch: 40, Step: 434/655, Loss: 2.207118, Accuracy: 18.58%\n",
            "Epoch: 40, Step: 435/655, Loss: 2.206917, Accuracy: 18.58%\n",
            "Epoch: 40, Step: 436/655, Loss: 2.206609, Accuracy: 18.59%\n",
            "Epoch: 40, Step: 437/655, Loss: 2.206513, Accuracy: 18.60%\n",
            "Epoch: 40, Step: 438/655, Loss: 2.206481, Accuracy: 18.61%\n",
            "Epoch: 40, Step: 439/655, Loss: 2.206351, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 440/655, Loss: 2.206416, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 441/655, Loss: 2.206547, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 442/655, Loss: 2.206761, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 443/655, Loss: 2.206450, Accuracy: 18.64%\n",
            "Epoch: 40, Step: 444/655, Loss: 2.206609, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 445/655, Loss: 2.206561, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 446/655, Loss: 2.206364, Accuracy: 18.64%\n",
            "Epoch: 40, Step: 447/655, Loss: 2.206599, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 448/655, Loss: 2.206682, Accuracy: 18.63%\n",
            "Epoch: 40, Step: 449/655, Loss: 2.206640, Accuracy: 18.62%\n",
            "Epoch: 40, Step: 450/655, Loss: 2.206821, Accuracy: 18.59%\n",
            "Epoch: 40, Step: 451/655, Loss: 2.206796, Accuracy: 18.57%\n",
            "Epoch: 40, Step: 452/655, Loss: 2.207050, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 453/655, Loss: 2.207017, Accuracy: 18.57%\n",
            "Epoch: 40, Step: 454/655, Loss: 2.207162, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 455/655, Loss: 2.206869, Accuracy: 18.55%\n",
            "Epoch: 40, Step: 456/655, Loss: 2.206648, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 457/655, Loss: 2.206588, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 458/655, Loss: 2.206633, Accuracy: 18.55%\n",
            "Epoch: 40, Step: 459/655, Loss: 2.206805, Accuracy: 18.52%\n",
            "Epoch: 40, Step: 460/655, Loss: 2.206844, Accuracy: 18.53%\n",
            "Epoch: 40, Step: 461/655, Loss: 2.206963, Accuracy: 18.51%\n",
            "Epoch: 40, Step: 462/655, Loss: 2.207136, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 463/655, Loss: 2.207285, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 464/655, Loss: 2.207129, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 465/655, Loss: 2.207480, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 466/655, Loss: 2.207335, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 467/655, Loss: 2.207377, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 468/655, Loss: 2.207382, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 469/655, Loss: 2.207250, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 470/655, Loss: 2.207176, Accuracy: 18.44%\n",
            "Epoch: 40, Step: 471/655, Loss: 2.207100, Accuracy: 18.44%\n",
            "Epoch: 40, Step: 472/655, Loss: 2.206965, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 473/655, Loss: 2.207169, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 474/655, Loss: 2.207042, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 475/655, Loss: 2.207128, Accuracy: 18.46%\n",
            "Epoch: 40, Step: 476/655, Loss: 2.207297, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 477/655, Loss: 2.206871, Accuracy: 18.50%\n",
            "Epoch: 40, Step: 478/655, Loss: 2.206639, Accuracy: 18.53%\n",
            "Epoch: 40, Step: 479/655, Loss: 2.206653, Accuracy: 18.52%\n",
            "Epoch: 40, Step: 480/655, Loss: 2.206655, Accuracy: 18.54%\n",
            "Epoch: 40, Step: 481/655, Loss: 2.206686, Accuracy: 18.54%\n",
            "Epoch: 40, Step: 482/655, Loss: 2.206822, Accuracy: 18.55%\n",
            "Epoch: 40, Step: 483/655, Loss: 2.207401, Accuracy: 18.53%\n",
            "Epoch: 40, Step: 484/655, Loss: 2.207359, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 485/655, Loss: 2.207558, Accuracy: 18.54%\n",
            "Epoch: 40, Step: 486/655, Loss: 2.207526, Accuracy: 18.54%\n",
            "Epoch: 40, Step: 487/655, Loss: 2.207379, Accuracy: 18.53%\n",
            "Epoch: 40, Step: 488/655, Loss: 2.207162, Accuracy: 18.53%\n",
            "Epoch: 40, Step: 489/655, Loss: 2.206869, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 490/655, Loss: 2.206684, Accuracy: 18.55%\n",
            "Epoch: 40, Step: 491/655, Loss: 2.206697, Accuracy: 18.51%\n",
            "Epoch: 40, Step: 492/655, Loss: 2.206649, Accuracy: 18.53%\n",
            "Epoch: 40, Step: 493/655, Loss: 2.206734, Accuracy: 18.52%\n",
            "Epoch: 40, Step: 494/655, Loss: 2.206710, Accuracy: 18.53%\n",
            "Epoch: 40, Step: 495/655, Loss: 2.206694, Accuracy: 18.54%\n",
            "Epoch: 40, Step: 496/655, Loss: 2.206672, Accuracy: 18.53%\n",
            "Epoch: 40, Step: 497/655, Loss: 2.206645, Accuracy: 18.53%\n",
            "Epoch: 40, Step: 498/655, Loss: 2.206637, Accuracy: 18.53%\n",
            "Epoch: 40, Step: 499/655, Loss: 2.206453, Accuracy: 18.54%\n",
            "Epoch: 40, Step: 500/655, Loss: 2.206482, Accuracy: 18.53%\n",
            "Epoch: 40, Step: 501/655, Loss: 2.206469, Accuracy: 18.54%\n",
            "Epoch: 40, Step: 502/655, Loss: 2.206498, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 503/655, Loss: 2.206531, Accuracy: 18.57%\n",
            "Epoch: 40, Step: 504/655, Loss: 2.206318, Accuracy: 18.58%\n",
            "Epoch: 40, Step: 505/655, Loss: 2.206329, Accuracy: 18.58%\n",
            "Epoch: 40, Step: 506/655, Loss: 2.206406, Accuracy: 18.56%\n",
            "Epoch: 40, Step: 507/655, Loss: 2.206700, Accuracy: 18.55%\n",
            "Epoch: 40, Step: 508/655, Loss: 2.206940, Accuracy: 18.52%\n",
            "Epoch: 40, Step: 509/655, Loss: 2.207022, Accuracy: 18.51%\n",
            "Epoch: 40, Step: 510/655, Loss: 2.206942, Accuracy: 18.50%\n",
            "Epoch: 40, Step: 511/655, Loss: 2.207154, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 512/655, Loss: 2.207375, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 513/655, Loss: 2.207534, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 514/655, Loss: 2.207714, Accuracy: 18.44%\n",
            "Epoch: 40, Step: 515/655, Loss: 2.207880, Accuracy: 18.43%\n",
            "Epoch: 40, Step: 516/655, Loss: 2.208014, Accuracy: 18.41%\n",
            "Epoch: 40, Step: 517/655, Loss: 2.207995, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 518/655, Loss: 2.208168, Accuracy: 18.39%\n",
            "Epoch: 40, Step: 519/655, Loss: 2.208316, Accuracy: 18.39%\n",
            "Epoch: 40, Step: 520/655, Loss: 2.208344, Accuracy: 18.41%\n",
            "Epoch: 40, Step: 521/655, Loss: 2.208559, Accuracy: 18.37%\n",
            "Epoch: 40, Step: 522/655, Loss: 2.208641, Accuracy: 18.37%\n",
            "Epoch: 40, Step: 523/655, Loss: 2.208741, Accuracy: 18.37%\n",
            "Epoch: 40, Step: 524/655, Loss: 2.208704, Accuracy: 18.34%\n",
            "Epoch: 40, Step: 525/655, Loss: 2.208580, Accuracy: 18.37%\n",
            "Epoch: 40, Step: 526/655, Loss: 2.208519, Accuracy: 18.39%\n",
            "Epoch: 40, Step: 527/655, Loss: 2.208246, Accuracy: 18.42%\n",
            "Epoch: 40, Step: 528/655, Loss: 2.208499, Accuracy: 18.43%\n",
            "Epoch: 40, Step: 529/655, Loss: 2.208621, Accuracy: 18.41%\n",
            "Epoch: 40, Step: 530/655, Loss: 2.208769, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 531/655, Loss: 2.208790, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 532/655, Loss: 2.208859, Accuracy: 18.39%\n",
            "Epoch: 40, Step: 533/655, Loss: 2.208771, Accuracy: 18.37%\n",
            "Epoch: 40, Step: 534/655, Loss: 2.208576, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 535/655, Loss: 2.208693, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 536/655, Loss: 2.208725, Accuracy: 18.38%\n",
            "Epoch: 40, Step: 537/655, Loss: 2.208707, Accuracy: 18.37%\n",
            "Epoch: 40, Step: 538/655, Loss: 2.208481, Accuracy: 18.38%\n",
            "Epoch: 40, Step: 539/655, Loss: 2.208565, Accuracy: 18.38%\n",
            "Epoch: 40, Step: 540/655, Loss: 2.208584, Accuracy: 18.39%\n",
            "Epoch: 40, Step: 541/655, Loss: 2.208451, Accuracy: 18.39%\n",
            "Epoch: 40, Step: 542/655, Loss: 2.208303, Accuracy: 18.39%\n",
            "Epoch: 40, Step: 543/655, Loss: 2.208145, Accuracy: 18.39%\n",
            "Epoch: 40, Step: 544/655, Loss: 2.208316, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 545/655, Loss: 2.208493, Accuracy: 18.39%\n",
            "Epoch: 40, Step: 546/655, Loss: 2.208623, Accuracy: 18.38%\n",
            "Epoch: 40, Step: 547/655, Loss: 2.208556, Accuracy: 18.38%\n",
            "Epoch: 40, Step: 548/655, Loss: 2.208339, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 549/655, Loss: 2.208428, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 550/655, Loss: 2.208468, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 551/655, Loss: 2.208528, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 552/655, Loss: 2.208230, Accuracy: 18.42%\n",
            "Epoch: 40, Step: 553/655, Loss: 2.208604, Accuracy: 18.41%\n",
            "Epoch: 40, Step: 554/655, Loss: 2.208402, Accuracy: 18.42%\n",
            "Epoch: 40, Step: 555/655, Loss: 2.208786, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 556/655, Loss: 2.208842, Accuracy: 18.38%\n",
            "Epoch: 40, Step: 557/655, Loss: 2.209063, Accuracy: 18.37%\n",
            "Epoch: 40, Step: 558/655, Loss: 2.209035, Accuracy: 18.36%\n",
            "Epoch: 40, Step: 559/655, Loss: 2.209072, Accuracy: 18.36%\n",
            "Epoch: 40, Step: 560/655, Loss: 2.208894, Accuracy: 18.36%\n",
            "Epoch: 40, Step: 561/655, Loss: 2.208862, Accuracy: 18.37%\n",
            "Epoch: 40, Step: 562/655, Loss: 2.208873, Accuracy: 18.38%\n",
            "Epoch: 40, Step: 563/655, Loss: 2.208846, Accuracy: 18.38%\n",
            "Epoch: 40, Step: 564/655, Loss: 2.208629, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 565/655, Loss: 2.208619, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 566/655, Loss: 2.208516, Accuracy: 18.41%\n",
            "Epoch: 40, Step: 567/655, Loss: 2.208868, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 568/655, Loss: 2.208900, Accuracy: 18.41%\n",
            "Epoch: 40, Step: 569/655, Loss: 2.208894, Accuracy: 18.40%\n",
            "Epoch: 40, Step: 570/655, Loss: 2.208924, Accuracy: 18.39%\n",
            "Epoch: 40, Step: 571/655, Loss: 2.208819, Accuracy: 18.42%\n",
            "Epoch: 40, Step: 572/655, Loss: 2.208743, Accuracy: 18.44%\n",
            "Epoch: 40, Step: 573/655, Loss: 2.208646, Accuracy: 18.43%\n",
            "Epoch: 40, Step: 574/655, Loss: 2.208473, Accuracy: 18.42%\n",
            "Epoch: 40, Step: 575/655, Loss: 2.208260, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 576/655, Loss: 2.208305, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 577/655, Loss: 2.208095, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 578/655, Loss: 2.208063, Accuracy: 18.46%\n",
            "Epoch: 40, Step: 579/655, Loss: 2.207992, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 580/655, Loss: 2.207958, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 581/655, Loss: 2.207976, Accuracy: 18.46%\n",
            "Epoch: 40, Step: 582/655, Loss: 2.207896, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 583/655, Loss: 2.208072, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 584/655, Loss: 2.208175, Accuracy: 18.43%\n",
            "Epoch: 40, Step: 585/655, Loss: 2.207967, Accuracy: 18.44%\n",
            "Epoch: 40, Step: 586/655, Loss: 2.207976, Accuracy: 18.44%\n",
            "Epoch: 40, Step: 587/655, Loss: 2.208028, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 588/655, Loss: 2.207969, Accuracy: 18.44%\n",
            "Epoch: 40, Step: 589/655, Loss: 2.207853, Accuracy: 18.43%\n",
            "Epoch: 40, Step: 590/655, Loss: 2.207914, Accuracy: 18.44%\n",
            "Epoch: 40, Step: 591/655, Loss: 2.207974, Accuracy: 18.44%\n",
            "Epoch: 40, Step: 592/655, Loss: 2.208079, Accuracy: 18.43%\n",
            "Epoch: 40, Step: 593/655, Loss: 2.207972, Accuracy: 18.44%\n",
            "Epoch: 40, Step: 594/655, Loss: 2.207805, Accuracy: 18.44%\n",
            "Epoch: 40, Step: 595/655, Loss: 2.207851, Accuracy: 18.44%\n",
            "Epoch: 40, Step: 596/655, Loss: 2.207603, Accuracy: 18.46%\n",
            "Epoch: 40, Step: 597/655, Loss: 2.207411, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 598/655, Loss: 2.207408, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 599/655, Loss: 2.207396, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 600/655, Loss: 2.207269, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 601/655, Loss: 2.207092, Accuracy: 18.50%\n",
            "Epoch: 40, Step: 602/655, Loss: 2.207243, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 603/655, Loss: 2.207166, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 604/655, Loss: 2.207008, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 605/655, Loss: 2.207044, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 606/655, Loss: 2.206899, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 607/655, Loss: 2.206776, Accuracy: 18.51%\n",
            "Epoch: 40, Step: 608/655, Loss: 2.206805, Accuracy: 18.51%\n",
            "Epoch: 40, Step: 609/655, Loss: 2.206753, Accuracy: 18.51%\n",
            "Epoch: 40, Step: 610/655, Loss: 2.206932, Accuracy: 18.51%\n",
            "Epoch: 40, Step: 611/655, Loss: 2.206736, Accuracy: 18.51%\n",
            "Epoch: 40, Step: 612/655, Loss: 2.206753, Accuracy: 18.52%\n",
            "Epoch: 40, Step: 613/655, Loss: 2.207112, Accuracy: 18.50%\n",
            "Epoch: 40, Step: 614/655, Loss: 2.207321, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 615/655, Loss: 2.207125, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 616/655, Loss: 2.206999, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 617/655, Loss: 2.207058, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 618/655, Loss: 2.206873, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 619/655, Loss: 2.206951, Accuracy: 18.48%\n",
            "Epoch: 40, Step: 620/655, Loss: 2.206793, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 621/655, Loss: 2.206812, Accuracy: 18.50%\n",
            "Epoch: 40, Step: 622/655, Loss: 2.206566, Accuracy: 18.51%\n",
            "Epoch: 40, Step: 623/655, Loss: 2.206557, Accuracy: 18.52%\n",
            "Epoch: 40, Step: 624/655, Loss: 2.206596, Accuracy: 18.52%\n",
            "Epoch: 40, Step: 625/655, Loss: 2.206717, Accuracy: 18.50%\n",
            "Epoch: 40, Step: 626/655, Loss: 2.206905, Accuracy: 18.51%\n",
            "Epoch: 40, Step: 627/655, Loss: 2.207189, Accuracy: 18.50%\n",
            "Epoch: 40, Step: 628/655, Loss: 2.207304, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 629/655, Loss: 2.207274, Accuracy: 18.48%\n",
            "Epoch: 40, Step: 630/655, Loss: 2.207315, Accuracy: 18.48%\n",
            "Epoch: 40, Step: 631/655, Loss: 2.207515, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 632/655, Loss: 2.207494, Accuracy: 18.48%\n",
            "Epoch: 40, Step: 633/655, Loss: 2.207465, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 634/655, Loss: 2.207649, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 635/655, Loss: 2.207710, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 636/655, Loss: 2.207782, Accuracy: 18.46%\n",
            "Epoch: 40, Step: 637/655, Loss: 2.207712, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 638/655, Loss: 2.207756, Accuracy: 18.44%\n",
            "Epoch: 40, Step: 639/655, Loss: 2.207738, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 640/655, Loss: 2.207712, Accuracy: 18.43%\n",
            "Epoch: 40, Step: 641/655, Loss: 2.207642, Accuracy: 18.42%\n",
            "Epoch: 40, Step: 642/655, Loss: 2.207742, Accuracy: 18.42%\n",
            "Epoch: 40, Step: 643/655, Loss: 2.207693, Accuracy: 18.42%\n",
            "Epoch: 40, Step: 644/655, Loss: 2.207515, Accuracy: 18.42%\n",
            "Epoch: 40, Step: 645/655, Loss: 2.207538, Accuracy: 18.41%\n",
            "Epoch: 40, Step: 646/655, Loss: 2.207404, Accuracy: 18.43%\n",
            "Epoch: 40, Step: 647/655, Loss: 2.207173, Accuracy: 18.46%\n",
            "Epoch: 40, Step: 648/655, Loss: 2.207242, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 649/655, Loss: 2.207569, Accuracy: 18.45%\n",
            "Epoch: 40, Step: 650/655, Loss: 2.207425, Accuracy: 18.46%\n",
            "Epoch: 40, Step: 651/655, Loss: 2.207395, Accuracy: 18.46%\n",
            "Epoch: 40, Step: 652/655, Loss: 2.207335, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 653/655, Loss: 2.207449, Accuracy: 18.47%\n",
            "Epoch: 40, Step: 654/655, Loss: 2.207462, Accuracy: 18.49%\n",
            "Epoch: 40, Step: 655/655, Loss: 2.207522, Accuracy: 18.49%\n",
            "Epoch: 41, Step: 1/655, Loss: 2.236528, Accuracy: 18.75%\n",
            "Epoch: 41, Step: 2/655, Loss: 2.249141, Accuracy: 18.75%\n",
            "Epoch: 41, Step: 3/655, Loss: 2.224370, Accuracy: 17.71%\n",
            "Epoch: 41, Step: 4/655, Loss: 2.246701, Accuracy: 17.19%\n",
            "Epoch: 41, Step: 5/655, Loss: 2.244370, Accuracy: 17.50%\n",
            "Epoch: 41, Step: 6/655, Loss: 2.233695, Accuracy: 17.71%\n",
            "Epoch: 41, Step: 7/655, Loss: 2.241723, Accuracy: 17.86%\n",
            "Epoch: 41, Step: 8/655, Loss: 2.245927, Accuracy: 17.58%\n",
            "Epoch: 41, Step: 9/655, Loss: 2.237730, Accuracy: 18.40%\n",
            "Epoch: 41, Step: 10/655, Loss: 2.233627, Accuracy: 19.06%\n",
            "Epoch: 41, Step: 11/655, Loss: 2.232127, Accuracy: 19.03%\n",
            "Epoch: 41, Step: 12/655, Loss: 2.235176, Accuracy: 18.49%\n",
            "Epoch: 41, Step: 13/655, Loss: 2.237969, Accuracy: 18.51%\n",
            "Epoch: 41, Step: 14/655, Loss: 2.241847, Accuracy: 17.41%\n",
            "Epoch: 41, Step: 15/655, Loss: 2.227955, Accuracy: 18.54%\n",
            "Epoch: 41, Step: 16/655, Loss: 2.223399, Accuracy: 18.55%\n",
            "Epoch: 41, Step: 17/655, Loss: 2.224960, Accuracy: 18.01%\n",
            "Epoch: 41, Step: 18/655, Loss: 2.221662, Accuracy: 18.06%\n",
            "Epoch: 41, Step: 19/655, Loss: 2.213381, Accuracy: 18.26%\n",
            "Epoch: 41, Step: 20/655, Loss: 2.215301, Accuracy: 17.66%\n",
            "Epoch: 41, Step: 21/655, Loss: 2.209533, Accuracy: 17.86%\n",
            "Epoch: 41, Step: 22/655, Loss: 2.209931, Accuracy: 17.76%\n",
            "Epoch: 41, Step: 23/655, Loss: 2.209699, Accuracy: 17.26%\n",
            "Epoch: 41, Step: 24/655, Loss: 2.206933, Accuracy: 17.19%\n",
            "Epoch: 41, Step: 25/655, Loss: 2.204992, Accuracy: 17.62%\n",
            "Epoch: 41, Step: 26/655, Loss: 2.205281, Accuracy: 17.79%\n",
            "Epoch: 41, Step: 27/655, Loss: 2.206639, Accuracy: 17.25%\n",
            "Epoch: 41, Step: 28/655, Loss: 2.206349, Accuracy: 17.52%\n",
            "Epoch: 41, Step: 29/655, Loss: 2.205900, Accuracy: 17.67%\n",
            "Epoch: 41, Step: 30/655, Loss: 2.206198, Accuracy: 17.50%\n",
            "Epoch: 41, Step: 31/655, Loss: 2.203710, Accuracy: 17.44%\n",
            "Epoch: 41, Step: 32/655, Loss: 2.201508, Accuracy: 17.68%\n",
            "Epoch: 41, Step: 33/655, Loss: 2.198645, Accuracy: 17.90%\n",
            "Epoch: 41, Step: 34/655, Loss: 2.203034, Accuracy: 17.92%\n",
            "Epoch: 41, Step: 35/655, Loss: 2.203485, Accuracy: 17.95%\n",
            "Epoch: 41, Step: 36/655, Loss: 2.206010, Accuracy: 17.80%\n",
            "Epoch: 41, Step: 37/655, Loss: 2.205613, Accuracy: 17.91%\n",
            "Epoch: 41, Step: 38/655, Loss: 2.209089, Accuracy: 17.60%\n",
            "Epoch: 41, Step: 39/655, Loss: 2.212370, Accuracy: 17.39%\n",
            "Epoch: 41, Step: 40/655, Loss: 2.210874, Accuracy: 17.42%\n",
            "Epoch: 41, Step: 41/655, Loss: 2.212644, Accuracy: 17.38%\n",
            "Epoch: 41, Step: 42/655, Loss: 2.213213, Accuracy: 17.34%\n",
            "Epoch: 41, Step: 43/655, Loss: 2.212806, Accuracy: 17.37%\n",
            "Epoch: 41, Step: 44/655, Loss: 2.210967, Accuracy: 17.54%\n",
            "Epoch: 41, Step: 45/655, Loss: 2.206955, Accuracy: 17.57%\n",
            "Epoch: 41, Step: 46/655, Loss: 2.206777, Accuracy: 17.93%\n",
            "Epoch: 41, Step: 47/655, Loss: 2.205829, Accuracy: 18.15%\n",
            "Epoch: 41, Step: 48/655, Loss: 2.204131, Accuracy: 18.36%\n",
            "Epoch: 41, Step: 49/655, Loss: 2.202607, Accuracy: 18.56%\n",
            "Epoch: 41, Step: 50/655, Loss: 2.202372, Accuracy: 18.38%\n",
            "Epoch: 41, Step: 51/655, Loss: 2.201777, Accuracy: 18.32%\n",
            "Epoch: 41, Step: 52/655, Loss: 2.200862, Accuracy: 18.51%\n",
            "Epoch: 41, Step: 53/655, Loss: 2.201264, Accuracy: 18.81%\n",
            "Epoch: 41, Step: 54/655, Loss: 2.200648, Accuracy: 19.04%\n",
            "Epoch: 41, Step: 55/655, Loss: 2.202371, Accuracy: 18.92%\n",
            "Epoch: 41, Step: 56/655, Loss: 2.201281, Accuracy: 19.03%\n",
            "Epoch: 41, Step: 57/655, Loss: 2.201038, Accuracy: 19.02%\n",
            "Epoch: 41, Step: 58/655, Loss: 2.201850, Accuracy: 18.97%\n",
            "Epoch: 41, Step: 59/655, Loss: 2.199942, Accuracy: 19.01%\n",
            "Epoch: 41, Step: 60/655, Loss: 2.202099, Accuracy: 18.96%\n",
            "Epoch: 41, Step: 61/655, Loss: 2.202953, Accuracy: 19.06%\n",
            "Epoch: 41, Step: 62/655, Loss: 2.205364, Accuracy: 18.85%\n",
            "Epoch: 41, Step: 63/655, Loss: 2.207414, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 64/655, Loss: 2.205742, Accuracy: 18.90%\n",
            "Epoch: 41, Step: 65/655, Loss: 2.204784, Accuracy: 18.89%\n",
            "Epoch: 41, Step: 66/655, Loss: 2.204798, Accuracy: 19.08%\n",
            "Epoch: 41, Step: 67/655, Loss: 2.206828, Accuracy: 19.03%\n",
            "Epoch: 41, Step: 68/655, Loss: 2.206308, Accuracy: 18.93%\n",
            "Epoch: 41, Step: 69/655, Loss: 2.205399, Accuracy: 18.89%\n",
            "Epoch: 41, Step: 70/655, Loss: 2.206937, Accuracy: 18.84%\n",
            "Epoch: 41, Step: 71/655, Loss: 2.206144, Accuracy: 18.88%\n",
            "Epoch: 41, Step: 72/655, Loss: 2.206619, Accuracy: 18.88%\n",
            "Epoch: 41, Step: 73/655, Loss: 2.205888, Accuracy: 18.84%\n",
            "Epoch: 41, Step: 74/655, Loss: 2.207965, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 75/655, Loss: 2.207711, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 76/655, Loss: 2.208321, Accuracy: 18.54%\n",
            "Epoch: 41, Step: 77/655, Loss: 2.208466, Accuracy: 18.55%\n",
            "Epoch: 41, Step: 78/655, Loss: 2.208286, Accuracy: 18.51%\n",
            "Epoch: 41, Step: 79/655, Loss: 2.207850, Accuracy: 18.43%\n",
            "Epoch: 41, Step: 80/655, Loss: 2.205890, Accuracy: 18.52%\n",
            "Epoch: 41, Step: 81/655, Loss: 2.204732, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 82/655, Loss: 2.204740, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 83/655, Loss: 2.204868, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 84/655, Loss: 2.204680, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 85/655, Loss: 2.206687, Accuracy: 18.53%\n",
            "Epoch: 41, Step: 86/655, Loss: 2.208600, Accuracy: 18.50%\n",
            "Epoch: 41, Step: 87/655, Loss: 2.208836, Accuracy: 18.53%\n",
            "Epoch: 41, Step: 88/655, Loss: 2.208247, Accuracy: 18.54%\n",
            "Epoch: 41, Step: 89/655, Loss: 2.207463, Accuracy: 18.54%\n",
            "Epoch: 41, Step: 90/655, Loss: 2.206887, Accuracy: 18.54%\n",
            "Epoch: 41, Step: 91/655, Loss: 2.207814, Accuracy: 18.44%\n",
            "Epoch: 41, Step: 92/655, Loss: 2.208343, Accuracy: 18.38%\n",
            "Epoch: 41, Step: 93/655, Loss: 2.209079, Accuracy: 18.45%\n",
            "Epoch: 41, Step: 94/655, Loss: 2.208416, Accuracy: 18.45%\n",
            "Epoch: 41, Step: 95/655, Loss: 2.207881, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 96/655, Loss: 2.208698, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 97/655, Loss: 2.208454, Accuracy: 18.56%\n",
            "Epoch: 41, Step: 98/655, Loss: 2.208498, Accuracy: 18.56%\n",
            "Epoch: 41, Step: 99/655, Loss: 2.207659, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 100/655, Loss: 2.207868, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 101/655, Loss: 2.207672, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 102/655, Loss: 2.208303, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 103/655, Loss: 2.207283, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 104/655, Loss: 2.207140, Accuracy: 18.54%\n",
            "Epoch: 41, Step: 105/655, Loss: 2.207611, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 106/655, Loss: 2.206805, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 107/655, Loss: 2.206546, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 108/655, Loss: 2.206337, Accuracy: 18.55%\n",
            "Epoch: 41, Step: 109/655, Loss: 2.206720, Accuracy: 18.52%\n",
            "Epoch: 41, Step: 110/655, Loss: 2.206527, Accuracy: 18.55%\n",
            "Epoch: 41, Step: 111/655, Loss: 2.206958, Accuracy: 18.50%\n",
            "Epoch: 41, Step: 112/655, Loss: 2.206552, Accuracy: 18.58%\n",
            "Epoch: 41, Step: 113/655, Loss: 2.207232, Accuracy: 18.56%\n",
            "Epoch: 41, Step: 114/655, Loss: 2.207431, Accuracy: 18.56%\n",
            "Epoch: 41, Step: 115/655, Loss: 2.207316, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 116/655, Loss: 2.207248, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 117/655, Loss: 2.206414, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 118/655, Loss: 2.206213, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 119/655, Loss: 2.206136, Accuracy: 18.72%\n",
            "Epoch: 41, Step: 120/655, Loss: 2.205395, Accuracy: 18.80%\n",
            "Epoch: 41, Step: 121/655, Loss: 2.205345, Accuracy: 18.88%\n",
            "Epoch: 41, Step: 122/655, Loss: 2.204541, Accuracy: 18.95%\n",
            "Epoch: 41, Step: 123/655, Loss: 2.203889, Accuracy: 18.93%\n",
            "Epoch: 41, Step: 124/655, Loss: 2.204291, Accuracy: 18.98%\n",
            "Epoch: 41, Step: 125/655, Loss: 2.204589, Accuracy: 18.93%\n",
            "Epoch: 41, Step: 126/655, Loss: 2.204620, Accuracy: 18.90%\n",
            "Epoch: 41, Step: 127/655, Loss: 2.205032, Accuracy: 18.92%\n",
            "Epoch: 41, Step: 128/655, Loss: 2.206772, Accuracy: 18.82%\n",
            "Epoch: 41, Step: 129/655, Loss: 2.205627, Accuracy: 18.87%\n",
            "Epoch: 41, Step: 130/655, Loss: 2.206169, Accuracy: 18.80%\n",
            "Epoch: 41, Step: 131/655, Loss: 2.207595, Accuracy: 18.73%\n",
            "Epoch: 41, Step: 132/655, Loss: 2.208509, Accuracy: 18.68%\n",
            "Epoch: 41, Step: 133/655, Loss: 2.209895, Accuracy: 18.61%\n",
            "Epoch: 41, Step: 134/655, Loss: 2.209251, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 135/655, Loss: 2.209825, Accuracy: 18.61%\n",
            "Epoch: 41, Step: 136/655, Loss: 2.209848, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 137/655, Loss: 2.209753, Accuracy: 18.61%\n",
            "Epoch: 41, Step: 138/655, Loss: 2.210557, Accuracy: 18.61%\n",
            "Epoch: 41, Step: 139/655, Loss: 2.210742, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 140/655, Loss: 2.210237, Accuracy: 18.68%\n",
            "Epoch: 41, Step: 141/655, Loss: 2.210372, Accuracy: 18.75%\n",
            "Epoch: 41, Step: 142/655, Loss: 2.209653, Accuracy: 18.86%\n",
            "Epoch: 41, Step: 143/655, Loss: 2.210545, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 144/655, Loss: 2.210776, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 145/655, Loss: 2.210967, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 146/655, Loss: 2.211096, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 147/655, Loss: 2.211974, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 148/655, Loss: 2.212678, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 149/655, Loss: 2.211892, Accuracy: 18.83%\n",
            "Epoch: 41, Step: 150/655, Loss: 2.211755, Accuracy: 18.81%\n",
            "Epoch: 41, Step: 151/655, Loss: 2.212065, Accuracy: 18.85%\n",
            "Epoch: 41, Step: 152/655, Loss: 2.212529, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 153/655, Loss: 2.212135, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 154/655, Loss: 2.211608, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 155/655, Loss: 2.210953, Accuracy: 18.87%\n",
            "Epoch: 41, Step: 156/655, Loss: 2.210513, Accuracy: 18.95%\n",
            "Epoch: 41, Step: 157/655, Loss: 2.211272, Accuracy: 18.91%\n",
            "Epoch: 41, Step: 158/655, Loss: 2.210667, Accuracy: 18.95%\n",
            "Epoch: 41, Step: 159/655, Loss: 2.210780, Accuracy: 18.97%\n",
            "Epoch: 41, Step: 160/655, Loss: 2.210853, Accuracy: 19.00%\n",
            "Epoch: 41, Step: 161/655, Loss: 2.210727, Accuracy: 19.04%\n",
            "Epoch: 41, Step: 162/655, Loss: 2.211113, Accuracy: 19.02%\n",
            "Epoch: 41, Step: 163/655, Loss: 2.211266, Accuracy: 18.96%\n",
            "Epoch: 41, Step: 164/655, Loss: 2.211446, Accuracy: 18.92%\n",
            "Epoch: 41, Step: 165/655, Loss: 2.211588, Accuracy: 18.86%\n",
            "Epoch: 41, Step: 166/655, Loss: 2.210662, Accuracy: 18.90%\n",
            "Epoch: 41, Step: 167/655, Loss: 2.211411, Accuracy: 18.81%\n",
            "Epoch: 41, Step: 168/655, Loss: 2.210431, Accuracy: 18.84%\n",
            "Epoch: 41, Step: 169/655, Loss: 2.210180, Accuracy: 18.82%\n",
            "Epoch: 41, Step: 170/655, Loss: 2.209816, Accuracy: 18.88%\n",
            "Epoch: 41, Step: 171/655, Loss: 2.209538, Accuracy: 18.90%\n",
            "Epoch: 41, Step: 172/655, Loss: 2.209430, Accuracy: 18.90%\n",
            "Epoch: 41, Step: 173/655, Loss: 2.209277, Accuracy: 18.88%\n",
            "Epoch: 41, Step: 174/655, Loss: 2.209199, Accuracy: 18.88%\n",
            "Epoch: 41, Step: 175/655, Loss: 2.208642, Accuracy: 18.95%\n",
            "Epoch: 41, Step: 176/655, Loss: 2.208524, Accuracy: 18.98%\n",
            "Epoch: 41, Step: 177/655, Loss: 2.208034, Accuracy: 19.03%\n",
            "Epoch: 41, Step: 178/655, Loss: 2.207657, Accuracy: 19.10%\n",
            "Epoch: 41, Step: 179/655, Loss: 2.208164, Accuracy: 19.08%\n",
            "Epoch: 41, Step: 180/655, Loss: 2.207805, Accuracy: 19.01%\n",
            "Epoch: 41, Step: 181/655, Loss: 2.207206, Accuracy: 19.04%\n",
            "Epoch: 41, Step: 182/655, Loss: 2.207709, Accuracy: 19.04%\n",
            "Epoch: 41, Step: 183/655, Loss: 2.207507, Accuracy: 19.01%\n",
            "Epoch: 41, Step: 184/655, Loss: 2.207847, Accuracy: 18.97%\n",
            "Epoch: 41, Step: 185/655, Loss: 2.207762, Accuracy: 19.02%\n",
            "Epoch: 41, Step: 186/655, Loss: 2.207601, Accuracy: 19.10%\n",
            "Epoch: 41, Step: 187/655, Loss: 2.207445, Accuracy: 19.10%\n",
            "Epoch: 41, Step: 188/655, Loss: 2.207869, Accuracy: 19.07%\n",
            "Epoch: 41, Step: 189/655, Loss: 2.207537, Accuracy: 19.05%\n",
            "Epoch: 41, Step: 190/655, Loss: 2.207534, Accuracy: 19.06%\n",
            "Epoch: 41, Step: 191/655, Loss: 2.208059, Accuracy: 19.03%\n",
            "Epoch: 41, Step: 192/655, Loss: 2.207936, Accuracy: 19.03%\n",
            "Epoch: 41, Step: 193/655, Loss: 2.207192, Accuracy: 19.06%\n",
            "Epoch: 41, Step: 194/655, Loss: 2.207617, Accuracy: 19.02%\n",
            "Epoch: 41, Step: 195/655, Loss: 2.206695, Accuracy: 19.05%\n",
            "Epoch: 41, Step: 196/655, Loss: 2.206746, Accuracy: 19.04%\n",
            "Epoch: 41, Step: 197/655, Loss: 2.206627, Accuracy: 19.02%\n",
            "Epoch: 41, Step: 198/655, Loss: 2.206887, Accuracy: 19.03%\n",
            "Epoch: 41, Step: 199/655, Loss: 2.206459, Accuracy: 19.10%\n",
            "Epoch: 41, Step: 200/655, Loss: 2.206518, Accuracy: 19.06%\n",
            "Epoch: 41, Step: 201/655, Loss: 2.206905, Accuracy: 19.03%\n",
            "Epoch: 41, Step: 202/655, Loss: 2.207198, Accuracy: 19.01%\n",
            "Epoch: 41, Step: 203/655, Loss: 2.207247, Accuracy: 19.04%\n",
            "Epoch: 41, Step: 204/655, Loss: 2.206755, Accuracy: 19.10%\n",
            "Epoch: 41, Step: 205/655, Loss: 2.206356, Accuracy: 19.13%\n",
            "Epoch: 41, Step: 206/655, Loss: 2.206655, Accuracy: 19.11%\n",
            "Epoch: 41, Step: 207/655, Loss: 2.206517, Accuracy: 19.14%\n",
            "Epoch: 41, Step: 208/655, Loss: 2.206280, Accuracy: 19.16%\n",
            "Epoch: 41, Step: 209/655, Loss: 2.206154, Accuracy: 19.15%\n",
            "Epoch: 41, Step: 210/655, Loss: 2.206006, Accuracy: 19.17%\n",
            "Epoch: 41, Step: 211/655, Loss: 2.205856, Accuracy: 19.16%\n",
            "Epoch: 41, Step: 212/655, Loss: 2.206229, Accuracy: 19.16%\n",
            "Epoch: 41, Step: 213/655, Loss: 2.206737, Accuracy: 19.15%\n",
            "Epoch: 41, Step: 214/655, Loss: 2.206539, Accuracy: 19.17%\n",
            "Epoch: 41, Step: 215/655, Loss: 2.206518, Accuracy: 19.20%\n",
            "Epoch: 41, Step: 216/655, Loss: 2.206207, Accuracy: 19.21%\n",
            "Epoch: 41, Step: 217/655, Loss: 2.206319, Accuracy: 19.24%\n",
            "Epoch: 41, Step: 218/655, Loss: 2.206292, Accuracy: 19.25%\n",
            "Epoch: 41, Step: 219/655, Loss: 2.206269, Accuracy: 19.28%\n",
            "Epoch: 41, Step: 220/655, Loss: 2.205709, Accuracy: 19.30%\n",
            "Epoch: 41, Step: 221/655, Loss: 2.205599, Accuracy: 19.32%\n",
            "Epoch: 41, Step: 222/655, Loss: 2.205838, Accuracy: 19.27%\n",
            "Epoch: 41, Step: 223/655, Loss: 2.205399, Accuracy: 19.27%\n",
            "Epoch: 41, Step: 224/655, Loss: 2.205907, Accuracy: 19.27%\n",
            "Epoch: 41, Step: 225/655, Loss: 2.205700, Accuracy: 19.29%\n",
            "Epoch: 41, Step: 226/655, Loss: 2.205137, Accuracy: 19.32%\n",
            "Epoch: 41, Step: 227/655, Loss: 2.205593, Accuracy: 19.27%\n",
            "Epoch: 41, Step: 228/655, Loss: 2.205364, Accuracy: 19.27%\n",
            "Epoch: 41, Step: 229/655, Loss: 2.205353, Accuracy: 19.28%\n",
            "Epoch: 41, Step: 230/655, Loss: 2.205770, Accuracy: 19.29%\n",
            "Epoch: 41, Step: 231/655, Loss: 2.206343, Accuracy: 19.28%\n",
            "Epoch: 41, Step: 232/655, Loss: 2.206489, Accuracy: 19.26%\n",
            "Epoch: 41, Step: 233/655, Loss: 2.206331, Accuracy: 19.27%\n",
            "Epoch: 41, Step: 234/655, Loss: 2.206238, Accuracy: 19.23%\n",
            "Epoch: 41, Step: 235/655, Loss: 2.205918, Accuracy: 19.23%\n",
            "Epoch: 41, Step: 236/655, Loss: 2.205896, Accuracy: 19.25%\n",
            "Epoch: 41, Step: 237/655, Loss: 2.205572, Accuracy: 19.25%\n",
            "Epoch: 41, Step: 238/655, Loss: 2.205495, Accuracy: 19.25%\n",
            "Epoch: 41, Step: 239/655, Loss: 2.206072, Accuracy: 19.23%\n",
            "Epoch: 41, Step: 240/655, Loss: 2.205449, Accuracy: 19.30%\n",
            "Epoch: 41, Step: 241/655, Loss: 2.205489, Accuracy: 19.28%\n",
            "Epoch: 41, Step: 242/655, Loss: 2.205136, Accuracy: 19.28%\n",
            "Epoch: 41, Step: 243/655, Loss: 2.205007, Accuracy: 19.28%\n",
            "Epoch: 41, Step: 244/655, Loss: 2.205346, Accuracy: 19.26%\n",
            "Epoch: 41, Step: 245/655, Loss: 2.205085, Accuracy: 19.27%\n",
            "Epoch: 41, Step: 246/655, Loss: 2.204908, Accuracy: 19.25%\n",
            "Epoch: 41, Step: 247/655, Loss: 2.205029, Accuracy: 19.24%\n",
            "Epoch: 41, Step: 248/655, Loss: 2.204733, Accuracy: 19.29%\n",
            "Epoch: 41, Step: 249/655, Loss: 2.204650, Accuracy: 19.26%\n",
            "Epoch: 41, Step: 250/655, Loss: 2.204902, Accuracy: 19.23%\n",
            "Epoch: 41, Step: 251/655, Loss: 2.205078, Accuracy: 19.21%\n",
            "Epoch: 41, Step: 252/655, Loss: 2.205725, Accuracy: 19.20%\n",
            "Epoch: 41, Step: 253/655, Loss: 2.205497, Accuracy: 19.24%\n",
            "Epoch: 41, Step: 254/655, Loss: 2.205327, Accuracy: 19.23%\n",
            "Epoch: 41, Step: 255/655, Loss: 2.205049, Accuracy: 19.22%\n",
            "Epoch: 41, Step: 256/655, Loss: 2.204920, Accuracy: 19.23%\n",
            "Epoch: 41, Step: 257/655, Loss: 2.205462, Accuracy: 19.19%\n",
            "Epoch: 41, Step: 258/655, Loss: 2.205767, Accuracy: 19.16%\n",
            "Epoch: 41, Step: 259/655, Loss: 2.205480, Accuracy: 19.21%\n",
            "Epoch: 41, Step: 260/655, Loss: 2.205287, Accuracy: 19.23%\n",
            "Epoch: 41, Step: 261/655, Loss: 2.205069, Accuracy: 19.22%\n",
            "Epoch: 41, Step: 262/655, Loss: 2.205310, Accuracy: 19.19%\n",
            "Epoch: 41, Step: 263/655, Loss: 2.205502, Accuracy: 19.18%\n",
            "Epoch: 41, Step: 264/655, Loss: 2.205207, Accuracy: 19.18%\n",
            "Epoch: 41, Step: 265/655, Loss: 2.205334, Accuracy: 19.15%\n",
            "Epoch: 41, Step: 266/655, Loss: 2.205715, Accuracy: 19.11%\n",
            "Epoch: 41, Step: 267/655, Loss: 2.205538, Accuracy: 19.07%\n",
            "Epoch: 41, Step: 268/655, Loss: 2.205572, Accuracy: 19.06%\n",
            "Epoch: 41, Step: 269/655, Loss: 2.205832, Accuracy: 19.03%\n",
            "Epoch: 41, Step: 270/655, Loss: 2.206311, Accuracy: 18.98%\n",
            "Epoch: 41, Step: 271/655, Loss: 2.206296, Accuracy: 19.02%\n",
            "Epoch: 41, Step: 272/655, Loss: 2.206236, Accuracy: 19.06%\n",
            "Epoch: 41, Step: 273/655, Loss: 2.205981, Accuracy: 19.07%\n",
            "Epoch: 41, Step: 274/655, Loss: 2.206298, Accuracy: 19.08%\n",
            "Epoch: 41, Step: 275/655, Loss: 2.206121, Accuracy: 19.11%\n",
            "Epoch: 41, Step: 276/655, Loss: 2.206360, Accuracy: 19.10%\n",
            "Epoch: 41, Step: 277/655, Loss: 2.206903, Accuracy: 19.10%\n",
            "Epoch: 41, Step: 278/655, Loss: 2.207043, Accuracy: 19.08%\n",
            "Epoch: 41, Step: 279/655, Loss: 2.207455, Accuracy: 19.04%\n",
            "Epoch: 41, Step: 280/655, Loss: 2.207463, Accuracy: 19.01%\n",
            "Epoch: 41, Step: 281/655, Loss: 2.206962, Accuracy: 18.99%\n",
            "Epoch: 41, Step: 282/655, Loss: 2.207195, Accuracy: 18.97%\n",
            "Epoch: 41, Step: 283/655, Loss: 2.206529, Accuracy: 18.99%\n",
            "Epoch: 41, Step: 284/655, Loss: 2.206147, Accuracy: 18.98%\n",
            "Epoch: 41, Step: 285/655, Loss: 2.206178, Accuracy: 19.00%\n",
            "Epoch: 41, Step: 286/655, Loss: 2.206310, Accuracy: 18.96%\n",
            "Epoch: 41, Step: 287/655, Loss: 2.205846, Accuracy: 19.00%\n",
            "Epoch: 41, Step: 288/655, Loss: 2.206013, Accuracy: 19.00%\n",
            "Epoch: 41, Step: 289/655, Loss: 2.205772, Accuracy: 19.00%\n",
            "Epoch: 41, Step: 290/655, Loss: 2.205640, Accuracy: 19.00%\n",
            "Epoch: 41, Step: 291/655, Loss: 2.205770, Accuracy: 18.99%\n",
            "Epoch: 41, Step: 292/655, Loss: 2.205720, Accuracy: 19.00%\n",
            "Epoch: 41, Step: 293/655, Loss: 2.206032, Accuracy: 18.96%\n",
            "Epoch: 41, Step: 294/655, Loss: 2.205792, Accuracy: 18.93%\n",
            "Epoch: 41, Step: 295/655, Loss: 2.205526, Accuracy: 18.97%\n",
            "Epoch: 41, Step: 296/655, Loss: 2.205715, Accuracy: 18.94%\n",
            "Epoch: 41, Step: 297/655, Loss: 2.206089, Accuracy: 18.93%\n",
            "Epoch: 41, Step: 298/655, Loss: 2.205992, Accuracy: 18.92%\n",
            "Epoch: 41, Step: 299/655, Loss: 2.205839, Accuracy: 18.92%\n",
            "Epoch: 41, Step: 300/655, Loss: 2.205856, Accuracy: 18.92%\n",
            "Epoch: 41, Step: 301/655, Loss: 2.205791, Accuracy: 18.91%\n",
            "Epoch: 41, Step: 302/655, Loss: 2.206012, Accuracy: 18.89%\n",
            "Epoch: 41, Step: 303/655, Loss: 2.206360, Accuracy: 18.86%\n",
            "Epoch: 41, Step: 304/655, Loss: 2.206364, Accuracy: 18.86%\n",
            "Epoch: 41, Step: 305/655, Loss: 2.206779, Accuracy: 18.83%\n",
            "Epoch: 41, Step: 306/655, Loss: 2.206412, Accuracy: 18.86%\n",
            "Epoch: 41, Step: 307/655, Loss: 2.206421, Accuracy: 18.86%\n",
            "Epoch: 41, Step: 308/655, Loss: 2.206589, Accuracy: 18.84%\n",
            "Epoch: 41, Step: 309/655, Loss: 2.206691, Accuracy: 18.82%\n",
            "Epoch: 41, Step: 310/655, Loss: 2.207073, Accuracy: 18.81%\n",
            "Epoch: 41, Step: 311/655, Loss: 2.207356, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 312/655, Loss: 2.207485, Accuracy: 18.78%\n",
            "Epoch: 41, Step: 313/655, Loss: 2.207575, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 314/655, Loss: 2.207846, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 315/655, Loss: 2.207873, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 316/655, Loss: 2.207733, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 317/655, Loss: 2.207557, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 318/655, Loss: 2.207899, Accuracy: 18.75%\n",
            "Epoch: 41, Step: 319/655, Loss: 2.208040, Accuracy: 18.75%\n",
            "Epoch: 41, Step: 320/655, Loss: 2.208397, Accuracy: 18.74%\n",
            "Epoch: 41, Step: 321/655, Loss: 2.208152, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 322/655, Loss: 2.207905, Accuracy: 18.76%\n",
            "Epoch: 41, Step: 323/655, Loss: 2.207370, Accuracy: 18.76%\n",
            "Epoch: 41, Step: 324/655, Loss: 2.207505, Accuracy: 18.75%\n",
            "Epoch: 41, Step: 325/655, Loss: 2.207479, Accuracy: 18.75%\n",
            "Epoch: 41, Step: 326/655, Loss: 2.207513, Accuracy: 18.78%\n",
            "Epoch: 41, Step: 327/655, Loss: 2.207654, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 328/655, Loss: 2.207846, Accuracy: 18.76%\n",
            "Epoch: 41, Step: 329/655, Loss: 2.207979, Accuracy: 18.75%\n",
            "Epoch: 41, Step: 330/655, Loss: 2.208028, Accuracy: 18.76%\n",
            "Epoch: 41, Step: 331/655, Loss: 2.208091, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 332/655, Loss: 2.208002, Accuracy: 18.75%\n",
            "Epoch: 41, Step: 333/655, Loss: 2.208300, Accuracy: 18.73%\n",
            "Epoch: 41, Step: 334/655, Loss: 2.208222, Accuracy: 18.76%\n",
            "Epoch: 41, Step: 335/655, Loss: 2.207881, Accuracy: 18.78%\n",
            "Epoch: 41, Step: 336/655, Loss: 2.207760, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 337/655, Loss: 2.207954, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 338/655, Loss: 2.207799, Accuracy: 18.78%\n",
            "Epoch: 41, Step: 339/655, Loss: 2.207878, Accuracy: 18.75%\n",
            "Epoch: 41, Step: 340/655, Loss: 2.207862, Accuracy: 18.74%\n",
            "Epoch: 41, Step: 341/655, Loss: 2.207903, Accuracy: 18.71%\n",
            "Epoch: 41, Step: 342/655, Loss: 2.207914, Accuracy: 18.75%\n",
            "Epoch: 41, Step: 343/655, Loss: 2.207798, Accuracy: 18.78%\n",
            "Epoch: 41, Step: 344/655, Loss: 2.207863, Accuracy: 18.76%\n",
            "Epoch: 41, Step: 345/655, Loss: 2.208047, Accuracy: 18.75%\n",
            "Epoch: 41, Step: 346/655, Loss: 2.208122, Accuracy: 18.76%\n",
            "Epoch: 41, Step: 347/655, Loss: 2.208250, Accuracy: 18.74%\n",
            "Epoch: 41, Step: 348/655, Loss: 2.208444, Accuracy: 18.73%\n",
            "Epoch: 41, Step: 349/655, Loss: 2.208434, Accuracy: 18.71%\n",
            "Epoch: 41, Step: 350/655, Loss: 2.208044, Accuracy: 18.73%\n",
            "Epoch: 41, Step: 351/655, Loss: 2.208059, Accuracy: 18.71%\n",
            "Epoch: 41, Step: 352/655, Loss: 2.208192, Accuracy: 18.72%\n",
            "Epoch: 41, Step: 353/655, Loss: 2.208022, Accuracy: 18.74%\n",
            "Epoch: 41, Step: 354/655, Loss: 2.207879, Accuracy: 18.74%\n",
            "Epoch: 41, Step: 355/655, Loss: 2.207534, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 356/655, Loss: 2.207522, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 357/655, Loss: 2.207594, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 358/655, Loss: 2.207427, Accuracy: 18.78%\n",
            "Epoch: 41, Step: 359/655, Loss: 2.207854, Accuracy: 18.74%\n",
            "Epoch: 41, Step: 360/655, Loss: 2.207786, Accuracy: 18.74%\n",
            "Epoch: 41, Step: 361/655, Loss: 2.207715, Accuracy: 18.73%\n",
            "Epoch: 41, Step: 362/655, Loss: 2.208014, Accuracy: 18.72%\n",
            "Epoch: 41, Step: 363/655, Loss: 2.207835, Accuracy: 18.72%\n",
            "Epoch: 41, Step: 364/655, Loss: 2.207736, Accuracy: 18.70%\n",
            "Epoch: 41, Step: 365/655, Loss: 2.207468, Accuracy: 18.72%\n",
            "Epoch: 41, Step: 366/655, Loss: 2.207490, Accuracy: 18.74%\n",
            "Epoch: 41, Step: 367/655, Loss: 2.207496, Accuracy: 18.73%\n",
            "Epoch: 41, Step: 368/655, Loss: 2.207566, Accuracy: 18.74%\n",
            "Epoch: 41, Step: 369/655, Loss: 2.207377, Accuracy: 18.75%\n",
            "Epoch: 41, Step: 370/655, Loss: 2.207292, Accuracy: 18.78%\n",
            "Epoch: 41, Step: 371/655, Loss: 2.207177, Accuracy: 18.83%\n",
            "Epoch: 41, Step: 372/655, Loss: 2.207146, Accuracy: 18.80%\n",
            "Epoch: 41, Step: 373/655, Loss: 2.207066, Accuracy: 18.85%\n",
            "Epoch: 41, Step: 374/655, Loss: 2.206926, Accuracy: 18.83%\n",
            "Epoch: 41, Step: 375/655, Loss: 2.207133, Accuracy: 18.83%\n",
            "Epoch: 41, Step: 376/655, Loss: 2.207049, Accuracy: 18.82%\n",
            "Epoch: 41, Step: 377/655, Loss: 2.207013, Accuracy: 18.81%\n",
            "Epoch: 41, Step: 378/655, Loss: 2.207112, Accuracy: 18.81%\n",
            "Epoch: 41, Step: 379/655, Loss: 2.207156, Accuracy: 18.80%\n",
            "Epoch: 41, Step: 380/655, Loss: 2.206811, Accuracy: 18.83%\n",
            "Epoch: 41, Step: 381/655, Loss: 2.206815, Accuracy: 18.81%\n",
            "Epoch: 41, Step: 382/655, Loss: 2.206698, Accuracy: 18.83%\n",
            "Epoch: 41, Step: 383/655, Loss: 2.206354, Accuracy: 18.83%\n",
            "Epoch: 41, Step: 384/655, Loss: 2.206409, Accuracy: 18.84%\n",
            "Epoch: 41, Step: 385/655, Loss: 2.206422, Accuracy: 18.84%\n",
            "Epoch: 41, Step: 386/655, Loss: 2.206248, Accuracy: 18.86%\n",
            "Epoch: 41, Step: 387/655, Loss: 2.206399, Accuracy: 18.85%\n",
            "Epoch: 41, Step: 388/655, Loss: 2.206476, Accuracy: 18.83%\n",
            "Epoch: 41, Step: 389/655, Loss: 2.206598, Accuracy: 18.81%\n",
            "Epoch: 41, Step: 390/655, Loss: 2.206150, Accuracy: 18.87%\n",
            "Epoch: 41, Step: 391/655, Loss: 2.205862, Accuracy: 18.89%\n",
            "Epoch: 41, Step: 392/655, Loss: 2.205774, Accuracy: 18.89%\n",
            "Epoch: 41, Step: 393/655, Loss: 2.205889, Accuracy: 18.90%\n",
            "Epoch: 41, Step: 394/655, Loss: 2.205986, Accuracy: 18.90%\n",
            "Epoch: 41, Step: 395/655, Loss: 2.205496, Accuracy: 18.91%\n",
            "Epoch: 41, Step: 396/655, Loss: 2.205646, Accuracy: 18.89%\n",
            "Epoch: 41, Step: 397/655, Loss: 2.205777, Accuracy: 18.90%\n",
            "Epoch: 41, Step: 398/655, Loss: 2.205429, Accuracy: 18.90%\n",
            "Epoch: 41, Step: 399/655, Loss: 2.205829, Accuracy: 18.89%\n",
            "Epoch: 41, Step: 400/655, Loss: 2.205707, Accuracy: 18.91%\n",
            "Epoch: 41, Step: 401/655, Loss: 2.206294, Accuracy: 18.87%\n",
            "Epoch: 41, Step: 402/655, Loss: 2.206339, Accuracy: 18.87%\n",
            "Epoch: 41, Step: 403/655, Loss: 2.206541, Accuracy: 18.86%\n",
            "Epoch: 41, Step: 404/655, Loss: 2.206874, Accuracy: 18.84%\n",
            "Epoch: 41, Step: 405/655, Loss: 2.207142, Accuracy: 18.80%\n",
            "Epoch: 41, Step: 406/655, Loss: 2.207060, Accuracy: 18.81%\n",
            "Epoch: 41, Step: 407/655, Loss: 2.206784, Accuracy: 18.86%\n",
            "Epoch: 41, Step: 408/655, Loss: 2.206833, Accuracy: 18.86%\n",
            "Epoch: 41, Step: 409/655, Loss: 2.206709, Accuracy: 18.86%\n",
            "Epoch: 41, Step: 410/655, Loss: 2.206813, Accuracy: 18.89%\n",
            "Epoch: 41, Step: 411/655, Loss: 2.207089, Accuracy: 18.85%\n",
            "Epoch: 41, Step: 412/655, Loss: 2.207336, Accuracy: 18.82%\n",
            "Epoch: 41, Step: 413/655, Loss: 2.207112, Accuracy: 18.82%\n",
            "Epoch: 41, Step: 414/655, Loss: 2.207259, Accuracy: 18.78%\n",
            "Epoch: 41, Step: 415/655, Loss: 2.207177, Accuracy: 18.80%\n",
            "Epoch: 41, Step: 416/655, Loss: 2.207047, Accuracy: 18.80%\n",
            "Epoch: 41, Step: 417/655, Loss: 2.206888, Accuracy: 18.82%\n",
            "Epoch: 41, Step: 418/655, Loss: 2.206854, Accuracy: 18.84%\n",
            "Epoch: 41, Step: 419/655, Loss: 2.206746, Accuracy: 18.81%\n",
            "Epoch: 41, Step: 420/655, Loss: 2.206416, Accuracy: 18.82%\n",
            "Epoch: 41, Step: 421/655, Loss: 2.206506, Accuracy: 18.81%\n",
            "Epoch: 41, Step: 422/655, Loss: 2.206674, Accuracy: 18.81%\n",
            "Epoch: 41, Step: 423/655, Loss: 2.206918, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 424/655, Loss: 2.206907, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 425/655, Loss: 2.206831, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 426/655, Loss: 2.206767, Accuracy: 18.82%\n",
            "Epoch: 41, Step: 427/655, Loss: 2.206251, Accuracy: 18.81%\n",
            "Epoch: 41, Step: 428/655, Loss: 2.206300, Accuracy: 18.81%\n",
            "Epoch: 41, Step: 429/655, Loss: 2.206624, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 430/655, Loss: 2.206611, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 431/655, Loss: 2.206627, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 432/655, Loss: 2.206539, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 433/655, Loss: 2.206504, Accuracy: 18.78%\n",
            "Epoch: 41, Step: 434/655, Loss: 2.206730, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 435/655, Loss: 2.206911, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 436/655, Loss: 2.206808, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 437/655, Loss: 2.206729, Accuracy: 18.79%\n",
            "Epoch: 41, Step: 438/655, Loss: 2.206646, Accuracy: 18.83%\n",
            "Epoch: 41, Step: 439/655, Loss: 2.206318, Accuracy: 18.85%\n",
            "Epoch: 41, Step: 440/655, Loss: 2.206338, Accuracy: 18.83%\n",
            "Epoch: 41, Step: 441/655, Loss: 2.206093, Accuracy: 18.84%\n",
            "Epoch: 41, Step: 442/655, Loss: 2.206054, Accuracy: 18.81%\n",
            "Epoch: 41, Step: 443/655, Loss: 2.206138, Accuracy: 18.80%\n",
            "Epoch: 41, Step: 444/655, Loss: 2.206422, Accuracy: 18.77%\n",
            "Epoch: 41, Step: 445/655, Loss: 2.206508, Accuracy: 18.76%\n",
            "Epoch: 41, Step: 446/655, Loss: 2.206732, Accuracy: 18.73%\n",
            "Epoch: 41, Step: 447/655, Loss: 2.206711, Accuracy: 18.74%\n",
            "Epoch: 41, Step: 448/655, Loss: 2.206569, Accuracy: 18.74%\n",
            "Epoch: 41, Step: 449/655, Loss: 2.206670, Accuracy: 18.72%\n",
            "Epoch: 41, Step: 450/655, Loss: 2.206551, Accuracy: 18.71%\n",
            "Epoch: 41, Step: 451/655, Loss: 2.206535, Accuracy: 18.71%\n",
            "Epoch: 41, Step: 452/655, Loss: 2.206428, Accuracy: 18.69%\n",
            "Epoch: 41, Step: 453/655, Loss: 2.206319, Accuracy: 18.72%\n",
            "Epoch: 41, Step: 454/655, Loss: 2.206283, Accuracy: 18.72%\n",
            "Epoch: 41, Step: 455/655, Loss: 2.206433, Accuracy: 18.70%\n",
            "Epoch: 41, Step: 456/655, Loss: 2.206446, Accuracy: 18.70%\n",
            "Epoch: 41, Step: 457/655, Loss: 2.206459, Accuracy: 18.69%\n",
            "Epoch: 41, Step: 458/655, Loss: 2.206661, Accuracy: 18.68%\n",
            "Epoch: 41, Step: 459/655, Loss: 2.206669, Accuracy: 18.68%\n",
            "Epoch: 41, Step: 460/655, Loss: 2.206439, Accuracy: 18.68%\n",
            "Epoch: 41, Step: 461/655, Loss: 2.206350, Accuracy: 18.69%\n",
            "Epoch: 41, Step: 462/655, Loss: 2.206424, Accuracy: 18.70%\n",
            "Epoch: 41, Step: 463/655, Loss: 2.206768, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 464/655, Loss: 2.206700, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 465/655, Loss: 2.206540, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 466/655, Loss: 2.206545, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 467/655, Loss: 2.206395, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 468/655, Loss: 2.206655, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 469/655, Loss: 2.206318, Accuracy: 18.70%\n",
            "Epoch: 41, Step: 470/655, Loss: 2.206385, Accuracy: 18.70%\n",
            "Epoch: 41, Step: 471/655, Loss: 2.206568, Accuracy: 18.69%\n",
            "Epoch: 41, Step: 472/655, Loss: 2.206458, Accuracy: 18.68%\n",
            "Epoch: 41, Step: 473/655, Loss: 2.206092, Accuracy: 18.73%\n",
            "Epoch: 41, Step: 474/655, Loss: 2.205927, Accuracy: 18.74%\n",
            "Epoch: 41, Step: 475/655, Loss: 2.206167, Accuracy: 18.72%\n",
            "Epoch: 41, Step: 476/655, Loss: 2.206029, Accuracy: 18.72%\n",
            "Epoch: 41, Step: 477/655, Loss: 2.206188, Accuracy: 18.72%\n",
            "Epoch: 41, Step: 478/655, Loss: 2.206156, Accuracy: 18.72%\n",
            "Epoch: 41, Step: 479/655, Loss: 2.206162, Accuracy: 18.72%\n",
            "Epoch: 41, Step: 480/655, Loss: 2.206163, Accuracy: 18.73%\n",
            "Epoch: 41, Step: 481/655, Loss: 2.206201, Accuracy: 18.73%\n",
            "Epoch: 41, Step: 482/655, Loss: 2.206183, Accuracy: 18.73%\n",
            "Epoch: 41, Step: 483/655, Loss: 2.206464, Accuracy: 18.72%\n",
            "Epoch: 41, Step: 484/655, Loss: 2.206664, Accuracy: 18.71%\n",
            "Epoch: 41, Step: 485/655, Loss: 2.206928, Accuracy: 18.69%\n",
            "Epoch: 41, Step: 486/655, Loss: 2.206733, Accuracy: 18.69%\n",
            "Epoch: 41, Step: 487/655, Loss: 2.206876, Accuracy: 18.68%\n",
            "Epoch: 41, Step: 488/655, Loss: 2.207078, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 489/655, Loss: 2.207120, Accuracy: 18.68%\n",
            "Epoch: 41, Step: 490/655, Loss: 2.207226, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 491/655, Loss: 2.207651, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 492/655, Loss: 2.207786, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 493/655, Loss: 2.207822, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 494/655, Loss: 2.207786, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 495/655, Loss: 2.207614, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 496/655, Loss: 2.207665, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 497/655, Loss: 2.207713, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 498/655, Loss: 2.207765, Accuracy: 18.68%\n",
            "Epoch: 41, Step: 499/655, Loss: 2.207672, Accuracy: 18.68%\n",
            "Epoch: 41, Step: 500/655, Loss: 2.207765, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 501/655, Loss: 2.207911, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 502/655, Loss: 2.208156, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 503/655, Loss: 2.208164, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 504/655, Loss: 2.208024, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 505/655, Loss: 2.208105, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 506/655, Loss: 2.208234, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 507/655, Loss: 2.208432, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 508/655, Loss: 2.208297, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 509/655, Loss: 2.208170, Accuracy: 18.68%\n",
            "Epoch: 41, Step: 510/655, Loss: 2.208026, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 511/655, Loss: 2.208187, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 512/655, Loss: 2.207888, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 513/655, Loss: 2.207880, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 514/655, Loss: 2.207838, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 515/655, Loss: 2.207764, Accuracy: 18.68%\n",
            "Epoch: 41, Step: 516/655, Loss: 2.208125, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 517/655, Loss: 2.208185, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 518/655, Loss: 2.208273, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 519/655, Loss: 2.208292, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 520/655, Loss: 2.208339, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 521/655, Loss: 2.208260, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 522/655, Loss: 2.208096, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 523/655, Loss: 2.207946, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 524/655, Loss: 2.208282, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 525/655, Loss: 2.208417, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 526/655, Loss: 2.208206, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 527/655, Loss: 2.208082, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 528/655, Loss: 2.208055, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 529/655, Loss: 2.208137, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 530/655, Loss: 2.208174, Accuracy: 18.61%\n",
            "Epoch: 41, Step: 531/655, Loss: 2.208139, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 532/655, Loss: 2.208030, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 533/655, Loss: 2.207872, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 534/655, Loss: 2.207732, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 535/655, Loss: 2.207704, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 536/655, Loss: 2.207721, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 537/655, Loss: 2.207573, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 538/655, Loss: 2.207494, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 539/655, Loss: 2.207467, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 540/655, Loss: 2.207337, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 541/655, Loss: 2.207365, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 542/655, Loss: 2.207610, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 543/655, Loss: 2.207686, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 544/655, Loss: 2.207600, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 545/655, Loss: 2.207547, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 546/655, Loss: 2.207482, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 547/655, Loss: 2.207550, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 548/655, Loss: 2.207621, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 549/655, Loss: 2.207676, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 550/655, Loss: 2.207785, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 551/655, Loss: 2.207870, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 552/655, Loss: 2.207694, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 553/655, Loss: 2.207548, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 554/655, Loss: 2.207286, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 555/655, Loss: 2.207410, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 556/655, Loss: 2.207359, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 557/655, Loss: 2.207299, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 558/655, Loss: 2.207375, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 559/655, Loss: 2.207473, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 560/655, Loss: 2.207313, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 561/655, Loss: 2.207171, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 562/655, Loss: 2.207263, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 563/655, Loss: 2.207449, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 564/655, Loss: 2.207311, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 565/655, Loss: 2.207031, Accuracy: 18.67%\n",
            "Epoch: 41, Step: 566/655, Loss: 2.207204, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 567/655, Loss: 2.207227, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 568/655, Loss: 2.207199, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 569/655, Loss: 2.207403, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 570/655, Loss: 2.207435, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 571/655, Loss: 2.207511, Accuracy: 18.61%\n",
            "Epoch: 41, Step: 572/655, Loss: 2.207382, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 573/655, Loss: 2.207574, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 574/655, Loss: 2.207536, Accuracy: 18.61%\n",
            "Epoch: 41, Step: 575/655, Loss: 2.207409, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 576/655, Loss: 2.207505, Accuracy: 18.61%\n",
            "Epoch: 41, Step: 577/655, Loss: 2.207552, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 578/655, Loss: 2.207473, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 579/655, Loss: 2.207483, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 580/655, Loss: 2.207427, Accuracy: 18.58%\n",
            "Epoch: 41, Step: 581/655, Loss: 2.207398, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 582/655, Loss: 2.207362, Accuracy: 18.58%\n",
            "Epoch: 41, Step: 583/655, Loss: 2.207353, Accuracy: 18.57%\n",
            "Epoch: 41, Step: 584/655, Loss: 2.207351, Accuracy: 18.56%\n",
            "Epoch: 41, Step: 585/655, Loss: 2.207368, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 586/655, Loss: 2.207283, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 587/655, Loss: 2.207389, Accuracy: 18.57%\n",
            "Epoch: 41, Step: 588/655, Loss: 2.207511, Accuracy: 18.56%\n",
            "Epoch: 41, Step: 589/655, Loss: 2.207558, Accuracy: 18.56%\n",
            "Epoch: 41, Step: 590/655, Loss: 2.207522, Accuracy: 18.56%\n",
            "Epoch: 41, Step: 591/655, Loss: 2.207429, Accuracy: 18.56%\n",
            "Epoch: 41, Step: 592/655, Loss: 2.207513, Accuracy: 18.55%\n",
            "Epoch: 41, Step: 593/655, Loss: 2.207621, Accuracy: 18.56%\n",
            "Epoch: 41, Step: 594/655, Loss: 2.207538, Accuracy: 18.56%\n",
            "Epoch: 41, Step: 595/655, Loss: 2.207526, Accuracy: 18.57%\n",
            "Epoch: 41, Step: 596/655, Loss: 2.207529, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 597/655, Loss: 2.207512, Accuracy: 18.61%\n",
            "Epoch: 41, Step: 598/655, Loss: 2.207730, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 599/655, Loss: 2.207590, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 600/655, Loss: 2.207570, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 601/655, Loss: 2.207454, Accuracy: 18.61%\n",
            "Epoch: 41, Step: 602/655, Loss: 2.207569, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 603/655, Loss: 2.207586, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 604/655, Loss: 2.207450, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 605/655, Loss: 2.207395, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 606/655, Loss: 2.207165, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 607/655, Loss: 2.207294, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 608/655, Loss: 2.207208, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 609/655, Loss: 2.207250, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 610/655, Loss: 2.207204, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 611/655, Loss: 2.207438, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 612/655, Loss: 2.207485, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 613/655, Loss: 2.207332, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 614/655, Loss: 2.207301, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 615/655, Loss: 2.207117, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 616/655, Loss: 2.207218, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 617/655, Loss: 2.207032, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 618/655, Loss: 2.207030, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 619/655, Loss: 2.207141, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 620/655, Loss: 2.206897, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 621/655, Loss: 2.206849, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 622/655, Loss: 2.206697, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 623/655, Loss: 2.206621, Accuracy: 18.66%\n",
            "Epoch: 41, Step: 624/655, Loss: 2.206822, Accuracy: 18.65%\n",
            "Epoch: 41, Step: 625/655, Loss: 2.207074, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 626/655, Loss: 2.207267, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 627/655, Loss: 2.207205, Accuracy: 18.64%\n",
            "Epoch: 41, Step: 628/655, Loss: 2.207191, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 629/655, Loss: 2.207132, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 630/655, Loss: 2.207067, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 631/655, Loss: 2.207166, Accuracy: 18.63%\n",
            "Epoch: 41, Step: 632/655, Loss: 2.207345, Accuracy: 18.62%\n",
            "Epoch: 41, Step: 633/655, Loss: 2.207352, Accuracy: 18.61%\n",
            "Epoch: 41, Step: 634/655, Loss: 2.207448, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 635/655, Loss: 2.207606, Accuracy: 18.58%\n",
            "Epoch: 41, Step: 636/655, Loss: 2.207592, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 637/655, Loss: 2.207557, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 638/655, Loss: 2.207523, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 639/655, Loss: 2.207569, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 640/655, Loss: 2.207670, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 641/655, Loss: 2.207729, Accuracy: 18.58%\n",
            "Epoch: 41, Step: 642/655, Loss: 2.207734, Accuracy: 18.58%\n",
            "Epoch: 41, Step: 643/655, Loss: 2.207636, Accuracy: 18.58%\n",
            "Epoch: 41, Step: 644/655, Loss: 2.207747, Accuracy: 18.58%\n",
            "Epoch: 41, Step: 645/655, Loss: 2.207671, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 646/655, Loss: 2.207728, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 647/655, Loss: 2.207558, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 648/655, Loss: 2.207750, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 649/655, Loss: 2.207687, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 650/655, Loss: 2.207471, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 651/655, Loss: 2.207489, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 652/655, Loss: 2.207451, Accuracy: 18.60%\n",
            "Epoch: 41, Step: 653/655, Loss: 2.207307, Accuracy: 18.59%\n",
            "Epoch: 41, Step: 654/655, Loss: 2.207376, Accuracy: 18.58%\n",
            "Epoch: 41, Step: 655/655, Loss: 2.207702, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 1/655, Loss: 2.380391, Accuracy: 12.50%\n",
            "Epoch: 42, Step: 2/655, Loss: 2.331750, Accuracy: 10.94%\n",
            "Epoch: 42, Step: 3/655, Loss: 2.265032, Accuracy: 17.71%\n",
            "Epoch: 42, Step: 4/655, Loss: 2.239390, Accuracy: 20.31%\n",
            "Epoch: 42, Step: 5/655, Loss: 2.226208, Accuracy: 20.00%\n",
            "Epoch: 42, Step: 6/655, Loss: 2.220448, Accuracy: 20.83%\n",
            "Epoch: 42, Step: 7/655, Loss: 2.213909, Accuracy: 20.98%\n",
            "Epoch: 42, Step: 8/655, Loss: 2.216920, Accuracy: 20.70%\n",
            "Epoch: 42, Step: 9/655, Loss: 2.221185, Accuracy: 20.83%\n",
            "Epoch: 42, Step: 10/655, Loss: 2.218606, Accuracy: 20.00%\n",
            "Epoch: 42, Step: 11/655, Loss: 2.225581, Accuracy: 19.03%\n",
            "Epoch: 42, Step: 12/655, Loss: 2.224419, Accuracy: 18.49%\n",
            "Epoch: 42, Step: 13/655, Loss: 2.219502, Accuracy: 18.75%\n",
            "Epoch: 42, Step: 14/655, Loss: 2.213322, Accuracy: 18.97%\n",
            "Epoch: 42, Step: 15/655, Loss: 2.213478, Accuracy: 18.75%\n",
            "Epoch: 42, Step: 16/655, Loss: 2.208663, Accuracy: 18.36%\n",
            "Epoch: 42, Step: 17/655, Loss: 2.207094, Accuracy: 18.20%\n",
            "Epoch: 42, Step: 18/655, Loss: 2.208511, Accuracy: 17.88%\n",
            "Epoch: 42, Step: 19/655, Loss: 2.210494, Accuracy: 17.11%\n",
            "Epoch: 42, Step: 20/655, Loss: 2.215160, Accuracy: 17.34%\n",
            "Epoch: 42, Step: 21/655, Loss: 2.214078, Accuracy: 17.26%\n",
            "Epoch: 42, Step: 22/655, Loss: 2.217159, Accuracy: 17.33%\n",
            "Epoch: 42, Step: 23/655, Loss: 2.211182, Accuracy: 17.53%\n",
            "Epoch: 42, Step: 24/655, Loss: 2.212450, Accuracy: 17.45%\n",
            "Epoch: 42, Step: 25/655, Loss: 2.210723, Accuracy: 17.50%\n",
            "Epoch: 42, Step: 26/655, Loss: 2.208708, Accuracy: 17.31%\n",
            "Epoch: 42, Step: 27/655, Loss: 2.210475, Accuracy: 17.36%\n",
            "Epoch: 42, Step: 28/655, Loss: 2.207210, Accuracy: 17.86%\n",
            "Epoch: 42, Step: 29/655, Loss: 2.207836, Accuracy: 17.89%\n",
            "Epoch: 42, Step: 30/655, Loss: 2.210521, Accuracy: 17.60%\n",
            "Epoch: 42, Step: 31/655, Loss: 2.208448, Accuracy: 17.44%\n",
            "Epoch: 42, Step: 32/655, Loss: 2.211171, Accuracy: 17.09%\n",
            "Epoch: 42, Step: 33/655, Loss: 2.208926, Accuracy: 17.52%\n",
            "Epoch: 42, Step: 34/655, Loss: 2.208607, Accuracy: 17.56%\n",
            "Epoch: 42, Step: 35/655, Loss: 2.210376, Accuracy: 17.32%\n",
            "Epoch: 42, Step: 36/655, Loss: 2.212498, Accuracy: 17.53%\n",
            "Epoch: 42, Step: 37/655, Loss: 2.209109, Accuracy: 17.82%\n",
            "Epoch: 42, Step: 38/655, Loss: 2.210445, Accuracy: 17.68%\n",
            "Epoch: 42, Step: 39/655, Loss: 2.208267, Accuracy: 18.11%\n",
            "Epoch: 42, Step: 40/655, Loss: 2.211123, Accuracy: 18.12%\n",
            "Epoch: 42, Step: 41/655, Loss: 2.209251, Accuracy: 18.06%\n",
            "Epoch: 42, Step: 42/655, Loss: 2.212983, Accuracy: 17.78%\n",
            "Epoch: 42, Step: 43/655, Loss: 2.213479, Accuracy: 17.73%\n",
            "Epoch: 42, Step: 44/655, Loss: 2.213210, Accuracy: 17.61%\n",
            "Epoch: 42, Step: 45/655, Loss: 2.212919, Accuracy: 17.50%\n",
            "Epoch: 42, Step: 46/655, Loss: 2.211795, Accuracy: 17.80%\n",
            "Epoch: 42, Step: 47/655, Loss: 2.210010, Accuracy: 17.95%\n",
            "Epoch: 42, Step: 48/655, Loss: 2.211269, Accuracy: 18.10%\n",
            "Epoch: 42, Step: 49/655, Loss: 2.210632, Accuracy: 18.05%\n",
            "Epoch: 42, Step: 50/655, Loss: 2.211107, Accuracy: 18.00%\n",
            "Epoch: 42, Step: 51/655, Loss: 2.210089, Accuracy: 18.01%\n",
            "Epoch: 42, Step: 52/655, Loss: 2.211001, Accuracy: 17.85%\n",
            "Epoch: 42, Step: 53/655, Loss: 2.209496, Accuracy: 18.04%\n",
            "Epoch: 42, Step: 54/655, Loss: 2.209396, Accuracy: 17.82%\n",
            "Epoch: 42, Step: 55/655, Loss: 2.207296, Accuracy: 17.90%\n",
            "Epoch: 42, Step: 56/655, Loss: 2.208644, Accuracy: 17.91%\n",
            "Epoch: 42, Step: 57/655, Loss: 2.208581, Accuracy: 17.93%\n",
            "Epoch: 42, Step: 58/655, Loss: 2.210545, Accuracy: 18.05%\n",
            "Epoch: 42, Step: 59/655, Loss: 2.212670, Accuracy: 17.85%\n",
            "Epoch: 42, Step: 60/655, Loss: 2.212135, Accuracy: 17.92%\n",
            "Epoch: 42, Step: 61/655, Loss: 2.212889, Accuracy: 17.83%\n",
            "Epoch: 42, Step: 62/655, Loss: 2.210714, Accuracy: 17.99%\n",
            "Epoch: 42, Step: 63/655, Loss: 2.209995, Accuracy: 17.96%\n",
            "Epoch: 42, Step: 64/655, Loss: 2.210212, Accuracy: 17.97%\n",
            "Epoch: 42, Step: 65/655, Loss: 2.209532, Accuracy: 18.03%\n",
            "Epoch: 42, Step: 66/655, Loss: 2.209953, Accuracy: 17.99%\n",
            "Epoch: 42, Step: 67/655, Loss: 2.210193, Accuracy: 18.05%\n",
            "Epoch: 42, Step: 68/655, Loss: 2.210797, Accuracy: 18.06%\n",
            "Epoch: 42, Step: 69/655, Loss: 2.210280, Accuracy: 17.98%\n",
            "Epoch: 42, Step: 70/655, Loss: 2.210634, Accuracy: 18.12%\n",
            "Epoch: 42, Step: 71/655, Loss: 2.209840, Accuracy: 18.13%\n",
            "Epoch: 42, Step: 72/655, Loss: 2.209281, Accuracy: 18.32%\n",
            "Epoch: 42, Step: 73/655, Loss: 2.207640, Accuracy: 18.36%\n",
            "Epoch: 42, Step: 74/655, Loss: 2.208157, Accuracy: 18.41%\n",
            "Epoch: 42, Step: 75/655, Loss: 2.207177, Accuracy: 18.54%\n",
            "Epoch: 42, Step: 76/655, Loss: 2.205396, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 77/655, Loss: 2.204888, Accuracy: 18.79%\n",
            "Epoch: 42, Step: 78/655, Loss: 2.206244, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 79/655, Loss: 2.206779, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 80/655, Loss: 2.206526, Accuracy: 18.71%\n",
            "Epoch: 42, Step: 81/655, Loss: 2.207159, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 82/655, Loss: 2.207561, Accuracy: 18.79%\n",
            "Epoch: 42, Step: 83/655, Loss: 2.208487, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 84/655, Loss: 2.207471, Accuracy: 18.79%\n",
            "Epoch: 42, Step: 85/655, Loss: 2.207029, Accuracy: 18.82%\n",
            "Epoch: 42, Step: 86/655, Loss: 2.207113, Accuracy: 18.75%\n",
            "Epoch: 42, Step: 87/655, Loss: 2.205703, Accuracy: 18.71%\n",
            "Epoch: 42, Step: 88/655, Loss: 2.206647, Accuracy: 18.71%\n",
            "Epoch: 42, Step: 89/655, Loss: 2.205756, Accuracy: 18.86%\n",
            "Epoch: 42, Step: 90/655, Loss: 2.206700, Accuracy: 18.82%\n",
            "Epoch: 42, Step: 91/655, Loss: 2.206147, Accuracy: 18.89%\n",
            "Epoch: 42, Step: 92/655, Loss: 2.204479, Accuracy: 18.95%\n",
            "Epoch: 42, Step: 93/655, Loss: 2.204123, Accuracy: 18.95%\n",
            "Epoch: 42, Step: 94/655, Loss: 2.202637, Accuracy: 19.02%\n",
            "Epoch: 42, Step: 95/655, Loss: 2.202817, Accuracy: 19.01%\n",
            "Epoch: 42, Step: 96/655, Loss: 2.202366, Accuracy: 19.14%\n",
            "Epoch: 42, Step: 97/655, Loss: 2.203557, Accuracy: 19.10%\n",
            "Epoch: 42, Step: 98/655, Loss: 2.204215, Accuracy: 19.10%\n",
            "Epoch: 42, Step: 99/655, Loss: 2.205134, Accuracy: 19.07%\n",
            "Epoch: 42, Step: 100/655, Loss: 2.203666, Accuracy: 19.19%\n",
            "Epoch: 42, Step: 101/655, Loss: 2.203440, Accuracy: 19.18%\n",
            "Epoch: 42, Step: 102/655, Loss: 2.204143, Accuracy: 19.18%\n",
            "Epoch: 42, Step: 103/655, Loss: 2.204228, Accuracy: 19.14%\n",
            "Epoch: 42, Step: 104/655, Loss: 2.202948, Accuracy: 19.20%\n",
            "Epoch: 42, Step: 105/655, Loss: 2.203890, Accuracy: 19.14%\n",
            "Epoch: 42, Step: 106/655, Loss: 2.203613, Accuracy: 19.19%\n",
            "Epoch: 42, Step: 107/655, Loss: 2.202812, Accuracy: 19.16%\n",
            "Epoch: 42, Step: 108/655, Loss: 2.203039, Accuracy: 19.16%\n",
            "Epoch: 42, Step: 109/655, Loss: 2.203076, Accuracy: 19.12%\n",
            "Epoch: 42, Step: 110/655, Loss: 2.203709, Accuracy: 19.01%\n",
            "Epoch: 42, Step: 111/655, Loss: 2.204797, Accuracy: 19.00%\n",
            "Epoch: 42, Step: 112/655, Loss: 2.205095, Accuracy: 18.97%\n",
            "Epoch: 42, Step: 113/655, Loss: 2.205503, Accuracy: 18.97%\n",
            "Epoch: 42, Step: 114/655, Loss: 2.206135, Accuracy: 18.91%\n",
            "Epoch: 42, Step: 115/655, Loss: 2.206875, Accuracy: 18.83%\n",
            "Epoch: 42, Step: 116/655, Loss: 2.206404, Accuracy: 18.78%\n",
            "Epoch: 42, Step: 117/655, Loss: 2.204627, Accuracy: 18.86%\n",
            "Epoch: 42, Step: 118/655, Loss: 2.203870, Accuracy: 18.99%\n",
            "Epoch: 42, Step: 119/655, Loss: 2.203803, Accuracy: 18.96%\n",
            "Epoch: 42, Step: 120/655, Loss: 2.204239, Accuracy: 18.88%\n",
            "Epoch: 42, Step: 121/655, Loss: 2.203861, Accuracy: 18.98%\n",
            "Epoch: 42, Step: 122/655, Loss: 2.204157, Accuracy: 18.93%\n",
            "Epoch: 42, Step: 123/655, Loss: 2.204115, Accuracy: 19.13%\n",
            "Epoch: 42, Step: 124/655, Loss: 2.203960, Accuracy: 19.10%\n",
            "Epoch: 42, Step: 125/655, Loss: 2.203834, Accuracy: 19.02%\n",
            "Epoch: 42, Step: 126/655, Loss: 2.203758, Accuracy: 19.07%\n",
            "Epoch: 42, Step: 127/655, Loss: 2.203055, Accuracy: 19.17%\n",
            "Epoch: 42, Step: 128/655, Loss: 2.202965, Accuracy: 19.14%\n",
            "Epoch: 42, Step: 129/655, Loss: 2.203522, Accuracy: 19.09%\n",
            "Epoch: 42, Step: 130/655, Loss: 2.203163, Accuracy: 19.11%\n",
            "Epoch: 42, Step: 131/655, Loss: 2.203005, Accuracy: 19.08%\n",
            "Epoch: 42, Step: 132/655, Loss: 2.203184, Accuracy: 19.11%\n",
            "Epoch: 42, Step: 133/655, Loss: 2.204108, Accuracy: 19.03%\n",
            "Epoch: 42, Step: 134/655, Loss: 2.204114, Accuracy: 18.98%\n",
            "Epoch: 42, Step: 135/655, Loss: 2.204541, Accuracy: 18.96%\n",
            "Epoch: 42, Step: 136/655, Loss: 2.204683, Accuracy: 18.98%\n",
            "Epoch: 42, Step: 137/655, Loss: 2.203955, Accuracy: 19.05%\n",
            "Epoch: 42, Step: 138/655, Loss: 2.204060, Accuracy: 19.02%\n",
            "Epoch: 42, Step: 139/655, Loss: 2.204100, Accuracy: 19.02%\n",
            "Epoch: 42, Step: 140/655, Loss: 2.204673, Accuracy: 18.97%\n",
            "Epoch: 42, Step: 141/655, Loss: 2.204441, Accuracy: 18.97%\n",
            "Epoch: 42, Step: 142/655, Loss: 2.204231, Accuracy: 18.97%\n",
            "Epoch: 42, Step: 143/655, Loss: 2.205003, Accuracy: 18.95%\n",
            "Epoch: 42, Step: 144/655, Loss: 2.205791, Accuracy: 18.86%\n",
            "Epoch: 42, Step: 145/655, Loss: 2.205282, Accuracy: 18.97%\n",
            "Epoch: 42, Step: 146/655, Loss: 2.204835, Accuracy: 19.07%\n",
            "Epoch: 42, Step: 147/655, Loss: 2.205264, Accuracy: 19.03%\n",
            "Epoch: 42, Step: 148/655, Loss: 2.204373, Accuracy: 19.09%\n",
            "Epoch: 42, Step: 149/655, Loss: 2.204584, Accuracy: 19.11%\n",
            "Epoch: 42, Step: 150/655, Loss: 2.205323, Accuracy: 19.08%\n",
            "Epoch: 42, Step: 151/655, Loss: 2.204829, Accuracy: 19.18%\n",
            "Epoch: 42, Step: 152/655, Loss: 2.204319, Accuracy: 19.24%\n",
            "Epoch: 42, Step: 153/655, Loss: 2.204200, Accuracy: 19.26%\n",
            "Epoch: 42, Step: 154/655, Loss: 2.203956, Accuracy: 19.30%\n",
            "Epoch: 42, Step: 155/655, Loss: 2.204665, Accuracy: 19.23%\n",
            "Epoch: 42, Step: 156/655, Loss: 2.204758, Accuracy: 19.23%\n",
            "Epoch: 42, Step: 157/655, Loss: 2.204542, Accuracy: 19.25%\n",
            "Epoch: 42, Step: 158/655, Loss: 2.204436, Accuracy: 19.20%\n",
            "Epoch: 42, Step: 159/655, Loss: 2.204708, Accuracy: 19.20%\n",
            "Epoch: 42, Step: 160/655, Loss: 2.204348, Accuracy: 19.14%\n",
            "Epoch: 42, Step: 161/655, Loss: 2.204365, Accuracy: 19.08%\n",
            "Epoch: 42, Step: 162/655, Loss: 2.203263, Accuracy: 19.10%\n",
            "Epoch: 42, Step: 163/655, Loss: 2.203106, Accuracy: 19.11%\n",
            "Epoch: 42, Step: 164/655, Loss: 2.203840, Accuracy: 19.11%\n",
            "Epoch: 42, Step: 165/655, Loss: 2.203920, Accuracy: 19.05%\n",
            "Epoch: 42, Step: 166/655, Loss: 2.203094, Accuracy: 19.15%\n",
            "Epoch: 42, Step: 167/655, Loss: 2.202925, Accuracy: 19.16%\n",
            "Epoch: 42, Step: 168/655, Loss: 2.203354, Accuracy: 19.14%\n",
            "Epoch: 42, Step: 169/655, Loss: 2.203575, Accuracy: 19.10%\n",
            "Epoch: 42, Step: 170/655, Loss: 2.203598, Accuracy: 19.10%\n",
            "Epoch: 42, Step: 171/655, Loss: 2.202947, Accuracy: 19.12%\n",
            "Epoch: 42, Step: 172/655, Loss: 2.203040, Accuracy: 19.19%\n",
            "Epoch: 42, Step: 173/655, Loss: 2.203754, Accuracy: 19.15%\n",
            "Epoch: 42, Step: 174/655, Loss: 2.203669, Accuracy: 19.16%\n",
            "Epoch: 42, Step: 175/655, Loss: 2.203864, Accuracy: 19.12%\n",
            "Epoch: 42, Step: 176/655, Loss: 2.203809, Accuracy: 19.12%\n",
            "Epoch: 42, Step: 177/655, Loss: 2.203311, Accuracy: 19.16%\n",
            "Epoch: 42, Step: 178/655, Loss: 2.203430, Accuracy: 19.21%\n",
            "Epoch: 42, Step: 179/655, Loss: 2.203696, Accuracy: 19.19%\n",
            "Epoch: 42, Step: 180/655, Loss: 2.203950, Accuracy: 19.13%\n",
            "Epoch: 42, Step: 181/655, Loss: 2.203783, Accuracy: 19.10%\n",
            "Epoch: 42, Step: 182/655, Loss: 2.203492, Accuracy: 19.08%\n",
            "Epoch: 42, Step: 183/655, Loss: 2.203731, Accuracy: 19.02%\n",
            "Epoch: 42, Step: 184/655, Loss: 2.203333, Accuracy: 19.07%\n",
            "Epoch: 42, Step: 185/655, Loss: 2.203490, Accuracy: 19.04%\n",
            "Epoch: 42, Step: 186/655, Loss: 2.203529, Accuracy: 18.99%\n",
            "Epoch: 42, Step: 187/655, Loss: 2.203552, Accuracy: 18.95%\n",
            "Epoch: 42, Step: 188/655, Loss: 2.203508, Accuracy: 18.97%\n",
            "Epoch: 42, Step: 189/655, Loss: 2.203644, Accuracy: 18.98%\n",
            "Epoch: 42, Step: 190/655, Loss: 2.204099, Accuracy: 18.95%\n",
            "Epoch: 42, Step: 191/655, Loss: 2.204187, Accuracy: 18.95%\n",
            "Epoch: 42, Step: 192/655, Loss: 2.203672, Accuracy: 18.98%\n",
            "Epoch: 42, Step: 193/655, Loss: 2.203374, Accuracy: 19.04%\n",
            "Epoch: 42, Step: 194/655, Loss: 2.203809, Accuracy: 19.06%\n",
            "Epoch: 42, Step: 195/655, Loss: 2.204015, Accuracy: 19.02%\n",
            "Epoch: 42, Step: 196/655, Loss: 2.203814, Accuracy: 18.99%\n",
            "Epoch: 42, Step: 197/655, Loss: 2.203993, Accuracy: 18.97%\n",
            "Epoch: 42, Step: 198/655, Loss: 2.203843, Accuracy: 19.00%\n",
            "Epoch: 42, Step: 199/655, Loss: 2.204110, Accuracy: 18.99%\n",
            "Epoch: 42, Step: 200/655, Loss: 2.203703, Accuracy: 18.97%\n",
            "Epoch: 42, Step: 201/655, Loss: 2.203365, Accuracy: 18.97%\n",
            "Epoch: 42, Step: 202/655, Loss: 2.202764, Accuracy: 18.98%\n",
            "Epoch: 42, Step: 203/655, Loss: 2.203409, Accuracy: 18.93%\n",
            "Epoch: 42, Step: 204/655, Loss: 2.203209, Accuracy: 18.95%\n",
            "Epoch: 42, Step: 205/655, Loss: 2.203021, Accuracy: 18.95%\n",
            "Epoch: 42, Step: 206/655, Loss: 2.203015, Accuracy: 18.96%\n",
            "Epoch: 42, Step: 207/655, Loss: 2.203358, Accuracy: 18.96%\n",
            "Epoch: 42, Step: 208/655, Loss: 2.204400, Accuracy: 18.90%\n",
            "Epoch: 42, Step: 209/655, Loss: 2.204163, Accuracy: 18.93%\n",
            "Epoch: 42, Step: 210/655, Loss: 2.203730, Accuracy: 18.96%\n",
            "Epoch: 42, Step: 211/655, Loss: 2.203656, Accuracy: 18.91%\n",
            "Epoch: 42, Step: 212/655, Loss: 2.203760, Accuracy: 18.87%\n",
            "Epoch: 42, Step: 213/655, Loss: 2.203802, Accuracy: 18.85%\n",
            "Epoch: 42, Step: 214/655, Loss: 2.204034, Accuracy: 18.85%\n",
            "Epoch: 42, Step: 215/655, Loss: 2.203423, Accuracy: 18.90%\n",
            "Epoch: 42, Step: 216/655, Loss: 2.202857, Accuracy: 18.92%\n",
            "Epoch: 42, Step: 217/655, Loss: 2.202920, Accuracy: 18.91%\n",
            "Epoch: 42, Step: 218/655, Loss: 2.203332, Accuracy: 18.86%\n",
            "Epoch: 42, Step: 219/655, Loss: 2.203527, Accuracy: 18.85%\n",
            "Epoch: 42, Step: 220/655, Loss: 2.203183, Accuracy: 18.89%\n",
            "Epoch: 42, Step: 221/655, Loss: 2.202857, Accuracy: 18.88%\n",
            "Epoch: 42, Step: 222/655, Loss: 2.202583, Accuracy: 18.88%\n",
            "Epoch: 42, Step: 223/655, Loss: 2.202157, Accuracy: 18.90%\n",
            "Epoch: 42, Step: 224/655, Loss: 2.201816, Accuracy: 18.90%\n",
            "Epoch: 42, Step: 225/655, Loss: 2.201272, Accuracy: 18.93%\n",
            "Epoch: 42, Step: 226/655, Loss: 2.201661, Accuracy: 18.94%\n",
            "Epoch: 42, Step: 227/655, Loss: 2.201682, Accuracy: 18.97%\n",
            "Epoch: 42, Step: 228/655, Loss: 2.202045, Accuracy: 18.93%\n",
            "Epoch: 42, Step: 229/655, Loss: 2.202042, Accuracy: 18.93%\n",
            "Epoch: 42, Step: 230/655, Loss: 2.202132, Accuracy: 18.93%\n",
            "Epoch: 42, Step: 231/655, Loss: 2.202614, Accuracy: 18.93%\n",
            "Epoch: 42, Step: 232/655, Loss: 2.202566, Accuracy: 18.94%\n",
            "Epoch: 42, Step: 233/655, Loss: 2.202590, Accuracy: 18.96%\n",
            "Epoch: 42, Step: 234/655, Loss: 2.202942, Accuracy: 18.95%\n",
            "Epoch: 42, Step: 235/655, Loss: 2.203316, Accuracy: 18.91%\n",
            "Epoch: 42, Step: 236/655, Loss: 2.203205, Accuracy: 18.92%\n",
            "Epoch: 42, Step: 237/655, Loss: 2.203513, Accuracy: 18.91%\n",
            "Epoch: 42, Step: 238/655, Loss: 2.203776, Accuracy: 18.92%\n",
            "Epoch: 42, Step: 239/655, Loss: 2.204388, Accuracy: 18.89%\n",
            "Epoch: 42, Step: 240/655, Loss: 2.204530, Accuracy: 18.89%\n",
            "Epoch: 42, Step: 241/655, Loss: 2.204431, Accuracy: 18.92%\n",
            "Epoch: 42, Step: 242/655, Loss: 2.204392, Accuracy: 18.93%\n",
            "Epoch: 42, Step: 243/655, Loss: 2.204434, Accuracy: 18.93%\n",
            "Epoch: 42, Step: 244/655, Loss: 2.203997, Accuracy: 18.94%\n",
            "Epoch: 42, Step: 245/655, Loss: 2.203952, Accuracy: 18.93%\n",
            "Epoch: 42, Step: 246/655, Loss: 2.204180, Accuracy: 18.92%\n",
            "Epoch: 42, Step: 247/655, Loss: 2.204402, Accuracy: 18.88%\n",
            "Epoch: 42, Step: 248/655, Loss: 2.204598, Accuracy: 18.83%\n",
            "Epoch: 42, Step: 249/655, Loss: 2.204820, Accuracy: 18.83%\n",
            "Epoch: 42, Step: 250/655, Loss: 2.204532, Accuracy: 18.84%\n",
            "Epoch: 42, Step: 251/655, Loss: 2.204409, Accuracy: 18.82%\n",
            "Epoch: 42, Step: 252/655, Loss: 2.204389, Accuracy: 18.81%\n",
            "Epoch: 42, Step: 253/655, Loss: 2.204080, Accuracy: 18.84%\n",
            "Epoch: 42, Step: 254/655, Loss: 2.204100, Accuracy: 18.80%\n",
            "Epoch: 42, Step: 255/655, Loss: 2.204243, Accuracy: 18.82%\n",
            "Epoch: 42, Step: 256/655, Loss: 2.204993, Accuracy: 18.79%\n",
            "Epoch: 42, Step: 257/655, Loss: 2.204546, Accuracy: 18.84%\n",
            "Epoch: 42, Step: 258/655, Loss: 2.204713, Accuracy: 18.83%\n",
            "Epoch: 42, Step: 259/655, Loss: 2.205193, Accuracy: 18.81%\n",
            "Epoch: 42, Step: 260/655, Loss: 2.204963, Accuracy: 18.83%\n",
            "Epoch: 42, Step: 261/655, Loss: 2.204936, Accuracy: 18.87%\n",
            "Epoch: 42, Step: 262/655, Loss: 2.205541, Accuracy: 18.82%\n",
            "Epoch: 42, Step: 263/655, Loss: 2.205585, Accuracy: 18.86%\n",
            "Epoch: 42, Step: 264/655, Loss: 2.205920, Accuracy: 18.84%\n",
            "Epoch: 42, Step: 265/655, Loss: 2.205704, Accuracy: 18.82%\n",
            "Epoch: 42, Step: 266/655, Loss: 2.205830, Accuracy: 18.80%\n",
            "Epoch: 42, Step: 267/655, Loss: 2.205547, Accuracy: 18.80%\n",
            "Epoch: 42, Step: 268/655, Loss: 2.205926, Accuracy: 18.81%\n",
            "Epoch: 42, Step: 269/655, Loss: 2.206345, Accuracy: 18.81%\n",
            "Epoch: 42, Step: 270/655, Loss: 2.206134, Accuracy: 18.81%\n",
            "Epoch: 42, Step: 271/655, Loss: 2.205876, Accuracy: 18.84%\n",
            "Epoch: 42, Step: 272/655, Loss: 2.206247, Accuracy: 18.78%\n",
            "Epoch: 42, Step: 273/655, Loss: 2.206181, Accuracy: 18.80%\n",
            "Epoch: 42, Step: 274/655, Loss: 2.206342, Accuracy: 18.76%\n",
            "Epoch: 42, Step: 275/655, Loss: 2.206161, Accuracy: 18.77%\n",
            "Epoch: 42, Step: 276/655, Loss: 2.206109, Accuracy: 18.80%\n",
            "Epoch: 42, Step: 277/655, Loss: 2.206035, Accuracy: 18.78%\n",
            "Epoch: 42, Step: 278/655, Loss: 2.205672, Accuracy: 18.79%\n",
            "Epoch: 42, Step: 279/655, Loss: 2.205730, Accuracy: 18.79%\n",
            "Epoch: 42, Step: 280/655, Loss: 2.206043, Accuracy: 18.75%\n",
            "Epoch: 42, Step: 281/655, Loss: 2.205551, Accuracy: 18.78%\n",
            "Epoch: 42, Step: 282/655, Loss: 2.205634, Accuracy: 18.77%\n",
            "Epoch: 42, Step: 283/655, Loss: 2.205817, Accuracy: 18.76%\n",
            "Epoch: 42, Step: 284/655, Loss: 2.205787, Accuracy: 18.75%\n",
            "Epoch: 42, Step: 285/655, Loss: 2.205829, Accuracy: 18.76%\n",
            "Epoch: 42, Step: 286/655, Loss: 2.205871, Accuracy: 18.76%\n",
            "Epoch: 42, Step: 287/655, Loss: 2.206102, Accuracy: 18.78%\n",
            "Epoch: 42, Step: 288/655, Loss: 2.206146, Accuracy: 18.76%\n",
            "Epoch: 42, Step: 289/655, Loss: 2.206246, Accuracy: 18.74%\n",
            "Epoch: 42, Step: 290/655, Loss: 2.206015, Accuracy: 18.75%\n",
            "Epoch: 42, Step: 291/655, Loss: 2.206410, Accuracy: 18.71%\n",
            "Epoch: 42, Step: 292/655, Loss: 2.206452, Accuracy: 18.72%\n",
            "Epoch: 42, Step: 293/655, Loss: 2.207356, Accuracy: 18.68%\n",
            "Epoch: 42, Step: 294/655, Loss: 2.207349, Accuracy: 18.65%\n",
            "Epoch: 42, Step: 295/655, Loss: 2.207334, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 296/655, Loss: 2.207795, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 297/655, Loss: 2.207315, Accuracy: 18.68%\n",
            "Epoch: 42, Step: 298/655, Loss: 2.207478, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 299/655, Loss: 2.207683, Accuracy: 18.68%\n",
            "Epoch: 42, Step: 300/655, Loss: 2.207793, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 301/655, Loss: 2.207857, Accuracy: 18.68%\n",
            "Epoch: 42, Step: 302/655, Loss: 2.207611, Accuracy: 18.70%\n",
            "Epoch: 42, Step: 303/655, Loss: 2.207748, Accuracy: 18.70%\n",
            "Epoch: 42, Step: 304/655, Loss: 2.207752, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 305/655, Loss: 2.207728, Accuracy: 18.70%\n",
            "Epoch: 42, Step: 306/655, Loss: 2.207803, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 307/655, Loss: 2.207916, Accuracy: 18.65%\n",
            "Epoch: 42, Step: 308/655, Loss: 2.207989, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 309/655, Loss: 2.208030, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 310/655, Loss: 2.208188, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 311/655, Loss: 2.208024, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 312/655, Loss: 2.208400, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 313/655, Loss: 2.208163, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 314/655, Loss: 2.208359, Accuracy: 18.55%\n",
            "Epoch: 42, Step: 315/655, Loss: 2.208487, Accuracy: 18.55%\n",
            "Epoch: 42, Step: 316/655, Loss: 2.208522, Accuracy: 18.54%\n",
            "Epoch: 42, Step: 317/655, Loss: 2.208175, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 318/655, Loss: 2.207780, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 319/655, Loss: 2.207791, Accuracy: 18.55%\n",
            "Epoch: 42, Step: 320/655, Loss: 2.207695, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 321/655, Loss: 2.207770, Accuracy: 18.54%\n",
            "Epoch: 42, Step: 322/655, Loss: 2.207968, Accuracy: 18.54%\n",
            "Epoch: 42, Step: 323/655, Loss: 2.207957, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 324/655, Loss: 2.207644, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 325/655, Loss: 2.208072, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 326/655, Loss: 2.208563, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 327/655, Loss: 2.208590, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 328/655, Loss: 2.208475, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 329/655, Loss: 2.208773, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 330/655, Loss: 2.208477, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 331/655, Loss: 2.208387, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 332/655, Loss: 2.208342, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 333/655, Loss: 2.208426, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 334/655, Loss: 2.208426, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 335/655, Loss: 2.208447, Accuracy: 18.57%\n",
            "Epoch: 42, Step: 336/655, Loss: 2.208438, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 337/655, Loss: 2.208168, Accuracy: 18.57%\n",
            "Epoch: 42, Step: 338/655, Loss: 2.207779, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 339/655, Loss: 2.208191, Accuracy: 18.57%\n",
            "Epoch: 42, Step: 340/655, Loss: 2.208163, Accuracy: 18.55%\n",
            "Epoch: 42, Step: 341/655, Loss: 2.207744, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 342/655, Loss: 2.207904, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 343/655, Loss: 2.207986, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 344/655, Loss: 2.207469, Accuracy: 18.65%\n",
            "Epoch: 42, Step: 345/655, Loss: 2.207666, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 346/655, Loss: 2.208015, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 347/655, Loss: 2.208232, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 348/655, Loss: 2.208223, Accuracy: 18.55%\n",
            "Epoch: 42, Step: 349/655, Loss: 2.207989, Accuracy: 18.55%\n",
            "Epoch: 42, Step: 350/655, Loss: 2.207998, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 351/655, Loss: 2.208092, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 352/655, Loss: 2.208241, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 353/655, Loss: 2.208102, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 354/655, Loss: 2.208522, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 355/655, Loss: 2.208685, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 356/655, Loss: 2.208724, Accuracy: 18.55%\n",
            "Epoch: 42, Step: 357/655, Loss: 2.208986, Accuracy: 18.50%\n",
            "Epoch: 42, Step: 358/655, Loss: 2.208792, Accuracy: 18.51%\n",
            "Epoch: 42, Step: 359/655, Loss: 2.209093, Accuracy: 18.49%\n",
            "Epoch: 42, Step: 360/655, Loss: 2.208643, Accuracy: 18.51%\n",
            "Epoch: 42, Step: 361/655, Loss: 2.208726, Accuracy: 18.50%\n",
            "Epoch: 42, Step: 362/655, Loss: 2.208935, Accuracy: 18.49%\n",
            "Epoch: 42, Step: 363/655, Loss: 2.208668, Accuracy: 18.52%\n",
            "Epoch: 42, Step: 364/655, Loss: 2.208397, Accuracy: 18.54%\n",
            "Epoch: 42, Step: 365/655, Loss: 2.208480, Accuracy: 18.52%\n",
            "Epoch: 42, Step: 366/655, Loss: 2.208321, Accuracy: 18.52%\n",
            "Epoch: 42, Step: 367/655, Loss: 2.208545, Accuracy: 18.49%\n",
            "Epoch: 42, Step: 368/655, Loss: 2.208251, Accuracy: 18.53%\n",
            "Epoch: 42, Step: 369/655, Loss: 2.208136, Accuracy: 18.52%\n",
            "Epoch: 42, Step: 370/655, Loss: 2.208041, Accuracy: 18.52%\n",
            "Epoch: 42, Step: 371/655, Loss: 2.208091, Accuracy: 18.51%\n",
            "Epoch: 42, Step: 372/655, Loss: 2.208122, Accuracy: 18.51%\n",
            "Epoch: 42, Step: 373/655, Loss: 2.208262, Accuracy: 18.52%\n",
            "Epoch: 42, Step: 374/655, Loss: 2.208169, Accuracy: 18.52%\n",
            "Epoch: 42, Step: 375/655, Loss: 2.208509, Accuracy: 18.48%\n",
            "Epoch: 42, Step: 376/655, Loss: 2.208328, Accuracy: 18.53%\n",
            "Epoch: 42, Step: 377/655, Loss: 2.208140, Accuracy: 18.53%\n",
            "Epoch: 42, Step: 378/655, Loss: 2.208117, Accuracy: 18.53%\n",
            "Epoch: 42, Step: 379/655, Loss: 2.208073, Accuracy: 18.53%\n",
            "Epoch: 42, Step: 380/655, Loss: 2.207815, Accuracy: 18.54%\n",
            "Epoch: 42, Step: 381/655, Loss: 2.207717, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 382/655, Loss: 2.207756, Accuracy: 18.57%\n",
            "Epoch: 42, Step: 383/655, Loss: 2.207481, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 384/655, Loss: 2.207305, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 385/655, Loss: 2.207530, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 386/655, Loss: 2.207433, Accuracy: 18.57%\n",
            "Epoch: 42, Step: 387/655, Loss: 2.207251, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 388/655, Loss: 2.207292, Accuracy: 18.57%\n",
            "Epoch: 42, Step: 389/655, Loss: 2.207276, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 390/655, Loss: 2.207343, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 391/655, Loss: 2.207641, Accuracy: 18.57%\n",
            "Epoch: 42, Step: 392/655, Loss: 2.207866, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 393/655, Loss: 2.208138, Accuracy: 18.55%\n",
            "Epoch: 42, Step: 394/655, Loss: 2.208020, Accuracy: 18.54%\n",
            "Epoch: 42, Step: 395/655, Loss: 2.208141, Accuracy: 18.54%\n",
            "Epoch: 42, Step: 396/655, Loss: 2.208167, Accuracy: 18.54%\n",
            "Epoch: 42, Step: 397/655, Loss: 2.208472, Accuracy: 18.53%\n",
            "Epoch: 42, Step: 398/655, Loss: 2.208470, Accuracy: 18.53%\n",
            "Epoch: 42, Step: 399/655, Loss: 2.208438, Accuracy: 18.52%\n",
            "Epoch: 42, Step: 400/655, Loss: 2.208209, Accuracy: 18.55%\n",
            "Epoch: 42, Step: 401/655, Loss: 2.208231, Accuracy: 18.54%\n",
            "Epoch: 42, Step: 402/655, Loss: 2.208586, Accuracy: 18.51%\n",
            "Epoch: 42, Step: 403/655, Loss: 2.208881, Accuracy: 18.50%\n",
            "Epoch: 42, Step: 404/655, Loss: 2.209095, Accuracy: 18.49%\n",
            "Epoch: 42, Step: 405/655, Loss: 2.208803, Accuracy: 18.51%\n",
            "Epoch: 42, Step: 406/655, Loss: 2.208680, Accuracy: 18.50%\n",
            "Epoch: 42, Step: 407/655, Loss: 2.208364, Accuracy: 18.54%\n",
            "Epoch: 42, Step: 408/655, Loss: 2.208360, Accuracy: 18.53%\n",
            "Epoch: 42, Step: 409/655, Loss: 2.208037, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 410/655, Loss: 2.207757, Accuracy: 18.57%\n",
            "Epoch: 42, Step: 411/655, Loss: 2.207670, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 412/655, Loss: 2.207455, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 413/655, Loss: 2.207275, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 414/655, Loss: 2.207410, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 415/655, Loss: 2.207350, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 416/655, Loss: 2.207453, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 417/655, Loss: 2.207521, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 418/655, Loss: 2.207542, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 419/655, Loss: 2.207942, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 420/655, Loss: 2.207984, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 421/655, Loss: 2.207916, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 422/655, Loss: 2.208093, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 423/655, Loss: 2.207991, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 424/655, Loss: 2.207954, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 425/655, Loss: 2.208043, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 426/655, Loss: 2.208141, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 427/655, Loss: 2.207906, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 428/655, Loss: 2.207750, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 429/655, Loss: 2.208087, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 430/655, Loss: 2.207933, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 431/655, Loss: 2.207904, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 432/655, Loss: 2.207893, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 433/655, Loss: 2.207835, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 434/655, Loss: 2.207696, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 435/655, Loss: 2.207664, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 436/655, Loss: 2.207720, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 437/655, Loss: 2.207763, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 438/655, Loss: 2.207426, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 439/655, Loss: 2.207240, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 440/655, Loss: 2.207318, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 441/655, Loss: 2.207372, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 442/655, Loss: 2.207489, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 443/655, Loss: 2.207581, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 444/655, Loss: 2.207535, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 445/655, Loss: 2.207555, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 446/655, Loss: 2.207375, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 447/655, Loss: 2.207440, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 448/655, Loss: 2.207417, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 449/655, Loss: 2.207094, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 450/655, Loss: 2.207192, Accuracy: 18.65%\n",
            "Epoch: 42, Step: 451/655, Loss: 2.207348, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 452/655, Loss: 2.207279, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 453/655, Loss: 2.207206, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 454/655, Loss: 2.207253, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 455/655, Loss: 2.207295, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 456/655, Loss: 2.207297, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 457/655, Loss: 2.207432, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 458/655, Loss: 2.207402, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 459/655, Loss: 2.207693, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 460/655, Loss: 2.207745, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 461/655, Loss: 2.207543, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 462/655, Loss: 2.207442, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 463/655, Loss: 2.207253, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 464/655, Loss: 2.207140, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 465/655, Loss: 2.206882, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 466/655, Loss: 2.206929, Accuracy: 18.65%\n",
            "Epoch: 42, Step: 467/655, Loss: 2.207149, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 468/655, Loss: 2.207360, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 469/655, Loss: 2.207140, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 470/655, Loss: 2.207293, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 471/655, Loss: 2.207301, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 472/655, Loss: 2.207282, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 473/655, Loss: 2.207287, Accuracy: 18.71%\n",
            "Epoch: 42, Step: 474/655, Loss: 2.207218, Accuracy: 18.71%\n",
            "Epoch: 42, Step: 475/655, Loss: 2.207133, Accuracy: 18.71%\n",
            "Epoch: 42, Step: 476/655, Loss: 2.207277, Accuracy: 18.68%\n",
            "Epoch: 42, Step: 477/655, Loss: 2.207266, Accuracy: 18.68%\n",
            "Epoch: 42, Step: 478/655, Loss: 2.207364, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 479/655, Loss: 2.207356, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 480/655, Loss: 2.207408, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 481/655, Loss: 2.207149, Accuracy: 18.70%\n",
            "Epoch: 42, Step: 482/655, Loss: 2.207296, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 483/655, Loss: 2.206918, Accuracy: 18.70%\n",
            "Epoch: 42, Step: 484/655, Loss: 2.206955, Accuracy: 18.68%\n",
            "Epoch: 42, Step: 485/655, Loss: 2.206999, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 486/655, Loss: 2.206983, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 487/655, Loss: 2.207022, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 488/655, Loss: 2.207129, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 489/655, Loss: 2.207188, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 490/655, Loss: 2.207327, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 491/655, Loss: 2.207277, Accuracy: 18.65%\n",
            "Epoch: 42, Step: 492/655, Loss: 2.207225, Accuracy: 18.65%\n",
            "Epoch: 42, Step: 493/655, Loss: 2.207121, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 494/655, Loss: 2.207219, Accuracy: 18.65%\n",
            "Epoch: 42, Step: 495/655, Loss: 2.207439, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 496/655, Loss: 2.207323, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 497/655, Loss: 2.207293, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 498/655, Loss: 2.206957, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 499/655, Loss: 2.207133, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 500/655, Loss: 2.206946, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 501/655, Loss: 2.207162, Accuracy: 18.65%\n",
            "Epoch: 42, Step: 502/655, Loss: 2.207050, Accuracy: 18.68%\n",
            "Epoch: 42, Step: 503/655, Loss: 2.206861, Accuracy: 18.68%\n",
            "Epoch: 42, Step: 504/655, Loss: 2.206988, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 505/655, Loss: 2.207235, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 506/655, Loss: 2.207201, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 507/655, Loss: 2.207039, Accuracy: 18.65%\n",
            "Epoch: 42, Step: 508/655, Loss: 2.206908, Accuracy: 18.68%\n",
            "Epoch: 42, Step: 509/655, Loss: 2.207136, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 510/655, Loss: 2.207268, Accuracy: 18.65%\n",
            "Epoch: 42, Step: 511/655, Loss: 2.207381, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 512/655, Loss: 2.207397, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 513/655, Loss: 2.207260, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 514/655, Loss: 2.207126, Accuracy: 18.65%\n",
            "Epoch: 42, Step: 515/655, Loss: 2.207364, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 516/655, Loss: 2.207470, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 517/655, Loss: 2.207176, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 518/655, Loss: 2.207261, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 519/655, Loss: 2.207337, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 520/655, Loss: 2.207257, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 521/655, Loss: 2.207584, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 522/655, Loss: 2.207586, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 523/655, Loss: 2.207575, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 524/655, Loss: 2.207649, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 525/655, Loss: 2.207661, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 526/655, Loss: 2.207597, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 527/655, Loss: 2.207739, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 528/655, Loss: 2.207821, Accuracy: 18.57%\n",
            "Epoch: 42, Step: 529/655, Loss: 2.207733, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 530/655, Loss: 2.207591, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 531/655, Loss: 2.207496, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 532/655, Loss: 2.207641, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 533/655, Loss: 2.207598, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 534/655, Loss: 2.207455, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 535/655, Loss: 2.207225, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 536/655, Loss: 2.207125, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 537/655, Loss: 2.207289, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 538/655, Loss: 2.207149, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 539/655, Loss: 2.207109, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 540/655, Loss: 2.207135, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 541/655, Loss: 2.207051, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 542/655, Loss: 2.206919, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 543/655, Loss: 2.206805, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 544/655, Loss: 2.206969, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 545/655, Loss: 2.207028, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 546/655, Loss: 2.207058, Accuracy: 18.57%\n",
            "Epoch: 42, Step: 547/655, Loss: 2.206864, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 548/655, Loss: 2.206968, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 549/655, Loss: 2.206969, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 550/655, Loss: 2.207131, Accuracy: 18.55%\n",
            "Epoch: 42, Step: 551/655, Loss: 2.207145, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 552/655, Loss: 2.207143, Accuracy: 18.57%\n",
            "Epoch: 42, Step: 553/655, Loss: 2.207020, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 554/655, Loss: 2.207392, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 555/655, Loss: 2.207523, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 556/655, Loss: 2.207547, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 557/655, Loss: 2.207475, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 558/655, Loss: 2.207165, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 559/655, Loss: 2.207145, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 560/655, Loss: 2.207161, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 561/655, Loss: 2.207061, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 562/655, Loss: 2.207075, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 563/655, Loss: 2.207044, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 564/655, Loss: 2.207173, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 565/655, Loss: 2.207198, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 566/655, Loss: 2.206926, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 567/655, Loss: 2.207076, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 568/655, Loss: 2.206856, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 569/655, Loss: 2.206810, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 570/655, Loss: 2.206874, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 571/655, Loss: 2.206852, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 572/655, Loss: 2.206688, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 573/655, Loss: 2.206673, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 574/655, Loss: 2.206609, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 575/655, Loss: 2.206596, Accuracy: 18.58%\n",
            "Epoch: 42, Step: 576/655, Loss: 2.206573, Accuracy: 18.57%\n",
            "Epoch: 42, Step: 577/655, Loss: 2.206747, Accuracy: 18.55%\n",
            "Epoch: 42, Step: 578/655, Loss: 2.206710, Accuracy: 18.55%\n",
            "Epoch: 42, Step: 579/655, Loss: 2.206764, Accuracy: 18.54%\n",
            "Epoch: 42, Step: 580/655, Loss: 2.206610, Accuracy: 18.57%\n",
            "Epoch: 42, Step: 581/655, Loss: 2.206877, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 582/655, Loss: 2.206789, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 583/655, Loss: 2.206806, Accuracy: 18.55%\n",
            "Epoch: 42, Step: 584/655, Loss: 2.206697, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 585/655, Loss: 2.206801, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 586/655, Loss: 2.206859, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 587/655, Loss: 2.206738, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 588/655, Loss: 2.206999, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 589/655, Loss: 2.207055, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 590/655, Loss: 2.207002, Accuracy: 18.57%\n",
            "Epoch: 42, Step: 591/655, Loss: 2.207071, Accuracy: 18.57%\n",
            "Epoch: 42, Step: 592/655, Loss: 2.207069, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 593/655, Loss: 2.207028, Accuracy: 18.56%\n",
            "Epoch: 42, Step: 594/655, Loss: 2.206820, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 595/655, Loss: 2.206823, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 596/655, Loss: 2.206877, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 597/655, Loss: 2.206684, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 598/655, Loss: 2.206707, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 599/655, Loss: 2.206630, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 600/655, Loss: 2.206413, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 601/655, Loss: 2.206290, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 602/655, Loss: 2.206325, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 603/655, Loss: 2.206499, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 604/655, Loss: 2.206520, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 605/655, Loss: 2.206296, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 606/655, Loss: 2.206451, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 607/655, Loss: 2.206273, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 608/655, Loss: 2.206296, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 609/655, Loss: 2.206219, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 610/655, Loss: 2.206359, Accuracy: 18.65%\n",
            "Epoch: 42, Step: 611/655, Loss: 2.206276, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 612/655, Loss: 2.206267, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 613/655, Loss: 2.206122, Accuracy: 18.68%\n",
            "Epoch: 42, Step: 614/655, Loss: 2.206019, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 615/655, Loss: 2.205897, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 616/655, Loss: 2.205770, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 617/655, Loss: 2.205772, Accuracy: 18.68%\n",
            "Epoch: 42, Step: 618/655, Loss: 2.205664, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 619/655, Loss: 2.205704, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 620/655, Loss: 2.205896, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 621/655, Loss: 2.206032, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 622/655, Loss: 2.206055, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 623/655, Loss: 2.206104, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 624/655, Loss: 2.206273, Accuracy: 18.66%\n",
            "Epoch: 42, Step: 625/655, Loss: 2.206291, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 626/655, Loss: 2.206256, Accuracy: 18.68%\n",
            "Epoch: 42, Step: 627/655, Loss: 2.206155, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 628/655, Loss: 2.206126, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 629/655, Loss: 2.206199, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 630/655, Loss: 2.206349, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 631/655, Loss: 2.206235, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 632/655, Loss: 2.206247, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 633/655, Loss: 2.206409, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 634/655, Loss: 2.206563, Accuracy: 18.68%\n",
            "Epoch: 42, Step: 635/655, Loss: 2.206647, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 636/655, Loss: 2.206647, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 637/655, Loss: 2.206638, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 638/655, Loss: 2.206557, Accuracy: 18.68%\n",
            "Epoch: 42, Step: 639/655, Loss: 2.206541, Accuracy: 18.69%\n",
            "Epoch: 42, Step: 640/655, Loss: 2.206729, Accuracy: 18.67%\n",
            "Epoch: 42, Step: 641/655, Loss: 2.206835, Accuracy: 18.65%\n",
            "Epoch: 42, Step: 642/655, Loss: 2.206962, Accuracy: 18.64%\n",
            "Epoch: 42, Step: 643/655, Loss: 2.206948, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 644/655, Loss: 2.207063, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 645/655, Loss: 2.207116, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 646/655, Loss: 2.207155, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 647/655, Loss: 2.206996, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 648/655, Loss: 2.206937, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 649/655, Loss: 2.206975, Accuracy: 18.63%\n",
            "Epoch: 42, Step: 650/655, Loss: 2.207141, Accuracy: 18.62%\n",
            "Epoch: 42, Step: 651/655, Loss: 2.207251, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 652/655, Loss: 2.207383, Accuracy: 18.61%\n",
            "Epoch: 42, Step: 653/655, Loss: 2.207275, Accuracy: 18.60%\n",
            "Epoch: 42, Step: 654/655, Loss: 2.207410, Accuracy: 18.59%\n",
            "Epoch: 42, Step: 655/655, Loss: 2.207614, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 1/655, Loss: 2.311309, Accuracy: 9.38%\n",
            "Epoch: 43, Step: 2/655, Loss: 2.224547, Accuracy: 15.62%\n",
            "Epoch: 43, Step: 3/655, Loss: 2.210867, Accuracy: 18.75%\n",
            "Epoch: 43, Step: 4/655, Loss: 2.233936, Accuracy: 15.62%\n",
            "Epoch: 43, Step: 5/655, Loss: 2.231486, Accuracy: 16.88%\n",
            "Epoch: 43, Step: 6/655, Loss: 2.237275, Accuracy: 18.23%\n",
            "Epoch: 43, Step: 7/655, Loss: 2.223206, Accuracy: 19.64%\n",
            "Epoch: 43, Step: 8/655, Loss: 2.216136, Accuracy: 19.53%\n",
            "Epoch: 43, Step: 9/655, Loss: 2.214920, Accuracy: 19.44%\n",
            "Epoch: 43, Step: 10/655, Loss: 2.209296, Accuracy: 20.00%\n",
            "Epoch: 43, Step: 11/655, Loss: 2.202684, Accuracy: 19.89%\n",
            "Epoch: 43, Step: 12/655, Loss: 2.197963, Accuracy: 20.05%\n",
            "Epoch: 43, Step: 13/655, Loss: 2.202874, Accuracy: 20.43%\n",
            "Epoch: 43, Step: 14/655, Loss: 2.197429, Accuracy: 20.09%\n",
            "Epoch: 43, Step: 15/655, Loss: 2.198226, Accuracy: 20.62%\n",
            "Epoch: 43, Step: 16/655, Loss: 2.201850, Accuracy: 20.12%\n",
            "Epoch: 43, Step: 17/655, Loss: 2.202980, Accuracy: 20.04%\n",
            "Epoch: 43, Step: 18/655, Loss: 2.202678, Accuracy: 19.79%\n",
            "Epoch: 43, Step: 19/655, Loss: 2.204114, Accuracy: 19.90%\n",
            "Epoch: 43, Step: 20/655, Loss: 2.203524, Accuracy: 19.84%\n",
            "Epoch: 43, Step: 21/655, Loss: 2.210692, Accuracy: 19.64%\n",
            "Epoch: 43, Step: 22/655, Loss: 2.215482, Accuracy: 19.46%\n",
            "Epoch: 43, Step: 23/655, Loss: 2.212280, Accuracy: 19.84%\n",
            "Epoch: 43, Step: 24/655, Loss: 2.202063, Accuracy: 20.05%\n",
            "Epoch: 43, Step: 25/655, Loss: 2.205890, Accuracy: 20.25%\n",
            "Epoch: 43, Step: 26/655, Loss: 2.204890, Accuracy: 20.07%\n",
            "Epoch: 43, Step: 27/655, Loss: 2.203187, Accuracy: 20.14%\n",
            "Epoch: 43, Step: 28/655, Loss: 2.207177, Accuracy: 20.20%\n",
            "Epoch: 43, Step: 29/655, Loss: 2.205793, Accuracy: 20.04%\n",
            "Epoch: 43, Step: 30/655, Loss: 2.206919, Accuracy: 20.21%\n",
            "Epoch: 43, Step: 31/655, Loss: 2.205122, Accuracy: 20.16%\n",
            "Epoch: 43, Step: 32/655, Loss: 2.208988, Accuracy: 19.82%\n",
            "Epoch: 43, Step: 33/655, Loss: 2.209961, Accuracy: 19.98%\n",
            "Epoch: 43, Step: 34/655, Loss: 2.209234, Accuracy: 20.04%\n",
            "Epoch: 43, Step: 35/655, Loss: 2.205789, Accuracy: 20.36%\n",
            "Epoch: 43, Step: 36/655, Loss: 2.206593, Accuracy: 20.31%\n",
            "Epoch: 43, Step: 37/655, Loss: 2.204762, Accuracy: 20.19%\n",
            "Epoch: 43, Step: 38/655, Loss: 2.201970, Accuracy: 20.48%\n",
            "Epoch: 43, Step: 39/655, Loss: 2.204976, Accuracy: 20.43%\n",
            "Epoch: 43, Step: 40/655, Loss: 2.205890, Accuracy: 20.39%\n",
            "Epoch: 43, Step: 41/655, Loss: 2.206257, Accuracy: 20.58%\n",
            "Epoch: 43, Step: 42/655, Loss: 2.207348, Accuracy: 20.24%\n",
            "Epoch: 43, Step: 43/655, Loss: 2.205115, Accuracy: 20.13%\n",
            "Epoch: 43, Step: 44/655, Loss: 2.207314, Accuracy: 20.10%\n",
            "Epoch: 43, Step: 45/655, Loss: 2.209176, Accuracy: 19.93%\n",
            "Epoch: 43, Step: 46/655, Loss: 2.211100, Accuracy: 19.70%\n",
            "Epoch: 43, Step: 47/655, Loss: 2.209730, Accuracy: 19.68%\n",
            "Epoch: 43, Step: 48/655, Loss: 2.211563, Accuracy: 19.47%\n",
            "Epoch: 43, Step: 49/655, Loss: 2.212277, Accuracy: 19.45%\n",
            "Epoch: 43, Step: 50/655, Loss: 2.210641, Accuracy: 19.44%\n",
            "Epoch: 43, Step: 51/655, Loss: 2.208042, Accuracy: 19.49%\n",
            "Epoch: 43, Step: 52/655, Loss: 2.209349, Accuracy: 19.35%\n",
            "Epoch: 43, Step: 53/655, Loss: 2.209562, Accuracy: 19.34%\n",
            "Epoch: 43, Step: 54/655, Loss: 2.209571, Accuracy: 19.21%\n",
            "Epoch: 43, Step: 55/655, Loss: 2.211165, Accuracy: 19.09%\n",
            "Epoch: 43, Step: 56/655, Loss: 2.212467, Accuracy: 19.03%\n",
            "Epoch: 43, Step: 57/655, Loss: 2.212533, Accuracy: 18.97%\n",
            "Epoch: 43, Step: 58/655, Loss: 2.211203, Accuracy: 18.91%\n",
            "Epoch: 43, Step: 59/655, Loss: 2.208769, Accuracy: 19.23%\n",
            "Epoch: 43, Step: 60/655, Loss: 2.207438, Accuracy: 19.43%\n",
            "Epoch: 43, Step: 61/655, Loss: 2.207673, Accuracy: 19.52%\n",
            "Epoch: 43, Step: 62/655, Loss: 2.206979, Accuracy: 19.71%\n",
            "Epoch: 43, Step: 63/655, Loss: 2.207599, Accuracy: 19.59%\n",
            "Epoch: 43, Step: 64/655, Loss: 2.208279, Accuracy: 19.63%\n",
            "Epoch: 43, Step: 65/655, Loss: 2.208554, Accuracy: 19.62%\n",
            "Epoch: 43, Step: 66/655, Loss: 2.208433, Accuracy: 19.55%\n",
            "Epoch: 43, Step: 67/655, Loss: 2.207314, Accuracy: 19.59%\n",
            "Epoch: 43, Step: 68/655, Loss: 2.206475, Accuracy: 19.53%\n",
            "Epoch: 43, Step: 69/655, Loss: 2.206099, Accuracy: 19.57%\n",
            "Epoch: 43, Step: 70/655, Loss: 2.203730, Accuracy: 19.60%\n",
            "Epoch: 43, Step: 71/655, Loss: 2.203829, Accuracy: 19.59%\n",
            "Epoch: 43, Step: 72/655, Loss: 2.204976, Accuracy: 19.49%\n",
            "Epoch: 43, Step: 73/655, Loss: 2.206149, Accuracy: 19.48%\n",
            "Epoch: 43, Step: 74/655, Loss: 2.205455, Accuracy: 19.59%\n",
            "Epoch: 43, Step: 75/655, Loss: 2.206453, Accuracy: 19.50%\n",
            "Epoch: 43, Step: 76/655, Loss: 2.204026, Accuracy: 19.57%\n",
            "Epoch: 43, Step: 77/655, Loss: 2.204123, Accuracy: 19.64%\n",
            "Epoch: 43, Step: 78/655, Loss: 2.204570, Accuracy: 19.63%\n",
            "Epoch: 43, Step: 79/655, Loss: 2.206908, Accuracy: 19.42%\n",
            "Epoch: 43, Step: 80/655, Loss: 2.207317, Accuracy: 19.45%\n",
            "Epoch: 43, Step: 81/655, Loss: 2.206873, Accuracy: 19.52%\n",
            "Epoch: 43, Step: 82/655, Loss: 2.206572, Accuracy: 19.59%\n",
            "Epoch: 43, Step: 83/655, Loss: 2.206254, Accuracy: 19.58%\n",
            "Epoch: 43, Step: 84/655, Loss: 2.207062, Accuracy: 19.61%\n",
            "Epoch: 43, Step: 85/655, Loss: 2.208173, Accuracy: 19.56%\n",
            "Epoch: 43, Step: 86/655, Loss: 2.207345, Accuracy: 19.66%\n",
            "Epoch: 43, Step: 87/655, Loss: 2.206619, Accuracy: 19.68%\n",
            "Epoch: 43, Step: 88/655, Loss: 2.205389, Accuracy: 19.74%\n",
            "Epoch: 43, Step: 89/655, Loss: 2.205327, Accuracy: 19.73%\n",
            "Epoch: 43, Step: 90/655, Loss: 2.205718, Accuracy: 19.83%\n",
            "Epoch: 43, Step: 91/655, Loss: 2.206765, Accuracy: 19.64%\n",
            "Epoch: 43, Step: 92/655, Loss: 2.207887, Accuracy: 19.60%\n",
            "Epoch: 43, Step: 93/655, Loss: 2.207299, Accuracy: 19.62%\n",
            "Epoch: 43, Step: 94/655, Loss: 2.209203, Accuracy: 19.48%\n",
            "Epoch: 43, Step: 95/655, Loss: 2.208054, Accuracy: 19.47%\n",
            "Epoch: 43, Step: 96/655, Loss: 2.207892, Accuracy: 19.43%\n",
            "Epoch: 43, Step: 97/655, Loss: 2.206302, Accuracy: 19.59%\n",
            "Epoch: 43, Step: 98/655, Loss: 2.204839, Accuracy: 19.67%\n",
            "Epoch: 43, Step: 99/655, Loss: 2.205285, Accuracy: 19.70%\n",
            "Epoch: 43, Step: 100/655, Loss: 2.205122, Accuracy: 19.69%\n",
            "Epoch: 43, Step: 101/655, Loss: 2.205249, Accuracy: 19.71%\n",
            "Epoch: 43, Step: 102/655, Loss: 2.206085, Accuracy: 19.76%\n",
            "Epoch: 43, Step: 103/655, Loss: 2.204758, Accuracy: 19.81%\n",
            "Epoch: 43, Step: 104/655, Loss: 2.204517, Accuracy: 19.74%\n",
            "Epoch: 43, Step: 105/655, Loss: 2.204785, Accuracy: 19.70%\n",
            "Epoch: 43, Step: 106/655, Loss: 2.205297, Accuracy: 19.58%\n",
            "Epoch: 43, Step: 107/655, Loss: 2.204488, Accuracy: 19.63%\n",
            "Epoch: 43, Step: 108/655, Loss: 2.203918, Accuracy: 19.76%\n",
            "Epoch: 43, Step: 109/655, Loss: 2.204490, Accuracy: 19.67%\n",
            "Epoch: 43, Step: 110/655, Loss: 2.204423, Accuracy: 19.72%\n",
            "Epoch: 43, Step: 111/655, Loss: 2.204614, Accuracy: 19.65%\n",
            "Epoch: 43, Step: 112/655, Loss: 2.205065, Accuracy: 19.64%\n",
            "Epoch: 43, Step: 113/655, Loss: 2.203590, Accuracy: 19.61%\n",
            "Epoch: 43, Step: 114/655, Loss: 2.203236, Accuracy: 19.68%\n",
            "Epoch: 43, Step: 115/655, Loss: 2.202942, Accuracy: 19.73%\n",
            "Epoch: 43, Step: 116/655, Loss: 2.203121, Accuracy: 19.75%\n",
            "Epoch: 43, Step: 117/655, Loss: 2.202692, Accuracy: 19.82%\n",
            "Epoch: 43, Step: 118/655, Loss: 2.202520, Accuracy: 19.76%\n",
            "Epoch: 43, Step: 119/655, Loss: 2.202068, Accuracy: 19.75%\n",
            "Epoch: 43, Step: 120/655, Loss: 2.202796, Accuracy: 19.69%\n",
            "Epoch: 43, Step: 121/655, Loss: 2.202874, Accuracy: 19.60%\n",
            "Epoch: 43, Step: 122/655, Loss: 2.202887, Accuracy: 19.52%\n",
            "Epoch: 43, Step: 123/655, Loss: 2.202264, Accuracy: 19.59%\n",
            "Epoch: 43, Step: 124/655, Loss: 2.201317, Accuracy: 19.61%\n",
            "Epoch: 43, Step: 125/655, Loss: 2.201589, Accuracy: 19.57%\n",
            "Epoch: 43, Step: 126/655, Loss: 2.202565, Accuracy: 19.57%\n",
            "Epoch: 43, Step: 127/655, Loss: 2.202614, Accuracy: 19.54%\n",
            "Epoch: 43, Step: 128/655, Loss: 2.203105, Accuracy: 19.48%\n",
            "Epoch: 43, Step: 129/655, Loss: 2.203378, Accuracy: 19.55%\n",
            "Epoch: 43, Step: 130/655, Loss: 2.202964, Accuracy: 19.57%\n",
            "Epoch: 43, Step: 131/655, Loss: 2.202562, Accuracy: 19.58%\n",
            "Epoch: 43, Step: 132/655, Loss: 2.202874, Accuracy: 19.55%\n",
            "Epoch: 43, Step: 133/655, Loss: 2.203170, Accuracy: 19.62%\n",
            "Epoch: 43, Step: 134/655, Loss: 2.203234, Accuracy: 19.59%\n",
            "Epoch: 43, Step: 135/655, Loss: 2.203005, Accuracy: 19.58%\n",
            "Epoch: 43, Step: 136/655, Loss: 2.202481, Accuracy: 19.65%\n",
            "Epoch: 43, Step: 137/655, Loss: 2.202205, Accuracy: 19.66%\n",
            "Epoch: 43, Step: 138/655, Loss: 2.202600, Accuracy: 19.68%\n",
            "Epoch: 43, Step: 139/655, Loss: 2.202514, Accuracy: 19.74%\n",
            "Epoch: 43, Step: 140/655, Loss: 2.203158, Accuracy: 19.73%\n",
            "Epoch: 43, Step: 141/655, Loss: 2.203186, Accuracy: 19.75%\n",
            "Epoch: 43, Step: 142/655, Loss: 2.203218, Accuracy: 19.81%\n",
            "Epoch: 43, Step: 143/655, Loss: 2.202920, Accuracy: 19.82%\n",
            "Epoch: 43, Step: 144/655, Loss: 2.203366, Accuracy: 19.77%\n",
            "Epoch: 43, Step: 145/655, Loss: 2.203248, Accuracy: 19.76%\n",
            "Epoch: 43, Step: 146/655, Loss: 2.203114, Accuracy: 19.73%\n",
            "Epoch: 43, Step: 147/655, Loss: 2.202451, Accuracy: 19.73%\n",
            "Epoch: 43, Step: 148/655, Loss: 2.202546, Accuracy: 19.74%\n",
            "Epoch: 43, Step: 149/655, Loss: 2.201955, Accuracy: 19.84%\n",
            "Epoch: 43, Step: 150/655, Loss: 2.202690, Accuracy: 19.79%\n",
            "Epoch: 43, Step: 151/655, Loss: 2.203434, Accuracy: 19.76%\n",
            "Epoch: 43, Step: 152/655, Loss: 2.203660, Accuracy: 19.76%\n",
            "Epoch: 43, Step: 153/655, Loss: 2.205026, Accuracy: 19.71%\n",
            "Epoch: 43, Step: 154/655, Loss: 2.205363, Accuracy: 19.68%\n",
            "Epoch: 43, Step: 155/655, Loss: 2.205401, Accuracy: 19.70%\n",
            "Epoch: 43, Step: 156/655, Loss: 2.204703, Accuracy: 19.67%\n",
            "Epoch: 43, Step: 157/655, Loss: 2.205218, Accuracy: 19.59%\n",
            "Epoch: 43, Step: 158/655, Loss: 2.204867, Accuracy: 19.58%\n",
            "Epoch: 43, Step: 159/655, Loss: 2.204677, Accuracy: 19.58%\n",
            "Epoch: 43, Step: 160/655, Loss: 2.204477, Accuracy: 19.61%\n",
            "Epoch: 43, Step: 161/655, Loss: 2.204136, Accuracy: 19.58%\n",
            "Epoch: 43, Step: 162/655, Loss: 2.204988, Accuracy: 19.56%\n",
            "Epoch: 43, Step: 163/655, Loss: 2.204165, Accuracy: 19.59%\n",
            "Epoch: 43, Step: 164/655, Loss: 2.203974, Accuracy: 19.57%\n",
            "Epoch: 43, Step: 165/655, Loss: 2.203842, Accuracy: 19.55%\n",
            "Epoch: 43, Step: 166/655, Loss: 2.203185, Accuracy: 19.65%\n",
            "Epoch: 43, Step: 167/655, Loss: 2.203817, Accuracy: 19.57%\n",
            "Epoch: 43, Step: 168/655, Loss: 2.204184, Accuracy: 19.59%\n",
            "Epoch: 43, Step: 169/655, Loss: 2.205426, Accuracy: 19.55%\n",
            "Epoch: 43, Step: 170/655, Loss: 2.204960, Accuracy: 19.52%\n",
            "Epoch: 43, Step: 171/655, Loss: 2.205123, Accuracy: 19.55%\n",
            "Epoch: 43, Step: 172/655, Loss: 2.205439, Accuracy: 19.53%\n",
            "Epoch: 43, Step: 173/655, Loss: 2.204589, Accuracy: 19.53%\n",
            "Epoch: 43, Step: 174/655, Loss: 2.205071, Accuracy: 19.50%\n",
            "Epoch: 43, Step: 175/655, Loss: 2.204786, Accuracy: 19.52%\n",
            "Epoch: 43, Step: 176/655, Loss: 2.204055, Accuracy: 19.60%\n",
            "Epoch: 43, Step: 177/655, Loss: 2.203573, Accuracy: 19.70%\n",
            "Epoch: 43, Step: 178/655, Loss: 2.204045, Accuracy: 19.70%\n",
            "Epoch: 43, Step: 179/655, Loss: 2.204560, Accuracy: 19.69%\n",
            "Epoch: 43, Step: 180/655, Loss: 2.204918, Accuracy: 19.65%\n",
            "Epoch: 43, Step: 181/655, Loss: 2.204723, Accuracy: 19.61%\n",
            "Epoch: 43, Step: 182/655, Loss: 2.205404, Accuracy: 19.61%\n",
            "Epoch: 43, Step: 183/655, Loss: 2.205630, Accuracy: 19.67%\n",
            "Epoch: 43, Step: 184/655, Loss: 2.205954, Accuracy: 19.62%\n",
            "Epoch: 43, Step: 185/655, Loss: 2.205354, Accuracy: 19.61%\n",
            "Epoch: 43, Step: 186/655, Loss: 2.205493, Accuracy: 19.56%\n",
            "Epoch: 43, Step: 187/655, Loss: 2.204941, Accuracy: 19.60%\n",
            "Epoch: 43, Step: 188/655, Loss: 2.205129, Accuracy: 19.58%\n",
            "Epoch: 43, Step: 189/655, Loss: 2.205439, Accuracy: 19.58%\n",
            "Epoch: 43, Step: 190/655, Loss: 2.204823, Accuracy: 19.59%\n",
            "Epoch: 43, Step: 191/655, Loss: 2.205125, Accuracy: 19.58%\n",
            "Epoch: 43, Step: 192/655, Loss: 2.204745, Accuracy: 19.56%\n",
            "Epoch: 43, Step: 193/655, Loss: 2.204663, Accuracy: 19.54%\n",
            "Epoch: 43, Step: 194/655, Loss: 2.204864, Accuracy: 19.52%\n",
            "Epoch: 43, Step: 195/655, Loss: 2.205476, Accuracy: 19.47%\n",
            "Epoch: 43, Step: 196/655, Loss: 2.205621, Accuracy: 19.45%\n",
            "Epoch: 43, Step: 197/655, Loss: 2.206195, Accuracy: 19.42%\n",
            "Epoch: 43, Step: 198/655, Loss: 2.205865, Accuracy: 19.41%\n",
            "Epoch: 43, Step: 199/655, Loss: 2.205412, Accuracy: 19.41%\n",
            "Epoch: 43, Step: 200/655, Loss: 2.205583, Accuracy: 19.34%\n",
            "Epoch: 43, Step: 201/655, Loss: 2.205271, Accuracy: 19.34%\n",
            "Epoch: 43, Step: 202/655, Loss: 2.205452, Accuracy: 19.37%\n",
            "Epoch: 43, Step: 203/655, Loss: 2.205791, Accuracy: 19.33%\n",
            "Epoch: 43, Step: 204/655, Loss: 2.206365, Accuracy: 19.33%\n",
            "Epoch: 43, Step: 205/655, Loss: 2.206594, Accuracy: 19.31%\n",
            "Epoch: 43, Step: 206/655, Loss: 2.207092, Accuracy: 19.30%\n",
            "Epoch: 43, Step: 207/655, Loss: 2.207037, Accuracy: 19.31%\n",
            "Epoch: 43, Step: 208/655, Loss: 2.206922, Accuracy: 19.28%\n",
            "Epoch: 43, Step: 209/655, Loss: 2.206804, Accuracy: 19.24%\n",
            "Epoch: 43, Step: 210/655, Loss: 2.206906, Accuracy: 19.27%\n",
            "Epoch: 43, Step: 211/655, Loss: 2.206888, Accuracy: 19.24%\n",
            "Epoch: 43, Step: 212/655, Loss: 2.206781, Accuracy: 19.18%\n",
            "Epoch: 43, Step: 213/655, Loss: 2.207573, Accuracy: 19.16%\n",
            "Epoch: 43, Step: 214/655, Loss: 2.207282, Accuracy: 19.14%\n",
            "Epoch: 43, Step: 215/655, Loss: 2.207424, Accuracy: 19.13%\n",
            "Epoch: 43, Step: 216/655, Loss: 2.207176, Accuracy: 19.18%\n",
            "Epoch: 43, Step: 217/655, Loss: 2.207190, Accuracy: 19.15%\n",
            "Epoch: 43, Step: 218/655, Loss: 2.207334, Accuracy: 19.14%\n",
            "Epoch: 43, Step: 219/655, Loss: 2.207833, Accuracy: 19.09%\n",
            "Epoch: 43, Step: 220/655, Loss: 2.208150, Accuracy: 19.11%\n",
            "Epoch: 43, Step: 221/655, Loss: 2.208321, Accuracy: 19.09%\n",
            "Epoch: 43, Step: 222/655, Loss: 2.208618, Accuracy: 19.06%\n",
            "Epoch: 43, Step: 223/655, Loss: 2.208568, Accuracy: 19.03%\n",
            "Epoch: 43, Step: 224/655, Loss: 2.208781, Accuracy: 19.03%\n",
            "Epoch: 43, Step: 225/655, Loss: 2.208571, Accuracy: 19.06%\n",
            "Epoch: 43, Step: 226/655, Loss: 2.208618, Accuracy: 19.05%\n",
            "Epoch: 43, Step: 227/655, Loss: 2.208356, Accuracy: 19.01%\n",
            "Epoch: 43, Step: 228/655, Loss: 2.209014, Accuracy: 18.98%\n",
            "Epoch: 43, Step: 229/655, Loss: 2.208940, Accuracy: 19.00%\n",
            "Epoch: 43, Step: 230/655, Loss: 2.208984, Accuracy: 18.99%\n",
            "Epoch: 43, Step: 231/655, Loss: 2.208891, Accuracy: 19.01%\n",
            "Epoch: 43, Step: 232/655, Loss: 2.208784, Accuracy: 19.05%\n",
            "Epoch: 43, Step: 233/655, Loss: 2.208864, Accuracy: 19.02%\n",
            "Epoch: 43, Step: 234/655, Loss: 2.208459, Accuracy: 19.04%\n",
            "Epoch: 43, Step: 235/655, Loss: 2.207756, Accuracy: 19.10%\n",
            "Epoch: 43, Step: 236/655, Loss: 2.207783, Accuracy: 19.16%\n",
            "Epoch: 43, Step: 237/655, Loss: 2.208053, Accuracy: 19.16%\n",
            "Epoch: 43, Step: 238/655, Loss: 2.208562, Accuracy: 19.10%\n",
            "Epoch: 43, Step: 239/655, Loss: 2.208969, Accuracy: 19.08%\n",
            "Epoch: 43, Step: 240/655, Loss: 2.209342, Accuracy: 19.06%\n",
            "Epoch: 43, Step: 241/655, Loss: 2.209698, Accuracy: 19.05%\n",
            "Epoch: 43, Step: 242/655, Loss: 2.210056, Accuracy: 19.01%\n",
            "Epoch: 43, Step: 243/655, Loss: 2.209893, Accuracy: 19.02%\n",
            "Epoch: 43, Step: 244/655, Loss: 2.209584, Accuracy: 19.02%\n",
            "Epoch: 43, Step: 245/655, Loss: 2.209494, Accuracy: 18.99%\n",
            "Epoch: 43, Step: 246/655, Loss: 2.209437, Accuracy: 18.99%\n",
            "Epoch: 43, Step: 247/655, Loss: 2.209574, Accuracy: 18.95%\n",
            "Epoch: 43, Step: 248/655, Loss: 2.209702, Accuracy: 18.91%\n",
            "Epoch: 43, Step: 249/655, Loss: 2.209485, Accuracy: 18.89%\n",
            "Epoch: 43, Step: 250/655, Loss: 2.209265, Accuracy: 18.91%\n",
            "Epoch: 43, Step: 251/655, Loss: 2.209217, Accuracy: 18.91%\n",
            "Epoch: 43, Step: 252/655, Loss: 2.208875, Accuracy: 18.92%\n",
            "Epoch: 43, Step: 253/655, Loss: 2.209090, Accuracy: 18.91%\n",
            "Epoch: 43, Step: 254/655, Loss: 2.209157, Accuracy: 18.91%\n",
            "Epoch: 43, Step: 255/655, Loss: 2.208979, Accuracy: 18.91%\n",
            "Epoch: 43, Step: 256/655, Loss: 2.208844, Accuracy: 18.90%\n",
            "Epoch: 43, Step: 257/655, Loss: 2.209132, Accuracy: 18.88%\n",
            "Epoch: 43, Step: 258/655, Loss: 2.209213, Accuracy: 18.91%\n",
            "Epoch: 43, Step: 259/655, Loss: 2.209752, Accuracy: 18.87%\n",
            "Epoch: 43, Step: 260/655, Loss: 2.209816, Accuracy: 18.89%\n",
            "Epoch: 43, Step: 261/655, Loss: 2.209489, Accuracy: 18.91%\n",
            "Epoch: 43, Step: 262/655, Loss: 2.209446, Accuracy: 18.87%\n",
            "Epoch: 43, Step: 263/655, Loss: 2.209242, Accuracy: 18.89%\n",
            "Epoch: 43, Step: 264/655, Loss: 2.209444, Accuracy: 18.86%\n",
            "Epoch: 43, Step: 265/655, Loss: 2.209258, Accuracy: 18.83%\n",
            "Epoch: 43, Step: 266/655, Loss: 2.208986, Accuracy: 18.84%\n",
            "Epoch: 43, Step: 267/655, Loss: 2.208954, Accuracy: 18.84%\n",
            "Epoch: 43, Step: 268/655, Loss: 2.208284, Accuracy: 18.91%\n",
            "Epoch: 43, Step: 269/655, Loss: 2.207889, Accuracy: 18.94%\n",
            "Epoch: 43, Step: 270/655, Loss: 2.207881, Accuracy: 18.92%\n",
            "Epoch: 43, Step: 271/655, Loss: 2.207598, Accuracy: 18.97%\n",
            "Epoch: 43, Step: 272/655, Loss: 2.207319, Accuracy: 18.96%\n",
            "Epoch: 43, Step: 273/655, Loss: 2.207316, Accuracy: 18.92%\n",
            "Epoch: 43, Step: 274/655, Loss: 2.207651, Accuracy: 18.93%\n",
            "Epoch: 43, Step: 275/655, Loss: 2.207822, Accuracy: 18.92%\n",
            "Epoch: 43, Step: 276/655, Loss: 2.208035, Accuracy: 18.91%\n",
            "Epoch: 43, Step: 277/655, Loss: 2.207680, Accuracy: 18.93%\n",
            "Epoch: 43, Step: 278/655, Loss: 2.207661, Accuracy: 18.92%\n",
            "Epoch: 43, Step: 279/655, Loss: 2.207868, Accuracy: 18.92%\n",
            "Epoch: 43, Step: 280/655, Loss: 2.208045, Accuracy: 18.91%\n",
            "Epoch: 43, Step: 281/655, Loss: 2.208042, Accuracy: 18.91%\n",
            "Epoch: 43, Step: 282/655, Loss: 2.207679, Accuracy: 18.92%\n",
            "Epoch: 43, Step: 283/655, Loss: 2.207830, Accuracy: 18.86%\n",
            "Epoch: 43, Step: 284/655, Loss: 2.208163, Accuracy: 18.85%\n",
            "Epoch: 43, Step: 285/655, Loss: 2.207767, Accuracy: 18.87%\n",
            "Epoch: 43, Step: 286/655, Loss: 2.208055, Accuracy: 18.85%\n",
            "Epoch: 43, Step: 287/655, Loss: 2.208300, Accuracy: 18.86%\n",
            "Epoch: 43, Step: 288/655, Loss: 2.208537, Accuracy: 18.84%\n",
            "Epoch: 43, Step: 289/655, Loss: 2.208936, Accuracy: 18.85%\n",
            "Epoch: 43, Step: 290/655, Loss: 2.208794, Accuracy: 18.87%\n",
            "Epoch: 43, Step: 291/655, Loss: 2.209222, Accuracy: 18.84%\n",
            "Epoch: 43, Step: 292/655, Loss: 2.209126, Accuracy: 18.80%\n",
            "Epoch: 43, Step: 293/655, Loss: 2.208911, Accuracy: 18.79%\n",
            "Epoch: 43, Step: 294/655, Loss: 2.208791, Accuracy: 18.78%\n",
            "Epoch: 43, Step: 295/655, Loss: 2.209419, Accuracy: 18.77%\n",
            "Epoch: 43, Step: 296/655, Loss: 2.209496, Accuracy: 18.78%\n",
            "Epoch: 43, Step: 297/655, Loss: 2.209590, Accuracy: 18.77%\n",
            "Epoch: 43, Step: 298/655, Loss: 2.209681, Accuracy: 18.75%\n",
            "Epoch: 43, Step: 299/655, Loss: 2.209740, Accuracy: 18.76%\n",
            "Epoch: 43, Step: 300/655, Loss: 2.209714, Accuracy: 18.74%\n",
            "Epoch: 43, Step: 301/655, Loss: 2.209833, Accuracy: 18.72%\n",
            "Epoch: 43, Step: 302/655, Loss: 2.210019, Accuracy: 18.71%\n",
            "Epoch: 43, Step: 303/655, Loss: 2.210275, Accuracy: 18.71%\n",
            "Epoch: 43, Step: 304/655, Loss: 2.209883, Accuracy: 18.77%\n",
            "Epoch: 43, Step: 305/655, Loss: 2.210438, Accuracy: 18.74%\n",
            "Epoch: 43, Step: 306/655, Loss: 2.210209, Accuracy: 18.74%\n",
            "Epoch: 43, Step: 307/655, Loss: 2.210269, Accuracy: 18.75%\n",
            "Epoch: 43, Step: 308/655, Loss: 2.210236, Accuracy: 18.77%\n",
            "Epoch: 43, Step: 309/655, Loss: 2.210197, Accuracy: 18.79%\n",
            "Epoch: 43, Step: 310/655, Loss: 2.210011, Accuracy: 18.81%\n",
            "Epoch: 43, Step: 311/655, Loss: 2.209985, Accuracy: 18.83%\n",
            "Epoch: 43, Step: 312/655, Loss: 2.210115, Accuracy: 18.83%\n",
            "Epoch: 43, Step: 313/655, Loss: 2.210155, Accuracy: 18.84%\n",
            "Epoch: 43, Step: 314/655, Loss: 2.209968, Accuracy: 18.85%\n",
            "Epoch: 43, Step: 315/655, Loss: 2.210234, Accuracy: 18.83%\n",
            "Epoch: 43, Step: 316/655, Loss: 2.210403, Accuracy: 18.79%\n",
            "Epoch: 43, Step: 317/655, Loss: 2.210913, Accuracy: 18.78%\n",
            "Epoch: 43, Step: 318/655, Loss: 2.210257, Accuracy: 18.82%\n",
            "Epoch: 43, Step: 319/655, Loss: 2.210014, Accuracy: 18.83%\n",
            "Epoch: 43, Step: 320/655, Loss: 2.210444, Accuracy: 18.80%\n",
            "Epoch: 43, Step: 321/655, Loss: 2.210899, Accuracy: 18.76%\n",
            "Epoch: 43, Step: 322/655, Loss: 2.211372, Accuracy: 18.73%\n",
            "Epoch: 43, Step: 323/655, Loss: 2.211429, Accuracy: 18.71%\n",
            "Epoch: 43, Step: 324/655, Loss: 2.211304, Accuracy: 18.73%\n",
            "Epoch: 43, Step: 325/655, Loss: 2.211196, Accuracy: 18.74%\n",
            "Epoch: 43, Step: 326/655, Loss: 2.211440, Accuracy: 18.74%\n",
            "Epoch: 43, Step: 327/655, Loss: 2.211221, Accuracy: 18.76%\n",
            "Epoch: 43, Step: 328/655, Loss: 2.211231, Accuracy: 18.74%\n",
            "Epoch: 43, Step: 329/655, Loss: 2.211123, Accuracy: 18.71%\n",
            "Epoch: 43, Step: 330/655, Loss: 2.211012, Accuracy: 18.71%\n",
            "Epoch: 43, Step: 331/655, Loss: 2.210563, Accuracy: 18.71%\n",
            "Epoch: 43, Step: 332/655, Loss: 2.210282, Accuracy: 18.69%\n",
            "Epoch: 43, Step: 333/655, Loss: 2.210458, Accuracy: 18.70%\n",
            "Epoch: 43, Step: 334/655, Loss: 2.210485, Accuracy: 18.70%\n",
            "Epoch: 43, Step: 335/655, Loss: 2.210349, Accuracy: 18.68%\n",
            "Epoch: 43, Step: 336/655, Loss: 2.210485, Accuracy: 18.67%\n",
            "Epoch: 43, Step: 337/655, Loss: 2.210784, Accuracy: 18.66%\n",
            "Epoch: 43, Step: 338/655, Loss: 2.210419, Accuracy: 18.69%\n",
            "Epoch: 43, Step: 339/655, Loss: 2.210846, Accuracy: 18.68%\n",
            "Epoch: 43, Step: 340/655, Loss: 2.211106, Accuracy: 18.66%\n",
            "Epoch: 43, Step: 341/655, Loss: 2.210916, Accuracy: 18.67%\n",
            "Epoch: 43, Step: 342/655, Loss: 2.210904, Accuracy: 18.64%\n",
            "Epoch: 43, Step: 343/655, Loss: 2.211032, Accuracy: 18.62%\n",
            "Epoch: 43, Step: 344/655, Loss: 2.211221, Accuracy: 18.63%\n",
            "Epoch: 43, Step: 345/655, Loss: 2.210884, Accuracy: 18.67%\n",
            "Epoch: 43, Step: 346/655, Loss: 2.210575, Accuracy: 18.69%\n",
            "Epoch: 43, Step: 347/655, Loss: 2.210489, Accuracy: 18.66%\n",
            "Epoch: 43, Step: 348/655, Loss: 2.210570, Accuracy: 18.64%\n",
            "Epoch: 43, Step: 349/655, Loss: 2.210515, Accuracy: 18.63%\n",
            "Epoch: 43, Step: 350/655, Loss: 2.210397, Accuracy: 18.64%\n",
            "Epoch: 43, Step: 351/655, Loss: 2.210134, Accuracy: 18.65%\n",
            "Epoch: 43, Step: 352/655, Loss: 2.209693, Accuracy: 18.68%\n",
            "Epoch: 43, Step: 353/655, Loss: 2.209414, Accuracy: 18.66%\n",
            "Epoch: 43, Step: 354/655, Loss: 2.208940, Accuracy: 18.66%\n",
            "Epoch: 43, Step: 355/655, Loss: 2.209242, Accuracy: 18.64%\n",
            "Epoch: 43, Step: 356/655, Loss: 2.209040, Accuracy: 18.66%\n",
            "Epoch: 43, Step: 357/655, Loss: 2.208769, Accuracy: 18.67%\n",
            "Epoch: 43, Step: 358/655, Loss: 2.208672, Accuracy: 18.67%\n",
            "Epoch: 43, Step: 359/655, Loss: 2.208687, Accuracy: 18.67%\n",
            "Epoch: 43, Step: 360/655, Loss: 2.208943, Accuracy: 18.65%\n",
            "Epoch: 43, Step: 361/655, Loss: 2.209278, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 362/655, Loss: 2.208961, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 363/655, Loss: 2.208886, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 364/655, Loss: 2.208932, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 365/655, Loss: 2.208801, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 366/655, Loss: 2.209271, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 367/655, Loss: 2.208901, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 368/655, Loss: 2.209225, Accuracy: 18.54%\n",
            "Epoch: 43, Step: 369/655, Loss: 2.209257, Accuracy: 18.52%\n",
            "Epoch: 43, Step: 370/655, Loss: 2.209238, Accuracy: 18.52%\n",
            "Epoch: 43, Step: 371/655, Loss: 2.209082, Accuracy: 18.52%\n",
            "Epoch: 43, Step: 372/655, Loss: 2.209115, Accuracy: 18.51%\n",
            "Epoch: 43, Step: 373/655, Loss: 2.209001, Accuracy: 18.51%\n",
            "Epoch: 43, Step: 374/655, Loss: 2.209161, Accuracy: 18.48%\n",
            "Epoch: 43, Step: 375/655, Loss: 2.208899, Accuracy: 18.51%\n",
            "Epoch: 43, Step: 376/655, Loss: 2.208727, Accuracy: 18.51%\n",
            "Epoch: 43, Step: 377/655, Loss: 2.208765, Accuracy: 18.50%\n",
            "Epoch: 43, Step: 378/655, Loss: 2.208627, Accuracy: 18.51%\n",
            "Epoch: 43, Step: 379/655, Loss: 2.208557, Accuracy: 18.54%\n",
            "Epoch: 43, Step: 380/655, Loss: 2.208696, Accuracy: 18.51%\n",
            "Epoch: 43, Step: 381/655, Loss: 2.209038, Accuracy: 18.49%\n",
            "Epoch: 43, Step: 382/655, Loss: 2.209162, Accuracy: 18.49%\n",
            "Epoch: 43, Step: 383/655, Loss: 2.209030, Accuracy: 18.49%\n",
            "Epoch: 43, Step: 384/655, Loss: 2.208787, Accuracy: 18.50%\n",
            "Epoch: 43, Step: 385/655, Loss: 2.208939, Accuracy: 18.48%\n",
            "Epoch: 43, Step: 386/655, Loss: 2.209032, Accuracy: 18.45%\n",
            "Epoch: 43, Step: 387/655, Loss: 2.209020, Accuracy: 18.44%\n",
            "Epoch: 43, Step: 388/655, Loss: 2.208864, Accuracy: 18.44%\n",
            "Epoch: 43, Step: 389/655, Loss: 2.208926, Accuracy: 18.45%\n",
            "Epoch: 43, Step: 390/655, Loss: 2.208801, Accuracy: 18.46%\n",
            "Epoch: 43, Step: 391/655, Loss: 2.209201, Accuracy: 18.44%\n",
            "Epoch: 43, Step: 392/655, Loss: 2.209359, Accuracy: 18.43%\n",
            "Epoch: 43, Step: 393/655, Loss: 2.209386, Accuracy: 18.44%\n",
            "Epoch: 43, Step: 394/655, Loss: 2.209345, Accuracy: 18.45%\n",
            "Epoch: 43, Step: 395/655, Loss: 2.209500, Accuracy: 18.44%\n",
            "Epoch: 43, Step: 396/655, Loss: 2.209468, Accuracy: 18.43%\n",
            "Epoch: 43, Step: 397/655, Loss: 2.209349, Accuracy: 18.47%\n",
            "Epoch: 43, Step: 398/655, Loss: 2.209172, Accuracy: 18.45%\n",
            "Epoch: 43, Step: 399/655, Loss: 2.209053, Accuracy: 18.48%\n",
            "Epoch: 43, Step: 400/655, Loss: 2.209038, Accuracy: 18.48%\n",
            "Epoch: 43, Step: 401/655, Loss: 2.208916, Accuracy: 18.49%\n",
            "Epoch: 43, Step: 402/655, Loss: 2.208929, Accuracy: 18.49%\n",
            "Epoch: 43, Step: 403/655, Loss: 2.209169, Accuracy: 18.47%\n",
            "Epoch: 43, Step: 404/655, Loss: 2.209032, Accuracy: 18.47%\n",
            "Epoch: 43, Step: 405/655, Loss: 2.208905, Accuracy: 18.48%\n",
            "Epoch: 43, Step: 406/655, Loss: 2.209164, Accuracy: 18.46%\n",
            "Epoch: 43, Step: 407/655, Loss: 2.209208, Accuracy: 18.46%\n",
            "Epoch: 43, Step: 408/655, Loss: 2.209421, Accuracy: 18.45%\n",
            "Epoch: 43, Step: 409/655, Loss: 2.209389, Accuracy: 18.44%\n",
            "Epoch: 43, Step: 410/655, Loss: 2.209482, Accuracy: 18.42%\n",
            "Epoch: 43, Step: 411/655, Loss: 2.209324, Accuracy: 18.42%\n",
            "Epoch: 43, Step: 412/655, Loss: 2.209277, Accuracy: 18.42%\n",
            "Epoch: 43, Step: 413/655, Loss: 2.209242, Accuracy: 18.42%\n",
            "Epoch: 43, Step: 414/655, Loss: 2.208959, Accuracy: 18.45%\n",
            "Epoch: 43, Step: 415/655, Loss: 2.208866, Accuracy: 18.43%\n",
            "Epoch: 43, Step: 416/655, Loss: 2.209185, Accuracy: 18.43%\n",
            "Epoch: 43, Step: 417/655, Loss: 2.209172, Accuracy: 18.42%\n",
            "Epoch: 43, Step: 418/655, Loss: 2.208962, Accuracy: 18.45%\n",
            "Epoch: 43, Step: 419/655, Loss: 2.208903, Accuracy: 18.47%\n",
            "Epoch: 43, Step: 420/655, Loss: 2.208656, Accuracy: 18.49%\n",
            "Epoch: 43, Step: 421/655, Loss: 2.208451, Accuracy: 18.51%\n",
            "Epoch: 43, Step: 422/655, Loss: 2.208290, Accuracy: 18.52%\n",
            "Epoch: 43, Step: 423/655, Loss: 2.208486, Accuracy: 18.51%\n",
            "Epoch: 43, Step: 424/655, Loss: 2.208004, Accuracy: 18.51%\n",
            "Epoch: 43, Step: 425/655, Loss: 2.207822, Accuracy: 18.50%\n",
            "Epoch: 43, Step: 426/655, Loss: 2.207827, Accuracy: 18.49%\n",
            "Epoch: 43, Step: 427/655, Loss: 2.207825, Accuracy: 18.48%\n",
            "Epoch: 43, Step: 428/655, Loss: 2.207881, Accuracy: 18.47%\n",
            "Epoch: 43, Step: 429/655, Loss: 2.207847, Accuracy: 18.48%\n",
            "Epoch: 43, Step: 430/655, Loss: 2.207696, Accuracy: 18.47%\n",
            "Epoch: 43, Step: 431/655, Loss: 2.207760, Accuracy: 18.49%\n",
            "Epoch: 43, Step: 432/655, Loss: 2.207691, Accuracy: 18.51%\n",
            "Epoch: 43, Step: 433/655, Loss: 2.207405, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 434/655, Loss: 2.207482, Accuracy: 18.55%\n",
            "Epoch: 43, Step: 435/655, Loss: 2.207148, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 436/655, Loss: 2.206868, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 437/655, Loss: 2.206976, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 438/655, Loss: 2.206735, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 439/655, Loss: 2.206892, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 440/655, Loss: 2.206951, Accuracy: 18.62%\n",
            "Epoch: 43, Step: 441/655, Loss: 2.207104, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 442/655, Loss: 2.207134, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 443/655, Loss: 2.207129, Accuracy: 18.62%\n",
            "Epoch: 43, Step: 444/655, Loss: 2.207257, Accuracy: 18.62%\n",
            "Epoch: 43, Step: 445/655, Loss: 2.207336, Accuracy: 18.62%\n",
            "Epoch: 43, Step: 446/655, Loss: 2.207117, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 447/655, Loss: 2.207244, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 448/655, Loss: 2.207183, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 449/655, Loss: 2.207328, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 450/655, Loss: 2.207467, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 451/655, Loss: 2.207710, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 452/655, Loss: 2.207584, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 453/655, Loss: 2.207600, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 454/655, Loss: 2.207179, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 455/655, Loss: 2.207545, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 456/655, Loss: 2.207561, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 457/655, Loss: 2.207447, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 458/655, Loss: 2.207590, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 459/655, Loss: 2.207767, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 460/655, Loss: 2.207895, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 461/655, Loss: 2.208210, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 462/655, Loss: 2.208351, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 463/655, Loss: 2.208645, Accuracy: 18.53%\n",
            "Epoch: 43, Step: 464/655, Loss: 2.209010, Accuracy: 18.51%\n",
            "Epoch: 43, Step: 465/655, Loss: 2.208944, Accuracy: 18.52%\n",
            "Epoch: 43, Step: 466/655, Loss: 2.208932, Accuracy: 18.52%\n",
            "Epoch: 43, Step: 467/655, Loss: 2.208808, Accuracy: 18.54%\n",
            "Epoch: 43, Step: 468/655, Loss: 2.208681, Accuracy: 18.55%\n",
            "Epoch: 43, Step: 469/655, Loss: 2.208770, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 470/655, Loss: 2.208493, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 471/655, Loss: 2.208592, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 472/655, Loss: 2.208672, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 473/655, Loss: 2.208716, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 474/655, Loss: 2.208854, Accuracy: 18.54%\n",
            "Epoch: 43, Step: 475/655, Loss: 2.208770, Accuracy: 18.53%\n",
            "Epoch: 43, Step: 476/655, Loss: 2.208840, Accuracy: 18.51%\n",
            "Epoch: 43, Step: 477/655, Loss: 2.208997, Accuracy: 18.51%\n",
            "Epoch: 43, Step: 478/655, Loss: 2.209059, Accuracy: 18.49%\n",
            "Epoch: 43, Step: 479/655, Loss: 2.208697, Accuracy: 18.50%\n",
            "Epoch: 43, Step: 480/655, Loss: 2.208556, Accuracy: 18.52%\n",
            "Epoch: 43, Step: 481/655, Loss: 2.208508, Accuracy: 18.53%\n",
            "Epoch: 43, Step: 482/655, Loss: 2.208443, Accuracy: 18.54%\n",
            "Epoch: 43, Step: 483/655, Loss: 2.208378, Accuracy: 18.54%\n",
            "Epoch: 43, Step: 484/655, Loss: 2.208412, Accuracy: 18.53%\n",
            "Epoch: 43, Step: 485/655, Loss: 2.208382, Accuracy: 18.52%\n",
            "Epoch: 43, Step: 486/655, Loss: 2.208538, Accuracy: 18.52%\n",
            "Epoch: 43, Step: 487/655, Loss: 2.208401, Accuracy: 18.53%\n",
            "Epoch: 43, Step: 488/655, Loss: 2.208030, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 489/655, Loss: 2.208178, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 490/655, Loss: 2.208488, Accuracy: 18.55%\n",
            "Epoch: 43, Step: 491/655, Loss: 2.208403, Accuracy: 18.54%\n",
            "Epoch: 43, Step: 492/655, Loss: 2.208331, Accuracy: 18.55%\n",
            "Epoch: 43, Step: 493/655, Loss: 2.208648, Accuracy: 18.52%\n",
            "Epoch: 43, Step: 494/655, Loss: 2.208713, Accuracy: 18.52%\n",
            "Epoch: 43, Step: 495/655, Loss: 2.208646, Accuracy: 18.55%\n",
            "Epoch: 43, Step: 496/655, Loss: 2.208676, Accuracy: 18.54%\n",
            "Epoch: 43, Step: 497/655, Loss: 2.208711, Accuracy: 18.54%\n",
            "Epoch: 43, Step: 498/655, Loss: 2.208792, Accuracy: 18.54%\n",
            "Epoch: 43, Step: 499/655, Loss: 2.208733, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 500/655, Loss: 2.208699, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 501/655, Loss: 2.208576, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 502/655, Loss: 2.208439, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 503/655, Loss: 2.208402, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 504/655, Loss: 2.208378, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 505/655, Loss: 2.208482, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 506/655, Loss: 2.208387, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 507/655, Loss: 2.208403, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 508/655, Loss: 2.208316, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 509/655, Loss: 2.208242, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 510/655, Loss: 2.208439, Accuracy: 18.55%\n",
            "Epoch: 43, Step: 511/655, Loss: 2.208549, Accuracy: 18.53%\n",
            "Epoch: 43, Step: 512/655, Loss: 2.208578, Accuracy: 18.53%\n",
            "Epoch: 43, Step: 513/655, Loss: 2.208609, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 514/655, Loss: 2.208486, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 515/655, Loss: 2.208160, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 516/655, Loss: 2.208299, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 517/655, Loss: 2.208253, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 518/655, Loss: 2.208403, Accuracy: 18.55%\n",
            "Epoch: 43, Step: 519/655, Loss: 2.208522, Accuracy: 18.53%\n",
            "Epoch: 43, Step: 520/655, Loss: 2.208336, Accuracy: 18.56%\n",
            "Epoch: 43, Step: 521/655, Loss: 2.208208, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 522/655, Loss: 2.208223, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 523/655, Loss: 2.208387, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 524/655, Loss: 2.208407, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 525/655, Loss: 2.208201, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 526/655, Loss: 2.208698, Accuracy: 18.54%\n",
            "Epoch: 43, Step: 527/655, Loss: 2.208554, Accuracy: 18.54%\n",
            "Epoch: 43, Step: 528/655, Loss: 2.208313, Accuracy: 18.55%\n",
            "Epoch: 43, Step: 529/655, Loss: 2.208048, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 530/655, Loss: 2.208234, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 531/655, Loss: 2.208458, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 532/655, Loss: 2.208773, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 533/655, Loss: 2.208901, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 534/655, Loss: 2.208992, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 535/655, Loss: 2.208981, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 536/655, Loss: 2.208894, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 537/655, Loss: 2.208802, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 538/655, Loss: 2.208771, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 539/655, Loss: 2.208573, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 540/655, Loss: 2.208627, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 541/655, Loss: 2.208609, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 542/655, Loss: 2.208437, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 543/655, Loss: 2.208217, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 544/655, Loss: 2.207922, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 545/655, Loss: 2.207876, Accuracy: 18.62%\n",
            "Epoch: 43, Step: 546/655, Loss: 2.207835, Accuracy: 18.62%\n",
            "Epoch: 43, Step: 547/655, Loss: 2.208027, Accuracy: 18.62%\n",
            "Epoch: 43, Step: 548/655, Loss: 2.208271, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 549/655, Loss: 2.208340, Accuracy: 18.64%\n",
            "Epoch: 43, Step: 550/655, Loss: 2.208234, Accuracy: 18.64%\n",
            "Epoch: 43, Step: 551/655, Loss: 2.208167, Accuracy: 18.64%\n",
            "Epoch: 43, Step: 552/655, Loss: 2.208045, Accuracy: 18.66%\n",
            "Epoch: 43, Step: 553/655, Loss: 2.207920, Accuracy: 18.67%\n",
            "Epoch: 43, Step: 554/655, Loss: 2.208055, Accuracy: 18.67%\n",
            "Epoch: 43, Step: 555/655, Loss: 2.208027, Accuracy: 18.68%\n",
            "Epoch: 43, Step: 556/655, Loss: 2.207933, Accuracy: 18.69%\n",
            "Epoch: 43, Step: 557/655, Loss: 2.208016, Accuracy: 18.69%\n",
            "Epoch: 43, Step: 558/655, Loss: 2.207869, Accuracy: 18.71%\n",
            "Epoch: 43, Step: 559/655, Loss: 2.207740, Accuracy: 18.72%\n",
            "Epoch: 43, Step: 560/655, Loss: 2.207711, Accuracy: 18.74%\n",
            "Epoch: 43, Step: 561/655, Loss: 2.207776, Accuracy: 18.73%\n",
            "Epoch: 43, Step: 562/655, Loss: 2.207868, Accuracy: 18.72%\n",
            "Epoch: 43, Step: 563/655, Loss: 2.207815, Accuracy: 18.72%\n",
            "Epoch: 43, Step: 564/655, Loss: 2.207886, Accuracy: 18.70%\n",
            "Epoch: 43, Step: 565/655, Loss: 2.207796, Accuracy: 18.70%\n",
            "Epoch: 43, Step: 566/655, Loss: 2.207690, Accuracy: 18.71%\n",
            "Epoch: 43, Step: 567/655, Loss: 2.207476, Accuracy: 18.73%\n",
            "Epoch: 43, Step: 568/655, Loss: 2.207462, Accuracy: 18.74%\n",
            "Epoch: 43, Step: 569/655, Loss: 2.207467, Accuracy: 18.73%\n",
            "Epoch: 43, Step: 570/655, Loss: 2.207393, Accuracy: 18.73%\n",
            "Epoch: 43, Step: 571/655, Loss: 2.207513, Accuracy: 18.72%\n",
            "Epoch: 43, Step: 572/655, Loss: 2.207327, Accuracy: 18.73%\n",
            "Epoch: 43, Step: 573/655, Loss: 2.207299, Accuracy: 18.73%\n",
            "Epoch: 43, Step: 574/655, Loss: 2.207293, Accuracy: 18.73%\n",
            "Epoch: 43, Step: 575/655, Loss: 2.207264, Accuracy: 18.72%\n",
            "Epoch: 43, Step: 576/655, Loss: 2.207330, Accuracy: 18.72%\n",
            "Epoch: 43, Step: 577/655, Loss: 2.207289, Accuracy: 18.72%\n",
            "Epoch: 43, Step: 578/655, Loss: 2.207094, Accuracy: 18.73%\n",
            "Epoch: 43, Step: 579/655, Loss: 2.207028, Accuracy: 18.72%\n",
            "Epoch: 43, Step: 580/655, Loss: 2.206909, Accuracy: 18.74%\n",
            "Epoch: 43, Step: 581/655, Loss: 2.207018, Accuracy: 18.72%\n",
            "Epoch: 43, Step: 582/655, Loss: 2.207015, Accuracy: 18.73%\n",
            "Epoch: 43, Step: 583/655, Loss: 2.207172, Accuracy: 18.72%\n",
            "Epoch: 43, Step: 584/655, Loss: 2.207047, Accuracy: 18.73%\n",
            "Epoch: 43, Step: 585/655, Loss: 2.207024, Accuracy: 18.74%\n",
            "Epoch: 43, Step: 586/655, Loss: 2.207168, Accuracy: 18.72%\n",
            "Epoch: 43, Step: 587/655, Loss: 2.207106, Accuracy: 18.70%\n",
            "Epoch: 43, Step: 588/655, Loss: 2.207279, Accuracy: 18.68%\n",
            "Epoch: 43, Step: 589/655, Loss: 2.207375, Accuracy: 18.67%\n",
            "Epoch: 43, Step: 590/655, Loss: 2.207543, Accuracy: 18.67%\n",
            "Epoch: 43, Step: 591/655, Loss: 2.207503, Accuracy: 18.67%\n",
            "Epoch: 43, Step: 592/655, Loss: 2.207547, Accuracy: 18.68%\n",
            "Epoch: 43, Step: 593/655, Loss: 2.207613, Accuracy: 18.68%\n",
            "Epoch: 43, Step: 594/655, Loss: 2.207593, Accuracy: 18.68%\n",
            "Epoch: 43, Step: 595/655, Loss: 2.207642, Accuracy: 18.67%\n",
            "Epoch: 43, Step: 596/655, Loss: 2.207731, Accuracy: 18.67%\n",
            "Epoch: 43, Step: 597/655, Loss: 2.207827, Accuracy: 18.66%\n",
            "Epoch: 43, Step: 598/655, Loss: 2.207949, Accuracy: 18.64%\n",
            "Epoch: 43, Step: 599/655, Loss: 2.207920, Accuracy: 18.65%\n",
            "Epoch: 43, Step: 600/655, Loss: 2.207966, Accuracy: 18.65%\n",
            "Epoch: 43, Step: 601/655, Loss: 2.207882, Accuracy: 18.65%\n",
            "Epoch: 43, Step: 602/655, Loss: 2.207797, Accuracy: 18.66%\n",
            "Epoch: 43, Step: 603/655, Loss: 2.207793, Accuracy: 18.67%\n",
            "Epoch: 43, Step: 604/655, Loss: 2.207935, Accuracy: 18.66%\n",
            "Epoch: 43, Step: 605/655, Loss: 2.207962, Accuracy: 18.66%\n",
            "Epoch: 43, Step: 606/655, Loss: 2.207975, Accuracy: 18.65%\n",
            "Epoch: 43, Step: 607/655, Loss: 2.208084, Accuracy: 18.63%\n",
            "Epoch: 43, Step: 608/655, Loss: 2.208077, Accuracy: 18.63%\n",
            "Epoch: 43, Step: 609/655, Loss: 2.207928, Accuracy: 18.63%\n",
            "Epoch: 43, Step: 610/655, Loss: 2.208044, Accuracy: 18.62%\n",
            "Epoch: 43, Step: 611/655, Loss: 2.207891, Accuracy: 18.63%\n",
            "Epoch: 43, Step: 612/655, Loss: 2.207922, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 613/655, Loss: 2.207952, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 614/655, Loss: 2.207872, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 615/655, Loss: 2.207945, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 616/655, Loss: 2.207821, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 617/655, Loss: 2.207868, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 618/655, Loss: 2.207816, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 619/655, Loss: 2.207748, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 620/655, Loss: 2.207876, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 621/655, Loss: 2.207999, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 622/655, Loss: 2.208057, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 623/655, Loss: 2.207916, Accuracy: 18.62%\n",
            "Epoch: 43, Step: 624/655, Loss: 2.207638, Accuracy: 18.63%\n",
            "Epoch: 43, Step: 625/655, Loss: 2.207699, Accuracy: 18.64%\n",
            "Epoch: 43, Step: 626/655, Loss: 2.207771, Accuracy: 18.62%\n",
            "Epoch: 43, Step: 627/655, Loss: 2.207622, Accuracy: 18.62%\n",
            "Epoch: 43, Step: 628/655, Loss: 2.207751, Accuracy: 18.63%\n",
            "Epoch: 43, Step: 629/655, Loss: 2.207691, Accuracy: 18.62%\n",
            "Epoch: 43, Step: 630/655, Loss: 2.207524, Accuracy: 18.63%\n",
            "Epoch: 43, Step: 631/655, Loss: 2.207591, Accuracy: 18.62%\n",
            "Epoch: 43, Step: 632/655, Loss: 2.207673, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 633/655, Loss: 2.207798, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 634/655, Loss: 2.207822, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 635/655, Loss: 2.207813, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 636/655, Loss: 2.207671, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 637/655, Loss: 2.207596, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 638/655, Loss: 2.207759, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 639/655, Loss: 2.207385, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 640/655, Loss: 2.207397, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 641/655, Loss: 2.207283, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 642/655, Loss: 2.207500, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 643/655, Loss: 2.207339, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 644/655, Loss: 2.207273, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 645/655, Loss: 2.207279, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 646/655, Loss: 2.207185, Accuracy: 18.59%\n",
            "Epoch: 43, Step: 647/655, Loss: 2.207006, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 648/655, Loss: 2.206777, Accuracy: 18.65%\n",
            "Epoch: 43, Step: 649/655, Loss: 2.206859, Accuracy: 18.63%\n",
            "Epoch: 43, Step: 650/655, Loss: 2.207123, Accuracy: 18.61%\n",
            "Epoch: 43, Step: 651/655, Loss: 2.207260, Accuracy: 18.60%\n",
            "Epoch: 43, Step: 652/655, Loss: 2.207364, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 653/655, Loss: 2.207177, Accuracy: 18.58%\n",
            "Epoch: 43, Step: 654/655, Loss: 2.207517, Accuracy: 18.57%\n",
            "Epoch: 43, Step: 655/655, Loss: 2.207326, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 1/655, Loss: 2.124905, Accuracy: 21.88%\n",
            "Epoch: 44, Step: 2/655, Loss: 2.263289, Accuracy: 14.06%\n",
            "Epoch: 44, Step: 3/655, Loss: 2.230132, Accuracy: 17.71%\n",
            "Epoch: 44, Step: 4/655, Loss: 2.251856, Accuracy: 17.19%\n",
            "Epoch: 44, Step: 5/655, Loss: 2.272399, Accuracy: 16.25%\n",
            "Epoch: 44, Step: 6/655, Loss: 2.227325, Accuracy: 18.23%\n",
            "Epoch: 44, Step: 7/655, Loss: 2.214838, Accuracy: 18.30%\n",
            "Epoch: 44, Step: 8/655, Loss: 2.209635, Accuracy: 18.36%\n",
            "Epoch: 44, Step: 9/655, Loss: 2.228868, Accuracy: 17.71%\n",
            "Epoch: 44, Step: 10/655, Loss: 2.231581, Accuracy: 17.19%\n",
            "Epoch: 44, Step: 11/655, Loss: 2.226564, Accuracy: 16.76%\n",
            "Epoch: 44, Step: 12/655, Loss: 2.229937, Accuracy: 16.41%\n",
            "Epoch: 44, Step: 13/655, Loss: 2.225911, Accuracy: 16.11%\n",
            "Epoch: 44, Step: 14/655, Loss: 2.223105, Accuracy: 16.07%\n",
            "Epoch: 44, Step: 15/655, Loss: 2.225652, Accuracy: 15.83%\n",
            "Epoch: 44, Step: 16/655, Loss: 2.218969, Accuracy: 16.02%\n",
            "Epoch: 44, Step: 17/655, Loss: 2.225572, Accuracy: 15.81%\n",
            "Epoch: 44, Step: 18/655, Loss: 2.223950, Accuracy: 15.80%\n",
            "Epoch: 44, Step: 19/655, Loss: 2.215207, Accuracy: 16.12%\n",
            "Epoch: 44, Step: 20/655, Loss: 2.216076, Accuracy: 15.62%\n",
            "Epoch: 44, Step: 21/655, Loss: 2.216104, Accuracy: 16.07%\n",
            "Epoch: 44, Step: 22/655, Loss: 2.213412, Accuracy: 16.48%\n",
            "Epoch: 44, Step: 23/655, Loss: 2.213978, Accuracy: 16.71%\n",
            "Epoch: 44, Step: 24/655, Loss: 2.208439, Accuracy: 16.54%\n",
            "Epoch: 44, Step: 25/655, Loss: 2.200667, Accuracy: 17.00%\n",
            "Epoch: 44, Step: 26/655, Loss: 2.198740, Accuracy: 17.31%\n",
            "Epoch: 44, Step: 27/655, Loss: 2.193521, Accuracy: 17.71%\n",
            "Epoch: 44, Step: 28/655, Loss: 2.199562, Accuracy: 17.63%\n",
            "Epoch: 44, Step: 29/655, Loss: 2.193498, Accuracy: 17.67%\n",
            "Epoch: 44, Step: 30/655, Loss: 2.198201, Accuracy: 17.50%\n",
            "Epoch: 44, Step: 31/655, Loss: 2.198346, Accuracy: 17.44%\n",
            "Epoch: 44, Step: 32/655, Loss: 2.197168, Accuracy: 17.77%\n",
            "Epoch: 44, Step: 33/655, Loss: 2.198167, Accuracy: 17.71%\n",
            "Epoch: 44, Step: 34/655, Loss: 2.199215, Accuracy: 17.65%\n",
            "Epoch: 44, Step: 35/655, Loss: 2.194984, Accuracy: 17.95%\n",
            "Epoch: 44, Step: 36/655, Loss: 2.192826, Accuracy: 18.06%\n",
            "Epoch: 44, Step: 37/655, Loss: 2.193175, Accuracy: 18.07%\n",
            "Epoch: 44, Step: 38/655, Loss: 2.196070, Accuracy: 18.09%\n",
            "Epoch: 44, Step: 39/655, Loss: 2.193452, Accuracy: 18.43%\n",
            "Epoch: 44, Step: 40/655, Loss: 2.192918, Accuracy: 18.44%\n",
            "Epoch: 44, Step: 41/655, Loss: 2.191358, Accuracy: 18.52%\n",
            "Epoch: 44, Step: 42/655, Loss: 2.190664, Accuracy: 18.68%\n",
            "Epoch: 44, Step: 43/655, Loss: 2.189887, Accuracy: 18.82%\n",
            "Epoch: 44, Step: 44/655, Loss: 2.188949, Accuracy: 19.03%\n",
            "Epoch: 44, Step: 45/655, Loss: 2.189757, Accuracy: 19.10%\n",
            "Epoch: 44, Step: 46/655, Loss: 2.191162, Accuracy: 19.09%\n",
            "Epoch: 44, Step: 47/655, Loss: 2.189155, Accuracy: 19.15%\n",
            "Epoch: 44, Step: 48/655, Loss: 2.189900, Accuracy: 19.08%\n",
            "Epoch: 44, Step: 49/655, Loss: 2.190818, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 50/655, Loss: 2.191186, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 51/655, Loss: 2.191553, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 52/655, Loss: 2.188725, Accuracy: 18.69%\n",
            "Epoch: 44, Step: 53/655, Loss: 2.188218, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 54/655, Loss: 2.187319, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 55/655, Loss: 2.189301, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 56/655, Loss: 2.190783, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 57/655, Loss: 2.189518, Accuracy: 18.80%\n",
            "Epoch: 44, Step: 58/655, Loss: 2.190730, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 59/655, Loss: 2.191287, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 60/655, Loss: 2.190363, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 61/655, Loss: 2.190292, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 62/655, Loss: 2.191711, Accuracy: 18.50%\n",
            "Epoch: 44, Step: 63/655, Loss: 2.191836, Accuracy: 18.35%\n",
            "Epoch: 44, Step: 64/655, Loss: 2.192616, Accuracy: 18.26%\n",
            "Epoch: 44, Step: 65/655, Loss: 2.194027, Accuracy: 18.17%\n",
            "Epoch: 44, Step: 66/655, Loss: 2.194637, Accuracy: 18.09%\n",
            "Epoch: 44, Step: 67/655, Loss: 2.195318, Accuracy: 18.14%\n",
            "Epoch: 44, Step: 68/655, Loss: 2.196437, Accuracy: 18.15%\n",
            "Epoch: 44, Step: 69/655, Loss: 2.195695, Accuracy: 18.39%\n",
            "Epoch: 44, Step: 70/655, Loss: 2.197131, Accuracy: 18.26%\n",
            "Epoch: 44, Step: 71/655, Loss: 2.195691, Accuracy: 18.44%\n",
            "Epoch: 44, Step: 72/655, Loss: 2.195200, Accuracy: 18.45%\n",
            "Epoch: 44, Step: 73/655, Loss: 2.194059, Accuracy: 18.36%\n",
            "Epoch: 44, Step: 74/655, Loss: 2.193654, Accuracy: 18.29%\n",
            "Epoch: 44, Step: 75/655, Loss: 2.193450, Accuracy: 18.25%\n",
            "Epoch: 44, Step: 76/655, Loss: 2.193178, Accuracy: 18.22%\n",
            "Epoch: 44, Step: 77/655, Loss: 2.193319, Accuracy: 18.22%\n",
            "Epoch: 44, Step: 78/655, Loss: 2.192098, Accuracy: 18.39%\n",
            "Epoch: 44, Step: 79/655, Loss: 2.192431, Accuracy: 18.31%\n",
            "Epoch: 44, Step: 80/655, Loss: 2.193513, Accuracy: 18.40%\n",
            "Epoch: 44, Step: 81/655, Loss: 2.194298, Accuracy: 18.36%\n",
            "Epoch: 44, Step: 82/655, Loss: 2.195848, Accuracy: 18.25%\n",
            "Epoch: 44, Step: 83/655, Loss: 2.197199, Accuracy: 18.22%\n",
            "Epoch: 44, Step: 84/655, Loss: 2.197348, Accuracy: 18.23%\n",
            "Epoch: 44, Step: 85/655, Loss: 2.199117, Accuracy: 18.24%\n",
            "Epoch: 44, Step: 86/655, Loss: 2.198255, Accuracy: 18.42%\n",
            "Epoch: 44, Step: 87/655, Loss: 2.197023, Accuracy: 18.46%\n",
            "Epoch: 44, Step: 88/655, Loss: 2.196646, Accuracy: 18.54%\n",
            "Epoch: 44, Step: 89/655, Loss: 2.195815, Accuracy: 18.68%\n",
            "Epoch: 44, Step: 90/655, Loss: 2.195102, Accuracy: 18.68%\n",
            "Epoch: 44, Step: 91/655, Loss: 2.194803, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 92/655, Loss: 2.195616, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 93/655, Loss: 2.195865, Accuracy: 18.68%\n",
            "Epoch: 44, Step: 94/655, Loss: 2.196514, Accuracy: 18.68%\n",
            "Epoch: 44, Step: 95/655, Loss: 2.196337, Accuracy: 18.68%\n",
            "Epoch: 44, Step: 96/655, Loss: 2.197285, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 97/655, Loss: 2.197382, Accuracy: 18.69%\n",
            "Epoch: 44, Step: 98/655, Loss: 2.196119, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 99/655, Loss: 2.197584, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 100/655, Loss: 2.198111, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 101/655, Loss: 2.197320, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 102/655, Loss: 2.197348, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 103/655, Loss: 2.198298, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 104/655, Loss: 2.198432, Accuracy: 18.69%\n",
            "Epoch: 44, Step: 105/655, Loss: 2.196858, Accuracy: 18.69%\n",
            "Epoch: 44, Step: 106/655, Loss: 2.197204, Accuracy: 18.69%\n",
            "Epoch: 44, Step: 107/655, Loss: 2.196860, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 108/655, Loss: 2.197039, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 109/655, Loss: 2.196826, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 110/655, Loss: 2.196804, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 111/655, Loss: 2.196394, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 112/655, Loss: 2.196260, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 113/655, Loss: 2.195546, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 114/655, Loss: 2.194124, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 115/655, Loss: 2.194543, Accuracy: 18.78%\n",
            "Epoch: 44, Step: 116/655, Loss: 2.193444, Accuracy: 18.86%\n",
            "Epoch: 44, Step: 117/655, Loss: 2.192220, Accuracy: 18.88%\n",
            "Epoch: 44, Step: 118/655, Loss: 2.192110, Accuracy: 18.88%\n",
            "Epoch: 44, Step: 119/655, Loss: 2.193385, Accuracy: 18.78%\n",
            "Epoch: 44, Step: 120/655, Loss: 2.193089, Accuracy: 18.85%\n",
            "Epoch: 44, Step: 121/655, Loss: 2.192929, Accuracy: 18.78%\n",
            "Epoch: 44, Step: 122/655, Loss: 2.193223, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 123/655, Loss: 2.192675, Accuracy: 18.70%\n",
            "Epoch: 44, Step: 124/655, Loss: 2.193076, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 125/655, Loss: 2.193988, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 126/655, Loss: 2.194033, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 127/655, Loss: 2.194915, Accuracy: 18.53%\n",
            "Epoch: 44, Step: 128/655, Loss: 2.194345, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 129/655, Loss: 2.195133, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 130/655, Loss: 2.194147, Accuracy: 18.68%\n",
            "Epoch: 44, Step: 131/655, Loss: 2.194141, Accuracy: 18.70%\n",
            "Epoch: 44, Step: 132/655, Loss: 2.193105, Accuracy: 18.77%\n",
            "Epoch: 44, Step: 133/655, Loss: 2.193847, Accuracy: 18.77%\n",
            "Epoch: 44, Step: 134/655, Loss: 2.194431, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 135/655, Loss: 2.194973, Accuracy: 18.70%\n",
            "Epoch: 44, Step: 136/655, Loss: 2.194459, Accuracy: 18.80%\n",
            "Epoch: 44, Step: 137/655, Loss: 2.194725, Accuracy: 18.82%\n",
            "Epoch: 44, Step: 138/655, Loss: 2.194940, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 139/655, Loss: 2.194255, Accuracy: 18.84%\n",
            "Epoch: 44, Step: 140/655, Loss: 2.194228, Accuracy: 18.84%\n",
            "Epoch: 44, Step: 141/655, Loss: 2.194286, Accuracy: 18.84%\n",
            "Epoch: 44, Step: 142/655, Loss: 2.194242, Accuracy: 18.86%\n",
            "Epoch: 44, Step: 143/655, Loss: 2.194502, Accuracy: 18.84%\n",
            "Epoch: 44, Step: 144/655, Loss: 2.194360, Accuracy: 18.90%\n",
            "Epoch: 44, Step: 145/655, Loss: 2.195466, Accuracy: 18.84%\n",
            "Epoch: 44, Step: 146/655, Loss: 2.196256, Accuracy: 18.81%\n",
            "Epoch: 44, Step: 147/655, Loss: 2.196629, Accuracy: 18.81%\n",
            "Epoch: 44, Step: 148/655, Loss: 2.196701, Accuracy: 18.79%\n",
            "Epoch: 44, Step: 149/655, Loss: 2.196927, Accuracy: 18.81%\n",
            "Epoch: 44, Step: 150/655, Loss: 2.196525, Accuracy: 18.83%\n",
            "Epoch: 44, Step: 151/655, Loss: 2.197288, Accuracy: 18.79%\n",
            "Epoch: 44, Step: 152/655, Loss: 2.197741, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 153/655, Loss: 2.197816, Accuracy: 18.77%\n",
            "Epoch: 44, Step: 154/655, Loss: 2.197803, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 155/655, Loss: 2.197281, Accuracy: 18.85%\n",
            "Epoch: 44, Step: 156/655, Loss: 2.197188, Accuracy: 18.85%\n",
            "Epoch: 44, Step: 157/655, Loss: 2.197683, Accuracy: 18.83%\n",
            "Epoch: 44, Step: 158/655, Loss: 2.197881, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 159/655, Loss: 2.197548, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 160/655, Loss: 2.197656, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 161/655, Loss: 2.197388, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 162/655, Loss: 2.198010, Accuracy: 18.69%\n",
            "Epoch: 44, Step: 163/655, Loss: 2.198679, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 164/655, Loss: 2.197495, Accuracy: 18.77%\n",
            "Epoch: 44, Step: 165/655, Loss: 2.197589, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 166/655, Loss: 2.197969, Accuracy: 18.69%\n",
            "Epoch: 44, Step: 167/655, Loss: 2.197766, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 168/655, Loss: 2.197985, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 169/655, Loss: 2.197637, Accuracy: 18.81%\n",
            "Epoch: 44, Step: 170/655, Loss: 2.197811, Accuracy: 18.81%\n",
            "Epoch: 44, Step: 171/655, Loss: 2.198224, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 172/655, Loss: 2.197686, Accuracy: 18.77%\n",
            "Epoch: 44, Step: 173/655, Loss: 2.197979, Accuracy: 18.79%\n",
            "Epoch: 44, Step: 174/655, Loss: 2.198182, Accuracy: 18.77%\n",
            "Epoch: 44, Step: 175/655, Loss: 2.198019, Accuracy: 18.79%\n",
            "Epoch: 44, Step: 176/655, Loss: 2.198796, Accuracy: 18.77%\n",
            "Epoch: 44, Step: 177/655, Loss: 2.198781, Accuracy: 18.70%\n",
            "Epoch: 44, Step: 178/655, Loss: 2.198959, Accuracy: 18.68%\n",
            "Epoch: 44, Step: 179/655, Loss: 2.199273, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 180/655, Loss: 2.199458, Accuracy: 18.70%\n",
            "Epoch: 44, Step: 181/655, Loss: 2.200003, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 182/655, Loss: 2.199327, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 183/655, Loss: 2.200147, Accuracy: 18.73%\n",
            "Epoch: 44, Step: 184/655, Loss: 2.199805, Accuracy: 18.80%\n",
            "Epoch: 44, Step: 185/655, Loss: 2.200212, Accuracy: 18.80%\n",
            "Epoch: 44, Step: 186/655, Loss: 2.200668, Accuracy: 18.78%\n",
            "Epoch: 44, Step: 187/655, Loss: 2.201155, Accuracy: 18.73%\n",
            "Epoch: 44, Step: 188/655, Loss: 2.201428, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 189/655, Loss: 2.201193, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 190/655, Loss: 2.201841, Accuracy: 18.73%\n",
            "Epoch: 44, Step: 191/655, Loss: 2.201723, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 192/655, Loss: 2.202395, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 193/655, Loss: 2.201952, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 194/655, Loss: 2.201833, Accuracy: 18.73%\n",
            "Epoch: 44, Step: 195/655, Loss: 2.202065, Accuracy: 18.69%\n",
            "Epoch: 44, Step: 196/655, Loss: 2.202519, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 197/655, Loss: 2.202158, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 198/655, Loss: 2.202325, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 199/655, Loss: 2.202195, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 200/655, Loss: 2.202007, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 201/655, Loss: 2.202283, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 202/655, Loss: 2.202542, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 203/655, Loss: 2.203074, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 204/655, Loss: 2.204111, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 205/655, Loss: 2.204456, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 206/655, Loss: 2.204684, Accuracy: 18.52%\n",
            "Epoch: 44, Step: 207/655, Loss: 2.205679, Accuracy: 18.46%\n",
            "Epoch: 44, Step: 208/655, Loss: 2.205648, Accuracy: 18.51%\n",
            "Epoch: 44, Step: 209/655, Loss: 2.205588, Accuracy: 18.48%\n",
            "Epoch: 44, Step: 210/655, Loss: 2.206077, Accuracy: 18.47%\n",
            "Epoch: 44, Step: 211/655, Loss: 2.206317, Accuracy: 18.44%\n",
            "Epoch: 44, Step: 212/655, Loss: 2.205876, Accuracy: 18.47%\n",
            "Epoch: 44, Step: 213/655, Loss: 2.205696, Accuracy: 18.43%\n",
            "Epoch: 44, Step: 214/655, Loss: 2.205496, Accuracy: 18.43%\n",
            "Epoch: 44, Step: 215/655, Loss: 2.205539, Accuracy: 18.43%\n",
            "Epoch: 44, Step: 216/655, Loss: 2.205523, Accuracy: 18.37%\n",
            "Epoch: 44, Step: 217/655, Loss: 2.205874, Accuracy: 18.38%\n",
            "Epoch: 44, Step: 218/655, Loss: 2.206026, Accuracy: 18.39%\n",
            "Epoch: 44, Step: 219/655, Loss: 2.205709, Accuracy: 18.41%\n",
            "Epoch: 44, Step: 220/655, Loss: 2.205275, Accuracy: 18.42%\n",
            "Epoch: 44, Step: 221/655, Loss: 2.205024, Accuracy: 18.41%\n",
            "Epoch: 44, Step: 222/655, Loss: 2.204858, Accuracy: 18.40%\n",
            "Epoch: 44, Step: 223/655, Loss: 2.204986, Accuracy: 18.36%\n",
            "Epoch: 44, Step: 224/655, Loss: 2.205591, Accuracy: 18.33%\n",
            "Epoch: 44, Step: 225/655, Loss: 2.205703, Accuracy: 18.32%\n",
            "Epoch: 44, Step: 226/655, Loss: 2.205755, Accuracy: 18.31%\n",
            "Epoch: 44, Step: 227/655, Loss: 2.205565, Accuracy: 18.32%\n",
            "Epoch: 44, Step: 228/655, Loss: 2.205934, Accuracy: 18.33%\n",
            "Epoch: 44, Step: 229/655, Loss: 2.205989, Accuracy: 18.38%\n",
            "Epoch: 44, Step: 230/655, Loss: 2.205739, Accuracy: 18.41%\n",
            "Epoch: 44, Step: 231/655, Loss: 2.205768, Accuracy: 18.40%\n",
            "Epoch: 44, Step: 232/655, Loss: 2.205890, Accuracy: 18.40%\n",
            "Epoch: 44, Step: 233/655, Loss: 2.205957, Accuracy: 18.43%\n",
            "Epoch: 44, Step: 234/655, Loss: 2.205941, Accuracy: 18.46%\n",
            "Epoch: 44, Step: 235/655, Loss: 2.206200, Accuracy: 18.46%\n",
            "Epoch: 44, Step: 236/655, Loss: 2.205912, Accuracy: 18.50%\n",
            "Epoch: 44, Step: 237/655, Loss: 2.205656, Accuracy: 18.53%\n",
            "Epoch: 44, Step: 238/655, Loss: 2.205600, Accuracy: 18.53%\n",
            "Epoch: 44, Step: 239/655, Loss: 2.205183, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 240/655, Loss: 2.204985, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 241/655, Loss: 2.204743, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 242/655, Loss: 2.204446, Accuracy: 18.69%\n",
            "Epoch: 44, Step: 243/655, Loss: 2.204327, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 244/655, Loss: 2.204306, Accuracy: 18.69%\n",
            "Epoch: 44, Step: 245/655, Loss: 2.204658, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 246/655, Loss: 2.204906, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 247/655, Loss: 2.204887, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 248/655, Loss: 2.204981, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 249/655, Loss: 2.204930, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 250/655, Loss: 2.205149, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 251/655, Loss: 2.205312, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 252/655, Loss: 2.206063, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 253/655, Loss: 2.206012, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 254/655, Loss: 2.205894, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 255/655, Loss: 2.206134, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 256/655, Loss: 2.205956, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 257/655, Loss: 2.206092, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 258/655, Loss: 2.206301, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 259/655, Loss: 2.206377, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 260/655, Loss: 2.206282, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 261/655, Loss: 2.206345, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 262/655, Loss: 2.206364, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 263/655, Loss: 2.206415, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 264/655, Loss: 2.206180, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 265/655, Loss: 2.206296, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 266/655, Loss: 2.206369, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 267/655, Loss: 2.206544, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 268/655, Loss: 2.206366, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 269/655, Loss: 2.206903, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 270/655, Loss: 2.206891, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 271/655, Loss: 2.206858, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 272/655, Loss: 2.206935, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 273/655, Loss: 2.207407, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 274/655, Loss: 2.207459, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 275/655, Loss: 2.207616, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 276/655, Loss: 2.208068, Accuracy: 18.53%\n",
            "Epoch: 44, Step: 277/655, Loss: 2.208492, Accuracy: 18.54%\n",
            "Epoch: 44, Step: 278/655, Loss: 2.209313, Accuracy: 18.50%\n",
            "Epoch: 44, Step: 279/655, Loss: 2.209333, Accuracy: 18.48%\n",
            "Epoch: 44, Step: 280/655, Loss: 2.209306, Accuracy: 18.50%\n",
            "Epoch: 44, Step: 281/655, Loss: 2.209649, Accuracy: 18.51%\n",
            "Epoch: 44, Step: 282/655, Loss: 2.210049, Accuracy: 18.51%\n",
            "Epoch: 44, Step: 283/655, Loss: 2.210198, Accuracy: 18.52%\n",
            "Epoch: 44, Step: 284/655, Loss: 2.210555, Accuracy: 18.47%\n",
            "Epoch: 44, Step: 285/655, Loss: 2.210507, Accuracy: 18.50%\n",
            "Epoch: 44, Step: 286/655, Loss: 2.210492, Accuracy: 18.51%\n",
            "Epoch: 44, Step: 287/655, Loss: 2.210456, Accuracy: 18.52%\n",
            "Epoch: 44, Step: 288/655, Loss: 2.210315, Accuracy: 18.53%\n",
            "Epoch: 44, Step: 289/655, Loss: 2.210552, Accuracy: 18.50%\n",
            "Epoch: 44, Step: 290/655, Loss: 2.211075, Accuracy: 18.48%\n",
            "Epoch: 44, Step: 291/655, Loss: 2.211003, Accuracy: 18.47%\n",
            "Epoch: 44, Step: 292/655, Loss: 2.210451, Accuracy: 18.49%\n",
            "Epoch: 44, Step: 293/655, Loss: 2.210251, Accuracy: 18.50%\n",
            "Epoch: 44, Step: 294/655, Loss: 2.210887, Accuracy: 18.47%\n",
            "Epoch: 44, Step: 295/655, Loss: 2.210919, Accuracy: 18.44%\n",
            "Epoch: 44, Step: 296/655, Loss: 2.210717, Accuracy: 18.46%\n",
            "Epoch: 44, Step: 297/655, Loss: 2.210571, Accuracy: 18.48%\n",
            "Epoch: 44, Step: 298/655, Loss: 2.210567, Accuracy: 18.46%\n",
            "Epoch: 44, Step: 299/655, Loss: 2.210636, Accuracy: 18.42%\n",
            "Epoch: 44, Step: 300/655, Loss: 2.210427, Accuracy: 18.44%\n",
            "Epoch: 44, Step: 301/655, Loss: 2.210707, Accuracy: 18.44%\n",
            "Epoch: 44, Step: 302/655, Loss: 2.210725, Accuracy: 18.47%\n",
            "Epoch: 44, Step: 303/655, Loss: 2.211029, Accuracy: 18.45%\n",
            "Epoch: 44, Step: 304/655, Loss: 2.211053, Accuracy: 18.45%\n",
            "Epoch: 44, Step: 305/655, Loss: 2.211737, Accuracy: 18.42%\n",
            "Epoch: 44, Step: 306/655, Loss: 2.211739, Accuracy: 18.41%\n",
            "Epoch: 44, Step: 307/655, Loss: 2.212000, Accuracy: 18.40%\n",
            "Epoch: 44, Step: 308/655, Loss: 2.211810, Accuracy: 18.45%\n",
            "Epoch: 44, Step: 309/655, Loss: 2.211941, Accuracy: 18.46%\n",
            "Epoch: 44, Step: 310/655, Loss: 2.211897, Accuracy: 18.50%\n",
            "Epoch: 44, Step: 311/655, Loss: 2.211974, Accuracy: 18.51%\n",
            "Epoch: 44, Step: 312/655, Loss: 2.212166, Accuracy: 18.51%\n",
            "Epoch: 44, Step: 313/655, Loss: 2.212126, Accuracy: 18.52%\n",
            "Epoch: 44, Step: 314/655, Loss: 2.212412, Accuracy: 18.51%\n",
            "Epoch: 44, Step: 315/655, Loss: 2.212125, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 316/655, Loss: 2.212003, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 317/655, Loss: 2.212104, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 318/655, Loss: 2.212396, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 319/655, Loss: 2.212580, Accuracy: 18.53%\n",
            "Epoch: 44, Step: 320/655, Loss: 2.212564, Accuracy: 18.51%\n",
            "Epoch: 44, Step: 321/655, Loss: 2.212652, Accuracy: 18.50%\n",
            "Epoch: 44, Step: 322/655, Loss: 2.212553, Accuracy: 18.51%\n",
            "Epoch: 44, Step: 323/655, Loss: 2.212874, Accuracy: 18.47%\n",
            "Epoch: 44, Step: 324/655, Loss: 2.212450, Accuracy: 18.49%\n",
            "Epoch: 44, Step: 325/655, Loss: 2.211956, Accuracy: 18.52%\n",
            "Epoch: 44, Step: 326/655, Loss: 2.211841, Accuracy: 18.52%\n",
            "Epoch: 44, Step: 327/655, Loss: 2.211831, Accuracy: 18.49%\n",
            "Epoch: 44, Step: 328/655, Loss: 2.211818, Accuracy: 18.52%\n",
            "Epoch: 44, Step: 329/655, Loss: 2.211497, Accuracy: 18.53%\n",
            "Epoch: 44, Step: 330/655, Loss: 2.211254, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 331/655, Loss: 2.211079, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 332/655, Loss: 2.210927, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 333/655, Loss: 2.210962, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 334/655, Loss: 2.210951, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 335/655, Loss: 2.211130, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 336/655, Loss: 2.211030, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 337/655, Loss: 2.211121, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 338/655, Loss: 2.210797, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 339/655, Loss: 2.210684, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 340/655, Loss: 2.210511, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 341/655, Loss: 2.210350, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 342/655, Loss: 2.210562, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 343/655, Loss: 2.210303, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 344/655, Loss: 2.210358, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 345/655, Loss: 2.210294, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 346/655, Loss: 2.210319, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 347/655, Loss: 2.210298, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 348/655, Loss: 2.210427, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 349/655, Loss: 2.210598, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 350/655, Loss: 2.210268, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 351/655, Loss: 2.210304, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 352/655, Loss: 2.210604, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 353/655, Loss: 2.210538, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 354/655, Loss: 2.210120, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 355/655, Loss: 2.210408, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 356/655, Loss: 2.210437, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 357/655, Loss: 2.210635, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 358/655, Loss: 2.210653, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 359/655, Loss: 2.210393, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 360/655, Loss: 2.210435, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 361/655, Loss: 2.210054, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 362/655, Loss: 2.209864, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 363/655, Loss: 2.209736, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 364/655, Loss: 2.209863, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 365/655, Loss: 2.209590, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 366/655, Loss: 2.209806, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 367/655, Loss: 2.209959, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 368/655, Loss: 2.209916, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 369/655, Loss: 2.209915, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 370/655, Loss: 2.209568, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 371/655, Loss: 2.209271, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 372/655, Loss: 2.209548, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 373/655, Loss: 2.209541, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 374/655, Loss: 2.209437, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 375/655, Loss: 2.209281, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 376/655, Loss: 2.208653, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 377/655, Loss: 2.208722, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 378/655, Loss: 2.208652, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 379/655, Loss: 2.208446, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 380/655, Loss: 2.208510, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 381/655, Loss: 2.208314, Accuracy: 18.68%\n",
            "Epoch: 44, Step: 382/655, Loss: 2.208009, Accuracy: 18.73%\n",
            "Epoch: 44, Step: 383/655, Loss: 2.208414, Accuracy: 18.71%\n",
            "Epoch: 44, Step: 384/655, Loss: 2.208741, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 385/655, Loss: 2.209116, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 386/655, Loss: 2.209150, Accuracy: 18.68%\n",
            "Epoch: 44, Step: 387/655, Loss: 2.209436, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 388/655, Loss: 2.209616, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 389/655, Loss: 2.209190, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 390/655, Loss: 2.209366, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 391/655, Loss: 2.209842, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 392/655, Loss: 2.210119, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 393/655, Loss: 2.210072, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 394/655, Loss: 2.209995, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 395/655, Loss: 2.209875, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 396/655, Loss: 2.209779, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 397/655, Loss: 2.209370, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 398/655, Loss: 2.209101, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 399/655, Loss: 2.209216, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 400/655, Loss: 2.209194, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 401/655, Loss: 2.209098, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 402/655, Loss: 2.209160, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 403/655, Loss: 2.209387, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 404/655, Loss: 2.209148, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 405/655, Loss: 2.209188, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 406/655, Loss: 2.209106, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 407/655, Loss: 2.208777, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 408/655, Loss: 2.208831, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 409/655, Loss: 2.209177, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 410/655, Loss: 2.208781, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 411/655, Loss: 2.208872, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 412/655, Loss: 2.208630, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 413/655, Loss: 2.208852, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 414/655, Loss: 2.208744, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 415/655, Loss: 2.208353, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 416/655, Loss: 2.208319, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 417/655, Loss: 2.208281, Accuracy: 18.68%\n",
            "Epoch: 44, Step: 418/655, Loss: 2.207788, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 419/655, Loss: 2.207428, Accuracy: 18.76%\n",
            "Epoch: 44, Step: 420/655, Loss: 2.207399, Accuracy: 18.74%\n",
            "Epoch: 44, Step: 421/655, Loss: 2.207490, Accuracy: 18.73%\n",
            "Epoch: 44, Step: 422/655, Loss: 2.207392, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 423/655, Loss: 2.207311, Accuracy: 18.74%\n",
            "Epoch: 44, Step: 424/655, Loss: 2.207455, Accuracy: 18.71%\n",
            "Epoch: 44, Step: 425/655, Loss: 2.207510, Accuracy: 18.71%\n",
            "Epoch: 44, Step: 426/655, Loss: 2.207324, Accuracy: 18.71%\n",
            "Epoch: 44, Step: 427/655, Loss: 2.207183, Accuracy: 18.71%\n",
            "Epoch: 44, Step: 428/655, Loss: 2.207458, Accuracy: 18.70%\n",
            "Epoch: 44, Step: 429/655, Loss: 2.207546, Accuracy: 18.68%\n",
            "Epoch: 44, Step: 430/655, Loss: 2.207214, Accuracy: 18.71%\n",
            "Epoch: 44, Step: 431/655, Loss: 2.207136, Accuracy: 18.71%\n",
            "Epoch: 44, Step: 432/655, Loss: 2.207367, Accuracy: 18.71%\n",
            "Epoch: 44, Step: 433/655, Loss: 2.207593, Accuracy: 18.71%\n",
            "Epoch: 44, Step: 434/655, Loss: 2.207483, Accuracy: 18.70%\n",
            "Epoch: 44, Step: 435/655, Loss: 2.207205, Accuracy: 18.69%\n",
            "Epoch: 44, Step: 436/655, Loss: 2.207076, Accuracy: 18.69%\n",
            "Epoch: 44, Step: 437/655, Loss: 2.206886, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 438/655, Loss: 2.207128, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 439/655, Loss: 2.207066, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 440/655, Loss: 2.207051, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 441/655, Loss: 2.206907, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 442/655, Loss: 2.206992, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 443/655, Loss: 2.206752, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 444/655, Loss: 2.206895, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 445/655, Loss: 2.206747, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 446/655, Loss: 2.206738, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 447/655, Loss: 2.206682, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 448/655, Loss: 2.206735, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 449/655, Loss: 2.206561, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 450/655, Loss: 2.206549, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 451/655, Loss: 2.206533, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 452/655, Loss: 2.206566, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 453/655, Loss: 2.206558, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 454/655, Loss: 2.206809, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 455/655, Loss: 2.206785, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 456/655, Loss: 2.206632, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 457/655, Loss: 2.206293, Accuracy: 18.68%\n",
            "Epoch: 44, Step: 458/655, Loss: 2.206243, Accuracy: 18.70%\n",
            "Epoch: 44, Step: 459/655, Loss: 2.206037, Accuracy: 18.70%\n",
            "Epoch: 44, Step: 460/655, Loss: 2.205977, Accuracy: 18.73%\n",
            "Epoch: 44, Step: 461/655, Loss: 2.205829, Accuracy: 18.73%\n",
            "Epoch: 44, Step: 462/655, Loss: 2.206091, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 463/655, Loss: 2.206090, Accuracy: 18.70%\n",
            "Epoch: 44, Step: 464/655, Loss: 2.205971, Accuracy: 18.70%\n",
            "Epoch: 44, Step: 465/655, Loss: 2.205857, Accuracy: 18.70%\n",
            "Epoch: 44, Step: 466/655, Loss: 2.205846, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 467/655, Loss: 2.205727, Accuracy: 18.74%\n",
            "Epoch: 44, Step: 468/655, Loss: 2.205752, Accuracy: 18.73%\n",
            "Epoch: 44, Step: 469/655, Loss: 2.205729, Accuracy: 18.73%\n",
            "Epoch: 44, Step: 470/655, Loss: 2.205800, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 471/655, Loss: 2.205873, Accuracy: 18.73%\n",
            "Epoch: 44, Step: 472/655, Loss: 2.205706, Accuracy: 18.73%\n",
            "Epoch: 44, Step: 473/655, Loss: 2.205647, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 474/655, Loss: 2.205613, Accuracy: 18.75%\n",
            "Epoch: 44, Step: 475/655, Loss: 2.205786, Accuracy: 18.74%\n",
            "Epoch: 44, Step: 476/655, Loss: 2.206011, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 477/655, Loss: 2.206065, Accuracy: 18.74%\n",
            "Epoch: 44, Step: 478/655, Loss: 2.206098, Accuracy: 18.74%\n",
            "Epoch: 44, Step: 479/655, Loss: 2.206186, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 480/655, Loss: 2.206119, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 481/655, Loss: 2.206216, Accuracy: 18.71%\n",
            "Epoch: 44, Step: 482/655, Loss: 2.206237, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 483/655, Loss: 2.206161, Accuracy: 18.72%\n",
            "Epoch: 44, Step: 484/655, Loss: 2.206104, Accuracy: 18.71%\n",
            "Epoch: 44, Step: 485/655, Loss: 2.206238, Accuracy: 18.69%\n",
            "Epoch: 44, Step: 486/655, Loss: 2.205921, Accuracy: 18.70%\n",
            "Epoch: 44, Step: 487/655, Loss: 2.206039, Accuracy: 18.70%\n",
            "Epoch: 44, Step: 488/655, Loss: 2.206186, Accuracy: 18.69%\n",
            "Epoch: 44, Step: 489/655, Loss: 2.206218, Accuracy: 18.69%\n",
            "Epoch: 44, Step: 490/655, Loss: 2.206560, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 491/655, Loss: 2.206529, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 492/655, Loss: 2.206631, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 493/655, Loss: 2.206968, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 494/655, Loss: 2.206801, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 495/655, Loss: 2.206724, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 496/655, Loss: 2.206730, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 497/655, Loss: 2.206705, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 498/655, Loss: 2.206923, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 499/655, Loss: 2.207111, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 500/655, Loss: 2.207280, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 501/655, Loss: 2.207256, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 502/655, Loss: 2.207081, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 503/655, Loss: 2.207047, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 504/655, Loss: 2.206972, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 505/655, Loss: 2.206849, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 506/655, Loss: 2.206787, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 507/655, Loss: 2.206946, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 508/655, Loss: 2.206717, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 509/655, Loss: 2.206992, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 510/655, Loss: 2.207049, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 511/655, Loss: 2.207180, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 512/655, Loss: 2.207402, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 513/655, Loss: 2.207327, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 514/655, Loss: 2.207390, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 515/655, Loss: 2.207196, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 516/655, Loss: 2.207219, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 517/655, Loss: 2.207114, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 518/655, Loss: 2.207040, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 519/655, Loss: 2.206865, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 520/655, Loss: 2.206674, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 521/655, Loss: 2.206666, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 522/655, Loss: 2.206668, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 523/655, Loss: 2.206696, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 524/655, Loss: 2.206663, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 525/655, Loss: 2.206707, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 526/655, Loss: 2.206878, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 527/655, Loss: 2.206887, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 528/655, Loss: 2.206988, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 529/655, Loss: 2.206885, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 530/655, Loss: 2.206562, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 531/655, Loss: 2.206544, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 532/655, Loss: 2.206678, Accuracy: 18.66%\n",
            "Epoch: 44, Step: 533/655, Loss: 2.206569, Accuracy: 18.68%\n",
            "Epoch: 44, Step: 534/655, Loss: 2.206714, Accuracy: 18.67%\n",
            "Epoch: 44, Step: 535/655, Loss: 2.206789, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 536/655, Loss: 2.206673, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 537/655, Loss: 2.206733, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 538/655, Loss: 2.206669, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 539/655, Loss: 2.206668, Accuracy: 18.63%\n",
            "Epoch: 44, Step: 540/655, Loss: 2.206752, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 541/655, Loss: 2.206885, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 542/655, Loss: 2.206971, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 543/655, Loss: 2.206938, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 544/655, Loss: 2.206854, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 545/655, Loss: 2.206662, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 546/655, Loss: 2.206710, Accuracy: 18.65%\n",
            "Epoch: 44, Step: 547/655, Loss: 2.206763, Accuracy: 18.64%\n",
            "Epoch: 44, Step: 548/655, Loss: 2.206940, Accuracy: 18.62%\n",
            "Epoch: 44, Step: 549/655, Loss: 2.206969, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 550/655, Loss: 2.207232, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 551/655, Loss: 2.207051, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 552/655, Loss: 2.207145, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 553/655, Loss: 2.207174, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 554/655, Loss: 2.207326, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 555/655, Loss: 2.207380, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 556/655, Loss: 2.207417, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 557/655, Loss: 2.207320, Accuracy: 18.54%\n",
            "Epoch: 44, Step: 558/655, Loss: 2.207270, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 559/655, Loss: 2.207287, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 560/655, Loss: 2.207520, Accuracy: 18.54%\n",
            "Epoch: 44, Step: 561/655, Loss: 2.207354, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 562/655, Loss: 2.207535, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 563/655, Loss: 2.207485, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 564/655, Loss: 2.207701, Accuracy: 18.54%\n",
            "Epoch: 44, Step: 565/655, Loss: 2.207758, Accuracy: 18.54%\n",
            "Epoch: 44, Step: 566/655, Loss: 2.207851, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 567/655, Loss: 2.207800, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 568/655, Loss: 2.208008, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 569/655, Loss: 2.207975, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 570/655, Loss: 2.208271, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 571/655, Loss: 2.208194, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 572/655, Loss: 2.208139, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 573/655, Loss: 2.208088, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 574/655, Loss: 2.208157, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 575/655, Loss: 2.208098, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 576/655, Loss: 2.207860, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 577/655, Loss: 2.208031, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 578/655, Loss: 2.207961, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 579/655, Loss: 2.208148, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 580/655, Loss: 2.208183, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 581/655, Loss: 2.208247, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 582/655, Loss: 2.208419, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 583/655, Loss: 2.208430, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 584/655, Loss: 2.208318, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 585/655, Loss: 2.208322, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 586/655, Loss: 2.208495, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 587/655, Loss: 2.208398, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 588/655, Loss: 2.208590, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 589/655, Loss: 2.208455, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 590/655, Loss: 2.208323, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 591/655, Loss: 2.208476, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 592/655, Loss: 2.208588, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 593/655, Loss: 2.208498, Accuracy: 18.54%\n",
            "Epoch: 44, Step: 594/655, Loss: 2.208349, Accuracy: 18.54%\n",
            "Epoch: 44, Step: 595/655, Loss: 2.208328, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 596/655, Loss: 2.208333, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 597/655, Loss: 2.208474, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 598/655, Loss: 2.208517, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 599/655, Loss: 2.208658, Accuracy: 18.54%\n",
            "Epoch: 44, Step: 600/655, Loss: 2.208586, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 601/655, Loss: 2.208551, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 602/655, Loss: 2.208431, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 603/655, Loss: 2.208353, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 604/655, Loss: 2.208428, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 605/655, Loss: 2.208563, Accuracy: 18.55%\n",
            "Epoch: 44, Step: 606/655, Loss: 2.208540, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 607/655, Loss: 2.208648, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 608/655, Loss: 2.208891, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 609/655, Loss: 2.208651, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 610/655, Loss: 2.208649, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 611/655, Loss: 2.208834, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 612/655, Loss: 2.208880, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 613/655, Loss: 2.208719, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 614/655, Loss: 2.208754, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 615/655, Loss: 2.208705, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 616/655, Loss: 2.208583, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 617/655, Loss: 2.208631, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 618/655, Loss: 2.208627, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 619/655, Loss: 2.208606, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 620/655, Loss: 2.208501, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 621/655, Loss: 2.208920, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 622/655, Loss: 2.208989, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 623/655, Loss: 2.208902, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 624/655, Loss: 2.208701, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 625/655, Loss: 2.208768, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 626/655, Loss: 2.208662, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 627/655, Loss: 2.208709, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 628/655, Loss: 2.208602, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 629/655, Loss: 2.208623, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 630/655, Loss: 2.208658, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 631/655, Loss: 2.208529, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 632/655, Loss: 2.208483, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 633/655, Loss: 2.208271, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 634/655, Loss: 2.208419, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 635/655, Loss: 2.208280, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 636/655, Loss: 2.208331, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 637/655, Loss: 2.208221, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 638/655, Loss: 2.207960, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 639/655, Loss: 2.207871, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 640/655, Loss: 2.207867, Accuracy: 18.61%\n",
            "Epoch: 44, Step: 641/655, Loss: 2.207870, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 642/655, Loss: 2.207868, Accuracy: 18.57%\n",
            "Epoch: 44, Step: 643/655, Loss: 2.207953, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 644/655, Loss: 2.207920, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 645/655, Loss: 2.207798, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 646/655, Loss: 2.207709, Accuracy: 18.60%\n",
            "Epoch: 44, Step: 647/655, Loss: 2.207573, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 648/655, Loss: 2.207531, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 649/655, Loss: 2.207455, Accuracy: 18.59%\n",
            "Epoch: 44, Step: 650/655, Loss: 2.207436, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 651/655, Loss: 2.207374, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 652/655, Loss: 2.207465, Accuracy: 18.56%\n",
            "Epoch: 44, Step: 653/655, Loss: 2.207454, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 654/655, Loss: 2.207353, Accuracy: 18.58%\n",
            "Epoch: 44, Step: 655/655, Loss: 2.207701, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 1/655, Loss: 2.225100, Accuracy: 18.75%\n",
            "Epoch: 45, Step: 2/655, Loss: 2.211756, Accuracy: 20.31%\n",
            "Epoch: 45, Step: 3/655, Loss: 2.230016, Accuracy: 18.75%\n",
            "Epoch: 45, Step: 4/655, Loss: 2.246382, Accuracy: 15.62%\n",
            "Epoch: 45, Step: 5/655, Loss: 2.263382, Accuracy: 14.38%\n",
            "Epoch: 45, Step: 6/655, Loss: 2.250888, Accuracy: 15.10%\n",
            "Epoch: 45, Step: 7/655, Loss: 2.246294, Accuracy: 15.62%\n",
            "Epoch: 45, Step: 8/655, Loss: 2.241984, Accuracy: 14.45%\n",
            "Epoch: 45, Step: 9/655, Loss: 2.232481, Accuracy: 15.97%\n",
            "Epoch: 45, Step: 10/655, Loss: 2.225955, Accuracy: 17.19%\n",
            "Epoch: 45, Step: 11/655, Loss: 2.220334, Accuracy: 17.05%\n",
            "Epoch: 45, Step: 12/655, Loss: 2.213267, Accuracy: 16.41%\n",
            "Epoch: 45, Step: 13/655, Loss: 2.216530, Accuracy: 15.62%\n",
            "Epoch: 45, Step: 14/655, Loss: 2.206565, Accuracy: 16.96%\n",
            "Epoch: 45, Step: 15/655, Loss: 2.204976, Accuracy: 16.88%\n",
            "Epoch: 45, Step: 16/655, Loss: 2.203971, Accuracy: 16.99%\n",
            "Epoch: 45, Step: 17/655, Loss: 2.204695, Accuracy: 16.73%\n",
            "Epoch: 45, Step: 18/655, Loss: 2.197274, Accuracy: 16.32%\n",
            "Epoch: 45, Step: 19/655, Loss: 2.197473, Accuracy: 16.61%\n",
            "Epoch: 45, Step: 20/655, Loss: 2.201193, Accuracy: 16.56%\n",
            "Epoch: 45, Step: 21/655, Loss: 2.195205, Accuracy: 17.71%\n",
            "Epoch: 45, Step: 22/655, Loss: 2.197465, Accuracy: 17.61%\n",
            "Epoch: 45, Step: 23/655, Loss: 2.197224, Accuracy: 17.80%\n",
            "Epoch: 45, Step: 24/655, Loss: 2.192679, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 25/655, Loss: 2.194481, Accuracy: 18.75%\n",
            "Epoch: 45, Step: 26/655, Loss: 2.192210, Accuracy: 18.87%\n",
            "Epoch: 45, Step: 27/655, Loss: 2.192686, Accuracy: 19.10%\n",
            "Epoch: 45, Step: 28/655, Loss: 2.189756, Accuracy: 19.53%\n",
            "Epoch: 45, Step: 29/655, Loss: 2.191110, Accuracy: 19.50%\n",
            "Epoch: 45, Step: 30/655, Loss: 2.192998, Accuracy: 19.38%\n",
            "Epoch: 45, Step: 31/655, Loss: 2.195351, Accuracy: 19.35%\n",
            "Epoch: 45, Step: 32/655, Loss: 2.194398, Accuracy: 19.24%\n",
            "Epoch: 45, Step: 33/655, Loss: 2.196142, Accuracy: 19.22%\n",
            "Epoch: 45, Step: 34/655, Loss: 2.195790, Accuracy: 19.21%\n",
            "Epoch: 45, Step: 35/655, Loss: 2.199359, Accuracy: 18.93%\n",
            "Epoch: 45, Step: 36/655, Loss: 2.196761, Accuracy: 18.75%\n",
            "Epoch: 45, Step: 37/655, Loss: 2.197049, Accuracy: 18.75%\n",
            "Epoch: 45, Step: 38/655, Loss: 2.194683, Accuracy: 19.08%\n",
            "Epoch: 45, Step: 39/655, Loss: 2.197099, Accuracy: 18.91%\n",
            "Epoch: 45, Step: 40/655, Loss: 2.195144, Accuracy: 18.75%\n",
            "Epoch: 45, Step: 41/655, Loss: 2.193976, Accuracy: 18.90%\n",
            "Epoch: 45, Step: 42/655, Loss: 2.196310, Accuracy: 18.82%\n",
            "Epoch: 45, Step: 43/655, Loss: 2.197744, Accuracy: 18.82%\n",
            "Epoch: 45, Step: 44/655, Loss: 2.198541, Accuracy: 18.75%\n",
            "Epoch: 45, Step: 45/655, Loss: 2.196802, Accuracy: 18.89%\n",
            "Epoch: 45, Step: 46/655, Loss: 2.196673, Accuracy: 19.02%\n",
            "Epoch: 45, Step: 47/655, Loss: 2.194533, Accuracy: 19.08%\n",
            "Epoch: 45, Step: 48/655, Loss: 2.195716, Accuracy: 18.95%\n",
            "Epoch: 45, Step: 49/655, Loss: 2.196345, Accuracy: 19.01%\n",
            "Epoch: 45, Step: 50/655, Loss: 2.196165, Accuracy: 19.19%\n",
            "Epoch: 45, Step: 51/655, Loss: 2.196942, Accuracy: 18.93%\n",
            "Epoch: 45, Step: 52/655, Loss: 2.198266, Accuracy: 18.93%\n",
            "Epoch: 45, Step: 53/655, Loss: 2.197742, Accuracy: 19.16%\n",
            "Epoch: 45, Step: 54/655, Loss: 2.198531, Accuracy: 19.10%\n",
            "Epoch: 45, Step: 55/655, Loss: 2.200467, Accuracy: 19.09%\n",
            "Epoch: 45, Step: 56/655, Loss: 2.199228, Accuracy: 18.97%\n",
            "Epoch: 45, Step: 57/655, Loss: 2.200259, Accuracy: 18.91%\n",
            "Epoch: 45, Step: 58/655, Loss: 2.199591, Accuracy: 19.02%\n",
            "Epoch: 45, Step: 59/655, Loss: 2.199671, Accuracy: 19.01%\n",
            "Epoch: 45, Step: 60/655, Loss: 2.199366, Accuracy: 18.96%\n",
            "Epoch: 45, Step: 61/655, Loss: 2.199601, Accuracy: 18.95%\n",
            "Epoch: 45, Step: 62/655, Loss: 2.198698, Accuracy: 18.95%\n",
            "Epoch: 45, Step: 63/655, Loss: 2.201243, Accuracy: 18.85%\n",
            "Epoch: 45, Step: 64/655, Loss: 2.201059, Accuracy: 18.90%\n",
            "Epoch: 45, Step: 65/655, Loss: 2.200470, Accuracy: 18.85%\n",
            "Epoch: 45, Step: 66/655, Loss: 2.202903, Accuracy: 18.70%\n",
            "Epoch: 45, Step: 67/655, Loss: 2.202203, Accuracy: 18.56%\n",
            "Epoch: 45, Step: 68/655, Loss: 2.201748, Accuracy: 18.57%\n",
            "Epoch: 45, Step: 69/655, Loss: 2.203000, Accuracy: 18.52%\n",
            "Epoch: 45, Step: 70/655, Loss: 2.202700, Accuracy: 18.57%\n",
            "Epoch: 45, Step: 71/655, Loss: 2.202644, Accuracy: 18.75%\n",
            "Epoch: 45, Step: 72/655, Loss: 2.201579, Accuracy: 18.79%\n",
            "Epoch: 45, Step: 73/655, Loss: 2.202122, Accuracy: 18.96%\n",
            "Epoch: 45, Step: 74/655, Loss: 2.203124, Accuracy: 18.79%\n",
            "Epoch: 45, Step: 75/655, Loss: 2.203249, Accuracy: 18.83%\n",
            "Epoch: 45, Step: 76/655, Loss: 2.202219, Accuracy: 18.83%\n",
            "Epoch: 45, Step: 77/655, Loss: 2.202381, Accuracy: 19.03%\n",
            "Epoch: 45, Step: 78/655, Loss: 2.201996, Accuracy: 18.99%\n",
            "Epoch: 45, Step: 79/655, Loss: 2.201800, Accuracy: 19.07%\n",
            "Epoch: 45, Step: 80/655, Loss: 2.201416, Accuracy: 18.98%\n",
            "Epoch: 45, Step: 81/655, Loss: 2.201608, Accuracy: 18.98%\n",
            "Epoch: 45, Step: 82/655, Loss: 2.201588, Accuracy: 19.02%\n",
            "Epoch: 45, Step: 83/655, Loss: 2.199712, Accuracy: 19.13%\n",
            "Epoch: 45, Step: 84/655, Loss: 2.198531, Accuracy: 19.08%\n",
            "Epoch: 45, Step: 85/655, Loss: 2.199538, Accuracy: 19.04%\n",
            "Epoch: 45, Step: 86/655, Loss: 2.199619, Accuracy: 19.04%\n",
            "Epoch: 45, Step: 87/655, Loss: 2.198932, Accuracy: 19.00%\n",
            "Epoch: 45, Step: 88/655, Loss: 2.200646, Accuracy: 19.00%\n",
            "Epoch: 45, Step: 89/655, Loss: 2.200788, Accuracy: 19.03%\n",
            "Epoch: 45, Step: 90/655, Loss: 2.202418, Accuracy: 18.92%\n",
            "Epoch: 45, Step: 91/655, Loss: 2.203484, Accuracy: 18.89%\n",
            "Epoch: 45, Step: 92/655, Loss: 2.203580, Accuracy: 18.85%\n",
            "Epoch: 45, Step: 93/655, Loss: 2.203013, Accuracy: 18.85%\n",
            "Epoch: 45, Step: 94/655, Loss: 2.202827, Accuracy: 18.78%\n",
            "Epoch: 45, Step: 95/655, Loss: 2.203164, Accuracy: 18.85%\n",
            "Epoch: 45, Step: 96/655, Loss: 2.202004, Accuracy: 18.88%\n",
            "Epoch: 45, Step: 97/655, Loss: 2.201797, Accuracy: 18.81%\n",
            "Epoch: 45, Step: 98/655, Loss: 2.201893, Accuracy: 18.78%\n",
            "Epoch: 45, Step: 99/655, Loss: 2.202651, Accuracy: 18.72%\n",
            "Epoch: 45, Step: 100/655, Loss: 2.201819, Accuracy: 18.69%\n",
            "Epoch: 45, Step: 101/655, Loss: 2.202544, Accuracy: 18.56%\n",
            "Epoch: 45, Step: 102/655, Loss: 2.202915, Accuracy: 18.60%\n",
            "Epoch: 45, Step: 103/655, Loss: 2.202305, Accuracy: 18.57%\n",
            "Epoch: 45, Step: 104/655, Loss: 2.201641, Accuracy: 18.63%\n",
            "Epoch: 45, Step: 105/655, Loss: 2.201742, Accuracy: 18.60%\n",
            "Epoch: 45, Step: 106/655, Loss: 2.201983, Accuracy: 18.57%\n",
            "Epoch: 45, Step: 107/655, Loss: 2.199754, Accuracy: 18.60%\n",
            "Epoch: 45, Step: 108/655, Loss: 2.200590, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 109/655, Loss: 2.199876, Accuracy: 18.64%\n",
            "Epoch: 45, Step: 110/655, Loss: 2.199882, Accuracy: 18.64%\n",
            "Epoch: 45, Step: 111/655, Loss: 2.199737, Accuracy: 18.75%\n",
            "Epoch: 45, Step: 112/655, Loss: 2.199673, Accuracy: 18.69%\n",
            "Epoch: 45, Step: 113/655, Loss: 2.199739, Accuracy: 18.69%\n",
            "Epoch: 45, Step: 114/655, Loss: 2.200405, Accuracy: 18.56%\n",
            "Epoch: 45, Step: 115/655, Loss: 2.200457, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 116/655, Loss: 2.201171, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 117/655, Loss: 2.202207, Accuracy: 18.43%\n",
            "Epoch: 45, Step: 118/655, Loss: 2.201328, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 119/655, Loss: 2.202583, Accuracy: 18.38%\n",
            "Epoch: 45, Step: 120/655, Loss: 2.202315, Accuracy: 18.39%\n",
            "Epoch: 45, Step: 121/655, Loss: 2.201223, Accuracy: 18.41%\n",
            "Epoch: 45, Step: 122/655, Loss: 2.202320, Accuracy: 18.37%\n",
            "Epoch: 45, Step: 123/655, Loss: 2.202094, Accuracy: 18.42%\n",
            "Epoch: 45, Step: 124/655, Loss: 2.201998, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 125/655, Loss: 2.202466, Accuracy: 18.38%\n",
            "Epoch: 45, Step: 126/655, Loss: 2.202208, Accuracy: 18.38%\n",
            "Epoch: 45, Step: 127/655, Loss: 2.202007, Accuracy: 18.41%\n",
            "Epoch: 45, Step: 128/655, Loss: 2.201545, Accuracy: 18.41%\n",
            "Epoch: 45, Step: 129/655, Loss: 2.201688, Accuracy: 18.36%\n",
            "Epoch: 45, Step: 130/655, Loss: 2.201870, Accuracy: 18.32%\n",
            "Epoch: 45, Step: 131/655, Loss: 2.203193, Accuracy: 18.27%\n",
            "Epoch: 45, Step: 132/655, Loss: 2.203013, Accuracy: 18.32%\n",
            "Epoch: 45, Step: 133/655, Loss: 2.202261, Accuracy: 18.42%\n",
            "Epoch: 45, Step: 134/655, Loss: 2.202460, Accuracy: 18.38%\n",
            "Epoch: 45, Step: 135/655, Loss: 2.202648, Accuracy: 18.43%\n",
            "Epoch: 45, Step: 136/655, Loss: 2.203301, Accuracy: 18.41%\n",
            "Epoch: 45, Step: 137/655, Loss: 2.202518, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 138/655, Loss: 2.201885, Accuracy: 18.52%\n",
            "Epoch: 45, Step: 139/655, Loss: 2.202285, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 140/655, Loss: 2.202029, Accuracy: 18.53%\n",
            "Epoch: 45, Step: 141/655, Loss: 2.201883, Accuracy: 18.57%\n",
            "Epoch: 45, Step: 142/655, Loss: 2.202083, Accuracy: 18.55%\n",
            "Epoch: 45, Step: 143/655, Loss: 2.202058, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 144/655, Loss: 2.201963, Accuracy: 18.55%\n",
            "Epoch: 45, Step: 145/655, Loss: 2.201943, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 146/655, Loss: 2.202348, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 147/655, Loss: 2.202692, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 148/655, Loss: 2.203507, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 149/655, Loss: 2.204008, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 150/655, Loss: 2.203541, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 151/655, Loss: 2.203370, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 152/655, Loss: 2.203671, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 153/655, Loss: 2.204277, Accuracy: 18.53%\n",
            "Epoch: 45, Step: 154/655, Loss: 2.204507, Accuracy: 18.53%\n",
            "Epoch: 45, Step: 155/655, Loss: 2.204777, Accuracy: 18.55%\n",
            "Epoch: 45, Step: 156/655, Loss: 2.204761, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 157/655, Loss: 2.204898, Accuracy: 18.43%\n",
            "Epoch: 45, Step: 158/655, Loss: 2.205908, Accuracy: 18.43%\n",
            "Epoch: 45, Step: 159/655, Loss: 2.206495, Accuracy: 18.44%\n",
            "Epoch: 45, Step: 160/655, Loss: 2.205907, Accuracy: 18.42%\n",
            "Epoch: 45, Step: 161/655, Loss: 2.205016, Accuracy: 18.50%\n",
            "Epoch: 45, Step: 162/655, Loss: 2.205164, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 163/655, Loss: 2.205527, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 164/655, Loss: 2.205863, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 165/655, Loss: 2.205368, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 166/655, Loss: 2.204979, Accuracy: 18.43%\n",
            "Epoch: 45, Step: 167/655, Loss: 2.204504, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 168/655, Loss: 2.204552, Accuracy: 18.51%\n",
            "Epoch: 45, Step: 169/655, Loss: 2.203721, Accuracy: 18.53%\n",
            "Epoch: 45, Step: 170/655, Loss: 2.204415, Accuracy: 18.53%\n",
            "Epoch: 45, Step: 171/655, Loss: 2.204916, Accuracy: 18.51%\n",
            "Epoch: 45, Step: 172/655, Loss: 2.204682, Accuracy: 18.53%\n",
            "Epoch: 45, Step: 173/655, Loss: 2.204904, Accuracy: 18.57%\n",
            "Epoch: 45, Step: 174/655, Loss: 2.205224, Accuracy: 18.53%\n",
            "Epoch: 45, Step: 175/655, Loss: 2.205262, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 176/655, Loss: 2.204938, Accuracy: 18.50%\n",
            "Epoch: 45, Step: 177/655, Loss: 2.204709, Accuracy: 18.50%\n",
            "Epoch: 45, Step: 178/655, Loss: 2.204485, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 179/655, Loss: 2.204259, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 180/655, Loss: 2.205002, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 181/655, Loss: 2.205029, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 182/655, Loss: 2.204721, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 183/655, Loss: 2.204963, Accuracy: 18.51%\n",
            "Epoch: 45, Step: 184/655, Loss: 2.204986, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 185/655, Loss: 2.205499, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 186/655, Loss: 2.205315, Accuracy: 18.63%\n",
            "Epoch: 45, Step: 187/655, Loss: 2.205262, Accuracy: 18.68%\n",
            "Epoch: 45, Step: 188/655, Loss: 2.205072, Accuracy: 18.70%\n",
            "Epoch: 45, Step: 189/655, Loss: 2.205070, Accuracy: 18.73%\n",
            "Epoch: 45, Step: 190/655, Loss: 2.204929, Accuracy: 18.75%\n",
            "Epoch: 45, Step: 191/655, Loss: 2.204493, Accuracy: 18.73%\n",
            "Epoch: 45, Step: 192/655, Loss: 2.204703, Accuracy: 18.73%\n",
            "Epoch: 45, Step: 193/655, Loss: 2.204745, Accuracy: 18.69%\n",
            "Epoch: 45, Step: 194/655, Loss: 2.204984, Accuracy: 18.67%\n",
            "Epoch: 45, Step: 195/655, Loss: 2.205271, Accuracy: 18.62%\n",
            "Epoch: 45, Step: 196/655, Loss: 2.205040, Accuracy: 18.62%\n",
            "Epoch: 45, Step: 197/655, Loss: 2.204783, Accuracy: 18.62%\n",
            "Epoch: 45, Step: 198/655, Loss: 2.204723, Accuracy: 18.59%\n",
            "Epoch: 45, Step: 199/655, Loss: 2.204202, Accuracy: 18.62%\n",
            "Epoch: 45, Step: 200/655, Loss: 2.204040, Accuracy: 18.66%\n",
            "Epoch: 45, Step: 201/655, Loss: 2.203549, Accuracy: 18.64%\n",
            "Epoch: 45, Step: 202/655, Loss: 2.204005, Accuracy: 18.63%\n",
            "Epoch: 45, Step: 203/655, Loss: 2.204228, Accuracy: 18.64%\n",
            "Epoch: 45, Step: 204/655, Loss: 2.203764, Accuracy: 18.69%\n",
            "Epoch: 45, Step: 205/655, Loss: 2.202900, Accuracy: 18.70%\n",
            "Epoch: 45, Step: 206/655, Loss: 2.202335, Accuracy: 18.75%\n",
            "Epoch: 45, Step: 207/655, Loss: 2.202250, Accuracy: 18.72%\n",
            "Epoch: 45, Step: 208/655, Loss: 2.202089, Accuracy: 18.70%\n",
            "Epoch: 45, Step: 209/655, Loss: 2.202240, Accuracy: 18.76%\n",
            "Epoch: 45, Step: 210/655, Loss: 2.201903, Accuracy: 18.79%\n",
            "Epoch: 45, Step: 211/655, Loss: 2.201846, Accuracy: 18.76%\n",
            "Epoch: 45, Step: 212/655, Loss: 2.201816, Accuracy: 18.74%\n",
            "Epoch: 45, Step: 213/655, Loss: 2.200967, Accuracy: 18.82%\n",
            "Epoch: 45, Step: 214/655, Loss: 2.201078, Accuracy: 18.84%\n",
            "Epoch: 45, Step: 215/655, Loss: 2.201563, Accuracy: 18.82%\n",
            "Epoch: 45, Step: 216/655, Loss: 2.201281, Accuracy: 18.85%\n",
            "Epoch: 45, Step: 217/655, Loss: 2.201273, Accuracy: 18.87%\n",
            "Epoch: 45, Step: 218/655, Loss: 2.200761, Accuracy: 18.92%\n",
            "Epoch: 45, Step: 219/655, Loss: 2.201025, Accuracy: 18.92%\n",
            "Epoch: 45, Step: 220/655, Loss: 2.200822, Accuracy: 18.93%\n",
            "Epoch: 45, Step: 221/655, Loss: 2.200463, Accuracy: 19.00%\n",
            "Epoch: 45, Step: 222/655, Loss: 2.201146, Accuracy: 18.98%\n",
            "Epoch: 45, Step: 223/655, Loss: 2.201082, Accuracy: 18.96%\n",
            "Epoch: 45, Step: 224/655, Loss: 2.201124, Accuracy: 18.99%\n",
            "Epoch: 45, Step: 225/655, Loss: 2.201319, Accuracy: 18.94%\n",
            "Epoch: 45, Step: 226/655, Loss: 2.200886, Accuracy: 18.99%\n",
            "Epoch: 45, Step: 227/655, Loss: 2.200944, Accuracy: 19.03%\n",
            "Epoch: 45, Step: 228/655, Loss: 2.201223, Accuracy: 19.02%\n",
            "Epoch: 45, Step: 229/655, Loss: 2.201268, Accuracy: 19.01%\n",
            "Epoch: 45, Step: 230/655, Loss: 2.200892, Accuracy: 19.04%\n",
            "Epoch: 45, Step: 231/655, Loss: 2.201435, Accuracy: 18.99%\n",
            "Epoch: 45, Step: 232/655, Loss: 2.200894, Accuracy: 19.05%\n",
            "Epoch: 45, Step: 233/655, Loss: 2.200562, Accuracy: 19.05%\n",
            "Epoch: 45, Step: 234/655, Loss: 2.200110, Accuracy: 19.02%\n",
            "Epoch: 45, Step: 235/655, Loss: 2.201097, Accuracy: 18.96%\n",
            "Epoch: 45, Step: 236/655, Loss: 2.201175, Accuracy: 18.98%\n",
            "Epoch: 45, Step: 237/655, Loss: 2.201091, Accuracy: 19.00%\n",
            "Epoch: 45, Step: 238/655, Loss: 2.201415, Accuracy: 18.99%\n",
            "Epoch: 45, Step: 239/655, Loss: 2.201474, Accuracy: 18.95%\n",
            "Epoch: 45, Step: 240/655, Loss: 2.201272, Accuracy: 18.95%\n",
            "Epoch: 45, Step: 241/655, Loss: 2.201530, Accuracy: 18.96%\n",
            "Epoch: 45, Step: 242/655, Loss: 2.201655, Accuracy: 18.97%\n",
            "Epoch: 45, Step: 243/655, Loss: 2.201332, Accuracy: 19.01%\n",
            "Epoch: 45, Step: 244/655, Loss: 2.201566, Accuracy: 18.98%\n",
            "Epoch: 45, Step: 245/655, Loss: 2.201237, Accuracy: 18.99%\n",
            "Epoch: 45, Step: 246/655, Loss: 2.201172, Accuracy: 19.00%\n",
            "Epoch: 45, Step: 247/655, Loss: 2.201722, Accuracy: 18.99%\n",
            "Epoch: 45, Step: 248/655, Loss: 2.202434, Accuracy: 18.96%\n",
            "Epoch: 45, Step: 249/655, Loss: 2.202640, Accuracy: 18.91%\n",
            "Epoch: 45, Step: 250/655, Loss: 2.202412, Accuracy: 18.98%\n",
            "Epoch: 45, Step: 251/655, Loss: 2.202726, Accuracy: 18.92%\n",
            "Epoch: 45, Step: 252/655, Loss: 2.202500, Accuracy: 18.91%\n",
            "Epoch: 45, Step: 253/655, Loss: 2.202657, Accuracy: 18.92%\n",
            "Epoch: 45, Step: 254/655, Loss: 2.202862, Accuracy: 18.87%\n",
            "Epoch: 45, Step: 255/655, Loss: 2.202612, Accuracy: 18.90%\n",
            "Epoch: 45, Step: 256/655, Loss: 2.202514, Accuracy: 18.85%\n",
            "Epoch: 45, Step: 257/655, Loss: 2.202220, Accuracy: 18.86%\n",
            "Epoch: 45, Step: 258/655, Loss: 2.202107, Accuracy: 18.83%\n",
            "Epoch: 45, Step: 259/655, Loss: 2.202140, Accuracy: 18.85%\n",
            "Epoch: 45, Step: 260/655, Loss: 2.202011, Accuracy: 18.88%\n",
            "Epoch: 45, Step: 261/655, Loss: 2.202045, Accuracy: 18.88%\n",
            "Epoch: 45, Step: 262/655, Loss: 2.202069, Accuracy: 18.88%\n",
            "Epoch: 45, Step: 263/655, Loss: 2.202192, Accuracy: 18.93%\n",
            "Epoch: 45, Step: 264/655, Loss: 2.202341, Accuracy: 18.89%\n",
            "Epoch: 45, Step: 265/655, Loss: 2.202382, Accuracy: 18.89%\n",
            "Epoch: 45, Step: 266/655, Loss: 2.202362, Accuracy: 18.89%\n",
            "Epoch: 45, Step: 267/655, Loss: 2.202889, Accuracy: 18.88%\n",
            "Epoch: 45, Step: 268/655, Loss: 2.202667, Accuracy: 18.90%\n",
            "Epoch: 45, Step: 269/655, Loss: 2.202978, Accuracy: 18.89%\n",
            "Epoch: 45, Step: 270/655, Loss: 2.203060, Accuracy: 18.90%\n",
            "Epoch: 45, Step: 271/655, Loss: 2.203341, Accuracy: 18.85%\n",
            "Epoch: 45, Step: 272/655, Loss: 2.203521, Accuracy: 18.83%\n",
            "Epoch: 45, Step: 273/655, Loss: 2.203449, Accuracy: 18.84%\n",
            "Epoch: 45, Step: 274/655, Loss: 2.203160, Accuracy: 18.85%\n",
            "Epoch: 45, Step: 275/655, Loss: 2.203255, Accuracy: 18.83%\n",
            "Epoch: 45, Step: 276/655, Loss: 2.203437, Accuracy: 18.84%\n",
            "Epoch: 45, Step: 277/655, Loss: 2.204087, Accuracy: 18.82%\n",
            "Epoch: 45, Step: 278/655, Loss: 2.204256, Accuracy: 18.83%\n",
            "Epoch: 45, Step: 279/655, Loss: 2.204411, Accuracy: 18.84%\n",
            "Epoch: 45, Step: 280/655, Loss: 2.204116, Accuracy: 18.87%\n",
            "Epoch: 45, Step: 281/655, Loss: 2.204314, Accuracy: 18.86%\n",
            "Epoch: 45, Step: 282/655, Loss: 2.204401, Accuracy: 18.87%\n",
            "Epoch: 45, Step: 283/655, Loss: 2.204166, Accuracy: 18.89%\n",
            "Epoch: 45, Step: 284/655, Loss: 2.204201, Accuracy: 18.90%\n",
            "Epoch: 45, Step: 285/655, Loss: 2.204197, Accuracy: 18.90%\n",
            "Epoch: 45, Step: 286/655, Loss: 2.204515, Accuracy: 18.89%\n",
            "Epoch: 45, Step: 287/655, Loss: 2.204657, Accuracy: 18.90%\n",
            "Epoch: 45, Step: 288/655, Loss: 2.204999, Accuracy: 18.91%\n",
            "Epoch: 45, Step: 289/655, Loss: 2.204996, Accuracy: 18.89%\n",
            "Epoch: 45, Step: 290/655, Loss: 2.204421, Accuracy: 18.93%\n",
            "Epoch: 45, Step: 291/655, Loss: 2.204208, Accuracy: 18.94%\n",
            "Epoch: 45, Step: 292/655, Loss: 2.204512, Accuracy: 18.92%\n",
            "Epoch: 45, Step: 293/655, Loss: 2.204278, Accuracy: 18.92%\n",
            "Epoch: 45, Step: 294/655, Loss: 2.204388, Accuracy: 18.90%\n",
            "Epoch: 45, Step: 295/655, Loss: 2.204481, Accuracy: 18.89%\n",
            "Epoch: 45, Step: 296/655, Loss: 2.204076, Accuracy: 18.93%\n",
            "Epoch: 45, Step: 297/655, Loss: 2.204346, Accuracy: 18.92%\n",
            "Epoch: 45, Step: 298/655, Loss: 2.204286, Accuracy: 18.94%\n",
            "Epoch: 45, Step: 299/655, Loss: 2.204213, Accuracy: 18.95%\n",
            "Epoch: 45, Step: 300/655, Loss: 2.204090, Accuracy: 18.98%\n",
            "Epoch: 45, Step: 301/655, Loss: 2.204396, Accuracy: 18.98%\n",
            "Epoch: 45, Step: 302/655, Loss: 2.204437, Accuracy: 19.00%\n",
            "Epoch: 45, Step: 303/655, Loss: 2.204773, Accuracy: 18.99%\n",
            "Epoch: 45, Step: 304/655, Loss: 2.204354, Accuracy: 19.06%\n",
            "Epoch: 45, Step: 305/655, Loss: 2.204182, Accuracy: 19.05%\n",
            "Epoch: 45, Step: 306/655, Loss: 2.204062, Accuracy: 19.07%\n",
            "Epoch: 45, Step: 307/655, Loss: 2.204340, Accuracy: 19.05%\n",
            "Epoch: 45, Step: 308/655, Loss: 2.204789, Accuracy: 19.01%\n",
            "Epoch: 45, Step: 309/655, Loss: 2.204241, Accuracy: 18.99%\n",
            "Epoch: 45, Step: 310/655, Loss: 2.204323, Accuracy: 18.97%\n",
            "Epoch: 45, Step: 311/655, Loss: 2.204555, Accuracy: 18.97%\n",
            "Epoch: 45, Step: 312/655, Loss: 2.204377, Accuracy: 18.99%\n",
            "Epoch: 45, Step: 313/655, Loss: 2.204218, Accuracy: 19.01%\n",
            "Epoch: 45, Step: 314/655, Loss: 2.203883, Accuracy: 19.04%\n",
            "Epoch: 45, Step: 315/655, Loss: 2.203829, Accuracy: 19.05%\n",
            "Epoch: 45, Step: 316/655, Loss: 2.204106, Accuracy: 19.05%\n",
            "Epoch: 45, Step: 317/655, Loss: 2.204042, Accuracy: 19.05%\n",
            "Epoch: 45, Step: 318/655, Loss: 2.204304, Accuracy: 19.03%\n",
            "Epoch: 45, Step: 319/655, Loss: 2.204767, Accuracy: 19.01%\n",
            "Epoch: 45, Step: 320/655, Loss: 2.204856, Accuracy: 19.01%\n",
            "Epoch: 45, Step: 321/655, Loss: 2.204653, Accuracy: 19.02%\n",
            "Epoch: 45, Step: 322/655, Loss: 2.204509, Accuracy: 19.04%\n",
            "Epoch: 45, Step: 323/655, Loss: 2.205073, Accuracy: 19.00%\n",
            "Epoch: 45, Step: 324/655, Loss: 2.205080, Accuracy: 19.01%\n",
            "Epoch: 45, Step: 325/655, Loss: 2.205283, Accuracy: 18.98%\n",
            "Epoch: 45, Step: 326/655, Loss: 2.205079, Accuracy: 19.00%\n",
            "Epoch: 45, Step: 327/655, Loss: 2.205022, Accuracy: 19.01%\n",
            "Epoch: 45, Step: 328/655, Loss: 2.205032, Accuracy: 19.00%\n",
            "Epoch: 45, Step: 329/655, Loss: 2.205295, Accuracy: 18.99%\n",
            "Epoch: 45, Step: 330/655, Loss: 2.205346, Accuracy: 18.98%\n",
            "Epoch: 45, Step: 331/655, Loss: 2.205518, Accuracy: 18.97%\n",
            "Epoch: 45, Step: 332/655, Loss: 2.205869, Accuracy: 18.92%\n",
            "Epoch: 45, Step: 333/655, Loss: 2.206288, Accuracy: 18.91%\n",
            "Epoch: 45, Step: 334/655, Loss: 2.206206, Accuracy: 18.93%\n",
            "Epoch: 45, Step: 335/655, Loss: 2.206602, Accuracy: 18.89%\n",
            "Epoch: 45, Step: 336/655, Loss: 2.206716, Accuracy: 18.88%\n",
            "Epoch: 45, Step: 337/655, Loss: 2.206676, Accuracy: 18.85%\n",
            "Epoch: 45, Step: 338/655, Loss: 2.206734, Accuracy: 18.81%\n",
            "Epoch: 45, Step: 339/655, Loss: 2.206612, Accuracy: 18.80%\n",
            "Epoch: 45, Step: 340/655, Loss: 2.206738, Accuracy: 18.81%\n",
            "Epoch: 45, Step: 341/655, Loss: 2.206487, Accuracy: 18.81%\n",
            "Epoch: 45, Step: 342/655, Loss: 2.206523, Accuracy: 18.82%\n",
            "Epoch: 45, Step: 343/655, Loss: 2.206424, Accuracy: 18.82%\n",
            "Epoch: 45, Step: 344/655, Loss: 2.206552, Accuracy: 18.80%\n",
            "Epoch: 45, Step: 345/655, Loss: 2.206451, Accuracy: 18.79%\n",
            "Epoch: 45, Step: 346/655, Loss: 2.206552, Accuracy: 18.80%\n",
            "Epoch: 45, Step: 347/655, Loss: 2.206610, Accuracy: 18.80%\n",
            "Epoch: 45, Step: 348/655, Loss: 2.206506, Accuracy: 18.79%\n",
            "Epoch: 45, Step: 349/655, Loss: 2.206545, Accuracy: 18.79%\n",
            "Epoch: 45, Step: 350/655, Loss: 2.206253, Accuracy: 18.79%\n",
            "Epoch: 45, Step: 351/655, Loss: 2.205835, Accuracy: 18.81%\n",
            "Epoch: 45, Step: 352/655, Loss: 2.206008, Accuracy: 18.79%\n",
            "Epoch: 45, Step: 353/655, Loss: 2.206178, Accuracy: 18.75%\n",
            "Epoch: 45, Step: 354/655, Loss: 2.205968, Accuracy: 18.76%\n",
            "Epoch: 45, Step: 355/655, Loss: 2.205856, Accuracy: 18.78%\n",
            "Epoch: 45, Step: 356/655, Loss: 2.206025, Accuracy: 18.78%\n",
            "Epoch: 45, Step: 357/655, Loss: 2.206282, Accuracy: 18.77%\n",
            "Epoch: 45, Step: 358/655, Loss: 2.206059, Accuracy: 18.78%\n",
            "Epoch: 45, Step: 359/655, Loss: 2.205954, Accuracy: 18.76%\n",
            "Epoch: 45, Step: 360/655, Loss: 2.206327, Accuracy: 18.73%\n",
            "Epoch: 45, Step: 361/655, Loss: 2.205857, Accuracy: 18.73%\n",
            "Epoch: 45, Step: 362/655, Loss: 2.206088, Accuracy: 18.72%\n",
            "Epoch: 45, Step: 363/655, Loss: 2.206386, Accuracy: 18.69%\n",
            "Epoch: 45, Step: 364/655, Loss: 2.206259, Accuracy: 18.67%\n",
            "Epoch: 45, Step: 365/655, Loss: 2.206095, Accuracy: 18.68%\n",
            "Epoch: 45, Step: 366/655, Loss: 2.206289, Accuracy: 18.67%\n",
            "Epoch: 45, Step: 367/655, Loss: 2.206271, Accuracy: 18.66%\n",
            "Epoch: 45, Step: 368/655, Loss: 2.206344, Accuracy: 18.66%\n",
            "Epoch: 45, Step: 369/655, Loss: 2.206445, Accuracy: 18.67%\n",
            "Epoch: 45, Step: 370/655, Loss: 2.206274, Accuracy: 18.70%\n",
            "Epoch: 45, Step: 371/655, Loss: 2.206416, Accuracy: 18.71%\n",
            "Epoch: 45, Step: 372/655, Loss: 2.206647, Accuracy: 18.70%\n",
            "Epoch: 45, Step: 373/655, Loss: 2.206833, Accuracy: 18.69%\n",
            "Epoch: 45, Step: 374/655, Loss: 2.206877, Accuracy: 18.66%\n",
            "Epoch: 45, Step: 375/655, Loss: 2.206555, Accuracy: 18.68%\n",
            "Epoch: 45, Step: 376/655, Loss: 2.206690, Accuracy: 18.65%\n",
            "Epoch: 45, Step: 377/655, Loss: 2.206602, Accuracy: 18.67%\n",
            "Epoch: 45, Step: 378/655, Loss: 2.206756, Accuracy: 18.63%\n",
            "Epoch: 45, Step: 379/655, Loss: 2.206542, Accuracy: 18.67%\n",
            "Epoch: 45, Step: 380/655, Loss: 2.206298, Accuracy: 18.69%\n",
            "Epoch: 45, Step: 381/655, Loss: 2.206325, Accuracy: 18.68%\n",
            "Epoch: 45, Step: 382/655, Loss: 2.205981, Accuracy: 18.70%\n",
            "Epoch: 45, Step: 383/655, Loss: 2.205834, Accuracy: 18.70%\n",
            "Epoch: 45, Step: 384/655, Loss: 2.205829, Accuracy: 18.72%\n",
            "Epoch: 45, Step: 385/655, Loss: 2.205620, Accuracy: 18.71%\n",
            "Epoch: 45, Step: 386/655, Loss: 2.205903, Accuracy: 18.72%\n",
            "Epoch: 45, Step: 387/655, Loss: 2.206251, Accuracy: 18.69%\n",
            "Epoch: 45, Step: 388/655, Loss: 2.206715, Accuracy: 18.65%\n",
            "Epoch: 45, Step: 389/655, Loss: 2.206791, Accuracy: 18.65%\n",
            "Epoch: 45, Step: 390/655, Loss: 2.206609, Accuracy: 18.65%\n",
            "Epoch: 45, Step: 391/655, Loss: 2.206327, Accuracy: 18.64%\n",
            "Epoch: 45, Step: 392/655, Loss: 2.206276, Accuracy: 18.61%\n",
            "Epoch: 45, Step: 393/655, Loss: 2.206609, Accuracy: 18.59%\n",
            "Epoch: 45, Step: 394/655, Loss: 2.206636, Accuracy: 18.57%\n",
            "Epoch: 45, Step: 395/655, Loss: 2.207008, Accuracy: 18.54%\n",
            "Epoch: 45, Step: 396/655, Loss: 2.207187, Accuracy: 18.55%\n",
            "Epoch: 45, Step: 397/655, Loss: 2.206743, Accuracy: 18.60%\n",
            "Epoch: 45, Step: 398/655, Loss: 2.206410, Accuracy: 18.62%\n",
            "Epoch: 45, Step: 399/655, Loss: 2.206386, Accuracy: 18.63%\n",
            "Epoch: 45, Step: 400/655, Loss: 2.206674, Accuracy: 18.62%\n",
            "Epoch: 45, Step: 401/655, Loss: 2.206763, Accuracy: 18.63%\n",
            "Epoch: 45, Step: 402/655, Loss: 2.206394, Accuracy: 18.62%\n",
            "Epoch: 45, Step: 403/655, Loss: 2.206660, Accuracy: 18.59%\n",
            "Epoch: 45, Step: 404/655, Loss: 2.206752, Accuracy: 18.59%\n",
            "Epoch: 45, Step: 405/655, Loss: 2.206637, Accuracy: 18.61%\n",
            "Epoch: 45, Step: 406/655, Loss: 2.206688, Accuracy: 18.61%\n",
            "Epoch: 45, Step: 407/655, Loss: 2.206603, Accuracy: 18.63%\n",
            "Epoch: 45, Step: 408/655, Loss: 2.206309, Accuracy: 18.64%\n",
            "Epoch: 45, Step: 409/655, Loss: 2.206214, Accuracy: 18.62%\n",
            "Epoch: 45, Step: 410/655, Loss: 2.206278, Accuracy: 18.61%\n",
            "Epoch: 45, Step: 411/655, Loss: 2.206199, Accuracy: 18.61%\n",
            "Epoch: 45, Step: 412/655, Loss: 2.206235, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 413/655, Loss: 2.206221, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 414/655, Loss: 2.206321, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 415/655, Loss: 2.206551, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 416/655, Loss: 2.206435, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 417/655, Loss: 2.206615, Accuracy: 18.57%\n",
            "Epoch: 45, Step: 418/655, Loss: 2.206858, Accuracy: 18.53%\n",
            "Epoch: 45, Step: 419/655, Loss: 2.207180, Accuracy: 18.50%\n",
            "Epoch: 45, Step: 420/655, Loss: 2.207246, Accuracy: 18.52%\n",
            "Epoch: 45, Step: 421/655, Loss: 2.206840, Accuracy: 18.55%\n",
            "Epoch: 45, Step: 422/655, Loss: 2.206894, Accuracy: 18.52%\n",
            "Epoch: 45, Step: 423/655, Loss: 2.206840, Accuracy: 18.54%\n",
            "Epoch: 45, Step: 424/655, Loss: 2.206705, Accuracy: 18.54%\n",
            "Epoch: 45, Step: 425/655, Loss: 2.206572, Accuracy: 18.56%\n",
            "Epoch: 45, Step: 426/655, Loss: 2.206457, Accuracy: 18.57%\n",
            "Epoch: 45, Step: 427/655, Loss: 2.206208, Accuracy: 18.59%\n",
            "Epoch: 45, Step: 428/655, Loss: 2.206332, Accuracy: 18.60%\n",
            "Epoch: 45, Step: 429/655, Loss: 2.206079, Accuracy: 18.59%\n",
            "Epoch: 45, Step: 430/655, Loss: 2.205888, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 431/655, Loss: 2.205956, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 432/655, Loss: 2.205925, Accuracy: 18.56%\n",
            "Epoch: 45, Step: 433/655, Loss: 2.206034, Accuracy: 18.54%\n",
            "Epoch: 45, Step: 434/655, Loss: 2.205982, Accuracy: 18.56%\n",
            "Epoch: 45, Step: 435/655, Loss: 2.206217, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 436/655, Loss: 2.206034, Accuracy: 18.60%\n",
            "Epoch: 45, Step: 437/655, Loss: 2.206001, Accuracy: 18.59%\n",
            "Epoch: 45, Step: 438/655, Loss: 2.205724, Accuracy: 18.60%\n",
            "Epoch: 45, Step: 439/655, Loss: 2.205721, Accuracy: 18.60%\n",
            "Epoch: 45, Step: 440/655, Loss: 2.205736, Accuracy: 18.61%\n",
            "Epoch: 45, Step: 441/655, Loss: 2.205806, Accuracy: 18.59%\n",
            "Epoch: 45, Step: 442/655, Loss: 2.206045, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 443/655, Loss: 2.206124, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 444/655, Loss: 2.206121, Accuracy: 18.57%\n",
            "Epoch: 45, Step: 445/655, Loss: 2.206108, Accuracy: 18.55%\n",
            "Epoch: 45, Step: 446/655, Loss: 2.206291, Accuracy: 18.52%\n",
            "Epoch: 45, Step: 447/655, Loss: 2.206223, Accuracy: 18.55%\n",
            "Epoch: 45, Step: 448/655, Loss: 2.206419, Accuracy: 18.55%\n",
            "Epoch: 45, Step: 449/655, Loss: 2.206370, Accuracy: 18.54%\n",
            "Epoch: 45, Step: 450/655, Loss: 2.206637, Accuracy: 18.52%\n",
            "Epoch: 45, Step: 451/655, Loss: 2.206880, Accuracy: 18.51%\n",
            "Epoch: 45, Step: 452/655, Loss: 2.206953, Accuracy: 18.52%\n",
            "Epoch: 45, Step: 453/655, Loss: 2.207279, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 454/655, Loss: 2.207530, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 455/655, Loss: 2.207689, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 456/655, Loss: 2.207843, Accuracy: 18.43%\n",
            "Epoch: 45, Step: 457/655, Loss: 2.207865, Accuracy: 18.42%\n",
            "Epoch: 45, Step: 458/655, Loss: 2.208124, Accuracy: 18.41%\n",
            "Epoch: 45, Step: 459/655, Loss: 2.208072, Accuracy: 18.42%\n",
            "Epoch: 45, Step: 460/655, Loss: 2.208118, Accuracy: 18.40%\n",
            "Epoch: 45, Step: 461/655, Loss: 2.208115, Accuracy: 18.38%\n",
            "Epoch: 45, Step: 462/655, Loss: 2.208121, Accuracy: 18.38%\n",
            "Epoch: 45, Step: 463/655, Loss: 2.208190, Accuracy: 18.38%\n",
            "Epoch: 45, Step: 464/655, Loss: 2.208157, Accuracy: 18.37%\n",
            "Epoch: 45, Step: 465/655, Loss: 2.207886, Accuracy: 18.41%\n",
            "Epoch: 45, Step: 466/655, Loss: 2.207579, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 467/655, Loss: 2.207692, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 468/655, Loss: 2.207773, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 469/655, Loss: 2.207912, Accuracy: 18.44%\n",
            "Epoch: 45, Step: 470/655, Loss: 2.207870, Accuracy: 18.44%\n",
            "Epoch: 45, Step: 471/655, Loss: 2.207647, Accuracy: 18.43%\n",
            "Epoch: 45, Step: 472/655, Loss: 2.207688, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 473/655, Loss: 2.207605, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 474/655, Loss: 2.207731, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 475/655, Loss: 2.207583, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 476/655, Loss: 2.207631, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 477/655, Loss: 2.207913, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 478/655, Loss: 2.208079, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 479/655, Loss: 2.208059, Accuracy: 18.43%\n",
            "Epoch: 45, Step: 480/655, Loss: 2.208047, Accuracy: 18.43%\n",
            "Epoch: 45, Step: 481/655, Loss: 2.208067, Accuracy: 18.44%\n",
            "Epoch: 45, Step: 482/655, Loss: 2.208016, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 483/655, Loss: 2.207840, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 484/655, Loss: 2.207749, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 485/655, Loss: 2.207758, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 486/655, Loss: 2.207749, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 487/655, Loss: 2.207904, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 488/655, Loss: 2.208023, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 489/655, Loss: 2.207987, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 490/655, Loss: 2.207763, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 491/655, Loss: 2.207655, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 492/655, Loss: 2.207920, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 493/655, Loss: 2.207960, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 494/655, Loss: 2.207736, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 495/655, Loss: 2.207722, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 496/655, Loss: 2.207441, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 497/655, Loss: 2.207387, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 498/655, Loss: 2.207337, Accuracy: 18.51%\n",
            "Epoch: 45, Step: 499/655, Loss: 2.207575, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 500/655, Loss: 2.207294, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 501/655, Loss: 2.207094, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 502/655, Loss: 2.207143, Accuracy: 18.51%\n",
            "Epoch: 45, Step: 503/655, Loss: 2.206835, Accuracy: 18.54%\n",
            "Epoch: 45, Step: 504/655, Loss: 2.206940, Accuracy: 18.51%\n",
            "Epoch: 45, Step: 505/655, Loss: 2.207028, Accuracy: 18.50%\n",
            "Epoch: 45, Step: 506/655, Loss: 2.206764, Accuracy: 18.52%\n",
            "Epoch: 45, Step: 507/655, Loss: 2.206673, Accuracy: 18.52%\n",
            "Epoch: 45, Step: 508/655, Loss: 2.206890, Accuracy: 18.50%\n",
            "Epoch: 45, Step: 509/655, Loss: 2.206896, Accuracy: 18.51%\n",
            "Epoch: 45, Step: 510/655, Loss: 2.206957, Accuracy: 18.50%\n",
            "Epoch: 45, Step: 511/655, Loss: 2.206923, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 512/655, Loss: 2.207218, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 513/655, Loss: 2.207230, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 514/655, Loss: 2.207307, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 515/655, Loss: 2.207100, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 516/655, Loss: 2.207318, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 517/655, Loss: 2.207255, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 518/655, Loss: 2.207499, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 519/655, Loss: 2.207354, Accuracy: 18.44%\n",
            "Epoch: 45, Step: 520/655, Loss: 2.207479, Accuracy: 18.44%\n",
            "Epoch: 45, Step: 521/655, Loss: 2.207348, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 522/655, Loss: 2.207235, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 523/655, Loss: 2.207185, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 524/655, Loss: 2.207620, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 525/655, Loss: 2.207646, Accuracy: 18.50%\n",
            "Epoch: 45, Step: 526/655, Loss: 2.207492, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 527/655, Loss: 2.207555, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 528/655, Loss: 2.207502, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 529/655, Loss: 2.207643, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 530/655, Loss: 2.207457, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 531/655, Loss: 2.207502, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 532/655, Loss: 2.207604, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 533/655, Loss: 2.207639, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 534/655, Loss: 2.207899, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 535/655, Loss: 2.208047, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 536/655, Loss: 2.207880, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 537/655, Loss: 2.207993, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 538/655, Loss: 2.207927, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 539/655, Loss: 2.207933, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 540/655, Loss: 2.208089, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 541/655, Loss: 2.208043, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 542/655, Loss: 2.208294, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 543/655, Loss: 2.208123, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 544/655, Loss: 2.208017, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 545/655, Loss: 2.208260, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 546/655, Loss: 2.208222, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 547/655, Loss: 2.208117, Accuracy: 18.50%\n",
            "Epoch: 45, Step: 548/655, Loss: 2.208190, Accuracy: 18.50%\n",
            "Epoch: 45, Step: 549/655, Loss: 2.208136, Accuracy: 18.50%\n",
            "Epoch: 45, Step: 550/655, Loss: 2.208168, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 551/655, Loss: 2.208338, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 552/655, Loss: 2.208357, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 553/655, Loss: 2.208444, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 554/655, Loss: 2.208325, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 555/655, Loss: 2.208315, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 556/655, Loss: 2.208534, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 557/655, Loss: 2.208624, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 558/655, Loss: 2.208682, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 559/655, Loss: 2.208889, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 560/655, Loss: 2.209184, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 561/655, Loss: 2.209309, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 562/655, Loss: 2.209586, Accuracy: 18.44%\n",
            "Epoch: 45, Step: 563/655, Loss: 2.209428, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 564/655, Loss: 2.209654, Accuracy: 18.44%\n",
            "Epoch: 45, Step: 565/655, Loss: 2.209596, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 566/655, Loss: 2.209346, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 567/655, Loss: 2.209578, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 568/655, Loss: 2.209394, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 569/655, Loss: 2.209464, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 570/655, Loss: 2.209336, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 571/655, Loss: 2.209694, Accuracy: 18.44%\n",
            "Epoch: 45, Step: 572/655, Loss: 2.209711, Accuracy: 18.43%\n",
            "Epoch: 45, Step: 573/655, Loss: 2.209462, Accuracy: 18.42%\n",
            "Epoch: 45, Step: 574/655, Loss: 2.209355, Accuracy: 18.42%\n",
            "Epoch: 45, Step: 575/655, Loss: 2.209339, Accuracy: 18.41%\n",
            "Epoch: 45, Step: 576/655, Loss: 2.209090, Accuracy: 18.39%\n",
            "Epoch: 45, Step: 577/655, Loss: 2.209127, Accuracy: 18.40%\n",
            "Epoch: 45, Step: 578/655, Loss: 2.209043, Accuracy: 18.41%\n",
            "Epoch: 45, Step: 579/655, Loss: 2.208977, Accuracy: 18.40%\n",
            "Epoch: 45, Step: 580/655, Loss: 2.209217, Accuracy: 18.41%\n",
            "Epoch: 45, Step: 581/655, Loss: 2.209195, Accuracy: 18.41%\n",
            "Epoch: 45, Step: 582/655, Loss: 2.209270, Accuracy: 18.41%\n",
            "Epoch: 45, Step: 583/655, Loss: 2.209226, Accuracy: 18.42%\n",
            "Epoch: 45, Step: 584/655, Loss: 2.209190, Accuracy: 18.44%\n",
            "Epoch: 45, Step: 585/655, Loss: 2.208998, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 586/655, Loss: 2.209206, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 587/655, Loss: 2.209201, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 588/655, Loss: 2.209030, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 589/655, Loss: 2.209074, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 590/655, Loss: 2.209090, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 591/655, Loss: 2.209119, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 592/655, Loss: 2.209183, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 593/655, Loss: 2.209204, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 594/655, Loss: 2.209053, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 595/655, Loss: 2.208853, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 596/655, Loss: 2.209026, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 597/655, Loss: 2.208808, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 598/655, Loss: 2.208718, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 599/655, Loss: 2.208800, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 600/655, Loss: 2.208627, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 601/655, Loss: 2.208763, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 602/655, Loss: 2.208610, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 603/655, Loss: 2.208629, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 604/655, Loss: 2.208733, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 605/655, Loss: 2.209189, Accuracy: 18.45%\n",
            "Epoch: 45, Step: 606/655, Loss: 2.209304, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 607/655, Loss: 2.209141, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 608/655, Loss: 2.208915, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 609/655, Loss: 2.208837, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 610/655, Loss: 2.208809, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 611/655, Loss: 2.208723, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 612/655, Loss: 2.208779, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 613/655, Loss: 2.208883, Accuracy: 18.46%\n",
            "Epoch: 45, Step: 614/655, Loss: 2.208716, Accuracy: 18.47%\n",
            "Epoch: 45, Step: 615/655, Loss: 2.208639, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 616/655, Loss: 2.208708, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 617/655, Loss: 2.208571, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 618/655, Loss: 2.208548, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 619/655, Loss: 2.208579, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 620/655, Loss: 2.208551, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 621/655, Loss: 2.208563, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 622/655, Loss: 2.208515, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 623/655, Loss: 2.208556, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 624/655, Loss: 2.208547, Accuracy: 18.48%\n",
            "Epoch: 45, Step: 625/655, Loss: 2.208522, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 626/655, Loss: 2.208398, Accuracy: 18.50%\n",
            "Epoch: 45, Step: 627/655, Loss: 2.208106, Accuracy: 18.51%\n",
            "Epoch: 45, Step: 628/655, Loss: 2.208275, Accuracy: 18.51%\n",
            "Epoch: 45, Step: 629/655, Loss: 2.208260, Accuracy: 18.52%\n",
            "Epoch: 45, Step: 630/655, Loss: 2.208122, Accuracy: 18.51%\n",
            "Epoch: 45, Step: 631/655, Loss: 2.208552, Accuracy: 18.49%\n",
            "Epoch: 45, Step: 632/655, Loss: 2.208308, Accuracy: 18.51%\n",
            "Epoch: 45, Step: 633/655, Loss: 2.208099, Accuracy: 18.53%\n",
            "Epoch: 45, Step: 634/655, Loss: 2.207962, Accuracy: 18.53%\n",
            "Epoch: 45, Step: 635/655, Loss: 2.207910, Accuracy: 18.53%\n",
            "Epoch: 45, Step: 636/655, Loss: 2.207657, Accuracy: 18.54%\n",
            "Epoch: 45, Step: 637/655, Loss: 2.207594, Accuracy: 18.55%\n",
            "Epoch: 45, Step: 638/655, Loss: 2.207788, Accuracy: 18.54%\n",
            "Epoch: 45, Step: 639/655, Loss: 2.207630, Accuracy: 18.54%\n",
            "Epoch: 45, Step: 640/655, Loss: 2.207588, Accuracy: 18.54%\n",
            "Epoch: 45, Step: 641/655, Loss: 2.207632, Accuracy: 18.55%\n",
            "Epoch: 45, Step: 642/655, Loss: 2.207676, Accuracy: 18.56%\n",
            "Epoch: 45, Step: 643/655, Loss: 2.207537, Accuracy: 18.56%\n",
            "Epoch: 45, Step: 644/655, Loss: 2.207236, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 645/655, Loss: 2.207349, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 646/655, Loss: 2.207418, Accuracy: 18.57%\n",
            "Epoch: 45, Step: 647/655, Loss: 2.207503, Accuracy: 18.56%\n",
            "Epoch: 45, Step: 648/655, Loss: 2.207393, Accuracy: 18.57%\n",
            "Epoch: 45, Step: 649/655, Loss: 2.207542, Accuracy: 18.56%\n",
            "Epoch: 45, Step: 650/655, Loss: 2.207471, Accuracy: 18.57%\n",
            "Epoch: 45, Step: 651/655, Loss: 2.207482, Accuracy: 18.57%\n",
            "Epoch: 45, Step: 652/655, Loss: 2.207474, Accuracy: 18.57%\n",
            "Epoch: 45, Step: 653/655, Loss: 2.207638, Accuracy: 18.56%\n",
            "Epoch: 45, Step: 654/655, Loss: 2.207436, Accuracy: 18.58%\n",
            "Epoch: 45, Step: 655/655, Loss: 2.207504, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 1/655, Loss: 2.192447, Accuracy: 18.75%\n",
            "Epoch: 46, Step: 2/655, Loss: 2.161820, Accuracy: 20.31%\n",
            "Epoch: 46, Step: 3/655, Loss: 2.201462, Accuracy: 16.67%\n",
            "Epoch: 46, Step: 4/655, Loss: 2.209913, Accuracy: 17.97%\n",
            "Epoch: 46, Step: 5/655, Loss: 2.221559, Accuracy: 16.88%\n",
            "Epoch: 46, Step: 6/655, Loss: 2.193249, Accuracy: 18.23%\n",
            "Epoch: 46, Step: 7/655, Loss: 2.193639, Accuracy: 18.30%\n",
            "Epoch: 46, Step: 8/655, Loss: 2.182120, Accuracy: 19.53%\n",
            "Epoch: 46, Step: 9/655, Loss: 2.201665, Accuracy: 18.40%\n",
            "Epoch: 46, Step: 10/655, Loss: 2.205738, Accuracy: 18.44%\n",
            "Epoch: 46, Step: 11/655, Loss: 2.192516, Accuracy: 18.18%\n",
            "Epoch: 46, Step: 12/655, Loss: 2.189911, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 13/655, Loss: 2.194749, Accuracy: 17.79%\n",
            "Epoch: 46, Step: 14/655, Loss: 2.201803, Accuracy: 16.96%\n",
            "Epoch: 46, Step: 15/655, Loss: 2.197655, Accuracy: 17.71%\n",
            "Epoch: 46, Step: 16/655, Loss: 2.200285, Accuracy: 17.58%\n",
            "Epoch: 46, Step: 17/655, Loss: 2.202189, Accuracy: 17.65%\n",
            "Epoch: 46, Step: 18/655, Loss: 2.200258, Accuracy: 17.36%\n",
            "Epoch: 46, Step: 19/655, Loss: 2.199589, Accuracy: 16.94%\n",
            "Epoch: 46, Step: 20/655, Loss: 2.199251, Accuracy: 17.03%\n",
            "Epoch: 46, Step: 21/655, Loss: 2.202280, Accuracy: 17.41%\n",
            "Epoch: 46, Step: 22/655, Loss: 2.202918, Accuracy: 17.19%\n",
            "Epoch: 46, Step: 23/655, Loss: 2.206205, Accuracy: 16.98%\n",
            "Epoch: 46, Step: 24/655, Loss: 2.210509, Accuracy: 16.41%\n",
            "Epoch: 46, Step: 25/655, Loss: 2.213737, Accuracy: 16.50%\n",
            "Epoch: 46, Step: 26/655, Loss: 2.211776, Accuracy: 16.71%\n",
            "Epoch: 46, Step: 27/655, Loss: 2.209759, Accuracy: 16.78%\n",
            "Epoch: 46, Step: 28/655, Loss: 2.209137, Accuracy: 16.85%\n",
            "Epoch: 46, Step: 29/655, Loss: 2.206062, Accuracy: 17.35%\n",
            "Epoch: 46, Step: 30/655, Loss: 2.207046, Accuracy: 17.40%\n",
            "Epoch: 46, Step: 31/655, Loss: 2.207834, Accuracy: 17.64%\n",
            "Epoch: 46, Step: 32/655, Loss: 2.207534, Accuracy: 17.68%\n",
            "Epoch: 46, Step: 33/655, Loss: 2.211811, Accuracy: 17.14%\n",
            "Epoch: 46, Step: 34/655, Loss: 2.210865, Accuracy: 17.46%\n",
            "Epoch: 46, Step: 35/655, Loss: 2.214738, Accuracy: 17.14%\n",
            "Epoch: 46, Step: 36/655, Loss: 2.218011, Accuracy: 16.93%\n",
            "Epoch: 46, Step: 37/655, Loss: 2.217353, Accuracy: 16.98%\n",
            "Epoch: 46, Step: 38/655, Loss: 2.220865, Accuracy: 17.02%\n",
            "Epoch: 46, Step: 39/655, Loss: 2.220123, Accuracy: 17.07%\n",
            "Epoch: 46, Step: 40/655, Loss: 2.218265, Accuracy: 17.19%\n",
            "Epoch: 46, Step: 41/655, Loss: 2.216652, Accuracy: 17.38%\n",
            "Epoch: 46, Step: 42/655, Loss: 2.217073, Accuracy: 17.49%\n",
            "Epoch: 46, Step: 43/655, Loss: 2.218204, Accuracy: 17.44%\n",
            "Epoch: 46, Step: 44/655, Loss: 2.218656, Accuracy: 17.40%\n",
            "Epoch: 46, Step: 45/655, Loss: 2.217527, Accuracy: 17.43%\n",
            "Epoch: 46, Step: 46/655, Loss: 2.217371, Accuracy: 17.60%\n",
            "Epoch: 46, Step: 47/655, Loss: 2.217703, Accuracy: 17.55%\n",
            "Epoch: 46, Step: 48/655, Loss: 2.216280, Accuracy: 17.64%\n",
            "Epoch: 46, Step: 49/655, Loss: 2.216021, Accuracy: 17.60%\n",
            "Epoch: 46, Step: 50/655, Loss: 2.214636, Accuracy: 17.56%\n",
            "Epoch: 46, Step: 51/655, Loss: 2.215429, Accuracy: 17.65%\n",
            "Epoch: 46, Step: 52/655, Loss: 2.215277, Accuracy: 17.67%\n",
            "Epoch: 46, Step: 53/655, Loss: 2.216672, Accuracy: 17.39%\n",
            "Epoch: 46, Step: 54/655, Loss: 2.215151, Accuracy: 17.53%\n",
            "Epoch: 46, Step: 55/655, Loss: 2.214965, Accuracy: 17.56%\n",
            "Epoch: 46, Step: 56/655, Loss: 2.214031, Accuracy: 17.69%\n",
            "Epoch: 46, Step: 57/655, Loss: 2.213697, Accuracy: 17.76%\n",
            "Epoch: 46, Step: 58/655, Loss: 2.211966, Accuracy: 17.62%\n",
            "Epoch: 46, Step: 59/655, Loss: 2.211996, Accuracy: 17.69%\n",
            "Epoch: 46, Step: 60/655, Loss: 2.211894, Accuracy: 17.76%\n",
            "Epoch: 46, Step: 61/655, Loss: 2.211654, Accuracy: 17.78%\n",
            "Epoch: 46, Step: 62/655, Loss: 2.211091, Accuracy: 17.84%\n",
            "Epoch: 46, Step: 63/655, Loss: 2.210855, Accuracy: 17.81%\n",
            "Epoch: 46, Step: 64/655, Loss: 2.209438, Accuracy: 17.72%\n",
            "Epoch: 46, Step: 65/655, Loss: 2.208606, Accuracy: 17.74%\n",
            "Epoch: 46, Step: 66/655, Loss: 2.208933, Accuracy: 17.71%\n",
            "Epoch: 46, Step: 67/655, Loss: 2.209028, Accuracy: 17.77%\n",
            "Epoch: 46, Step: 68/655, Loss: 2.208187, Accuracy: 17.83%\n",
            "Epoch: 46, Step: 69/655, Loss: 2.207646, Accuracy: 17.98%\n",
            "Epoch: 46, Step: 70/655, Loss: 2.209010, Accuracy: 17.95%\n",
            "Epoch: 46, Step: 71/655, Loss: 2.210200, Accuracy: 17.87%\n",
            "Epoch: 46, Step: 72/655, Loss: 2.211803, Accuracy: 17.88%\n",
            "Epoch: 46, Step: 73/655, Loss: 2.211436, Accuracy: 17.94%\n",
            "Epoch: 46, Step: 74/655, Loss: 2.211359, Accuracy: 17.99%\n",
            "Epoch: 46, Step: 75/655, Loss: 2.211208, Accuracy: 18.00%\n",
            "Epoch: 46, Step: 76/655, Loss: 2.210390, Accuracy: 17.93%\n",
            "Epoch: 46, Step: 77/655, Loss: 2.210271, Accuracy: 17.82%\n",
            "Epoch: 46, Step: 78/655, Loss: 2.209868, Accuracy: 17.75%\n",
            "Epoch: 46, Step: 79/655, Loss: 2.208151, Accuracy: 17.84%\n",
            "Epoch: 46, Step: 80/655, Loss: 2.208185, Accuracy: 17.85%\n",
            "Epoch: 46, Step: 81/655, Loss: 2.208437, Accuracy: 17.94%\n",
            "Epoch: 46, Step: 82/655, Loss: 2.208480, Accuracy: 17.95%\n",
            "Epoch: 46, Step: 83/655, Loss: 2.208553, Accuracy: 18.00%\n",
            "Epoch: 46, Step: 84/655, Loss: 2.209851, Accuracy: 17.93%\n",
            "Epoch: 46, Step: 85/655, Loss: 2.211438, Accuracy: 17.87%\n",
            "Epoch: 46, Step: 86/655, Loss: 2.210072, Accuracy: 17.81%\n",
            "Epoch: 46, Step: 87/655, Loss: 2.209295, Accuracy: 17.85%\n",
            "Epoch: 46, Step: 88/655, Loss: 2.210330, Accuracy: 17.83%\n",
            "Epoch: 46, Step: 89/655, Loss: 2.208604, Accuracy: 17.91%\n",
            "Epoch: 46, Step: 90/655, Loss: 2.209557, Accuracy: 17.85%\n",
            "Epoch: 46, Step: 91/655, Loss: 2.209954, Accuracy: 17.89%\n",
            "Epoch: 46, Step: 92/655, Loss: 2.208723, Accuracy: 17.80%\n",
            "Epoch: 46, Step: 93/655, Loss: 2.208271, Accuracy: 17.84%\n",
            "Epoch: 46, Step: 94/655, Loss: 2.208939, Accuracy: 17.85%\n",
            "Epoch: 46, Step: 95/655, Loss: 2.209302, Accuracy: 17.80%\n",
            "Epoch: 46, Step: 96/655, Loss: 2.209207, Accuracy: 17.74%\n",
            "Epoch: 46, Step: 97/655, Loss: 2.208787, Accuracy: 17.69%\n",
            "Epoch: 46, Step: 98/655, Loss: 2.209120, Accuracy: 17.63%\n",
            "Epoch: 46, Step: 99/655, Loss: 2.207758, Accuracy: 17.74%\n",
            "Epoch: 46, Step: 100/655, Loss: 2.207861, Accuracy: 17.69%\n",
            "Epoch: 46, Step: 101/655, Loss: 2.208319, Accuracy: 17.70%\n",
            "Epoch: 46, Step: 102/655, Loss: 2.207255, Accuracy: 17.71%\n",
            "Epoch: 46, Step: 103/655, Loss: 2.208444, Accuracy: 17.72%\n",
            "Epoch: 46, Step: 104/655, Loss: 2.207388, Accuracy: 17.79%\n",
            "Epoch: 46, Step: 105/655, Loss: 2.207404, Accuracy: 17.89%\n",
            "Epoch: 46, Step: 106/655, Loss: 2.207101, Accuracy: 17.92%\n",
            "Epoch: 46, Step: 107/655, Loss: 2.207256, Accuracy: 17.96%\n",
            "Epoch: 46, Step: 108/655, Loss: 2.207802, Accuracy: 17.94%\n",
            "Epoch: 46, Step: 109/655, Loss: 2.208889, Accuracy: 17.89%\n",
            "Epoch: 46, Step: 110/655, Loss: 2.209545, Accuracy: 17.90%\n",
            "Epoch: 46, Step: 111/655, Loss: 2.211175, Accuracy: 17.82%\n",
            "Epoch: 46, Step: 112/655, Loss: 2.210404, Accuracy: 17.83%\n",
            "Epoch: 46, Step: 113/655, Loss: 2.209614, Accuracy: 17.87%\n",
            "Epoch: 46, Step: 114/655, Loss: 2.209470, Accuracy: 17.82%\n",
            "Epoch: 46, Step: 115/655, Loss: 2.209218, Accuracy: 17.77%\n",
            "Epoch: 46, Step: 116/655, Loss: 2.208974, Accuracy: 17.75%\n",
            "Epoch: 46, Step: 117/655, Loss: 2.209441, Accuracy: 17.82%\n",
            "Epoch: 46, Step: 118/655, Loss: 2.208917, Accuracy: 17.82%\n",
            "Epoch: 46, Step: 119/655, Loss: 2.208138, Accuracy: 17.83%\n",
            "Epoch: 46, Step: 120/655, Loss: 2.208757, Accuracy: 17.84%\n",
            "Epoch: 46, Step: 121/655, Loss: 2.209521, Accuracy: 17.79%\n",
            "Epoch: 46, Step: 122/655, Loss: 2.210158, Accuracy: 17.70%\n",
            "Epoch: 46, Step: 123/655, Loss: 2.210628, Accuracy: 17.63%\n",
            "Epoch: 46, Step: 124/655, Loss: 2.211576, Accuracy: 17.62%\n",
            "Epoch: 46, Step: 125/655, Loss: 2.211491, Accuracy: 17.60%\n",
            "Epoch: 46, Step: 126/655, Loss: 2.211695, Accuracy: 17.56%\n",
            "Epoch: 46, Step: 127/655, Loss: 2.211771, Accuracy: 17.47%\n",
            "Epoch: 46, Step: 128/655, Loss: 2.212558, Accuracy: 17.38%\n",
            "Epoch: 46, Step: 129/655, Loss: 2.213243, Accuracy: 17.37%\n",
            "Epoch: 46, Step: 130/655, Loss: 2.213234, Accuracy: 17.33%\n",
            "Epoch: 46, Step: 131/655, Loss: 2.213023, Accuracy: 17.44%\n",
            "Epoch: 46, Step: 132/655, Loss: 2.214542, Accuracy: 17.40%\n",
            "Epoch: 46, Step: 133/655, Loss: 2.214048, Accuracy: 17.36%\n",
            "Epoch: 46, Step: 134/655, Loss: 2.214063, Accuracy: 17.44%\n",
            "Epoch: 46, Step: 135/655, Loss: 2.213837, Accuracy: 17.48%\n",
            "Epoch: 46, Step: 136/655, Loss: 2.213503, Accuracy: 17.53%\n",
            "Epoch: 46, Step: 137/655, Loss: 2.212692, Accuracy: 17.66%\n",
            "Epoch: 46, Step: 138/655, Loss: 2.212123, Accuracy: 17.66%\n",
            "Epoch: 46, Step: 139/655, Loss: 2.211993, Accuracy: 17.69%\n",
            "Epoch: 46, Step: 140/655, Loss: 2.212601, Accuracy: 17.68%\n",
            "Epoch: 46, Step: 141/655, Loss: 2.212549, Accuracy: 17.69%\n",
            "Epoch: 46, Step: 142/655, Loss: 2.212496, Accuracy: 17.69%\n",
            "Epoch: 46, Step: 143/655, Loss: 2.212583, Accuracy: 17.70%\n",
            "Epoch: 46, Step: 144/655, Loss: 2.213565, Accuracy: 17.69%\n",
            "Epoch: 46, Step: 145/655, Loss: 2.213503, Accuracy: 17.72%\n",
            "Epoch: 46, Step: 146/655, Loss: 2.214149, Accuracy: 17.66%\n",
            "Epoch: 46, Step: 147/655, Loss: 2.213454, Accuracy: 17.71%\n",
            "Epoch: 46, Step: 148/655, Loss: 2.213978, Accuracy: 17.63%\n",
            "Epoch: 46, Step: 149/655, Loss: 2.213863, Accuracy: 17.74%\n",
            "Epoch: 46, Step: 150/655, Loss: 2.213357, Accuracy: 17.71%\n",
            "Epoch: 46, Step: 151/655, Loss: 2.213903, Accuracy: 17.67%\n",
            "Epoch: 46, Step: 152/655, Loss: 2.214745, Accuracy: 17.66%\n",
            "Epoch: 46, Step: 153/655, Loss: 2.214711, Accuracy: 17.61%\n",
            "Epoch: 46, Step: 154/655, Loss: 2.214805, Accuracy: 17.61%\n",
            "Epoch: 46, Step: 155/655, Loss: 2.214468, Accuracy: 17.62%\n",
            "Epoch: 46, Step: 156/655, Loss: 2.214619, Accuracy: 17.67%\n",
            "Epoch: 46, Step: 157/655, Loss: 2.214762, Accuracy: 17.70%\n",
            "Epoch: 46, Step: 158/655, Loss: 2.214219, Accuracy: 17.72%\n",
            "Epoch: 46, Step: 159/655, Loss: 2.214057, Accuracy: 17.75%\n",
            "Epoch: 46, Step: 160/655, Loss: 2.214442, Accuracy: 17.73%\n",
            "Epoch: 46, Step: 161/655, Loss: 2.214320, Accuracy: 17.72%\n",
            "Epoch: 46, Step: 162/655, Loss: 2.213768, Accuracy: 17.77%\n",
            "Epoch: 46, Step: 163/655, Loss: 2.213531, Accuracy: 17.75%\n",
            "Epoch: 46, Step: 164/655, Loss: 2.213779, Accuracy: 17.70%\n",
            "Epoch: 46, Step: 165/655, Loss: 2.214208, Accuracy: 17.67%\n",
            "Epoch: 46, Step: 166/655, Loss: 2.214657, Accuracy: 17.64%\n",
            "Epoch: 46, Step: 167/655, Loss: 2.214503, Accuracy: 17.66%\n",
            "Epoch: 46, Step: 168/655, Loss: 2.214385, Accuracy: 17.71%\n",
            "Epoch: 46, Step: 169/655, Loss: 2.214558, Accuracy: 17.66%\n",
            "Epoch: 46, Step: 170/655, Loss: 2.214943, Accuracy: 17.70%\n",
            "Epoch: 46, Step: 171/655, Loss: 2.214844, Accuracy: 17.71%\n",
            "Epoch: 46, Step: 172/655, Loss: 2.214959, Accuracy: 17.71%\n",
            "Epoch: 46, Step: 173/655, Loss: 2.214775, Accuracy: 17.70%\n",
            "Epoch: 46, Step: 174/655, Loss: 2.215104, Accuracy: 17.64%\n",
            "Epoch: 46, Step: 175/655, Loss: 2.214529, Accuracy: 17.66%\n",
            "Epoch: 46, Step: 176/655, Loss: 2.214863, Accuracy: 17.61%\n",
            "Epoch: 46, Step: 177/655, Loss: 2.215309, Accuracy: 17.64%\n",
            "Epoch: 46, Step: 178/655, Loss: 2.215100, Accuracy: 17.61%\n",
            "Epoch: 46, Step: 179/655, Loss: 2.215591, Accuracy: 17.62%\n",
            "Epoch: 46, Step: 180/655, Loss: 2.215398, Accuracy: 17.64%\n",
            "Epoch: 46, Step: 181/655, Loss: 2.215627, Accuracy: 17.65%\n",
            "Epoch: 46, Step: 182/655, Loss: 2.215442, Accuracy: 17.69%\n",
            "Epoch: 46, Step: 183/655, Loss: 2.214797, Accuracy: 17.76%\n",
            "Epoch: 46, Step: 184/655, Loss: 2.215628, Accuracy: 17.71%\n",
            "Epoch: 46, Step: 185/655, Loss: 2.215810, Accuracy: 17.70%\n",
            "Epoch: 46, Step: 186/655, Loss: 2.216162, Accuracy: 17.69%\n",
            "Epoch: 46, Step: 187/655, Loss: 2.216849, Accuracy: 17.68%\n",
            "Epoch: 46, Step: 188/655, Loss: 2.216697, Accuracy: 17.77%\n",
            "Epoch: 46, Step: 189/655, Loss: 2.216370, Accuracy: 17.77%\n",
            "Epoch: 46, Step: 190/655, Loss: 2.216298, Accuracy: 17.78%\n",
            "Epoch: 46, Step: 191/655, Loss: 2.215912, Accuracy: 17.78%\n",
            "Epoch: 46, Step: 192/655, Loss: 2.215370, Accuracy: 17.85%\n",
            "Epoch: 46, Step: 193/655, Loss: 2.215673, Accuracy: 17.86%\n",
            "Epoch: 46, Step: 194/655, Loss: 2.215633, Accuracy: 17.86%\n",
            "Epoch: 46, Step: 195/655, Loss: 2.215958, Accuracy: 17.92%\n",
            "Epoch: 46, Step: 196/655, Loss: 2.215978, Accuracy: 17.97%\n",
            "Epoch: 46, Step: 197/655, Loss: 2.216417, Accuracy: 17.93%\n",
            "Epoch: 46, Step: 198/655, Loss: 2.216280, Accuracy: 17.95%\n",
            "Epoch: 46, Step: 199/655, Loss: 2.216160, Accuracy: 17.92%\n",
            "Epoch: 46, Step: 200/655, Loss: 2.216086, Accuracy: 17.89%\n",
            "Epoch: 46, Step: 201/655, Loss: 2.215187, Accuracy: 17.93%\n",
            "Epoch: 46, Step: 202/655, Loss: 2.215718, Accuracy: 17.91%\n",
            "Epoch: 46, Step: 203/655, Loss: 2.215269, Accuracy: 17.92%\n",
            "Epoch: 46, Step: 204/655, Loss: 2.215032, Accuracy: 17.94%\n",
            "Epoch: 46, Step: 205/655, Loss: 2.214521, Accuracy: 17.97%\n",
            "Epoch: 46, Step: 206/655, Loss: 2.214422, Accuracy: 17.98%\n",
            "Epoch: 46, Step: 207/655, Loss: 2.214363, Accuracy: 17.95%\n",
            "Epoch: 46, Step: 208/655, Loss: 2.214097, Accuracy: 17.97%\n",
            "Epoch: 46, Step: 209/655, Loss: 2.213916, Accuracy: 17.99%\n",
            "Epoch: 46, Step: 210/655, Loss: 2.213240, Accuracy: 18.02%\n",
            "Epoch: 46, Step: 211/655, Loss: 2.213316, Accuracy: 18.02%\n",
            "Epoch: 46, Step: 212/655, Loss: 2.212967, Accuracy: 18.06%\n",
            "Epoch: 46, Step: 213/655, Loss: 2.212491, Accuracy: 18.06%\n",
            "Epoch: 46, Step: 214/655, Loss: 2.212379, Accuracy: 18.06%\n",
            "Epoch: 46, Step: 215/655, Loss: 2.212404, Accuracy: 18.10%\n",
            "Epoch: 46, Step: 216/655, Loss: 2.212687, Accuracy: 18.10%\n",
            "Epoch: 46, Step: 217/655, Loss: 2.212494, Accuracy: 18.13%\n",
            "Epoch: 46, Step: 218/655, Loss: 2.212422, Accuracy: 18.10%\n",
            "Epoch: 46, Step: 219/655, Loss: 2.211970, Accuracy: 18.15%\n",
            "Epoch: 46, Step: 220/655, Loss: 2.212113, Accuracy: 18.20%\n",
            "Epoch: 46, Step: 221/655, Loss: 2.212370, Accuracy: 18.16%\n",
            "Epoch: 46, Step: 222/655, Loss: 2.212271, Accuracy: 18.14%\n",
            "Epoch: 46, Step: 223/655, Loss: 2.212800, Accuracy: 18.13%\n",
            "Epoch: 46, Step: 224/655, Loss: 2.212395, Accuracy: 18.14%\n",
            "Epoch: 46, Step: 225/655, Loss: 2.211678, Accuracy: 18.17%\n",
            "Epoch: 46, Step: 226/655, Loss: 2.211304, Accuracy: 18.18%\n",
            "Epoch: 46, Step: 227/655, Loss: 2.211203, Accuracy: 18.25%\n",
            "Epoch: 46, Step: 228/655, Loss: 2.211375, Accuracy: 18.28%\n",
            "Epoch: 46, Step: 229/655, Loss: 2.211329, Accuracy: 18.30%\n",
            "Epoch: 46, Step: 230/655, Loss: 2.211336, Accuracy: 18.32%\n",
            "Epoch: 46, Step: 231/655, Loss: 2.211252, Accuracy: 18.30%\n",
            "Epoch: 46, Step: 232/655, Loss: 2.210793, Accuracy: 18.33%\n",
            "Epoch: 46, Step: 233/655, Loss: 2.210609, Accuracy: 18.36%\n",
            "Epoch: 46, Step: 234/655, Loss: 2.210517, Accuracy: 18.39%\n",
            "Epoch: 46, Step: 235/655, Loss: 2.210618, Accuracy: 18.40%\n",
            "Epoch: 46, Step: 236/655, Loss: 2.210810, Accuracy: 18.41%\n",
            "Epoch: 46, Step: 237/655, Loss: 2.210203, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 238/655, Loss: 2.209906, Accuracy: 18.46%\n",
            "Epoch: 46, Step: 239/655, Loss: 2.209536, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 240/655, Loss: 2.209626, Accuracy: 18.46%\n",
            "Epoch: 46, Step: 241/655, Loss: 2.209835, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 242/655, Loss: 2.209579, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 243/655, Loss: 2.209765, Accuracy: 18.43%\n",
            "Epoch: 46, Step: 244/655, Loss: 2.210305, Accuracy: 18.38%\n",
            "Epoch: 46, Step: 245/655, Loss: 2.210397, Accuracy: 18.43%\n",
            "Epoch: 46, Step: 246/655, Loss: 2.209966, Accuracy: 18.47%\n",
            "Epoch: 46, Step: 247/655, Loss: 2.210251, Accuracy: 18.47%\n",
            "Epoch: 46, Step: 248/655, Loss: 2.210271, Accuracy: 18.46%\n",
            "Epoch: 46, Step: 249/655, Loss: 2.210498, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 250/655, Loss: 2.210940, Accuracy: 18.40%\n",
            "Epoch: 46, Step: 251/655, Loss: 2.211213, Accuracy: 18.39%\n",
            "Epoch: 46, Step: 252/655, Loss: 2.211305, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 253/655, Loss: 2.211019, Accuracy: 18.43%\n",
            "Epoch: 46, Step: 254/655, Loss: 2.210962, Accuracy: 18.44%\n",
            "Epoch: 46, Step: 255/655, Loss: 2.211047, Accuracy: 18.44%\n",
            "Epoch: 46, Step: 256/655, Loss: 2.211695, Accuracy: 18.38%\n",
            "Epoch: 46, Step: 257/655, Loss: 2.211540, Accuracy: 18.39%\n",
            "Epoch: 46, Step: 258/655, Loss: 2.211539, Accuracy: 18.36%\n",
            "Epoch: 46, Step: 259/655, Loss: 2.212169, Accuracy: 18.34%\n",
            "Epoch: 46, Step: 260/655, Loss: 2.212707, Accuracy: 18.34%\n",
            "Epoch: 46, Step: 261/655, Loss: 2.212952, Accuracy: 18.35%\n",
            "Epoch: 46, Step: 262/655, Loss: 2.212496, Accuracy: 18.38%\n",
            "Epoch: 46, Step: 263/655, Loss: 2.212341, Accuracy: 18.39%\n",
            "Epoch: 46, Step: 264/655, Loss: 2.212095, Accuracy: 18.39%\n",
            "Epoch: 46, Step: 265/655, Loss: 2.212422, Accuracy: 18.40%\n",
            "Epoch: 46, Step: 266/655, Loss: 2.212427, Accuracy: 18.41%\n",
            "Epoch: 46, Step: 267/655, Loss: 2.212497, Accuracy: 18.41%\n",
            "Epoch: 46, Step: 268/655, Loss: 2.212771, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 269/655, Loss: 2.212488, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 270/655, Loss: 2.212713, Accuracy: 18.46%\n",
            "Epoch: 46, Step: 271/655, Loss: 2.212600, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 272/655, Loss: 2.212302, Accuracy: 18.46%\n",
            "Epoch: 46, Step: 273/655, Loss: 2.212194, Accuracy: 18.46%\n",
            "Epoch: 46, Step: 274/655, Loss: 2.212098, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 275/655, Loss: 2.212166, Accuracy: 18.44%\n",
            "Epoch: 46, Step: 276/655, Loss: 2.212022, Accuracy: 18.46%\n",
            "Epoch: 46, Step: 277/655, Loss: 2.212371, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 278/655, Loss: 2.212640, Accuracy: 18.41%\n",
            "Epoch: 46, Step: 279/655, Loss: 2.212210, Accuracy: 18.44%\n",
            "Epoch: 46, Step: 280/655, Loss: 2.212142, Accuracy: 18.44%\n",
            "Epoch: 46, Step: 281/655, Loss: 2.212645, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 282/655, Loss: 2.213199, Accuracy: 18.41%\n",
            "Epoch: 46, Step: 283/655, Loss: 2.213270, Accuracy: 18.40%\n",
            "Epoch: 46, Step: 284/655, Loss: 2.212828, Accuracy: 18.39%\n",
            "Epoch: 46, Step: 285/655, Loss: 2.212557, Accuracy: 18.39%\n",
            "Epoch: 46, Step: 286/655, Loss: 2.212404, Accuracy: 18.38%\n",
            "Epoch: 46, Step: 287/655, Loss: 2.212488, Accuracy: 18.37%\n",
            "Epoch: 46, Step: 288/655, Loss: 2.211790, Accuracy: 18.41%\n",
            "Epoch: 46, Step: 289/655, Loss: 2.212155, Accuracy: 18.40%\n",
            "Epoch: 46, Step: 290/655, Loss: 2.211981, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 291/655, Loss: 2.211932, Accuracy: 18.43%\n",
            "Epoch: 46, Step: 292/655, Loss: 2.211782, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 293/655, Loss: 2.211558, Accuracy: 18.47%\n",
            "Epoch: 46, Step: 294/655, Loss: 2.211467, Accuracy: 18.47%\n",
            "Epoch: 46, Step: 295/655, Loss: 2.211692, Accuracy: 18.44%\n",
            "Epoch: 46, Step: 296/655, Loss: 2.211456, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 297/655, Loss: 2.210845, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 298/655, Loss: 2.210495, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 299/655, Loss: 2.210438, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 300/655, Loss: 2.210415, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 301/655, Loss: 2.210289, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 302/655, Loss: 2.210407, Accuracy: 18.51%\n",
            "Epoch: 46, Step: 303/655, Loss: 2.210142, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 304/655, Loss: 2.209942, Accuracy: 18.55%\n",
            "Epoch: 46, Step: 305/655, Loss: 2.210167, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 306/655, Loss: 2.209661, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 307/655, Loss: 2.209813, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 308/655, Loss: 2.209584, Accuracy: 18.60%\n",
            "Epoch: 46, Step: 309/655, Loss: 2.209650, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 310/655, Loss: 2.209423, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 311/655, Loss: 2.209695, Accuracy: 18.60%\n",
            "Epoch: 46, Step: 312/655, Loss: 2.209504, Accuracy: 18.61%\n",
            "Epoch: 46, Step: 313/655, Loss: 2.209803, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 314/655, Loss: 2.210482, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 315/655, Loss: 2.210712, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 316/655, Loss: 2.210839, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 317/655, Loss: 2.210776, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 318/655, Loss: 2.210695, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 319/655, Loss: 2.210327, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 320/655, Loss: 2.210342, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 321/655, Loss: 2.210565, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 322/655, Loss: 2.210152, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 323/655, Loss: 2.209859, Accuracy: 18.61%\n",
            "Epoch: 46, Step: 324/655, Loss: 2.209694, Accuracy: 18.64%\n",
            "Epoch: 46, Step: 325/655, Loss: 2.209463, Accuracy: 18.66%\n",
            "Epoch: 46, Step: 326/655, Loss: 2.209361, Accuracy: 18.66%\n",
            "Epoch: 46, Step: 327/655, Loss: 2.209205, Accuracy: 18.66%\n",
            "Epoch: 46, Step: 328/655, Loss: 2.208997, Accuracy: 18.68%\n",
            "Epoch: 46, Step: 329/655, Loss: 2.209189, Accuracy: 18.66%\n",
            "Epoch: 46, Step: 330/655, Loss: 2.209098, Accuracy: 18.66%\n",
            "Epoch: 46, Step: 331/655, Loss: 2.209581, Accuracy: 18.64%\n",
            "Epoch: 46, Step: 332/655, Loss: 2.209812, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 333/655, Loss: 2.209716, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 334/655, Loss: 2.210074, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 335/655, Loss: 2.209944, Accuracy: 18.65%\n",
            "Epoch: 46, Step: 336/655, Loss: 2.210051, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 337/655, Loss: 2.209844, Accuracy: 18.61%\n",
            "Epoch: 46, Step: 338/655, Loss: 2.209593, Accuracy: 18.61%\n",
            "Epoch: 46, Step: 339/655, Loss: 2.210177, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 340/655, Loss: 2.210406, Accuracy: 18.56%\n",
            "Epoch: 46, Step: 341/655, Loss: 2.210197, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 342/655, Loss: 2.209983, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 343/655, Loss: 2.209797, Accuracy: 18.61%\n",
            "Epoch: 46, Step: 344/655, Loss: 2.210269, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 345/655, Loss: 2.210542, Accuracy: 18.56%\n",
            "Epoch: 46, Step: 346/655, Loss: 2.210680, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 347/655, Loss: 2.210906, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 348/655, Loss: 2.211072, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 349/655, Loss: 2.210937, Accuracy: 18.51%\n",
            "Epoch: 46, Step: 350/655, Loss: 2.211046, Accuracy: 18.51%\n",
            "Epoch: 46, Step: 351/655, Loss: 2.211030, Accuracy: 18.51%\n",
            "Epoch: 46, Step: 352/655, Loss: 2.211281, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 353/655, Loss: 2.211119, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 354/655, Loss: 2.210770, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 355/655, Loss: 2.210808, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 356/655, Loss: 2.211045, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 357/655, Loss: 2.211005, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 358/655, Loss: 2.210687, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 359/655, Loss: 2.210327, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 360/655, Loss: 2.210062, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 361/655, Loss: 2.210016, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 362/655, Loss: 2.209967, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 363/655, Loss: 2.210009, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 364/655, Loss: 2.209678, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 365/655, Loss: 2.209491, Accuracy: 18.55%\n",
            "Epoch: 46, Step: 366/655, Loss: 2.209604, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 367/655, Loss: 2.209658, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 368/655, Loss: 2.209768, Accuracy: 18.51%\n",
            "Epoch: 46, Step: 369/655, Loss: 2.209526, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 370/655, Loss: 2.209502, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 371/655, Loss: 2.209182, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 372/655, Loss: 2.208937, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 373/655, Loss: 2.208902, Accuracy: 18.52%\n",
            "Epoch: 46, Step: 374/655, Loss: 2.209110, Accuracy: 18.52%\n",
            "Epoch: 46, Step: 375/655, Loss: 2.209370, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 376/655, Loss: 2.209523, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 377/655, Loss: 2.209475, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 378/655, Loss: 2.209445, Accuracy: 18.52%\n",
            "Epoch: 46, Step: 379/655, Loss: 2.209975, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 380/655, Loss: 2.209859, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 381/655, Loss: 2.209927, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 382/655, Loss: 2.209971, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 383/655, Loss: 2.209960, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 384/655, Loss: 2.210066, Accuracy: 18.47%\n",
            "Epoch: 46, Step: 385/655, Loss: 2.210227, Accuracy: 18.47%\n",
            "Epoch: 46, Step: 386/655, Loss: 2.210054, Accuracy: 18.47%\n",
            "Epoch: 46, Step: 387/655, Loss: 2.210302, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 388/655, Loss: 2.210255, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 389/655, Loss: 2.210450, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 390/655, Loss: 2.210623, Accuracy: 18.44%\n",
            "Epoch: 46, Step: 391/655, Loss: 2.210671, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 392/655, Loss: 2.211072, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 393/655, Loss: 2.211404, Accuracy: 18.40%\n",
            "Epoch: 46, Step: 394/655, Loss: 2.211504, Accuracy: 18.39%\n",
            "Epoch: 46, Step: 395/655, Loss: 2.210977, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 396/655, Loss: 2.210891, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 397/655, Loss: 2.210747, Accuracy: 18.44%\n",
            "Epoch: 46, Step: 398/655, Loss: 2.210893, Accuracy: 18.44%\n",
            "Epoch: 46, Step: 399/655, Loss: 2.211066, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 400/655, Loss: 2.211153, Accuracy: 18.41%\n",
            "Epoch: 46, Step: 401/655, Loss: 2.211224, Accuracy: 18.41%\n",
            "Epoch: 46, Step: 402/655, Loss: 2.211001, Accuracy: 18.39%\n",
            "Epoch: 46, Step: 403/655, Loss: 2.210935, Accuracy: 18.40%\n",
            "Epoch: 46, Step: 404/655, Loss: 2.210609, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 405/655, Loss: 2.210867, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 406/655, Loss: 2.210982, Accuracy: 18.40%\n",
            "Epoch: 46, Step: 407/655, Loss: 2.210795, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 408/655, Loss: 2.210898, Accuracy: 18.40%\n",
            "Epoch: 46, Step: 409/655, Loss: 2.211197, Accuracy: 18.39%\n",
            "Epoch: 46, Step: 410/655, Loss: 2.211277, Accuracy: 18.40%\n",
            "Epoch: 46, Step: 411/655, Loss: 2.211259, Accuracy: 18.41%\n",
            "Epoch: 46, Step: 412/655, Loss: 2.211143, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 413/655, Loss: 2.210805, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 414/655, Loss: 2.210655, Accuracy: 18.46%\n",
            "Epoch: 46, Step: 415/655, Loss: 2.210728, Accuracy: 18.47%\n",
            "Epoch: 46, Step: 416/655, Loss: 2.210462, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 417/655, Loss: 2.210239, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 418/655, Loss: 2.210328, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 419/655, Loss: 2.210245, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 420/655, Loss: 2.210165, Accuracy: 18.47%\n",
            "Epoch: 46, Step: 421/655, Loss: 2.210137, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 422/655, Loss: 2.210083, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 423/655, Loss: 2.209747, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 424/655, Loss: 2.209512, Accuracy: 18.51%\n",
            "Epoch: 46, Step: 425/655, Loss: 2.209578, Accuracy: 18.51%\n",
            "Epoch: 46, Step: 426/655, Loss: 2.209447, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 427/655, Loss: 2.209418, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 428/655, Loss: 2.209252, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 429/655, Loss: 2.209070, Accuracy: 18.52%\n",
            "Epoch: 46, Step: 430/655, Loss: 2.209289, Accuracy: 18.52%\n",
            "Epoch: 46, Step: 431/655, Loss: 2.209363, Accuracy: 18.52%\n",
            "Epoch: 46, Step: 432/655, Loss: 2.209262, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 433/655, Loss: 2.209397, Accuracy: 18.56%\n",
            "Epoch: 46, Step: 434/655, Loss: 2.209493, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 435/655, Loss: 2.209598, Accuracy: 18.56%\n",
            "Epoch: 46, Step: 436/655, Loss: 2.209724, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 437/655, Loss: 2.210050, Accuracy: 18.52%\n",
            "Epoch: 46, Step: 438/655, Loss: 2.210023, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 439/655, Loss: 2.209937, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 440/655, Loss: 2.209869, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 441/655, Loss: 2.209679, Accuracy: 18.55%\n",
            "Epoch: 46, Step: 442/655, Loss: 2.209545, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 443/655, Loss: 2.209431, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 444/655, Loss: 2.209509, Accuracy: 18.56%\n",
            "Epoch: 46, Step: 445/655, Loss: 2.209540, Accuracy: 18.55%\n",
            "Epoch: 46, Step: 446/655, Loss: 2.209864, Accuracy: 18.51%\n",
            "Epoch: 46, Step: 447/655, Loss: 2.209649, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 448/655, Loss: 2.209565, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 449/655, Loss: 2.209474, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 450/655, Loss: 2.209571, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 451/655, Loss: 2.209425, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 452/655, Loss: 2.209479, Accuracy: 18.52%\n",
            "Epoch: 46, Step: 453/655, Loss: 2.209413, Accuracy: 18.55%\n",
            "Epoch: 46, Step: 454/655, Loss: 2.209359, Accuracy: 18.51%\n",
            "Epoch: 46, Step: 455/655, Loss: 2.209637, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 456/655, Loss: 2.209827, Accuracy: 18.46%\n",
            "Epoch: 46, Step: 457/655, Loss: 2.209767, Accuracy: 18.47%\n",
            "Epoch: 46, Step: 458/655, Loss: 2.209578, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 459/655, Loss: 2.209556, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 460/655, Loss: 2.209659, Accuracy: 18.47%\n",
            "Epoch: 46, Step: 461/655, Loss: 2.209835, Accuracy: 18.46%\n",
            "Epoch: 46, Step: 462/655, Loss: 2.209819, Accuracy: 18.47%\n",
            "Epoch: 46, Step: 463/655, Loss: 2.209687, Accuracy: 18.47%\n",
            "Epoch: 46, Step: 464/655, Loss: 2.209717, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 465/655, Loss: 2.209600, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 466/655, Loss: 2.209592, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 467/655, Loss: 2.209878, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 468/655, Loss: 2.210054, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 469/655, Loss: 2.209751, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 470/655, Loss: 2.209813, Accuracy: 18.52%\n",
            "Epoch: 46, Step: 471/655, Loss: 2.209765, Accuracy: 18.52%\n",
            "Epoch: 46, Step: 472/655, Loss: 2.209885, Accuracy: 18.51%\n",
            "Epoch: 46, Step: 473/655, Loss: 2.210183, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 474/655, Loss: 2.209995, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 475/655, Loss: 2.210187, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 476/655, Loss: 2.210163, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 477/655, Loss: 2.210023, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 478/655, Loss: 2.210154, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 479/655, Loss: 2.210391, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 480/655, Loss: 2.210391, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 481/655, Loss: 2.210296, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 482/655, Loss: 2.210407, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 483/655, Loss: 2.210236, Accuracy: 18.51%\n",
            "Epoch: 46, Step: 484/655, Loss: 2.210152, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 485/655, Loss: 2.210221, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 486/655, Loss: 2.209970, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 487/655, Loss: 2.210127, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 488/655, Loss: 2.209835, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 489/655, Loss: 2.210106, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 490/655, Loss: 2.210301, Accuracy: 18.47%\n",
            "Epoch: 46, Step: 491/655, Loss: 2.210250, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 492/655, Loss: 2.210355, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 493/655, Loss: 2.210018, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 494/655, Loss: 2.209628, Accuracy: 18.51%\n",
            "Epoch: 46, Step: 495/655, Loss: 2.209539, Accuracy: 18.52%\n",
            "Epoch: 46, Step: 496/655, Loss: 2.209443, Accuracy: 18.52%\n",
            "Epoch: 46, Step: 497/655, Loss: 2.209174, Accuracy: 18.55%\n",
            "Epoch: 46, Step: 498/655, Loss: 2.209308, Accuracy: 18.56%\n",
            "Epoch: 46, Step: 499/655, Loss: 2.209269, Accuracy: 18.56%\n",
            "Epoch: 46, Step: 500/655, Loss: 2.209323, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 501/655, Loss: 2.209063, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 502/655, Loss: 2.209033, Accuracy: 18.60%\n",
            "Epoch: 46, Step: 503/655, Loss: 2.209306, Accuracy: 18.60%\n",
            "Epoch: 46, Step: 504/655, Loss: 2.208856, Accuracy: 18.61%\n",
            "Epoch: 46, Step: 505/655, Loss: 2.208538, Accuracy: 18.63%\n",
            "Epoch: 46, Step: 506/655, Loss: 2.208355, Accuracy: 18.63%\n",
            "Epoch: 46, Step: 507/655, Loss: 2.208300, Accuracy: 18.65%\n",
            "Epoch: 46, Step: 508/655, Loss: 2.208237, Accuracy: 18.65%\n",
            "Epoch: 46, Step: 509/655, Loss: 2.208037, Accuracy: 18.64%\n",
            "Epoch: 46, Step: 510/655, Loss: 2.208242, Accuracy: 18.63%\n",
            "Epoch: 46, Step: 511/655, Loss: 2.208130, Accuracy: 18.63%\n",
            "Epoch: 46, Step: 512/655, Loss: 2.208365, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 513/655, Loss: 2.208510, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 514/655, Loss: 2.208579, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 515/655, Loss: 2.208741, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 516/655, Loss: 2.208538, Accuracy: 18.60%\n",
            "Epoch: 46, Step: 517/655, Loss: 2.208587, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 518/655, Loss: 2.208716, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 519/655, Loss: 2.208633, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 520/655, Loss: 2.208695, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 521/655, Loss: 2.208448, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 522/655, Loss: 2.208394, Accuracy: 18.56%\n",
            "Epoch: 46, Step: 523/655, Loss: 2.208581, Accuracy: 18.56%\n",
            "Epoch: 46, Step: 524/655, Loss: 2.208347, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 525/655, Loss: 2.208402, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 526/655, Loss: 2.208377, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 527/655, Loss: 2.208368, Accuracy: 18.52%\n",
            "Epoch: 46, Step: 528/655, Loss: 2.208388, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 529/655, Loss: 2.208521, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 530/655, Loss: 2.208518, Accuracy: 18.51%\n",
            "Epoch: 46, Step: 531/655, Loss: 2.208538, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 532/655, Loss: 2.208466, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 533/655, Loss: 2.208303, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 534/655, Loss: 2.208165, Accuracy: 18.55%\n",
            "Epoch: 46, Step: 535/655, Loss: 2.208563, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 536/655, Loss: 2.208611, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 537/655, Loss: 2.208670, Accuracy: 18.52%\n",
            "Epoch: 46, Step: 538/655, Loss: 2.208672, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 539/655, Loss: 2.208631, Accuracy: 18.55%\n",
            "Epoch: 46, Step: 540/655, Loss: 2.208683, Accuracy: 18.55%\n",
            "Epoch: 46, Step: 541/655, Loss: 2.208697, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 542/655, Loss: 2.208937, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 543/655, Loss: 2.208853, Accuracy: 18.53%\n",
            "Epoch: 46, Step: 544/655, Loss: 2.208997, Accuracy: 18.51%\n",
            "Epoch: 46, Step: 545/655, Loss: 2.209108, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 546/655, Loss: 2.209181, Accuracy: 18.46%\n",
            "Epoch: 46, Step: 547/655, Loss: 2.209339, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 548/655, Loss: 2.209322, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 549/655, Loss: 2.209302, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 550/655, Loss: 2.209291, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 551/655, Loss: 2.209108, Accuracy: 18.46%\n",
            "Epoch: 46, Step: 552/655, Loss: 2.209148, Accuracy: 18.46%\n",
            "Epoch: 46, Step: 553/655, Loss: 2.209059, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 554/655, Loss: 2.209080, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 555/655, Loss: 2.209049, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 556/655, Loss: 2.208963, Accuracy: 18.44%\n",
            "Epoch: 46, Step: 557/655, Loss: 2.209113, Accuracy: 18.43%\n",
            "Epoch: 46, Step: 558/655, Loss: 2.209183, Accuracy: 18.44%\n",
            "Epoch: 46, Step: 559/655, Loss: 2.209244, Accuracy: 18.43%\n",
            "Epoch: 46, Step: 560/655, Loss: 2.209176, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 561/655, Loss: 2.209182, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 562/655, Loss: 2.209274, Accuracy: 18.41%\n",
            "Epoch: 46, Step: 563/655, Loss: 2.209128, Accuracy: 18.42%\n",
            "Epoch: 46, Step: 564/655, Loss: 2.209045, Accuracy: 18.43%\n",
            "Epoch: 46, Step: 565/655, Loss: 2.209084, Accuracy: 18.44%\n",
            "Epoch: 46, Step: 566/655, Loss: 2.208998, Accuracy: 18.44%\n",
            "Epoch: 46, Step: 567/655, Loss: 2.208958, Accuracy: 18.45%\n",
            "Epoch: 46, Step: 568/655, Loss: 2.208913, Accuracy: 18.46%\n",
            "Epoch: 46, Step: 569/655, Loss: 2.208834, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 570/655, Loss: 2.208822, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 571/655, Loss: 2.208829, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 572/655, Loss: 2.208880, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 573/655, Loss: 2.208871, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 574/655, Loss: 2.208892, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 575/655, Loss: 2.209117, Accuracy: 18.47%\n",
            "Epoch: 46, Step: 576/655, Loss: 2.209127, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 577/655, Loss: 2.209099, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 578/655, Loss: 2.208973, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 579/655, Loss: 2.208959, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 580/655, Loss: 2.208730, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 581/655, Loss: 2.208793, Accuracy: 18.48%\n",
            "Epoch: 46, Step: 582/655, Loss: 2.208777, Accuracy: 18.49%\n",
            "Epoch: 46, Step: 583/655, Loss: 2.208620, Accuracy: 18.50%\n",
            "Epoch: 46, Step: 584/655, Loss: 2.208622, Accuracy: 18.51%\n",
            "Epoch: 46, Step: 585/655, Loss: 2.208271, Accuracy: 18.54%\n",
            "Epoch: 46, Step: 586/655, Loss: 2.208188, Accuracy: 18.56%\n",
            "Epoch: 46, Step: 587/655, Loss: 2.208084, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 588/655, Loss: 2.207939, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 589/655, Loss: 2.207946, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 590/655, Loss: 2.208030, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 591/655, Loss: 2.207941, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 592/655, Loss: 2.208192, Accuracy: 18.55%\n",
            "Epoch: 46, Step: 593/655, Loss: 2.207956, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 594/655, Loss: 2.207984, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 595/655, Loss: 2.207856, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 596/655, Loss: 2.207758, Accuracy: 18.60%\n",
            "Epoch: 46, Step: 597/655, Loss: 2.207626, Accuracy: 18.60%\n",
            "Epoch: 46, Step: 598/655, Loss: 2.207686, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 599/655, Loss: 2.207658, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 600/655, Loss: 2.207681, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 601/655, Loss: 2.207638, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 602/655, Loss: 2.207334, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 603/655, Loss: 2.207351, Accuracy: 18.60%\n",
            "Epoch: 46, Step: 604/655, Loss: 2.207221, Accuracy: 18.60%\n",
            "Epoch: 46, Step: 605/655, Loss: 2.207347, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 606/655, Loss: 2.207305, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 607/655, Loss: 2.207398, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 608/655, Loss: 2.207273, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 609/655, Loss: 2.207155, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 610/655, Loss: 2.207193, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 611/655, Loss: 2.207189, Accuracy: 18.59%\n",
            "Epoch: 46, Step: 612/655, Loss: 2.207207, Accuracy: 18.61%\n",
            "Epoch: 46, Step: 613/655, Loss: 2.206985, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 614/655, Loss: 2.206843, Accuracy: 18.63%\n",
            "Epoch: 46, Step: 615/655, Loss: 2.206807, Accuracy: 18.63%\n",
            "Epoch: 46, Step: 616/655, Loss: 2.206968, Accuracy: 18.64%\n",
            "Epoch: 46, Step: 617/655, Loss: 2.206959, Accuracy: 18.63%\n",
            "Epoch: 46, Step: 618/655, Loss: 2.206899, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 619/655, Loss: 2.206908, Accuracy: 18.63%\n",
            "Epoch: 46, Step: 620/655, Loss: 2.206809, Accuracy: 18.63%\n",
            "Epoch: 46, Step: 621/655, Loss: 2.206513, Accuracy: 18.67%\n",
            "Epoch: 46, Step: 622/655, Loss: 2.206506, Accuracy: 18.68%\n",
            "Epoch: 46, Step: 623/655, Loss: 2.206625, Accuracy: 18.67%\n",
            "Epoch: 46, Step: 624/655, Loss: 2.206593, Accuracy: 18.65%\n",
            "Epoch: 46, Step: 625/655, Loss: 2.206725, Accuracy: 18.64%\n",
            "Epoch: 46, Step: 626/655, Loss: 2.206706, Accuracy: 18.63%\n",
            "Epoch: 46, Step: 627/655, Loss: 2.206768, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 628/655, Loss: 2.206937, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 629/655, Loss: 2.206921, Accuracy: 18.61%\n",
            "Epoch: 46, Step: 630/655, Loss: 2.206623, Accuracy: 18.64%\n",
            "Epoch: 46, Step: 631/655, Loss: 2.206589, Accuracy: 18.64%\n",
            "Epoch: 46, Step: 632/655, Loss: 2.206654, Accuracy: 18.65%\n",
            "Epoch: 46, Step: 633/655, Loss: 2.206694, Accuracy: 18.64%\n",
            "Epoch: 46, Step: 634/655, Loss: 2.206797, Accuracy: 18.63%\n",
            "Epoch: 46, Step: 635/655, Loss: 2.206933, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 636/655, Loss: 2.206937, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 637/655, Loss: 2.206919, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 638/655, Loss: 2.207099, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 639/655, Loss: 2.207111, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 640/655, Loss: 2.207026, Accuracy: 18.63%\n",
            "Epoch: 46, Step: 641/655, Loss: 2.207146, Accuracy: 18.63%\n",
            "Epoch: 46, Step: 642/655, Loss: 2.207009, Accuracy: 18.65%\n",
            "Epoch: 46, Step: 643/655, Loss: 2.207144, Accuracy: 18.63%\n",
            "Epoch: 46, Step: 644/655, Loss: 2.207100, Accuracy: 18.64%\n",
            "Epoch: 46, Step: 645/655, Loss: 2.207177, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 646/655, Loss: 2.207238, Accuracy: 18.62%\n",
            "Epoch: 46, Step: 647/655, Loss: 2.207342, Accuracy: 18.61%\n",
            "Epoch: 46, Step: 648/655, Loss: 2.207463, Accuracy: 18.60%\n",
            "Epoch: 46, Step: 649/655, Loss: 2.207560, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 650/655, Loss: 2.207604, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 651/655, Loss: 2.207590, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 652/655, Loss: 2.207577, Accuracy: 18.57%\n",
            "Epoch: 46, Step: 653/655, Loss: 2.207488, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 654/655, Loss: 2.207502, Accuracy: 18.58%\n",
            "Epoch: 46, Step: 655/655, Loss: 2.207315, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 1/655, Loss: 2.204240, Accuracy: 15.62%\n",
            "Epoch: 47, Step: 2/655, Loss: 2.292308, Accuracy: 12.50%\n",
            "Epoch: 47, Step: 3/655, Loss: 2.300245, Accuracy: 11.46%\n",
            "Epoch: 47, Step: 4/655, Loss: 2.283725, Accuracy: 11.72%\n",
            "Epoch: 47, Step: 5/655, Loss: 2.258310, Accuracy: 12.50%\n",
            "Epoch: 47, Step: 6/655, Loss: 2.248143, Accuracy: 13.54%\n",
            "Epoch: 47, Step: 7/655, Loss: 2.231398, Accuracy: 13.84%\n",
            "Epoch: 47, Step: 8/655, Loss: 2.231447, Accuracy: 13.67%\n",
            "Epoch: 47, Step: 9/655, Loss: 2.231386, Accuracy: 14.58%\n",
            "Epoch: 47, Step: 10/655, Loss: 2.232603, Accuracy: 15.31%\n",
            "Epoch: 47, Step: 11/655, Loss: 2.237125, Accuracy: 15.34%\n",
            "Epoch: 47, Step: 12/655, Loss: 2.236779, Accuracy: 16.15%\n",
            "Epoch: 47, Step: 13/655, Loss: 2.229228, Accuracy: 16.35%\n",
            "Epoch: 47, Step: 14/655, Loss: 2.236416, Accuracy: 16.29%\n",
            "Epoch: 47, Step: 15/655, Loss: 2.238231, Accuracy: 16.46%\n",
            "Epoch: 47, Step: 16/655, Loss: 2.235702, Accuracy: 16.21%\n",
            "Epoch: 47, Step: 17/655, Loss: 2.228242, Accuracy: 16.18%\n",
            "Epoch: 47, Step: 18/655, Loss: 2.233454, Accuracy: 16.32%\n",
            "Epoch: 47, Step: 19/655, Loss: 2.231499, Accuracy: 15.95%\n",
            "Epoch: 47, Step: 20/655, Loss: 2.234590, Accuracy: 16.09%\n",
            "Epoch: 47, Step: 21/655, Loss: 2.238809, Accuracy: 15.92%\n",
            "Epoch: 47, Step: 22/655, Loss: 2.238357, Accuracy: 16.19%\n",
            "Epoch: 47, Step: 23/655, Loss: 2.239719, Accuracy: 16.03%\n",
            "Epoch: 47, Step: 24/655, Loss: 2.238259, Accuracy: 16.41%\n",
            "Epoch: 47, Step: 25/655, Loss: 2.236598, Accuracy: 16.62%\n",
            "Epoch: 47, Step: 26/655, Loss: 2.242248, Accuracy: 16.59%\n",
            "Epoch: 47, Step: 27/655, Loss: 2.241542, Accuracy: 17.01%\n",
            "Epoch: 47, Step: 28/655, Loss: 2.242889, Accuracy: 16.96%\n",
            "Epoch: 47, Step: 29/655, Loss: 2.245359, Accuracy: 16.81%\n",
            "Epoch: 47, Step: 30/655, Loss: 2.243955, Accuracy: 16.67%\n",
            "Epoch: 47, Step: 31/655, Loss: 2.239435, Accuracy: 17.04%\n",
            "Epoch: 47, Step: 32/655, Loss: 2.239466, Accuracy: 17.09%\n",
            "Epoch: 47, Step: 33/655, Loss: 2.237238, Accuracy: 17.23%\n",
            "Epoch: 47, Step: 34/655, Loss: 2.236527, Accuracy: 17.19%\n",
            "Epoch: 47, Step: 35/655, Loss: 2.233315, Accuracy: 17.50%\n",
            "Epoch: 47, Step: 36/655, Loss: 2.233052, Accuracy: 17.45%\n",
            "Epoch: 47, Step: 37/655, Loss: 2.229636, Accuracy: 17.48%\n",
            "Epoch: 47, Step: 38/655, Loss: 2.229011, Accuracy: 17.68%\n",
            "Epoch: 47, Step: 39/655, Loss: 2.228015, Accuracy: 17.71%\n",
            "Epoch: 47, Step: 40/655, Loss: 2.229311, Accuracy: 17.73%\n",
            "Epoch: 47, Step: 41/655, Loss: 2.228895, Accuracy: 17.84%\n",
            "Epoch: 47, Step: 42/655, Loss: 2.225130, Accuracy: 17.93%\n",
            "Epoch: 47, Step: 43/655, Loss: 2.227651, Accuracy: 17.81%\n",
            "Epoch: 47, Step: 44/655, Loss: 2.229367, Accuracy: 17.76%\n",
            "Epoch: 47, Step: 45/655, Loss: 2.228108, Accuracy: 17.71%\n",
            "Epoch: 47, Step: 46/655, Loss: 2.226442, Accuracy: 17.80%\n",
            "Epoch: 47, Step: 47/655, Loss: 2.226300, Accuracy: 17.69%\n",
            "Epoch: 47, Step: 48/655, Loss: 2.226232, Accuracy: 17.58%\n",
            "Epoch: 47, Step: 49/655, Loss: 2.227805, Accuracy: 17.54%\n",
            "Epoch: 47, Step: 50/655, Loss: 2.226763, Accuracy: 17.44%\n",
            "Epoch: 47, Step: 51/655, Loss: 2.226197, Accuracy: 17.59%\n",
            "Epoch: 47, Step: 52/655, Loss: 2.222559, Accuracy: 17.55%\n",
            "Epoch: 47, Step: 53/655, Loss: 2.221439, Accuracy: 17.57%\n",
            "Epoch: 47, Step: 54/655, Loss: 2.219512, Accuracy: 17.77%\n",
            "Epoch: 47, Step: 55/655, Loss: 2.219195, Accuracy: 17.78%\n",
            "Epoch: 47, Step: 56/655, Loss: 2.215101, Accuracy: 18.19%\n",
            "Epoch: 47, Step: 57/655, Loss: 2.213930, Accuracy: 18.37%\n",
            "Epoch: 47, Step: 58/655, Loss: 2.210640, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 59/655, Loss: 2.209257, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 60/655, Loss: 2.210131, Accuracy: 18.54%\n",
            "Epoch: 47, Step: 61/655, Loss: 2.208386, Accuracy: 18.70%\n",
            "Epoch: 47, Step: 62/655, Loss: 2.208415, Accuracy: 18.75%\n",
            "Epoch: 47, Step: 63/655, Loss: 2.208502, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 64/655, Loss: 2.209329, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 65/655, Loss: 2.209458, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 66/655, Loss: 2.210452, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 67/655, Loss: 2.210170, Accuracy: 18.66%\n",
            "Epoch: 47, Step: 68/655, Loss: 2.210107, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 69/655, Loss: 2.210511, Accuracy: 18.39%\n",
            "Epoch: 47, Step: 70/655, Loss: 2.209044, Accuracy: 18.39%\n",
            "Epoch: 47, Step: 71/655, Loss: 2.211196, Accuracy: 18.18%\n",
            "Epoch: 47, Step: 72/655, Loss: 2.211130, Accuracy: 18.23%\n",
            "Epoch: 47, Step: 73/655, Loss: 2.210380, Accuracy: 18.28%\n",
            "Epoch: 47, Step: 74/655, Loss: 2.210897, Accuracy: 18.37%\n",
            "Epoch: 47, Step: 75/655, Loss: 2.210421, Accuracy: 18.42%\n",
            "Epoch: 47, Step: 76/655, Loss: 2.209503, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 77/655, Loss: 2.207765, Accuracy: 18.71%\n",
            "Epoch: 47, Step: 78/655, Loss: 2.206490, Accuracy: 18.75%\n",
            "Epoch: 47, Step: 79/655, Loss: 2.206202, Accuracy: 18.67%\n",
            "Epoch: 47, Step: 80/655, Loss: 2.204721, Accuracy: 18.75%\n",
            "Epoch: 47, Step: 81/655, Loss: 2.205173, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 82/655, Loss: 2.204582, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 83/655, Loss: 2.204688, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 84/655, Loss: 2.204844, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 85/655, Loss: 2.205872, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 86/655, Loss: 2.206206, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 87/655, Loss: 2.206169, Accuracy: 18.68%\n",
            "Epoch: 47, Step: 88/655, Loss: 2.206683, Accuracy: 18.71%\n",
            "Epoch: 47, Step: 89/655, Loss: 2.205588, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 90/655, Loss: 2.206109, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 91/655, Loss: 2.206324, Accuracy: 18.65%\n",
            "Epoch: 47, Step: 92/655, Loss: 2.206828, Accuracy: 18.65%\n",
            "Epoch: 47, Step: 93/655, Loss: 2.206402, Accuracy: 18.65%\n",
            "Epoch: 47, Step: 94/655, Loss: 2.206464, Accuracy: 18.68%\n",
            "Epoch: 47, Step: 95/655, Loss: 2.205743, Accuracy: 18.88%\n",
            "Epoch: 47, Step: 96/655, Loss: 2.206520, Accuracy: 18.82%\n",
            "Epoch: 47, Step: 97/655, Loss: 2.205897, Accuracy: 18.91%\n",
            "Epoch: 47, Step: 98/655, Loss: 2.205813, Accuracy: 18.97%\n",
            "Epoch: 47, Step: 99/655, Loss: 2.206879, Accuracy: 18.84%\n",
            "Epoch: 47, Step: 100/655, Loss: 2.206994, Accuracy: 18.88%\n",
            "Epoch: 47, Step: 101/655, Loss: 2.206662, Accuracy: 18.87%\n",
            "Epoch: 47, Step: 102/655, Loss: 2.206117, Accuracy: 18.93%\n",
            "Epoch: 47, Step: 103/655, Loss: 2.205204, Accuracy: 18.99%\n",
            "Epoch: 47, Step: 104/655, Loss: 2.205652, Accuracy: 18.96%\n",
            "Epoch: 47, Step: 105/655, Loss: 2.205396, Accuracy: 18.96%\n",
            "Epoch: 47, Step: 106/655, Loss: 2.206110, Accuracy: 18.93%\n",
            "Epoch: 47, Step: 107/655, Loss: 2.206202, Accuracy: 19.07%\n",
            "Epoch: 47, Step: 108/655, Loss: 2.206885, Accuracy: 19.18%\n",
            "Epoch: 47, Step: 109/655, Loss: 2.207176, Accuracy: 19.24%\n",
            "Epoch: 47, Step: 110/655, Loss: 2.207224, Accuracy: 19.26%\n",
            "Epoch: 47, Step: 111/655, Loss: 2.207299, Accuracy: 19.23%\n",
            "Epoch: 47, Step: 112/655, Loss: 2.206928, Accuracy: 19.34%\n",
            "Epoch: 47, Step: 113/655, Loss: 2.207215, Accuracy: 19.39%\n",
            "Epoch: 47, Step: 114/655, Loss: 2.206932, Accuracy: 19.38%\n",
            "Epoch: 47, Step: 115/655, Loss: 2.208142, Accuracy: 19.29%\n",
            "Epoch: 47, Step: 116/655, Loss: 2.207555, Accuracy: 19.34%\n",
            "Epoch: 47, Step: 117/655, Loss: 2.206978, Accuracy: 19.42%\n",
            "Epoch: 47, Step: 118/655, Loss: 2.207846, Accuracy: 19.36%\n",
            "Epoch: 47, Step: 119/655, Loss: 2.206617, Accuracy: 19.35%\n",
            "Epoch: 47, Step: 120/655, Loss: 2.206868, Accuracy: 19.38%\n",
            "Epoch: 47, Step: 121/655, Loss: 2.206951, Accuracy: 19.32%\n",
            "Epoch: 47, Step: 122/655, Loss: 2.207207, Accuracy: 19.34%\n",
            "Epoch: 47, Step: 123/655, Loss: 2.208131, Accuracy: 19.31%\n",
            "Epoch: 47, Step: 124/655, Loss: 2.208113, Accuracy: 19.20%\n",
            "Epoch: 47, Step: 125/655, Loss: 2.208155, Accuracy: 19.23%\n",
            "Epoch: 47, Step: 126/655, Loss: 2.209163, Accuracy: 19.15%\n",
            "Epoch: 47, Step: 127/655, Loss: 2.209342, Accuracy: 19.09%\n",
            "Epoch: 47, Step: 128/655, Loss: 2.209786, Accuracy: 19.04%\n",
            "Epoch: 47, Step: 129/655, Loss: 2.210021, Accuracy: 19.04%\n",
            "Epoch: 47, Step: 130/655, Loss: 2.209424, Accuracy: 19.01%\n",
            "Epoch: 47, Step: 131/655, Loss: 2.209978, Accuracy: 18.99%\n",
            "Epoch: 47, Step: 132/655, Loss: 2.208865, Accuracy: 19.08%\n",
            "Epoch: 47, Step: 133/655, Loss: 2.208950, Accuracy: 19.03%\n",
            "Epoch: 47, Step: 134/655, Loss: 2.209787, Accuracy: 19.01%\n",
            "Epoch: 47, Step: 135/655, Loss: 2.209708, Accuracy: 18.98%\n",
            "Epoch: 47, Step: 136/655, Loss: 2.209866, Accuracy: 18.98%\n",
            "Epoch: 47, Step: 137/655, Loss: 2.209361, Accuracy: 19.05%\n",
            "Epoch: 47, Step: 138/655, Loss: 2.208943, Accuracy: 18.98%\n",
            "Epoch: 47, Step: 139/655, Loss: 2.209076, Accuracy: 19.02%\n",
            "Epoch: 47, Step: 140/655, Loss: 2.208717, Accuracy: 19.06%\n",
            "Epoch: 47, Step: 141/655, Loss: 2.208432, Accuracy: 19.06%\n",
            "Epoch: 47, Step: 142/655, Loss: 2.208300, Accuracy: 19.06%\n",
            "Epoch: 47, Step: 143/655, Loss: 2.208253, Accuracy: 19.03%\n",
            "Epoch: 47, Step: 144/655, Loss: 2.208582, Accuracy: 19.05%\n",
            "Epoch: 47, Step: 145/655, Loss: 2.208439, Accuracy: 19.03%\n",
            "Epoch: 47, Step: 146/655, Loss: 2.209381, Accuracy: 19.05%\n",
            "Epoch: 47, Step: 147/655, Loss: 2.209451, Accuracy: 19.01%\n",
            "Epoch: 47, Step: 148/655, Loss: 2.210660, Accuracy: 18.98%\n",
            "Epoch: 47, Step: 149/655, Loss: 2.211480, Accuracy: 18.92%\n",
            "Epoch: 47, Step: 150/655, Loss: 2.212159, Accuracy: 18.85%\n",
            "Epoch: 47, Step: 151/655, Loss: 2.212018, Accuracy: 18.85%\n",
            "Epoch: 47, Step: 152/655, Loss: 2.211963, Accuracy: 18.85%\n",
            "Epoch: 47, Step: 153/655, Loss: 2.211821, Accuracy: 18.83%\n",
            "Epoch: 47, Step: 154/655, Loss: 2.212726, Accuracy: 18.81%\n",
            "Epoch: 47, Step: 155/655, Loss: 2.212962, Accuracy: 18.75%\n",
            "Epoch: 47, Step: 156/655, Loss: 2.213128, Accuracy: 18.71%\n",
            "Epoch: 47, Step: 157/655, Loss: 2.212773, Accuracy: 18.71%\n",
            "Epoch: 47, Step: 158/655, Loss: 2.212965, Accuracy: 18.73%\n",
            "Epoch: 47, Step: 159/655, Loss: 2.212851, Accuracy: 18.75%\n",
            "Epoch: 47, Step: 160/655, Loss: 2.211535, Accuracy: 18.83%\n",
            "Epoch: 47, Step: 161/655, Loss: 2.212110, Accuracy: 18.87%\n",
            "Epoch: 47, Step: 162/655, Loss: 2.212956, Accuracy: 18.83%\n",
            "Epoch: 47, Step: 163/655, Loss: 2.212843, Accuracy: 18.83%\n",
            "Epoch: 47, Step: 164/655, Loss: 2.211990, Accuracy: 18.90%\n",
            "Epoch: 47, Step: 165/655, Loss: 2.211603, Accuracy: 18.92%\n",
            "Epoch: 47, Step: 166/655, Loss: 2.210838, Accuracy: 18.92%\n",
            "Epoch: 47, Step: 167/655, Loss: 2.210656, Accuracy: 18.97%\n",
            "Epoch: 47, Step: 168/655, Loss: 2.210549, Accuracy: 18.94%\n",
            "Epoch: 47, Step: 169/655, Loss: 2.210879, Accuracy: 18.95%\n",
            "Epoch: 47, Step: 170/655, Loss: 2.210305, Accuracy: 18.93%\n",
            "Epoch: 47, Step: 171/655, Loss: 2.210442, Accuracy: 18.88%\n",
            "Epoch: 47, Step: 172/655, Loss: 2.211111, Accuracy: 18.82%\n",
            "Epoch: 47, Step: 173/655, Loss: 2.210699, Accuracy: 18.88%\n",
            "Epoch: 47, Step: 174/655, Loss: 2.210481, Accuracy: 18.88%\n",
            "Epoch: 47, Step: 175/655, Loss: 2.210395, Accuracy: 18.89%\n",
            "Epoch: 47, Step: 176/655, Loss: 2.210284, Accuracy: 18.87%\n",
            "Epoch: 47, Step: 177/655, Loss: 2.210214, Accuracy: 18.84%\n",
            "Epoch: 47, Step: 178/655, Loss: 2.210455, Accuracy: 18.84%\n",
            "Epoch: 47, Step: 179/655, Loss: 2.210578, Accuracy: 18.78%\n",
            "Epoch: 47, Step: 180/655, Loss: 2.210793, Accuracy: 18.75%\n",
            "Epoch: 47, Step: 181/655, Loss: 2.210820, Accuracy: 18.73%\n",
            "Epoch: 47, Step: 182/655, Loss: 2.210833, Accuracy: 18.72%\n",
            "Epoch: 47, Step: 183/655, Loss: 2.210822, Accuracy: 18.73%\n",
            "Epoch: 47, Step: 184/655, Loss: 2.211237, Accuracy: 18.70%\n",
            "Epoch: 47, Step: 185/655, Loss: 2.211011, Accuracy: 18.72%\n",
            "Epoch: 47, Step: 186/655, Loss: 2.211487, Accuracy: 18.65%\n",
            "Epoch: 47, Step: 187/655, Loss: 2.211505, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 188/655, Loss: 2.210813, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 189/655, Loss: 2.211178, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 190/655, Loss: 2.211280, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 191/655, Loss: 2.211152, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 192/655, Loss: 2.211314, Accuracy: 18.51%\n",
            "Epoch: 47, Step: 193/655, Loss: 2.211440, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 194/655, Loss: 2.211472, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 195/655, Loss: 2.211392, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 196/655, Loss: 2.211999, Accuracy: 18.49%\n",
            "Epoch: 47, Step: 197/655, Loss: 2.212387, Accuracy: 18.46%\n",
            "Epoch: 47, Step: 198/655, Loss: 2.212531, Accuracy: 18.43%\n",
            "Epoch: 47, Step: 199/655, Loss: 2.212903, Accuracy: 18.44%\n",
            "Epoch: 47, Step: 200/655, Loss: 2.213291, Accuracy: 18.39%\n",
            "Epoch: 47, Step: 201/655, Loss: 2.213595, Accuracy: 18.41%\n",
            "Epoch: 47, Step: 202/655, Loss: 2.214233, Accuracy: 18.39%\n",
            "Epoch: 47, Step: 203/655, Loss: 2.213777, Accuracy: 18.41%\n",
            "Epoch: 47, Step: 204/655, Loss: 2.213722, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 205/655, Loss: 2.212973, Accuracy: 18.46%\n",
            "Epoch: 47, Step: 206/655, Loss: 2.212724, Accuracy: 18.54%\n",
            "Epoch: 47, Step: 207/655, Loss: 2.212814, Accuracy: 18.49%\n",
            "Epoch: 47, Step: 208/655, Loss: 2.213531, Accuracy: 18.42%\n",
            "Epoch: 47, Step: 209/655, Loss: 2.213946, Accuracy: 18.44%\n",
            "Epoch: 47, Step: 210/655, Loss: 2.213036, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 211/655, Loss: 2.213584, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 212/655, Loss: 2.213760, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 213/655, Loss: 2.213443, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 214/655, Loss: 2.213455, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 215/655, Loss: 2.213519, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 216/655, Loss: 2.213631, Accuracy: 18.49%\n",
            "Epoch: 47, Step: 217/655, Loss: 2.213814, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 218/655, Loss: 2.213241, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 219/655, Loss: 2.213486, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 220/655, Loss: 2.213903, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 221/655, Loss: 2.213749, Accuracy: 18.44%\n",
            "Epoch: 47, Step: 222/655, Loss: 2.214121, Accuracy: 18.41%\n",
            "Epoch: 47, Step: 223/655, Loss: 2.214274, Accuracy: 18.39%\n",
            "Epoch: 47, Step: 224/655, Loss: 2.214345, Accuracy: 18.39%\n",
            "Epoch: 47, Step: 225/655, Loss: 2.214712, Accuracy: 18.36%\n",
            "Epoch: 47, Step: 226/655, Loss: 2.214183, Accuracy: 18.42%\n",
            "Epoch: 47, Step: 227/655, Loss: 2.214218, Accuracy: 18.45%\n",
            "Epoch: 47, Step: 228/655, Loss: 2.213951, Accuracy: 18.46%\n",
            "Epoch: 47, Step: 229/655, Loss: 2.213838, Accuracy: 18.45%\n",
            "Epoch: 47, Step: 230/655, Loss: 2.214248, Accuracy: 18.42%\n",
            "Epoch: 47, Step: 231/655, Loss: 2.214529, Accuracy: 18.43%\n",
            "Epoch: 47, Step: 232/655, Loss: 2.214477, Accuracy: 18.44%\n",
            "Epoch: 47, Step: 233/655, Loss: 2.214343, Accuracy: 18.41%\n",
            "Epoch: 47, Step: 234/655, Loss: 2.214058, Accuracy: 18.46%\n",
            "Epoch: 47, Step: 235/655, Loss: 2.214311, Accuracy: 18.43%\n",
            "Epoch: 47, Step: 236/655, Loss: 2.214167, Accuracy: 18.49%\n",
            "Epoch: 47, Step: 237/655, Loss: 2.213830, Accuracy: 18.49%\n",
            "Epoch: 47, Step: 238/655, Loss: 2.213711, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 239/655, Loss: 2.213781, Accuracy: 18.51%\n",
            "Epoch: 47, Step: 240/655, Loss: 2.214130, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 241/655, Loss: 2.213547, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 242/655, Loss: 2.213481, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 243/655, Loss: 2.214224, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 244/655, Loss: 2.214278, Accuracy: 18.49%\n",
            "Epoch: 47, Step: 245/655, Loss: 2.214111, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 246/655, Loss: 2.213355, Accuracy: 18.51%\n",
            "Epoch: 47, Step: 247/655, Loss: 2.213292, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 248/655, Loss: 2.213349, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 249/655, Loss: 2.213068, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 250/655, Loss: 2.213079, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 251/655, Loss: 2.212932, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 252/655, Loss: 2.212586, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 253/655, Loss: 2.212767, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 254/655, Loss: 2.213190, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 255/655, Loss: 2.213190, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 256/655, Loss: 2.213548, Accuracy: 18.54%\n",
            "Epoch: 47, Step: 257/655, Loss: 2.213150, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 258/655, Loss: 2.213480, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 259/655, Loss: 2.213416, Accuracy: 18.54%\n",
            "Epoch: 47, Step: 260/655, Loss: 2.213215, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 261/655, Loss: 2.213029, Accuracy: 18.51%\n",
            "Epoch: 47, Step: 262/655, Loss: 2.213078, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 263/655, Loss: 2.213330, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 264/655, Loss: 2.213168, Accuracy: 18.45%\n",
            "Epoch: 47, Step: 265/655, Loss: 2.213502, Accuracy: 18.44%\n",
            "Epoch: 47, Step: 266/655, Loss: 2.214214, Accuracy: 18.40%\n",
            "Epoch: 47, Step: 267/655, Loss: 2.213934, Accuracy: 18.41%\n",
            "Epoch: 47, Step: 268/655, Loss: 2.213410, Accuracy: 18.42%\n",
            "Epoch: 47, Step: 269/655, Loss: 2.213170, Accuracy: 18.45%\n",
            "Epoch: 47, Step: 270/655, Loss: 2.213212, Accuracy: 18.46%\n",
            "Epoch: 47, Step: 271/655, Loss: 2.213268, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 272/655, Loss: 2.213737, Accuracy: 18.45%\n",
            "Epoch: 47, Step: 273/655, Loss: 2.213215, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 274/655, Loss: 2.212921, Accuracy: 18.51%\n",
            "Epoch: 47, Step: 275/655, Loss: 2.212532, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 276/655, Loss: 2.212407, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 277/655, Loss: 2.212552, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 278/655, Loss: 2.212973, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 279/655, Loss: 2.213028, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 280/655, Loss: 2.213475, Accuracy: 18.43%\n",
            "Epoch: 47, Step: 281/655, Loss: 2.213541, Accuracy: 18.45%\n",
            "Epoch: 47, Step: 282/655, Loss: 2.213407, Accuracy: 18.46%\n",
            "Epoch: 47, Step: 283/655, Loss: 2.212924, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 284/655, Loss: 2.212658, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 285/655, Loss: 2.212744, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 286/655, Loss: 2.212778, Accuracy: 18.54%\n",
            "Epoch: 47, Step: 287/655, Loss: 2.212429, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 288/655, Loss: 2.212416, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 289/655, Loss: 2.212368, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 290/655, Loss: 2.212777, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 291/655, Loss: 2.212781, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 292/655, Loss: 2.212904, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 293/655, Loss: 2.212733, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 294/655, Loss: 2.212481, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 295/655, Loss: 2.212560, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 296/655, Loss: 2.212623, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 297/655, Loss: 2.212738, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 298/655, Loss: 2.212638, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 299/655, Loss: 2.212612, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 300/655, Loss: 2.212218, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 301/655, Loss: 2.212283, Accuracy: 18.54%\n",
            "Epoch: 47, Step: 302/655, Loss: 2.211881, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 303/655, Loss: 2.211799, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 304/655, Loss: 2.211789, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 305/655, Loss: 2.211459, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 306/655, Loss: 2.211285, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 307/655, Loss: 2.210863, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 308/655, Loss: 2.210536, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 309/655, Loss: 2.210395, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 310/655, Loss: 2.210937, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 311/655, Loss: 2.210808, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 312/655, Loss: 2.211473, Accuracy: 18.54%\n",
            "Epoch: 47, Step: 313/655, Loss: 2.211041, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 314/655, Loss: 2.210954, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 315/655, Loss: 2.211375, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 316/655, Loss: 2.211697, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 317/655, Loss: 2.211920, Accuracy: 18.51%\n",
            "Epoch: 47, Step: 318/655, Loss: 2.211982, Accuracy: 18.51%\n",
            "Epoch: 47, Step: 319/655, Loss: 2.211739, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 320/655, Loss: 2.211841, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 321/655, Loss: 2.212042, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 322/655, Loss: 2.211857, Accuracy: 18.54%\n",
            "Epoch: 47, Step: 323/655, Loss: 2.212054, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 324/655, Loss: 2.211995, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 325/655, Loss: 2.211966, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 326/655, Loss: 2.212011, Accuracy: 18.51%\n",
            "Epoch: 47, Step: 327/655, Loss: 2.212104, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 328/655, Loss: 2.212228, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 329/655, Loss: 2.212157, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 330/655, Loss: 2.212181, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 331/655, Loss: 2.211894, Accuracy: 18.54%\n",
            "Epoch: 47, Step: 332/655, Loss: 2.211928, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 333/655, Loss: 2.211883, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 334/655, Loss: 2.211698, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 335/655, Loss: 2.211502, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 336/655, Loss: 2.211366, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 337/655, Loss: 2.211162, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 338/655, Loss: 2.211211, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 339/655, Loss: 2.211539, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 340/655, Loss: 2.212005, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 341/655, Loss: 2.212052, Accuracy: 18.54%\n",
            "Epoch: 47, Step: 342/655, Loss: 2.212074, Accuracy: 18.54%\n",
            "Epoch: 47, Step: 343/655, Loss: 2.212018, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 344/655, Loss: 2.211607, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 345/655, Loss: 2.211704, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 346/655, Loss: 2.211602, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 347/655, Loss: 2.211358, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 348/655, Loss: 2.211353, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 349/655, Loss: 2.211724, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 350/655, Loss: 2.211962, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 351/655, Loss: 2.212076, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 352/655, Loss: 2.212138, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 353/655, Loss: 2.212131, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 354/655, Loss: 2.212158, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 355/655, Loss: 2.212006, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 356/655, Loss: 2.212427, Accuracy: 18.49%\n",
            "Epoch: 47, Step: 357/655, Loss: 2.212458, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 358/655, Loss: 2.212817, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 359/655, Loss: 2.212337, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 360/655, Loss: 2.212449, Accuracy: 18.46%\n",
            "Epoch: 47, Step: 361/655, Loss: 2.212190, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 362/655, Loss: 2.211927, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 363/655, Loss: 2.212029, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 364/655, Loss: 2.212513, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 365/655, Loss: 2.212439, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 366/655, Loss: 2.212660, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 367/655, Loss: 2.212701, Accuracy: 18.49%\n",
            "Epoch: 47, Step: 368/655, Loss: 2.212589, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 369/655, Loss: 2.212299, Accuracy: 18.46%\n",
            "Epoch: 47, Step: 370/655, Loss: 2.212403, Accuracy: 18.45%\n",
            "Epoch: 47, Step: 371/655, Loss: 2.212160, Accuracy: 18.45%\n",
            "Epoch: 47, Step: 372/655, Loss: 2.212204, Accuracy: 18.45%\n",
            "Epoch: 47, Step: 373/655, Loss: 2.211969, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 374/655, Loss: 2.211614, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 375/655, Loss: 2.211661, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 376/655, Loss: 2.211565, Accuracy: 18.51%\n",
            "Epoch: 47, Step: 377/655, Loss: 2.211853, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 378/655, Loss: 2.211960, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 379/655, Loss: 2.212160, Accuracy: 18.49%\n",
            "Epoch: 47, Step: 380/655, Loss: 2.212285, Accuracy: 18.46%\n",
            "Epoch: 47, Step: 381/655, Loss: 2.212169, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 382/655, Loss: 2.211916, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 383/655, Loss: 2.211773, Accuracy: 18.46%\n",
            "Epoch: 47, Step: 384/655, Loss: 2.211824, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 385/655, Loss: 2.211769, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 386/655, Loss: 2.211914, Accuracy: 18.46%\n",
            "Epoch: 47, Step: 387/655, Loss: 2.211703, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 388/655, Loss: 2.211577, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 389/655, Loss: 2.211707, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 390/655, Loss: 2.211581, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 391/655, Loss: 2.211410, Accuracy: 18.46%\n",
            "Epoch: 47, Step: 392/655, Loss: 2.211508, Accuracy: 18.46%\n",
            "Epoch: 47, Step: 393/655, Loss: 2.211665, Accuracy: 18.45%\n",
            "Epoch: 47, Step: 394/655, Loss: 2.211568, Accuracy: 18.45%\n",
            "Epoch: 47, Step: 395/655, Loss: 2.211492, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 396/655, Loss: 2.211523, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 397/655, Loss: 2.211140, Accuracy: 18.49%\n",
            "Epoch: 47, Step: 398/655, Loss: 2.211503, Accuracy: 18.49%\n",
            "Epoch: 47, Step: 399/655, Loss: 2.211513, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 400/655, Loss: 2.211816, Accuracy: 18.47%\n",
            "Epoch: 47, Step: 401/655, Loss: 2.211843, Accuracy: 18.49%\n",
            "Epoch: 47, Step: 402/655, Loss: 2.211720, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 403/655, Loss: 2.211643, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 404/655, Loss: 2.211646, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 405/655, Loss: 2.211939, Accuracy: 18.48%\n",
            "Epoch: 47, Step: 406/655, Loss: 2.211713, Accuracy: 18.50%\n",
            "Epoch: 47, Step: 407/655, Loss: 2.211308, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 408/655, Loss: 2.211149, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 409/655, Loss: 2.211363, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 410/655, Loss: 2.211110, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 411/655, Loss: 2.211193, Accuracy: 18.51%\n",
            "Epoch: 47, Step: 412/655, Loss: 2.211187, Accuracy: 18.51%\n",
            "Epoch: 47, Step: 413/655, Loss: 2.211062, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 414/655, Loss: 2.210975, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 415/655, Loss: 2.210934, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 416/655, Loss: 2.210852, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 417/655, Loss: 2.210851, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 418/655, Loss: 2.210750, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 419/655, Loss: 2.210746, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 420/655, Loss: 2.211041, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 421/655, Loss: 2.210976, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 422/655, Loss: 2.210869, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 423/655, Loss: 2.211061, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 424/655, Loss: 2.211191, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 425/655, Loss: 2.210863, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 426/655, Loss: 2.211009, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 427/655, Loss: 2.211031, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 428/655, Loss: 2.210792, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 429/655, Loss: 2.210947, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 430/655, Loss: 2.211235, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 431/655, Loss: 2.210907, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 432/655, Loss: 2.211085, Accuracy: 18.54%\n",
            "Epoch: 47, Step: 433/655, Loss: 2.210642, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 434/655, Loss: 2.210897, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 435/655, Loss: 2.211196, Accuracy: 18.51%\n",
            "Epoch: 47, Step: 436/655, Loss: 2.211153, Accuracy: 18.51%\n",
            "Epoch: 47, Step: 437/655, Loss: 2.211255, Accuracy: 18.49%\n",
            "Epoch: 47, Step: 438/655, Loss: 2.211291, Accuracy: 18.51%\n",
            "Epoch: 47, Step: 439/655, Loss: 2.211227, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 440/655, Loss: 2.211340, Accuracy: 18.52%\n",
            "Epoch: 47, Step: 441/655, Loss: 2.211327, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 442/655, Loss: 2.211243, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 443/655, Loss: 2.211039, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 444/655, Loss: 2.210919, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 445/655, Loss: 2.210991, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 446/655, Loss: 2.211190, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 447/655, Loss: 2.211347, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 448/655, Loss: 2.211026, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 449/655, Loss: 2.210942, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 450/655, Loss: 2.211016, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 451/655, Loss: 2.210878, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 452/655, Loss: 2.210723, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 453/655, Loss: 2.210863, Accuracy: 18.65%\n",
            "Epoch: 47, Step: 454/655, Loss: 2.210942, Accuracy: 18.66%\n",
            "Epoch: 47, Step: 455/655, Loss: 2.210816, Accuracy: 18.66%\n",
            "Epoch: 47, Step: 456/655, Loss: 2.210882, Accuracy: 18.65%\n",
            "Epoch: 47, Step: 457/655, Loss: 2.210707, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 458/655, Loss: 2.210818, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 459/655, Loss: 2.210901, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 460/655, Loss: 2.211263, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 461/655, Loss: 2.211239, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 462/655, Loss: 2.211262, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 463/655, Loss: 2.211415, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 464/655, Loss: 2.211376, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 465/655, Loss: 2.211419, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 466/655, Loss: 2.211508, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 467/655, Loss: 2.211526, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 468/655, Loss: 2.211708, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 469/655, Loss: 2.211866, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 470/655, Loss: 2.211957, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 471/655, Loss: 2.212082, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 472/655, Loss: 2.211933, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 473/655, Loss: 2.211756, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 474/655, Loss: 2.211796, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 475/655, Loss: 2.211721, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 476/655, Loss: 2.211678, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 477/655, Loss: 2.211489, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 478/655, Loss: 2.211613, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 479/655, Loss: 2.211765, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 480/655, Loss: 2.211990, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 481/655, Loss: 2.212040, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 482/655, Loss: 2.211846, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 483/655, Loss: 2.211547, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 484/655, Loss: 2.211506, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 485/655, Loss: 2.211488, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 486/655, Loss: 2.211377, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 487/655, Loss: 2.211504, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 488/655, Loss: 2.211470, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 489/655, Loss: 2.211358, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 490/655, Loss: 2.211719, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 491/655, Loss: 2.211504, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 492/655, Loss: 2.211592, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 493/655, Loss: 2.211441, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 494/655, Loss: 2.211555, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 495/655, Loss: 2.211509, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 496/655, Loss: 2.211253, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 497/655, Loss: 2.210894, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 498/655, Loss: 2.210711, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 499/655, Loss: 2.210872, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 500/655, Loss: 2.210948, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 501/655, Loss: 2.210634, Accuracy: 18.66%\n",
            "Epoch: 47, Step: 502/655, Loss: 2.210940, Accuracy: 18.66%\n",
            "Epoch: 47, Step: 503/655, Loss: 2.210905, Accuracy: 18.66%\n",
            "Epoch: 47, Step: 504/655, Loss: 2.210508, Accuracy: 18.65%\n",
            "Epoch: 47, Step: 505/655, Loss: 2.210226, Accuracy: 18.66%\n",
            "Epoch: 47, Step: 506/655, Loss: 2.210151, Accuracy: 18.67%\n",
            "Epoch: 47, Step: 507/655, Loss: 2.210181, Accuracy: 18.68%\n",
            "Epoch: 47, Step: 508/655, Loss: 2.210186, Accuracy: 18.66%\n",
            "Epoch: 47, Step: 509/655, Loss: 2.209919, Accuracy: 18.68%\n",
            "Epoch: 47, Step: 510/655, Loss: 2.209688, Accuracy: 18.68%\n",
            "Epoch: 47, Step: 511/655, Loss: 2.209667, Accuracy: 18.68%\n",
            "Epoch: 47, Step: 512/655, Loss: 2.209222, Accuracy: 18.71%\n",
            "Epoch: 47, Step: 513/655, Loss: 2.209287, Accuracy: 18.71%\n",
            "Epoch: 47, Step: 514/655, Loss: 2.209103, Accuracy: 18.74%\n",
            "Epoch: 47, Step: 515/655, Loss: 2.209053, Accuracy: 18.73%\n",
            "Epoch: 47, Step: 516/655, Loss: 2.209245, Accuracy: 18.73%\n",
            "Epoch: 47, Step: 517/655, Loss: 2.209047, Accuracy: 18.73%\n",
            "Epoch: 47, Step: 518/655, Loss: 2.209228, Accuracy: 18.72%\n",
            "Epoch: 47, Step: 519/655, Loss: 2.209259, Accuracy: 18.73%\n",
            "Epoch: 47, Step: 520/655, Loss: 2.209289, Accuracy: 18.71%\n",
            "Epoch: 47, Step: 521/655, Loss: 2.209255, Accuracy: 18.70%\n",
            "Epoch: 47, Step: 522/655, Loss: 2.209154, Accuracy: 18.71%\n",
            "Epoch: 47, Step: 523/655, Loss: 2.209107, Accuracy: 18.69%\n",
            "Epoch: 47, Step: 524/655, Loss: 2.209110, Accuracy: 18.70%\n",
            "Epoch: 47, Step: 525/655, Loss: 2.209125, Accuracy: 18.70%\n",
            "Epoch: 47, Step: 526/655, Loss: 2.209050, Accuracy: 18.70%\n",
            "Epoch: 47, Step: 527/655, Loss: 2.209148, Accuracy: 18.68%\n",
            "Epoch: 47, Step: 528/655, Loss: 2.209189, Accuracy: 18.70%\n",
            "Epoch: 47, Step: 529/655, Loss: 2.209149, Accuracy: 18.69%\n",
            "Epoch: 47, Step: 530/655, Loss: 2.208828, Accuracy: 18.70%\n",
            "Epoch: 47, Step: 531/655, Loss: 2.208804, Accuracy: 18.69%\n",
            "Epoch: 47, Step: 532/655, Loss: 2.208863, Accuracy: 18.66%\n",
            "Epoch: 47, Step: 533/655, Loss: 2.208928, Accuracy: 18.65%\n",
            "Epoch: 47, Step: 534/655, Loss: 2.209091, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 535/655, Loss: 2.209085, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 536/655, Loss: 2.209228, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 537/655, Loss: 2.209300, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 538/655, Loss: 2.209275, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 539/655, Loss: 2.209297, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 540/655, Loss: 2.209250, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 541/655, Loss: 2.209140, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 542/655, Loss: 2.209396, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 543/655, Loss: 2.209229, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 544/655, Loss: 2.209202, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 545/655, Loss: 2.209165, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 546/655, Loss: 2.209316, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 547/655, Loss: 2.209477, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 548/655, Loss: 2.209367, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 549/655, Loss: 2.209235, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 550/655, Loss: 2.209374, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 551/655, Loss: 2.209334, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 552/655, Loss: 2.209210, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 553/655, Loss: 2.209140, Accuracy: 18.54%\n",
            "Epoch: 47, Step: 554/655, Loss: 2.209035, Accuracy: 18.54%\n",
            "Epoch: 47, Step: 555/655, Loss: 2.209140, Accuracy: 18.53%\n",
            "Epoch: 47, Step: 556/655, Loss: 2.208944, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 557/655, Loss: 2.208756, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 558/655, Loss: 2.208710, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 559/655, Loss: 2.208768, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 560/655, Loss: 2.208643, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 561/655, Loss: 2.208561, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 562/655, Loss: 2.208412, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 563/655, Loss: 2.208323, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 564/655, Loss: 2.208237, Accuracy: 18.66%\n",
            "Epoch: 47, Step: 565/655, Loss: 2.208326, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 566/655, Loss: 2.208236, Accuracy: 18.65%\n",
            "Epoch: 47, Step: 567/655, Loss: 2.208210, Accuracy: 18.66%\n",
            "Epoch: 47, Step: 568/655, Loss: 2.208135, Accuracy: 18.67%\n",
            "Epoch: 47, Step: 569/655, Loss: 2.208181, Accuracy: 18.65%\n",
            "Epoch: 47, Step: 570/655, Loss: 2.208141, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 571/655, Loss: 2.208224, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 572/655, Loss: 2.208151, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 573/655, Loss: 2.208167, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 574/655, Loss: 2.208230, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 575/655, Loss: 2.208205, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 576/655, Loss: 2.207945, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 577/655, Loss: 2.208286, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 578/655, Loss: 2.208337, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 579/655, Loss: 2.208441, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 580/655, Loss: 2.208383, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 581/655, Loss: 2.208463, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 582/655, Loss: 2.208442, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 583/655, Loss: 2.208066, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 584/655, Loss: 2.208153, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 585/655, Loss: 2.208036, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 586/655, Loss: 2.207603, Accuracy: 18.68%\n",
            "Epoch: 47, Step: 587/655, Loss: 2.207532, Accuracy: 18.69%\n",
            "Epoch: 47, Step: 588/655, Loss: 2.207393, Accuracy: 18.69%\n",
            "Epoch: 47, Step: 589/655, Loss: 2.207555, Accuracy: 18.67%\n",
            "Epoch: 47, Step: 590/655, Loss: 2.207653, Accuracy: 18.66%\n",
            "Epoch: 47, Step: 591/655, Loss: 2.207448, Accuracy: 18.67%\n",
            "Epoch: 47, Step: 592/655, Loss: 2.207418, Accuracy: 18.66%\n",
            "Epoch: 47, Step: 593/655, Loss: 2.207567, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 594/655, Loss: 2.207496, Accuracy: 18.66%\n",
            "Epoch: 47, Step: 595/655, Loss: 2.207502, Accuracy: 18.66%\n",
            "Epoch: 47, Step: 596/655, Loss: 2.207497, Accuracy: 18.65%\n",
            "Epoch: 47, Step: 597/655, Loss: 2.207549, Accuracy: 18.65%\n",
            "Epoch: 47, Step: 598/655, Loss: 2.207597, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 599/655, Loss: 2.207664, Accuracy: 18.65%\n",
            "Epoch: 47, Step: 600/655, Loss: 2.207477, Accuracy: 18.65%\n",
            "Epoch: 47, Step: 601/655, Loss: 2.207319, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 602/655, Loss: 2.207446, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 603/655, Loss: 2.207738, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 604/655, Loss: 2.207583, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 605/655, Loss: 2.207590, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 606/655, Loss: 2.207574, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 607/655, Loss: 2.207640, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 608/655, Loss: 2.207562, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 609/655, Loss: 2.207574, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 610/655, Loss: 2.207474, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 611/655, Loss: 2.207436, Accuracy: 18.64%\n",
            "Epoch: 47, Step: 612/655, Loss: 2.207401, Accuracy: 18.63%\n",
            "Epoch: 47, Step: 613/655, Loss: 2.207719, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 614/655, Loss: 2.207877, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 615/655, Loss: 2.207985, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 616/655, Loss: 2.207850, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 617/655, Loss: 2.208076, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 618/655, Loss: 2.208262, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 619/655, Loss: 2.208184, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 620/655, Loss: 2.208315, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 621/655, Loss: 2.208339, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 622/655, Loss: 2.208336, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 623/655, Loss: 2.208234, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 624/655, Loss: 2.208341, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 625/655, Loss: 2.208182, Accuracy: 18.61%\n",
            "Epoch: 47, Step: 626/655, Loss: 2.208218, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 627/655, Loss: 2.208303, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 628/655, Loss: 2.208403, Accuracy: 18.62%\n",
            "Epoch: 47, Step: 629/655, Loss: 2.208383, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 630/655, Loss: 2.208180, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 631/655, Loss: 2.207953, Accuracy: 18.60%\n",
            "Epoch: 47, Step: 632/655, Loss: 2.208065, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 633/655, Loss: 2.207989, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 634/655, Loss: 2.207980, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 635/655, Loss: 2.207970, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 636/655, Loss: 2.207838, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 637/655, Loss: 2.207870, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 638/655, Loss: 2.207996, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 639/655, Loss: 2.207875, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 640/655, Loss: 2.207783, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 641/655, Loss: 2.207902, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 642/655, Loss: 2.207757, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 643/655, Loss: 2.207754, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 644/655, Loss: 2.207880, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 645/655, Loss: 2.207877, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 646/655, Loss: 2.207839, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 647/655, Loss: 2.207956, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 648/655, Loss: 2.207962, Accuracy: 18.55%\n",
            "Epoch: 47, Step: 649/655, Loss: 2.207855, Accuracy: 18.56%\n",
            "Epoch: 47, Step: 650/655, Loss: 2.207753, Accuracy: 18.57%\n",
            "Epoch: 47, Step: 651/655, Loss: 2.207557, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 652/655, Loss: 2.207614, Accuracy: 18.58%\n",
            "Epoch: 47, Step: 653/655, Loss: 2.207326, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 654/655, Loss: 2.207358, Accuracy: 18.59%\n",
            "Epoch: 47, Step: 655/655, Loss: 2.207623, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 1/655, Loss: 2.015660, Accuracy: 31.25%\n",
            "Epoch: 48, Step: 2/655, Loss: 2.036443, Accuracy: 28.12%\n",
            "Epoch: 48, Step: 3/655, Loss: 2.146695, Accuracy: 23.96%\n",
            "Epoch: 48, Step: 4/655, Loss: 2.156159, Accuracy: 24.22%\n",
            "Epoch: 48, Step: 5/655, Loss: 2.158851, Accuracy: 22.50%\n",
            "Epoch: 48, Step: 6/655, Loss: 2.166607, Accuracy: 22.40%\n",
            "Epoch: 48, Step: 7/655, Loss: 2.156482, Accuracy: 21.43%\n",
            "Epoch: 48, Step: 8/655, Loss: 2.175963, Accuracy: 20.31%\n",
            "Epoch: 48, Step: 9/655, Loss: 2.177612, Accuracy: 20.83%\n",
            "Epoch: 48, Step: 10/655, Loss: 2.177170, Accuracy: 20.00%\n",
            "Epoch: 48, Step: 11/655, Loss: 2.175813, Accuracy: 20.45%\n",
            "Epoch: 48, Step: 12/655, Loss: 2.178168, Accuracy: 20.57%\n",
            "Epoch: 48, Step: 13/655, Loss: 2.186372, Accuracy: 20.43%\n",
            "Epoch: 48, Step: 14/655, Loss: 2.188932, Accuracy: 20.31%\n",
            "Epoch: 48, Step: 15/655, Loss: 2.185179, Accuracy: 20.42%\n",
            "Epoch: 48, Step: 16/655, Loss: 2.193658, Accuracy: 20.31%\n",
            "Epoch: 48, Step: 17/655, Loss: 2.195557, Accuracy: 20.04%\n",
            "Epoch: 48, Step: 18/655, Loss: 2.197511, Accuracy: 19.62%\n",
            "Epoch: 48, Step: 19/655, Loss: 2.195897, Accuracy: 20.07%\n",
            "Epoch: 48, Step: 20/655, Loss: 2.192950, Accuracy: 19.84%\n",
            "Epoch: 48, Step: 21/655, Loss: 2.191172, Accuracy: 19.64%\n",
            "Epoch: 48, Step: 22/655, Loss: 2.187159, Accuracy: 19.46%\n",
            "Epoch: 48, Step: 23/655, Loss: 2.190414, Accuracy: 18.89%\n",
            "Epoch: 48, Step: 24/655, Loss: 2.195361, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 25/655, Loss: 2.195709, Accuracy: 18.75%\n",
            "Epoch: 48, Step: 26/655, Loss: 2.192417, Accuracy: 18.87%\n",
            "Epoch: 48, Step: 27/655, Loss: 2.190545, Accuracy: 18.87%\n",
            "Epoch: 48, Step: 28/655, Loss: 2.189620, Accuracy: 19.20%\n",
            "Epoch: 48, Step: 29/655, Loss: 2.187043, Accuracy: 18.97%\n",
            "Epoch: 48, Step: 30/655, Loss: 2.183179, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 31/655, Loss: 2.186693, Accuracy: 18.45%\n",
            "Epoch: 48, Step: 32/655, Loss: 2.184260, Accuracy: 18.46%\n",
            "Epoch: 48, Step: 33/655, Loss: 2.186620, Accuracy: 18.47%\n",
            "Epoch: 48, Step: 34/655, Loss: 2.188173, Accuracy: 18.29%\n",
            "Epoch: 48, Step: 35/655, Loss: 2.187427, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 36/655, Loss: 2.184559, Accuracy: 18.49%\n",
            "Epoch: 48, Step: 37/655, Loss: 2.185478, Accuracy: 18.50%\n",
            "Epoch: 48, Step: 38/655, Loss: 2.190267, Accuracy: 18.34%\n",
            "Epoch: 48, Step: 39/655, Loss: 2.189692, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 40/655, Loss: 2.189360, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 41/655, Loss: 2.188412, Accuracy: 18.67%\n",
            "Epoch: 48, Step: 42/655, Loss: 2.185068, Accuracy: 18.68%\n",
            "Epoch: 48, Step: 43/655, Loss: 2.185783, Accuracy: 18.75%\n",
            "Epoch: 48, Step: 44/655, Loss: 2.186114, Accuracy: 18.89%\n",
            "Epoch: 48, Step: 45/655, Loss: 2.185091, Accuracy: 18.96%\n",
            "Epoch: 48, Step: 46/655, Loss: 2.184701, Accuracy: 19.09%\n",
            "Epoch: 48, Step: 47/655, Loss: 2.187985, Accuracy: 18.88%\n",
            "Epoch: 48, Step: 48/655, Loss: 2.189183, Accuracy: 18.95%\n",
            "Epoch: 48, Step: 49/655, Loss: 2.188801, Accuracy: 18.94%\n",
            "Epoch: 48, Step: 50/655, Loss: 2.188531, Accuracy: 18.81%\n",
            "Epoch: 48, Step: 51/655, Loss: 2.188825, Accuracy: 18.81%\n",
            "Epoch: 48, Step: 52/655, Loss: 2.189384, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 53/655, Loss: 2.191205, Accuracy: 18.46%\n",
            "Epoch: 48, Step: 54/655, Loss: 2.189652, Accuracy: 18.69%\n",
            "Epoch: 48, Step: 55/655, Loss: 2.189368, Accuracy: 18.75%\n",
            "Epoch: 48, Step: 56/655, Loss: 2.188057, Accuracy: 18.86%\n",
            "Epoch: 48, Step: 57/655, Loss: 2.188069, Accuracy: 18.91%\n",
            "Epoch: 48, Step: 58/655, Loss: 2.190969, Accuracy: 18.80%\n",
            "Epoch: 48, Step: 59/655, Loss: 2.191064, Accuracy: 18.86%\n",
            "Epoch: 48, Step: 60/655, Loss: 2.189642, Accuracy: 18.80%\n",
            "Epoch: 48, Step: 61/655, Loss: 2.188441, Accuracy: 18.90%\n",
            "Epoch: 48, Step: 62/655, Loss: 2.190357, Accuracy: 18.70%\n",
            "Epoch: 48, Step: 63/655, Loss: 2.190549, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 64/655, Loss: 2.192253, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 65/655, Loss: 2.194212, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 66/655, Loss: 2.194786, Accuracy: 18.23%\n",
            "Epoch: 48, Step: 67/655, Loss: 2.192867, Accuracy: 18.33%\n",
            "Epoch: 48, Step: 68/655, Loss: 2.192422, Accuracy: 18.24%\n",
            "Epoch: 48, Step: 69/655, Loss: 2.193221, Accuracy: 18.30%\n",
            "Epoch: 48, Step: 70/655, Loss: 2.193996, Accuracy: 18.21%\n",
            "Epoch: 48, Step: 71/655, Loss: 2.194698, Accuracy: 18.27%\n",
            "Epoch: 48, Step: 72/655, Loss: 2.195700, Accuracy: 18.19%\n",
            "Epoch: 48, Step: 73/655, Loss: 2.196569, Accuracy: 18.11%\n",
            "Epoch: 48, Step: 74/655, Loss: 2.197060, Accuracy: 18.07%\n",
            "Epoch: 48, Step: 75/655, Loss: 2.199947, Accuracy: 18.00%\n",
            "Epoch: 48, Step: 76/655, Loss: 2.198852, Accuracy: 18.01%\n",
            "Epoch: 48, Step: 77/655, Loss: 2.198059, Accuracy: 18.14%\n",
            "Epoch: 48, Step: 78/655, Loss: 2.198191, Accuracy: 18.07%\n",
            "Epoch: 48, Step: 79/655, Loss: 2.198068, Accuracy: 18.16%\n",
            "Epoch: 48, Step: 80/655, Loss: 2.198977, Accuracy: 18.09%\n",
            "Epoch: 48, Step: 81/655, Loss: 2.199811, Accuracy: 18.17%\n",
            "Epoch: 48, Step: 82/655, Loss: 2.198582, Accuracy: 18.29%\n",
            "Epoch: 48, Step: 83/655, Loss: 2.199454, Accuracy: 18.26%\n",
            "Epoch: 48, Step: 84/655, Loss: 2.200556, Accuracy: 18.23%\n",
            "Epoch: 48, Step: 85/655, Loss: 2.200650, Accuracy: 18.24%\n",
            "Epoch: 48, Step: 86/655, Loss: 2.199160, Accuracy: 18.39%\n",
            "Epoch: 48, Step: 87/655, Loss: 2.198452, Accuracy: 18.46%\n",
            "Epoch: 48, Step: 88/655, Loss: 2.198244, Accuracy: 18.39%\n",
            "Epoch: 48, Step: 89/655, Loss: 2.198183, Accuracy: 18.47%\n",
            "Epoch: 48, Step: 90/655, Loss: 2.199349, Accuracy: 18.44%\n",
            "Epoch: 48, Step: 91/655, Loss: 2.198880, Accuracy: 18.54%\n",
            "Epoch: 48, Step: 92/655, Loss: 2.199826, Accuracy: 18.48%\n",
            "Epoch: 48, Step: 93/655, Loss: 2.200850, Accuracy: 18.35%\n",
            "Epoch: 48, Step: 94/655, Loss: 2.202220, Accuracy: 18.35%\n",
            "Epoch: 48, Step: 95/655, Loss: 2.202708, Accuracy: 18.29%\n",
            "Epoch: 48, Step: 96/655, Loss: 2.203280, Accuracy: 18.26%\n",
            "Epoch: 48, Step: 97/655, Loss: 2.203463, Accuracy: 18.20%\n",
            "Epoch: 48, Step: 98/655, Loss: 2.202544, Accuracy: 18.27%\n",
            "Epoch: 48, Step: 99/655, Loss: 2.203079, Accuracy: 18.21%\n",
            "Epoch: 48, Step: 100/655, Loss: 2.203834, Accuracy: 18.16%\n",
            "Epoch: 48, Step: 101/655, Loss: 2.203775, Accuracy: 18.04%\n",
            "Epoch: 48, Step: 102/655, Loss: 2.203632, Accuracy: 17.98%\n",
            "Epoch: 48, Step: 103/655, Loss: 2.204294, Accuracy: 17.93%\n",
            "Epoch: 48, Step: 104/655, Loss: 2.204176, Accuracy: 18.03%\n",
            "Epoch: 48, Step: 105/655, Loss: 2.204290, Accuracy: 18.07%\n",
            "Epoch: 48, Step: 106/655, Loss: 2.204816, Accuracy: 18.10%\n",
            "Epoch: 48, Step: 107/655, Loss: 2.204130, Accuracy: 18.20%\n",
            "Epoch: 48, Step: 108/655, Loss: 2.203889, Accuracy: 18.26%\n",
            "Epoch: 48, Step: 109/655, Loss: 2.204668, Accuracy: 18.23%\n",
            "Epoch: 48, Step: 110/655, Loss: 2.205250, Accuracy: 18.18%\n",
            "Epoch: 48, Step: 111/655, Loss: 2.205490, Accuracy: 18.24%\n",
            "Epoch: 48, Step: 112/655, Loss: 2.205533, Accuracy: 18.25%\n",
            "Epoch: 48, Step: 113/655, Loss: 2.205841, Accuracy: 18.25%\n",
            "Epoch: 48, Step: 114/655, Loss: 2.206973, Accuracy: 18.20%\n",
            "Epoch: 48, Step: 115/655, Loss: 2.206123, Accuracy: 18.15%\n",
            "Epoch: 48, Step: 116/655, Loss: 2.206008, Accuracy: 18.18%\n",
            "Epoch: 48, Step: 117/655, Loss: 2.206631, Accuracy: 18.11%\n",
            "Epoch: 48, Step: 118/655, Loss: 2.206967, Accuracy: 18.09%\n",
            "Epoch: 48, Step: 119/655, Loss: 2.205535, Accuracy: 18.17%\n",
            "Epoch: 48, Step: 120/655, Loss: 2.205188, Accuracy: 18.18%\n",
            "Epoch: 48, Step: 121/655, Loss: 2.205325, Accuracy: 18.21%\n",
            "Epoch: 48, Step: 122/655, Loss: 2.205305, Accuracy: 18.16%\n",
            "Epoch: 48, Step: 123/655, Loss: 2.205172, Accuracy: 18.19%\n",
            "Epoch: 48, Step: 124/655, Loss: 2.205428, Accuracy: 18.15%\n",
            "Epoch: 48, Step: 125/655, Loss: 2.205890, Accuracy: 18.10%\n",
            "Epoch: 48, Step: 126/655, Loss: 2.205982, Accuracy: 18.11%\n",
            "Epoch: 48, Step: 127/655, Loss: 2.205074, Accuracy: 18.21%\n",
            "Epoch: 48, Step: 128/655, Loss: 2.204518, Accuracy: 18.24%\n",
            "Epoch: 48, Step: 129/655, Loss: 2.204831, Accuracy: 18.27%\n",
            "Epoch: 48, Step: 130/655, Loss: 2.204831, Accuracy: 18.27%\n",
            "Epoch: 48, Step: 131/655, Loss: 2.204473, Accuracy: 18.34%\n",
            "Epoch: 48, Step: 132/655, Loss: 2.204655, Accuracy: 18.32%\n",
            "Epoch: 48, Step: 133/655, Loss: 2.205551, Accuracy: 18.30%\n",
            "Epoch: 48, Step: 134/655, Loss: 2.205252, Accuracy: 18.31%\n",
            "Epoch: 48, Step: 135/655, Loss: 2.205321, Accuracy: 18.38%\n",
            "Epoch: 48, Step: 136/655, Loss: 2.205808, Accuracy: 18.38%\n",
            "Epoch: 48, Step: 137/655, Loss: 2.206484, Accuracy: 18.36%\n",
            "Epoch: 48, Step: 138/655, Loss: 2.206668, Accuracy: 18.37%\n",
            "Epoch: 48, Step: 139/655, Loss: 2.206432, Accuracy: 18.37%\n",
            "Epoch: 48, Step: 140/655, Loss: 2.206528, Accuracy: 18.37%\n",
            "Epoch: 48, Step: 141/655, Loss: 2.206514, Accuracy: 18.33%\n",
            "Epoch: 48, Step: 142/655, Loss: 2.205701, Accuracy: 18.33%\n",
            "Epoch: 48, Step: 143/655, Loss: 2.205122, Accuracy: 18.38%\n",
            "Epoch: 48, Step: 144/655, Loss: 2.206062, Accuracy: 18.34%\n",
            "Epoch: 48, Step: 145/655, Loss: 2.205832, Accuracy: 18.43%\n",
            "Epoch: 48, Step: 146/655, Loss: 2.205688, Accuracy: 18.43%\n",
            "Epoch: 48, Step: 147/655, Loss: 2.206024, Accuracy: 18.39%\n",
            "Epoch: 48, Step: 148/655, Loss: 2.205542, Accuracy: 18.50%\n",
            "Epoch: 48, Step: 149/655, Loss: 2.206481, Accuracy: 18.46%\n",
            "Epoch: 48, Step: 150/655, Loss: 2.206263, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 151/655, Loss: 2.206500, Accuracy: 18.46%\n",
            "Epoch: 48, Step: 152/655, Loss: 2.206024, Accuracy: 18.48%\n",
            "Epoch: 48, Step: 153/655, Loss: 2.206607, Accuracy: 18.40%\n",
            "Epoch: 48, Step: 154/655, Loss: 2.206836, Accuracy: 18.36%\n",
            "Epoch: 48, Step: 155/655, Loss: 2.206448, Accuracy: 18.33%\n",
            "Epoch: 48, Step: 156/655, Loss: 2.206341, Accuracy: 18.37%\n",
            "Epoch: 48, Step: 157/655, Loss: 2.206253, Accuracy: 18.37%\n",
            "Epoch: 48, Step: 158/655, Loss: 2.206209, Accuracy: 18.37%\n",
            "Epoch: 48, Step: 159/655, Loss: 2.206747, Accuracy: 18.36%\n",
            "Epoch: 48, Step: 160/655, Loss: 2.207392, Accuracy: 18.30%\n",
            "Epoch: 48, Step: 161/655, Loss: 2.207294, Accuracy: 18.32%\n",
            "Epoch: 48, Step: 162/655, Loss: 2.207148, Accuracy: 18.36%\n",
            "Epoch: 48, Step: 163/655, Loss: 2.206339, Accuracy: 18.46%\n",
            "Epoch: 48, Step: 164/655, Loss: 2.205485, Accuracy: 18.50%\n",
            "Epoch: 48, Step: 165/655, Loss: 2.204367, Accuracy: 18.54%\n",
            "Epoch: 48, Step: 166/655, Loss: 2.205003, Accuracy: 18.47%\n",
            "Epoch: 48, Step: 167/655, Loss: 2.204998, Accuracy: 18.53%\n",
            "Epoch: 48, Step: 168/655, Loss: 2.205537, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 169/655, Loss: 2.206007, Accuracy: 18.45%\n",
            "Epoch: 48, Step: 170/655, Loss: 2.205822, Accuracy: 18.46%\n",
            "Epoch: 48, Step: 171/655, Loss: 2.204707, Accuracy: 18.48%\n",
            "Epoch: 48, Step: 172/655, Loss: 2.204875, Accuracy: 18.50%\n",
            "Epoch: 48, Step: 173/655, Loss: 2.204922, Accuracy: 18.50%\n",
            "Epoch: 48, Step: 174/655, Loss: 2.205658, Accuracy: 18.43%\n",
            "Epoch: 48, Step: 175/655, Loss: 2.206001, Accuracy: 18.38%\n",
            "Epoch: 48, Step: 176/655, Loss: 2.206869, Accuracy: 18.31%\n",
            "Epoch: 48, Step: 177/655, Loss: 2.206236, Accuracy: 18.31%\n",
            "Epoch: 48, Step: 178/655, Loss: 2.207123, Accuracy: 18.24%\n",
            "Epoch: 48, Step: 179/655, Loss: 2.206316, Accuracy: 18.23%\n",
            "Epoch: 48, Step: 180/655, Loss: 2.206607, Accuracy: 18.26%\n",
            "Epoch: 48, Step: 181/655, Loss: 2.206530, Accuracy: 18.32%\n",
            "Epoch: 48, Step: 182/655, Loss: 2.206639, Accuracy: 18.29%\n",
            "Epoch: 48, Step: 183/655, Loss: 2.206692, Accuracy: 18.29%\n",
            "Epoch: 48, Step: 184/655, Loss: 2.206247, Accuracy: 18.34%\n",
            "Epoch: 48, Step: 185/655, Loss: 2.206041, Accuracy: 18.40%\n",
            "Epoch: 48, Step: 186/655, Loss: 2.205930, Accuracy: 18.41%\n",
            "Epoch: 48, Step: 187/655, Loss: 2.206241, Accuracy: 18.37%\n",
            "Epoch: 48, Step: 188/655, Loss: 2.206277, Accuracy: 18.37%\n",
            "Epoch: 48, Step: 189/655, Loss: 2.205989, Accuracy: 18.44%\n",
            "Epoch: 48, Step: 190/655, Loss: 2.206264, Accuracy: 18.39%\n",
            "Epoch: 48, Step: 191/655, Loss: 2.206567, Accuracy: 18.36%\n",
            "Epoch: 48, Step: 192/655, Loss: 2.206123, Accuracy: 18.42%\n",
            "Epoch: 48, Step: 193/655, Loss: 2.206065, Accuracy: 18.44%\n",
            "Epoch: 48, Step: 194/655, Loss: 2.206483, Accuracy: 18.43%\n",
            "Epoch: 48, Step: 195/655, Loss: 2.206080, Accuracy: 18.49%\n",
            "Epoch: 48, Step: 196/655, Loss: 2.205547, Accuracy: 18.49%\n",
            "Epoch: 48, Step: 197/655, Loss: 2.205992, Accuracy: 18.42%\n",
            "Epoch: 48, Step: 198/655, Loss: 2.205476, Accuracy: 18.40%\n",
            "Epoch: 48, Step: 199/655, Loss: 2.205716, Accuracy: 18.42%\n",
            "Epoch: 48, Step: 200/655, Loss: 2.205757, Accuracy: 18.45%\n",
            "Epoch: 48, Step: 201/655, Loss: 2.205674, Accuracy: 18.42%\n",
            "Epoch: 48, Step: 202/655, Loss: 2.206040, Accuracy: 18.38%\n",
            "Epoch: 48, Step: 203/655, Loss: 2.206275, Accuracy: 18.38%\n",
            "Epoch: 48, Step: 204/655, Loss: 2.206318, Accuracy: 18.38%\n",
            "Epoch: 48, Step: 205/655, Loss: 2.206264, Accuracy: 18.41%\n",
            "Epoch: 48, Step: 206/655, Loss: 2.206766, Accuracy: 18.39%\n",
            "Epoch: 48, Step: 207/655, Loss: 2.206620, Accuracy: 18.40%\n",
            "Epoch: 48, Step: 208/655, Loss: 2.205771, Accuracy: 18.48%\n",
            "Epoch: 48, Step: 209/655, Loss: 2.206104, Accuracy: 18.47%\n",
            "Epoch: 48, Step: 210/655, Loss: 2.206344, Accuracy: 18.44%\n",
            "Epoch: 48, Step: 211/655, Loss: 2.206798, Accuracy: 18.44%\n",
            "Epoch: 48, Step: 212/655, Loss: 2.206898, Accuracy: 18.43%\n",
            "Epoch: 48, Step: 213/655, Loss: 2.206898, Accuracy: 18.40%\n",
            "Epoch: 48, Step: 214/655, Loss: 2.207385, Accuracy: 18.37%\n",
            "Epoch: 48, Step: 215/655, Loss: 2.207461, Accuracy: 18.36%\n",
            "Epoch: 48, Step: 216/655, Loss: 2.207831, Accuracy: 18.32%\n",
            "Epoch: 48, Step: 217/655, Loss: 2.208251, Accuracy: 18.30%\n",
            "Epoch: 48, Step: 218/655, Loss: 2.208526, Accuracy: 18.26%\n",
            "Epoch: 48, Step: 219/655, Loss: 2.208649, Accuracy: 18.26%\n",
            "Epoch: 48, Step: 220/655, Loss: 2.208145, Accuracy: 18.28%\n",
            "Epoch: 48, Step: 221/655, Loss: 2.208570, Accuracy: 18.30%\n",
            "Epoch: 48, Step: 222/655, Loss: 2.209078, Accuracy: 18.29%\n",
            "Epoch: 48, Step: 223/655, Loss: 2.208828, Accuracy: 18.30%\n",
            "Epoch: 48, Step: 224/655, Loss: 2.209125, Accuracy: 18.28%\n",
            "Epoch: 48, Step: 225/655, Loss: 2.209526, Accuracy: 18.25%\n",
            "Epoch: 48, Step: 226/655, Loss: 2.208978, Accuracy: 18.28%\n",
            "Epoch: 48, Step: 227/655, Loss: 2.208907, Accuracy: 18.27%\n",
            "Epoch: 48, Step: 228/655, Loss: 2.208826, Accuracy: 18.28%\n",
            "Epoch: 48, Step: 229/655, Loss: 2.208267, Accuracy: 18.34%\n",
            "Epoch: 48, Step: 230/655, Loss: 2.208519, Accuracy: 18.33%\n",
            "Epoch: 48, Step: 231/655, Loss: 2.208408, Accuracy: 18.33%\n",
            "Epoch: 48, Step: 232/655, Loss: 2.208526, Accuracy: 18.33%\n",
            "Epoch: 48, Step: 233/655, Loss: 2.208679, Accuracy: 18.31%\n",
            "Epoch: 48, Step: 234/655, Loss: 2.208322, Accuracy: 18.34%\n",
            "Epoch: 48, Step: 235/655, Loss: 2.208647, Accuracy: 18.34%\n",
            "Epoch: 48, Step: 236/655, Loss: 2.209098, Accuracy: 18.35%\n",
            "Epoch: 48, Step: 237/655, Loss: 2.209828, Accuracy: 18.31%\n",
            "Epoch: 48, Step: 238/655, Loss: 2.209678, Accuracy: 18.33%\n",
            "Epoch: 48, Step: 239/655, Loss: 2.209673, Accuracy: 18.34%\n",
            "Epoch: 48, Step: 240/655, Loss: 2.209428, Accuracy: 18.37%\n",
            "Epoch: 48, Step: 241/655, Loss: 2.209749, Accuracy: 18.37%\n",
            "Epoch: 48, Step: 242/655, Loss: 2.209744, Accuracy: 18.38%\n",
            "Epoch: 48, Step: 243/655, Loss: 2.209721, Accuracy: 18.38%\n",
            "Epoch: 48, Step: 244/655, Loss: 2.209638, Accuracy: 18.39%\n",
            "Epoch: 48, Step: 245/655, Loss: 2.209795, Accuracy: 18.41%\n",
            "Epoch: 48, Step: 246/655, Loss: 2.210380, Accuracy: 18.39%\n",
            "Epoch: 48, Step: 247/655, Loss: 2.210169, Accuracy: 18.42%\n",
            "Epoch: 48, Step: 248/655, Loss: 2.210007, Accuracy: 18.46%\n",
            "Epoch: 48, Step: 249/655, Loss: 2.209729, Accuracy: 18.44%\n",
            "Epoch: 48, Step: 250/655, Loss: 2.209138, Accuracy: 18.48%\n",
            "Epoch: 48, Step: 251/655, Loss: 2.209266, Accuracy: 18.45%\n",
            "Epoch: 48, Step: 252/655, Loss: 2.209781, Accuracy: 18.42%\n",
            "Epoch: 48, Step: 253/655, Loss: 2.209424, Accuracy: 18.44%\n",
            "Epoch: 48, Step: 254/655, Loss: 2.209221, Accuracy: 18.44%\n",
            "Epoch: 48, Step: 255/655, Loss: 2.209131, Accuracy: 18.47%\n",
            "Epoch: 48, Step: 256/655, Loss: 2.209163, Accuracy: 18.47%\n",
            "Epoch: 48, Step: 257/655, Loss: 2.208774, Accuracy: 18.47%\n",
            "Epoch: 48, Step: 258/655, Loss: 2.208674, Accuracy: 18.48%\n",
            "Epoch: 48, Step: 259/655, Loss: 2.208645, Accuracy: 18.45%\n",
            "Epoch: 48, Step: 260/655, Loss: 2.208251, Accuracy: 18.50%\n",
            "Epoch: 48, Step: 261/655, Loss: 2.208327, Accuracy: 18.49%\n",
            "Epoch: 48, Step: 262/655, Loss: 2.208340, Accuracy: 18.46%\n",
            "Epoch: 48, Step: 263/655, Loss: 2.208228, Accuracy: 18.49%\n",
            "Epoch: 48, Step: 264/655, Loss: 2.208189, Accuracy: 18.48%\n",
            "Epoch: 48, Step: 265/655, Loss: 2.208804, Accuracy: 18.48%\n",
            "Epoch: 48, Step: 266/655, Loss: 2.208906, Accuracy: 18.46%\n",
            "Epoch: 48, Step: 267/655, Loss: 2.208686, Accuracy: 18.50%\n",
            "Epoch: 48, Step: 268/655, Loss: 2.208843, Accuracy: 18.49%\n",
            "Epoch: 48, Step: 269/655, Loss: 2.208793, Accuracy: 18.48%\n",
            "Epoch: 48, Step: 270/655, Loss: 2.208963, Accuracy: 18.48%\n",
            "Epoch: 48, Step: 271/655, Loss: 2.208587, Accuracy: 18.54%\n",
            "Epoch: 48, Step: 272/655, Loss: 2.208606, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 273/655, Loss: 2.208543, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 274/655, Loss: 2.208814, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 275/655, Loss: 2.208823, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 276/655, Loss: 2.208430, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 277/655, Loss: 2.208502, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 278/655, Loss: 2.208810, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 279/655, Loss: 2.208365, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 280/655, Loss: 2.208569, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 281/655, Loss: 2.208461, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 282/655, Loss: 2.208644, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 283/655, Loss: 2.209194, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 284/655, Loss: 2.209072, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 285/655, Loss: 2.208882, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 286/655, Loss: 2.208960, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 287/655, Loss: 2.209023, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 288/655, Loss: 2.209338, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 289/655, Loss: 2.209705, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 290/655, Loss: 2.209761, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 291/655, Loss: 2.209417, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 292/655, Loss: 2.209224, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 293/655, Loss: 2.209526, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 294/655, Loss: 2.209573, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 295/655, Loss: 2.209079, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 296/655, Loss: 2.209212, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 297/655, Loss: 2.208779, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 298/655, Loss: 2.208618, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 299/655, Loss: 2.208065, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 300/655, Loss: 2.207552, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 301/655, Loss: 2.207551, Accuracy: 18.67%\n",
            "Epoch: 48, Step: 302/655, Loss: 2.207294, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 303/655, Loss: 2.207176, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 304/655, Loss: 2.207230, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 305/655, Loss: 2.207162, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 306/655, Loss: 2.207106, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 307/655, Loss: 2.207124, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 308/655, Loss: 2.207190, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 309/655, Loss: 2.207383, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 310/655, Loss: 2.207384, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 311/655, Loss: 2.207754, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 312/655, Loss: 2.207847, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 313/655, Loss: 2.207892, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 314/655, Loss: 2.207874, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 315/655, Loss: 2.207591, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 316/655, Loss: 2.207785, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 317/655, Loss: 2.207525, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 318/655, Loss: 2.207199, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 319/655, Loss: 2.206791, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 320/655, Loss: 2.206493, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 321/655, Loss: 2.206595, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 322/655, Loss: 2.206917, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 323/655, Loss: 2.207184, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 324/655, Loss: 2.206909, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 325/655, Loss: 2.206890, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 326/655, Loss: 2.206734, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 327/655, Loss: 2.206706, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 328/655, Loss: 2.206717, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 329/655, Loss: 2.206426, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 330/655, Loss: 2.206400, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 331/655, Loss: 2.206122, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 332/655, Loss: 2.206410, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 333/655, Loss: 2.206445, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 334/655, Loss: 2.206444, Accuracy: 18.68%\n",
            "Epoch: 48, Step: 335/655, Loss: 2.206440, Accuracy: 18.67%\n",
            "Epoch: 48, Step: 336/655, Loss: 2.206287, Accuracy: 18.67%\n",
            "Epoch: 48, Step: 337/655, Loss: 2.206312, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 338/655, Loss: 2.205976, Accuracy: 18.67%\n",
            "Epoch: 48, Step: 339/655, Loss: 2.205909, Accuracy: 18.67%\n",
            "Epoch: 48, Step: 340/655, Loss: 2.205751, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 341/655, Loss: 2.205548, Accuracy: 18.68%\n",
            "Epoch: 48, Step: 342/655, Loss: 2.205371, Accuracy: 18.69%\n",
            "Epoch: 48, Step: 343/655, Loss: 2.205206, Accuracy: 18.71%\n",
            "Epoch: 48, Step: 344/655, Loss: 2.204769, Accuracy: 18.76%\n",
            "Epoch: 48, Step: 345/655, Loss: 2.204976, Accuracy: 18.76%\n",
            "Epoch: 48, Step: 346/655, Loss: 2.205363, Accuracy: 18.76%\n",
            "Epoch: 48, Step: 347/655, Loss: 2.205369, Accuracy: 18.74%\n",
            "Epoch: 48, Step: 348/655, Loss: 2.205759, Accuracy: 18.71%\n",
            "Epoch: 48, Step: 349/655, Loss: 2.206006, Accuracy: 18.72%\n",
            "Epoch: 48, Step: 350/655, Loss: 2.205785, Accuracy: 18.73%\n",
            "Epoch: 48, Step: 351/655, Loss: 2.205910, Accuracy: 18.72%\n",
            "Epoch: 48, Step: 352/655, Loss: 2.206159, Accuracy: 18.71%\n",
            "Epoch: 48, Step: 353/655, Loss: 2.206194, Accuracy: 18.71%\n",
            "Epoch: 48, Step: 354/655, Loss: 2.206272, Accuracy: 18.70%\n",
            "Epoch: 48, Step: 355/655, Loss: 2.206276, Accuracy: 18.70%\n",
            "Epoch: 48, Step: 356/655, Loss: 2.206148, Accuracy: 18.72%\n",
            "Epoch: 48, Step: 357/655, Loss: 2.206050, Accuracy: 18.73%\n",
            "Epoch: 48, Step: 358/655, Loss: 2.206156, Accuracy: 18.70%\n",
            "Epoch: 48, Step: 359/655, Loss: 2.205764, Accuracy: 18.73%\n",
            "Epoch: 48, Step: 360/655, Loss: 2.205624, Accuracy: 18.74%\n",
            "Epoch: 48, Step: 361/655, Loss: 2.205417, Accuracy: 18.72%\n",
            "Epoch: 48, Step: 362/655, Loss: 2.205164, Accuracy: 18.69%\n",
            "Epoch: 48, Step: 363/655, Loss: 2.205078, Accuracy: 18.68%\n",
            "Epoch: 48, Step: 364/655, Loss: 2.205285, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 365/655, Loss: 2.205327, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 366/655, Loss: 2.205245, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 367/655, Loss: 2.205289, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 368/655, Loss: 2.205429, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 369/655, Loss: 2.205445, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 370/655, Loss: 2.205633, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 371/655, Loss: 2.206055, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 372/655, Loss: 2.206283, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 373/655, Loss: 2.206061, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 374/655, Loss: 2.205840, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 375/655, Loss: 2.206169, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 376/655, Loss: 2.206420, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 377/655, Loss: 2.206494, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 378/655, Loss: 2.206866, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 379/655, Loss: 2.206621, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 380/655, Loss: 2.206864, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 381/655, Loss: 2.207025, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 382/655, Loss: 2.207044, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 383/655, Loss: 2.207198, Accuracy: 18.55%\n",
            "Epoch: 48, Step: 384/655, Loss: 2.207179, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 385/655, Loss: 2.207285, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 386/655, Loss: 2.207453, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 387/655, Loss: 2.207581, Accuracy: 18.55%\n",
            "Epoch: 48, Step: 388/655, Loss: 2.207921, Accuracy: 18.54%\n",
            "Epoch: 48, Step: 389/655, Loss: 2.207776, Accuracy: 18.55%\n",
            "Epoch: 48, Step: 390/655, Loss: 2.208326, Accuracy: 18.53%\n",
            "Epoch: 48, Step: 391/655, Loss: 2.208306, Accuracy: 18.53%\n",
            "Epoch: 48, Step: 392/655, Loss: 2.208209, Accuracy: 18.55%\n",
            "Epoch: 48, Step: 393/655, Loss: 2.208172, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 394/655, Loss: 2.207997, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 395/655, Loss: 2.207946, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 396/655, Loss: 2.207812, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 397/655, Loss: 2.207681, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 398/655, Loss: 2.207919, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 399/655, Loss: 2.207804, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 400/655, Loss: 2.207799, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 401/655, Loss: 2.207836, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 402/655, Loss: 2.207641, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 403/655, Loss: 2.207577, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 404/655, Loss: 2.207633, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 405/655, Loss: 2.207677, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 406/655, Loss: 2.207924, Accuracy: 18.55%\n",
            "Epoch: 48, Step: 407/655, Loss: 2.207740, Accuracy: 18.55%\n",
            "Epoch: 48, Step: 408/655, Loss: 2.207793, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 409/655, Loss: 2.207723, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 410/655, Loss: 2.207867, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 411/655, Loss: 2.208187, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 412/655, Loss: 2.208171, Accuracy: 18.55%\n",
            "Epoch: 48, Step: 413/655, Loss: 2.208244, Accuracy: 18.54%\n",
            "Epoch: 48, Step: 414/655, Loss: 2.208381, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 415/655, Loss: 2.208638, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 416/655, Loss: 2.208605, Accuracy: 18.55%\n",
            "Epoch: 48, Step: 417/655, Loss: 2.208614, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 418/655, Loss: 2.208445, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 419/655, Loss: 2.208824, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 420/655, Loss: 2.208551, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 421/655, Loss: 2.208276, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 422/655, Loss: 2.208222, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 423/655, Loss: 2.208243, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 424/655, Loss: 2.208331, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 425/655, Loss: 2.208242, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 426/655, Loss: 2.208225, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 427/655, Loss: 2.207844, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 428/655, Loss: 2.208040, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 429/655, Loss: 2.207950, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 430/655, Loss: 2.208066, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 431/655, Loss: 2.208167, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 432/655, Loss: 2.207920, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 433/655, Loss: 2.208114, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 434/655, Loss: 2.208005, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 435/655, Loss: 2.207947, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 436/655, Loss: 2.207856, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 437/655, Loss: 2.207988, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 438/655, Loss: 2.208023, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 439/655, Loss: 2.207895, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 440/655, Loss: 2.207871, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 441/655, Loss: 2.208091, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 442/655, Loss: 2.208097, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 443/655, Loss: 2.207867, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 444/655, Loss: 2.207745, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 445/655, Loss: 2.207904, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 446/655, Loss: 2.208183, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 447/655, Loss: 2.208111, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 448/655, Loss: 2.207835, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 449/655, Loss: 2.207798, Accuracy: 18.67%\n",
            "Epoch: 48, Step: 450/655, Loss: 2.207684, Accuracy: 18.67%\n",
            "Epoch: 48, Step: 451/655, Loss: 2.207731, Accuracy: 18.67%\n",
            "Epoch: 48, Step: 452/655, Loss: 2.207907, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 453/655, Loss: 2.208101, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 454/655, Loss: 2.208042, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 455/655, Loss: 2.208219, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 456/655, Loss: 2.208320, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 457/655, Loss: 2.208160, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 458/655, Loss: 2.208193, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 459/655, Loss: 2.208117, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 460/655, Loss: 2.208226, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 461/655, Loss: 2.208316, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 462/655, Loss: 2.208265, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 463/655, Loss: 2.208240, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 464/655, Loss: 2.208499, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 465/655, Loss: 2.208412, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 466/655, Loss: 2.208351, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 467/655, Loss: 2.208529, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 468/655, Loss: 2.208512, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 469/655, Loss: 2.208673, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 470/655, Loss: 2.208504, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 471/655, Loss: 2.208390, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 472/655, Loss: 2.208261, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 473/655, Loss: 2.208281, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 474/655, Loss: 2.208490, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 475/655, Loss: 2.208432, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 476/655, Loss: 2.208643, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 477/655, Loss: 2.208388, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 478/655, Loss: 2.208313, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 479/655, Loss: 2.208284, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 480/655, Loss: 2.208363, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 481/655, Loss: 2.208326, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 482/655, Loss: 2.208173, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 483/655, Loss: 2.207943, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 484/655, Loss: 2.207929, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 485/655, Loss: 2.208016, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 486/655, Loss: 2.207857, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 487/655, Loss: 2.207799, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 488/655, Loss: 2.207641, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 489/655, Loss: 2.207403, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 490/655, Loss: 2.207379, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 491/655, Loss: 2.207537, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 492/655, Loss: 2.207423, Accuracy: 18.66%\n",
            "Epoch: 48, Step: 493/655, Loss: 2.207232, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 494/655, Loss: 2.207442, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 495/655, Loss: 2.207521, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 496/655, Loss: 2.207557, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 497/655, Loss: 2.207626, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 498/655, Loss: 2.207766, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 499/655, Loss: 2.207880, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 500/655, Loss: 2.208105, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 501/655, Loss: 2.208227, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 502/655, Loss: 2.208157, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 503/655, Loss: 2.208064, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 504/655, Loss: 2.207804, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 505/655, Loss: 2.207958, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 506/655, Loss: 2.207952, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 507/655, Loss: 2.207660, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 508/655, Loss: 2.207758, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 509/655, Loss: 2.207789, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 510/655, Loss: 2.207950, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 511/655, Loss: 2.207868, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 512/655, Loss: 2.207963, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 513/655, Loss: 2.207782, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 514/655, Loss: 2.207940, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 515/655, Loss: 2.207831, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 516/655, Loss: 2.207807, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 517/655, Loss: 2.207662, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 518/655, Loss: 2.207762, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 519/655, Loss: 2.207964, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 520/655, Loss: 2.207723, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 521/655, Loss: 2.207461, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 522/655, Loss: 2.207236, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 523/655, Loss: 2.207408, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 524/655, Loss: 2.207436, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 525/655, Loss: 2.207320, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 526/655, Loss: 2.207450, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 527/655, Loss: 2.207565, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 528/655, Loss: 2.207752, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 529/655, Loss: 2.207540, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 530/655, Loss: 2.207560, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 531/655, Loss: 2.207665, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 532/655, Loss: 2.207436, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 533/655, Loss: 2.207331, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 534/655, Loss: 2.207453, Accuracy: 18.63%\n",
            "Epoch: 48, Step: 535/655, Loss: 2.207438, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 536/655, Loss: 2.207557, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 537/655, Loss: 2.207607, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 538/655, Loss: 2.207415, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 539/655, Loss: 2.207342, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 540/655, Loss: 2.207286, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 541/655, Loss: 2.207040, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 542/655, Loss: 2.207176, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 543/655, Loss: 2.207162, Accuracy: 18.65%\n",
            "Epoch: 48, Step: 544/655, Loss: 2.207398, Accuracy: 18.64%\n",
            "Epoch: 48, Step: 545/655, Loss: 2.207593, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 546/655, Loss: 2.207584, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 547/655, Loss: 2.207352, Accuracy: 18.62%\n",
            "Epoch: 48, Step: 548/655, Loss: 2.207552, Accuracy: 18.61%\n",
            "Epoch: 48, Step: 549/655, Loss: 2.207830, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 550/655, Loss: 2.207807, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 551/655, Loss: 2.207994, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 552/655, Loss: 2.208059, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 553/655, Loss: 2.208108, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 554/655, Loss: 2.208339, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 555/655, Loss: 2.208148, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 556/655, Loss: 2.208023, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 557/655, Loss: 2.207690, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 558/655, Loss: 2.207806, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 559/655, Loss: 2.207783, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 560/655, Loss: 2.207820, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 561/655, Loss: 2.207805, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 562/655, Loss: 2.207892, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 563/655, Loss: 2.207930, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 564/655, Loss: 2.207922, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 565/655, Loss: 2.207932, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 566/655, Loss: 2.207774, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 567/655, Loss: 2.207752, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 568/655, Loss: 2.207723, Accuracy: 18.58%\n",
            "Epoch: 48, Step: 569/655, Loss: 2.207658, Accuracy: 18.60%\n",
            "Epoch: 48, Step: 570/655, Loss: 2.207769, Accuracy: 18.59%\n",
            "Epoch: 48, Step: 571/655, Loss: 2.207650, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 572/655, Loss: 2.207680, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 573/655, Loss: 2.207660, Accuracy: 18.53%\n",
            "Epoch: 48, Step: 574/655, Loss: 2.207584, Accuracy: 18.55%\n",
            "Epoch: 48, Step: 575/655, Loss: 2.207634, Accuracy: 18.55%\n",
            "Epoch: 48, Step: 576/655, Loss: 2.207544, Accuracy: 18.55%\n",
            "Epoch: 48, Step: 577/655, Loss: 2.207401, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 578/655, Loss: 2.207380, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 579/655, Loss: 2.207615, Accuracy: 18.56%\n",
            "Epoch: 48, Step: 580/655, Loss: 2.207664, Accuracy: 18.55%\n",
            "Epoch: 48, Step: 581/655, Loss: 2.207686, Accuracy: 18.53%\n",
            "Epoch: 48, Step: 582/655, Loss: 2.207769, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 583/655, Loss: 2.207994, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 584/655, Loss: 2.207616, Accuracy: 18.54%\n",
            "Epoch: 48, Step: 585/655, Loss: 2.207593, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 586/655, Loss: 2.207869, Accuracy: 18.50%\n",
            "Epoch: 48, Step: 587/655, Loss: 2.208016, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 588/655, Loss: 2.208159, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 589/655, Loss: 2.208059, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 590/655, Loss: 2.207968, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 591/655, Loss: 2.207921, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 592/655, Loss: 2.207881, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 593/655, Loss: 2.207635, Accuracy: 18.50%\n",
            "Epoch: 48, Step: 594/655, Loss: 2.207681, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 595/655, Loss: 2.207648, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 596/655, Loss: 2.207420, Accuracy: 18.53%\n",
            "Epoch: 48, Step: 597/655, Loss: 2.207481, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 598/655, Loss: 2.207641, Accuracy: 18.50%\n",
            "Epoch: 48, Step: 599/655, Loss: 2.207669, Accuracy: 18.49%\n",
            "Epoch: 48, Step: 600/655, Loss: 2.207806, Accuracy: 18.48%\n",
            "Epoch: 48, Step: 601/655, Loss: 2.207711, Accuracy: 18.50%\n",
            "Epoch: 48, Step: 602/655, Loss: 2.207810, Accuracy: 18.50%\n",
            "Epoch: 48, Step: 603/655, Loss: 2.207582, Accuracy: 18.53%\n",
            "Epoch: 48, Step: 604/655, Loss: 2.207681, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 605/655, Loss: 2.207960, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 606/655, Loss: 2.207758, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 607/655, Loss: 2.207621, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 608/655, Loss: 2.207439, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 609/655, Loss: 2.207255, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 610/655, Loss: 2.207227, Accuracy: 18.53%\n",
            "Epoch: 48, Step: 611/655, Loss: 2.207353, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 612/655, Loss: 2.207264, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 613/655, Loss: 2.207396, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 614/655, Loss: 2.207448, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 615/655, Loss: 2.207676, Accuracy: 18.50%\n",
            "Epoch: 48, Step: 616/655, Loss: 2.207709, Accuracy: 18.49%\n",
            "Epoch: 48, Step: 617/655, Loss: 2.207636, Accuracy: 18.49%\n",
            "Epoch: 48, Step: 618/655, Loss: 2.207656, Accuracy: 18.50%\n",
            "Epoch: 48, Step: 619/655, Loss: 2.207804, Accuracy: 18.48%\n",
            "Epoch: 48, Step: 620/655, Loss: 2.207660, Accuracy: 18.49%\n",
            "Epoch: 48, Step: 621/655, Loss: 2.207575, Accuracy: 18.49%\n",
            "Epoch: 48, Step: 622/655, Loss: 2.207744, Accuracy: 18.48%\n",
            "Epoch: 48, Step: 623/655, Loss: 2.207825, Accuracy: 18.46%\n",
            "Epoch: 48, Step: 624/655, Loss: 2.207888, Accuracy: 18.47%\n",
            "Epoch: 48, Step: 625/655, Loss: 2.207930, Accuracy: 18.46%\n",
            "Epoch: 48, Step: 626/655, Loss: 2.208122, Accuracy: 18.46%\n",
            "Epoch: 48, Step: 627/655, Loss: 2.208139, Accuracy: 18.46%\n",
            "Epoch: 48, Step: 628/655, Loss: 2.208156, Accuracy: 18.45%\n",
            "Epoch: 48, Step: 629/655, Loss: 2.208239, Accuracy: 18.44%\n",
            "Epoch: 48, Step: 630/655, Loss: 2.208276, Accuracy: 18.43%\n",
            "Epoch: 48, Step: 631/655, Loss: 2.208214, Accuracy: 18.43%\n",
            "Epoch: 48, Step: 632/655, Loss: 2.208139, Accuracy: 18.44%\n",
            "Epoch: 48, Step: 633/655, Loss: 2.208055, Accuracy: 18.44%\n",
            "Epoch: 48, Step: 634/655, Loss: 2.208114, Accuracy: 18.43%\n",
            "Epoch: 48, Step: 635/655, Loss: 2.208017, Accuracy: 18.45%\n",
            "Epoch: 48, Step: 636/655, Loss: 2.207957, Accuracy: 18.46%\n",
            "Epoch: 48, Step: 637/655, Loss: 2.207779, Accuracy: 18.48%\n",
            "Epoch: 48, Step: 638/655, Loss: 2.207487, Accuracy: 18.50%\n",
            "Epoch: 48, Step: 639/655, Loss: 2.207639, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 640/655, Loss: 2.207543, Accuracy: 18.51%\n",
            "Epoch: 48, Step: 641/655, Loss: 2.207511, Accuracy: 18.53%\n",
            "Epoch: 48, Step: 642/655, Loss: 2.207621, Accuracy: 18.53%\n",
            "Epoch: 48, Step: 643/655, Loss: 2.207572, Accuracy: 18.55%\n",
            "Epoch: 48, Step: 644/655, Loss: 2.207678, Accuracy: 18.55%\n",
            "Epoch: 48, Step: 645/655, Loss: 2.207812, Accuracy: 18.54%\n",
            "Epoch: 48, Step: 646/655, Loss: 2.207942, Accuracy: 18.52%\n",
            "Epoch: 48, Step: 647/655, Loss: 2.207994, Accuracy: 18.54%\n",
            "Epoch: 48, Step: 648/655, Loss: 2.207625, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 649/655, Loss: 2.207503, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 650/655, Loss: 2.207408, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 651/655, Loss: 2.207571, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 652/655, Loss: 2.207500, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 653/655, Loss: 2.207489, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 654/655, Loss: 2.207572, Accuracy: 18.57%\n",
            "Epoch: 48, Step: 655/655, Loss: 2.207153, Accuracy: 18.58%\n",
            "Epoch: 49, Step: 1/655, Loss: 2.214897, Accuracy: 18.75%\n",
            "Epoch: 49, Step: 2/655, Loss: 2.251522, Accuracy: 21.88%\n",
            "Epoch: 49, Step: 3/655, Loss: 2.221789, Accuracy: 22.92%\n",
            "Epoch: 49, Step: 4/655, Loss: 2.225751, Accuracy: 21.09%\n",
            "Epoch: 49, Step: 5/655, Loss: 2.250979, Accuracy: 18.75%\n",
            "Epoch: 49, Step: 6/655, Loss: 2.265554, Accuracy: 18.75%\n",
            "Epoch: 49, Step: 7/655, Loss: 2.243685, Accuracy: 19.20%\n",
            "Epoch: 49, Step: 8/655, Loss: 2.228907, Accuracy: 19.53%\n",
            "Epoch: 49, Step: 9/655, Loss: 2.237312, Accuracy: 19.79%\n",
            "Epoch: 49, Step: 10/655, Loss: 2.235021, Accuracy: 19.69%\n",
            "Epoch: 49, Step: 11/655, Loss: 2.226155, Accuracy: 19.89%\n",
            "Epoch: 49, Step: 12/655, Loss: 2.220849, Accuracy: 20.57%\n",
            "Epoch: 49, Step: 13/655, Loss: 2.213524, Accuracy: 20.67%\n",
            "Epoch: 49, Step: 14/655, Loss: 2.213526, Accuracy: 21.43%\n",
            "Epoch: 49, Step: 15/655, Loss: 2.219735, Accuracy: 20.42%\n",
            "Epoch: 49, Step: 16/655, Loss: 2.222688, Accuracy: 19.92%\n",
            "Epoch: 49, Step: 17/655, Loss: 2.222890, Accuracy: 20.04%\n",
            "Epoch: 49, Step: 18/655, Loss: 2.217097, Accuracy: 20.14%\n",
            "Epoch: 49, Step: 19/655, Loss: 2.222873, Accuracy: 19.41%\n",
            "Epoch: 49, Step: 20/655, Loss: 2.225898, Accuracy: 18.91%\n",
            "Epoch: 49, Step: 21/655, Loss: 2.226054, Accuracy: 19.35%\n",
            "Epoch: 49, Step: 22/655, Loss: 2.227250, Accuracy: 19.32%\n",
            "Epoch: 49, Step: 23/655, Loss: 2.221440, Accuracy: 19.02%\n",
            "Epoch: 49, Step: 24/655, Loss: 2.217954, Accuracy: 19.01%\n",
            "Epoch: 49, Step: 25/655, Loss: 2.220436, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 26/655, Loss: 2.219893, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 27/655, Loss: 2.216679, Accuracy: 18.87%\n",
            "Epoch: 49, Step: 28/655, Loss: 2.214249, Accuracy: 18.97%\n",
            "Epoch: 49, Step: 29/655, Loss: 2.213977, Accuracy: 18.86%\n",
            "Epoch: 49, Step: 30/655, Loss: 2.214106, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 31/655, Loss: 2.214934, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 32/655, Loss: 2.219484, Accuracy: 18.75%\n",
            "Epoch: 49, Step: 33/655, Loss: 2.220297, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 34/655, Loss: 2.220056, Accuracy: 18.47%\n",
            "Epoch: 49, Step: 35/655, Loss: 2.219175, Accuracy: 18.57%\n",
            "Epoch: 49, Step: 36/655, Loss: 2.217815, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 37/655, Loss: 2.217136, Accuracy: 18.92%\n",
            "Epoch: 49, Step: 38/655, Loss: 2.217234, Accuracy: 19.08%\n",
            "Epoch: 49, Step: 39/655, Loss: 2.218130, Accuracy: 19.07%\n",
            "Epoch: 49, Step: 40/655, Loss: 2.217622, Accuracy: 19.06%\n",
            "Epoch: 49, Step: 41/655, Loss: 2.217313, Accuracy: 18.98%\n",
            "Epoch: 49, Step: 42/655, Loss: 2.218829, Accuracy: 18.90%\n",
            "Epoch: 49, Step: 43/655, Loss: 2.219336, Accuracy: 18.75%\n",
            "Epoch: 49, Step: 44/655, Loss: 2.221374, Accuracy: 18.47%\n",
            "Epoch: 49, Step: 45/655, Loss: 2.218642, Accuracy: 18.54%\n",
            "Epoch: 49, Step: 46/655, Loss: 2.217191, Accuracy: 18.41%\n",
            "Epoch: 49, Step: 47/655, Loss: 2.214895, Accuracy: 18.55%\n",
            "Epoch: 49, Step: 48/655, Loss: 2.214772, Accuracy: 18.82%\n",
            "Epoch: 49, Step: 49/655, Loss: 2.214651, Accuracy: 18.69%\n",
            "Epoch: 49, Step: 50/655, Loss: 2.216329, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 51/655, Loss: 2.215801, Accuracy: 18.75%\n",
            "Epoch: 49, Step: 52/655, Loss: 2.215935, Accuracy: 18.87%\n",
            "Epoch: 49, Step: 53/655, Loss: 2.216195, Accuracy: 19.10%\n",
            "Epoch: 49, Step: 54/655, Loss: 2.213940, Accuracy: 19.16%\n",
            "Epoch: 49, Step: 55/655, Loss: 2.213370, Accuracy: 19.09%\n",
            "Epoch: 49, Step: 56/655, Loss: 2.212621, Accuracy: 19.20%\n",
            "Epoch: 49, Step: 57/655, Loss: 2.212108, Accuracy: 19.46%\n",
            "Epoch: 49, Step: 58/655, Loss: 2.210673, Accuracy: 19.56%\n",
            "Epoch: 49, Step: 59/655, Loss: 2.211768, Accuracy: 19.54%\n",
            "Epoch: 49, Step: 60/655, Loss: 2.212131, Accuracy: 19.53%\n",
            "Epoch: 49, Step: 61/655, Loss: 2.213537, Accuracy: 19.42%\n",
            "Epoch: 49, Step: 62/655, Loss: 2.214372, Accuracy: 19.46%\n",
            "Epoch: 49, Step: 63/655, Loss: 2.213987, Accuracy: 19.54%\n",
            "Epoch: 49, Step: 64/655, Loss: 2.213575, Accuracy: 19.58%\n",
            "Epoch: 49, Step: 65/655, Loss: 2.213132, Accuracy: 19.62%\n",
            "Epoch: 49, Step: 66/655, Loss: 2.212072, Accuracy: 19.60%\n",
            "Epoch: 49, Step: 67/655, Loss: 2.211256, Accuracy: 19.64%\n",
            "Epoch: 49, Step: 68/655, Loss: 2.209691, Accuracy: 19.76%\n",
            "Epoch: 49, Step: 69/655, Loss: 2.209607, Accuracy: 19.84%\n",
            "Epoch: 49, Step: 70/655, Loss: 2.210883, Accuracy: 19.78%\n",
            "Epoch: 49, Step: 71/655, Loss: 2.211241, Accuracy: 19.76%\n",
            "Epoch: 49, Step: 72/655, Loss: 2.212662, Accuracy: 19.66%\n",
            "Epoch: 49, Step: 73/655, Loss: 2.212587, Accuracy: 19.52%\n",
            "Epoch: 49, Step: 74/655, Loss: 2.212317, Accuracy: 19.51%\n",
            "Epoch: 49, Step: 75/655, Loss: 2.211709, Accuracy: 19.58%\n",
            "Epoch: 49, Step: 76/655, Loss: 2.211220, Accuracy: 19.65%\n",
            "Epoch: 49, Step: 77/655, Loss: 2.211999, Accuracy: 19.56%\n",
            "Epoch: 49, Step: 78/655, Loss: 2.211431, Accuracy: 19.55%\n",
            "Epoch: 49, Step: 79/655, Loss: 2.212608, Accuracy: 19.50%\n",
            "Epoch: 49, Step: 80/655, Loss: 2.212902, Accuracy: 19.49%\n",
            "Epoch: 49, Step: 81/655, Loss: 2.212145, Accuracy: 19.41%\n",
            "Epoch: 49, Step: 82/655, Loss: 2.211572, Accuracy: 19.40%\n",
            "Epoch: 49, Step: 83/655, Loss: 2.212499, Accuracy: 19.35%\n",
            "Epoch: 49, Step: 84/655, Loss: 2.213006, Accuracy: 19.35%\n",
            "Epoch: 49, Step: 85/655, Loss: 2.211216, Accuracy: 19.56%\n",
            "Epoch: 49, Step: 86/655, Loss: 2.209880, Accuracy: 19.55%\n",
            "Epoch: 49, Step: 87/655, Loss: 2.209732, Accuracy: 19.50%\n",
            "Epoch: 49, Step: 88/655, Loss: 2.209990, Accuracy: 19.42%\n",
            "Epoch: 49, Step: 89/655, Loss: 2.209655, Accuracy: 19.38%\n",
            "Epoch: 49, Step: 90/655, Loss: 2.208430, Accuracy: 19.38%\n",
            "Epoch: 49, Step: 91/655, Loss: 2.208204, Accuracy: 19.44%\n",
            "Epoch: 49, Step: 92/655, Loss: 2.208475, Accuracy: 19.40%\n",
            "Epoch: 49, Step: 93/655, Loss: 2.209230, Accuracy: 19.32%\n",
            "Epoch: 49, Step: 94/655, Loss: 2.209105, Accuracy: 19.41%\n",
            "Epoch: 49, Step: 95/655, Loss: 2.207927, Accuracy: 19.44%\n",
            "Epoch: 49, Step: 96/655, Loss: 2.208400, Accuracy: 19.43%\n",
            "Epoch: 49, Step: 97/655, Loss: 2.207403, Accuracy: 19.46%\n",
            "Epoch: 49, Step: 98/655, Loss: 2.205901, Accuracy: 19.58%\n",
            "Epoch: 49, Step: 99/655, Loss: 2.205446, Accuracy: 19.67%\n",
            "Epoch: 49, Step: 100/655, Loss: 2.204552, Accuracy: 19.75%\n",
            "Epoch: 49, Step: 101/655, Loss: 2.204739, Accuracy: 19.68%\n",
            "Epoch: 49, Step: 102/655, Loss: 2.206470, Accuracy: 19.58%\n",
            "Epoch: 49, Step: 103/655, Loss: 2.206497, Accuracy: 19.57%\n",
            "Epoch: 49, Step: 104/655, Loss: 2.205208, Accuracy: 19.62%\n",
            "Epoch: 49, Step: 105/655, Loss: 2.204961, Accuracy: 19.61%\n",
            "Epoch: 49, Step: 106/655, Loss: 2.204601, Accuracy: 19.60%\n",
            "Epoch: 49, Step: 107/655, Loss: 2.204694, Accuracy: 19.60%\n",
            "Epoch: 49, Step: 108/655, Loss: 2.204466, Accuracy: 19.62%\n",
            "Epoch: 49, Step: 109/655, Loss: 2.203682, Accuracy: 19.55%\n",
            "Epoch: 49, Step: 110/655, Loss: 2.202917, Accuracy: 19.57%\n",
            "Epoch: 49, Step: 111/655, Loss: 2.203341, Accuracy: 19.57%\n",
            "Epoch: 49, Step: 112/655, Loss: 2.202735, Accuracy: 19.56%\n",
            "Epoch: 49, Step: 113/655, Loss: 2.203611, Accuracy: 19.47%\n",
            "Epoch: 49, Step: 114/655, Loss: 2.204406, Accuracy: 19.46%\n",
            "Epoch: 49, Step: 115/655, Loss: 2.205694, Accuracy: 19.35%\n",
            "Epoch: 49, Step: 116/655, Loss: 2.206554, Accuracy: 19.32%\n",
            "Epoch: 49, Step: 117/655, Loss: 2.207858, Accuracy: 19.20%\n",
            "Epoch: 49, Step: 118/655, Loss: 2.207439, Accuracy: 19.25%\n",
            "Epoch: 49, Step: 119/655, Loss: 2.206786, Accuracy: 19.33%\n",
            "Epoch: 49, Step: 120/655, Loss: 2.206487, Accuracy: 19.35%\n",
            "Epoch: 49, Step: 121/655, Loss: 2.204757, Accuracy: 19.45%\n",
            "Epoch: 49, Step: 122/655, Loss: 2.204318, Accuracy: 19.47%\n",
            "Epoch: 49, Step: 123/655, Loss: 2.204922, Accuracy: 19.44%\n",
            "Epoch: 49, Step: 124/655, Loss: 2.205080, Accuracy: 19.41%\n",
            "Epoch: 49, Step: 125/655, Loss: 2.203951, Accuracy: 19.50%\n",
            "Epoch: 49, Step: 126/655, Loss: 2.204195, Accuracy: 19.54%\n",
            "Epoch: 49, Step: 127/655, Loss: 2.202780, Accuracy: 19.56%\n",
            "Epoch: 49, Step: 128/655, Loss: 2.202135, Accuracy: 19.60%\n",
            "Epoch: 49, Step: 129/655, Loss: 2.202922, Accuracy: 19.60%\n",
            "Epoch: 49, Step: 130/655, Loss: 2.203343, Accuracy: 19.57%\n",
            "Epoch: 49, Step: 131/655, Loss: 2.203880, Accuracy: 19.51%\n",
            "Epoch: 49, Step: 132/655, Loss: 2.203939, Accuracy: 19.51%\n",
            "Epoch: 49, Step: 133/655, Loss: 2.204256, Accuracy: 19.45%\n",
            "Epoch: 49, Step: 134/655, Loss: 2.204849, Accuracy: 19.43%\n",
            "Epoch: 49, Step: 135/655, Loss: 2.204600, Accuracy: 19.35%\n",
            "Epoch: 49, Step: 136/655, Loss: 2.204178, Accuracy: 19.32%\n",
            "Epoch: 49, Step: 137/655, Loss: 2.204282, Accuracy: 19.27%\n",
            "Epoch: 49, Step: 138/655, Loss: 2.205829, Accuracy: 19.18%\n",
            "Epoch: 49, Step: 139/655, Loss: 2.205416, Accuracy: 19.18%\n",
            "Epoch: 49, Step: 140/655, Loss: 2.205144, Accuracy: 19.15%\n",
            "Epoch: 49, Step: 141/655, Loss: 2.205726, Accuracy: 19.13%\n",
            "Epoch: 49, Step: 142/655, Loss: 2.206516, Accuracy: 19.10%\n",
            "Epoch: 49, Step: 143/655, Loss: 2.206282, Accuracy: 19.14%\n",
            "Epoch: 49, Step: 144/655, Loss: 2.206962, Accuracy: 19.08%\n",
            "Epoch: 49, Step: 145/655, Loss: 2.206488, Accuracy: 19.05%\n",
            "Epoch: 49, Step: 146/655, Loss: 2.205817, Accuracy: 19.11%\n",
            "Epoch: 49, Step: 147/655, Loss: 2.204932, Accuracy: 19.13%\n",
            "Epoch: 49, Step: 148/655, Loss: 2.204675, Accuracy: 19.17%\n",
            "Epoch: 49, Step: 149/655, Loss: 2.203867, Accuracy: 19.19%\n",
            "Epoch: 49, Step: 150/655, Loss: 2.203971, Accuracy: 19.17%\n",
            "Epoch: 49, Step: 151/655, Loss: 2.204520, Accuracy: 19.18%\n",
            "Epoch: 49, Step: 152/655, Loss: 2.204254, Accuracy: 19.24%\n",
            "Epoch: 49, Step: 153/655, Loss: 2.205053, Accuracy: 19.28%\n",
            "Epoch: 49, Step: 154/655, Loss: 2.206110, Accuracy: 19.22%\n",
            "Epoch: 49, Step: 155/655, Loss: 2.206920, Accuracy: 19.17%\n",
            "Epoch: 49, Step: 156/655, Loss: 2.206575, Accuracy: 19.19%\n",
            "Epoch: 49, Step: 157/655, Loss: 2.206444, Accuracy: 19.17%\n",
            "Epoch: 49, Step: 158/655, Loss: 2.206619, Accuracy: 19.15%\n",
            "Epoch: 49, Step: 159/655, Loss: 2.206786, Accuracy: 19.10%\n",
            "Epoch: 49, Step: 160/655, Loss: 2.206789, Accuracy: 19.10%\n",
            "Epoch: 49, Step: 161/655, Loss: 2.205951, Accuracy: 19.12%\n",
            "Epoch: 49, Step: 162/655, Loss: 2.206528, Accuracy: 19.12%\n",
            "Epoch: 49, Step: 163/655, Loss: 2.207659, Accuracy: 19.04%\n",
            "Epoch: 49, Step: 164/655, Loss: 2.207739, Accuracy: 19.00%\n",
            "Epoch: 49, Step: 165/655, Loss: 2.207958, Accuracy: 18.96%\n",
            "Epoch: 49, Step: 166/655, Loss: 2.208123, Accuracy: 18.92%\n",
            "Epoch: 49, Step: 167/655, Loss: 2.207589, Accuracy: 18.92%\n",
            "Epoch: 49, Step: 168/655, Loss: 2.207493, Accuracy: 18.95%\n",
            "Epoch: 49, Step: 169/655, Loss: 2.207515, Accuracy: 18.99%\n",
            "Epoch: 49, Step: 170/655, Loss: 2.207620, Accuracy: 18.95%\n",
            "Epoch: 49, Step: 171/655, Loss: 2.207489, Accuracy: 18.95%\n",
            "Epoch: 49, Step: 172/655, Loss: 2.207760, Accuracy: 18.95%\n",
            "Epoch: 49, Step: 173/655, Loss: 2.208422, Accuracy: 18.91%\n",
            "Epoch: 49, Step: 174/655, Loss: 2.208570, Accuracy: 18.89%\n",
            "Epoch: 49, Step: 175/655, Loss: 2.208233, Accuracy: 18.89%\n",
            "Epoch: 49, Step: 176/655, Loss: 2.209036, Accuracy: 18.86%\n",
            "Epoch: 49, Step: 177/655, Loss: 2.209763, Accuracy: 18.84%\n",
            "Epoch: 49, Step: 178/655, Loss: 2.209655, Accuracy: 18.82%\n",
            "Epoch: 49, Step: 179/655, Loss: 2.209747, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 180/655, Loss: 2.210029, Accuracy: 18.84%\n",
            "Epoch: 49, Step: 181/655, Loss: 2.209938, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 182/655, Loss: 2.210680, Accuracy: 18.84%\n",
            "Epoch: 49, Step: 183/655, Loss: 2.210576, Accuracy: 18.87%\n",
            "Epoch: 49, Step: 184/655, Loss: 2.211095, Accuracy: 18.80%\n",
            "Epoch: 49, Step: 185/655, Loss: 2.211309, Accuracy: 18.80%\n",
            "Epoch: 49, Step: 186/655, Loss: 2.211463, Accuracy: 18.80%\n",
            "Epoch: 49, Step: 187/655, Loss: 2.211300, Accuracy: 18.83%\n",
            "Epoch: 49, Step: 188/655, Loss: 2.210890, Accuracy: 18.90%\n",
            "Epoch: 49, Step: 189/655, Loss: 2.210721, Accuracy: 18.95%\n",
            "Epoch: 49, Step: 190/655, Loss: 2.210723, Accuracy: 18.91%\n",
            "Epoch: 49, Step: 191/655, Loss: 2.210772, Accuracy: 18.95%\n",
            "Epoch: 49, Step: 192/655, Loss: 2.210947, Accuracy: 19.03%\n",
            "Epoch: 49, Step: 193/655, Loss: 2.210493, Accuracy: 19.06%\n",
            "Epoch: 49, Step: 194/655, Loss: 2.210725, Accuracy: 19.04%\n",
            "Epoch: 49, Step: 195/655, Loss: 2.210543, Accuracy: 19.04%\n",
            "Epoch: 49, Step: 196/655, Loss: 2.210263, Accuracy: 19.05%\n",
            "Epoch: 49, Step: 197/655, Loss: 2.210206, Accuracy: 19.04%\n",
            "Epoch: 49, Step: 198/655, Loss: 2.209885, Accuracy: 19.07%\n",
            "Epoch: 49, Step: 199/655, Loss: 2.210297, Accuracy: 19.03%\n",
            "Epoch: 49, Step: 200/655, Loss: 2.209972, Accuracy: 19.00%\n",
            "Epoch: 49, Step: 201/655, Loss: 2.210417, Accuracy: 18.95%\n",
            "Epoch: 49, Step: 202/655, Loss: 2.210466, Accuracy: 18.95%\n",
            "Epoch: 49, Step: 203/655, Loss: 2.209743, Accuracy: 19.00%\n",
            "Epoch: 49, Step: 204/655, Loss: 2.209525, Accuracy: 18.98%\n",
            "Epoch: 49, Step: 205/655, Loss: 2.210093, Accuracy: 18.92%\n",
            "Epoch: 49, Step: 206/655, Loss: 2.209922, Accuracy: 18.89%\n",
            "Epoch: 49, Step: 207/655, Loss: 2.209870, Accuracy: 18.87%\n",
            "Epoch: 49, Step: 208/655, Loss: 2.209960, Accuracy: 18.84%\n",
            "Epoch: 49, Step: 209/655, Loss: 2.209623, Accuracy: 18.84%\n",
            "Epoch: 49, Step: 210/655, Loss: 2.210228, Accuracy: 18.76%\n",
            "Epoch: 49, Step: 211/655, Loss: 2.210088, Accuracy: 18.75%\n",
            "Epoch: 49, Step: 212/655, Loss: 2.210250, Accuracy: 18.75%\n",
            "Epoch: 49, Step: 213/655, Loss: 2.210321, Accuracy: 18.78%\n",
            "Epoch: 49, Step: 214/655, Loss: 2.210551, Accuracy: 18.74%\n",
            "Epoch: 49, Step: 215/655, Loss: 2.210277, Accuracy: 18.76%\n",
            "Epoch: 49, Step: 216/655, Loss: 2.210089, Accuracy: 18.79%\n",
            "Epoch: 49, Step: 217/655, Loss: 2.210025, Accuracy: 18.78%\n",
            "Epoch: 49, Step: 218/655, Loss: 2.209561, Accuracy: 18.78%\n",
            "Epoch: 49, Step: 219/655, Loss: 2.209501, Accuracy: 18.81%\n",
            "Epoch: 49, Step: 220/655, Loss: 2.209451, Accuracy: 18.78%\n",
            "Epoch: 49, Step: 221/655, Loss: 2.209066, Accuracy: 18.83%\n",
            "Epoch: 49, Step: 222/655, Loss: 2.208717, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 223/655, Loss: 2.208966, Accuracy: 18.81%\n",
            "Epoch: 49, Step: 224/655, Loss: 2.208570, Accuracy: 18.81%\n",
            "Epoch: 49, Step: 225/655, Loss: 2.208121, Accuracy: 18.90%\n",
            "Epoch: 49, Step: 226/655, Loss: 2.207197, Accuracy: 18.99%\n",
            "Epoch: 49, Step: 227/655, Loss: 2.207336, Accuracy: 18.97%\n",
            "Epoch: 49, Step: 228/655, Loss: 2.207861, Accuracy: 18.94%\n",
            "Epoch: 49, Step: 229/655, Loss: 2.207650, Accuracy: 19.00%\n",
            "Epoch: 49, Step: 230/655, Loss: 2.208125, Accuracy: 18.95%\n",
            "Epoch: 49, Step: 231/655, Loss: 2.208014, Accuracy: 18.98%\n",
            "Epoch: 49, Step: 232/655, Loss: 2.207804, Accuracy: 18.98%\n",
            "Epoch: 49, Step: 233/655, Loss: 2.207879, Accuracy: 18.98%\n",
            "Epoch: 49, Step: 234/655, Loss: 2.207707, Accuracy: 18.98%\n",
            "Epoch: 49, Step: 235/655, Loss: 2.207939, Accuracy: 18.95%\n",
            "Epoch: 49, Step: 236/655, Loss: 2.207888, Accuracy: 18.95%\n",
            "Epoch: 49, Step: 237/655, Loss: 2.207922, Accuracy: 18.93%\n",
            "Epoch: 49, Step: 238/655, Loss: 2.208026, Accuracy: 18.92%\n",
            "Epoch: 49, Step: 239/655, Loss: 2.207850, Accuracy: 18.93%\n",
            "Epoch: 49, Step: 240/655, Loss: 2.207881, Accuracy: 18.93%\n",
            "Epoch: 49, Step: 241/655, Loss: 2.208068, Accuracy: 18.93%\n",
            "Epoch: 49, Step: 242/655, Loss: 2.207495, Accuracy: 18.97%\n",
            "Epoch: 49, Step: 243/655, Loss: 2.207535, Accuracy: 18.98%\n",
            "Epoch: 49, Step: 244/655, Loss: 2.207499, Accuracy: 18.94%\n",
            "Epoch: 49, Step: 245/655, Loss: 2.207586, Accuracy: 18.94%\n",
            "Epoch: 49, Step: 246/655, Loss: 2.207309, Accuracy: 18.95%\n",
            "Epoch: 49, Step: 247/655, Loss: 2.207098, Accuracy: 18.95%\n",
            "Epoch: 49, Step: 248/655, Loss: 2.206967, Accuracy: 18.98%\n",
            "Epoch: 49, Step: 249/655, Loss: 2.207221, Accuracy: 18.95%\n",
            "Epoch: 49, Step: 250/655, Loss: 2.207434, Accuracy: 18.96%\n",
            "Epoch: 49, Step: 251/655, Loss: 2.206997, Accuracy: 18.95%\n",
            "Epoch: 49, Step: 252/655, Loss: 2.207239, Accuracy: 18.90%\n",
            "Epoch: 49, Step: 253/655, Loss: 2.207013, Accuracy: 18.90%\n",
            "Epoch: 49, Step: 254/655, Loss: 2.206710, Accuracy: 18.89%\n",
            "Epoch: 49, Step: 255/655, Loss: 2.206381, Accuracy: 18.93%\n",
            "Epoch: 49, Step: 256/655, Loss: 2.206241, Accuracy: 18.92%\n",
            "Epoch: 49, Step: 257/655, Loss: 2.206477, Accuracy: 18.90%\n",
            "Epoch: 49, Step: 258/655, Loss: 2.206800, Accuracy: 18.87%\n",
            "Epoch: 49, Step: 259/655, Loss: 2.206872, Accuracy: 18.83%\n",
            "Epoch: 49, Step: 260/655, Loss: 2.206396, Accuracy: 18.86%\n",
            "Epoch: 49, Step: 261/655, Loss: 2.206841, Accuracy: 18.82%\n",
            "Epoch: 49, Step: 262/655, Loss: 2.206762, Accuracy: 18.82%\n",
            "Epoch: 49, Step: 263/655, Loss: 2.206400, Accuracy: 18.81%\n",
            "Epoch: 49, Step: 264/655, Loss: 2.205894, Accuracy: 18.82%\n",
            "Epoch: 49, Step: 265/655, Loss: 2.205751, Accuracy: 18.82%\n",
            "Epoch: 49, Step: 266/655, Loss: 2.205966, Accuracy: 18.80%\n",
            "Epoch: 49, Step: 267/655, Loss: 2.206392, Accuracy: 18.74%\n",
            "Epoch: 49, Step: 268/655, Loss: 2.206298, Accuracy: 18.75%\n",
            "Epoch: 49, Step: 269/655, Loss: 2.206429, Accuracy: 18.75%\n",
            "Epoch: 49, Step: 270/655, Loss: 2.206322, Accuracy: 18.74%\n",
            "Epoch: 49, Step: 271/655, Loss: 2.206415, Accuracy: 18.76%\n",
            "Epoch: 49, Step: 272/655, Loss: 2.206759, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 273/655, Loss: 2.206454, Accuracy: 18.76%\n",
            "Epoch: 49, Step: 274/655, Loss: 2.206149, Accuracy: 18.77%\n",
            "Epoch: 49, Step: 275/655, Loss: 2.206216, Accuracy: 18.78%\n",
            "Epoch: 49, Step: 276/655, Loss: 2.206118, Accuracy: 18.76%\n",
            "Epoch: 49, Step: 277/655, Loss: 2.205992, Accuracy: 18.81%\n",
            "Epoch: 49, Step: 278/655, Loss: 2.206131, Accuracy: 18.79%\n",
            "Epoch: 49, Step: 279/655, Loss: 2.205703, Accuracy: 18.81%\n",
            "Epoch: 49, Step: 280/655, Loss: 2.205770, Accuracy: 18.81%\n",
            "Epoch: 49, Step: 281/655, Loss: 2.206053, Accuracy: 18.82%\n",
            "Epoch: 49, Step: 282/655, Loss: 2.205996, Accuracy: 18.82%\n",
            "Epoch: 49, Step: 283/655, Loss: 2.206222, Accuracy: 18.82%\n",
            "Epoch: 49, Step: 284/655, Loss: 2.206623, Accuracy: 18.81%\n",
            "Epoch: 49, Step: 285/655, Loss: 2.206917, Accuracy: 18.78%\n",
            "Epoch: 49, Step: 286/655, Loss: 2.206383, Accuracy: 18.84%\n",
            "Epoch: 49, Step: 287/655, Loss: 2.206558, Accuracy: 18.84%\n",
            "Epoch: 49, Step: 288/655, Loss: 2.206656, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 289/655, Loss: 2.206678, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 290/655, Loss: 2.206843, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 291/655, Loss: 2.206685, Accuracy: 18.87%\n",
            "Epoch: 49, Step: 292/655, Loss: 2.207112, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 293/655, Loss: 2.207467, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 294/655, Loss: 2.207373, Accuracy: 18.86%\n",
            "Epoch: 49, Step: 295/655, Loss: 2.207417, Accuracy: 18.87%\n",
            "Epoch: 49, Step: 296/655, Loss: 2.207135, Accuracy: 18.90%\n",
            "Epoch: 49, Step: 297/655, Loss: 2.207171, Accuracy: 18.93%\n",
            "Epoch: 49, Step: 298/655, Loss: 2.207349, Accuracy: 18.90%\n",
            "Epoch: 49, Step: 299/655, Loss: 2.207039, Accuracy: 18.93%\n",
            "Epoch: 49, Step: 300/655, Loss: 2.206991, Accuracy: 18.90%\n",
            "Epoch: 49, Step: 301/655, Loss: 2.206899, Accuracy: 18.88%\n",
            "Epoch: 49, Step: 302/655, Loss: 2.207037, Accuracy: 18.86%\n",
            "Epoch: 49, Step: 303/655, Loss: 2.206760, Accuracy: 18.86%\n",
            "Epoch: 49, Step: 304/655, Loss: 2.207189, Accuracy: 18.82%\n",
            "Epoch: 49, Step: 305/655, Loss: 2.207391, Accuracy: 18.80%\n",
            "Epoch: 49, Step: 306/655, Loss: 2.207304, Accuracy: 18.82%\n",
            "Epoch: 49, Step: 307/655, Loss: 2.207230, Accuracy: 18.86%\n",
            "Epoch: 49, Step: 308/655, Loss: 2.207021, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 309/655, Loss: 2.207458, Accuracy: 18.81%\n",
            "Epoch: 49, Step: 310/655, Loss: 2.207990, Accuracy: 18.79%\n",
            "Epoch: 49, Step: 311/655, Loss: 2.207929, Accuracy: 18.80%\n",
            "Epoch: 49, Step: 312/655, Loss: 2.208119, Accuracy: 18.78%\n",
            "Epoch: 49, Step: 313/655, Loss: 2.207964, Accuracy: 18.79%\n",
            "Epoch: 49, Step: 314/655, Loss: 2.207952, Accuracy: 18.80%\n",
            "Epoch: 49, Step: 315/655, Loss: 2.208432, Accuracy: 18.79%\n",
            "Epoch: 49, Step: 316/655, Loss: 2.208428, Accuracy: 18.79%\n",
            "Epoch: 49, Step: 317/655, Loss: 2.208220, Accuracy: 18.80%\n",
            "Epoch: 49, Step: 318/655, Loss: 2.208606, Accuracy: 18.79%\n",
            "Epoch: 49, Step: 319/655, Loss: 2.208603, Accuracy: 18.75%\n",
            "Epoch: 49, Step: 320/655, Loss: 2.208870, Accuracy: 18.76%\n",
            "Epoch: 49, Step: 321/655, Loss: 2.209276, Accuracy: 18.74%\n",
            "Epoch: 49, Step: 322/655, Loss: 2.209173, Accuracy: 18.74%\n",
            "Epoch: 49, Step: 323/655, Loss: 2.208758, Accuracy: 18.79%\n",
            "Epoch: 49, Step: 324/655, Loss: 2.208938, Accuracy: 18.78%\n",
            "Epoch: 49, Step: 325/655, Loss: 2.208706, Accuracy: 18.80%\n",
            "Epoch: 49, Step: 326/655, Loss: 2.208961, Accuracy: 18.80%\n",
            "Epoch: 49, Step: 327/655, Loss: 2.209214, Accuracy: 18.80%\n",
            "Epoch: 49, Step: 328/655, Loss: 2.208970, Accuracy: 18.84%\n",
            "Epoch: 49, Step: 329/655, Loss: 2.209042, Accuracy: 18.82%\n",
            "Epoch: 49, Step: 330/655, Loss: 2.209092, Accuracy: 18.84%\n",
            "Epoch: 49, Step: 331/655, Loss: 2.209386, Accuracy: 18.83%\n",
            "Epoch: 49, Step: 332/655, Loss: 2.209347, Accuracy: 18.79%\n",
            "Epoch: 49, Step: 333/655, Loss: 2.209785, Accuracy: 18.77%\n",
            "Epoch: 49, Step: 334/655, Loss: 2.209776, Accuracy: 18.75%\n",
            "Epoch: 49, Step: 335/655, Loss: 2.209468, Accuracy: 18.78%\n",
            "Epoch: 49, Step: 336/655, Loss: 2.209408, Accuracy: 18.79%\n",
            "Epoch: 49, Step: 337/655, Loss: 2.209604, Accuracy: 18.79%\n",
            "Epoch: 49, Step: 338/655, Loss: 2.210104, Accuracy: 18.76%\n",
            "Epoch: 49, Step: 339/655, Loss: 2.210200, Accuracy: 18.76%\n",
            "Epoch: 49, Step: 340/655, Loss: 2.210114, Accuracy: 18.79%\n",
            "Epoch: 49, Step: 341/655, Loss: 2.210037, Accuracy: 18.80%\n",
            "Epoch: 49, Step: 342/655, Loss: 2.209570, Accuracy: 18.81%\n",
            "Epoch: 49, Step: 343/655, Loss: 2.209182, Accuracy: 18.86%\n",
            "Epoch: 49, Step: 344/655, Loss: 2.209235, Accuracy: 18.87%\n",
            "Epoch: 49, Step: 345/655, Loss: 2.208916, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 346/655, Loss: 2.208994, Accuracy: 18.84%\n",
            "Epoch: 49, Step: 347/655, Loss: 2.209180, Accuracy: 18.82%\n",
            "Epoch: 49, Step: 348/655, Loss: 2.209039, Accuracy: 18.84%\n",
            "Epoch: 49, Step: 349/655, Loss: 2.208908, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 350/655, Loss: 2.208769, Accuracy: 18.86%\n",
            "Epoch: 49, Step: 351/655, Loss: 2.208777, Accuracy: 18.87%\n",
            "Epoch: 49, Step: 352/655, Loss: 2.208850, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 353/655, Loss: 2.208903, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 354/655, Loss: 2.208982, Accuracy: 18.82%\n",
            "Epoch: 49, Step: 355/655, Loss: 2.208832, Accuracy: 18.85%\n",
            "Epoch: 49, Step: 356/655, Loss: 2.208589, Accuracy: 18.86%\n",
            "Epoch: 49, Step: 357/655, Loss: 2.208552, Accuracy: 18.86%\n",
            "Epoch: 49, Step: 358/655, Loss: 2.208724, Accuracy: 18.83%\n",
            "Epoch: 49, Step: 359/655, Loss: 2.208945, Accuracy: 18.82%\n",
            "Epoch: 49, Step: 360/655, Loss: 2.208838, Accuracy: 18.83%\n",
            "Epoch: 49, Step: 361/655, Loss: 2.208983, Accuracy: 18.83%\n",
            "Epoch: 49, Step: 362/655, Loss: 2.209120, Accuracy: 18.83%\n",
            "Epoch: 49, Step: 363/655, Loss: 2.209584, Accuracy: 18.79%\n",
            "Epoch: 49, Step: 364/655, Loss: 2.209641, Accuracy: 18.77%\n",
            "Epoch: 49, Step: 365/655, Loss: 2.209377, Accuracy: 18.77%\n",
            "Epoch: 49, Step: 366/655, Loss: 2.209583, Accuracy: 18.75%\n",
            "Epoch: 49, Step: 367/655, Loss: 2.209753, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 368/655, Loss: 2.210070, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 369/655, Loss: 2.209929, Accuracy: 18.71%\n",
            "Epoch: 49, Step: 370/655, Loss: 2.209636, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 371/655, Loss: 2.209130, Accuracy: 18.78%\n",
            "Epoch: 49, Step: 372/655, Loss: 2.209321, Accuracy: 18.76%\n",
            "Epoch: 49, Step: 373/655, Loss: 2.209334, Accuracy: 18.76%\n",
            "Epoch: 49, Step: 374/655, Loss: 2.209341, Accuracy: 18.77%\n",
            "Epoch: 49, Step: 375/655, Loss: 2.209190, Accuracy: 18.76%\n",
            "Epoch: 49, Step: 376/655, Loss: 2.209081, Accuracy: 18.76%\n",
            "Epoch: 49, Step: 377/655, Loss: 2.208605, Accuracy: 18.81%\n",
            "Epoch: 49, Step: 378/655, Loss: 2.208583, Accuracy: 18.78%\n",
            "Epoch: 49, Step: 379/655, Loss: 2.208526, Accuracy: 18.78%\n",
            "Epoch: 49, Step: 380/655, Loss: 2.208258, Accuracy: 18.78%\n",
            "Epoch: 49, Step: 381/655, Loss: 2.208332, Accuracy: 18.76%\n",
            "Epoch: 49, Step: 382/655, Loss: 2.207948, Accuracy: 18.77%\n",
            "Epoch: 49, Step: 383/655, Loss: 2.207862, Accuracy: 18.76%\n",
            "Epoch: 49, Step: 384/655, Loss: 2.207892, Accuracy: 18.76%\n",
            "Epoch: 49, Step: 385/655, Loss: 2.208132, Accuracy: 18.73%\n",
            "Epoch: 49, Step: 386/655, Loss: 2.208382, Accuracy: 18.71%\n",
            "Epoch: 49, Step: 387/655, Loss: 2.208264, Accuracy: 18.70%\n",
            "Epoch: 49, Step: 388/655, Loss: 2.208186, Accuracy: 18.70%\n",
            "Epoch: 49, Step: 389/655, Loss: 2.208341, Accuracy: 18.69%\n",
            "Epoch: 49, Step: 390/655, Loss: 2.208243, Accuracy: 18.69%\n",
            "Epoch: 49, Step: 391/655, Loss: 2.208727, Accuracy: 18.67%\n",
            "Epoch: 49, Step: 392/655, Loss: 2.208510, Accuracy: 18.70%\n",
            "Epoch: 49, Step: 393/655, Loss: 2.208648, Accuracy: 18.69%\n",
            "Epoch: 49, Step: 394/655, Loss: 2.208489, Accuracy: 18.68%\n",
            "Epoch: 49, Step: 395/655, Loss: 2.208492, Accuracy: 18.69%\n",
            "Epoch: 49, Step: 396/655, Loss: 2.208500, Accuracy: 18.68%\n",
            "Epoch: 49, Step: 397/655, Loss: 2.208820, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 398/655, Loss: 2.208855, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 399/655, Loss: 2.209153, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 400/655, Loss: 2.209164, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 401/655, Loss: 2.208705, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 402/655, Loss: 2.208872, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 403/655, Loss: 2.209018, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 404/655, Loss: 2.209293, Accuracy: 18.57%\n",
            "Epoch: 49, Step: 405/655, Loss: 2.209250, Accuracy: 18.58%\n",
            "Epoch: 49, Step: 406/655, Loss: 2.209396, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 407/655, Loss: 2.209402, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 408/655, Loss: 2.209068, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 409/655, Loss: 2.208924, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 410/655, Loss: 2.208949, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 411/655, Loss: 2.208991, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 412/655, Loss: 2.209320, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 413/655, Loss: 2.209171, Accuracy: 18.58%\n",
            "Epoch: 49, Step: 414/655, Loss: 2.209116, Accuracy: 18.56%\n",
            "Epoch: 49, Step: 415/655, Loss: 2.208867, Accuracy: 18.56%\n",
            "Epoch: 49, Step: 416/655, Loss: 2.209017, Accuracy: 18.55%\n",
            "Epoch: 49, Step: 417/655, Loss: 2.209126, Accuracy: 18.55%\n",
            "Epoch: 49, Step: 418/655, Loss: 2.208999, Accuracy: 18.58%\n",
            "Epoch: 49, Step: 419/655, Loss: 2.208808, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 420/655, Loss: 2.208386, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 421/655, Loss: 2.208265, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 422/655, Loss: 2.208038, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 423/655, Loss: 2.207952, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 424/655, Loss: 2.207587, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 425/655, Loss: 2.207608, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 426/655, Loss: 2.207614, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 427/655, Loss: 2.207248, Accuracy: 18.68%\n",
            "Epoch: 49, Step: 428/655, Loss: 2.207271, Accuracy: 18.67%\n",
            "Epoch: 49, Step: 429/655, Loss: 2.207423, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 430/655, Loss: 2.207326, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 431/655, Loss: 2.207591, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 432/655, Loss: 2.207219, Accuracy: 18.68%\n",
            "Epoch: 49, Step: 433/655, Loss: 2.207406, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 434/655, Loss: 2.207290, Accuracy: 18.67%\n",
            "Epoch: 49, Step: 435/655, Loss: 2.207276, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 436/655, Loss: 2.207260, Accuracy: 18.68%\n",
            "Epoch: 49, Step: 437/655, Loss: 2.206887, Accuracy: 18.71%\n",
            "Epoch: 49, Step: 438/655, Loss: 2.206881, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 439/655, Loss: 2.206786, Accuracy: 18.70%\n",
            "Epoch: 49, Step: 440/655, Loss: 2.206817, Accuracy: 18.70%\n",
            "Epoch: 49, Step: 441/655, Loss: 2.207107, Accuracy: 18.69%\n",
            "Epoch: 49, Step: 442/655, Loss: 2.206791, Accuracy: 18.67%\n",
            "Epoch: 49, Step: 443/655, Loss: 2.207230, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 444/655, Loss: 2.207033, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 445/655, Loss: 2.207126, Accuracy: 18.67%\n",
            "Epoch: 49, Step: 446/655, Loss: 2.207160, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 447/655, Loss: 2.207047, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 448/655, Loss: 2.207366, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 449/655, Loss: 2.207153, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 450/655, Loss: 2.207239, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 451/655, Loss: 2.207233, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 452/655, Loss: 2.207276, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 453/655, Loss: 2.207279, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 454/655, Loss: 2.207391, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 455/655, Loss: 2.207479, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 456/655, Loss: 2.207576, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 457/655, Loss: 2.207781, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 458/655, Loss: 2.207716, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 459/655, Loss: 2.207858, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 460/655, Loss: 2.207973, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 461/655, Loss: 2.208134, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 462/655, Loss: 2.208316, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 463/655, Loss: 2.208552, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 464/655, Loss: 2.208518, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 465/655, Loss: 2.208266, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 466/655, Loss: 2.208173, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 467/655, Loss: 2.208382, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 468/655, Loss: 2.208333, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 469/655, Loss: 2.208529, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 470/655, Loss: 2.208212, Accuracy: 18.67%\n",
            "Epoch: 49, Step: 471/655, Loss: 2.208115, Accuracy: 18.68%\n",
            "Epoch: 49, Step: 472/655, Loss: 2.208090, Accuracy: 18.69%\n",
            "Epoch: 49, Step: 473/655, Loss: 2.208348, Accuracy: 18.69%\n",
            "Epoch: 49, Step: 474/655, Loss: 2.208365, Accuracy: 18.69%\n",
            "Epoch: 49, Step: 475/655, Loss: 2.208247, Accuracy: 18.70%\n",
            "Epoch: 49, Step: 476/655, Loss: 2.208371, Accuracy: 18.70%\n",
            "Epoch: 49, Step: 477/655, Loss: 2.208205, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 478/655, Loss: 2.208133, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 479/655, Loss: 2.208392, Accuracy: 18.70%\n",
            "Epoch: 49, Step: 480/655, Loss: 2.208594, Accuracy: 18.68%\n",
            "Epoch: 49, Step: 481/655, Loss: 2.208547, Accuracy: 18.69%\n",
            "Epoch: 49, Step: 482/655, Loss: 2.208588, Accuracy: 18.70%\n",
            "Epoch: 49, Step: 483/655, Loss: 2.208560, Accuracy: 18.70%\n",
            "Epoch: 49, Step: 484/655, Loss: 2.208462, Accuracy: 18.69%\n",
            "Epoch: 49, Step: 485/655, Loss: 2.208273, Accuracy: 18.69%\n",
            "Epoch: 49, Step: 486/655, Loss: 2.208077, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 487/655, Loss: 2.208157, Accuracy: 18.73%\n",
            "Epoch: 49, Step: 488/655, Loss: 2.208385, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 489/655, Loss: 2.208351, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 490/655, Loss: 2.208467, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 491/655, Loss: 2.208516, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 492/655, Loss: 2.208285, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 493/655, Loss: 2.208336, Accuracy: 18.73%\n",
            "Epoch: 49, Step: 494/655, Loss: 2.208180, Accuracy: 18.73%\n",
            "Epoch: 49, Step: 495/655, Loss: 2.208218, Accuracy: 18.73%\n",
            "Epoch: 49, Step: 496/655, Loss: 2.208103, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 497/655, Loss: 2.208070, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 498/655, Loss: 2.207850, Accuracy: 18.74%\n",
            "Epoch: 49, Step: 499/655, Loss: 2.207754, Accuracy: 18.74%\n",
            "Epoch: 49, Step: 500/655, Loss: 2.207730, Accuracy: 18.71%\n",
            "Epoch: 49, Step: 501/655, Loss: 2.207997, Accuracy: 18.70%\n",
            "Epoch: 49, Step: 502/655, Loss: 2.207922, Accuracy: 18.72%\n",
            "Epoch: 49, Step: 503/655, Loss: 2.208196, Accuracy: 18.71%\n",
            "Epoch: 49, Step: 504/655, Loss: 2.208119, Accuracy: 18.71%\n",
            "Epoch: 49, Step: 505/655, Loss: 2.208162, Accuracy: 18.71%\n",
            "Epoch: 49, Step: 506/655, Loss: 2.208182, Accuracy: 18.69%\n",
            "Epoch: 49, Step: 507/655, Loss: 2.208230, Accuracy: 18.68%\n",
            "Epoch: 49, Step: 508/655, Loss: 2.208181, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 509/655, Loss: 2.208090, Accuracy: 18.67%\n",
            "Epoch: 49, Step: 510/655, Loss: 2.208007, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 511/655, Loss: 2.208170, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 512/655, Loss: 2.208194, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 513/655, Loss: 2.208275, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 514/655, Loss: 2.208294, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 515/655, Loss: 2.208461, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 516/655, Loss: 2.208512, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 517/655, Loss: 2.208716, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 518/655, Loss: 2.208634, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 519/655, Loss: 2.208629, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 520/655, Loss: 2.208625, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 521/655, Loss: 2.208742, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 522/655, Loss: 2.208835, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 523/655, Loss: 2.208747, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 524/655, Loss: 2.208593, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 525/655, Loss: 2.208566, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 526/655, Loss: 2.208547, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 527/655, Loss: 2.208616, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 528/655, Loss: 2.208472, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 529/655, Loss: 2.208448, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 530/655, Loss: 2.208690, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 531/655, Loss: 2.208469, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 532/655, Loss: 2.208350, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 533/655, Loss: 2.208110, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 534/655, Loss: 2.207921, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 535/655, Loss: 2.207801, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 536/655, Loss: 2.207694, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 537/655, Loss: 2.207678, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 538/655, Loss: 2.207603, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 539/655, Loss: 2.207604, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 540/655, Loss: 2.207796, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 541/655, Loss: 2.207647, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 542/655, Loss: 2.207313, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 543/655, Loss: 2.207272, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 544/655, Loss: 2.207353, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 545/655, Loss: 2.207315, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 546/655, Loss: 2.207331, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 547/655, Loss: 2.207601, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 548/655, Loss: 2.207599, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 549/655, Loss: 2.207563, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 550/655, Loss: 2.207712, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 551/655, Loss: 2.207728, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 552/655, Loss: 2.207850, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 553/655, Loss: 2.207644, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 554/655, Loss: 2.207659, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 555/655, Loss: 2.207483, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 556/655, Loss: 2.207487, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 557/655, Loss: 2.207428, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 558/655, Loss: 2.207685, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 559/655, Loss: 2.207736, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 560/655, Loss: 2.207426, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 561/655, Loss: 2.207546, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 562/655, Loss: 2.207507, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 563/655, Loss: 2.207403, Accuracy: 18.68%\n",
            "Epoch: 49, Step: 564/655, Loss: 2.207392, Accuracy: 18.67%\n",
            "Epoch: 49, Step: 565/655, Loss: 2.207466, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 566/655, Loss: 2.207333, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 567/655, Loss: 2.207079, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 568/655, Loss: 2.207133, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 569/655, Loss: 2.207328, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 570/655, Loss: 2.207222, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 571/655, Loss: 2.207263, Accuracy: 18.66%\n",
            "Epoch: 49, Step: 572/655, Loss: 2.207354, Accuracy: 18.65%\n",
            "Epoch: 49, Step: 573/655, Loss: 2.207298, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 574/655, Loss: 2.207101, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 575/655, Loss: 2.207016, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 576/655, Loss: 2.207057, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 577/655, Loss: 2.207044, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 578/655, Loss: 2.207172, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 579/655, Loss: 2.207247, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 580/655, Loss: 2.207365, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 581/655, Loss: 2.207291, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 582/655, Loss: 2.207312, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 583/655, Loss: 2.207477, Accuracy: 18.58%\n",
            "Epoch: 49, Step: 584/655, Loss: 2.207372, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 585/655, Loss: 2.207321, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 586/655, Loss: 2.207179, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 587/655, Loss: 2.207328, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 588/655, Loss: 2.207393, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 589/655, Loss: 2.207508, Accuracy: 18.57%\n",
            "Epoch: 49, Step: 590/655, Loss: 2.207418, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 591/655, Loss: 2.207395, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 592/655, Loss: 2.207477, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 593/655, Loss: 2.207360, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 594/655, Loss: 2.207259, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 595/655, Loss: 2.207450, Accuracy: 18.58%\n",
            "Epoch: 49, Step: 596/655, Loss: 2.207599, Accuracy: 18.58%\n",
            "Epoch: 49, Step: 597/655, Loss: 2.207530, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 598/655, Loss: 2.207537, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 599/655, Loss: 2.207508, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 600/655, Loss: 2.207469, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 601/655, Loss: 2.207633, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 602/655, Loss: 2.207621, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 603/655, Loss: 2.207541, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 604/655, Loss: 2.207503, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 605/655, Loss: 2.207439, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 606/655, Loss: 2.207461, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 607/655, Loss: 2.207444, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 608/655, Loss: 2.207362, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 609/655, Loss: 2.207591, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 610/655, Loss: 2.207534, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 611/655, Loss: 2.207513, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 612/655, Loss: 2.207559, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 613/655, Loss: 2.207555, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 614/655, Loss: 2.207608, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 615/655, Loss: 2.207583, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 616/655, Loss: 2.207690, Accuracy: 18.58%\n",
            "Epoch: 49, Step: 617/655, Loss: 2.207878, Accuracy: 18.58%\n",
            "Epoch: 49, Step: 618/655, Loss: 2.207855, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 619/655, Loss: 2.207939, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 620/655, Loss: 2.208007, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 621/655, Loss: 2.208039, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 622/655, Loss: 2.207816, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 623/655, Loss: 2.207737, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 624/655, Loss: 2.207831, Accuracy: 18.57%\n",
            "Epoch: 49, Step: 625/655, Loss: 2.207752, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 626/655, Loss: 2.207772, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 627/655, Loss: 2.207723, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 628/655, Loss: 2.207734, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 629/655, Loss: 2.207487, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 630/655, Loss: 2.207341, Accuracy: 18.62%\n",
            "Epoch: 49, Step: 631/655, Loss: 2.207201, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 632/655, Loss: 2.207064, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 633/655, Loss: 2.207082, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 634/655, Loss: 2.207087, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 635/655, Loss: 2.207035, Accuracy: 18.64%\n",
            "Epoch: 49, Step: 636/655, Loss: 2.207251, Accuracy: 18.63%\n",
            "Epoch: 49, Step: 637/655, Loss: 2.207436, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 638/655, Loss: 2.207442, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 639/655, Loss: 2.207194, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 640/655, Loss: 2.207384, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 641/655, Loss: 2.207266, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 642/655, Loss: 2.207053, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 643/655, Loss: 2.207148, Accuracy: 18.58%\n",
            "Epoch: 49, Step: 644/655, Loss: 2.207076, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 645/655, Loss: 2.207211, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 646/655, Loss: 2.207251, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 647/655, Loss: 2.207083, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 648/655, Loss: 2.207134, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 649/655, Loss: 2.207266, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 650/655, Loss: 2.207220, Accuracy: 18.59%\n",
            "Epoch: 49, Step: 651/655, Loss: 2.207063, Accuracy: 18.61%\n",
            "Epoch: 49, Step: 652/655, Loss: 2.207153, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 653/655, Loss: 2.207084, Accuracy: 18.60%\n",
            "Epoch: 49, Step: 654/655, Loss: 2.207296, Accuracy: 18.58%\n",
            "Epoch: 49, Step: 655/655, Loss: 2.207733, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 1/655, Loss: 2.238364, Accuracy: 12.50%\n",
            "Epoch: 50, Step: 2/655, Loss: 2.160483, Accuracy: 18.75%\n",
            "Epoch: 50, Step: 3/655, Loss: 2.192420, Accuracy: 18.75%\n",
            "Epoch: 50, Step: 4/655, Loss: 2.176489, Accuracy: 23.44%\n",
            "Epoch: 50, Step: 5/655, Loss: 2.215738, Accuracy: 21.25%\n",
            "Epoch: 50, Step: 6/655, Loss: 2.221973, Accuracy: 20.31%\n",
            "Epoch: 50, Step: 7/655, Loss: 2.201328, Accuracy: 20.09%\n",
            "Epoch: 50, Step: 8/655, Loss: 2.201854, Accuracy: 19.92%\n",
            "Epoch: 50, Step: 9/655, Loss: 2.205018, Accuracy: 19.79%\n",
            "Epoch: 50, Step: 10/655, Loss: 2.192677, Accuracy: 20.31%\n",
            "Epoch: 50, Step: 11/655, Loss: 2.201348, Accuracy: 19.60%\n",
            "Epoch: 50, Step: 12/655, Loss: 2.214096, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 13/655, Loss: 2.214357, Accuracy: 18.75%\n",
            "Epoch: 50, Step: 14/655, Loss: 2.212978, Accuracy: 18.53%\n",
            "Epoch: 50, Step: 15/655, Loss: 2.222239, Accuracy: 17.71%\n",
            "Epoch: 50, Step: 16/655, Loss: 2.224169, Accuracy: 16.99%\n",
            "Epoch: 50, Step: 17/655, Loss: 2.224485, Accuracy: 17.83%\n",
            "Epoch: 50, Step: 18/655, Loss: 2.227550, Accuracy: 17.19%\n",
            "Epoch: 50, Step: 19/655, Loss: 2.233614, Accuracy: 16.94%\n",
            "Epoch: 50, Step: 20/655, Loss: 2.232377, Accuracy: 16.72%\n",
            "Epoch: 50, Step: 21/655, Loss: 2.235727, Accuracy: 16.96%\n",
            "Epoch: 50, Step: 22/655, Loss: 2.233513, Accuracy: 17.05%\n",
            "Epoch: 50, Step: 23/655, Loss: 2.235859, Accuracy: 16.98%\n",
            "Epoch: 50, Step: 24/655, Loss: 2.238064, Accuracy: 16.93%\n",
            "Epoch: 50, Step: 25/655, Loss: 2.242999, Accuracy: 16.88%\n",
            "Epoch: 50, Step: 26/655, Loss: 2.241061, Accuracy: 17.43%\n",
            "Epoch: 50, Step: 27/655, Loss: 2.235851, Accuracy: 17.82%\n",
            "Epoch: 50, Step: 28/655, Loss: 2.235316, Accuracy: 18.08%\n",
            "Epoch: 50, Step: 29/655, Loss: 2.235518, Accuracy: 18.43%\n",
            "Epoch: 50, Step: 30/655, Loss: 2.234503, Accuracy: 18.23%\n",
            "Epoch: 50, Step: 31/655, Loss: 2.232920, Accuracy: 18.15%\n",
            "Epoch: 50, Step: 32/655, Loss: 2.235229, Accuracy: 18.16%\n",
            "Epoch: 50, Step: 33/655, Loss: 2.235946, Accuracy: 17.90%\n",
            "Epoch: 50, Step: 34/655, Loss: 2.233775, Accuracy: 17.74%\n",
            "Epoch: 50, Step: 35/655, Loss: 2.230714, Accuracy: 17.86%\n",
            "Epoch: 50, Step: 36/655, Loss: 2.228844, Accuracy: 18.14%\n",
            "Epoch: 50, Step: 37/655, Loss: 2.226828, Accuracy: 18.16%\n",
            "Epoch: 50, Step: 38/655, Loss: 2.229867, Accuracy: 17.93%\n",
            "Epoch: 50, Step: 39/655, Loss: 2.228614, Accuracy: 18.03%\n",
            "Epoch: 50, Step: 40/655, Loss: 2.227396, Accuracy: 18.05%\n",
            "Epoch: 50, Step: 41/655, Loss: 2.226706, Accuracy: 17.84%\n",
            "Epoch: 50, Step: 42/655, Loss: 2.230418, Accuracy: 17.63%\n",
            "Epoch: 50, Step: 43/655, Loss: 2.228175, Accuracy: 17.59%\n",
            "Epoch: 50, Step: 44/655, Loss: 2.228193, Accuracy: 17.76%\n",
            "Epoch: 50, Step: 45/655, Loss: 2.227525, Accuracy: 17.57%\n",
            "Epoch: 50, Step: 46/655, Loss: 2.226395, Accuracy: 17.53%\n",
            "Epoch: 50, Step: 47/655, Loss: 2.224361, Accuracy: 17.55%\n",
            "Epoch: 50, Step: 48/655, Loss: 2.222590, Accuracy: 17.64%\n",
            "Epoch: 50, Step: 49/655, Loss: 2.222666, Accuracy: 17.67%\n",
            "Epoch: 50, Step: 50/655, Loss: 2.220261, Accuracy: 17.56%\n",
            "Epoch: 50, Step: 51/655, Loss: 2.220076, Accuracy: 17.83%\n",
            "Epoch: 50, Step: 52/655, Loss: 2.220512, Accuracy: 17.91%\n",
            "Epoch: 50, Step: 53/655, Loss: 2.219715, Accuracy: 17.98%\n",
            "Epoch: 50, Step: 54/655, Loss: 2.221053, Accuracy: 17.82%\n",
            "Epoch: 50, Step: 55/655, Loss: 2.222113, Accuracy: 17.78%\n",
            "Epoch: 50, Step: 56/655, Loss: 2.220956, Accuracy: 17.91%\n",
            "Epoch: 50, Step: 57/655, Loss: 2.220855, Accuracy: 17.82%\n",
            "Epoch: 50, Step: 58/655, Loss: 2.222261, Accuracy: 17.73%\n",
            "Epoch: 50, Step: 59/655, Loss: 2.222661, Accuracy: 17.69%\n",
            "Epoch: 50, Step: 60/655, Loss: 2.220245, Accuracy: 17.66%\n",
            "Epoch: 50, Step: 61/655, Loss: 2.222116, Accuracy: 17.52%\n",
            "Epoch: 50, Step: 62/655, Loss: 2.223149, Accuracy: 17.49%\n",
            "Epoch: 50, Step: 63/655, Loss: 2.222199, Accuracy: 17.46%\n",
            "Epoch: 50, Step: 64/655, Loss: 2.219978, Accuracy: 17.53%\n",
            "Epoch: 50, Step: 65/655, Loss: 2.220682, Accuracy: 17.55%\n",
            "Epoch: 50, Step: 66/655, Loss: 2.221415, Accuracy: 17.57%\n",
            "Epoch: 50, Step: 67/655, Loss: 2.220937, Accuracy: 17.63%\n",
            "Epoch: 50, Step: 68/655, Loss: 2.219852, Accuracy: 17.69%\n",
            "Epoch: 50, Step: 69/655, Loss: 2.217236, Accuracy: 18.03%\n",
            "Epoch: 50, Step: 70/655, Loss: 2.216401, Accuracy: 18.04%\n",
            "Epoch: 50, Step: 71/655, Loss: 2.214803, Accuracy: 18.05%\n",
            "Epoch: 50, Step: 72/655, Loss: 2.216547, Accuracy: 17.93%\n",
            "Epoch: 50, Step: 73/655, Loss: 2.216577, Accuracy: 17.98%\n",
            "Epoch: 50, Step: 74/655, Loss: 2.215576, Accuracy: 18.07%\n",
            "Epoch: 50, Step: 75/655, Loss: 2.215023, Accuracy: 18.12%\n",
            "Epoch: 50, Step: 76/655, Loss: 2.214564, Accuracy: 18.26%\n",
            "Epoch: 50, Step: 77/655, Loss: 2.213347, Accuracy: 18.38%\n",
            "Epoch: 50, Step: 78/655, Loss: 2.211084, Accuracy: 18.55%\n",
            "Epoch: 50, Step: 79/655, Loss: 2.211399, Accuracy: 18.63%\n",
            "Epoch: 50, Step: 80/655, Loss: 2.209804, Accuracy: 18.63%\n",
            "Epoch: 50, Step: 81/655, Loss: 2.210100, Accuracy: 18.71%\n",
            "Epoch: 50, Step: 82/655, Loss: 2.209478, Accuracy: 18.71%\n",
            "Epoch: 50, Step: 83/655, Loss: 2.210102, Accuracy: 18.56%\n",
            "Epoch: 50, Step: 84/655, Loss: 2.211716, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 85/655, Loss: 2.211907, Accuracy: 18.46%\n",
            "Epoch: 50, Step: 86/655, Loss: 2.211937, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 87/655, Loss: 2.211594, Accuracy: 18.53%\n",
            "Epoch: 50, Step: 88/655, Loss: 2.211626, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 89/655, Loss: 2.211121, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 90/655, Loss: 2.210471, Accuracy: 18.65%\n",
            "Epoch: 50, Step: 91/655, Loss: 2.210363, Accuracy: 18.78%\n",
            "Epoch: 50, Step: 92/655, Loss: 2.209993, Accuracy: 18.82%\n",
            "Epoch: 50, Step: 93/655, Loss: 2.211169, Accuracy: 18.78%\n",
            "Epoch: 50, Step: 94/655, Loss: 2.210810, Accuracy: 18.82%\n",
            "Epoch: 50, Step: 95/655, Loss: 2.210293, Accuracy: 18.85%\n",
            "Epoch: 50, Step: 96/655, Loss: 2.209811, Accuracy: 18.88%\n",
            "Epoch: 50, Step: 97/655, Loss: 2.209558, Accuracy: 18.75%\n",
            "Epoch: 50, Step: 98/655, Loss: 2.209628, Accuracy: 18.69%\n",
            "Epoch: 50, Step: 99/655, Loss: 2.209870, Accuracy: 18.66%\n",
            "Epoch: 50, Step: 100/655, Loss: 2.210650, Accuracy: 18.53%\n",
            "Epoch: 50, Step: 101/655, Loss: 2.210466, Accuracy: 18.53%\n",
            "Epoch: 50, Step: 102/655, Loss: 2.210905, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 103/655, Loss: 2.210710, Accuracy: 18.42%\n",
            "Epoch: 50, Step: 104/655, Loss: 2.210635, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 105/655, Loss: 2.209974, Accuracy: 18.51%\n",
            "Epoch: 50, Step: 106/655, Loss: 2.209588, Accuracy: 18.66%\n",
            "Epoch: 50, Step: 107/655, Loss: 2.211310, Accuracy: 18.60%\n",
            "Epoch: 50, Step: 108/655, Loss: 2.211492, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 109/655, Loss: 2.212147, Accuracy: 18.52%\n",
            "Epoch: 50, Step: 110/655, Loss: 2.211751, Accuracy: 18.55%\n",
            "Epoch: 50, Step: 111/655, Loss: 2.212849, Accuracy: 18.55%\n",
            "Epoch: 50, Step: 112/655, Loss: 2.212476, Accuracy: 18.55%\n",
            "Epoch: 50, Step: 113/655, Loss: 2.213649, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 114/655, Loss: 2.213664, Accuracy: 18.42%\n",
            "Epoch: 50, Step: 115/655, Loss: 2.213488, Accuracy: 18.34%\n",
            "Epoch: 50, Step: 116/655, Loss: 2.213091, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 117/655, Loss: 2.212681, Accuracy: 18.48%\n",
            "Epoch: 50, Step: 118/655, Loss: 2.213158, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 119/655, Loss: 2.213228, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 120/655, Loss: 2.212530, Accuracy: 18.67%\n",
            "Epoch: 50, Step: 121/655, Loss: 2.211707, Accuracy: 18.65%\n",
            "Epoch: 50, Step: 122/655, Loss: 2.211437, Accuracy: 18.60%\n",
            "Epoch: 50, Step: 123/655, Loss: 2.212391, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 124/655, Loss: 2.212138, Accuracy: 18.62%\n",
            "Epoch: 50, Step: 125/655, Loss: 2.211473, Accuracy: 18.62%\n",
            "Epoch: 50, Step: 126/655, Loss: 2.211691, Accuracy: 18.60%\n",
            "Epoch: 50, Step: 127/655, Loss: 2.211618, Accuracy: 18.55%\n",
            "Epoch: 50, Step: 128/655, Loss: 2.212888, Accuracy: 18.48%\n",
            "Epoch: 50, Step: 129/655, Loss: 2.212212, Accuracy: 18.56%\n",
            "Epoch: 50, Step: 130/655, Loss: 2.212437, Accuracy: 18.53%\n",
            "Epoch: 50, Step: 131/655, Loss: 2.213093, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 132/655, Loss: 2.212492, Accuracy: 18.56%\n",
            "Epoch: 50, Step: 133/655, Loss: 2.213029, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 134/655, Loss: 2.212862, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 135/655, Loss: 2.212005, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 136/655, Loss: 2.211292, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 137/655, Loss: 2.211616, Accuracy: 18.34%\n",
            "Epoch: 50, Step: 138/655, Loss: 2.211282, Accuracy: 18.23%\n",
            "Epoch: 50, Step: 139/655, Loss: 2.210409, Accuracy: 18.30%\n",
            "Epoch: 50, Step: 140/655, Loss: 2.210590, Accuracy: 18.30%\n",
            "Epoch: 50, Step: 141/655, Loss: 2.210421, Accuracy: 18.24%\n",
            "Epoch: 50, Step: 142/655, Loss: 2.209940, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 143/655, Loss: 2.209189, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 144/655, Loss: 2.209632, Accuracy: 18.23%\n",
            "Epoch: 50, Step: 145/655, Loss: 2.209193, Accuracy: 18.21%\n",
            "Epoch: 50, Step: 146/655, Loss: 2.208519, Accuracy: 18.26%\n",
            "Epoch: 50, Step: 147/655, Loss: 2.207859, Accuracy: 18.35%\n",
            "Epoch: 50, Step: 148/655, Loss: 2.207255, Accuracy: 18.37%\n",
            "Epoch: 50, Step: 149/655, Loss: 2.206357, Accuracy: 18.46%\n",
            "Epoch: 50, Step: 150/655, Loss: 2.206285, Accuracy: 18.48%\n",
            "Epoch: 50, Step: 151/655, Loss: 2.206543, Accuracy: 18.44%\n",
            "Epoch: 50, Step: 152/655, Loss: 2.207484, Accuracy: 18.32%\n",
            "Epoch: 50, Step: 153/655, Loss: 2.208271, Accuracy: 18.24%\n",
            "Epoch: 50, Step: 154/655, Loss: 2.208200, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 155/655, Loss: 2.208070, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 156/655, Loss: 2.207566, Accuracy: 18.33%\n",
            "Epoch: 50, Step: 157/655, Loss: 2.207665, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 158/655, Loss: 2.208183, Accuracy: 18.20%\n",
            "Epoch: 50, Step: 159/655, Loss: 2.208518, Accuracy: 18.18%\n",
            "Epoch: 50, Step: 160/655, Loss: 2.208427, Accuracy: 18.20%\n",
            "Epoch: 50, Step: 161/655, Loss: 2.207596, Accuracy: 18.26%\n",
            "Epoch: 50, Step: 162/655, Loss: 2.206944, Accuracy: 18.33%\n",
            "Epoch: 50, Step: 163/655, Loss: 2.207458, Accuracy: 18.25%\n",
            "Epoch: 50, Step: 164/655, Loss: 2.207570, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 165/655, Loss: 2.207651, Accuracy: 18.30%\n",
            "Epoch: 50, Step: 166/655, Loss: 2.208280, Accuracy: 18.26%\n",
            "Epoch: 50, Step: 167/655, Loss: 2.208382, Accuracy: 18.23%\n",
            "Epoch: 50, Step: 168/655, Loss: 2.208433, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 169/655, Loss: 2.208692, Accuracy: 18.31%\n",
            "Epoch: 50, Step: 170/655, Loss: 2.208737, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 171/655, Loss: 2.208446, Accuracy: 18.24%\n",
            "Epoch: 50, Step: 172/655, Loss: 2.208086, Accuracy: 18.30%\n",
            "Epoch: 50, Step: 173/655, Loss: 2.207393, Accuracy: 18.33%\n",
            "Epoch: 50, Step: 174/655, Loss: 2.207183, Accuracy: 18.37%\n",
            "Epoch: 50, Step: 175/655, Loss: 2.206966, Accuracy: 18.38%\n",
            "Epoch: 50, Step: 176/655, Loss: 2.206498, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 177/655, Loss: 2.206557, Accuracy: 18.43%\n",
            "Epoch: 50, Step: 178/655, Loss: 2.206487, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 179/655, Loss: 2.205914, Accuracy: 18.52%\n",
            "Epoch: 50, Step: 180/655, Loss: 2.206147, Accuracy: 18.52%\n",
            "Epoch: 50, Step: 181/655, Loss: 2.206816, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 182/655, Loss: 2.206536, Accuracy: 18.48%\n",
            "Epoch: 50, Step: 183/655, Loss: 2.206958, Accuracy: 18.43%\n",
            "Epoch: 50, Step: 184/655, Loss: 2.206348, Accuracy: 18.53%\n",
            "Epoch: 50, Step: 185/655, Loss: 2.205799, Accuracy: 18.55%\n",
            "Epoch: 50, Step: 186/655, Loss: 2.205767, Accuracy: 18.55%\n",
            "Epoch: 50, Step: 187/655, Loss: 2.205688, Accuracy: 18.52%\n",
            "Epoch: 50, Step: 188/655, Loss: 2.205485, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 189/655, Loss: 2.205152, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 190/655, Loss: 2.205805, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 191/655, Loss: 2.206223, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 192/655, Loss: 2.205657, Accuracy: 18.34%\n",
            "Epoch: 50, Step: 193/655, Loss: 2.205335, Accuracy: 18.31%\n",
            "Epoch: 50, Step: 194/655, Loss: 2.205345, Accuracy: 18.32%\n",
            "Epoch: 50, Step: 195/655, Loss: 2.205722, Accuracy: 18.29%\n",
            "Epoch: 50, Step: 196/655, Loss: 2.206272, Accuracy: 18.26%\n",
            "Epoch: 50, Step: 197/655, Loss: 2.206542, Accuracy: 18.21%\n",
            "Epoch: 50, Step: 198/655, Loss: 2.206601, Accuracy: 18.20%\n",
            "Epoch: 50, Step: 199/655, Loss: 2.206577, Accuracy: 18.20%\n",
            "Epoch: 50, Step: 200/655, Loss: 2.206576, Accuracy: 18.20%\n",
            "Epoch: 50, Step: 201/655, Loss: 2.206893, Accuracy: 18.14%\n",
            "Epoch: 50, Step: 202/655, Loss: 2.206710, Accuracy: 18.21%\n",
            "Epoch: 50, Step: 203/655, Loss: 2.206442, Accuracy: 18.21%\n",
            "Epoch: 50, Step: 204/655, Loss: 2.206026, Accuracy: 18.29%\n",
            "Epoch: 50, Step: 205/655, Loss: 2.207045, Accuracy: 18.25%\n",
            "Epoch: 50, Step: 206/655, Loss: 2.206795, Accuracy: 18.25%\n",
            "Epoch: 50, Step: 207/655, Loss: 2.206465, Accuracy: 18.24%\n",
            "Epoch: 50, Step: 208/655, Loss: 2.206253, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 209/655, Loss: 2.206125, Accuracy: 18.26%\n",
            "Epoch: 50, Step: 210/655, Loss: 2.206022, Accuracy: 18.26%\n",
            "Epoch: 50, Step: 211/655, Loss: 2.206508, Accuracy: 18.26%\n",
            "Epoch: 50, Step: 212/655, Loss: 2.206595, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 213/655, Loss: 2.207118, Accuracy: 18.31%\n",
            "Epoch: 50, Step: 214/655, Loss: 2.207947, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 215/655, Loss: 2.208832, Accuracy: 18.24%\n",
            "Epoch: 50, Step: 216/655, Loss: 2.209521, Accuracy: 18.23%\n",
            "Epoch: 50, Step: 217/655, Loss: 2.210156, Accuracy: 18.17%\n",
            "Epoch: 50, Step: 218/655, Loss: 2.210551, Accuracy: 18.15%\n",
            "Epoch: 50, Step: 219/655, Loss: 2.210703, Accuracy: 18.09%\n",
            "Epoch: 50, Step: 220/655, Loss: 2.210486, Accuracy: 18.14%\n",
            "Epoch: 50, Step: 221/655, Loss: 2.210696, Accuracy: 18.14%\n",
            "Epoch: 50, Step: 222/655, Loss: 2.210640, Accuracy: 18.20%\n",
            "Epoch: 50, Step: 223/655, Loss: 2.210741, Accuracy: 18.25%\n",
            "Epoch: 50, Step: 224/655, Loss: 2.210948, Accuracy: 18.21%\n",
            "Epoch: 50, Step: 225/655, Loss: 2.211611, Accuracy: 18.18%\n",
            "Epoch: 50, Step: 226/655, Loss: 2.211329, Accuracy: 18.17%\n",
            "Epoch: 50, Step: 227/655, Loss: 2.211168, Accuracy: 18.16%\n",
            "Epoch: 50, Step: 228/655, Loss: 2.211115, Accuracy: 18.15%\n",
            "Epoch: 50, Step: 229/655, Loss: 2.211272, Accuracy: 18.16%\n",
            "Epoch: 50, Step: 230/655, Loss: 2.211025, Accuracy: 18.19%\n",
            "Epoch: 50, Step: 231/655, Loss: 2.211201, Accuracy: 18.14%\n",
            "Epoch: 50, Step: 232/655, Loss: 2.211764, Accuracy: 18.09%\n",
            "Epoch: 50, Step: 233/655, Loss: 2.211213, Accuracy: 18.15%\n",
            "Epoch: 50, Step: 234/655, Loss: 2.211016, Accuracy: 18.15%\n",
            "Epoch: 50, Step: 235/655, Loss: 2.210742, Accuracy: 18.18%\n",
            "Epoch: 50, Step: 236/655, Loss: 2.211442, Accuracy: 18.14%\n",
            "Epoch: 50, Step: 237/655, Loss: 2.211128, Accuracy: 18.14%\n",
            "Epoch: 50, Step: 238/655, Loss: 2.210984, Accuracy: 18.16%\n",
            "Epoch: 50, Step: 239/655, Loss: 2.211249, Accuracy: 18.15%\n",
            "Epoch: 50, Step: 240/655, Loss: 2.211157, Accuracy: 18.14%\n",
            "Epoch: 50, Step: 241/655, Loss: 2.211152, Accuracy: 18.13%\n",
            "Epoch: 50, Step: 242/655, Loss: 2.211292, Accuracy: 18.16%\n",
            "Epoch: 50, Step: 243/655, Loss: 2.210808, Accuracy: 18.20%\n",
            "Epoch: 50, Step: 244/655, Loss: 2.210836, Accuracy: 18.22%\n",
            "Epoch: 50, Step: 245/655, Loss: 2.210696, Accuracy: 18.25%\n",
            "Epoch: 50, Step: 246/655, Loss: 2.211096, Accuracy: 18.25%\n",
            "Epoch: 50, Step: 247/655, Loss: 2.210901, Accuracy: 18.26%\n",
            "Epoch: 50, Step: 248/655, Loss: 2.210424, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 249/655, Loss: 2.210038, Accuracy: 18.36%\n",
            "Epoch: 50, Step: 250/655, Loss: 2.209985, Accuracy: 18.36%\n",
            "Epoch: 50, Step: 251/655, Loss: 2.209796, Accuracy: 18.38%\n",
            "Epoch: 50, Step: 252/655, Loss: 2.209418, Accuracy: 18.38%\n",
            "Epoch: 50, Step: 253/655, Loss: 2.209363, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 254/655, Loss: 2.208882, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 255/655, Loss: 2.208539, Accuracy: 18.43%\n",
            "Epoch: 50, Step: 256/655, Loss: 2.208281, Accuracy: 18.44%\n",
            "Epoch: 50, Step: 257/655, Loss: 2.208106, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 258/655, Loss: 2.207791, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 259/655, Loss: 2.208254, Accuracy: 18.44%\n",
            "Epoch: 50, Step: 260/655, Loss: 2.207848, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 261/655, Loss: 2.207662, Accuracy: 18.52%\n",
            "Epoch: 50, Step: 262/655, Loss: 2.207974, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 263/655, Loss: 2.207473, Accuracy: 18.51%\n",
            "Epoch: 50, Step: 264/655, Loss: 2.207218, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 265/655, Loss: 2.207049, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 266/655, Loss: 2.206812, Accuracy: 18.53%\n",
            "Epoch: 50, Step: 267/655, Loss: 2.206970, Accuracy: 18.50%\n",
            "Epoch: 50, Step: 268/655, Loss: 2.207173, Accuracy: 18.51%\n",
            "Epoch: 50, Step: 269/655, Loss: 2.207094, Accuracy: 18.51%\n",
            "Epoch: 50, Step: 270/655, Loss: 2.207011, Accuracy: 18.50%\n",
            "Epoch: 50, Step: 271/655, Loss: 2.207104, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 272/655, Loss: 2.206712, Accuracy: 18.46%\n",
            "Epoch: 50, Step: 273/655, Loss: 2.206543, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 274/655, Loss: 2.206127, Accuracy: 18.44%\n",
            "Epoch: 50, Step: 275/655, Loss: 2.206318, Accuracy: 18.42%\n",
            "Epoch: 50, Step: 276/655, Loss: 2.206260, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 277/655, Loss: 2.205977, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 278/655, Loss: 2.205905, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 279/655, Loss: 2.205901, Accuracy: 18.35%\n",
            "Epoch: 50, Step: 280/655, Loss: 2.205791, Accuracy: 18.30%\n",
            "Epoch: 50, Step: 281/655, Loss: 2.205505, Accuracy: 18.34%\n",
            "Epoch: 50, Step: 282/655, Loss: 2.205509, Accuracy: 18.35%\n",
            "Epoch: 50, Step: 283/655, Loss: 2.205840, Accuracy: 18.34%\n",
            "Epoch: 50, Step: 284/655, Loss: 2.205576, Accuracy: 18.35%\n",
            "Epoch: 50, Step: 285/655, Loss: 2.205742, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 286/655, Loss: 2.205256, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 287/655, Loss: 2.205064, Accuracy: 18.37%\n",
            "Epoch: 50, Step: 288/655, Loss: 2.205258, Accuracy: 18.38%\n",
            "Epoch: 50, Step: 289/655, Loss: 2.205454, Accuracy: 18.38%\n",
            "Epoch: 50, Step: 290/655, Loss: 2.205837, Accuracy: 18.36%\n",
            "Epoch: 50, Step: 291/655, Loss: 2.205993, Accuracy: 18.36%\n",
            "Epoch: 50, Step: 292/655, Loss: 2.206253, Accuracy: 18.36%\n",
            "Epoch: 50, Step: 293/655, Loss: 2.206006, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 294/655, Loss: 2.205824, Accuracy: 18.37%\n",
            "Epoch: 50, Step: 295/655, Loss: 2.205555, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 296/655, Loss: 2.205653, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 297/655, Loss: 2.206062, Accuracy: 18.34%\n",
            "Epoch: 50, Step: 298/655, Loss: 2.206165, Accuracy: 18.33%\n",
            "Epoch: 50, Step: 299/655, Loss: 2.206209, Accuracy: 18.29%\n",
            "Epoch: 50, Step: 300/655, Loss: 2.205772, Accuracy: 18.32%\n",
            "Epoch: 50, Step: 301/655, Loss: 2.206211, Accuracy: 18.29%\n",
            "Epoch: 50, Step: 302/655, Loss: 2.206316, Accuracy: 18.31%\n",
            "Epoch: 50, Step: 303/655, Loss: 2.206521, Accuracy: 18.31%\n",
            "Epoch: 50, Step: 304/655, Loss: 2.206319, Accuracy: 18.32%\n",
            "Epoch: 50, Step: 305/655, Loss: 2.206242, Accuracy: 18.32%\n",
            "Epoch: 50, Step: 306/655, Loss: 2.206195, Accuracy: 18.30%\n",
            "Epoch: 50, Step: 307/655, Loss: 2.206603, Accuracy: 18.31%\n",
            "Epoch: 50, Step: 308/655, Loss: 2.206421, Accuracy: 18.32%\n",
            "Epoch: 50, Step: 309/655, Loss: 2.206223, Accuracy: 18.32%\n",
            "Epoch: 50, Step: 310/655, Loss: 2.206254, Accuracy: 18.31%\n",
            "Epoch: 50, Step: 311/655, Loss: 2.206334, Accuracy: 18.32%\n",
            "Epoch: 50, Step: 312/655, Loss: 2.206511, Accuracy: 18.30%\n",
            "Epoch: 50, Step: 313/655, Loss: 2.206274, Accuracy: 18.29%\n",
            "Epoch: 50, Step: 314/655, Loss: 2.206154, Accuracy: 18.32%\n",
            "Epoch: 50, Step: 315/655, Loss: 2.206058, Accuracy: 18.30%\n",
            "Epoch: 50, Step: 316/655, Loss: 2.206128, Accuracy: 18.30%\n",
            "Epoch: 50, Step: 317/655, Loss: 2.206215, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 318/655, Loss: 2.205991, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 319/655, Loss: 2.206147, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 320/655, Loss: 2.206167, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 321/655, Loss: 2.206588, Accuracy: 18.26%\n",
            "Epoch: 50, Step: 322/655, Loss: 2.206627, Accuracy: 18.24%\n",
            "Epoch: 50, Step: 323/655, Loss: 2.206569, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 324/655, Loss: 2.206630, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 325/655, Loss: 2.206724, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 326/655, Loss: 2.207081, Accuracy: 18.24%\n",
            "Epoch: 50, Step: 327/655, Loss: 2.207011, Accuracy: 18.23%\n",
            "Epoch: 50, Step: 328/655, Loss: 2.206818, Accuracy: 18.25%\n",
            "Epoch: 50, Step: 329/655, Loss: 2.206826, Accuracy: 18.24%\n",
            "Epoch: 50, Step: 330/655, Loss: 2.206732, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 331/655, Loss: 2.206953, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 332/655, Loss: 2.207019, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 333/655, Loss: 2.207321, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 334/655, Loss: 2.207263, Accuracy: 18.30%\n",
            "Epoch: 50, Step: 335/655, Loss: 2.207219, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 336/655, Loss: 2.207407, Accuracy: 18.25%\n",
            "Epoch: 50, Step: 337/655, Loss: 2.207283, Accuracy: 18.26%\n",
            "Epoch: 50, Step: 338/655, Loss: 2.207543, Accuracy: 18.24%\n",
            "Epoch: 50, Step: 339/655, Loss: 2.207424, Accuracy: 18.22%\n",
            "Epoch: 50, Step: 340/655, Loss: 2.207335, Accuracy: 18.22%\n",
            "Epoch: 50, Step: 341/655, Loss: 2.207288, Accuracy: 18.22%\n",
            "Epoch: 50, Step: 342/655, Loss: 2.206849, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 343/655, Loss: 2.206806, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 344/655, Loss: 2.207129, Accuracy: 18.23%\n",
            "Epoch: 50, Step: 345/655, Loss: 2.207048, Accuracy: 18.25%\n",
            "Epoch: 50, Step: 346/655, Loss: 2.206874, Accuracy: 18.29%\n",
            "Epoch: 50, Step: 347/655, Loss: 2.207083, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 348/655, Loss: 2.207127, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 349/655, Loss: 2.206975, Accuracy: 18.29%\n",
            "Epoch: 50, Step: 350/655, Loss: 2.206987, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 351/655, Loss: 2.207087, Accuracy: 18.30%\n",
            "Epoch: 50, Step: 352/655, Loss: 2.206971, Accuracy: 18.30%\n",
            "Epoch: 50, Step: 353/655, Loss: 2.206991, Accuracy: 18.29%\n",
            "Epoch: 50, Step: 354/655, Loss: 2.207005, Accuracy: 18.30%\n",
            "Epoch: 50, Step: 355/655, Loss: 2.206841, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 356/655, Loss: 2.206932, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 357/655, Loss: 2.206746, Accuracy: 18.29%\n",
            "Epoch: 50, Step: 358/655, Loss: 2.206981, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 359/655, Loss: 2.206996, Accuracy: 18.26%\n",
            "Epoch: 50, Step: 360/655, Loss: 2.207024, Accuracy: 18.29%\n",
            "Epoch: 50, Step: 361/655, Loss: 2.207047, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 362/655, Loss: 2.207293, Accuracy: 18.26%\n",
            "Epoch: 50, Step: 363/655, Loss: 2.207451, Accuracy: 18.25%\n",
            "Epoch: 50, Step: 364/655, Loss: 2.207556, Accuracy: 18.26%\n",
            "Epoch: 50, Step: 365/655, Loss: 2.207928, Accuracy: 18.24%\n",
            "Epoch: 50, Step: 366/655, Loss: 2.207915, Accuracy: 18.24%\n",
            "Epoch: 50, Step: 367/655, Loss: 2.207942, Accuracy: 18.23%\n",
            "Epoch: 50, Step: 368/655, Loss: 2.207913, Accuracy: 18.27%\n",
            "Epoch: 50, Step: 369/655, Loss: 2.207760, Accuracy: 18.28%\n",
            "Epoch: 50, Step: 370/655, Loss: 2.207721, Accuracy: 18.29%\n",
            "Epoch: 50, Step: 371/655, Loss: 2.207506, Accuracy: 18.33%\n",
            "Epoch: 50, Step: 372/655, Loss: 2.207378, Accuracy: 18.36%\n",
            "Epoch: 50, Step: 373/655, Loss: 2.207015, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 374/655, Loss: 2.206930, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 375/655, Loss: 2.206582, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 376/655, Loss: 2.206650, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 377/655, Loss: 2.206623, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 378/655, Loss: 2.206317, Accuracy: 18.43%\n",
            "Epoch: 50, Step: 379/655, Loss: 2.205968, Accuracy: 18.44%\n",
            "Epoch: 50, Step: 380/655, Loss: 2.205656, Accuracy: 18.46%\n",
            "Epoch: 50, Step: 381/655, Loss: 2.206098, Accuracy: 18.43%\n",
            "Epoch: 50, Step: 382/655, Loss: 2.206338, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 383/655, Loss: 2.206352, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 384/655, Loss: 2.206127, Accuracy: 18.42%\n",
            "Epoch: 50, Step: 385/655, Loss: 2.206173, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 386/655, Loss: 2.206491, Accuracy: 18.42%\n",
            "Epoch: 50, Step: 387/655, Loss: 2.206336, Accuracy: 18.42%\n",
            "Epoch: 50, Step: 388/655, Loss: 2.206527, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 389/655, Loss: 2.206146, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 390/655, Loss: 2.206543, Accuracy: 18.44%\n",
            "Epoch: 50, Step: 391/655, Loss: 2.206886, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 392/655, Loss: 2.206891, Accuracy: 18.42%\n",
            "Epoch: 50, Step: 393/655, Loss: 2.207091, Accuracy: 18.42%\n",
            "Epoch: 50, Step: 394/655, Loss: 2.206992, Accuracy: 18.42%\n",
            "Epoch: 50, Step: 395/655, Loss: 2.206749, Accuracy: 18.44%\n",
            "Epoch: 50, Step: 396/655, Loss: 2.206893, Accuracy: 18.43%\n",
            "Epoch: 50, Step: 397/655, Loss: 2.207047, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 398/655, Loss: 2.206855, Accuracy: 18.44%\n",
            "Epoch: 50, Step: 399/655, Loss: 2.206840, Accuracy: 18.43%\n",
            "Epoch: 50, Step: 400/655, Loss: 2.207011, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 401/655, Loss: 2.206858, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 402/655, Loss: 2.207067, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 403/655, Loss: 2.207254, Accuracy: 18.37%\n",
            "Epoch: 50, Step: 404/655, Loss: 2.207336, Accuracy: 18.36%\n",
            "Epoch: 50, Step: 405/655, Loss: 2.207121, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 406/655, Loss: 2.207089, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 407/655, Loss: 2.206812, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 408/655, Loss: 2.206828, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 409/655, Loss: 2.206358, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 410/655, Loss: 2.206564, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 411/655, Loss: 2.206475, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 412/655, Loss: 2.206480, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 413/655, Loss: 2.206542, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 414/655, Loss: 2.206994, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 415/655, Loss: 2.207172, Accuracy: 18.37%\n",
            "Epoch: 50, Step: 416/655, Loss: 2.207076, Accuracy: 18.37%\n",
            "Epoch: 50, Step: 417/655, Loss: 2.206862, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 418/655, Loss: 2.206843, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 419/655, Loss: 2.207000, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 420/655, Loss: 2.207051, Accuracy: 18.42%\n",
            "Epoch: 50, Step: 421/655, Loss: 2.206917, Accuracy: 18.42%\n",
            "Epoch: 50, Step: 422/655, Loss: 2.207182, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 423/655, Loss: 2.207337, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 424/655, Loss: 2.207415, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 425/655, Loss: 2.207782, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 426/655, Loss: 2.207808, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 427/655, Loss: 2.207901, Accuracy: 18.43%\n",
            "Epoch: 50, Step: 428/655, Loss: 2.207573, Accuracy: 18.46%\n",
            "Epoch: 50, Step: 429/655, Loss: 2.207548, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 430/655, Loss: 2.207448, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 431/655, Loss: 2.207452, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 432/655, Loss: 2.207389, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 433/655, Loss: 2.207655, Accuracy: 18.46%\n",
            "Epoch: 50, Step: 434/655, Loss: 2.207297, Accuracy: 18.48%\n",
            "Epoch: 50, Step: 435/655, Loss: 2.207424, Accuracy: 18.48%\n",
            "Epoch: 50, Step: 436/655, Loss: 2.207699, Accuracy: 18.48%\n",
            "Epoch: 50, Step: 437/655, Loss: 2.207609, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 438/655, Loss: 2.207612, Accuracy: 18.46%\n",
            "Epoch: 50, Step: 439/655, Loss: 2.207596, Accuracy: 18.44%\n",
            "Epoch: 50, Step: 440/655, Loss: 2.207259, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 441/655, Loss: 2.207216, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 442/655, Loss: 2.207250, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 443/655, Loss: 2.207104, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 444/655, Loss: 2.207158, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 445/655, Loss: 2.207203, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 446/655, Loss: 2.207426, Accuracy: 18.48%\n",
            "Epoch: 50, Step: 447/655, Loss: 2.207356, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 448/655, Loss: 2.207649, Accuracy: 18.48%\n",
            "Epoch: 50, Step: 449/655, Loss: 2.207511, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 450/655, Loss: 2.207662, Accuracy: 18.48%\n",
            "Epoch: 50, Step: 451/655, Loss: 2.207634, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 452/655, Loss: 2.207651, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 453/655, Loss: 2.207803, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 454/655, Loss: 2.207911, Accuracy: 18.48%\n",
            "Epoch: 50, Step: 455/655, Loss: 2.207885, Accuracy: 18.48%\n",
            "Epoch: 50, Step: 456/655, Loss: 2.207982, Accuracy: 18.48%\n",
            "Epoch: 50, Step: 457/655, Loss: 2.207795, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 458/655, Loss: 2.207981, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 459/655, Loss: 2.207826, Accuracy: 18.46%\n",
            "Epoch: 50, Step: 460/655, Loss: 2.208108, Accuracy: 18.46%\n",
            "Epoch: 50, Step: 461/655, Loss: 2.208297, Accuracy: 18.44%\n",
            "Epoch: 50, Step: 462/655, Loss: 2.208502, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 463/655, Loss: 2.208509, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 464/655, Loss: 2.208214, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 465/655, Loss: 2.208136, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 466/655, Loss: 2.208311, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 467/655, Loss: 2.208229, Accuracy: 18.39%\n",
            "Epoch: 50, Step: 468/655, Loss: 2.208041, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 469/655, Loss: 2.208440, Accuracy: 18.38%\n",
            "Epoch: 50, Step: 470/655, Loss: 2.208372, Accuracy: 18.38%\n",
            "Epoch: 50, Step: 471/655, Loss: 2.208359, Accuracy: 18.40%\n",
            "Epoch: 50, Step: 472/655, Loss: 2.208376, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 473/655, Loss: 2.208265, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 474/655, Loss: 2.208183, Accuracy: 18.41%\n",
            "Epoch: 50, Step: 475/655, Loss: 2.208024, Accuracy: 18.43%\n",
            "Epoch: 50, Step: 476/655, Loss: 2.207872, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 477/655, Loss: 2.207761, Accuracy: 18.46%\n",
            "Epoch: 50, Step: 478/655, Loss: 2.207678, Accuracy: 18.48%\n",
            "Epoch: 50, Step: 479/655, Loss: 2.207665, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 480/655, Loss: 2.207715, Accuracy: 18.50%\n",
            "Epoch: 50, Step: 481/655, Loss: 2.207642, Accuracy: 18.53%\n",
            "Epoch: 50, Step: 482/655, Loss: 2.208097, Accuracy: 18.50%\n",
            "Epoch: 50, Step: 483/655, Loss: 2.208189, Accuracy: 18.52%\n",
            "Epoch: 50, Step: 484/655, Loss: 2.208329, Accuracy: 18.50%\n",
            "Epoch: 50, Step: 485/655, Loss: 2.208286, Accuracy: 18.50%\n",
            "Epoch: 50, Step: 486/655, Loss: 2.208428, Accuracy: 18.50%\n",
            "Epoch: 50, Step: 487/655, Loss: 2.208316, Accuracy: 18.51%\n",
            "Epoch: 50, Step: 488/655, Loss: 2.208293, Accuracy: 18.53%\n",
            "Epoch: 50, Step: 489/655, Loss: 2.208267, Accuracy: 18.53%\n",
            "Epoch: 50, Step: 490/655, Loss: 2.208227, Accuracy: 18.55%\n",
            "Epoch: 50, Step: 491/655, Loss: 2.208198, Accuracy: 18.55%\n",
            "Epoch: 50, Step: 492/655, Loss: 2.208166, Accuracy: 18.56%\n",
            "Epoch: 50, Step: 493/655, Loss: 2.208045, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 494/655, Loss: 2.208140, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 495/655, Loss: 2.208103, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 496/655, Loss: 2.207963, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 497/655, Loss: 2.207949, Accuracy: 18.60%\n",
            "Epoch: 50, Step: 498/655, Loss: 2.207969, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 499/655, Loss: 2.207903, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 500/655, Loss: 2.207809, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 501/655, Loss: 2.207707, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 502/655, Loss: 2.207878, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 503/655, Loss: 2.207549, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 504/655, Loss: 2.207511, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 505/655, Loss: 2.207470, Accuracy: 18.63%\n",
            "Epoch: 50, Step: 506/655, Loss: 2.207463, Accuracy: 18.60%\n",
            "Epoch: 50, Step: 507/655, Loss: 2.207428, Accuracy: 18.60%\n",
            "Epoch: 50, Step: 508/655, Loss: 2.207419, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 509/655, Loss: 2.207357, Accuracy: 18.60%\n",
            "Epoch: 50, Step: 510/655, Loss: 2.207503, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 511/655, Loss: 2.207665, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 512/655, Loss: 2.207727, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 513/655, Loss: 2.207938, Accuracy: 18.56%\n",
            "Epoch: 50, Step: 514/655, Loss: 2.208160, Accuracy: 18.56%\n",
            "Epoch: 50, Step: 515/655, Loss: 2.208188, Accuracy: 18.55%\n",
            "Epoch: 50, Step: 516/655, Loss: 2.208399, Accuracy: 18.54%\n",
            "Epoch: 50, Step: 517/655, Loss: 2.208493, Accuracy: 18.53%\n",
            "Epoch: 50, Step: 518/655, Loss: 2.208426, Accuracy: 18.52%\n",
            "Epoch: 50, Step: 519/655, Loss: 2.208490, Accuracy: 18.50%\n",
            "Epoch: 50, Step: 520/655, Loss: 2.208663, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 521/655, Loss: 2.208500, Accuracy: 18.50%\n",
            "Epoch: 50, Step: 522/655, Loss: 2.208413, Accuracy: 18.52%\n",
            "Epoch: 50, Step: 523/655, Loss: 2.208341, Accuracy: 18.52%\n",
            "Epoch: 50, Step: 524/655, Loss: 2.208204, Accuracy: 18.52%\n",
            "Epoch: 50, Step: 525/655, Loss: 2.208398, Accuracy: 18.51%\n",
            "Epoch: 50, Step: 526/655, Loss: 2.208256, Accuracy: 18.51%\n",
            "Epoch: 50, Step: 527/655, Loss: 2.208351, Accuracy: 18.50%\n",
            "Epoch: 50, Step: 528/655, Loss: 2.208228, Accuracy: 18.50%\n",
            "Epoch: 50, Step: 529/655, Loss: 2.208114, Accuracy: 18.50%\n",
            "Epoch: 50, Step: 530/655, Loss: 2.208033, Accuracy: 18.48%\n",
            "Epoch: 50, Step: 531/655, Loss: 2.208042, Accuracy: 18.46%\n",
            "Epoch: 50, Step: 532/655, Loss: 2.208232, Accuracy: 18.44%\n",
            "Epoch: 50, Step: 533/655, Loss: 2.208308, Accuracy: 18.43%\n",
            "Epoch: 50, Step: 534/655, Loss: 2.208157, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 535/655, Loss: 2.208470, Accuracy: 18.44%\n",
            "Epoch: 50, Step: 536/655, Loss: 2.208540, Accuracy: 18.43%\n",
            "Epoch: 50, Step: 537/655, Loss: 2.208478, Accuracy: 18.44%\n",
            "Epoch: 50, Step: 538/655, Loss: 2.208315, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 539/655, Loss: 2.208324, Accuracy: 18.46%\n",
            "Epoch: 50, Step: 540/655, Loss: 2.208358, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 541/655, Loss: 2.208606, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 542/655, Loss: 2.208363, Accuracy: 18.46%\n",
            "Epoch: 50, Step: 543/655, Loss: 2.208118, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 544/655, Loss: 2.208380, Accuracy: 18.45%\n",
            "Epoch: 50, Step: 545/655, Loss: 2.208217, Accuracy: 18.47%\n",
            "Epoch: 50, Step: 546/655, Loss: 2.208262, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 547/655, Loss: 2.208136, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 548/655, Loss: 2.208001, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 549/655, Loss: 2.207935, Accuracy: 18.51%\n",
            "Epoch: 50, Step: 550/655, Loss: 2.207959, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 551/655, Loss: 2.207740, Accuracy: 18.51%\n",
            "Epoch: 50, Step: 552/655, Loss: 2.207674, Accuracy: 18.50%\n",
            "Epoch: 50, Step: 553/655, Loss: 2.207656, Accuracy: 18.50%\n",
            "Epoch: 50, Step: 554/655, Loss: 2.207455, Accuracy: 18.49%\n",
            "Epoch: 50, Step: 555/655, Loss: 2.207425, Accuracy: 18.51%\n",
            "Epoch: 50, Step: 556/655, Loss: 2.207525, Accuracy: 18.51%\n",
            "Epoch: 50, Step: 557/655, Loss: 2.207342, Accuracy: 18.53%\n",
            "Epoch: 50, Step: 558/655, Loss: 2.207440, Accuracy: 18.53%\n",
            "Epoch: 50, Step: 559/655, Loss: 2.207468, Accuracy: 18.53%\n",
            "Epoch: 50, Step: 560/655, Loss: 2.207662, Accuracy: 18.53%\n",
            "Epoch: 50, Step: 561/655, Loss: 2.207739, Accuracy: 18.52%\n",
            "Epoch: 50, Step: 562/655, Loss: 2.207726, Accuracy: 18.52%\n",
            "Epoch: 50, Step: 563/655, Loss: 2.207685, Accuracy: 18.55%\n",
            "Epoch: 50, Step: 564/655, Loss: 2.207519, Accuracy: 18.54%\n",
            "Epoch: 50, Step: 565/655, Loss: 2.207602, Accuracy: 18.55%\n",
            "Epoch: 50, Step: 566/655, Loss: 2.207728, Accuracy: 18.54%\n",
            "Epoch: 50, Step: 567/655, Loss: 2.207734, Accuracy: 18.55%\n",
            "Epoch: 50, Step: 568/655, Loss: 2.207646, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 569/655, Loss: 2.207678, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 570/655, Loss: 2.207794, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 571/655, Loss: 2.207843, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 572/655, Loss: 2.207787, Accuracy: 18.56%\n",
            "Epoch: 50, Step: 573/655, Loss: 2.207710, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 574/655, Loss: 2.207810, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 575/655, Loss: 2.207908, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 576/655, Loss: 2.207963, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 577/655, Loss: 2.207898, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 578/655, Loss: 2.208067, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 579/655, Loss: 2.208033, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 580/655, Loss: 2.207943, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 581/655, Loss: 2.207757, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 582/655, Loss: 2.207780, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 583/655, Loss: 2.207747, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 584/655, Loss: 2.207687, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 585/655, Loss: 2.207752, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 586/655, Loss: 2.207591, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 587/655, Loss: 2.207444, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 588/655, Loss: 2.207483, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 589/655, Loss: 2.207427, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 590/655, Loss: 2.207527, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 591/655, Loss: 2.207555, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 592/655, Loss: 2.207667, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 593/655, Loss: 2.207737, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 594/655, Loss: 2.207700, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 595/655, Loss: 2.207550, Accuracy: 18.57%\n",
            "Epoch: 50, Step: 596/655, Loss: 2.207817, Accuracy: 18.55%\n",
            "Epoch: 50, Step: 597/655, Loss: 2.207933, Accuracy: 18.54%\n",
            "Epoch: 50, Step: 598/655, Loss: 2.207829, Accuracy: 18.54%\n",
            "Epoch: 50, Step: 599/655, Loss: 2.207549, Accuracy: 18.56%\n",
            "Epoch: 50, Step: 600/655, Loss: 2.207488, Accuracy: 18.55%\n",
            "Epoch: 50, Step: 601/655, Loss: 2.207527, Accuracy: 18.56%\n",
            "Epoch: 50, Step: 602/655, Loss: 2.207352, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 603/655, Loss: 2.207104, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 604/655, Loss: 2.207210, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 605/655, Loss: 2.207186, Accuracy: 18.60%\n",
            "Epoch: 50, Step: 606/655, Loss: 2.207321, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 607/655, Loss: 2.207456, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 608/655, Loss: 2.207461, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 609/655, Loss: 2.207535, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 610/655, Loss: 2.207395, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 611/655, Loss: 2.207356, Accuracy: 18.62%\n",
            "Epoch: 50, Step: 612/655, Loss: 2.207282, Accuracy: 18.62%\n",
            "Epoch: 50, Step: 613/655, Loss: 2.207207, Accuracy: 18.63%\n",
            "Epoch: 50, Step: 614/655, Loss: 2.207389, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 615/655, Loss: 2.207527, Accuracy: 18.63%\n",
            "Epoch: 50, Step: 616/655, Loss: 2.207359, Accuracy: 18.63%\n",
            "Epoch: 50, Step: 617/655, Loss: 2.207310, Accuracy: 18.64%\n",
            "Epoch: 50, Step: 618/655, Loss: 2.207503, Accuracy: 18.63%\n",
            "Epoch: 50, Step: 619/655, Loss: 2.207462, Accuracy: 18.64%\n",
            "Epoch: 50, Step: 620/655, Loss: 2.207555, Accuracy: 18.63%\n",
            "Epoch: 50, Step: 621/655, Loss: 2.207434, Accuracy: 18.64%\n",
            "Epoch: 50, Step: 622/655, Loss: 2.207555, Accuracy: 18.64%\n",
            "Epoch: 50, Step: 623/655, Loss: 2.207568, Accuracy: 18.63%\n",
            "Epoch: 50, Step: 624/655, Loss: 2.207786, Accuracy: 18.62%\n",
            "Epoch: 50, Step: 625/655, Loss: 2.207760, Accuracy: 18.63%\n",
            "Epoch: 50, Step: 626/655, Loss: 2.207740, Accuracy: 18.62%\n",
            "Epoch: 50, Step: 627/655, Loss: 2.207816, Accuracy: 18.62%\n",
            "Epoch: 50, Step: 628/655, Loss: 2.207753, Accuracy: 18.62%\n",
            "Epoch: 50, Step: 629/655, Loss: 2.207649, Accuracy: 18.62%\n",
            "Epoch: 50, Step: 630/655, Loss: 2.207877, Accuracy: 18.60%\n",
            "Epoch: 50, Step: 631/655, Loss: 2.207901, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 632/655, Loss: 2.207901, Accuracy: 18.60%\n",
            "Epoch: 50, Step: 633/655, Loss: 2.207840, Accuracy: 18.60%\n",
            "Epoch: 50, Step: 634/655, Loss: 2.207672, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 635/655, Loss: 2.207500, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 636/655, Loss: 2.207541, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 637/655, Loss: 2.207670, Accuracy: 18.60%\n",
            "Epoch: 50, Step: 638/655, Loss: 2.207702, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 639/655, Loss: 2.207514, Accuracy: 18.62%\n",
            "Epoch: 50, Step: 640/655, Loss: 2.207602, Accuracy: 18.62%\n",
            "Epoch: 50, Step: 641/655, Loss: 2.207727, Accuracy: 18.62%\n",
            "Epoch: 50, Step: 642/655, Loss: 2.207746, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 643/655, Loss: 2.207576, Accuracy: 18.61%\n",
            "Epoch: 50, Step: 644/655, Loss: 2.207725, Accuracy: 18.60%\n",
            "Epoch: 50, Step: 645/655, Loss: 2.207776, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 646/655, Loss: 2.207635, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 647/655, Loss: 2.207535, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 648/655, Loss: 2.207423, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 649/655, Loss: 2.207460, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 650/655, Loss: 2.207289, Accuracy: 18.60%\n",
            "Epoch: 50, Step: 651/655, Loss: 2.207302, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 652/655, Loss: 2.207326, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 653/655, Loss: 2.207447, Accuracy: 18.58%\n",
            "Epoch: 50, Step: 654/655, Loss: 2.207307, Accuracy: 18.59%\n",
            "Epoch: 50, Step: 655/655, Loss: 2.207704, Accuracy: 18.58%\n"
          ]
        }
      ],
      "source": [
        "train(model, train_loader, criterion, optimizer, scheduler, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "Loss: 2.208211, Accuracy: 18.57%\n"
          ]
        }
      ],
      "source": [
        "test(model, test_loader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMKkQqFUUVtP"
      },
      "source": [
        "# GoogLeNet, Inception 모듈\n",
        "\n",
        "- VGGNet을 제치고 같은 해 분류 과제에서 1등을 차지\n",
        "\n",
        "- 인셉션 블록이라는 개념을 도입하여, **인셉션 네트워크(Inception Network)**라고도 불림\n",
        "\n",
        "  <img src=\"https://miro.medium.com/max/2800/0*rbWRzjKvoGt9W3Mf.png\">\n",
        "\n",
        "  <sub>[이미지 출처] https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5</sub>\n",
        "\n",
        "  <br>\n",
        "\n",
        "- 특징\n",
        "  \n",
        "  - CNN 계산 용량을 최적화하는 것을 고려\n",
        "\n",
        "  - 전형적인 합성곱, 풀링 계층으로 시작하고, 이 정보는 9개의 인셉션 모듈 스택을 통과  \n",
        "    해당 모듈을 하위 네트워크라고도 함\n",
        "\n",
        "  - 각 모듈에서 입력 특징 맵은 서로 다른 계층으로 구성된 4개의 병렬 하위 블록에 전달되고, 이를 서로 다시 연결\n",
        "\n",
        "  - 모든 합성곱과 풀링 계층의 padding옵션은 \"SAME\"이며 `stride=1`,  \n",
        "    활성화 함수는 `ReLU` 사용\n",
        "\n",
        "- 기여\n",
        "\n",
        "  - 규모가 큰 블록과 병목을 보편화\n",
        "\n",
        "  - 병목 계층으로 1x1 합성곱 계층 사용\n",
        "\n",
        "  - 완전 연결 계층 대신 풀링 계층 사용\n",
        "\n",
        "  - 중간 소실로 경사 소실 문제 해결\n",
        "\n",
        "  <img src=\"https://norman3.github.io/papers/images/google_inception/f01.png\">\n",
        "\n",
        "  <sub>[이미지 출처] https://norman3.github.io/papers/docs/google_inception.html</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P91oc7YFauuk"
      },
      "source": [
        "# ResNet - 잔차 네트워크\n",
        "\n",
        "- 네트워크의 깊이가 깊어질수록 경사가 소실되거나 폭발하는 문제를 해결하고자 함\n",
        "\n",
        "- 병목 합성곱 계층을 추가하거나 크기가 작은 커널을 사용\n",
        "\n",
        "- 152개의 훈련가능한 계층을 수직으로 연결하여 구성\n",
        "\n",
        "- 모든 합성곱과 풀링 계층에서 패딩옵셥으로 \"SAME\", stride=1 사용\n",
        "\n",
        "- 3x3 합성곱 계층 다음마다 배치 정규화 적용,  \n",
        "  1x1 합성곱 계층에는 활성화 함수가 존재하지 않음\n",
        "\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://miro.medium.com/max/1200/1*6hF97Upuqg_LdsqWY6n_wg.png\">\n",
        "\n",
        "  <sub>[이미지 출처] https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYIix2vrbwH9"
      },
      "source": [
        "## 잔차 블록 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "0SBaUMSfaqgH"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    2개의 3x3 Convolution Layer로 이루어져 ResNet-18을 구성하는 Basic block\n",
        "    \"\"\"\n",
        "    expansion = 1\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride=1, down_sample=None):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.down_sample = down_sample\n",
        "    \n",
        "    def forward(self, x: torch.Tensor):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        \n",
        "        if self.down_sample is not None:\n",
        "            residual = self.down_sample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "9da3RqU_c4MZ"
      },
      "outputs": [],
      "source": [
        "class ResNet18(nn.Module):\n",
        "    \"\"\"\n",
        "    5개의 block으로 구성\n",
        "    \"\"\"\n",
        "    def __init__(self, block: BasicBlock, layers, n_classes=10):\n",
        "        super().__init__()\n",
        "        self.in_channels = 64\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.out = nn.Linear(512 * block.expansion, n_classes)\n",
        "        \n",
        "    def _make_layer(self, block: BasicBlock, out_channels: int, blocks, stride=1):\n",
        "        down_sample = None\n",
        "        mask = stride != 1 or self.in_channels != out_channels * block.expansion\n",
        "\n",
        "        if mask:\n",
        "            down_sample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, 1, stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion)\n",
        "            )\n",
        "        \n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, down_sample))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        \n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "        \n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = F.relu(out)\n",
        "        out = F.max_pool2d(out, (3, 3), (2, 2), (1, 1))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.out(out)\n",
        "        return out\n",
        "    \n",
        "    @staticmethod\n",
        "    def init_params(m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "b6UTGl44drbG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet18(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (down_sample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (down_sample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (down_sample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (out): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "def resnet18(n_classes=10):\n",
        "    return ResNet18(BasicBlock, [2, 2, 2, 2], n_classes)\n",
        "\n",
        "model = resnet18().to('cuda')\n",
        "model.apply(ResNet18.init_params)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.5083, 0.4799, 0.3961]) tensor([0.2634, 0.2587, 0.2701])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "\n",
        "transform_temp = transforms.Compose([\n",
        "    transforms.RandomResizedCrop((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(root='./data/animals-10/train', transform=transform_temp)\n",
        "loader = DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "def calc_mean_std(loader: DataLoader):\n",
        "    sum, sq_sum, n_batches = 0, 0, 0\n",
        "    \n",
        "    for data, _ in loader:\n",
        "        sum += torch.mean(data, dim=[0, 2, 3])\n",
        "        sq_sum += torch.mean(data ** 2, dim=[0, 2, 3])\n",
        "        n_batches += 1\n",
        "    \n",
        "    mean = sum / n_batches\n",
        "    std = ((sq_sum / n_batches) - mean ** 2) ** .5\n",
        "    \n",
        "    return mean, std\n",
        "\n",
        "mean, std = calc_mean_std(loader)\n",
        "print(mean, std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(root=os.path.join(os.getcwd(), 'data', 'animals-10', 'train'), transform=transform)\n",
        "test_data = datasets.ImageFolder(root=os.path.join(os.getcwd(), 'data', 'animals-10', 'test'), transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "lr = 1e-3\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=.6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model: nn.Module, train_loader: DataLoader, criterion: nn.modules.loss._Loss, optimizer: optim.Optimizer, scheduler: optim.lr_scheduler.StepLR, epochs: int):\n",
        "    model.train()\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        for idx, (inputs, labels) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            print(f'Epoch: {epoch + 1}, Step: {idx + 1}/{len(train_loader)}, Loss: {running_loss / (idx + 1):.6f}, Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "        scheduler.step()\n",
        "                \n",
        "def test(model: nn.Module, test_loader: DataLoader, criterion: nn.modules.loss._Loss):\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        t_loss = 0\n",
        "        correct = 0\n",
        "        \n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "            outputs = model(inputs)\n",
        "            pred_vals, pred_indices = torch.max(outputs, dim=1)\n",
        "            \n",
        "            t_loss += criterion(outputs, labels).item()\n",
        "            correct += pred_indices.eq(labels).sum().item()\n",
        "        \n",
        "        t_loss /= len(test_loader)\n",
        "        acc = correct / len(test_loader.dataset)\n",
        "    \n",
        "    print('Test')\n",
        "    print(f'Loss: {t_loss:.6f}, Accuracy: {acc * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Step: 1/164, Loss: 2.763364, Accuracy: 7.81%\n",
            "Epoch: 1, Step: 2/164, Loss: 3.527186, Accuracy: 12.89%\n",
            "Epoch: 1, Step: 3/164, Loss: 3.615749, Accuracy: 14.58%\n",
            "Epoch: 1, Step: 4/164, Loss: 3.427653, Accuracy: 14.45%\n",
            "Epoch: 1, Step: 5/164, Loss: 3.201532, Accuracy: 15.62%\n",
            "Epoch: 1, Step: 6/164, Loss: 3.030017, Accuracy: 17.19%\n",
            "Epoch: 1, Step: 7/164, Loss: 2.976851, Accuracy: 18.30%\n",
            "Epoch: 1, Step: 8/164, Loss: 2.883705, Accuracy: 18.36%\n",
            "Epoch: 1, Step: 9/164, Loss: 2.802215, Accuracy: 19.10%\n",
            "Epoch: 1, Step: 10/164, Loss: 2.744764, Accuracy: 20.31%\n",
            "Epoch: 1, Step: 11/164, Loss: 2.692424, Accuracy: 20.60%\n",
            "Epoch: 1, Step: 12/164, Loss: 2.640583, Accuracy: 21.16%\n",
            "Epoch: 1, Step: 13/164, Loss: 2.606119, Accuracy: 20.97%\n",
            "Epoch: 1, Step: 14/164, Loss: 2.571197, Accuracy: 21.09%\n",
            "Epoch: 1, Step: 15/164, Loss: 2.538151, Accuracy: 21.46%\n",
            "Epoch: 1, Step: 16/164, Loss: 2.504676, Accuracy: 21.58%\n",
            "Epoch: 1, Step: 17/164, Loss: 2.478631, Accuracy: 22.01%\n",
            "Epoch: 1, Step: 18/164, Loss: 2.447697, Accuracy: 22.57%\n",
            "Epoch: 1, Step: 19/164, Loss: 2.425190, Accuracy: 22.94%\n",
            "Epoch: 1, Step: 20/164, Loss: 2.406452, Accuracy: 22.93%\n",
            "Epoch: 1, Step: 21/164, Loss: 2.386197, Accuracy: 23.29%\n",
            "Epoch: 1, Step: 22/164, Loss: 2.367498, Accuracy: 23.51%\n",
            "Epoch: 1, Step: 23/164, Loss: 2.350914, Accuracy: 23.68%\n",
            "Epoch: 1, Step: 24/164, Loss: 2.327268, Accuracy: 24.32%\n",
            "Epoch: 1, Step: 25/164, Loss: 2.304424, Accuracy: 24.94%\n",
            "Epoch: 1, Step: 26/164, Loss: 2.291589, Accuracy: 25.15%\n",
            "Epoch: 1, Step: 27/164, Loss: 2.275847, Accuracy: 25.55%\n",
            "Epoch: 1, Step: 28/164, Loss: 2.261575, Accuracy: 25.86%\n",
            "Epoch: 1, Step: 29/164, Loss: 2.257641, Accuracy: 25.84%\n",
            "Epoch: 1, Step: 30/164, Loss: 2.246636, Accuracy: 26.15%\n",
            "Epoch: 1, Step: 31/164, Loss: 2.239224, Accuracy: 26.21%\n",
            "Epoch: 1, Step: 32/164, Loss: 2.228980, Accuracy: 26.39%\n",
            "Epoch: 1, Step: 33/164, Loss: 2.222427, Accuracy: 26.59%\n",
            "Epoch: 1, Step: 34/164, Loss: 2.215299, Accuracy: 26.63%\n",
            "Epoch: 1, Step: 35/164, Loss: 2.210259, Accuracy: 26.67%\n",
            "Epoch: 1, Step: 36/164, Loss: 2.200003, Accuracy: 26.89%\n",
            "Epoch: 1, Step: 37/164, Loss: 2.193702, Accuracy: 27.17%\n",
            "Epoch: 1, Step: 38/164, Loss: 2.187399, Accuracy: 27.22%\n",
            "Epoch: 1, Step: 39/164, Loss: 2.179863, Accuracy: 27.30%\n",
            "Epoch: 1, Step: 40/164, Loss: 2.176960, Accuracy: 27.32%\n",
            "Epoch: 1, Step: 41/164, Loss: 2.172324, Accuracy: 27.52%\n",
            "Epoch: 1, Step: 42/164, Loss: 2.165293, Accuracy: 27.49%\n",
            "Epoch: 1, Step: 43/164, Loss: 2.161647, Accuracy: 27.56%\n",
            "Epoch: 1, Step: 44/164, Loss: 2.155921, Accuracy: 27.61%\n",
            "Epoch: 1, Step: 45/164, Loss: 2.152851, Accuracy: 27.57%\n",
            "Epoch: 1, Step: 46/164, Loss: 2.146646, Accuracy: 27.67%\n",
            "Epoch: 1, Step: 47/164, Loss: 2.141278, Accuracy: 27.69%\n",
            "Epoch: 1, Step: 48/164, Loss: 2.138480, Accuracy: 27.80%\n",
            "Epoch: 1, Step: 49/164, Loss: 2.133933, Accuracy: 27.95%\n",
            "Epoch: 1, Step: 50/164, Loss: 2.130638, Accuracy: 28.16%\n",
            "Epoch: 1, Step: 51/164, Loss: 2.127524, Accuracy: 28.29%\n",
            "Epoch: 1, Step: 52/164, Loss: 2.123429, Accuracy: 28.43%\n",
            "Epoch: 1, Step: 53/164, Loss: 2.117121, Accuracy: 28.67%\n",
            "Epoch: 1, Step: 54/164, Loss: 2.108958, Accuracy: 28.94%\n",
            "Epoch: 1, Step: 55/164, Loss: 2.105939, Accuracy: 28.99%\n",
            "Epoch: 1, Step: 56/164, Loss: 2.105227, Accuracy: 29.06%\n",
            "Epoch: 1, Step: 57/164, Loss: 2.100612, Accuracy: 29.17%\n",
            "Epoch: 1, Step: 58/164, Loss: 2.097742, Accuracy: 29.27%\n",
            "Epoch: 1, Step: 59/164, Loss: 2.093869, Accuracy: 29.38%\n",
            "Epoch: 1, Step: 60/164, Loss: 2.091844, Accuracy: 29.52%\n",
            "Epoch: 1, Step: 61/164, Loss: 2.087500, Accuracy: 29.71%\n",
            "Epoch: 1, Step: 62/164, Loss: 2.083837, Accuracy: 29.78%\n",
            "Epoch: 1, Step: 63/164, Loss: 2.078759, Accuracy: 29.96%\n",
            "Epoch: 1, Step: 64/164, Loss: 2.076303, Accuracy: 30.07%\n",
            "Epoch: 1, Step: 65/164, Loss: 2.070952, Accuracy: 30.22%\n",
            "Epoch: 1, Step: 66/164, Loss: 2.069650, Accuracy: 30.26%\n",
            "Epoch: 1, Step: 67/164, Loss: 2.064653, Accuracy: 30.43%\n",
            "Epoch: 1, Step: 68/164, Loss: 2.060080, Accuracy: 30.56%\n",
            "Epoch: 1, Step: 69/164, Loss: 2.056216, Accuracy: 30.74%\n",
            "Epoch: 1, Step: 70/164, Loss: 2.054829, Accuracy: 30.80%\n",
            "Epoch: 1, Step: 71/164, Loss: 2.053531, Accuracy: 30.81%\n",
            "Epoch: 1, Step: 72/164, Loss: 2.049289, Accuracy: 30.86%\n",
            "Epoch: 1, Step: 73/164, Loss: 2.044880, Accuracy: 30.98%\n",
            "Epoch: 1, Step: 74/164, Loss: 2.043983, Accuracy: 30.99%\n",
            "Epoch: 1, Step: 75/164, Loss: 2.040112, Accuracy: 31.16%\n",
            "Epoch: 1, Step: 76/164, Loss: 2.037024, Accuracy: 31.20%\n",
            "Epoch: 1, Step: 77/164, Loss: 2.032898, Accuracy: 31.31%\n",
            "Epoch: 1, Step: 78/164, Loss: 2.031127, Accuracy: 31.37%\n",
            "Epoch: 1, Step: 79/164, Loss: 2.028843, Accuracy: 31.48%\n",
            "Epoch: 1, Step: 80/164, Loss: 2.025008, Accuracy: 31.50%\n",
            "Epoch: 1, Step: 81/164, Loss: 2.020722, Accuracy: 31.59%\n",
            "Epoch: 1, Step: 82/164, Loss: 2.018369, Accuracy: 31.60%\n",
            "Epoch: 1, Step: 83/164, Loss: 2.016182, Accuracy: 31.66%\n",
            "Epoch: 1, Step: 84/164, Loss: 2.012936, Accuracy: 31.73%\n",
            "Epoch: 1, Step: 85/164, Loss: 2.009736, Accuracy: 31.82%\n",
            "Epoch: 1, Step: 86/164, Loss: 2.009087, Accuracy: 31.90%\n",
            "Epoch: 1, Step: 87/164, Loss: 2.006551, Accuracy: 32.03%\n",
            "Epoch: 1, Step: 88/164, Loss: 2.003835, Accuracy: 32.07%\n",
            "Epoch: 1, Step: 89/164, Loss: 2.000874, Accuracy: 32.18%\n",
            "Epoch: 1, Step: 90/164, Loss: 1.997296, Accuracy: 32.28%\n",
            "Epoch: 1, Step: 91/164, Loss: 1.995120, Accuracy: 32.28%\n",
            "Epoch: 1, Step: 92/164, Loss: 1.992423, Accuracy: 32.32%\n",
            "Epoch: 1, Step: 93/164, Loss: 1.989188, Accuracy: 32.37%\n",
            "Epoch: 1, Step: 94/164, Loss: 1.986085, Accuracy: 32.39%\n",
            "Epoch: 1, Step: 95/164, Loss: 1.984194, Accuracy: 32.40%\n",
            "Epoch: 1, Step: 96/164, Loss: 1.984261, Accuracy: 32.37%\n",
            "Epoch: 1, Step: 97/164, Loss: 1.982235, Accuracy: 32.39%\n",
            "Epoch: 1, Step: 98/164, Loss: 1.980702, Accuracy: 32.46%\n",
            "Epoch: 1, Step: 99/164, Loss: 1.978241, Accuracy: 32.55%\n",
            "Epoch: 1, Step: 100/164, Loss: 1.975812, Accuracy: 32.61%\n",
            "Epoch: 1, Step: 101/164, Loss: 1.972004, Accuracy: 32.76%\n",
            "Epoch: 1, Step: 102/164, Loss: 1.970837, Accuracy: 32.80%\n",
            "Epoch: 1, Step: 103/164, Loss: 1.971890, Accuracy: 32.82%\n",
            "Epoch: 1, Step: 104/164, Loss: 1.970132, Accuracy: 32.90%\n",
            "Epoch: 1, Step: 105/164, Loss: 1.966684, Accuracy: 32.98%\n",
            "Epoch: 1, Step: 106/164, Loss: 1.964075, Accuracy: 33.08%\n",
            "Epoch: 1, Step: 107/164, Loss: 1.961198, Accuracy: 33.20%\n",
            "Epoch: 1, Step: 108/164, Loss: 1.958840, Accuracy: 33.23%\n",
            "Epoch: 1, Step: 109/164, Loss: 1.957159, Accuracy: 33.30%\n",
            "Epoch: 1, Step: 110/164, Loss: 1.954431, Accuracy: 33.37%\n",
            "Epoch: 1, Step: 111/164, Loss: 1.952140, Accuracy: 33.42%\n",
            "Epoch: 1, Step: 112/164, Loss: 1.948809, Accuracy: 33.52%\n",
            "Epoch: 1, Step: 113/164, Loss: 1.946789, Accuracy: 33.57%\n",
            "Epoch: 1, Step: 114/164, Loss: 1.944348, Accuracy: 33.63%\n",
            "Epoch: 1, Step: 115/164, Loss: 1.942582, Accuracy: 33.68%\n",
            "Epoch: 1, Step: 116/164, Loss: 1.940528, Accuracy: 33.74%\n",
            "Epoch: 1, Step: 117/164, Loss: 1.938432, Accuracy: 33.82%\n",
            "Epoch: 1, Step: 118/164, Loss: 1.936426, Accuracy: 33.92%\n",
            "Epoch: 1, Step: 119/164, Loss: 1.935355, Accuracy: 33.95%\n",
            "Epoch: 1, Step: 120/164, Loss: 1.932668, Accuracy: 34.04%\n",
            "Epoch: 1, Step: 121/164, Loss: 1.930874, Accuracy: 34.14%\n",
            "Epoch: 1, Step: 122/164, Loss: 1.930708, Accuracy: 34.14%\n",
            "Epoch: 1, Step: 123/164, Loss: 1.928952, Accuracy: 34.21%\n",
            "Epoch: 1, Step: 124/164, Loss: 1.926769, Accuracy: 34.27%\n",
            "Epoch: 1, Step: 125/164, Loss: 1.925365, Accuracy: 34.39%\n",
            "Epoch: 1, Step: 126/164, Loss: 1.923869, Accuracy: 34.44%\n",
            "Epoch: 1, Step: 127/164, Loss: 1.921743, Accuracy: 34.51%\n",
            "Epoch: 1, Step: 128/164, Loss: 1.919973, Accuracy: 34.55%\n",
            "Epoch: 1, Step: 129/164, Loss: 1.918734, Accuracy: 34.59%\n",
            "Epoch: 1, Step: 130/164, Loss: 1.917079, Accuracy: 34.66%\n",
            "Epoch: 1, Step: 131/164, Loss: 1.914411, Accuracy: 34.74%\n",
            "Epoch: 1, Step: 132/164, Loss: 1.913389, Accuracy: 34.75%\n",
            "Epoch: 1, Step: 133/164, Loss: 1.911703, Accuracy: 34.79%\n",
            "Epoch: 1, Step: 134/164, Loss: 1.910697, Accuracy: 34.79%\n",
            "Epoch: 1, Step: 135/164, Loss: 1.908275, Accuracy: 34.83%\n",
            "Epoch: 1, Step: 136/164, Loss: 1.906463, Accuracy: 34.90%\n",
            "Epoch: 1, Step: 137/164, Loss: 1.905092, Accuracy: 34.92%\n",
            "Epoch: 1, Step: 138/164, Loss: 1.902628, Accuracy: 34.99%\n",
            "Epoch: 1, Step: 139/164, Loss: 1.901801, Accuracy: 35.03%\n",
            "Epoch: 1, Step: 140/164, Loss: 1.901500, Accuracy: 35.05%\n",
            "Epoch: 1, Step: 141/164, Loss: 1.899747, Accuracy: 35.10%\n",
            "Epoch: 1, Step: 142/164, Loss: 1.898779, Accuracy: 35.08%\n",
            "Epoch: 1, Step: 143/164, Loss: 1.896140, Accuracy: 35.17%\n",
            "Epoch: 1, Step: 144/164, Loss: 1.894211, Accuracy: 35.24%\n",
            "Epoch: 1, Step: 145/164, Loss: 1.894633, Accuracy: 35.23%\n",
            "Epoch: 1, Step: 146/164, Loss: 1.892500, Accuracy: 35.33%\n",
            "Epoch: 1, Step: 147/164, Loss: 1.890627, Accuracy: 35.41%\n",
            "Epoch: 1, Step: 148/164, Loss: 1.889212, Accuracy: 35.44%\n",
            "Epoch: 1, Step: 149/164, Loss: 1.888892, Accuracy: 35.43%\n",
            "Epoch: 1, Step: 150/164, Loss: 1.887617, Accuracy: 35.48%\n",
            "Epoch: 1, Step: 151/164, Loss: 1.887022, Accuracy: 35.47%\n",
            "Epoch: 1, Step: 152/164, Loss: 1.885736, Accuracy: 35.48%\n",
            "Epoch: 1, Step: 153/164, Loss: 1.884132, Accuracy: 35.56%\n",
            "Epoch: 1, Step: 154/164, Loss: 1.883652, Accuracy: 35.57%\n",
            "Epoch: 1, Step: 155/164, Loss: 1.881828, Accuracy: 35.62%\n",
            "Epoch: 1, Step: 156/164, Loss: 1.880671, Accuracy: 35.66%\n",
            "Epoch: 1, Step: 157/164, Loss: 1.878772, Accuracy: 35.73%\n",
            "Epoch: 1, Step: 158/164, Loss: 1.876762, Accuracy: 35.80%\n",
            "Epoch: 1, Step: 159/164, Loss: 1.874664, Accuracy: 35.86%\n",
            "Epoch: 1, Step: 160/164, Loss: 1.873458, Accuracy: 35.90%\n",
            "Epoch: 1, Step: 161/164, Loss: 1.871501, Accuracy: 35.98%\n",
            "Epoch: 1, Step: 162/164, Loss: 1.869924, Accuracy: 36.02%\n",
            "Epoch: 1, Step: 163/164, Loss: 1.868361, Accuracy: 36.08%\n",
            "Epoch: 1, Step: 164/164, Loss: 1.866191, Accuracy: 36.12%\n",
            "Epoch: 2, Step: 1/164, Loss: 1.404626, Accuracy: 46.88%\n",
            "Epoch: 2, Step: 2/164, Loss: 1.485313, Accuracy: 48.83%\n",
            "Epoch: 2, Step: 3/164, Loss: 1.546198, Accuracy: 48.18%\n",
            "Epoch: 2, Step: 4/164, Loss: 1.568679, Accuracy: 47.85%\n",
            "Epoch: 2, Step: 5/164, Loss: 1.582379, Accuracy: 47.03%\n",
            "Epoch: 2, Step: 6/164, Loss: 1.568889, Accuracy: 47.92%\n",
            "Epoch: 2, Step: 7/164, Loss: 1.597113, Accuracy: 46.88%\n",
            "Epoch: 2, Step: 8/164, Loss: 1.606247, Accuracy: 46.48%\n",
            "Epoch: 2, Step: 9/164, Loss: 1.610510, Accuracy: 46.61%\n",
            "Epoch: 2, Step: 10/164, Loss: 1.613603, Accuracy: 45.55%\n",
            "Epoch: 2, Step: 11/164, Loss: 1.609772, Accuracy: 45.67%\n",
            "Epoch: 2, Step: 12/164, Loss: 1.613729, Accuracy: 45.51%\n",
            "Epoch: 2, Step: 13/164, Loss: 1.607692, Accuracy: 45.91%\n",
            "Epoch: 2, Step: 14/164, Loss: 1.613632, Accuracy: 45.65%\n",
            "Epoch: 2, Step: 15/164, Loss: 1.614466, Accuracy: 45.36%\n",
            "Epoch: 2, Step: 16/164, Loss: 1.622831, Accuracy: 45.51%\n",
            "Epoch: 2, Step: 17/164, Loss: 1.616747, Accuracy: 45.77%\n",
            "Epoch: 2, Step: 18/164, Loss: 1.604074, Accuracy: 46.05%\n",
            "Epoch: 2, Step: 19/164, Loss: 1.605204, Accuracy: 45.76%\n",
            "Epoch: 2, Step: 20/164, Loss: 1.603332, Accuracy: 45.90%\n",
            "Epoch: 2, Step: 21/164, Loss: 1.595587, Accuracy: 45.87%\n",
            "Epoch: 2, Step: 22/164, Loss: 1.601873, Accuracy: 45.70%\n",
            "Epoch: 2, Step: 23/164, Loss: 1.602757, Accuracy: 45.89%\n",
            "Epoch: 2, Step: 24/164, Loss: 1.603508, Accuracy: 45.77%\n",
            "Epoch: 2, Step: 25/164, Loss: 1.606763, Accuracy: 45.56%\n",
            "Epoch: 2, Step: 26/164, Loss: 1.605237, Accuracy: 45.58%\n",
            "Epoch: 2, Step: 27/164, Loss: 1.598402, Accuracy: 45.95%\n",
            "Epoch: 2, Step: 28/164, Loss: 1.596500, Accuracy: 45.93%\n",
            "Epoch: 2, Step: 29/164, Loss: 1.600423, Accuracy: 45.72%\n",
            "Epoch: 2, Step: 30/164, Loss: 1.600753, Accuracy: 45.73%\n",
            "Epoch: 2, Step: 31/164, Loss: 1.601063, Accuracy: 45.67%\n",
            "Epoch: 2, Step: 32/164, Loss: 1.600509, Accuracy: 45.75%\n",
            "Epoch: 2, Step: 33/164, Loss: 1.599699, Accuracy: 45.62%\n",
            "Epoch: 2, Step: 34/164, Loss: 1.600405, Accuracy: 45.59%\n",
            "Epoch: 2, Step: 35/164, Loss: 1.601316, Accuracy: 45.56%\n",
            "Epoch: 2, Step: 36/164, Loss: 1.601622, Accuracy: 45.49%\n",
            "Epoch: 2, Step: 37/164, Loss: 1.597764, Accuracy: 45.54%\n",
            "Epoch: 2, Step: 38/164, Loss: 1.599219, Accuracy: 45.48%\n",
            "Epoch: 2, Step: 39/164, Loss: 1.601833, Accuracy: 45.41%\n",
            "Epoch: 2, Step: 40/164, Loss: 1.603865, Accuracy: 45.37%\n",
            "Epoch: 2, Step: 41/164, Loss: 1.598410, Accuracy: 45.50%\n",
            "Epoch: 2, Step: 42/164, Loss: 1.599063, Accuracy: 45.61%\n",
            "Epoch: 2, Step: 43/164, Loss: 1.596395, Accuracy: 45.57%\n",
            "Epoch: 2, Step: 44/164, Loss: 1.593535, Accuracy: 45.79%\n",
            "Epoch: 2, Step: 45/164, Loss: 1.591043, Accuracy: 45.83%\n",
            "Epoch: 2, Step: 46/164, Loss: 1.589058, Accuracy: 45.94%\n",
            "Epoch: 2, Step: 47/164, Loss: 1.591814, Accuracy: 45.83%\n",
            "Epoch: 2, Step: 48/164, Loss: 1.588728, Accuracy: 45.90%\n",
            "Epoch: 2, Step: 49/164, Loss: 1.587212, Accuracy: 45.90%\n",
            "Epoch: 2, Step: 50/164, Loss: 1.588403, Accuracy: 45.91%\n",
            "Epoch: 2, Step: 51/164, Loss: 1.586285, Accuracy: 45.82%\n",
            "Epoch: 2, Step: 52/164, Loss: 1.588565, Accuracy: 45.76%\n",
            "Epoch: 2, Step: 53/164, Loss: 1.586074, Accuracy: 45.81%\n",
            "Epoch: 2, Step: 54/164, Loss: 1.585458, Accuracy: 45.85%\n",
            "Epoch: 2, Step: 55/164, Loss: 1.585566, Accuracy: 45.84%\n",
            "Epoch: 2, Step: 56/164, Loss: 1.583549, Accuracy: 45.86%\n",
            "Epoch: 2, Step: 57/164, Loss: 1.582931, Accuracy: 45.86%\n",
            "Epoch: 2, Step: 58/164, Loss: 1.581926, Accuracy: 45.86%\n",
            "Epoch: 2, Step: 59/164, Loss: 1.581080, Accuracy: 45.86%\n",
            "Epoch: 2, Step: 60/164, Loss: 1.579470, Accuracy: 46.00%\n",
            "Epoch: 2, Step: 61/164, Loss: 1.579050, Accuracy: 46.03%\n",
            "Epoch: 2, Step: 62/164, Loss: 1.577535, Accuracy: 46.08%\n",
            "Epoch: 2, Step: 63/164, Loss: 1.577100, Accuracy: 46.12%\n",
            "Epoch: 2, Step: 64/164, Loss: 1.573640, Accuracy: 46.23%\n",
            "Epoch: 2, Step: 65/164, Loss: 1.571265, Accuracy: 46.30%\n",
            "Epoch: 2, Step: 66/164, Loss: 1.570608, Accuracy: 46.31%\n",
            "Epoch: 2, Step: 67/164, Loss: 1.570863, Accuracy: 46.29%\n",
            "Epoch: 2, Step: 68/164, Loss: 1.570627, Accuracy: 46.31%\n",
            "Epoch: 2, Step: 69/164, Loss: 1.568888, Accuracy: 46.31%\n",
            "Epoch: 2, Step: 70/164, Loss: 1.568760, Accuracy: 46.26%\n",
            "Epoch: 2, Step: 71/164, Loss: 1.569431, Accuracy: 46.17%\n",
            "Epoch: 2, Step: 72/164, Loss: 1.567159, Accuracy: 46.18%\n",
            "Epoch: 2, Step: 73/164, Loss: 1.569090, Accuracy: 46.21%\n",
            "Epoch: 2, Step: 74/164, Loss: 1.567453, Accuracy: 46.37%\n",
            "Epoch: 2, Step: 75/164, Loss: 1.566105, Accuracy: 46.46%\n",
            "Epoch: 2, Step: 76/164, Loss: 1.564152, Accuracy: 46.62%\n",
            "Epoch: 2, Step: 77/164, Loss: 1.559925, Accuracy: 46.77%\n",
            "Epoch: 2, Step: 78/164, Loss: 1.560297, Accuracy: 46.76%\n",
            "Epoch: 2, Step: 79/164, Loss: 1.560982, Accuracy: 46.75%\n",
            "Epoch: 2, Step: 80/164, Loss: 1.559140, Accuracy: 46.81%\n",
            "Epoch: 2, Step: 81/164, Loss: 1.560188, Accuracy: 46.75%\n",
            "Epoch: 2, Step: 82/164, Loss: 1.560537, Accuracy: 46.75%\n",
            "Epoch: 2, Step: 83/164, Loss: 1.559688, Accuracy: 46.79%\n",
            "Epoch: 2, Step: 84/164, Loss: 1.556637, Accuracy: 46.94%\n",
            "Epoch: 2, Step: 85/164, Loss: 1.554296, Accuracy: 47.02%\n",
            "Epoch: 2, Step: 86/164, Loss: 1.554643, Accuracy: 46.99%\n",
            "Epoch: 2, Step: 87/164, Loss: 1.553496, Accuracy: 47.05%\n",
            "Epoch: 2, Step: 88/164, Loss: 1.552528, Accuracy: 47.02%\n",
            "Epoch: 2, Step: 89/164, Loss: 1.549918, Accuracy: 47.14%\n",
            "Epoch: 2, Step: 90/164, Loss: 1.548046, Accuracy: 47.20%\n",
            "Epoch: 2, Step: 91/164, Loss: 1.547134, Accuracy: 47.23%\n",
            "Epoch: 2, Step: 92/164, Loss: 1.545344, Accuracy: 47.28%\n",
            "Epoch: 2, Step: 93/164, Loss: 1.546605, Accuracy: 47.21%\n",
            "Epoch: 2, Step: 94/164, Loss: 1.548003, Accuracy: 47.12%\n",
            "Epoch: 2, Step: 95/164, Loss: 1.548457, Accuracy: 47.17%\n",
            "Epoch: 2, Step: 96/164, Loss: 1.547640, Accuracy: 47.22%\n",
            "Epoch: 2, Step: 97/164, Loss: 1.547314, Accuracy: 47.25%\n",
            "Epoch: 2, Step: 98/164, Loss: 1.546633, Accuracy: 47.20%\n",
            "Epoch: 2, Step: 99/164, Loss: 1.546257, Accuracy: 47.22%\n",
            "Epoch: 2, Step: 100/164, Loss: 1.547220, Accuracy: 47.16%\n",
            "Epoch: 2, Step: 101/164, Loss: 1.547309, Accuracy: 47.13%\n",
            "Epoch: 2, Step: 102/164, Loss: 1.544764, Accuracy: 47.29%\n",
            "Epoch: 2, Step: 103/164, Loss: 1.543898, Accuracy: 47.31%\n",
            "Epoch: 2, Step: 104/164, Loss: 1.543314, Accuracy: 47.30%\n",
            "Epoch: 2, Step: 105/164, Loss: 1.542461, Accuracy: 47.33%\n",
            "Epoch: 2, Step: 106/164, Loss: 1.540459, Accuracy: 47.38%\n",
            "Epoch: 2, Step: 107/164, Loss: 1.540097, Accuracy: 47.40%\n",
            "Epoch: 2, Step: 108/164, Loss: 1.538745, Accuracy: 47.41%\n",
            "Epoch: 2, Step: 109/164, Loss: 1.539808, Accuracy: 47.43%\n",
            "Epoch: 2, Step: 110/164, Loss: 1.539343, Accuracy: 47.45%\n",
            "Epoch: 2, Step: 111/164, Loss: 1.536993, Accuracy: 47.48%\n",
            "Epoch: 2, Step: 112/164, Loss: 1.535938, Accuracy: 47.51%\n",
            "Epoch: 2, Step: 113/164, Loss: 1.535343, Accuracy: 47.50%\n",
            "Epoch: 2, Step: 114/164, Loss: 1.534677, Accuracy: 47.49%\n",
            "Epoch: 2, Step: 115/164, Loss: 1.534133, Accuracy: 47.60%\n",
            "Epoch: 2, Step: 116/164, Loss: 1.535613, Accuracy: 47.58%\n",
            "Epoch: 2, Step: 117/164, Loss: 1.533717, Accuracy: 47.68%\n",
            "Epoch: 2, Step: 118/164, Loss: 1.533571, Accuracy: 47.65%\n",
            "Epoch: 2, Step: 119/164, Loss: 1.532610, Accuracy: 47.68%\n",
            "Epoch: 2, Step: 120/164, Loss: 1.531644, Accuracy: 47.68%\n",
            "Epoch: 2, Step: 121/164, Loss: 1.530555, Accuracy: 47.73%\n",
            "Epoch: 2, Step: 122/164, Loss: 1.529845, Accuracy: 47.74%\n",
            "Epoch: 2, Step: 123/164, Loss: 1.528423, Accuracy: 47.78%\n",
            "Epoch: 2, Step: 124/164, Loss: 1.527771, Accuracy: 47.81%\n",
            "Epoch: 2, Step: 125/164, Loss: 1.527288, Accuracy: 47.80%\n",
            "Epoch: 2, Step: 126/164, Loss: 1.527131, Accuracy: 47.82%\n",
            "Epoch: 2, Step: 127/164, Loss: 1.526326, Accuracy: 47.82%\n",
            "Epoch: 2, Step: 128/164, Loss: 1.524147, Accuracy: 47.91%\n",
            "Epoch: 2, Step: 129/164, Loss: 1.523166, Accuracy: 47.93%\n",
            "Epoch: 2, Step: 130/164, Loss: 1.522651, Accuracy: 47.96%\n",
            "Epoch: 2, Step: 131/164, Loss: 1.522970, Accuracy: 47.92%\n",
            "Epoch: 2, Step: 132/164, Loss: 1.522376, Accuracy: 47.93%\n",
            "Epoch: 2, Step: 133/164, Loss: 1.522336, Accuracy: 47.90%\n",
            "Epoch: 2, Step: 134/164, Loss: 1.522275, Accuracy: 47.95%\n",
            "Epoch: 2, Step: 135/164, Loss: 1.521321, Accuracy: 47.99%\n",
            "Epoch: 2, Step: 136/164, Loss: 1.520529, Accuracy: 47.98%\n",
            "Epoch: 2, Step: 137/164, Loss: 1.520806, Accuracy: 47.98%\n",
            "Epoch: 2, Step: 138/164, Loss: 1.521153, Accuracy: 47.97%\n",
            "Epoch: 2, Step: 139/164, Loss: 1.520366, Accuracy: 48.01%\n",
            "Epoch: 2, Step: 140/164, Loss: 1.520657, Accuracy: 48.00%\n",
            "Epoch: 2, Step: 141/164, Loss: 1.520520, Accuracy: 48.03%\n",
            "Epoch: 2, Step: 142/164, Loss: 1.521788, Accuracy: 47.98%\n",
            "Epoch: 2, Step: 143/164, Loss: 1.521438, Accuracy: 47.97%\n",
            "Epoch: 2, Step: 144/164, Loss: 1.522633, Accuracy: 47.91%\n",
            "Epoch: 2, Step: 145/164, Loss: 1.521150, Accuracy: 47.95%\n",
            "Epoch: 2, Step: 146/164, Loss: 1.521113, Accuracy: 47.97%\n",
            "Epoch: 2, Step: 147/164, Loss: 1.520733, Accuracy: 47.99%\n",
            "Epoch: 2, Step: 148/164, Loss: 1.520978, Accuracy: 47.98%\n",
            "Epoch: 2, Step: 149/164, Loss: 1.520298, Accuracy: 48.00%\n",
            "Epoch: 2, Step: 150/164, Loss: 1.518879, Accuracy: 48.08%\n",
            "Epoch: 2, Step: 151/164, Loss: 1.518514, Accuracy: 48.10%\n",
            "Epoch: 2, Step: 152/164, Loss: 1.517988, Accuracy: 48.11%\n",
            "Epoch: 2, Step: 153/164, Loss: 1.519429, Accuracy: 48.09%\n",
            "Epoch: 2, Step: 154/164, Loss: 1.519484, Accuracy: 48.08%\n",
            "Epoch: 2, Step: 155/164, Loss: 1.519247, Accuracy: 48.08%\n",
            "Epoch: 2, Step: 156/164, Loss: 1.519173, Accuracy: 48.10%\n",
            "Epoch: 2, Step: 157/164, Loss: 1.519432, Accuracy: 48.09%\n",
            "Epoch: 2, Step: 158/164, Loss: 1.518499, Accuracy: 48.11%\n",
            "Epoch: 2, Step: 159/164, Loss: 1.517424, Accuracy: 48.18%\n",
            "Epoch: 2, Step: 160/164, Loss: 1.516677, Accuracy: 48.21%\n",
            "Epoch: 2, Step: 161/164, Loss: 1.515972, Accuracy: 48.25%\n",
            "Epoch: 2, Step: 162/164, Loss: 1.516261, Accuracy: 48.24%\n",
            "Epoch: 2, Step: 163/164, Loss: 1.516679, Accuracy: 48.25%\n",
            "Epoch: 2, Step: 164/164, Loss: 1.514559, Accuracy: 48.29%\n",
            "Epoch: 3, Step: 1/164, Loss: 1.592035, Accuracy: 51.56%\n",
            "Epoch: 3, Step: 2/164, Loss: 1.472334, Accuracy: 55.47%\n",
            "Epoch: 3, Step: 3/164, Loss: 1.456445, Accuracy: 54.17%\n",
            "Epoch: 3, Step: 4/164, Loss: 1.435110, Accuracy: 53.12%\n",
            "Epoch: 3, Step: 5/164, Loss: 1.437551, Accuracy: 52.81%\n",
            "Epoch: 3, Step: 6/164, Loss: 1.434899, Accuracy: 52.60%\n",
            "Epoch: 3, Step: 7/164, Loss: 1.427840, Accuracy: 52.79%\n",
            "Epoch: 3, Step: 8/164, Loss: 1.448535, Accuracy: 52.05%\n",
            "Epoch: 3, Step: 9/164, Loss: 1.436653, Accuracy: 52.69%\n",
            "Epoch: 3, Step: 10/164, Loss: 1.424777, Accuracy: 53.12%\n",
            "Epoch: 3, Step: 11/164, Loss: 1.428432, Accuracy: 52.34%\n",
            "Epoch: 3, Step: 12/164, Loss: 1.420869, Accuracy: 52.60%\n",
            "Epoch: 3, Step: 13/164, Loss: 1.417192, Accuracy: 52.28%\n",
            "Epoch: 3, Step: 14/164, Loss: 1.426336, Accuracy: 51.84%\n",
            "Epoch: 3, Step: 15/164, Loss: 1.417736, Accuracy: 52.29%\n",
            "Epoch: 3, Step: 16/164, Loss: 1.427298, Accuracy: 52.10%\n",
            "Epoch: 3, Step: 17/164, Loss: 1.422017, Accuracy: 52.07%\n",
            "Epoch: 3, Step: 18/164, Loss: 1.425684, Accuracy: 51.95%\n",
            "Epoch: 3, Step: 19/164, Loss: 1.435538, Accuracy: 51.40%\n",
            "Epoch: 3, Step: 20/164, Loss: 1.433449, Accuracy: 51.37%\n",
            "Epoch: 3, Step: 21/164, Loss: 1.432055, Accuracy: 51.49%\n",
            "Epoch: 3, Step: 22/164, Loss: 1.420486, Accuracy: 52.06%\n",
            "Epoch: 3, Step: 23/164, Loss: 1.416021, Accuracy: 52.21%\n",
            "Epoch: 3, Step: 24/164, Loss: 1.407699, Accuracy: 52.41%\n",
            "Epoch: 3, Step: 25/164, Loss: 1.400139, Accuracy: 52.69%\n",
            "Epoch: 3, Step: 26/164, Loss: 1.404322, Accuracy: 52.58%\n",
            "Epoch: 3, Step: 27/164, Loss: 1.405171, Accuracy: 52.52%\n",
            "Epoch: 3, Step: 28/164, Loss: 1.408684, Accuracy: 52.40%\n",
            "Epoch: 3, Step: 29/164, Loss: 1.407018, Accuracy: 52.45%\n",
            "Epoch: 3, Step: 30/164, Loss: 1.401162, Accuracy: 52.58%\n",
            "Epoch: 3, Step: 31/164, Loss: 1.396085, Accuracy: 52.70%\n",
            "Epoch: 3, Step: 32/164, Loss: 1.394723, Accuracy: 52.76%\n",
            "Epoch: 3, Step: 33/164, Loss: 1.401953, Accuracy: 52.34%\n",
            "Epoch: 3, Step: 34/164, Loss: 1.400857, Accuracy: 52.44%\n",
            "Epoch: 3, Step: 35/164, Loss: 1.396338, Accuracy: 52.57%\n",
            "Epoch: 3, Step: 36/164, Loss: 1.398523, Accuracy: 52.34%\n",
            "Epoch: 3, Step: 37/164, Loss: 1.398924, Accuracy: 52.32%\n",
            "Epoch: 3, Step: 38/164, Loss: 1.393358, Accuracy: 52.51%\n",
            "Epoch: 3, Step: 39/164, Loss: 1.391290, Accuracy: 52.74%\n",
            "Epoch: 3, Step: 40/164, Loss: 1.395104, Accuracy: 52.60%\n",
            "Epoch: 3, Step: 41/164, Loss: 1.397849, Accuracy: 52.52%\n",
            "Epoch: 3, Step: 42/164, Loss: 1.392601, Accuracy: 52.70%\n",
            "Epoch: 3, Step: 43/164, Loss: 1.389254, Accuracy: 52.78%\n",
            "Epoch: 3, Step: 44/164, Loss: 1.391998, Accuracy: 52.68%\n",
            "Epoch: 3, Step: 45/164, Loss: 1.393063, Accuracy: 52.64%\n",
            "Epoch: 3, Step: 46/164, Loss: 1.391244, Accuracy: 52.63%\n",
            "Epoch: 3, Step: 47/164, Loss: 1.388729, Accuracy: 52.68%\n",
            "Epoch: 3, Step: 48/164, Loss: 1.385913, Accuracy: 52.86%\n",
            "Epoch: 3, Step: 49/164, Loss: 1.385874, Accuracy: 52.69%\n",
            "Epoch: 3, Step: 50/164, Loss: 1.387686, Accuracy: 52.62%\n",
            "Epoch: 3, Step: 51/164, Loss: 1.387505, Accuracy: 52.59%\n",
            "Epoch: 3, Step: 52/164, Loss: 1.387146, Accuracy: 52.63%\n",
            "Epoch: 3, Step: 53/164, Loss: 1.385334, Accuracy: 52.70%\n",
            "Epoch: 3, Step: 54/164, Loss: 1.384329, Accuracy: 52.58%\n",
            "Epoch: 3, Step: 55/164, Loss: 1.384516, Accuracy: 52.56%\n",
            "Epoch: 3, Step: 56/164, Loss: 1.382750, Accuracy: 52.59%\n",
            "Epoch: 3, Step: 57/164, Loss: 1.384998, Accuracy: 52.55%\n",
            "Epoch: 3, Step: 58/164, Loss: 1.387450, Accuracy: 52.45%\n",
            "Epoch: 3, Step: 59/164, Loss: 1.386975, Accuracy: 52.50%\n",
            "Epoch: 3, Step: 60/164, Loss: 1.385676, Accuracy: 52.50%\n",
            "Epoch: 3, Step: 61/164, Loss: 1.386311, Accuracy: 52.51%\n",
            "Epoch: 3, Step: 62/164, Loss: 1.387566, Accuracy: 52.57%\n",
            "Epoch: 3, Step: 63/164, Loss: 1.389789, Accuracy: 52.43%\n",
            "Epoch: 3, Step: 64/164, Loss: 1.388037, Accuracy: 52.49%\n",
            "Epoch: 3, Step: 65/164, Loss: 1.385764, Accuracy: 52.58%\n",
            "Epoch: 3, Step: 66/164, Loss: 1.385669, Accuracy: 52.54%\n",
            "Epoch: 3, Step: 67/164, Loss: 1.384357, Accuracy: 52.62%\n",
            "Epoch: 3, Step: 68/164, Loss: 1.385381, Accuracy: 52.61%\n",
            "Epoch: 3, Step: 69/164, Loss: 1.384873, Accuracy: 52.58%\n",
            "Epoch: 3, Step: 70/164, Loss: 1.382677, Accuracy: 52.71%\n",
            "Epoch: 3, Step: 71/164, Loss: 1.382801, Accuracy: 52.71%\n",
            "Epoch: 3, Step: 72/164, Loss: 1.383007, Accuracy: 52.67%\n",
            "Epoch: 3, Step: 73/164, Loss: 1.381756, Accuracy: 52.73%\n",
            "Epoch: 3, Step: 74/164, Loss: 1.382305, Accuracy: 52.68%\n",
            "Epoch: 3, Step: 75/164, Loss: 1.383167, Accuracy: 52.67%\n",
            "Epoch: 3, Step: 76/164, Loss: 1.383893, Accuracy: 52.65%\n",
            "Epoch: 3, Step: 77/164, Loss: 1.383673, Accuracy: 52.68%\n",
            "Epoch: 3, Step: 78/164, Loss: 1.383625, Accuracy: 52.71%\n",
            "Epoch: 3, Step: 79/164, Loss: 1.383903, Accuracy: 52.74%\n",
            "Epoch: 3, Step: 80/164, Loss: 1.385225, Accuracy: 52.72%\n",
            "Epoch: 3, Step: 81/164, Loss: 1.384999, Accuracy: 52.72%\n",
            "Epoch: 3, Step: 82/164, Loss: 1.385662, Accuracy: 52.70%\n",
            "Epoch: 3, Step: 83/164, Loss: 1.386066, Accuracy: 52.64%\n",
            "Epoch: 3, Step: 84/164, Loss: 1.384592, Accuracy: 52.72%\n",
            "Epoch: 3, Step: 85/164, Loss: 1.384303, Accuracy: 52.70%\n",
            "Epoch: 3, Step: 86/164, Loss: 1.386485, Accuracy: 52.73%\n",
            "Epoch: 3, Step: 87/164, Loss: 1.385992, Accuracy: 52.70%\n",
            "Epoch: 3, Step: 88/164, Loss: 1.384644, Accuracy: 52.81%\n",
            "Epoch: 3, Step: 89/164, Loss: 1.384044, Accuracy: 52.77%\n",
            "Epoch: 3, Step: 90/164, Loss: 1.383927, Accuracy: 52.78%\n",
            "Epoch: 3, Step: 91/164, Loss: 1.383541, Accuracy: 52.78%\n",
            "Epoch: 3, Step: 92/164, Loss: 1.382847, Accuracy: 52.84%\n",
            "Epoch: 3, Step: 93/164, Loss: 1.381926, Accuracy: 52.86%\n",
            "Epoch: 3, Step: 94/164, Loss: 1.383996, Accuracy: 52.78%\n",
            "Epoch: 3, Step: 95/164, Loss: 1.384202, Accuracy: 52.74%\n",
            "Epoch: 3, Step: 96/164, Loss: 1.385139, Accuracy: 52.64%\n",
            "Epoch: 3, Step: 97/164, Loss: 1.384515, Accuracy: 52.70%\n",
            "Epoch: 3, Step: 98/164, Loss: 1.383466, Accuracy: 52.69%\n",
            "Epoch: 3, Step: 99/164, Loss: 1.381870, Accuracy: 52.71%\n",
            "Epoch: 3, Step: 100/164, Loss: 1.382739, Accuracy: 52.70%\n",
            "Epoch: 3, Step: 101/164, Loss: 1.381599, Accuracy: 52.75%\n",
            "Epoch: 3, Step: 102/164, Loss: 1.381451, Accuracy: 52.77%\n",
            "Epoch: 3, Step: 103/164, Loss: 1.378623, Accuracy: 52.89%\n",
            "Epoch: 3, Step: 104/164, Loss: 1.379239, Accuracy: 52.87%\n",
            "Epoch: 3, Step: 105/164, Loss: 1.377838, Accuracy: 52.90%\n",
            "Epoch: 3, Step: 106/164, Loss: 1.377147, Accuracy: 52.85%\n",
            "Epoch: 3, Step: 107/164, Loss: 1.376397, Accuracy: 52.85%\n",
            "Epoch: 3, Step: 108/164, Loss: 1.375901, Accuracy: 52.87%\n",
            "Epoch: 3, Step: 109/164, Loss: 1.374063, Accuracy: 52.92%\n",
            "Epoch: 3, Step: 110/164, Loss: 1.373930, Accuracy: 52.90%\n",
            "Epoch: 3, Step: 111/164, Loss: 1.373451, Accuracy: 52.92%\n",
            "Epoch: 3, Step: 112/164, Loss: 1.373510, Accuracy: 52.89%\n",
            "Epoch: 3, Step: 113/164, Loss: 1.371513, Accuracy: 52.95%\n",
            "Epoch: 3, Step: 114/164, Loss: 1.370825, Accuracy: 52.96%\n",
            "Epoch: 3, Step: 115/164, Loss: 1.370459, Accuracy: 53.00%\n",
            "Epoch: 3, Step: 116/164, Loss: 1.371477, Accuracy: 52.98%\n",
            "Epoch: 3, Step: 117/164, Loss: 1.371589, Accuracy: 53.00%\n",
            "Epoch: 3, Step: 118/164, Loss: 1.370842, Accuracy: 53.00%\n",
            "Epoch: 3, Step: 119/164, Loss: 1.370856, Accuracy: 52.97%\n",
            "Epoch: 3, Step: 120/164, Loss: 1.370613, Accuracy: 52.99%\n",
            "Epoch: 3, Step: 121/164, Loss: 1.368558, Accuracy: 53.07%\n",
            "Epoch: 3, Step: 122/164, Loss: 1.366775, Accuracy: 53.12%\n",
            "Epoch: 3, Step: 123/164, Loss: 1.365775, Accuracy: 53.19%\n",
            "Epoch: 3, Step: 124/164, Loss: 1.366141, Accuracy: 53.20%\n",
            "Epoch: 3, Step: 125/164, Loss: 1.365948, Accuracy: 53.21%\n",
            "Epoch: 3, Step: 126/164, Loss: 1.365227, Accuracy: 53.24%\n",
            "Epoch: 3, Step: 127/164, Loss: 1.364279, Accuracy: 53.28%\n",
            "Epoch: 3, Step: 128/164, Loss: 1.363515, Accuracy: 53.32%\n",
            "Epoch: 3, Step: 129/164, Loss: 1.362920, Accuracy: 53.34%\n",
            "Epoch: 3, Step: 130/164, Loss: 1.361392, Accuracy: 53.37%\n",
            "Epoch: 3, Step: 131/164, Loss: 1.361132, Accuracy: 53.38%\n",
            "Epoch: 3, Step: 132/164, Loss: 1.360201, Accuracy: 53.41%\n",
            "Epoch: 3, Step: 133/164, Loss: 1.359221, Accuracy: 53.41%\n",
            "Epoch: 3, Step: 134/164, Loss: 1.358635, Accuracy: 53.43%\n",
            "Epoch: 3, Step: 135/164, Loss: 1.357624, Accuracy: 53.45%\n",
            "Epoch: 3, Step: 136/164, Loss: 1.357570, Accuracy: 53.42%\n",
            "Epoch: 3, Step: 137/164, Loss: 1.356624, Accuracy: 53.42%\n",
            "Epoch: 3, Step: 138/164, Loss: 1.356030, Accuracy: 53.41%\n",
            "Epoch: 3, Step: 139/164, Loss: 1.356180, Accuracy: 53.42%\n",
            "Epoch: 3, Step: 140/164, Loss: 1.356820, Accuracy: 53.40%\n",
            "Epoch: 3, Step: 141/164, Loss: 1.356657, Accuracy: 53.39%\n",
            "Epoch: 3, Step: 142/164, Loss: 1.356208, Accuracy: 53.41%\n",
            "Epoch: 3, Step: 143/164, Loss: 1.354715, Accuracy: 53.45%\n",
            "Epoch: 3, Step: 144/164, Loss: 1.355135, Accuracy: 53.47%\n",
            "Epoch: 3, Step: 145/164, Loss: 1.354461, Accuracy: 53.45%\n",
            "Epoch: 3, Step: 146/164, Loss: 1.354136, Accuracy: 53.48%\n",
            "Epoch: 3, Step: 147/164, Loss: 1.355338, Accuracy: 53.41%\n",
            "Epoch: 3, Step: 148/164, Loss: 1.354889, Accuracy: 53.43%\n",
            "Epoch: 3, Step: 149/164, Loss: 1.354975, Accuracy: 53.44%\n",
            "Epoch: 3, Step: 150/164, Loss: 1.354249, Accuracy: 53.46%\n",
            "Epoch: 3, Step: 151/164, Loss: 1.355201, Accuracy: 53.42%\n",
            "Epoch: 3, Step: 152/164, Loss: 1.355483, Accuracy: 53.42%\n",
            "Epoch: 3, Step: 153/164, Loss: 1.355721, Accuracy: 53.43%\n",
            "Epoch: 3, Step: 154/164, Loss: 1.355968, Accuracy: 53.41%\n",
            "Epoch: 3, Step: 155/164, Loss: 1.355086, Accuracy: 53.44%\n",
            "Epoch: 3, Step: 156/164, Loss: 1.355429, Accuracy: 53.41%\n",
            "Epoch: 3, Step: 157/164, Loss: 1.356108, Accuracy: 53.40%\n",
            "Epoch: 3, Step: 158/164, Loss: 1.356049, Accuracy: 53.40%\n",
            "Epoch: 3, Step: 159/164, Loss: 1.356125, Accuracy: 53.39%\n",
            "Epoch: 3, Step: 160/164, Loss: 1.355331, Accuracy: 53.42%\n",
            "Epoch: 3, Step: 161/164, Loss: 1.355240, Accuracy: 53.40%\n",
            "Epoch: 3, Step: 162/164, Loss: 1.354926, Accuracy: 53.40%\n",
            "Epoch: 3, Step: 163/164, Loss: 1.354847, Accuracy: 53.39%\n",
            "Epoch: 3, Step: 164/164, Loss: 1.354823, Accuracy: 53.40%\n",
            "Epoch: 4, Step: 1/164, Loss: 1.212547, Accuracy: 60.16%\n",
            "Epoch: 4, Step: 2/164, Loss: 1.233453, Accuracy: 59.77%\n",
            "Epoch: 4, Step: 3/164, Loss: 1.306220, Accuracy: 56.25%\n",
            "Epoch: 4, Step: 4/164, Loss: 1.290958, Accuracy: 57.42%\n",
            "Epoch: 4, Step: 5/164, Loss: 1.238804, Accuracy: 59.06%\n",
            "Epoch: 4, Step: 6/164, Loss: 1.283189, Accuracy: 58.20%\n",
            "Epoch: 4, Step: 7/164, Loss: 1.291706, Accuracy: 58.26%\n",
            "Epoch: 4, Step: 8/164, Loss: 1.276781, Accuracy: 58.40%\n",
            "Epoch: 4, Step: 9/164, Loss: 1.273799, Accuracy: 58.16%\n",
            "Epoch: 4, Step: 10/164, Loss: 1.277085, Accuracy: 57.58%\n",
            "Epoch: 4, Step: 11/164, Loss: 1.278206, Accuracy: 57.39%\n",
            "Epoch: 4, Step: 12/164, Loss: 1.275300, Accuracy: 57.23%\n",
            "Epoch: 4, Step: 13/164, Loss: 1.285183, Accuracy: 57.03%\n",
            "Epoch: 4, Step: 14/164, Loss: 1.289434, Accuracy: 57.20%\n",
            "Epoch: 4, Step: 15/164, Loss: 1.295075, Accuracy: 57.08%\n",
            "Epoch: 4, Step: 16/164, Loss: 1.283768, Accuracy: 57.37%\n",
            "Epoch: 4, Step: 17/164, Loss: 1.288264, Accuracy: 57.03%\n",
            "Epoch: 4, Step: 18/164, Loss: 1.291805, Accuracy: 56.64%\n",
            "Epoch: 4, Step: 19/164, Loss: 1.300655, Accuracy: 56.41%\n",
            "Epoch: 4, Step: 20/164, Loss: 1.307243, Accuracy: 56.17%\n",
            "Epoch: 4, Step: 21/164, Loss: 1.306950, Accuracy: 55.95%\n",
            "Epoch: 4, Step: 22/164, Loss: 1.302449, Accuracy: 56.00%\n",
            "Epoch: 4, Step: 23/164, Loss: 1.293261, Accuracy: 56.25%\n",
            "Epoch: 4, Step: 24/164, Loss: 1.290297, Accuracy: 56.28%\n",
            "Epoch: 4, Step: 25/164, Loss: 1.281860, Accuracy: 56.75%\n",
            "Epoch: 4, Step: 26/164, Loss: 1.286711, Accuracy: 56.55%\n",
            "Epoch: 4, Step: 27/164, Loss: 1.282829, Accuracy: 56.80%\n",
            "Epoch: 4, Step: 28/164, Loss: 1.283686, Accuracy: 56.78%\n",
            "Epoch: 4, Step: 29/164, Loss: 1.281971, Accuracy: 56.92%\n",
            "Epoch: 4, Step: 30/164, Loss: 1.283863, Accuracy: 56.93%\n",
            "Epoch: 4, Step: 31/164, Loss: 1.284385, Accuracy: 56.91%\n",
            "Epoch: 4, Step: 32/164, Loss: 1.289102, Accuracy: 56.79%\n",
            "Epoch: 4, Step: 33/164, Loss: 1.294957, Accuracy: 56.53%\n",
            "Epoch: 4, Step: 34/164, Loss: 1.293056, Accuracy: 56.66%\n",
            "Epoch: 4, Step: 35/164, Loss: 1.290111, Accuracy: 56.94%\n",
            "Epoch: 4, Step: 36/164, Loss: 1.284609, Accuracy: 57.16%\n",
            "Epoch: 4, Step: 37/164, Loss: 1.287252, Accuracy: 57.01%\n",
            "Epoch: 4, Step: 38/164, Loss: 1.288141, Accuracy: 56.95%\n",
            "Epoch: 4, Step: 39/164, Loss: 1.288664, Accuracy: 56.95%\n",
            "Epoch: 4, Step: 40/164, Loss: 1.283605, Accuracy: 56.99%\n",
            "Epoch: 4, Step: 41/164, Loss: 1.276507, Accuracy: 57.18%\n",
            "Epoch: 4, Step: 42/164, Loss: 1.271846, Accuracy: 57.31%\n",
            "Epoch: 4, Step: 43/164, Loss: 1.274687, Accuracy: 57.25%\n",
            "Epoch: 4, Step: 44/164, Loss: 1.273905, Accuracy: 57.28%\n",
            "Epoch: 4, Step: 45/164, Loss: 1.274795, Accuracy: 57.33%\n",
            "Epoch: 4, Step: 46/164, Loss: 1.274799, Accuracy: 57.18%\n",
            "Epoch: 4, Step: 47/164, Loss: 1.272235, Accuracy: 57.30%\n",
            "Epoch: 4, Step: 48/164, Loss: 1.272781, Accuracy: 57.37%\n",
            "Epoch: 4, Step: 49/164, Loss: 1.274381, Accuracy: 57.25%\n",
            "Epoch: 4, Step: 50/164, Loss: 1.272661, Accuracy: 57.23%\n",
            "Epoch: 4, Step: 51/164, Loss: 1.271490, Accuracy: 57.25%\n",
            "Epoch: 4, Step: 52/164, Loss: 1.270825, Accuracy: 57.27%\n",
            "Epoch: 4, Step: 53/164, Loss: 1.271307, Accuracy: 57.21%\n",
            "Epoch: 4, Step: 54/164, Loss: 1.269334, Accuracy: 57.28%\n",
            "Epoch: 4, Step: 55/164, Loss: 1.268898, Accuracy: 57.30%\n",
            "Epoch: 4, Step: 56/164, Loss: 1.265649, Accuracy: 57.44%\n",
            "Epoch: 4, Step: 57/164, Loss: 1.263365, Accuracy: 57.48%\n",
            "Epoch: 4, Step: 58/164, Loss: 1.262824, Accuracy: 57.48%\n",
            "Epoch: 4, Step: 59/164, Loss: 1.262162, Accuracy: 57.49%\n",
            "Epoch: 4, Step: 60/164, Loss: 1.263790, Accuracy: 57.37%\n",
            "Epoch: 4, Step: 61/164, Loss: 1.264899, Accuracy: 57.29%\n",
            "Epoch: 4, Step: 62/164, Loss: 1.265234, Accuracy: 57.23%\n",
            "Epoch: 4, Step: 63/164, Loss: 1.263883, Accuracy: 57.35%\n",
            "Epoch: 4, Step: 64/164, Loss: 1.266898, Accuracy: 57.28%\n",
            "Epoch: 4, Step: 65/164, Loss: 1.268036, Accuracy: 57.18%\n",
            "Epoch: 4, Step: 66/164, Loss: 1.268414, Accuracy: 57.13%\n",
            "Epoch: 4, Step: 67/164, Loss: 1.265272, Accuracy: 57.19%\n",
            "Epoch: 4, Step: 68/164, Loss: 1.264886, Accuracy: 57.17%\n",
            "Epoch: 4, Step: 69/164, Loss: 1.264322, Accuracy: 57.22%\n",
            "Epoch: 4, Step: 70/164, Loss: 1.264385, Accuracy: 57.23%\n",
            "Epoch: 4, Step: 71/164, Loss: 1.264040, Accuracy: 57.33%\n",
            "Epoch: 4, Step: 72/164, Loss: 1.262540, Accuracy: 57.36%\n",
            "Epoch: 4, Step: 73/164, Loss: 1.261100, Accuracy: 57.35%\n",
            "Epoch: 4, Step: 74/164, Loss: 1.259671, Accuracy: 57.37%\n",
            "Epoch: 4, Step: 75/164, Loss: 1.258397, Accuracy: 57.39%\n",
            "Epoch: 4, Step: 76/164, Loss: 1.257594, Accuracy: 57.40%\n",
            "Epoch: 4, Step: 77/164, Loss: 1.258138, Accuracy: 57.39%\n",
            "Epoch: 4, Step: 78/164, Loss: 1.259689, Accuracy: 57.29%\n",
            "Epoch: 4, Step: 79/164, Loss: 1.262392, Accuracy: 57.19%\n",
            "Epoch: 4, Step: 80/164, Loss: 1.265366, Accuracy: 57.11%\n",
            "Epoch: 4, Step: 81/164, Loss: 1.262770, Accuracy: 57.17%\n",
            "Epoch: 4, Step: 82/164, Loss: 1.260873, Accuracy: 57.23%\n",
            "Epoch: 4, Step: 83/164, Loss: 1.260775, Accuracy: 57.21%\n",
            "Epoch: 4, Step: 84/164, Loss: 1.260838, Accuracy: 57.18%\n",
            "Epoch: 4, Step: 85/164, Loss: 1.258977, Accuracy: 57.22%\n",
            "Epoch: 4, Step: 86/164, Loss: 1.256800, Accuracy: 57.27%\n",
            "Epoch: 4, Step: 87/164, Loss: 1.257170, Accuracy: 57.21%\n",
            "Epoch: 4, Step: 88/164, Loss: 1.255728, Accuracy: 57.29%\n",
            "Epoch: 4, Step: 89/164, Loss: 1.254506, Accuracy: 57.31%\n",
            "Epoch: 4, Step: 90/164, Loss: 1.254675, Accuracy: 57.31%\n",
            "Epoch: 4, Step: 91/164, Loss: 1.253261, Accuracy: 57.38%\n",
            "Epoch: 4, Step: 92/164, Loss: 1.251673, Accuracy: 57.40%\n",
            "Epoch: 4, Step: 93/164, Loss: 1.252169, Accuracy: 57.42%\n",
            "Epoch: 4, Step: 94/164, Loss: 1.252846, Accuracy: 57.43%\n",
            "Epoch: 4, Step: 95/164, Loss: 1.252633, Accuracy: 57.43%\n",
            "Epoch: 4, Step: 96/164, Loss: 1.252961, Accuracy: 57.40%\n",
            "Epoch: 4, Step: 97/164, Loss: 1.253817, Accuracy: 57.39%\n",
            "Epoch: 4, Step: 98/164, Loss: 1.252407, Accuracy: 57.43%\n",
            "Epoch: 4, Step: 99/164, Loss: 1.252034, Accuracy: 57.43%\n",
            "Epoch: 4, Step: 100/164, Loss: 1.251082, Accuracy: 57.50%\n",
            "Epoch: 4, Step: 101/164, Loss: 1.249707, Accuracy: 57.55%\n",
            "Epoch: 4, Step: 102/164, Loss: 1.249338, Accuracy: 57.50%\n",
            "Epoch: 4, Step: 103/164, Loss: 1.248142, Accuracy: 57.54%\n",
            "Epoch: 4, Step: 104/164, Loss: 1.246835, Accuracy: 57.59%\n",
            "Epoch: 4, Step: 105/164, Loss: 1.247049, Accuracy: 57.54%\n",
            "Epoch: 4, Step: 106/164, Loss: 1.245224, Accuracy: 57.58%\n",
            "Epoch: 4, Step: 107/164, Loss: 1.243966, Accuracy: 57.64%\n",
            "Epoch: 4, Step: 108/164, Loss: 1.243698, Accuracy: 57.68%\n",
            "Epoch: 4, Step: 109/164, Loss: 1.242472, Accuracy: 57.73%\n",
            "Epoch: 4, Step: 110/164, Loss: 1.240508, Accuracy: 57.76%\n",
            "Epoch: 4, Step: 111/164, Loss: 1.239691, Accuracy: 57.83%\n",
            "Epoch: 4, Step: 112/164, Loss: 1.238694, Accuracy: 57.87%\n",
            "Epoch: 4, Step: 113/164, Loss: 1.239114, Accuracy: 57.85%\n",
            "Epoch: 4, Step: 114/164, Loss: 1.238676, Accuracy: 57.87%\n",
            "Epoch: 4, Step: 115/164, Loss: 1.238745, Accuracy: 57.85%\n",
            "Epoch: 4, Step: 116/164, Loss: 1.238077, Accuracy: 57.87%\n",
            "Epoch: 4, Step: 117/164, Loss: 1.239363, Accuracy: 57.85%\n",
            "Epoch: 4, Step: 118/164, Loss: 1.238892, Accuracy: 57.84%\n",
            "Epoch: 4, Step: 119/164, Loss: 1.237750, Accuracy: 57.90%\n",
            "Epoch: 4, Step: 120/164, Loss: 1.236469, Accuracy: 57.90%\n",
            "Epoch: 4, Step: 121/164, Loss: 1.236645, Accuracy: 57.90%\n",
            "Epoch: 4, Step: 122/164, Loss: 1.236784, Accuracy: 57.87%\n",
            "Epoch: 4, Step: 123/164, Loss: 1.234717, Accuracy: 57.96%\n",
            "Epoch: 4, Step: 124/164, Loss: 1.233167, Accuracy: 58.01%\n",
            "Epoch: 4, Step: 125/164, Loss: 1.233022, Accuracy: 58.04%\n",
            "Epoch: 4, Step: 126/164, Loss: 1.232463, Accuracy: 58.06%\n",
            "Epoch: 4, Step: 127/164, Loss: 1.232317, Accuracy: 58.06%\n",
            "Epoch: 4, Step: 128/164, Loss: 1.233052, Accuracy: 58.05%\n",
            "Epoch: 4, Step: 129/164, Loss: 1.232243, Accuracy: 58.08%\n",
            "Epoch: 4, Step: 130/164, Loss: 1.231013, Accuracy: 58.11%\n",
            "Epoch: 4, Step: 131/164, Loss: 1.230287, Accuracy: 58.15%\n",
            "Epoch: 4, Step: 132/164, Loss: 1.231170, Accuracy: 58.10%\n",
            "Epoch: 4, Step: 133/164, Loss: 1.232985, Accuracy: 58.09%\n",
            "Epoch: 4, Step: 134/164, Loss: 1.233672, Accuracy: 58.03%\n",
            "Epoch: 4, Step: 135/164, Loss: 1.233386, Accuracy: 58.04%\n",
            "Epoch: 4, Step: 136/164, Loss: 1.232526, Accuracy: 58.05%\n",
            "Epoch: 4, Step: 137/164, Loss: 1.233272, Accuracy: 58.02%\n",
            "Epoch: 4, Step: 138/164, Loss: 1.232567, Accuracy: 58.07%\n",
            "Epoch: 4, Step: 139/164, Loss: 1.231763, Accuracy: 58.08%\n",
            "Epoch: 4, Step: 140/164, Loss: 1.230148, Accuracy: 58.14%\n",
            "Epoch: 4, Step: 141/164, Loss: 1.229743, Accuracy: 58.12%\n",
            "Epoch: 4, Step: 142/164, Loss: 1.229587, Accuracy: 58.13%\n",
            "Epoch: 4, Step: 143/164, Loss: 1.230851, Accuracy: 58.06%\n",
            "Epoch: 4, Step: 144/164, Loss: 1.229463, Accuracy: 58.13%\n",
            "Epoch: 4, Step: 145/164, Loss: 1.229661, Accuracy: 58.12%\n",
            "Epoch: 4, Step: 146/164, Loss: 1.229088, Accuracy: 58.18%\n",
            "Epoch: 4, Step: 147/164, Loss: 1.229086, Accuracy: 58.20%\n",
            "Epoch: 4, Step: 148/164, Loss: 1.229757, Accuracy: 58.18%\n",
            "Epoch: 4, Step: 149/164, Loss: 1.230535, Accuracy: 58.14%\n",
            "Epoch: 4, Step: 150/164, Loss: 1.229464, Accuracy: 58.17%\n",
            "Epoch: 4, Step: 151/164, Loss: 1.229995, Accuracy: 58.16%\n",
            "Epoch: 4, Step: 152/164, Loss: 1.230081, Accuracy: 58.17%\n",
            "Epoch: 4, Step: 153/164, Loss: 1.228976, Accuracy: 58.17%\n",
            "Epoch: 4, Step: 154/164, Loss: 1.228500, Accuracy: 58.15%\n",
            "Epoch: 4, Step: 155/164, Loss: 1.227654, Accuracy: 58.20%\n",
            "Epoch: 4, Step: 156/164, Loss: 1.227582, Accuracy: 58.19%\n",
            "Epoch: 4, Step: 157/164, Loss: 1.227200, Accuracy: 58.18%\n",
            "Epoch: 4, Step: 158/164, Loss: 1.226284, Accuracy: 58.22%\n",
            "Epoch: 4, Step: 159/164, Loss: 1.227196, Accuracy: 58.20%\n",
            "Epoch: 4, Step: 160/164, Loss: 1.226735, Accuracy: 58.22%\n",
            "Epoch: 4, Step: 161/164, Loss: 1.226445, Accuracy: 58.25%\n",
            "Epoch: 4, Step: 162/164, Loss: 1.225101, Accuracy: 58.29%\n",
            "Epoch: 4, Step: 163/164, Loss: 1.225302, Accuracy: 58.29%\n",
            "Epoch: 4, Step: 164/164, Loss: 1.225356, Accuracy: 58.29%\n",
            "Epoch: 5, Step: 1/164, Loss: 1.044514, Accuracy: 59.38%\n",
            "Epoch: 5, Step: 2/164, Loss: 1.137918, Accuracy: 60.94%\n",
            "Epoch: 5, Step: 3/164, Loss: 1.123756, Accuracy: 60.94%\n",
            "Epoch: 5, Step: 4/164, Loss: 1.201810, Accuracy: 58.79%\n",
            "Epoch: 5, Step: 5/164, Loss: 1.174332, Accuracy: 60.62%\n",
            "Epoch: 5, Step: 6/164, Loss: 1.152736, Accuracy: 60.81%\n",
            "Epoch: 5, Step: 7/164, Loss: 1.162974, Accuracy: 60.49%\n",
            "Epoch: 5, Step: 8/164, Loss: 1.167028, Accuracy: 60.84%\n",
            "Epoch: 5, Step: 9/164, Loss: 1.176055, Accuracy: 59.98%\n",
            "Epoch: 5, Step: 10/164, Loss: 1.184857, Accuracy: 59.69%\n",
            "Epoch: 5, Step: 11/164, Loss: 1.180518, Accuracy: 60.01%\n",
            "Epoch: 5, Step: 12/164, Loss: 1.191294, Accuracy: 60.16%\n",
            "Epoch: 5, Step: 13/164, Loss: 1.181302, Accuracy: 60.40%\n",
            "Epoch: 5, Step: 14/164, Loss: 1.183390, Accuracy: 60.32%\n",
            "Epoch: 5, Step: 15/164, Loss: 1.182053, Accuracy: 60.42%\n",
            "Epoch: 5, Step: 16/164, Loss: 1.176606, Accuracy: 60.84%\n",
            "Epoch: 5, Step: 17/164, Loss: 1.184550, Accuracy: 60.71%\n",
            "Epoch: 5, Step: 18/164, Loss: 1.182166, Accuracy: 60.94%\n",
            "Epoch: 5, Step: 19/164, Loss: 1.183577, Accuracy: 60.77%\n",
            "Epoch: 5, Step: 20/164, Loss: 1.180997, Accuracy: 60.51%\n",
            "Epoch: 5, Step: 21/164, Loss: 1.181586, Accuracy: 60.45%\n",
            "Epoch: 5, Step: 22/164, Loss: 1.171603, Accuracy: 60.72%\n",
            "Epoch: 5, Step: 23/164, Loss: 1.168926, Accuracy: 60.56%\n",
            "Epoch: 5, Step: 24/164, Loss: 1.166829, Accuracy: 60.55%\n",
            "Epoch: 5, Step: 25/164, Loss: 1.163962, Accuracy: 60.50%\n",
            "Epoch: 5, Step: 26/164, Loss: 1.159394, Accuracy: 60.37%\n",
            "Epoch: 5, Step: 27/164, Loss: 1.160307, Accuracy: 60.33%\n",
            "Epoch: 5, Step: 28/164, Loss: 1.155332, Accuracy: 60.49%\n",
            "Epoch: 5, Step: 29/164, Loss: 1.155403, Accuracy: 60.48%\n",
            "Epoch: 5, Step: 30/164, Loss: 1.152053, Accuracy: 60.60%\n",
            "Epoch: 5, Step: 31/164, Loss: 1.148472, Accuracy: 60.66%\n",
            "Epoch: 5, Step: 32/164, Loss: 1.143356, Accuracy: 60.82%\n",
            "Epoch: 5, Step: 33/164, Loss: 1.144223, Accuracy: 60.70%\n",
            "Epoch: 5, Step: 34/164, Loss: 1.141562, Accuracy: 60.85%\n",
            "Epoch: 5, Step: 35/164, Loss: 1.142831, Accuracy: 60.80%\n",
            "Epoch: 5, Step: 36/164, Loss: 1.145390, Accuracy: 60.72%\n",
            "Epoch: 5, Step: 37/164, Loss: 1.142068, Accuracy: 60.77%\n",
            "Epoch: 5, Step: 38/164, Loss: 1.146353, Accuracy: 60.59%\n",
            "Epoch: 5, Step: 39/164, Loss: 1.150306, Accuracy: 60.40%\n",
            "Epoch: 5, Step: 40/164, Loss: 1.152379, Accuracy: 60.25%\n",
            "Epoch: 5, Step: 41/164, Loss: 1.153777, Accuracy: 60.25%\n",
            "Epoch: 5, Step: 42/164, Loss: 1.150667, Accuracy: 60.45%\n",
            "Epoch: 5, Step: 43/164, Loss: 1.153834, Accuracy: 60.36%\n",
            "Epoch: 5, Step: 44/164, Loss: 1.155096, Accuracy: 60.28%\n",
            "Epoch: 5, Step: 45/164, Loss: 1.153991, Accuracy: 60.43%\n",
            "Epoch: 5, Step: 46/164, Loss: 1.156973, Accuracy: 60.43%\n",
            "Epoch: 5, Step: 47/164, Loss: 1.155472, Accuracy: 60.37%\n",
            "Epoch: 5, Step: 48/164, Loss: 1.154467, Accuracy: 60.43%\n",
            "Epoch: 5, Step: 49/164, Loss: 1.156700, Accuracy: 60.33%\n",
            "Epoch: 5, Step: 50/164, Loss: 1.155608, Accuracy: 60.34%\n",
            "Epoch: 5, Step: 51/164, Loss: 1.154394, Accuracy: 60.28%\n",
            "Epoch: 5, Step: 52/164, Loss: 1.154945, Accuracy: 60.22%\n",
            "Epoch: 5, Step: 53/164, Loss: 1.155867, Accuracy: 60.29%\n",
            "Epoch: 5, Step: 54/164, Loss: 1.156515, Accuracy: 60.19%\n",
            "Epoch: 5, Step: 55/164, Loss: 1.154178, Accuracy: 60.34%\n",
            "Epoch: 5, Step: 56/164, Loss: 1.153571, Accuracy: 60.45%\n",
            "Epoch: 5, Step: 57/164, Loss: 1.155890, Accuracy: 60.31%\n",
            "Epoch: 5, Step: 58/164, Loss: 1.153971, Accuracy: 60.34%\n",
            "Epoch: 5, Step: 59/164, Loss: 1.153424, Accuracy: 60.37%\n",
            "Epoch: 5, Step: 60/164, Loss: 1.154675, Accuracy: 60.27%\n",
            "Epoch: 5, Step: 61/164, Loss: 1.154541, Accuracy: 60.22%\n",
            "Epoch: 5, Step: 62/164, Loss: 1.156121, Accuracy: 60.13%\n",
            "Epoch: 5, Step: 63/164, Loss: 1.157313, Accuracy: 60.12%\n",
            "Epoch: 5, Step: 64/164, Loss: 1.160461, Accuracy: 60.03%\n",
            "Epoch: 5, Step: 65/164, Loss: 1.160587, Accuracy: 59.98%\n",
            "Epoch: 5, Step: 66/164, Loss: 1.163346, Accuracy: 59.84%\n",
            "Epoch: 5, Step: 67/164, Loss: 1.163477, Accuracy: 59.85%\n",
            "Epoch: 5, Step: 68/164, Loss: 1.162040, Accuracy: 59.97%\n",
            "Epoch: 5, Step: 69/164, Loss: 1.160538, Accuracy: 60.00%\n",
            "Epoch: 5, Step: 70/164, Loss: 1.162228, Accuracy: 59.98%\n",
            "Epoch: 5, Step: 71/164, Loss: 1.165512, Accuracy: 59.84%\n",
            "Epoch: 5, Step: 72/164, Loss: 1.161772, Accuracy: 59.97%\n",
            "Epoch: 5, Step: 73/164, Loss: 1.159527, Accuracy: 60.03%\n",
            "Epoch: 5, Step: 74/164, Loss: 1.159650, Accuracy: 60.01%\n",
            "Epoch: 5, Step: 75/164, Loss: 1.159590, Accuracy: 59.96%\n",
            "Epoch: 5, Step: 76/164, Loss: 1.159950, Accuracy: 59.92%\n",
            "Epoch: 5, Step: 77/164, Loss: 1.158355, Accuracy: 59.96%\n",
            "Epoch: 5, Step: 78/164, Loss: 1.159062, Accuracy: 59.90%\n",
            "Epoch: 5, Step: 79/164, Loss: 1.159466, Accuracy: 59.89%\n",
            "Epoch: 5, Step: 80/164, Loss: 1.157784, Accuracy: 59.96%\n",
            "Epoch: 5, Step: 81/164, Loss: 1.155238, Accuracy: 60.07%\n",
            "Epoch: 5, Step: 82/164, Loss: 1.154651, Accuracy: 60.06%\n",
            "Epoch: 5, Step: 83/164, Loss: 1.152847, Accuracy: 60.13%\n",
            "Epoch: 5, Step: 84/164, Loss: 1.154544, Accuracy: 60.13%\n",
            "Epoch: 5, Step: 85/164, Loss: 1.155964, Accuracy: 60.01%\n",
            "Epoch: 5, Step: 86/164, Loss: 1.156258, Accuracy: 59.97%\n",
            "Epoch: 5, Step: 87/164, Loss: 1.156174, Accuracy: 59.99%\n",
            "Epoch: 5, Step: 88/164, Loss: 1.154622, Accuracy: 60.04%\n",
            "Epoch: 5, Step: 89/164, Loss: 1.154795, Accuracy: 60.03%\n",
            "Epoch: 5, Step: 90/164, Loss: 1.154067, Accuracy: 60.06%\n",
            "Epoch: 5, Step: 91/164, Loss: 1.153309, Accuracy: 60.04%\n",
            "Epoch: 5, Step: 92/164, Loss: 1.151861, Accuracy: 60.11%\n",
            "Epoch: 5, Step: 93/164, Loss: 1.151020, Accuracy: 60.17%\n",
            "Epoch: 5, Step: 94/164, Loss: 1.150850, Accuracy: 60.21%\n",
            "Epoch: 5, Step: 95/164, Loss: 1.150660, Accuracy: 60.26%\n",
            "Epoch: 5, Step: 96/164, Loss: 1.148583, Accuracy: 60.36%\n",
            "Epoch: 5, Step: 97/164, Loss: 1.150173, Accuracy: 60.27%\n",
            "Epoch: 5, Step: 98/164, Loss: 1.149267, Accuracy: 60.29%\n",
            "Epoch: 5, Step: 99/164, Loss: 1.148361, Accuracy: 60.30%\n",
            "Epoch: 5, Step: 100/164, Loss: 1.148671, Accuracy: 60.30%\n",
            "Epoch: 5, Step: 101/164, Loss: 1.147803, Accuracy: 60.31%\n",
            "Epoch: 5, Step: 102/164, Loss: 1.147340, Accuracy: 60.30%\n",
            "Epoch: 5, Step: 103/164, Loss: 1.147111, Accuracy: 60.27%\n",
            "Epoch: 5, Step: 104/164, Loss: 1.148376, Accuracy: 60.24%\n",
            "Epoch: 5, Step: 105/164, Loss: 1.148430, Accuracy: 60.25%\n",
            "Epoch: 5, Step: 106/164, Loss: 1.147987, Accuracy: 60.24%\n",
            "Epoch: 5, Step: 107/164, Loss: 1.148122, Accuracy: 60.22%\n",
            "Epoch: 5, Step: 108/164, Loss: 1.148681, Accuracy: 60.18%\n",
            "Epoch: 5, Step: 109/164, Loss: 1.148517, Accuracy: 60.21%\n",
            "Epoch: 5, Step: 110/164, Loss: 1.148271, Accuracy: 60.23%\n",
            "Epoch: 5, Step: 111/164, Loss: 1.147922, Accuracy: 60.23%\n",
            "Epoch: 5, Step: 112/164, Loss: 1.147646, Accuracy: 60.25%\n",
            "Epoch: 5, Step: 113/164, Loss: 1.146923, Accuracy: 60.29%\n",
            "Epoch: 5, Step: 114/164, Loss: 1.146000, Accuracy: 60.31%\n",
            "Epoch: 5, Step: 115/164, Loss: 1.145858, Accuracy: 60.31%\n",
            "Epoch: 5, Step: 116/164, Loss: 1.147380, Accuracy: 60.27%\n",
            "Epoch: 5, Step: 117/164, Loss: 1.146659, Accuracy: 60.33%\n",
            "Epoch: 5, Step: 118/164, Loss: 1.146574, Accuracy: 60.33%\n",
            "Epoch: 5, Step: 119/164, Loss: 1.145963, Accuracy: 60.35%\n",
            "Epoch: 5, Step: 120/164, Loss: 1.144307, Accuracy: 60.40%\n",
            "Epoch: 5, Step: 121/164, Loss: 1.143668, Accuracy: 60.43%\n",
            "Epoch: 5, Step: 122/164, Loss: 1.142905, Accuracy: 60.48%\n",
            "Epoch: 5, Step: 123/164, Loss: 1.142750, Accuracy: 60.47%\n",
            "Epoch: 5, Step: 124/164, Loss: 1.141947, Accuracy: 60.53%\n",
            "Epoch: 5, Step: 125/164, Loss: 1.141626, Accuracy: 60.56%\n",
            "Epoch: 5, Step: 126/164, Loss: 1.141875, Accuracy: 60.52%\n",
            "Epoch: 5, Step: 127/164, Loss: 1.143143, Accuracy: 60.49%\n",
            "Epoch: 5, Step: 128/164, Loss: 1.143296, Accuracy: 60.48%\n",
            "Epoch: 5, Step: 129/164, Loss: 1.143250, Accuracy: 60.48%\n",
            "Epoch: 5, Step: 130/164, Loss: 1.143962, Accuracy: 60.48%\n",
            "Epoch: 5, Step: 131/164, Loss: 1.144097, Accuracy: 60.51%\n",
            "Epoch: 5, Step: 132/164, Loss: 1.144411, Accuracy: 60.53%\n",
            "Epoch: 5, Step: 133/164, Loss: 1.143834, Accuracy: 60.58%\n",
            "Epoch: 5, Step: 134/164, Loss: 1.144030, Accuracy: 60.57%\n",
            "Epoch: 5, Step: 135/164, Loss: 1.142992, Accuracy: 60.59%\n",
            "Epoch: 5, Step: 136/164, Loss: 1.143504, Accuracy: 60.54%\n",
            "Epoch: 5, Step: 137/164, Loss: 1.143702, Accuracy: 60.54%\n",
            "Epoch: 5, Step: 138/164, Loss: 1.143104, Accuracy: 60.54%\n",
            "Epoch: 5, Step: 139/164, Loss: 1.144642, Accuracy: 60.48%\n",
            "Epoch: 5, Step: 140/164, Loss: 1.143859, Accuracy: 60.50%\n",
            "Epoch: 5, Step: 141/164, Loss: 1.143423, Accuracy: 60.53%\n",
            "Epoch: 5, Step: 142/164, Loss: 1.143062, Accuracy: 60.57%\n",
            "Epoch: 5, Step: 143/164, Loss: 1.142708, Accuracy: 60.57%\n",
            "Epoch: 5, Step: 144/164, Loss: 1.142461, Accuracy: 60.60%\n",
            "Epoch: 5, Step: 145/164, Loss: 1.142061, Accuracy: 60.61%\n",
            "Epoch: 5, Step: 146/164, Loss: 1.141334, Accuracy: 60.64%\n",
            "Epoch: 5, Step: 147/164, Loss: 1.141476, Accuracy: 60.63%\n",
            "Epoch: 5, Step: 148/164, Loss: 1.141848, Accuracy: 60.61%\n",
            "Epoch: 5, Step: 149/164, Loss: 1.142338, Accuracy: 60.57%\n",
            "Epoch: 5, Step: 150/164, Loss: 1.141960, Accuracy: 60.57%\n",
            "Epoch: 5, Step: 151/164, Loss: 1.141380, Accuracy: 60.60%\n",
            "Epoch: 5, Step: 152/164, Loss: 1.140392, Accuracy: 60.59%\n",
            "Epoch: 5, Step: 153/164, Loss: 1.139709, Accuracy: 60.61%\n",
            "Epoch: 5, Step: 154/164, Loss: 1.139489, Accuracy: 60.64%\n",
            "Epoch: 5, Step: 155/164, Loss: 1.139736, Accuracy: 60.63%\n",
            "Epoch: 5, Step: 156/164, Loss: 1.139167, Accuracy: 60.65%\n",
            "Epoch: 5, Step: 157/164, Loss: 1.139992, Accuracy: 60.65%\n",
            "Epoch: 5, Step: 158/164, Loss: 1.140335, Accuracy: 60.66%\n",
            "Epoch: 5, Step: 159/164, Loss: 1.140115, Accuracy: 60.66%\n",
            "Epoch: 5, Step: 160/164, Loss: 1.141661, Accuracy: 60.60%\n",
            "Epoch: 5, Step: 161/164, Loss: 1.142537, Accuracy: 60.54%\n",
            "Epoch: 5, Step: 162/164, Loss: 1.142646, Accuracy: 60.55%\n",
            "Epoch: 5, Step: 163/164, Loss: 1.142901, Accuracy: 60.57%\n",
            "Epoch: 5, Step: 164/164, Loss: 1.141020, Accuracy: 60.62%\n",
            "Epoch: 6, Step: 1/164, Loss: 1.266826, Accuracy: 57.81%\n",
            "Epoch: 6, Step: 2/164, Loss: 1.083486, Accuracy: 64.06%\n",
            "Epoch: 6, Step: 3/164, Loss: 1.035801, Accuracy: 65.62%\n",
            "Epoch: 6, Step: 4/164, Loss: 1.066031, Accuracy: 64.45%\n",
            "Epoch: 6, Step: 5/164, Loss: 1.068132, Accuracy: 63.44%\n",
            "Epoch: 6, Step: 6/164, Loss: 1.089429, Accuracy: 62.63%\n",
            "Epoch: 6, Step: 7/164, Loss: 1.080311, Accuracy: 62.83%\n",
            "Epoch: 6, Step: 8/164, Loss: 1.069443, Accuracy: 62.99%\n",
            "Epoch: 6, Step: 9/164, Loss: 1.060341, Accuracy: 62.93%\n",
            "Epoch: 6, Step: 10/164, Loss: 1.056379, Accuracy: 63.12%\n",
            "Epoch: 6, Step: 11/164, Loss: 1.045199, Accuracy: 63.71%\n",
            "Epoch: 6, Step: 12/164, Loss: 1.051983, Accuracy: 63.35%\n",
            "Epoch: 6, Step: 13/164, Loss: 1.061328, Accuracy: 63.34%\n",
            "Epoch: 6, Step: 14/164, Loss: 1.055163, Accuracy: 63.67%\n",
            "Epoch: 6, Step: 15/164, Loss: 1.056757, Accuracy: 63.85%\n",
            "Epoch: 6, Step: 16/164, Loss: 1.053188, Accuracy: 64.16%\n",
            "Epoch: 6, Step: 17/164, Loss: 1.051183, Accuracy: 64.20%\n",
            "Epoch: 6, Step: 18/164, Loss: 1.047236, Accuracy: 64.15%\n",
            "Epoch: 6, Step: 19/164, Loss: 1.043530, Accuracy: 64.27%\n",
            "Epoch: 6, Step: 20/164, Loss: 1.037244, Accuracy: 64.49%\n",
            "Epoch: 6, Step: 21/164, Loss: 1.032209, Accuracy: 64.62%\n",
            "Epoch: 6, Step: 22/164, Loss: 1.030401, Accuracy: 64.77%\n",
            "Epoch: 6, Step: 23/164, Loss: 1.022969, Accuracy: 64.95%\n",
            "Epoch: 6, Step: 24/164, Loss: 1.030177, Accuracy: 64.78%\n",
            "Epoch: 6, Step: 25/164, Loss: 1.025982, Accuracy: 64.84%\n",
            "Epoch: 6, Step: 26/164, Loss: 1.024444, Accuracy: 64.90%\n",
            "Epoch: 6, Step: 27/164, Loss: 1.023220, Accuracy: 64.84%\n",
            "Epoch: 6, Step: 28/164, Loss: 1.025222, Accuracy: 64.73%\n",
            "Epoch: 6, Step: 29/164, Loss: 1.024063, Accuracy: 64.84%\n",
            "Epoch: 6, Step: 30/164, Loss: 1.026856, Accuracy: 64.79%\n",
            "Epoch: 6, Step: 31/164, Loss: 1.027636, Accuracy: 64.69%\n",
            "Epoch: 6, Step: 32/164, Loss: 1.024977, Accuracy: 64.67%\n",
            "Epoch: 6, Step: 33/164, Loss: 1.021597, Accuracy: 64.63%\n",
            "Epoch: 6, Step: 34/164, Loss: 1.028322, Accuracy: 64.45%\n",
            "Epoch: 6, Step: 35/164, Loss: 1.025620, Accuracy: 64.55%\n",
            "Epoch: 6, Step: 36/164, Loss: 1.028499, Accuracy: 64.43%\n",
            "Epoch: 6, Step: 37/164, Loss: 1.023774, Accuracy: 64.63%\n",
            "Epoch: 6, Step: 38/164, Loss: 1.021461, Accuracy: 64.74%\n",
            "Epoch: 6, Step: 39/164, Loss: 1.022718, Accuracy: 64.72%\n",
            "Epoch: 6, Step: 40/164, Loss: 1.026622, Accuracy: 64.71%\n",
            "Epoch: 6, Step: 41/164, Loss: 1.027490, Accuracy: 64.58%\n",
            "Epoch: 6, Step: 42/164, Loss: 1.024840, Accuracy: 64.66%\n",
            "Epoch: 6, Step: 43/164, Loss: 1.026977, Accuracy: 64.73%\n",
            "Epoch: 6, Step: 44/164, Loss: 1.026661, Accuracy: 64.68%\n",
            "Epoch: 6, Step: 45/164, Loss: 1.025852, Accuracy: 64.64%\n",
            "Epoch: 6, Step: 46/164, Loss: 1.030081, Accuracy: 64.45%\n",
            "Epoch: 6, Step: 47/164, Loss: 1.025892, Accuracy: 64.68%\n",
            "Epoch: 6, Step: 48/164, Loss: 1.028625, Accuracy: 64.58%\n",
            "Epoch: 6, Step: 49/164, Loss: 1.026411, Accuracy: 64.70%\n",
            "Epoch: 6, Step: 50/164, Loss: 1.024399, Accuracy: 64.77%\n",
            "Epoch: 6, Step: 51/164, Loss: 1.026438, Accuracy: 64.66%\n",
            "Epoch: 6, Step: 52/164, Loss: 1.024035, Accuracy: 64.71%\n",
            "Epoch: 6, Step: 53/164, Loss: 1.025525, Accuracy: 64.67%\n",
            "Epoch: 6, Step: 54/164, Loss: 1.025531, Accuracy: 64.70%\n",
            "Epoch: 6, Step: 55/164, Loss: 1.026047, Accuracy: 64.69%\n",
            "Epoch: 6, Step: 56/164, Loss: 1.023425, Accuracy: 64.79%\n",
            "Epoch: 6, Step: 57/164, Loss: 1.022384, Accuracy: 64.86%\n",
            "Epoch: 6, Step: 58/164, Loss: 1.018453, Accuracy: 65.02%\n",
            "Epoch: 6, Step: 59/164, Loss: 1.014083, Accuracy: 65.17%\n",
            "Epoch: 6, Step: 60/164, Loss: 1.013788, Accuracy: 65.21%\n",
            "Epoch: 6, Step: 61/164, Loss: 1.012342, Accuracy: 65.19%\n",
            "Epoch: 6, Step: 62/164, Loss: 1.012080, Accuracy: 65.18%\n",
            "Epoch: 6, Step: 63/164, Loss: 1.013325, Accuracy: 65.15%\n",
            "Epoch: 6, Step: 64/164, Loss: 1.010698, Accuracy: 65.22%\n",
            "Epoch: 6, Step: 65/164, Loss: 1.007418, Accuracy: 65.36%\n",
            "Epoch: 6, Step: 66/164, Loss: 1.006814, Accuracy: 65.33%\n",
            "Epoch: 6, Step: 67/164, Loss: 1.006454, Accuracy: 65.35%\n",
            "Epoch: 6, Step: 68/164, Loss: 1.004117, Accuracy: 65.40%\n",
            "Epoch: 6, Step: 69/164, Loss: 1.003565, Accuracy: 65.39%\n",
            "Epoch: 6, Step: 70/164, Loss: 1.004217, Accuracy: 65.33%\n",
            "Epoch: 6, Step: 71/164, Loss: 1.004859, Accuracy: 65.31%\n",
            "Epoch: 6, Step: 72/164, Loss: 1.006097, Accuracy: 65.25%\n",
            "Epoch: 6, Step: 73/164, Loss: 1.005080, Accuracy: 65.29%\n",
            "Epoch: 6, Step: 74/164, Loss: 1.003276, Accuracy: 65.36%\n",
            "Epoch: 6, Step: 75/164, Loss: 1.001648, Accuracy: 65.40%\n",
            "Epoch: 6, Step: 76/164, Loss: 1.003452, Accuracy: 65.36%\n",
            "Epoch: 6, Step: 77/164, Loss: 1.007004, Accuracy: 65.23%\n",
            "Epoch: 6, Step: 78/164, Loss: 1.005691, Accuracy: 65.30%\n",
            "Epoch: 6, Step: 79/164, Loss: 1.006074, Accuracy: 65.29%\n",
            "Epoch: 6, Step: 80/164, Loss: 1.005748, Accuracy: 65.30%\n",
            "Epoch: 6, Step: 81/164, Loss: 1.006199, Accuracy: 65.25%\n",
            "Epoch: 6, Step: 82/164, Loss: 1.006717, Accuracy: 65.25%\n",
            "Epoch: 6, Step: 83/164, Loss: 1.008109, Accuracy: 65.20%\n",
            "Epoch: 6, Step: 84/164, Loss: 1.009339, Accuracy: 65.13%\n",
            "Epoch: 6, Step: 85/164, Loss: 1.007902, Accuracy: 65.19%\n",
            "Epoch: 6, Step: 86/164, Loss: 1.009018, Accuracy: 65.18%\n",
            "Epoch: 6, Step: 87/164, Loss: 1.009595, Accuracy: 65.19%\n",
            "Epoch: 6, Step: 88/164, Loss: 1.008556, Accuracy: 65.27%\n",
            "Epoch: 6, Step: 89/164, Loss: 1.007758, Accuracy: 65.28%\n",
            "Epoch: 6, Step: 90/164, Loss: 1.006858, Accuracy: 65.35%\n",
            "Epoch: 6, Step: 91/164, Loss: 1.006933, Accuracy: 65.34%\n",
            "Epoch: 6, Step: 92/164, Loss: 1.006339, Accuracy: 65.40%\n",
            "Epoch: 6, Step: 93/164, Loss: 1.008310, Accuracy: 65.36%\n",
            "Epoch: 6, Step: 94/164, Loss: 1.009438, Accuracy: 65.35%\n",
            "Epoch: 6, Step: 95/164, Loss: 1.010218, Accuracy: 65.34%\n",
            "Epoch: 6, Step: 96/164, Loss: 1.011299, Accuracy: 65.28%\n",
            "Epoch: 6, Step: 97/164, Loss: 1.009922, Accuracy: 65.30%\n",
            "Epoch: 6, Step: 98/164, Loss: 1.010592, Accuracy: 65.25%\n",
            "Epoch: 6, Step: 99/164, Loss: 1.009738, Accuracy: 65.30%\n",
            "Epoch: 6, Step: 100/164, Loss: 1.009731, Accuracy: 65.33%\n",
            "Epoch: 6, Step: 101/164, Loss: 1.009489, Accuracy: 65.32%\n",
            "Epoch: 6, Step: 102/164, Loss: 1.011559, Accuracy: 65.24%\n",
            "Epoch: 6, Step: 103/164, Loss: 1.010855, Accuracy: 65.26%\n",
            "Epoch: 6, Step: 104/164, Loss: 1.010867, Accuracy: 65.32%\n",
            "Epoch: 6, Step: 105/164, Loss: 1.010817, Accuracy: 65.31%\n",
            "Epoch: 6, Step: 106/164, Loss: 1.010281, Accuracy: 65.32%\n",
            "Epoch: 6, Step: 107/164, Loss: 1.010889, Accuracy: 65.28%\n",
            "Epoch: 6, Step: 108/164, Loss: 1.010320, Accuracy: 65.31%\n",
            "Epoch: 6, Step: 109/164, Loss: 1.010146, Accuracy: 65.30%\n",
            "Epoch: 6, Step: 110/164, Loss: 1.010622, Accuracy: 65.23%\n",
            "Epoch: 6, Step: 111/164, Loss: 1.010071, Accuracy: 65.23%\n",
            "Epoch: 6, Step: 112/164, Loss: 1.008304, Accuracy: 65.30%\n",
            "Epoch: 6, Step: 113/164, Loss: 1.008923, Accuracy: 65.27%\n",
            "Epoch: 6, Step: 114/164, Loss: 1.009161, Accuracy: 65.28%\n",
            "Epoch: 6, Step: 115/164, Loss: 1.009838, Accuracy: 65.26%\n",
            "Epoch: 6, Step: 116/164, Loss: 1.008962, Accuracy: 65.29%\n",
            "Epoch: 6, Step: 117/164, Loss: 1.008914, Accuracy: 65.29%\n",
            "Epoch: 6, Step: 118/164, Loss: 1.009952, Accuracy: 65.25%\n",
            "Epoch: 6, Step: 119/164, Loss: 1.008812, Accuracy: 65.29%\n",
            "Epoch: 6, Step: 120/164, Loss: 1.007747, Accuracy: 65.29%\n",
            "Epoch: 6, Step: 121/164, Loss: 1.007647, Accuracy: 65.25%\n",
            "Epoch: 6, Step: 122/164, Loss: 1.007435, Accuracy: 65.27%\n",
            "Epoch: 6, Step: 123/164, Loss: 1.006334, Accuracy: 65.31%\n",
            "Epoch: 6, Step: 124/164, Loss: 1.005508, Accuracy: 65.37%\n",
            "Epoch: 6, Step: 125/164, Loss: 1.004872, Accuracy: 65.35%\n",
            "Epoch: 6, Step: 126/164, Loss: 1.005607, Accuracy: 65.31%\n",
            "Epoch: 6, Step: 127/164, Loss: 1.005431, Accuracy: 65.31%\n",
            "Epoch: 6, Step: 128/164, Loss: 1.005995, Accuracy: 65.33%\n",
            "Epoch: 6, Step: 129/164, Loss: 1.005147, Accuracy: 65.34%\n",
            "Epoch: 6, Step: 130/164, Loss: 1.004878, Accuracy: 65.38%\n",
            "Epoch: 6, Step: 131/164, Loss: 1.005661, Accuracy: 65.35%\n",
            "Epoch: 6, Step: 132/164, Loss: 1.005664, Accuracy: 65.39%\n",
            "Epoch: 6, Step: 133/164, Loss: 1.005654, Accuracy: 65.35%\n",
            "Epoch: 6, Step: 134/164, Loss: 1.005345, Accuracy: 65.34%\n",
            "Epoch: 6, Step: 135/164, Loss: 1.004105, Accuracy: 65.38%\n",
            "Epoch: 6, Step: 136/164, Loss: 1.002460, Accuracy: 65.44%\n",
            "Epoch: 6, Step: 137/164, Loss: 1.000753, Accuracy: 65.47%\n",
            "Epoch: 6, Step: 138/164, Loss: 1.000742, Accuracy: 65.48%\n",
            "Epoch: 6, Step: 139/164, Loss: 1.000955, Accuracy: 65.52%\n",
            "Epoch: 6, Step: 140/164, Loss: 0.999934, Accuracy: 65.56%\n",
            "Epoch: 6, Step: 141/164, Loss: 0.998771, Accuracy: 65.58%\n",
            "Epoch: 6, Step: 142/164, Loss: 1.000006, Accuracy: 65.54%\n",
            "Epoch: 6, Step: 143/164, Loss: 0.999634, Accuracy: 65.56%\n",
            "Epoch: 6, Step: 144/164, Loss: 0.999090, Accuracy: 65.57%\n",
            "Epoch: 6, Step: 145/164, Loss: 1.000285, Accuracy: 65.52%\n",
            "Epoch: 6, Step: 146/164, Loss: 1.000045, Accuracy: 65.53%\n",
            "Epoch: 6, Step: 147/164, Loss: 1.000224, Accuracy: 65.56%\n",
            "Epoch: 6, Step: 148/164, Loss: 0.999596, Accuracy: 65.56%\n",
            "Epoch: 6, Step: 149/164, Loss: 0.999849, Accuracy: 65.55%\n",
            "Epoch: 6, Step: 150/164, Loss: 0.999561, Accuracy: 65.57%\n",
            "Epoch: 6, Step: 151/164, Loss: 0.999022, Accuracy: 65.59%\n",
            "Epoch: 6, Step: 152/164, Loss: 0.999939, Accuracy: 65.58%\n",
            "Epoch: 6, Step: 153/164, Loss: 0.999775, Accuracy: 65.61%\n",
            "Epoch: 6, Step: 154/164, Loss: 1.001234, Accuracy: 65.58%\n",
            "Epoch: 6, Step: 155/164, Loss: 0.999500, Accuracy: 65.62%\n",
            "Epoch: 6, Step: 156/164, Loss: 0.999407, Accuracy: 65.65%\n",
            "Epoch: 6, Step: 157/164, Loss: 0.999016, Accuracy: 65.64%\n",
            "Epoch: 6, Step: 158/164, Loss: 0.998624, Accuracy: 65.64%\n",
            "Epoch: 6, Step: 159/164, Loss: 0.997499, Accuracy: 65.68%\n",
            "Epoch: 6, Step: 160/164, Loss: 0.999023, Accuracy: 65.65%\n",
            "Epoch: 6, Step: 161/164, Loss: 0.998463, Accuracy: 65.72%\n",
            "Epoch: 6, Step: 162/164, Loss: 0.998138, Accuracy: 65.71%\n",
            "Epoch: 6, Step: 163/164, Loss: 0.998237, Accuracy: 65.71%\n",
            "Epoch: 6, Step: 164/164, Loss: 0.999634, Accuracy: 65.70%\n",
            "Epoch: 7, Step: 1/164, Loss: 1.005082, Accuracy: 69.53%\n",
            "Epoch: 7, Step: 2/164, Loss: 0.939762, Accuracy: 68.36%\n",
            "Epoch: 7, Step: 3/164, Loss: 0.946926, Accuracy: 66.67%\n",
            "Epoch: 7, Step: 4/164, Loss: 0.916623, Accuracy: 68.75%\n",
            "Epoch: 7, Step: 5/164, Loss: 0.949707, Accuracy: 67.34%\n",
            "Epoch: 7, Step: 6/164, Loss: 0.981429, Accuracy: 66.02%\n",
            "Epoch: 7, Step: 7/164, Loss: 0.995907, Accuracy: 65.74%\n",
            "Epoch: 7, Step: 8/164, Loss: 0.989668, Accuracy: 65.72%\n",
            "Epoch: 7, Step: 9/164, Loss: 0.993038, Accuracy: 65.80%\n",
            "Epoch: 7, Step: 10/164, Loss: 0.984517, Accuracy: 66.17%\n",
            "Epoch: 7, Step: 11/164, Loss: 0.981509, Accuracy: 65.98%\n",
            "Epoch: 7, Step: 12/164, Loss: 0.983299, Accuracy: 66.28%\n",
            "Epoch: 7, Step: 13/164, Loss: 0.975714, Accuracy: 66.53%\n",
            "Epoch: 7, Step: 14/164, Loss: 0.970808, Accuracy: 66.85%\n",
            "Epoch: 7, Step: 15/164, Loss: 0.958850, Accuracy: 66.93%\n",
            "Epoch: 7, Step: 16/164, Loss: 0.953509, Accuracy: 67.14%\n",
            "Epoch: 7, Step: 17/164, Loss: 0.952112, Accuracy: 67.51%\n",
            "Epoch: 7, Step: 18/164, Loss: 0.949945, Accuracy: 67.62%\n",
            "Epoch: 7, Step: 19/164, Loss: 0.954495, Accuracy: 67.31%\n",
            "Epoch: 7, Step: 20/164, Loss: 0.947305, Accuracy: 67.46%\n",
            "Epoch: 7, Step: 21/164, Loss: 0.947325, Accuracy: 67.60%\n",
            "Epoch: 7, Step: 22/164, Loss: 0.955676, Accuracy: 67.33%\n",
            "Epoch: 7, Step: 23/164, Loss: 0.953595, Accuracy: 67.63%\n",
            "Epoch: 7, Step: 24/164, Loss: 0.956044, Accuracy: 67.48%\n",
            "Epoch: 7, Step: 25/164, Loss: 0.956526, Accuracy: 67.53%\n",
            "Epoch: 7, Step: 26/164, Loss: 0.954207, Accuracy: 67.52%\n",
            "Epoch: 7, Step: 27/164, Loss: 0.951643, Accuracy: 67.53%\n",
            "Epoch: 7, Step: 28/164, Loss: 0.954198, Accuracy: 67.38%\n",
            "Epoch: 7, Step: 29/164, Loss: 0.956735, Accuracy: 67.30%\n",
            "Epoch: 7, Step: 30/164, Loss: 0.955186, Accuracy: 67.37%\n",
            "Epoch: 7, Step: 31/164, Loss: 0.957609, Accuracy: 67.39%\n",
            "Epoch: 7, Step: 32/164, Loss: 0.954723, Accuracy: 67.43%\n",
            "Epoch: 7, Step: 33/164, Loss: 0.956981, Accuracy: 67.45%\n",
            "Epoch: 7, Step: 34/164, Loss: 0.957830, Accuracy: 67.37%\n",
            "Epoch: 7, Step: 35/164, Loss: 0.955290, Accuracy: 67.61%\n",
            "Epoch: 7, Step: 36/164, Loss: 0.954010, Accuracy: 67.58%\n",
            "Epoch: 7, Step: 37/164, Loss: 0.947685, Accuracy: 67.84%\n",
            "Epoch: 7, Step: 38/164, Loss: 0.944927, Accuracy: 67.87%\n",
            "Epoch: 7, Step: 39/164, Loss: 0.941601, Accuracy: 67.97%\n",
            "Epoch: 7, Step: 40/164, Loss: 0.941512, Accuracy: 67.93%\n",
            "Epoch: 7, Step: 41/164, Loss: 0.942482, Accuracy: 67.87%\n",
            "Epoch: 7, Step: 42/164, Loss: 0.942675, Accuracy: 67.78%\n",
            "Epoch: 7, Step: 43/164, Loss: 0.943035, Accuracy: 67.70%\n",
            "Epoch: 7, Step: 44/164, Loss: 0.942065, Accuracy: 67.67%\n",
            "Epoch: 7, Step: 45/164, Loss: 0.942257, Accuracy: 67.74%\n",
            "Epoch: 7, Step: 46/164, Loss: 0.944674, Accuracy: 67.71%\n",
            "Epoch: 7, Step: 47/164, Loss: 0.946737, Accuracy: 67.69%\n",
            "Epoch: 7, Step: 48/164, Loss: 0.943757, Accuracy: 67.68%\n",
            "Epoch: 7, Step: 49/164, Loss: 0.942412, Accuracy: 67.71%\n",
            "Epoch: 7, Step: 50/164, Loss: 0.939034, Accuracy: 67.77%\n",
            "Epoch: 7, Step: 51/164, Loss: 0.939283, Accuracy: 67.80%\n",
            "Epoch: 7, Step: 52/164, Loss: 0.939789, Accuracy: 67.77%\n",
            "Epoch: 7, Step: 53/164, Loss: 0.943232, Accuracy: 67.57%\n",
            "Epoch: 7, Step: 54/164, Loss: 0.943017, Accuracy: 67.53%\n",
            "Epoch: 7, Step: 55/164, Loss: 0.940490, Accuracy: 67.68%\n",
            "Epoch: 7, Step: 56/164, Loss: 0.941237, Accuracy: 67.70%\n",
            "Epoch: 7, Step: 57/164, Loss: 0.944361, Accuracy: 67.63%\n",
            "Epoch: 7, Step: 58/164, Loss: 0.944335, Accuracy: 67.65%\n",
            "Epoch: 7, Step: 59/164, Loss: 0.943830, Accuracy: 67.68%\n",
            "Epoch: 7, Step: 60/164, Loss: 0.943532, Accuracy: 67.70%\n",
            "Epoch: 7, Step: 61/164, Loss: 0.943148, Accuracy: 67.66%\n",
            "Epoch: 7, Step: 62/164, Loss: 0.941247, Accuracy: 67.82%\n",
            "Epoch: 7, Step: 63/164, Loss: 0.941986, Accuracy: 67.80%\n",
            "Epoch: 7, Step: 64/164, Loss: 0.942309, Accuracy: 67.70%\n",
            "Epoch: 7, Step: 65/164, Loss: 0.945288, Accuracy: 67.56%\n",
            "Epoch: 7, Step: 66/164, Loss: 0.946489, Accuracy: 67.58%\n",
            "Epoch: 7, Step: 67/164, Loss: 0.943417, Accuracy: 67.70%\n",
            "Epoch: 7, Step: 68/164, Loss: 0.941932, Accuracy: 67.77%\n",
            "Epoch: 7, Step: 69/164, Loss: 0.942079, Accuracy: 67.75%\n",
            "Epoch: 7, Step: 70/164, Loss: 0.943774, Accuracy: 67.68%\n",
            "Epoch: 7, Step: 71/164, Loss: 0.943964, Accuracy: 67.67%\n",
            "Epoch: 7, Step: 72/164, Loss: 0.941459, Accuracy: 67.77%\n",
            "Epoch: 7, Step: 73/164, Loss: 0.941613, Accuracy: 67.74%\n",
            "Epoch: 7, Step: 74/164, Loss: 0.942552, Accuracy: 67.69%\n",
            "Epoch: 7, Step: 75/164, Loss: 0.944866, Accuracy: 67.59%\n",
            "Epoch: 7, Step: 76/164, Loss: 0.945049, Accuracy: 67.59%\n",
            "Epoch: 7, Step: 77/164, Loss: 0.945979, Accuracy: 67.60%\n",
            "Epoch: 7, Step: 78/164, Loss: 0.947872, Accuracy: 67.59%\n",
            "Epoch: 7, Step: 79/164, Loss: 0.947574, Accuracy: 67.61%\n",
            "Epoch: 7, Step: 80/164, Loss: 0.945473, Accuracy: 67.71%\n",
            "Epoch: 7, Step: 81/164, Loss: 0.947910, Accuracy: 67.66%\n",
            "Epoch: 7, Step: 82/164, Loss: 0.947341, Accuracy: 67.66%\n",
            "Epoch: 7, Step: 83/164, Loss: 0.947178, Accuracy: 67.70%\n",
            "Epoch: 7, Step: 84/164, Loss: 0.944899, Accuracy: 67.77%\n",
            "Epoch: 7, Step: 85/164, Loss: 0.944642, Accuracy: 67.78%\n",
            "Epoch: 7, Step: 86/164, Loss: 0.944559, Accuracy: 67.85%\n",
            "Epoch: 7, Step: 87/164, Loss: 0.941432, Accuracy: 67.94%\n",
            "Epoch: 7, Step: 88/164, Loss: 0.940288, Accuracy: 67.92%\n",
            "Epoch: 7, Step: 89/164, Loss: 0.940918, Accuracy: 67.92%\n",
            "Epoch: 7, Step: 90/164, Loss: 0.940863, Accuracy: 67.98%\n",
            "Epoch: 7, Step: 91/164, Loss: 0.940893, Accuracy: 67.99%\n",
            "Epoch: 7, Step: 92/164, Loss: 0.940303, Accuracy: 68.01%\n",
            "Epoch: 7, Step: 93/164, Loss: 0.939931, Accuracy: 68.00%\n",
            "Epoch: 7, Step: 94/164, Loss: 0.941706, Accuracy: 67.96%\n",
            "Epoch: 7, Step: 95/164, Loss: 0.941993, Accuracy: 67.99%\n",
            "Epoch: 7, Step: 96/164, Loss: 0.942124, Accuracy: 67.99%\n",
            "Epoch: 7, Step: 97/164, Loss: 0.942496, Accuracy: 67.94%\n",
            "Epoch: 7, Step: 98/164, Loss: 0.943234, Accuracy: 67.90%\n",
            "Epoch: 7, Step: 99/164, Loss: 0.943562, Accuracy: 67.88%\n",
            "Epoch: 7, Step: 100/164, Loss: 0.943000, Accuracy: 67.96%\n",
            "Epoch: 7, Step: 101/164, Loss: 0.942949, Accuracy: 67.95%\n",
            "Epoch: 7, Step: 102/164, Loss: 0.945476, Accuracy: 67.84%\n",
            "Epoch: 7, Step: 103/164, Loss: 0.945445, Accuracy: 67.85%\n",
            "Epoch: 7, Step: 104/164, Loss: 0.945741, Accuracy: 67.86%\n",
            "Epoch: 7, Step: 105/164, Loss: 0.944165, Accuracy: 67.88%\n",
            "Epoch: 7, Step: 106/164, Loss: 0.943750, Accuracy: 67.92%\n",
            "Epoch: 7, Step: 107/164, Loss: 0.943688, Accuracy: 67.93%\n",
            "Epoch: 7, Step: 108/164, Loss: 0.942233, Accuracy: 67.95%\n",
            "Epoch: 7, Step: 109/164, Loss: 0.943041, Accuracy: 67.94%\n",
            "Epoch: 7, Step: 110/164, Loss: 0.942539, Accuracy: 67.97%\n",
            "Epoch: 7, Step: 111/164, Loss: 0.942063, Accuracy: 67.99%\n",
            "Epoch: 7, Step: 112/164, Loss: 0.941724, Accuracy: 68.01%\n",
            "Epoch: 7, Step: 113/164, Loss: 0.941302, Accuracy: 68.04%\n",
            "Epoch: 7, Step: 114/164, Loss: 0.940343, Accuracy: 68.08%\n",
            "Epoch: 7, Step: 115/164, Loss: 0.939660, Accuracy: 68.12%\n",
            "Epoch: 7, Step: 116/164, Loss: 0.939927, Accuracy: 68.10%\n",
            "Epoch: 7, Step: 117/164, Loss: 0.941032, Accuracy: 68.08%\n",
            "Epoch: 7, Step: 118/164, Loss: 0.941310, Accuracy: 68.10%\n",
            "Epoch: 7, Step: 119/164, Loss: 0.941424, Accuracy: 68.09%\n",
            "Epoch: 7, Step: 120/164, Loss: 0.940153, Accuracy: 68.13%\n",
            "Epoch: 7, Step: 121/164, Loss: 0.939284, Accuracy: 68.18%\n",
            "Epoch: 7, Step: 122/164, Loss: 0.939527, Accuracy: 68.18%\n",
            "Epoch: 7, Step: 123/164, Loss: 0.938894, Accuracy: 68.15%\n",
            "Epoch: 7, Step: 124/164, Loss: 0.939494, Accuracy: 68.15%\n",
            "Epoch: 7, Step: 125/164, Loss: 0.938716, Accuracy: 68.14%\n",
            "Epoch: 7, Step: 126/164, Loss: 0.939335, Accuracy: 68.13%\n",
            "Epoch: 7, Step: 127/164, Loss: 0.939170, Accuracy: 68.11%\n",
            "Epoch: 7, Step: 128/164, Loss: 0.939286, Accuracy: 68.09%\n",
            "Epoch: 7, Step: 129/164, Loss: 0.939538, Accuracy: 68.06%\n",
            "Epoch: 7, Step: 130/164, Loss: 0.939035, Accuracy: 68.09%\n",
            "Epoch: 7, Step: 131/164, Loss: 0.940874, Accuracy: 68.05%\n",
            "Epoch: 7, Step: 132/164, Loss: 0.941196, Accuracy: 68.00%\n",
            "Epoch: 7, Step: 133/164, Loss: 0.940531, Accuracy: 68.00%\n",
            "Epoch: 7, Step: 134/164, Loss: 0.941565, Accuracy: 67.97%\n",
            "Epoch: 7, Step: 135/164, Loss: 0.942395, Accuracy: 67.92%\n",
            "Epoch: 7, Step: 136/164, Loss: 0.942392, Accuracy: 67.93%\n",
            "Epoch: 7, Step: 137/164, Loss: 0.942168, Accuracy: 67.93%\n",
            "Epoch: 7, Step: 138/164, Loss: 0.941519, Accuracy: 67.97%\n",
            "Epoch: 7, Step: 139/164, Loss: 0.940147, Accuracy: 68.05%\n",
            "Epoch: 7, Step: 140/164, Loss: 0.939007, Accuracy: 68.08%\n",
            "Epoch: 7, Step: 141/164, Loss: 0.938285, Accuracy: 68.10%\n",
            "Epoch: 7, Step: 142/164, Loss: 0.938325, Accuracy: 68.10%\n",
            "Epoch: 7, Step: 143/164, Loss: 0.939215, Accuracy: 68.05%\n",
            "Epoch: 7, Step: 144/164, Loss: 0.939302, Accuracy: 68.03%\n",
            "Epoch: 7, Step: 145/164, Loss: 0.940931, Accuracy: 67.99%\n",
            "Epoch: 7, Step: 146/164, Loss: 0.940371, Accuracy: 68.00%\n",
            "Epoch: 7, Step: 147/164, Loss: 0.940258, Accuracy: 68.01%\n",
            "Epoch: 7, Step: 148/164, Loss: 0.939908, Accuracy: 68.02%\n",
            "Epoch: 7, Step: 149/164, Loss: 0.940535, Accuracy: 67.98%\n",
            "Epoch: 7, Step: 150/164, Loss: 0.940500, Accuracy: 68.00%\n",
            "Epoch: 7, Step: 151/164, Loss: 0.940797, Accuracy: 68.00%\n",
            "Epoch: 7, Step: 152/164, Loss: 0.940565, Accuracy: 68.04%\n",
            "Epoch: 7, Step: 153/164, Loss: 0.939872, Accuracy: 68.07%\n",
            "Epoch: 7, Step: 154/164, Loss: 0.939860, Accuracy: 68.08%\n",
            "Epoch: 7, Step: 155/164, Loss: 0.938994, Accuracy: 68.11%\n",
            "Epoch: 7, Step: 156/164, Loss: 0.939137, Accuracy: 68.10%\n",
            "Epoch: 7, Step: 157/164, Loss: 0.940033, Accuracy: 68.09%\n",
            "Epoch: 7, Step: 158/164, Loss: 0.940210, Accuracy: 68.08%\n",
            "Epoch: 7, Step: 159/164, Loss: 0.940383, Accuracy: 68.06%\n",
            "Epoch: 7, Step: 160/164, Loss: 0.940178, Accuracy: 68.05%\n",
            "Epoch: 7, Step: 161/164, Loss: 0.939622, Accuracy: 68.07%\n",
            "Epoch: 7, Step: 162/164, Loss: 0.939596, Accuracy: 68.06%\n",
            "Epoch: 7, Step: 163/164, Loss: 0.938978, Accuracy: 68.10%\n",
            "Epoch: 7, Step: 164/164, Loss: 0.939102, Accuracy: 68.10%\n",
            "Epoch: 8, Step: 1/164, Loss: 0.814332, Accuracy: 69.53%\n",
            "Epoch: 8, Step: 2/164, Loss: 0.848374, Accuracy: 69.92%\n",
            "Epoch: 8, Step: 3/164, Loss: 0.879187, Accuracy: 68.23%\n",
            "Epoch: 8, Step: 4/164, Loss: 0.926510, Accuracy: 68.16%\n",
            "Epoch: 8, Step: 5/164, Loss: 0.935183, Accuracy: 67.50%\n",
            "Epoch: 8, Step: 6/164, Loss: 0.928151, Accuracy: 67.71%\n",
            "Epoch: 8, Step: 7/164, Loss: 0.926770, Accuracy: 67.97%\n",
            "Epoch: 8, Step: 8/164, Loss: 0.923589, Accuracy: 67.58%\n",
            "Epoch: 8, Step: 9/164, Loss: 0.910205, Accuracy: 67.97%\n",
            "Epoch: 8, Step: 10/164, Loss: 0.920021, Accuracy: 67.42%\n",
            "Epoch: 8, Step: 11/164, Loss: 0.916006, Accuracy: 67.68%\n",
            "Epoch: 8, Step: 12/164, Loss: 0.907664, Accuracy: 68.16%\n",
            "Epoch: 8, Step: 13/164, Loss: 0.906674, Accuracy: 67.97%\n",
            "Epoch: 8, Step: 14/164, Loss: 0.897919, Accuracy: 68.53%\n",
            "Epoch: 8, Step: 15/164, Loss: 0.889022, Accuracy: 68.70%\n",
            "Epoch: 8, Step: 16/164, Loss: 0.886998, Accuracy: 68.65%\n",
            "Epoch: 8, Step: 17/164, Loss: 0.884467, Accuracy: 68.66%\n",
            "Epoch: 8, Step: 18/164, Loss: 0.888481, Accuracy: 68.62%\n",
            "Epoch: 8, Step: 19/164, Loss: 0.891731, Accuracy: 68.63%\n",
            "Epoch: 8, Step: 20/164, Loss: 0.898390, Accuracy: 68.59%\n",
            "Epoch: 8, Step: 21/164, Loss: 0.904159, Accuracy: 68.45%\n",
            "Epoch: 8, Step: 22/164, Loss: 0.900929, Accuracy: 68.32%\n",
            "Epoch: 8, Step: 23/164, Loss: 0.900250, Accuracy: 68.48%\n",
            "Epoch: 8, Step: 24/164, Loss: 0.898687, Accuracy: 68.75%\n",
            "Epoch: 8, Step: 25/164, Loss: 0.898819, Accuracy: 68.84%\n",
            "Epoch: 8, Step: 26/164, Loss: 0.898167, Accuracy: 68.78%\n",
            "Epoch: 8, Step: 27/164, Loss: 0.900097, Accuracy: 68.58%\n",
            "Epoch: 8, Step: 28/164, Loss: 0.902762, Accuracy: 68.53%\n",
            "Epoch: 8, Step: 29/164, Loss: 0.908111, Accuracy: 68.35%\n",
            "Epoch: 8, Step: 30/164, Loss: 0.910301, Accuracy: 68.36%\n",
            "Epoch: 8, Step: 31/164, Loss: 0.907436, Accuracy: 68.52%\n",
            "Epoch: 8, Step: 32/164, Loss: 0.908540, Accuracy: 68.48%\n",
            "Epoch: 8, Step: 33/164, Loss: 0.911581, Accuracy: 68.32%\n",
            "Epoch: 8, Step: 34/164, Loss: 0.919636, Accuracy: 68.06%\n",
            "Epoch: 8, Step: 35/164, Loss: 0.916932, Accuracy: 68.21%\n",
            "Epoch: 8, Step: 36/164, Loss: 0.918677, Accuracy: 68.10%\n",
            "Epoch: 8, Step: 37/164, Loss: 0.919441, Accuracy: 68.01%\n",
            "Epoch: 8, Step: 38/164, Loss: 0.917178, Accuracy: 68.11%\n",
            "Epoch: 8, Step: 39/164, Loss: 0.918174, Accuracy: 68.11%\n",
            "Epoch: 8, Step: 40/164, Loss: 0.921056, Accuracy: 67.89%\n",
            "Epoch: 8, Step: 41/164, Loss: 0.921221, Accuracy: 67.85%\n",
            "Epoch: 8, Step: 42/164, Loss: 0.918126, Accuracy: 67.93%\n",
            "Epoch: 8, Step: 43/164, Loss: 0.916225, Accuracy: 67.90%\n",
            "Epoch: 8, Step: 44/164, Loss: 0.917798, Accuracy: 67.86%\n",
            "Epoch: 8, Step: 45/164, Loss: 0.917754, Accuracy: 67.92%\n",
            "Epoch: 8, Step: 46/164, Loss: 0.920537, Accuracy: 67.85%\n",
            "Epoch: 8, Step: 47/164, Loss: 0.920767, Accuracy: 67.95%\n",
            "Epoch: 8, Step: 48/164, Loss: 0.921616, Accuracy: 67.94%\n",
            "Epoch: 8, Step: 49/164, Loss: 0.920902, Accuracy: 67.98%\n",
            "Epoch: 8, Step: 50/164, Loss: 0.919120, Accuracy: 68.02%\n",
            "Epoch: 8, Step: 51/164, Loss: 0.917209, Accuracy: 68.08%\n",
            "Epoch: 8, Step: 52/164, Loss: 0.917291, Accuracy: 68.04%\n",
            "Epoch: 8, Step: 53/164, Loss: 0.914690, Accuracy: 68.19%\n",
            "Epoch: 8, Step: 54/164, Loss: 0.915723, Accuracy: 68.17%\n",
            "Epoch: 8, Step: 55/164, Loss: 0.916513, Accuracy: 68.11%\n",
            "Epoch: 8, Step: 56/164, Loss: 0.917766, Accuracy: 68.07%\n",
            "Epoch: 8, Step: 57/164, Loss: 0.920049, Accuracy: 68.04%\n",
            "Epoch: 8, Step: 58/164, Loss: 0.920032, Accuracy: 68.04%\n",
            "Epoch: 8, Step: 59/164, Loss: 0.918693, Accuracy: 68.10%\n",
            "Epoch: 8, Step: 60/164, Loss: 0.918843, Accuracy: 68.07%\n",
            "Epoch: 8, Step: 61/164, Loss: 0.918388, Accuracy: 68.05%\n",
            "Epoch: 8, Step: 62/164, Loss: 0.921951, Accuracy: 67.94%\n",
            "Epoch: 8, Step: 63/164, Loss: 0.919443, Accuracy: 68.02%\n",
            "Epoch: 8, Step: 64/164, Loss: 0.921333, Accuracy: 67.91%\n",
            "Epoch: 8, Step: 65/164, Loss: 0.922075, Accuracy: 67.93%\n",
            "Epoch: 8, Step: 66/164, Loss: 0.922400, Accuracy: 67.84%\n",
            "Epoch: 8, Step: 67/164, Loss: 0.920497, Accuracy: 67.93%\n",
            "Epoch: 8, Step: 68/164, Loss: 0.921329, Accuracy: 67.89%\n",
            "Epoch: 8, Step: 69/164, Loss: 0.920786, Accuracy: 67.91%\n",
            "Epoch: 8, Step: 70/164, Loss: 0.921986, Accuracy: 67.88%\n",
            "Epoch: 8, Step: 71/164, Loss: 0.921843, Accuracy: 67.94%\n",
            "Epoch: 8, Step: 72/164, Loss: 0.923190, Accuracy: 67.99%\n",
            "Epoch: 8, Step: 73/164, Loss: 0.923204, Accuracy: 68.03%\n",
            "Epoch: 8, Step: 74/164, Loss: 0.923809, Accuracy: 68.01%\n",
            "Epoch: 8, Step: 75/164, Loss: 0.923832, Accuracy: 68.09%\n",
            "Epoch: 8, Step: 76/164, Loss: 0.922819, Accuracy: 68.07%\n",
            "Epoch: 8, Step: 77/164, Loss: 0.920751, Accuracy: 68.14%\n",
            "Epoch: 8, Step: 78/164, Loss: 0.922498, Accuracy: 68.10%\n",
            "Epoch: 8, Step: 79/164, Loss: 0.923346, Accuracy: 68.03%\n",
            "Epoch: 8, Step: 80/164, Loss: 0.921850, Accuracy: 68.12%\n",
            "Epoch: 8, Step: 81/164, Loss: 0.920294, Accuracy: 68.14%\n",
            "Epoch: 8, Step: 82/164, Loss: 0.919614, Accuracy: 68.16%\n",
            "Epoch: 8, Step: 83/164, Loss: 0.919206, Accuracy: 68.16%\n",
            "Epoch: 8, Step: 84/164, Loss: 0.916617, Accuracy: 68.22%\n",
            "Epoch: 8, Step: 85/164, Loss: 0.916000, Accuracy: 68.24%\n",
            "Epoch: 8, Step: 86/164, Loss: 0.917606, Accuracy: 68.20%\n",
            "Epoch: 8, Step: 87/164, Loss: 0.918271, Accuracy: 68.18%\n",
            "Epoch: 8, Step: 88/164, Loss: 0.915869, Accuracy: 68.26%\n",
            "Epoch: 8, Step: 89/164, Loss: 0.914709, Accuracy: 68.25%\n",
            "Epoch: 8, Step: 90/164, Loss: 0.913544, Accuracy: 68.28%\n",
            "Epoch: 8, Step: 91/164, Loss: 0.912507, Accuracy: 68.29%\n",
            "Epoch: 8, Step: 92/164, Loss: 0.911155, Accuracy: 68.34%\n",
            "Epoch: 8, Step: 93/164, Loss: 0.912442, Accuracy: 68.32%\n",
            "Epoch: 8, Step: 94/164, Loss: 0.912645, Accuracy: 68.30%\n",
            "Epoch: 8, Step: 95/164, Loss: 0.913475, Accuracy: 68.26%\n",
            "Epoch: 8, Step: 96/164, Loss: 0.915097, Accuracy: 68.18%\n",
            "Epoch: 8, Step: 97/164, Loss: 0.914540, Accuracy: 68.20%\n",
            "Epoch: 8, Step: 98/164, Loss: 0.914860, Accuracy: 68.22%\n",
            "Epoch: 8, Step: 99/164, Loss: 0.914169, Accuracy: 68.25%\n",
            "Epoch: 8, Step: 100/164, Loss: 0.913491, Accuracy: 68.27%\n",
            "Epoch: 8, Step: 101/164, Loss: 0.912568, Accuracy: 68.30%\n",
            "Epoch: 8, Step: 102/164, Loss: 0.910256, Accuracy: 68.38%\n",
            "Epoch: 8, Step: 103/164, Loss: 0.910264, Accuracy: 68.40%\n",
            "Epoch: 8, Step: 104/164, Loss: 0.910653, Accuracy: 68.38%\n",
            "Epoch: 8, Step: 105/164, Loss: 0.909769, Accuracy: 68.44%\n",
            "Epoch: 8, Step: 106/164, Loss: 0.907774, Accuracy: 68.53%\n",
            "Epoch: 8, Step: 107/164, Loss: 0.906766, Accuracy: 68.57%\n",
            "Epoch: 8, Step: 108/164, Loss: 0.906903, Accuracy: 68.55%\n",
            "Epoch: 8, Step: 109/164, Loss: 0.907794, Accuracy: 68.55%\n",
            "Epoch: 8, Step: 110/164, Loss: 0.906581, Accuracy: 68.58%\n",
            "Epoch: 8, Step: 111/164, Loss: 0.905930, Accuracy: 68.57%\n",
            "Epoch: 8, Step: 112/164, Loss: 0.905856, Accuracy: 68.56%\n",
            "Epoch: 8, Step: 113/164, Loss: 0.904565, Accuracy: 68.58%\n",
            "Epoch: 8, Step: 114/164, Loss: 0.904485, Accuracy: 68.59%\n",
            "Epoch: 8, Step: 115/164, Loss: 0.904387, Accuracy: 68.60%\n",
            "Epoch: 8, Step: 116/164, Loss: 0.903717, Accuracy: 68.60%\n",
            "Epoch: 8, Step: 117/164, Loss: 0.903947, Accuracy: 68.62%\n",
            "Epoch: 8, Step: 118/164, Loss: 0.905522, Accuracy: 68.54%\n",
            "Epoch: 8, Step: 119/164, Loss: 0.904158, Accuracy: 68.59%\n",
            "Epoch: 8, Step: 120/164, Loss: 0.904995, Accuracy: 68.60%\n",
            "Epoch: 8, Step: 121/164, Loss: 0.903558, Accuracy: 68.67%\n",
            "Epoch: 8, Step: 122/164, Loss: 0.904282, Accuracy: 68.67%\n",
            "Epoch: 8, Step: 123/164, Loss: 0.904977, Accuracy: 68.67%\n",
            "Epoch: 8, Step: 124/164, Loss: 0.904067, Accuracy: 68.68%\n",
            "Epoch: 8, Step: 125/164, Loss: 0.902981, Accuracy: 68.72%\n",
            "Epoch: 8, Step: 126/164, Loss: 0.902249, Accuracy: 68.73%\n",
            "Epoch: 8, Step: 127/164, Loss: 0.902038, Accuracy: 68.76%\n",
            "Epoch: 8, Step: 128/164, Loss: 0.901768, Accuracy: 68.77%\n",
            "Epoch: 8, Step: 129/164, Loss: 0.902407, Accuracy: 68.78%\n",
            "Epoch: 8, Step: 130/164, Loss: 0.902050, Accuracy: 68.79%\n",
            "Epoch: 8, Step: 131/164, Loss: 0.902577, Accuracy: 68.77%\n",
            "Epoch: 8, Step: 132/164, Loss: 0.902840, Accuracy: 68.76%\n",
            "Epoch: 8, Step: 133/164, Loss: 0.904549, Accuracy: 68.74%\n",
            "Epoch: 8, Step: 134/164, Loss: 0.904364, Accuracy: 68.76%\n",
            "Epoch: 8, Step: 135/164, Loss: 0.904493, Accuracy: 68.74%\n",
            "Epoch: 8, Step: 136/164, Loss: 0.903612, Accuracy: 68.75%\n",
            "Epoch: 8, Step: 137/164, Loss: 0.904492, Accuracy: 68.74%\n",
            "Epoch: 8, Step: 138/164, Loss: 0.906089, Accuracy: 68.73%\n",
            "Epoch: 8, Step: 139/164, Loss: 0.904887, Accuracy: 68.77%\n",
            "Epoch: 8, Step: 140/164, Loss: 0.904301, Accuracy: 68.81%\n",
            "Epoch: 8, Step: 141/164, Loss: 0.904829, Accuracy: 68.81%\n",
            "Epoch: 8, Step: 142/164, Loss: 0.905204, Accuracy: 68.78%\n",
            "Epoch: 8, Step: 143/164, Loss: 0.904528, Accuracy: 68.81%\n",
            "Epoch: 8, Step: 144/164, Loss: 0.905078, Accuracy: 68.82%\n",
            "Epoch: 8, Step: 145/164, Loss: 0.904656, Accuracy: 68.87%\n",
            "Epoch: 8, Step: 146/164, Loss: 0.903960, Accuracy: 68.87%\n",
            "Epoch: 8, Step: 147/164, Loss: 0.904546, Accuracy: 68.88%\n",
            "Epoch: 8, Step: 148/164, Loss: 0.904258, Accuracy: 68.88%\n",
            "Epoch: 8, Step: 149/164, Loss: 0.903681, Accuracy: 68.88%\n",
            "Epoch: 8, Step: 150/164, Loss: 0.905260, Accuracy: 68.78%\n",
            "Epoch: 8, Step: 151/164, Loss: 0.904389, Accuracy: 68.82%\n",
            "Epoch: 8, Step: 152/164, Loss: 0.904531, Accuracy: 68.81%\n",
            "Epoch: 8, Step: 153/164, Loss: 0.903839, Accuracy: 68.83%\n",
            "Epoch: 8, Step: 154/164, Loss: 0.903264, Accuracy: 68.82%\n",
            "Epoch: 8, Step: 155/164, Loss: 0.902770, Accuracy: 68.83%\n",
            "Epoch: 8, Step: 156/164, Loss: 0.901141, Accuracy: 68.90%\n",
            "Epoch: 8, Step: 157/164, Loss: 0.900592, Accuracy: 68.92%\n",
            "Epoch: 8, Step: 158/164, Loss: 0.901721, Accuracy: 68.88%\n",
            "Epoch: 8, Step: 159/164, Loss: 0.901593, Accuracy: 68.86%\n",
            "Epoch: 8, Step: 160/164, Loss: 0.902875, Accuracy: 68.82%\n",
            "Epoch: 8, Step: 161/164, Loss: 0.903065, Accuracy: 68.81%\n",
            "Epoch: 8, Step: 162/164, Loss: 0.902322, Accuracy: 68.82%\n",
            "Epoch: 8, Step: 163/164, Loss: 0.901819, Accuracy: 68.86%\n",
            "Epoch: 8, Step: 164/164, Loss: 0.901346, Accuracy: 68.87%\n",
            "Epoch: 9, Step: 1/164, Loss: 0.901156, Accuracy: 72.66%\n",
            "Epoch: 9, Step: 2/164, Loss: 1.023491, Accuracy: 68.75%\n",
            "Epoch: 9, Step: 3/164, Loss: 0.942947, Accuracy: 71.61%\n",
            "Epoch: 9, Step: 4/164, Loss: 0.907658, Accuracy: 71.68%\n",
            "Epoch: 9, Step: 5/164, Loss: 0.890396, Accuracy: 71.56%\n",
            "Epoch: 9, Step: 6/164, Loss: 0.867743, Accuracy: 71.74%\n",
            "Epoch: 9, Step: 7/164, Loss: 0.877636, Accuracy: 71.09%\n",
            "Epoch: 9, Step: 8/164, Loss: 0.873483, Accuracy: 71.00%\n",
            "Epoch: 9, Step: 9/164, Loss: 0.868574, Accuracy: 70.92%\n",
            "Epoch: 9, Step: 10/164, Loss: 0.855280, Accuracy: 70.86%\n",
            "Epoch: 9, Step: 11/164, Loss: 0.849425, Accuracy: 70.88%\n",
            "Epoch: 9, Step: 12/164, Loss: 0.845521, Accuracy: 70.83%\n",
            "Epoch: 9, Step: 13/164, Loss: 0.849180, Accuracy: 70.61%\n",
            "Epoch: 9, Step: 14/164, Loss: 0.858683, Accuracy: 70.26%\n",
            "Epoch: 9, Step: 15/164, Loss: 0.874417, Accuracy: 69.43%\n",
            "Epoch: 9, Step: 16/164, Loss: 0.869677, Accuracy: 69.53%\n",
            "Epoch: 9, Step: 17/164, Loss: 0.866402, Accuracy: 69.39%\n",
            "Epoch: 9, Step: 18/164, Loss: 0.865245, Accuracy: 69.44%\n",
            "Epoch: 9, Step: 19/164, Loss: 0.864371, Accuracy: 69.45%\n",
            "Epoch: 9, Step: 20/164, Loss: 0.866976, Accuracy: 69.57%\n",
            "Epoch: 9, Step: 21/164, Loss: 0.868422, Accuracy: 69.42%\n",
            "Epoch: 9, Step: 22/164, Loss: 0.864609, Accuracy: 69.60%\n",
            "Epoch: 9, Step: 23/164, Loss: 0.866661, Accuracy: 69.60%\n",
            "Epoch: 9, Step: 24/164, Loss: 0.864252, Accuracy: 69.69%\n",
            "Epoch: 9, Step: 25/164, Loss: 0.859279, Accuracy: 69.88%\n",
            "Epoch: 9, Step: 26/164, Loss: 0.857966, Accuracy: 69.86%\n",
            "Epoch: 9, Step: 27/164, Loss: 0.864641, Accuracy: 69.50%\n",
            "Epoch: 9, Step: 28/164, Loss: 0.863578, Accuracy: 69.53%\n",
            "Epoch: 9, Step: 29/164, Loss: 0.865873, Accuracy: 69.53%\n",
            "Epoch: 9, Step: 30/164, Loss: 0.875441, Accuracy: 69.19%\n",
            "Epoch: 9, Step: 31/164, Loss: 0.875890, Accuracy: 69.15%\n",
            "Epoch: 9, Step: 32/164, Loss: 0.874370, Accuracy: 69.21%\n",
            "Epoch: 9, Step: 33/164, Loss: 0.873248, Accuracy: 69.27%\n",
            "Epoch: 9, Step: 34/164, Loss: 0.871873, Accuracy: 69.42%\n",
            "Epoch: 9, Step: 35/164, Loss: 0.872608, Accuracy: 69.38%\n",
            "Epoch: 9, Step: 36/164, Loss: 0.873618, Accuracy: 69.29%\n",
            "Epoch: 9, Step: 37/164, Loss: 0.875096, Accuracy: 69.32%\n",
            "Epoch: 9, Step: 38/164, Loss: 0.880003, Accuracy: 69.24%\n",
            "Epoch: 9, Step: 39/164, Loss: 0.875593, Accuracy: 69.45%\n",
            "Epoch: 9, Step: 40/164, Loss: 0.876175, Accuracy: 69.45%\n",
            "Epoch: 9, Step: 41/164, Loss: 0.876818, Accuracy: 69.51%\n",
            "Epoch: 9, Step: 42/164, Loss: 0.877380, Accuracy: 69.53%\n",
            "Epoch: 9, Step: 43/164, Loss: 0.875973, Accuracy: 69.66%\n",
            "Epoch: 9, Step: 44/164, Loss: 0.876166, Accuracy: 69.64%\n",
            "Epoch: 9, Step: 45/164, Loss: 0.876497, Accuracy: 69.58%\n",
            "Epoch: 9, Step: 46/164, Loss: 0.875508, Accuracy: 69.65%\n",
            "Epoch: 9, Step: 47/164, Loss: 0.874468, Accuracy: 69.65%\n",
            "Epoch: 9, Step: 48/164, Loss: 0.871421, Accuracy: 69.78%\n",
            "Epoch: 9, Step: 49/164, Loss: 0.870097, Accuracy: 69.80%\n",
            "Epoch: 9, Step: 50/164, Loss: 0.871888, Accuracy: 69.78%\n",
            "Epoch: 9, Step: 51/164, Loss: 0.872448, Accuracy: 69.81%\n",
            "Epoch: 9, Step: 52/164, Loss: 0.871922, Accuracy: 69.73%\n",
            "Epoch: 9, Step: 53/164, Loss: 0.874480, Accuracy: 69.60%\n",
            "Epoch: 9, Step: 54/164, Loss: 0.873581, Accuracy: 69.63%\n",
            "Epoch: 9, Step: 55/164, Loss: 0.872538, Accuracy: 69.67%\n",
            "Epoch: 9, Step: 56/164, Loss: 0.868214, Accuracy: 69.82%\n",
            "Epoch: 9, Step: 57/164, Loss: 0.869605, Accuracy: 69.78%\n",
            "Epoch: 9, Step: 58/164, Loss: 0.870905, Accuracy: 69.73%\n",
            "Epoch: 9, Step: 59/164, Loss: 0.869216, Accuracy: 69.76%\n",
            "Epoch: 9, Step: 60/164, Loss: 0.869760, Accuracy: 69.70%\n",
            "Epoch: 9, Step: 61/164, Loss: 0.870522, Accuracy: 69.65%\n",
            "Epoch: 9, Step: 62/164, Loss: 0.870222, Accuracy: 69.70%\n",
            "Epoch: 9, Step: 63/164, Loss: 0.869019, Accuracy: 69.75%\n",
            "Epoch: 9, Step: 64/164, Loss: 0.868787, Accuracy: 69.74%\n",
            "Epoch: 9, Step: 65/164, Loss: 0.866900, Accuracy: 69.84%\n",
            "Epoch: 9, Step: 66/164, Loss: 0.867484, Accuracy: 69.79%\n",
            "Epoch: 9, Step: 67/164, Loss: 0.866030, Accuracy: 69.88%\n",
            "Epoch: 9, Step: 68/164, Loss: 0.864386, Accuracy: 69.96%\n",
            "Epoch: 9, Step: 69/164, Loss: 0.866305, Accuracy: 69.89%\n",
            "Epoch: 9, Step: 70/164, Loss: 0.866244, Accuracy: 69.92%\n",
            "Epoch: 9, Step: 71/164, Loss: 0.865418, Accuracy: 69.93%\n",
            "Epoch: 9, Step: 72/164, Loss: 0.863186, Accuracy: 70.05%\n",
            "Epoch: 9, Step: 73/164, Loss: 0.862182, Accuracy: 70.06%\n",
            "Epoch: 9, Step: 74/164, Loss: 0.863909, Accuracy: 69.97%\n",
            "Epoch: 9, Step: 75/164, Loss: 0.865509, Accuracy: 70.00%\n",
            "Epoch: 9, Step: 76/164, Loss: 0.865774, Accuracy: 69.98%\n",
            "Epoch: 9, Step: 77/164, Loss: 0.864843, Accuracy: 70.05%\n",
            "Epoch: 9, Step: 78/164, Loss: 0.864602, Accuracy: 70.04%\n",
            "Epoch: 9, Step: 79/164, Loss: 0.863371, Accuracy: 70.12%\n",
            "Epoch: 9, Step: 80/164, Loss: 0.863673, Accuracy: 70.14%\n",
            "Epoch: 9, Step: 81/164, Loss: 0.862673, Accuracy: 70.17%\n",
            "Epoch: 9, Step: 82/164, Loss: 0.862123, Accuracy: 70.20%\n",
            "Epoch: 9, Step: 83/164, Loss: 0.861476, Accuracy: 70.20%\n",
            "Epoch: 9, Step: 84/164, Loss: 0.859317, Accuracy: 70.28%\n",
            "Epoch: 9, Step: 85/164, Loss: 0.859300, Accuracy: 70.29%\n",
            "Epoch: 9, Step: 86/164, Loss: 0.858610, Accuracy: 70.30%\n",
            "Epoch: 9, Step: 87/164, Loss: 0.858736, Accuracy: 70.36%\n",
            "Epoch: 9, Step: 88/164, Loss: 0.859166, Accuracy: 70.36%\n",
            "Epoch: 9, Step: 89/164, Loss: 0.858315, Accuracy: 70.38%\n",
            "Epoch: 9, Step: 90/164, Loss: 0.858332, Accuracy: 70.38%\n",
            "Epoch: 9, Step: 91/164, Loss: 0.858125, Accuracy: 70.41%\n",
            "Epoch: 9, Step: 92/164, Loss: 0.858831, Accuracy: 70.40%\n",
            "Epoch: 9, Step: 93/164, Loss: 0.858741, Accuracy: 70.39%\n",
            "Epoch: 9, Step: 94/164, Loss: 0.858964, Accuracy: 70.38%\n",
            "Epoch: 9, Step: 95/164, Loss: 0.860694, Accuracy: 70.30%\n",
            "Epoch: 9, Step: 96/164, Loss: 0.860482, Accuracy: 70.32%\n",
            "Epoch: 9, Step: 97/164, Loss: 0.859666, Accuracy: 70.36%\n",
            "Epoch: 9, Step: 98/164, Loss: 0.859678, Accuracy: 70.35%\n",
            "Epoch: 9, Step: 99/164, Loss: 0.859142, Accuracy: 70.36%\n",
            "Epoch: 9, Step: 100/164, Loss: 0.861401, Accuracy: 70.29%\n",
            "Epoch: 9, Step: 101/164, Loss: 0.861484, Accuracy: 70.26%\n",
            "Epoch: 9, Step: 102/164, Loss: 0.861738, Accuracy: 70.25%\n",
            "Epoch: 9, Step: 103/164, Loss: 0.861960, Accuracy: 70.26%\n",
            "Epoch: 9, Step: 104/164, Loss: 0.863430, Accuracy: 70.20%\n",
            "Epoch: 9, Step: 105/164, Loss: 0.864198, Accuracy: 70.19%\n",
            "Epoch: 9, Step: 106/164, Loss: 0.864091, Accuracy: 70.22%\n",
            "Epoch: 9, Step: 107/164, Loss: 0.863178, Accuracy: 70.25%\n",
            "Epoch: 9, Step: 108/164, Loss: 0.862175, Accuracy: 70.27%\n",
            "Epoch: 9, Step: 109/164, Loss: 0.860306, Accuracy: 70.35%\n",
            "Epoch: 9, Step: 110/164, Loss: 0.862438, Accuracy: 70.27%\n",
            "Epoch: 9, Step: 111/164, Loss: 0.861436, Accuracy: 70.33%\n",
            "Epoch: 9, Step: 112/164, Loss: 0.861348, Accuracy: 70.33%\n",
            "Epoch: 9, Step: 113/164, Loss: 0.860628, Accuracy: 70.36%\n",
            "Epoch: 9, Step: 114/164, Loss: 0.861654, Accuracy: 70.33%\n",
            "Epoch: 9, Step: 115/164, Loss: 0.859522, Accuracy: 70.43%\n",
            "Epoch: 9, Step: 116/164, Loss: 0.859580, Accuracy: 70.43%\n",
            "Epoch: 9, Step: 117/164, Loss: 0.859309, Accuracy: 70.47%\n",
            "Epoch: 9, Step: 118/164, Loss: 0.859946, Accuracy: 70.46%\n",
            "Epoch: 9, Step: 119/164, Loss: 0.860468, Accuracy: 70.44%\n",
            "Epoch: 9, Step: 120/164, Loss: 0.861298, Accuracy: 70.38%\n",
            "Epoch: 9, Step: 121/164, Loss: 0.859981, Accuracy: 70.42%\n",
            "Epoch: 9, Step: 122/164, Loss: 0.859040, Accuracy: 70.46%\n",
            "Epoch: 9, Step: 123/164, Loss: 0.857831, Accuracy: 70.50%\n",
            "Epoch: 9, Step: 124/164, Loss: 0.858204, Accuracy: 70.48%\n",
            "Epoch: 9, Step: 125/164, Loss: 0.858007, Accuracy: 70.48%\n",
            "Epoch: 9, Step: 126/164, Loss: 0.858784, Accuracy: 70.46%\n",
            "Epoch: 9, Step: 127/164, Loss: 0.857356, Accuracy: 70.50%\n",
            "Epoch: 9, Step: 128/164, Loss: 0.859004, Accuracy: 70.44%\n",
            "Epoch: 9, Step: 129/164, Loss: 0.859799, Accuracy: 70.45%\n",
            "Epoch: 9, Step: 130/164, Loss: 0.858956, Accuracy: 70.45%\n",
            "Epoch: 9, Step: 131/164, Loss: 0.858954, Accuracy: 70.47%\n",
            "Epoch: 9, Step: 132/164, Loss: 0.857967, Accuracy: 70.53%\n",
            "Epoch: 9, Step: 133/164, Loss: 0.859656, Accuracy: 70.51%\n",
            "Epoch: 9, Step: 134/164, Loss: 0.860359, Accuracy: 70.50%\n",
            "Epoch: 9, Step: 135/164, Loss: 0.861226, Accuracy: 70.50%\n",
            "Epoch: 9, Step: 136/164, Loss: 0.861408, Accuracy: 70.52%\n",
            "Epoch: 9, Step: 137/164, Loss: 0.862249, Accuracy: 70.51%\n",
            "Epoch: 9, Step: 138/164, Loss: 0.861254, Accuracy: 70.56%\n",
            "Epoch: 9, Step: 139/164, Loss: 0.860604, Accuracy: 70.55%\n",
            "Epoch: 9, Step: 140/164, Loss: 0.860089, Accuracy: 70.60%\n",
            "Epoch: 9, Step: 141/164, Loss: 0.859364, Accuracy: 70.61%\n",
            "Epoch: 9, Step: 142/164, Loss: 0.859155, Accuracy: 70.61%\n",
            "Epoch: 9, Step: 143/164, Loss: 0.859247, Accuracy: 70.61%\n",
            "Epoch: 9, Step: 144/164, Loss: 0.858692, Accuracy: 70.60%\n",
            "Epoch: 9, Step: 145/164, Loss: 0.858960, Accuracy: 70.62%\n",
            "Epoch: 9, Step: 146/164, Loss: 0.858845, Accuracy: 70.61%\n",
            "Epoch: 9, Step: 147/164, Loss: 0.858925, Accuracy: 70.62%\n",
            "Epoch: 9, Step: 148/164, Loss: 0.858610, Accuracy: 70.62%\n",
            "Epoch: 9, Step: 149/164, Loss: 0.859341, Accuracy: 70.59%\n",
            "Epoch: 9, Step: 150/164, Loss: 0.860562, Accuracy: 70.56%\n",
            "Epoch: 9, Step: 151/164, Loss: 0.859411, Accuracy: 70.60%\n",
            "Epoch: 9, Step: 152/164, Loss: 0.859597, Accuracy: 70.60%\n",
            "Epoch: 9, Step: 153/164, Loss: 0.859036, Accuracy: 70.63%\n",
            "Epoch: 9, Step: 154/164, Loss: 0.858828, Accuracy: 70.64%\n",
            "Epoch: 9, Step: 155/164, Loss: 0.858879, Accuracy: 70.66%\n",
            "Epoch: 9, Step: 156/164, Loss: 0.858754, Accuracy: 70.68%\n",
            "Epoch: 9, Step: 157/164, Loss: 0.858098, Accuracy: 70.68%\n",
            "Epoch: 9, Step: 158/164, Loss: 0.857284, Accuracy: 70.69%\n",
            "Epoch: 9, Step: 159/164, Loss: 0.857247, Accuracy: 70.70%\n",
            "Epoch: 9, Step: 160/164, Loss: 0.857315, Accuracy: 70.69%\n",
            "Epoch: 9, Step: 161/164, Loss: 0.857671, Accuracy: 70.69%\n",
            "Epoch: 9, Step: 162/164, Loss: 0.858554, Accuracy: 70.62%\n",
            "Epoch: 9, Step: 163/164, Loss: 0.858537, Accuracy: 70.61%\n",
            "Epoch: 9, Step: 164/164, Loss: 0.859592, Accuracy: 70.59%\n",
            "Epoch: 10, Step: 1/164, Loss: 0.809011, Accuracy: 73.44%\n",
            "Epoch: 10, Step: 2/164, Loss: 0.789397, Accuracy: 74.22%\n",
            "Epoch: 10, Step: 3/164, Loss: 0.819961, Accuracy: 70.83%\n",
            "Epoch: 10, Step: 4/164, Loss: 0.808797, Accuracy: 71.48%\n",
            "Epoch: 10, Step: 5/164, Loss: 0.788035, Accuracy: 72.19%\n",
            "Epoch: 10, Step: 6/164, Loss: 0.782361, Accuracy: 72.66%\n",
            "Epoch: 10, Step: 7/164, Loss: 0.782083, Accuracy: 72.43%\n",
            "Epoch: 10, Step: 8/164, Loss: 0.795527, Accuracy: 72.36%\n",
            "Epoch: 10, Step: 9/164, Loss: 0.825588, Accuracy: 71.70%\n",
            "Epoch: 10, Step: 10/164, Loss: 0.831320, Accuracy: 71.33%\n",
            "Epoch: 10, Step: 11/164, Loss: 0.826762, Accuracy: 71.88%\n",
            "Epoch: 10, Step: 12/164, Loss: 0.825091, Accuracy: 71.81%\n",
            "Epoch: 10, Step: 13/164, Loss: 0.825378, Accuracy: 71.88%\n",
            "Epoch: 10, Step: 14/164, Loss: 0.819502, Accuracy: 72.27%\n",
            "Epoch: 10, Step: 15/164, Loss: 0.824847, Accuracy: 72.29%\n",
            "Epoch: 10, Step: 16/164, Loss: 0.837907, Accuracy: 72.12%\n",
            "Epoch: 10, Step: 17/164, Loss: 0.845157, Accuracy: 71.88%\n",
            "Epoch: 10, Step: 18/164, Loss: 0.844254, Accuracy: 71.74%\n",
            "Epoch: 10, Step: 19/164, Loss: 0.851563, Accuracy: 71.42%\n",
            "Epoch: 10, Step: 20/164, Loss: 0.849477, Accuracy: 71.25%\n",
            "Epoch: 10, Step: 21/164, Loss: 0.844043, Accuracy: 71.32%\n",
            "Epoch: 10, Step: 22/164, Loss: 0.836378, Accuracy: 71.56%\n",
            "Epoch: 10, Step: 23/164, Loss: 0.838054, Accuracy: 71.50%\n",
            "Epoch: 10, Step: 24/164, Loss: 0.842657, Accuracy: 71.29%\n",
            "Epoch: 10, Step: 25/164, Loss: 0.842408, Accuracy: 71.38%\n",
            "Epoch: 10, Step: 26/164, Loss: 0.847225, Accuracy: 71.09%\n",
            "Epoch: 10, Step: 27/164, Loss: 0.840605, Accuracy: 71.50%\n",
            "Epoch: 10, Step: 28/164, Loss: 0.842348, Accuracy: 71.34%\n",
            "Epoch: 10, Step: 29/164, Loss: 0.842502, Accuracy: 71.17%\n",
            "Epoch: 10, Step: 30/164, Loss: 0.841788, Accuracy: 71.04%\n",
            "Epoch: 10, Step: 31/164, Loss: 0.841407, Accuracy: 71.17%\n",
            "Epoch: 10, Step: 32/164, Loss: 0.837308, Accuracy: 71.17%\n",
            "Epoch: 10, Step: 33/164, Loss: 0.837680, Accuracy: 71.16%\n",
            "Epoch: 10, Step: 34/164, Loss: 0.840556, Accuracy: 71.00%\n",
            "Epoch: 10, Step: 35/164, Loss: 0.834571, Accuracy: 71.07%\n",
            "Epoch: 10, Step: 36/164, Loss: 0.835086, Accuracy: 71.09%\n",
            "Epoch: 10, Step: 37/164, Loss: 0.837211, Accuracy: 71.09%\n",
            "Epoch: 10, Step: 38/164, Loss: 0.832011, Accuracy: 71.28%\n",
            "Epoch: 10, Step: 39/164, Loss: 0.833168, Accuracy: 71.29%\n",
            "Epoch: 10, Step: 40/164, Loss: 0.834373, Accuracy: 71.29%\n",
            "Epoch: 10, Step: 41/164, Loss: 0.834210, Accuracy: 71.38%\n",
            "Epoch: 10, Step: 42/164, Loss: 0.833303, Accuracy: 71.43%\n",
            "Epoch: 10, Step: 43/164, Loss: 0.831353, Accuracy: 71.49%\n",
            "Epoch: 10, Step: 44/164, Loss: 0.831341, Accuracy: 71.41%\n",
            "Epoch: 10, Step: 45/164, Loss: 0.830906, Accuracy: 71.53%\n",
            "Epoch: 10, Step: 46/164, Loss: 0.830908, Accuracy: 71.45%\n",
            "Epoch: 10, Step: 47/164, Loss: 0.832910, Accuracy: 71.38%\n",
            "Epoch: 10, Step: 48/164, Loss: 0.832882, Accuracy: 71.40%\n",
            "Epoch: 10, Step: 49/164, Loss: 0.832347, Accuracy: 71.38%\n",
            "Epoch: 10, Step: 50/164, Loss: 0.835559, Accuracy: 71.28%\n",
            "Epoch: 10, Step: 51/164, Loss: 0.835997, Accuracy: 71.25%\n",
            "Epoch: 10, Step: 52/164, Loss: 0.836970, Accuracy: 71.23%\n",
            "Epoch: 10, Step: 53/164, Loss: 0.836504, Accuracy: 71.21%\n",
            "Epoch: 10, Step: 54/164, Loss: 0.836932, Accuracy: 71.20%\n",
            "Epoch: 10, Step: 55/164, Loss: 0.835154, Accuracy: 71.34%\n",
            "Epoch: 10, Step: 56/164, Loss: 0.834708, Accuracy: 71.34%\n",
            "Epoch: 10, Step: 57/164, Loss: 0.836558, Accuracy: 71.22%\n",
            "Epoch: 10, Step: 58/164, Loss: 0.834600, Accuracy: 71.24%\n",
            "Epoch: 10, Step: 59/164, Loss: 0.834755, Accuracy: 71.27%\n",
            "Epoch: 10, Step: 60/164, Loss: 0.834978, Accuracy: 71.29%\n",
            "Epoch: 10, Step: 61/164, Loss: 0.832602, Accuracy: 71.39%\n",
            "Epoch: 10, Step: 62/164, Loss: 0.830827, Accuracy: 71.45%\n",
            "Epoch: 10, Step: 63/164, Loss: 0.832438, Accuracy: 71.48%\n",
            "Epoch: 10, Step: 64/164, Loss: 0.831685, Accuracy: 71.50%\n",
            "Epoch: 10, Step: 65/164, Loss: 0.830581, Accuracy: 71.56%\n",
            "Epoch: 10, Step: 66/164, Loss: 0.833282, Accuracy: 71.47%\n",
            "Epoch: 10, Step: 67/164, Loss: 0.831909, Accuracy: 71.54%\n",
            "Epoch: 10, Step: 68/164, Loss: 0.830950, Accuracy: 71.62%\n",
            "Epoch: 10, Step: 69/164, Loss: 0.832315, Accuracy: 71.65%\n",
            "Epoch: 10, Step: 70/164, Loss: 0.831957, Accuracy: 71.69%\n",
            "Epoch: 10, Step: 71/164, Loss: 0.834370, Accuracy: 71.61%\n",
            "Epoch: 10, Step: 72/164, Loss: 0.836694, Accuracy: 71.60%\n",
            "Epoch: 10, Step: 73/164, Loss: 0.839911, Accuracy: 71.51%\n",
            "Epoch: 10, Step: 74/164, Loss: 0.838753, Accuracy: 71.55%\n",
            "Epoch: 10, Step: 75/164, Loss: 0.835960, Accuracy: 71.65%\n",
            "Epoch: 10, Step: 76/164, Loss: 0.836569, Accuracy: 71.66%\n",
            "Epoch: 10, Step: 77/164, Loss: 0.836677, Accuracy: 71.62%\n",
            "Epoch: 10, Step: 78/164, Loss: 0.835398, Accuracy: 71.62%\n",
            "Epoch: 10, Step: 79/164, Loss: 0.834629, Accuracy: 71.62%\n",
            "Epoch: 10, Step: 80/164, Loss: 0.835420, Accuracy: 71.52%\n",
            "Epoch: 10, Step: 81/164, Loss: 0.834828, Accuracy: 71.55%\n",
            "Epoch: 10, Step: 82/164, Loss: 0.836174, Accuracy: 71.50%\n",
            "Epoch: 10, Step: 83/164, Loss: 0.834252, Accuracy: 71.54%\n",
            "Epoch: 10, Step: 84/164, Loss: 0.833539, Accuracy: 71.59%\n",
            "Epoch: 10, Step: 85/164, Loss: 0.833794, Accuracy: 71.62%\n",
            "Epoch: 10, Step: 86/164, Loss: 0.831756, Accuracy: 71.74%\n",
            "Epoch: 10, Step: 87/164, Loss: 0.832276, Accuracy: 71.69%\n",
            "Epoch: 10, Step: 88/164, Loss: 0.833237, Accuracy: 71.63%\n",
            "Epoch: 10, Step: 89/164, Loss: 0.831211, Accuracy: 71.73%\n",
            "Epoch: 10, Step: 90/164, Loss: 0.830276, Accuracy: 71.75%\n",
            "Epoch: 10, Step: 91/164, Loss: 0.827525, Accuracy: 71.87%\n",
            "Epoch: 10, Step: 92/164, Loss: 0.828445, Accuracy: 71.90%\n",
            "Epoch: 10, Step: 93/164, Loss: 0.827987, Accuracy: 71.95%\n",
            "Epoch: 10, Step: 94/164, Loss: 0.826795, Accuracy: 72.02%\n",
            "Epoch: 10, Step: 95/164, Loss: 0.826591, Accuracy: 72.01%\n",
            "Epoch: 10, Step: 96/164, Loss: 0.826074, Accuracy: 72.03%\n",
            "Epoch: 10, Step: 97/164, Loss: 0.826963, Accuracy: 71.96%\n",
            "Epoch: 10, Step: 98/164, Loss: 0.826229, Accuracy: 71.95%\n",
            "Epoch: 10, Step: 99/164, Loss: 0.824365, Accuracy: 72.01%\n",
            "Epoch: 10, Step: 100/164, Loss: 0.824106, Accuracy: 72.01%\n",
            "Epoch: 10, Step: 101/164, Loss: 0.827337, Accuracy: 71.89%\n",
            "Epoch: 10, Step: 102/164, Loss: 0.827678, Accuracy: 71.86%\n",
            "Epoch: 10, Step: 103/164, Loss: 0.827476, Accuracy: 71.86%\n",
            "Epoch: 10, Step: 104/164, Loss: 0.827363, Accuracy: 71.87%\n",
            "Epoch: 10, Step: 105/164, Loss: 0.828867, Accuracy: 71.85%\n",
            "Epoch: 10, Step: 106/164, Loss: 0.829965, Accuracy: 71.80%\n",
            "Epoch: 10, Step: 107/164, Loss: 0.830215, Accuracy: 71.79%\n",
            "Epoch: 10, Step: 108/164, Loss: 0.830432, Accuracy: 71.77%\n",
            "Epoch: 10, Step: 109/164, Loss: 0.832687, Accuracy: 71.68%\n",
            "Epoch: 10, Step: 110/164, Loss: 0.832399, Accuracy: 71.68%\n",
            "Epoch: 10, Step: 111/164, Loss: 0.832715, Accuracy: 71.71%\n",
            "Epoch: 10, Step: 112/164, Loss: 0.831652, Accuracy: 71.74%\n",
            "Epoch: 10, Step: 113/164, Loss: 0.831097, Accuracy: 71.76%\n",
            "Epoch: 10, Step: 114/164, Loss: 0.832326, Accuracy: 71.73%\n",
            "Epoch: 10, Step: 115/164, Loss: 0.832396, Accuracy: 71.73%\n",
            "Epoch: 10, Step: 116/164, Loss: 0.831746, Accuracy: 71.75%\n",
            "Epoch: 10, Step: 117/164, Loss: 0.831957, Accuracy: 71.75%\n",
            "Epoch: 10, Step: 118/164, Loss: 0.832682, Accuracy: 71.73%\n",
            "Epoch: 10, Step: 119/164, Loss: 0.832210, Accuracy: 71.75%\n",
            "Epoch: 10, Step: 120/164, Loss: 0.832059, Accuracy: 71.73%\n",
            "Epoch: 10, Step: 121/164, Loss: 0.831418, Accuracy: 71.78%\n",
            "Epoch: 10, Step: 122/164, Loss: 0.832684, Accuracy: 71.77%\n",
            "Epoch: 10, Step: 123/164, Loss: 0.832133, Accuracy: 71.77%\n",
            "Epoch: 10, Step: 124/164, Loss: 0.831378, Accuracy: 71.80%\n",
            "Epoch: 10, Step: 125/164, Loss: 0.831887, Accuracy: 71.82%\n",
            "Epoch: 10, Step: 126/164, Loss: 0.831196, Accuracy: 71.81%\n",
            "Epoch: 10, Step: 127/164, Loss: 0.831656, Accuracy: 71.80%\n",
            "Epoch: 10, Step: 128/164, Loss: 0.832478, Accuracy: 71.83%\n",
            "Epoch: 10, Step: 129/164, Loss: 0.831933, Accuracy: 71.86%\n",
            "Epoch: 10, Step: 130/164, Loss: 0.831795, Accuracy: 71.88%\n",
            "Epoch: 10, Step: 131/164, Loss: 0.829933, Accuracy: 71.95%\n",
            "Epoch: 10, Step: 132/164, Loss: 0.830149, Accuracy: 71.96%\n",
            "Epoch: 10, Step: 133/164, Loss: 0.830139, Accuracy: 71.93%\n",
            "Epoch: 10, Step: 134/164, Loss: 0.832298, Accuracy: 71.88%\n",
            "Epoch: 10, Step: 135/164, Loss: 0.831673, Accuracy: 71.89%\n",
            "Epoch: 10, Step: 136/164, Loss: 0.832972, Accuracy: 71.88%\n",
            "Epoch: 10, Step: 137/164, Loss: 0.833196, Accuracy: 71.85%\n",
            "Epoch: 10, Step: 138/164, Loss: 0.834036, Accuracy: 71.84%\n",
            "Epoch: 10, Step: 139/164, Loss: 0.835731, Accuracy: 71.72%\n",
            "Epoch: 10, Step: 140/164, Loss: 0.835198, Accuracy: 71.74%\n",
            "Epoch: 10, Step: 141/164, Loss: 0.836171, Accuracy: 71.71%\n",
            "Epoch: 10, Step: 142/164, Loss: 0.836466, Accuracy: 71.71%\n",
            "Epoch: 10, Step: 143/164, Loss: 0.836328, Accuracy: 71.71%\n",
            "Epoch: 10, Step: 144/164, Loss: 0.836755, Accuracy: 71.69%\n",
            "Epoch: 10, Step: 145/164, Loss: 0.836903, Accuracy: 71.68%\n",
            "Epoch: 10, Step: 146/164, Loss: 0.836165, Accuracy: 71.73%\n",
            "Epoch: 10, Step: 147/164, Loss: 0.835726, Accuracy: 71.77%\n",
            "Epoch: 10, Step: 148/164, Loss: 0.835369, Accuracy: 71.79%\n",
            "Epoch: 10, Step: 149/164, Loss: 0.837018, Accuracy: 71.73%\n",
            "Epoch: 10, Step: 150/164, Loss: 0.836883, Accuracy: 71.72%\n",
            "Epoch: 10, Step: 151/164, Loss: 0.837921, Accuracy: 71.68%\n",
            "Epoch: 10, Step: 152/164, Loss: 0.838841, Accuracy: 71.62%\n",
            "Epoch: 10, Step: 153/164, Loss: 0.838557, Accuracy: 71.63%\n",
            "Epoch: 10, Step: 154/164, Loss: 0.839553, Accuracy: 71.59%\n",
            "Epoch: 10, Step: 155/164, Loss: 0.840127, Accuracy: 71.56%\n",
            "Epoch: 10, Step: 156/164, Loss: 0.840078, Accuracy: 71.57%\n",
            "Epoch: 10, Step: 157/164, Loss: 0.839810, Accuracy: 71.56%\n",
            "Epoch: 10, Step: 158/164, Loss: 0.839138, Accuracy: 71.58%\n",
            "Epoch: 10, Step: 159/164, Loss: 0.839276, Accuracy: 71.57%\n",
            "Epoch: 10, Step: 160/164, Loss: 0.839217, Accuracy: 71.59%\n",
            "Epoch: 10, Step: 161/164, Loss: 0.840071, Accuracy: 71.59%\n",
            "Epoch: 10, Step: 162/164, Loss: 0.839709, Accuracy: 71.62%\n",
            "Epoch: 10, Step: 163/164, Loss: 0.838845, Accuracy: 71.64%\n",
            "Epoch: 10, Step: 164/164, Loss: 0.838090, Accuracy: 71.66%\n",
            "Epoch: 11, Step: 1/164, Loss: 0.889426, Accuracy: 65.62%\n",
            "Epoch: 11, Step: 2/164, Loss: 0.710751, Accuracy: 74.61%\n",
            "Epoch: 11, Step: 3/164, Loss: 0.812882, Accuracy: 70.83%\n",
            "Epoch: 11, Step: 4/164, Loss: 0.774205, Accuracy: 72.27%\n",
            "Epoch: 11, Step: 5/164, Loss: 0.762307, Accuracy: 72.66%\n",
            "Epoch: 11, Step: 6/164, Loss: 0.746053, Accuracy: 73.31%\n",
            "Epoch: 11, Step: 7/164, Loss: 0.736148, Accuracy: 73.77%\n",
            "Epoch: 11, Step: 8/164, Loss: 0.749915, Accuracy: 73.24%\n",
            "Epoch: 11, Step: 9/164, Loss: 0.738681, Accuracy: 73.96%\n",
            "Epoch: 11, Step: 10/164, Loss: 0.741558, Accuracy: 73.67%\n",
            "Epoch: 11, Step: 11/164, Loss: 0.749502, Accuracy: 73.22%\n",
            "Epoch: 11, Step: 12/164, Loss: 0.764155, Accuracy: 72.53%\n",
            "Epoch: 11, Step: 13/164, Loss: 0.755398, Accuracy: 72.78%\n",
            "Epoch: 11, Step: 14/164, Loss: 0.750100, Accuracy: 73.05%\n",
            "Epoch: 11, Step: 15/164, Loss: 0.750619, Accuracy: 72.81%\n",
            "Epoch: 11, Step: 16/164, Loss: 0.749222, Accuracy: 72.95%\n",
            "Epoch: 11, Step: 17/164, Loss: 0.745554, Accuracy: 73.25%\n",
            "Epoch: 11, Step: 18/164, Loss: 0.737840, Accuracy: 73.78%\n",
            "Epoch: 11, Step: 19/164, Loss: 0.735022, Accuracy: 74.10%\n",
            "Epoch: 11, Step: 20/164, Loss: 0.734860, Accuracy: 74.02%\n",
            "Epoch: 11, Step: 21/164, Loss: 0.729513, Accuracy: 74.26%\n",
            "Epoch: 11, Step: 22/164, Loss: 0.730804, Accuracy: 74.36%\n",
            "Epoch: 11, Step: 23/164, Loss: 0.732191, Accuracy: 74.46%\n",
            "Epoch: 11, Step: 24/164, Loss: 0.732959, Accuracy: 74.38%\n",
            "Epoch: 11, Step: 25/164, Loss: 0.737855, Accuracy: 74.28%\n",
            "Epoch: 11, Step: 26/164, Loss: 0.740053, Accuracy: 74.40%\n",
            "Epoch: 11, Step: 27/164, Loss: 0.738560, Accuracy: 74.51%\n",
            "Epoch: 11, Step: 28/164, Loss: 0.740295, Accuracy: 74.47%\n",
            "Epoch: 11, Step: 29/164, Loss: 0.741421, Accuracy: 74.41%\n",
            "Epoch: 11, Step: 30/164, Loss: 0.739650, Accuracy: 74.64%\n",
            "Epoch: 11, Step: 31/164, Loss: 0.738227, Accuracy: 74.57%\n",
            "Epoch: 11, Step: 32/164, Loss: 0.737119, Accuracy: 74.66%\n",
            "Epoch: 11, Step: 33/164, Loss: 0.734965, Accuracy: 74.72%\n",
            "Epoch: 11, Step: 34/164, Loss: 0.732968, Accuracy: 74.82%\n",
            "Epoch: 11, Step: 35/164, Loss: 0.731623, Accuracy: 74.91%\n",
            "Epoch: 11, Step: 36/164, Loss: 0.734034, Accuracy: 74.93%\n",
            "Epoch: 11, Step: 37/164, Loss: 0.735356, Accuracy: 74.98%\n",
            "Epoch: 11, Step: 38/164, Loss: 0.733289, Accuracy: 75.02%\n",
            "Epoch: 11, Step: 39/164, Loss: 0.734658, Accuracy: 75.02%\n",
            "Epoch: 11, Step: 40/164, Loss: 0.737865, Accuracy: 74.90%\n",
            "Epoch: 11, Step: 41/164, Loss: 0.737662, Accuracy: 74.90%\n",
            "Epoch: 11, Step: 42/164, Loss: 0.734542, Accuracy: 75.02%\n",
            "Epoch: 11, Step: 43/164, Loss: 0.733441, Accuracy: 75.02%\n",
            "Epoch: 11, Step: 44/164, Loss: 0.734184, Accuracy: 75.00%\n",
            "Epoch: 11, Step: 45/164, Loss: 0.737192, Accuracy: 74.90%\n",
            "Epoch: 11, Step: 46/164, Loss: 0.736957, Accuracy: 74.93%\n",
            "Epoch: 11, Step: 47/164, Loss: 0.738834, Accuracy: 74.90%\n",
            "Epoch: 11, Step: 48/164, Loss: 0.740595, Accuracy: 74.77%\n",
            "Epoch: 11, Step: 49/164, Loss: 0.741266, Accuracy: 74.71%\n",
            "Epoch: 11, Step: 50/164, Loss: 0.740284, Accuracy: 74.77%\n",
            "Epoch: 11, Step: 51/164, Loss: 0.740588, Accuracy: 74.79%\n",
            "Epoch: 11, Step: 52/164, Loss: 0.736912, Accuracy: 74.91%\n",
            "Epoch: 11, Step: 53/164, Loss: 0.736085, Accuracy: 74.90%\n",
            "Epoch: 11, Step: 54/164, Loss: 0.735404, Accuracy: 74.88%\n",
            "Epoch: 11, Step: 55/164, Loss: 0.736016, Accuracy: 74.91%\n",
            "Epoch: 11, Step: 56/164, Loss: 0.738796, Accuracy: 74.92%\n",
            "Epoch: 11, Step: 57/164, Loss: 0.738098, Accuracy: 74.92%\n",
            "Epoch: 11, Step: 58/164, Loss: 0.739154, Accuracy: 74.92%\n",
            "Epoch: 11, Step: 59/164, Loss: 0.738373, Accuracy: 74.96%\n",
            "Epoch: 11, Step: 60/164, Loss: 0.738779, Accuracy: 74.82%\n",
            "Epoch: 11, Step: 61/164, Loss: 0.737385, Accuracy: 74.85%\n",
            "Epoch: 11, Step: 62/164, Loss: 0.736972, Accuracy: 74.82%\n",
            "Epoch: 11, Step: 63/164, Loss: 0.735554, Accuracy: 74.90%\n",
            "Epoch: 11, Step: 64/164, Loss: 0.732538, Accuracy: 74.96%\n",
            "Epoch: 11, Step: 65/164, Loss: 0.733234, Accuracy: 75.00%\n",
            "Epoch: 11, Step: 66/164, Loss: 0.733909, Accuracy: 75.00%\n",
            "Epoch: 11, Step: 67/164, Loss: 0.732410, Accuracy: 75.02%\n",
            "Epoch: 11, Step: 68/164, Loss: 0.731883, Accuracy: 74.98%\n",
            "Epoch: 11, Step: 69/164, Loss: 0.732496, Accuracy: 74.97%\n",
            "Epoch: 11, Step: 70/164, Loss: 0.730517, Accuracy: 75.03%\n",
            "Epoch: 11, Step: 71/164, Loss: 0.730191, Accuracy: 75.06%\n",
            "Epoch: 11, Step: 72/164, Loss: 0.728275, Accuracy: 75.13%\n",
            "Epoch: 11, Step: 73/164, Loss: 0.727447, Accuracy: 75.14%\n",
            "Epoch: 11, Step: 74/164, Loss: 0.727530, Accuracy: 75.12%\n",
            "Epoch: 11, Step: 75/164, Loss: 0.726954, Accuracy: 75.14%\n",
            "Epoch: 11, Step: 76/164, Loss: 0.728148, Accuracy: 75.11%\n",
            "Epoch: 11, Step: 77/164, Loss: 0.729692, Accuracy: 75.05%\n",
            "Epoch: 11, Step: 78/164, Loss: 0.732197, Accuracy: 74.96%\n",
            "Epoch: 11, Step: 79/164, Loss: 0.733305, Accuracy: 74.94%\n",
            "Epoch: 11, Step: 80/164, Loss: 0.733467, Accuracy: 74.91%\n",
            "Epoch: 11, Step: 81/164, Loss: 0.732739, Accuracy: 74.86%\n",
            "Epoch: 11, Step: 82/164, Loss: 0.731488, Accuracy: 74.92%\n",
            "Epoch: 11, Step: 83/164, Loss: 0.732038, Accuracy: 74.95%\n",
            "Epoch: 11, Step: 84/164, Loss: 0.730731, Accuracy: 74.97%\n",
            "Epoch: 11, Step: 85/164, Loss: 0.733248, Accuracy: 74.91%\n",
            "Epoch: 11, Step: 86/164, Loss: 0.731853, Accuracy: 74.95%\n",
            "Epoch: 11, Step: 87/164, Loss: 0.733698, Accuracy: 74.95%\n",
            "Epoch: 11, Step: 88/164, Loss: 0.735148, Accuracy: 74.88%\n",
            "Epoch: 11, Step: 89/164, Loss: 0.732774, Accuracy: 74.98%\n",
            "Epoch: 11, Step: 90/164, Loss: 0.733106, Accuracy: 74.95%\n",
            "Epoch: 11, Step: 91/164, Loss: 0.733211, Accuracy: 74.96%\n",
            "Epoch: 11, Step: 92/164, Loss: 0.733227, Accuracy: 74.92%\n",
            "Epoch: 11, Step: 93/164, Loss: 0.731592, Accuracy: 74.98%\n",
            "Epoch: 11, Step: 94/164, Loss: 0.731955, Accuracy: 74.92%\n",
            "Epoch: 11, Step: 95/164, Loss: 0.734700, Accuracy: 74.80%\n",
            "Epoch: 11, Step: 96/164, Loss: 0.733810, Accuracy: 74.82%\n",
            "Epoch: 11, Step: 97/164, Loss: 0.731815, Accuracy: 74.91%\n",
            "Epoch: 11, Step: 98/164, Loss: 0.732658, Accuracy: 74.84%\n",
            "Epoch: 11, Step: 99/164, Loss: 0.732075, Accuracy: 74.88%\n",
            "Epoch: 11, Step: 100/164, Loss: 0.733850, Accuracy: 74.85%\n",
            "Epoch: 11, Step: 101/164, Loss: 0.734189, Accuracy: 74.85%\n",
            "Epoch: 11, Step: 102/164, Loss: 0.735228, Accuracy: 74.83%\n",
            "Epoch: 11, Step: 103/164, Loss: 0.735514, Accuracy: 74.82%\n",
            "Epoch: 11, Step: 104/164, Loss: 0.735336, Accuracy: 74.81%\n",
            "Epoch: 11, Step: 105/164, Loss: 0.734832, Accuracy: 74.82%\n",
            "Epoch: 11, Step: 106/164, Loss: 0.733881, Accuracy: 74.90%\n",
            "Epoch: 11, Step: 107/164, Loss: 0.733593, Accuracy: 74.93%\n",
            "Epoch: 11, Step: 108/164, Loss: 0.733497, Accuracy: 74.91%\n",
            "Epoch: 11, Step: 109/164, Loss: 0.734528, Accuracy: 74.86%\n",
            "Epoch: 11, Step: 110/164, Loss: 0.735039, Accuracy: 74.82%\n",
            "Epoch: 11, Step: 111/164, Loss: 0.734347, Accuracy: 74.86%\n",
            "Epoch: 11, Step: 112/164, Loss: 0.735148, Accuracy: 74.80%\n",
            "Epoch: 11, Step: 113/164, Loss: 0.734259, Accuracy: 74.84%\n",
            "Epoch: 11, Step: 114/164, Loss: 0.734128, Accuracy: 74.88%\n",
            "Epoch: 11, Step: 115/164, Loss: 0.732782, Accuracy: 74.92%\n",
            "Epoch: 11, Step: 116/164, Loss: 0.733710, Accuracy: 74.90%\n",
            "Epoch: 11, Step: 117/164, Loss: 0.732977, Accuracy: 74.91%\n",
            "Epoch: 11, Step: 118/164, Loss: 0.732495, Accuracy: 74.94%\n",
            "Epoch: 11, Step: 119/164, Loss: 0.732983, Accuracy: 74.92%\n",
            "Epoch: 11, Step: 120/164, Loss: 0.733834, Accuracy: 74.88%\n",
            "Epoch: 11, Step: 121/164, Loss: 0.733256, Accuracy: 74.88%\n",
            "Epoch: 11, Step: 122/164, Loss: 0.733025, Accuracy: 74.85%\n",
            "Epoch: 11, Step: 123/164, Loss: 0.733490, Accuracy: 74.83%\n",
            "Epoch: 11, Step: 124/164, Loss: 0.733697, Accuracy: 74.84%\n",
            "Epoch: 11, Step: 125/164, Loss: 0.733685, Accuracy: 74.86%\n",
            "Epoch: 11, Step: 126/164, Loss: 0.732888, Accuracy: 74.90%\n",
            "Epoch: 11, Step: 127/164, Loss: 0.733147, Accuracy: 74.89%\n",
            "Epoch: 11, Step: 128/164, Loss: 0.732887, Accuracy: 74.93%\n",
            "Epoch: 11, Step: 129/164, Loss: 0.731528, Accuracy: 74.96%\n",
            "Epoch: 11, Step: 130/164, Loss: 0.731011, Accuracy: 74.97%\n",
            "Epoch: 11, Step: 131/164, Loss: 0.730501, Accuracy: 75.00%\n",
            "Epoch: 11, Step: 132/164, Loss: 0.732134, Accuracy: 74.95%\n",
            "Epoch: 11, Step: 133/164, Loss: 0.734412, Accuracy: 74.88%\n",
            "Epoch: 11, Step: 134/164, Loss: 0.733958, Accuracy: 74.90%\n",
            "Epoch: 11, Step: 135/164, Loss: 0.733340, Accuracy: 74.94%\n",
            "Epoch: 11, Step: 136/164, Loss: 0.733495, Accuracy: 74.92%\n",
            "Epoch: 11, Step: 137/164, Loss: 0.733680, Accuracy: 74.91%\n",
            "Epoch: 11, Step: 138/164, Loss: 0.734128, Accuracy: 74.88%\n",
            "Epoch: 11, Step: 139/164, Loss: 0.733953, Accuracy: 74.86%\n",
            "Epoch: 11, Step: 140/164, Loss: 0.733873, Accuracy: 74.84%\n",
            "Epoch: 11, Step: 141/164, Loss: 0.734042, Accuracy: 74.85%\n",
            "Epoch: 11, Step: 142/164, Loss: 0.735247, Accuracy: 74.81%\n",
            "Epoch: 11, Step: 143/164, Loss: 0.735585, Accuracy: 74.78%\n",
            "Epoch: 11, Step: 144/164, Loss: 0.735378, Accuracy: 74.80%\n",
            "Epoch: 11, Step: 145/164, Loss: 0.736451, Accuracy: 74.80%\n",
            "Epoch: 11, Step: 146/164, Loss: 0.736159, Accuracy: 74.79%\n",
            "Epoch: 11, Step: 147/164, Loss: 0.736389, Accuracy: 74.79%\n",
            "Epoch: 11, Step: 148/164, Loss: 0.735876, Accuracy: 74.81%\n",
            "Epoch: 11, Step: 149/164, Loss: 0.735447, Accuracy: 74.86%\n",
            "Epoch: 11, Step: 150/164, Loss: 0.735727, Accuracy: 74.85%\n",
            "Epoch: 11, Step: 151/164, Loss: 0.735608, Accuracy: 74.87%\n",
            "Epoch: 11, Step: 152/164, Loss: 0.736131, Accuracy: 74.83%\n",
            "Epoch: 11, Step: 153/164, Loss: 0.735669, Accuracy: 74.84%\n",
            "Epoch: 11, Step: 154/164, Loss: 0.736711, Accuracy: 74.83%\n",
            "Epoch: 11, Step: 155/164, Loss: 0.737311, Accuracy: 74.80%\n",
            "Epoch: 11, Step: 156/164, Loss: 0.737799, Accuracy: 74.79%\n",
            "Epoch: 11, Step: 157/164, Loss: 0.737694, Accuracy: 74.77%\n",
            "Epoch: 11, Step: 158/164, Loss: 0.738757, Accuracy: 74.75%\n",
            "Epoch: 11, Step: 159/164, Loss: 0.737547, Accuracy: 74.81%\n",
            "Epoch: 11, Step: 160/164, Loss: 0.737328, Accuracy: 74.82%\n",
            "Epoch: 11, Step: 161/164, Loss: 0.737665, Accuracy: 74.80%\n",
            "Epoch: 11, Step: 162/164, Loss: 0.738744, Accuracy: 74.77%\n",
            "Epoch: 11, Step: 163/164, Loss: 0.737952, Accuracy: 74.78%\n",
            "Epoch: 11, Step: 164/164, Loss: 0.738508, Accuracy: 74.77%\n",
            "Epoch: 12, Step: 1/164, Loss: 0.623940, Accuracy: 77.34%\n",
            "Epoch: 12, Step: 2/164, Loss: 0.606593, Accuracy: 78.52%\n",
            "Epoch: 12, Step: 3/164, Loss: 0.621766, Accuracy: 78.91%\n",
            "Epoch: 12, Step: 4/164, Loss: 0.644272, Accuracy: 77.93%\n",
            "Epoch: 12, Step: 5/164, Loss: 0.633106, Accuracy: 78.12%\n",
            "Epoch: 12, Step: 6/164, Loss: 0.636393, Accuracy: 78.26%\n",
            "Epoch: 12, Step: 7/164, Loss: 0.649650, Accuracy: 77.57%\n",
            "Epoch: 12, Step: 8/164, Loss: 0.643654, Accuracy: 77.54%\n",
            "Epoch: 12, Step: 9/164, Loss: 0.661515, Accuracy: 76.74%\n",
            "Epoch: 12, Step: 10/164, Loss: 0.672578, Accuracy: 76.33%\n",
            "Epoch: 12, Step: 11/164, Loss: 0.672814, Accuracy: 76.35%\n",
            "Epoch: 12, Step: 12/164, Loss: 0.664414, Accuracy: 76.56%\n",
            "Epoch: 12, Step: 13/164, Loss: 0.657883, Accuracy: 76.86%\n",
            "Epoch: 12, Step: 14/164, Loss: 0.673518, Accuracy: 76.51%\n",
            "Epoch: 12, Step: 15/164, Loss: 0.681906, Accuracy: 76.30%\n",
            "Epoch: 12, Step: 16/164, Loss: 0.687665, Accuracy: 76.37%\n",
            "Epoch: 12, Step: 17/164, Loss: 0.697226, Accuracy: 76.47%\n",
            "Epoch: 12, Step: 18/164, Loss: 0.698592, Accuracy: 76.43%\n",
            "Epoch: 12, Step: 19/164, Loss: 0.697126, Accuracy: 76.48%\n",
            "Epoch: 12, Step: 20/164, Loss: 0.700305, Accuracy: 76.48%\n",
            "Epoch: 12, Step: 21/164, Loss: 0.698645, Accuracy: 76.45%\n",
            "Epoch: 12, Step: 22/164, Loss: 0.698284, Accuracy: 76.35%\n",
            "Epoch: 12, Step: 23/164, Loss: 0.697345, Accuracy: 76.36%\n",
            "Epoch: 12, Step: 24/164, Loss: 0.701388, Accuracy: 76.43%\n",
            "Epoch: 12, Step: 25/164, Loss: 0.696183, Accuracy: 76.75%\n",
            "Epoch: 12, Step: 26/164, Loss: 0.688103, Accuracy: 76.95%\n",
            "Epoch: 12, Step: 27/164, Loss: 0.685098, Accuracy: 77.03%\n",
            "Epoch: 12, Step: 28/164, Loss: 0.687257, Accuracy: 76.95%\n",
            "Epoch: 12, Step: 29/164, Loss: 0.692299, Accuracy: 76.83%\n",
            "Epoch: 12, Step: 30/164, Loss: 0.693570, Accuracy: 76.64%\n",
            "Epoch: 12, Step: 31/164, Loss: 0.694808, Accuracy: 76.46%\n",
            "Epoch: 12, Step: 32/164, Loss: 0.697434, Accuracy: 76.44%\n",
            "Epoch: 12, Step: 33/164, Loss: 0.693255, Accuracy: 76.63%\n",
            "Epoch: 12, Step: 34/164, Loss: 0.689053, Accuracy: 76.75%\n",
            "Epoch: 12, Step: 35/164, Loss: 0.691091, Accuracy: 76.74%\n",
            "Epoch: 12, Step: 36/164, Loss: 0.690444, Accuracy: 76.82%\n",
            "Epoch: 12, Step: 37/164, Loss: 0.691278, Accuracy: 76.75%\n",
            "Epoch: 12, Step: 38/164, Loss: 0.689980, Accuracy: 76.83%\n",
            "Epoch: 12, Step: 39/164, Loss: 0.690423, Accuracy: 76.90%\n",
            "Epoch: 12, Step: 40/164, Loss: 0.689570, Accuracy: 76.84%\n",
            "Epoch: 12, Step: 41/164, Loss: 0.692151, Accuracy: 76.70%\n",
            "Epoch: 12, Step: 42/164, Loss: 0.697378, Accuracy: 76.49%\n",
            "Epoch: 12, Step: 43/164, Loss: 0.694233, Accuracy: 76.65%\n",
            "Epoch: 12, Step: 44/164, Loss: 0.691786, Accuracy: 76.69%\n",
            "Epoch: 12, Step: 45/164, Loss: 0.692582, Accuracy: 76.70%\n",
            "Epoch: 12, Step: 46/164, Loss: 0.693867, Accuracy: 76.63%\n",
            "Epoch: 12, Step: 47/164, Loss: 0.693087, Accuracy: 76.63%\n",
            "Epoch: 12, Step: 48/164, Loss: 0.692471, Accuracy: 76.68%\n",
            "Epoch: 12, Step: 49/164, Loss: 0.692472, Accuracy: 76.74%\n",
            "Epoch: 12, Step: 50/164, Loss: 0.694343, Accuracy: 76.72%\n",
            "Epoch: 12, Step: 51/164, Loss: 0.695115, Accuracy: 76.70%\n",
            "Epoch: 12, Step: 52/164, Loss: 0.694353, Accuracy: 76.76%\n",
            "Epoch: 12, Step: 53/164, Loss: 0.693845, Accuracy: 76.74%\n",
            "Epoch: 12, Step: 54/164, Loss: 0.694750, Accuracy: 76.74%\n",
            "Epoch: 12, Step: 55/164, Loss: 0.694252, Accuracy: 76.70%\n",
            "Epoch: 12, Step: 56/164, Loss: 0.693210, Accuracy: 76.72%\n",
            "Epoch: 12, Step: 57/164, Loss: 0.693978, Accuracy: 76.66%\n",
            "Epoch: 12, Step: 58/164, Loss: 0.695688, Accuracy: 76.50%\n",
            "Epoch: 12, Step: 59/164, Loss: 0.695742, Accuracy: 76.47%\n",
            "Epoch: 12, Step: 60/164, Loss: 0.692481, Accuracy: 76.56%\n",
            "Epoch: 12, Step: 61/164, Loss: 0.692252, Accuracy: 76.55%\n",
            "Epoch: 12, Step: 62/164, Loss: 0.692046, Accuracy: 76.59%\n",
            "Epoch: 12, Step: 63/164, Loss: 0.691368, Accuracy: 76.62%\n",
            "Epoch: 12, Step: 64/164, Loss: 0.691216, Accuracy: 76.67%\n",
            "Epoch: 12, Step: 65/164, Loss: 0.690077, Accuracy: 76.71%\n",
            "Epoch: 12, Step: 66/164, Loss: 0.691902, Accuracy: 76.69%\n",
            "Epoch: 12, Step: 67/164, Loss: 0.693600, Accuracy: 76.59%\n",
            "Epoch: 12, Step: 68/164, Loss: 0.695154, Accuracy: 76.55%\n",
            "Epoch: 12, Step: 69/164, Loss: 0.695234, Accuracy: 76.53%\n",
            "Epoch: 12, Step: 70/164, Loss: 0.694548, Accuracy: 76.50%\n",
            "Epoch: 12, Step: 71/164, Loss: 0.693398, Accuracy: 76.53%\n",
            "Epoch: 12, Step: 72/164, Loss: 0.694805, Accuracy: 76.51%\n",
            "Epoch: 12, Step: 73/164, Loss: 0.695798, Accuracy: 76.50%\n",
            "Epoch: 12, Step: 74/164, Loss: 0.694995, Accuracy: 76.51%\n",
            "Epoch: 12, Step: 75/164, Loss: 0.695325, Accuracy: 76.50%\n",
            "Epoch: 12, Step: 76/164, Loss: 0.694956, Accuracy: 76.51%\n",
            "Epoch: 12, Step: 77/164, Loss: 0.695608, Accuracy: 76.47%\n",
            "Epoch: 12, Step: 78/164, Loss: 0.694803, Accuracy: 76.48%\n",
            "Epoch: 12, Step: 79/164, Loss: 0.692485, Accuracy: 76.56%\n",
            "Epoch: 12, Step: 80/164, Loss: 0.692046, Accuracy: 76.55%\n",
            "Epoch: 12, Step: 81/164, Loss: 0.693260, Accuracy: 76.54%\n",
            "Epoch: 12, Step: 82/164, Loss: 0.694380, Accuracy: 76.42%\n",
            "Epoch: 12, Step: 83/164, Loss: 0.693626, Accuracy: 76.40%\n",
            "Epoch: 12, Step: 84/164, Loss: 0.693317, Accuracy: 76.39%\n",
            "Epoch: 12, Step: 85/164, Loss: 0.693265, Accuracy: 76.40%\n",
            "Epoch: 12, Step: 86/164, Loss: 0.691927, Accuracy: 76.44%\n",
            "Epoch: 12, Step: 87/164, Loss: 0.690969, Accuracy: 76.49%\n",
            "Epoch: 12, Step: 88/164, Loss: 0.690113, Accuracy: 76.54%\n",
            "Epoch: 12, Step: 89/164, Loss: 0.689765, Accuracy: 76.54%\n",
            "Epoch: 12, Step: 90/164, Loss: 0.688878, Accuracy: 76.57%\n",
            "Epoch: 12, Step: 91/164, Loss: 0.689561, Accuracy: 76.59%\n",
            "Epoch: 12, Step: 92/164, Loss: 0.689184, Accuracy: 76.60%\n",
            "Epoch: 12, Step: 93/164, Loss: 0.689203, Accuracy: 76.59%\n",
            "Epoch: 12, Step: 94/164, Loss: 0.690315, Accuracy: 76.54%\n",
            "Epoch: 12, Step: 95/164, Loss: 0.689915, Accuracy: 76.55%\n",
            "Epoch: 12, Step: 96/164, Loss: 0.690311, Accuracy: 76.51%\n",
            "Epoch: 12, Step: 97/164, Loss: 0.690300, Accuracy: 76.52%\n",
            "Epoch: 12, Step: 98/164, Loss: 0.690500, Accuracy: 76.48%\n",
            "Epoch: 12, Step: 99/164, Loss: 0.691557, Accuracy: 76.42%\n",
            "Epoch: 12, Step: 100/164, Loss: 0.692525, Accuracy: 76.38%\n",
            "Epoch: 12, Step: 101/164, Loss: 0.692774, Accuracy: 76.36%\n",
            "Epoch: 12, Step: 102/164, Loss: 0.692652, Accuracy: 76.37%\n",
            "Epoch: 12, Step: 103/164, Loss: 0.691220, Accuracy: 76.43%\n",
            "Epoch: 12, Step: 104/164, Loss: 0.691071, Accuracy: 76.41%\n",
            "Epoch: 12, Step: 105/164, Loss: 0.690745, Accuracy: 76.41%\n",
            "Epoch: 12, Step: 106/164, Loss: 0.691127, Accuracy: 76.43%\n",
            "Epoch: 12, Step: 107/164, Loss: 0.691096, Accuracy: 76.39%\n",
            "Epoch: 12, Step: 108/164, Loss: 0.689671, Accuracy: 76.48%\n",
            "Epoch: 12, Step: 109/164, Loss: 0.690650, Accuracy: 76.45%\n",
            "Epoch: 12, Step: 110/164, Loss: 0.691635, Accuracy: 76.43%\n",
            "Epoch: 12, Step: 111/164, Loss: 0.692002, Accuracy: 76.41%\n",
            "Epoch: 12, Step: 112/164, Loss: 0.691255, Accuracy: 76.43%\n",
            "Epoch: 12, Step: 113/164, Loss: 0.692768, Accuracy: 76.40%\n",
            "Epoch: 12, Step: 114/164, Loss: 0.692686, Accuracy: 76.38%\n",
            "Epoch: 12, Step: 115/164, Loss: 0.691831, Accuracy: 76.39%\n",
            "Epoch: 12, Step: 116/164, Loss: 0.692990, Accuracy: 76.35%\n",
            "Epoch: 12, Step: 117/164, Loss: 0.695908, Accuracy: 76.29%\n",
            "Epoch: 12, Step: 118/164, Loss: 0.696299, Accuracy: 76.30%\n",
            "Epoch: 12, Step: 119/164, Loss: 0.695981, Accuracy: 76.31%\n",
            "Epoch: 12, Step: 120/164, Loss: 0.696576, Accuracy: 76.28%\n",
            "Epoch: 12, Step: 121/164, Loss: 0.696373, Accuracy: 76.29%\n",
            "Epoch: 12, Step: 122/164, Loss: 0.697478, Accuracy: 76.26%\n",
            "Epoch: 12, Step: 123/164, Loss: 0.697237, Accuracy: 76.27%\n",
            "Epoch: 12, Step: 124/164, Loss: 0.697672, Accuracy: 76.27%\n",
            "Epoch: 12, Step: 125/164, Loss: 0.697868, Accuracy: 76.26%\n",
            "Epoch: 12, Step: 126/164, Loss: 0.697074, Accuracy: 76.26%\n",
            "Epoch: 12, Step: 127/164, Loss: 0.696923, Accuracy: 76.25%\n",
            "Epoch: 12, Step: 128/164, Loss: 0.695988, Accuracy: 76.30%\n",
            "Epoch: 12, Step: 129/164, Loss: 0.696285, Accuracy: 76.26%\n",
            "Epoch: 12, Step: 130/164, Loss: 0.696822, Accuracy: 76.26%\n",
            "Epoch: 12, Step: 131/164, Loss: 0.696214, Accuracy: 76.27%\n",
            "Epoch: 12, Step: 132/164, Loss: 0.696293, Accuracy: 76.26%\n",
            "Epoch: 12, Step: 133/164, Loss: 0.696232, Accuracy: 76.29%\n",
            "Epoch: 12, Step: 134/164, Loss: 0.697650, Accuracy: 76.26%\n",
            "Epoch: 12, Step: 135/164, Loss: 0.697667, Accuracy: 76.28%\n",
            "Epoch: 12, Step: 136/164, Loss: 0.699448, Accuracy: 76.20%\n",
            "Epoch: 12, Step: 137/164, Loss: 0.698094, Accuracy: 76.25%\n",
            "Epoch: 12, Step: 138/164, Loss: 0.698557, Accuracy: 76.21%\n",
            "Epoch: 12, Step: 139/164, Loss: 0.699162, Accuracy: 76.16%\n",
            "Epoch: 12, Step: 140/164, Loss: 0.699772, Accuracy: 76.16%\n",
            "Epoch: 12, Step: 141/164, Loss: 0.699302, Accuracy: 76.15%\n",
            "Epoch: 12, Step: 142/164, Loss: 0.700031, Accuracy: 76.13%\n",
            "Epoch: 12, Step: 143/164, Loss: 0.699212, Accuracy: 76.16%\n",
            "Epoch: 12, Step: 144/164, Loss: 0.700747, Accuracy: 76.11%\n",
            "Epoch: 12, Step: 145/164, Loss: 0.700040, Accuracy: 76.14%\n",
            "Epoch: 12, Step: 146/164, Loss: 0.699382, Accuracy: 76.19%\n",
            "Epoch: 12, Step: 147/164, Loss: 0.699800, Accuracy: 76.19%\n",
            "Epoch: 12, Step: 148/164, Loss: 0.699404, Accuracy: 76.20%\n",
            "Epoch: 12, Step: 149/164, Loss: 0.699390, Accuracy: 76.18%\n",
            "Epoch: 12, Step: 150/164, Loss: 0.700345, Accuracy: 76.14%\n",
            "Epoch: 12, Step: 151/164, Loss: 0.698799, Accuracy: 76.20%\n",
            "Epoch: 12, Step: 152/164, Loss: 0.697585, Accuracy: 76.22%\n",
            "Epoch: 12, Step: 153/164, Loss: 0.696950, Accuracy: 76.25%\n",
            "Epoch: 12, Step: 154/164, Loss: 0.697253, Accuracy: 76.25%\n",
            "Epoch: 12, Step: 155/164, Loss: 0.696405, Accuracy: 76.28%\n",
            "Epoch: 12, Step: 156/164, Loss: 0.695759, Accuracy: 76.30%\n",
            "Epoch: 12, Step: 157/164, Loss: 0.695205, Accuracy: 76.30%\n",
            "Epoch: 12, Step: 158/164, Loss: 0.695876, Accuracy: 76.26%\n",
            "Epoch: 12, Step: 159/164, Loss: 0.695988, Accuracy: 76.24%\n",
            "Epoch: 12, Step: 160/164, Loss: 0.695969, Accuracy: 76.26%\n",
            "Epoch: 12, Step: 161/164, Loss: 0.696075, Accuracy: 76.25%\n",
            "Epoch: 12, Step: 162/164, Loss: 0.695790, Accuracy: 76.25%\n",
            "Epoch: 12, Step: 163/164, Loss: 0.696068, Accuracy: 76.24%\n",
            "Epoch: 12, Step: 164/164, Loss: 0.695504, Accuracy: 76.26%\n",
            "Epoch: 13, Step: 1/164, Loss: 0.632374, Accuracy: 78.12%\n",
            "Epoch: 13, Step: 2/164, Loss: 0.628705, Accuracy: 78.52%\n",
            "Epoch: 13, Step: 3/164, Loss: 0.664371, Accuracy: 77.60%\n",
            "Epoch: 13, Step: 4/164, Loss: 0.651833, Accuracy: 77.73%\n",
            "Epoch: 13, Step: 5/164, Loss: 0.630334, Accuracy: 77.81%\n",
            "Epoch: 13, Step: 6/164, Loss: 0.644846, Accuracy: 77.34%\n",
            "Epoch: 13, Step: 7/164, Loss: 0.652250, Accuracy: 76.79%\n",
            "Epoch: 13, Step: 8/164, Loss: 0.645259, Accuracy: 77.15%\n",
            "Epoch: 13, Step: 9/164, Loss: 0.643641, Accuracy: 77.26%\n",
            "Epoch: 13, Step: 10/164, Loss: 0.647168, Accuracy: 77.11%\n",
            "Epoch: 13, Step: 11/164, Loss: 0.642991, Accuracy: 77.63%\n",
            "Epoch: 13, Step: 12/164, Loss: 0.631999, Accuracy: 78.19%\n",
            "Epoch: 13, Step: 13/164, Loss: 0.630471, Accuracy: 78.19%\n",
            "Epoch: 13, Step: 14/164, Loss: 0.640008, Accuracy: 77.79%\n",
            "Epoch: 13, Step: 15/164, Loss: 0.640805, Accuracy: 77.86%\n",
            "Epoch: 13, Step: 16/164, Loss: 0.634233, Accuracy: 78.22%\n",
            "Epoch: 13, Step: 17/164, Loss: 0.648528, Accuracy: 78.12%\n",
            "Epoch: 13, Step: 18/164, Loss: 0.647727, Accuracy: 78.21%\n",
            "Epoch: 13, Step: 19/164, Loss: 0.634909, Accuracy: 78.66%\n",
            "Epoch: 13, Step: 20/164, Loss: 0.639605, Accuracy: 78.40%\n",
            "Epoch: 13, Step: 21/164, Loss: 0.638788, Accuracy: 78.31%\n",
            "Epoch: 13, Step: 22/164, Loss: 0.635950, Accuracy: 78.41%\n",
            "Epoch: 13, Step: 23/164, Loss: 0.643247, Accuracy: 78.26%\n",
            "Epoch: 13, Step: 24/164, Loss: 0.641906, Accuracy: 78.39%\n",
            "Epoch: 13, Step: 25/164, Loss: 0.638320, Accuracy: 78.34%\n",
            "Epoch: 13, Step: 26/164, Loss: 0.649255, Accuracy: 78.06%\n",
            "Epoch: 13, Step: 27/164, Loss: 0.650466, Accuracy: 78.01%\n",
            "Epoch: 13, Step: 28/164, Loss: 0.649074, Accuracy: 78.18%\n",
            "Epoch: 13, Step: 29/164, Loss: 0.653050, Accuracy: 77.96%\n",
            "Epoch: 13, Step: 30/164, Loss: 0.650978, Accuracy: 78.12%\n",
            "Epoch: 13, Step: 31/164, Loss: 0.650146, Accuracy: 78.15%\n",
            "Epoch: 13, Step: 32/164, Loss: 0.651456, Accuracy: 78.00%\n",
            "Epoch: 13, Step: 33/164, Loss: 0.651523, Accuracy: 77.89%\n",
            "Epoch: 13, Step: 34/164, Loss: 0.653677, Accuracy: 77.76%\n",
            "Epoch: 13, Step: 35/164, Loss: 0.657291, Accuracy: 77.63%\n",
            "Epoch: 13, Step: 36/164, Loss: 0.657011, Accuracy: 77.60%\n",
            "Epoch: 13, Step: 37/164, Loss: 0.655266, Accuracy: 77.77%\n",
            "Epoch: 13, Step: 38/164, Loss: 0.654316, Accuracy: 77.88%\n",
            "Epoch: 13, Step: 39/164, Loss: 0.656792, Accuracy: 77.78%\n",
            "Epoch: 13, Step: 40/164, Loss: 0.659253, Accuracy: 77.71%\n",
            "Epoch: 13, Step: 41/164, Loss: 0.660007, Accuracy: 77.71%\n",
            "Epoch: 13, Step: 42/164, Loss: 0.660375, Accuracy: 77.70%\n",
            "Epoch: 13, Step: 43/164, Loss: 0.662176, Accuracy: 77.65%\n",
            "Epoch: 13, Step: 44/164, Loss: 0.660696, Accuracy: 77.59%\n",
            "Epoch: 13, Step: 45/164, Loss: 0.661612, Accuracy: 77.53%\n",
            "Epoch: 13, Step: 46/164, Loss: 0.659961, Accuracy: 77.60%\n",
            "Epoch: 13, Step: 47/164, Loss: 0.664044, Accuracy: 77.49%\n",
            "Epoch: 13, Step: 48/164, Loss: 0.663127, Accuracy: 77.49%\n",
            "Epoch: 13, Step: 49/164, Loss: 0.661532, Accuracy: 77.58%\n",
            "Epoch: 13, Step: 50/164, Loss: 0.660596, Accuracy: 77.66%\n",
            "Epoch: 13, Step: 51/164, Loss: 0.661992, Accuracy: 77.57%\n",
            "Epoch: 13, Step: 52/164, Loss: 0.661196, Accuracy: 77.64%\n",
            "Epoch: 13, Step: 53/164, Loss: 0.662160, Accuracy: 77.59%\n",
            "Epoch: 13, Step: 54/164, Loss: 0.665098, Accuracy: 77.52%\n",
            "Epoch: 13, Step: 55/164, Loss: 0.665514, Accuracy: 77.51%\n",
            "Epoch: 13, Step: 56/164, Loss: 0.664854, Accuracy: 77.58%\n",
            "Epoch: 13, Step: 57/164, Loss: 0.663416, Accuracy: 77.62%\n",
            "Epoch: 13, Step: 58/164, Loss: 0.663655, Accuracy: 77.57%\n",
            "Epoch: 13, Step: 59/164, Loss: 0.663605, Accuracy: 77.57%\n",
            "Epoch: 13, Step: 60/164, Loss: 0.661700, Accuracy: 77.58%\n",
            "Epoch: 13, Step: 61/164, Loss: 0.665338, Accuracy: 77.54%\n",
            "Epoch: 13, Step: 62/164, Loss: 0.664724, Accuracy: 77.56%\n",
            "Epoch: 13, Step: 63/164, Loss: 0.665940, Accuracy: 77.49%\n",
            "Epoch: 13, Step: 64/164, Loss: 0.666482, Accuracy: 77.48%\n",
            "Epoch: 13, Step: 65/164, Loss: 0.665576, Accuracy: 77.48%\n",
            "Epoch: 13, Step: 66/164, Loss: 0.668256, Accuracy: 77.39%\n",
            "Epoch: 13, Step: 67/164, Loss: 0.666583, Accuracy: 77.47%\n",
            "Epoch: 13, Step: 68/164, Loss: 0.666141, Accuracy: 77.52%\n",
            "Epoch: 13, Step: 69/164, Loss: 0.667956, Accuracy: 77.43%\n",
            "Epoch: 13, Step: 70/164, Loss: 0.666125, Accuracy: 77.50%\n",
            "Epoch: 13, Step: 71/164, Loss: 0.666433, Accuracy: 77.48%\n",
            "Epoch: 13, Step: 72/164, Loss: 0.667134, Accuracy: 77.44%\n",
            "Epoch: 13, Step: 73/164, Loss: 0.666608, Accuracy: 77.44%\n",
            "Epoch: 13, Step: 74/164, Loss: 0.665573, Accuracy: 77.46%\n",
            "Epoch: 13, Step: 75/164, Loss: 0.665243, Accuracy: 77.45%\n",
            "Epoch: 13, Step: 76/164, Loss: 0.663283, Accuracy: 77.53%\n",
            "Epoch: 13, Step: 77/164, Loss: 0.662900, Accuracy: 77.57%\n",
            "Epoch: 13, Step: 78/164, Loss: 0.664686, Accuracy: 77.45%\n",
            "Epoch: 13, Step: 79/164, Loss: 0.665204, Accuracy: 77.40%\n",
            "Epoch: 13, Step: 80/164, Loss: 0.666242, Accuracy: 77.37%\n",
            "Epoch: 13, Step: 81/164, Loss: 0.665402, Accuracy: 77.41%\n",
            "Epoch: 13, Step: 82/164, Loss: 0.666199, Accuracy: 77.32%\n",
            "Epoch: 13, Step: 83/164, Loss: 0.664560, Accuracy: 77.38%\n",
            "Epoch: 13, Step: 84/164, Loss: 0.662756, Accuracy: 77.50%\n",
            "Epoch: 13, Step: 85/164, Loss: 0.662712, Accuracy: 77.45%\n",
            "Epoch: 13, Step: 86/164, Loss: 0.661141, Accuracy: 77.51%\n",
            "Epoch: 13, Step: 87/164, Loss: 0.660283, Accuracy: 77.53%\n",
            "Epoch: 13, Step: 88/164, Loss: 0.661037, Accuracy: 77.51%\n",
            "Epoch: 13, Step: 89/164, Loss: 0.663010, Accuracy: 77.48%\n",
            "Epoch: 13, Step: 90/164, Loss: 0.663540, Accuracy: 77.45%\n",
            "Epoch: 13, Step: 91/164, Loss: 0.663164, Accuracy: 77.52%\n",
            "Epoch: 13, Step: 92/164, Loss: 0.662449, Accuracy: 77.51%\n",
            "Epoch: 13, Step: 93/164, Loss: 0.662900, Accuracy: 77.51%\n",
            "Epoch: 13, Step: 94/164, Loss: 0.662570, Accuracy: 77.49%\n",
            "Epoch: 13, Step: 95/164, Loss: 0.662996, Accuracy: 77.50%\n",
            "Epoch: 13, Step: 96/164, Loss: 0.664625, Accuracy: 77.45%\n",
            "Epoch: 13, Step: 97/164, Loss: 0.663736, Accuracy: 77.46%\n",
            "Epoch: 13, Step: 98/164, Loss: 0.664223, Accuracy: 77.42%\n",
            "Epoch: 13, Step: 99/164, Loss: 0.666333, Accuracy: 77.38%\n",
            "Epoch: 13, Step: 100/164, Loss: 0.665853, Accuracy: 77.40%\n",
            "Epoch: 13, Step: 101/164, Loss: 0.667384, Accuracy: 77.34%\n",
            "Epoch: 13, Step: 102/164, Loss: 0.669438, Accuracy: 77.27%\n",
            "Epoch: 13, Step: 103/164, Loss: 0.669226, Accuracy: 77.28%\n",
            "Epoch: 13, Step: 104/164, Loss: 0.668608, Accuracy: 77.30%\n",
            "Epoch: 13, Step: 105/164, Loss: 0.667418, Accuracy: 77.34%\n",
            "Epoch: 13, Step: 106/164, Loss: 0.666144, Accuracy: 77.37%\n",
            "Epoch: 13, Step: 107/164, Loss: 0.667070, Accuracy: 77.35%\n",
            "Epoch: 13, Step: 108/164, Loss: 0.667096, Accuracy: 77.32%\n",
            "Epoch: 13, Step: 109/164, Loss: 0.666812, Accuracy: 77.37%\n",
            "Epoch: 13, Step: 110/164, Loss: 0.666119, Accuracy: 77.39%\n",
            "Epoch: 13, Step: 111/164, Loss: 0.666860, Accuracy: 77.34%\n",
            "Epoch: 13, Step: 112/164, Loss: 0.666263, Accuracy: 77.36%\n",
            "Epoch: 13, Step: 113/164, Loss: 0.666080, Accuracy: 77.32%\n",
            "Epoch: 13, Step: 114/164, Loss: 0.666358, Accuracy: 77.31%\n",
            "Epoch: 13, Step: 115/164, Loss: 0.666547, Accuracy: 77.31%\n",
            "Epoch: 13, Step: 116/164, Loss: 0.666309, Accuracy: 77.30%\n",
            "Epoch: 13, Step: 117/164, Loss: 0.668156, Accuracy: 77.24%\n",
            "Epoch: 13, Step: 118/164, Loss: 0.669028, Accuracy: 77.22%\n",
            "Epoch: 13, Step: 119/164, Loss: 0.669076, Accuracy: 77.21%\n",
            "Epoch: 13, Step: 120/164, Loss: 0.668688, Accuracy: 77.23%\n",
            "Epoch: 13, Step: 121/164, Loss: 0.669761, Accuracy: 77.19%\n",
            "Epoch: 13, Step: 122/164, Loss: 0.669842, Accuracy: 77.21%\n",
            "Epoch: 13, Step: 123/164, Loss: 0.670443, Accuracy: 77.15%\n",
            "Epoch: 13, Step: 124/164, Loss: 0.670181, Accuracy: 77.15%\n",
            "Epoch: 13, Step: 125/164, Loss: 0.671210, Accuracy: 77.18%\n",
            "Epoch: 13, Step: 126/164, Loss: 0.669220, Accuracy: 77.26%\n",
            "Epoch: 13, Step: 127/164, Loss: 0.669165, Accuracy: 77.26%\n",
            "Epoch: 13, Step: 128/164, Loss: 0.668948, Accuracy: 77.26%\n",
            "Epoch: 13, Step: 129/164, Loss: 0.669320, Accuracy: 77.28%\n",
            "Epoch: 13, Step: 130/164, Loss: 0.669051, Accuracy: 77.28%\n",
            "Epoch: 13, Step: 131/164, Loss: 0.668835, Accuracy: 77.28%\n",
            "Epoch: 13, Step: 132/164, Loss: 0.668022, Accuracy: 77.31%\n",
            "Epoch: 13, Step: 133/164, Loss: 0.668261, Accuracy: 77.30%\n",
            "Epoch: 13, Step: 134/164, Loss: 0.669039, Accuracy: 77.29%\n",
            "Epoch: 13, Step: 135/164, Loss: 0.669240, Accuracy: 77.27%\n",
            "Epoch: 13, Step: 136/164, Loss: 0.669094, Accuracy: 77.26%\n",
            "Epoch: 13, Step: 137/164, Loss: 0.668158, Accuracy: 77.29%\n",
            "Epoch: 13, Step: 138/164, Loss: 0.668489, Accuracy: 77.28%\n",
            "Epoch: 13, Step: 139/164, Loss: 0.668156, Accuracy: 77.30%\n",
            "Epoch: 13, Step: 140/164, Loss: 0.668846, Accuracy: 77.30%\n",
            "Epoch: 13, Step: 141/164, Loss: 0.669192, Accuracy: 77.30%\n",
            "Epoch: 13, Step: 142/164, Loss: 0.669115, Accuracy: 77.29%\n",
            "Epoch: 13, Step: 143/164, Loss: 0.670810, Accuracy: 77.24%\n",
            "Epoch: 13, Step: 144/164, Loss: 0.670416, Accuracy: 77.25%\n",
            "Epoch: 13, Step: 145/164, Loss: 0.671585, Accuracy: 77.23%\n",
            "Epoch: 13, Step: 146/164, Loss: 0.670669, Accuracy: 77.26%\n",
            "Epoch: 13, Step: 147/164, Loss: 0.670549, Accuracy: 77.25%\n",
            "Epoch: 13, Step: 148/164, Loss: 0.671776, Accuracy: 77.20%\n",
            "Epoch: 13, Step: 149/164, Loss: 0.672063, Accuracy: 77.22%\n",
            "Epoch: 13, Step: 150/164, Loss: 0.672923, Accuracy: 77.18%\n",
            "Epoch: 13, Step: 151/164, Loss: 0.673164, Accuracy: 77.16%\n",
            "Epoch: 13, Step: 152/164, Loss: 0.673878, Accuracy: 77.15%\n",
            "Epoch: 13, Step: 153/164, Loss: 0.674091, Accuracy: 77.15%\n",
            "Epoch: 13, Step: 154/164, Loss: 0.674855, Accuracy: 77.17%\n",
            "Epoch: 13, Step: 155/164, Loss: 0.674240, Accuracy: 77.20%\n",
            "Epoch: 13, Step: 156/164, Loss: 0.673404, Accuracy: 77.24%\n",
            "Epoch: 13, Step: 157/164, Loss: 0.673273, Accuracy: 77.23%\n",
            "Epoch: 13, Step: 158/164, Loss: 0.672429, Accuracy: 77.25%\n",
            "Epoch: 13, Step: 159/164, Loss: 0.673447, Accuracy: 77.23%\n",
            "Epoch: 13, Step: 160/164, Loss: 0.673717, Accuracy: 77.21%\n",
            "Epoch: 13, Step: 161/164, Loss: 0.674174, Accuracy: 77.16%\n",
            "Epoch: 13, Step: 162/164, Loss: 0.674192, Accuracy: 77.16%\n",
            "Epoch: 13, Step: 163/164, Loss: 0.674655, Accuracy: 77.14%\n",
            "Epoch: 13, Step: 164/164, Loss: 0.674521, Accuracy: 77.13%\n",
            "Epoch: 14, Step: 1/164, Loss: 0.608177, Accuracy: 74.22%\n",
            "Epoch: 14, Step: 2/164, Loss: 0.571506, Accuracy: 77.34%\n",
            "Epoch: 14, Step: 3/164, Loss: 0.640694, Accuracy: 76.82%\n",
            "Epoch: 14, Step: 4/164, Loss: 0.647644, Accuracy: 76.95%\n",
            "Epoch: 14, Step: 5/164, Loss: 0.628735, Accuracy: 77.66%\n",
            "Epoch: 14, Step: 6/164, Loss: 0.648242, Accuracy: 76.95%\n",
            "Epoch: 14, Step: 7/164, Loss: 0.669823, Accuracy: 76.56%\n",
            "Epoch: 14, Step: 8/164, Loss: 0.681355, Accuracy: 75.88%\n",
            "Epoch: 14, Step: 9/164, Loss: 0.670096, Accuracy: 76.22%\n",
            "Epoch: 14, Step: 10/164, Loss: 0.670612, Accuracy: 76.02%\n",
            "Epoch: 14, Step: 11/164, Loss: 0.670902, Accuracy: 76.21%\n",
            "Epoch: 14, Step: 12/164, Loss: 0.676272, Accuracy: 75.98%\n",
            "Epoch: 14, Step: 13/164, Loss: 0.682241, Accuracy: 75.84%\n",
            "Epoch: 14, Step: 14/164, Loss: 0.681610, Accuracy: 75.67%\n",
            "Epoch: 14, Step: 15/164, Loss: 0.691539, Accuracy: 75.47%\n",
            "Epoch: 14, Step: 16/164, Loss: 0.686303, Accuracy: 75.68%\n",
            "Epoch: 14, Step: 17/164, Loss: 0.678237, Accuracy: 75.87%\n",
            "Epoch: 14, Step: 18/164, Loss: 0.681514, Accuracy: 75.91%\n",
            "Epoch: 14, Step: 19/164, Loss: 0.680487, Accuracy: 76.23%\n",
            "Epoch: 14, Step: 20/164, Loss: 0.681870, Accuracy: 76.25%\n",
            "Epoch: 14, Step: 21/164, Loss: 0.680953, Accuracy: 76.26%\n",
            "Epoch: 14, Step: 22/164, Loss: 0.681290, Accuracy: 76.42%\n",
            "Epoch: 14, Step: 23/164, Loss: 0.679417, Accuracy: 76.43%\n",
            "Epoch: 14, Step: 24/164, Loss: 0.682620, Accuracy: 76.37%\n",
            "Epoch: 14, Step: 25/164, Loss: 0.685431, Accuracy: 76.34%\n",
            "Epoch: 14, Step: 26/164, Loss: 0.679888, Accuracy: 76.68%\n",
            "Epoch: 14, Step: 27/164, Loss: 0.678519, Accuracy: 76.71%\n",
            "Epoch: 14, Step: 28/164, Loss: 0.680985, Accuracy: 76.65%\n",
            "Epoch: 14, Step: 29/164, Loss: 0.678276, Accuracy: 76.59%\n",
            "Epoch: 14, Step: 30/164, Loss: 0.678171, Accuracy: 76.67%\n",
            "Epoch: 14, Step: 31/164, Loss: 0.673372, Accuracy: 76.92%\n",
            "Epoch: 14, Step: 32/164, Loss: 0.676041, Accuracy: 76.76%\n",
            "Epoch: 14, Step: 33/164, Loss: 0.673839, Accuracy: 76.89%\n",
            "Epoch: 14, Step: 34/164, Loss: 0.678048, Accuracy: 76.75%\n",
            "Epoch: 14, Step: 35/164, Loss: 0.682352, Accuracy: 76.65%\n",
            "Epoch: 14, Step: 36/164, Loss: 0.683263, Accuracy: 76.69%\n",
            "Epoch: 14, Step: 37/164, Loss: 0.688015, Accuracy: 76.54%\n",
            "Epoch: 14, Step: 38/164, Loss: 0.685331, Accuracy: 76.56%\n",
            "Epoch: 14, Step: 39/164, Loss: 0.685928, Accuracy: 76.56%\n",
            "Epoch: 14, Step: 40/164, Loss: 0.687456, Accuracy: 76.46%\n",
            "Epoch: 14, Step: 41/164, Loss: 0.689215, Accuracy: 76.41%\n",
            "Epoch: 14, Step: 42/164, Loss: 0.688867, Accuracy: 76.41%\n",
            "Epoch: 14, Step: 43/164, Loss: 0.686767, Accuracy: 76.51%\n",
            "Epoch: 14, Step: 44/164, Loss: 0.687561, Accuracy: 76.58%\n",
            "Epoch: 14, Step: 45/164, Loss: 0.686939, Accuracy: 76.55%\n",
            "Epoch: 14, Step: 46/164, Loss: 0.686657, Accuracy: 76.60%\n",
            "Epoch: 14, Step: 47/164, Loss: 0.685576, Accuracy: 76.68%\n",
            "Epoch: 14, Step: 48/164, Loss: 0.684478, Accuracy: 76.71%\n",
            "Epoch: 14, Step: 49/164, Loss: 0.685917, Accuracy: 76.64%\n",
            "Epoch: 14, Step: 50/164, Loss: 0.684155, Accuracy: 76.72%\n",
            "Epoch: 14, Step: 51/164, Loss: 0.684504, Accuracy: 76.84%\n",
            "Epoch: 14, Step: 52/164, Loss: 0.684584, Accuracy: 76.86%\n",
            "Epoch: 14, Step: 53/164, Loss: 0.687215, Accuracy: 76.78%\n",
            "Epoch: 14, Step: 54/164, Loss: 0.689015, Accuracy: 76.77%\n",
            "Epoch: 14, Step: 55/164, Loss: 0.689427, Accuracy: 76.68%\n",
            "Epoch: 14, Step: 56/164, Loss: 0.688857, Accuracy: 76.70%\n",
            "Epoch: 14, Step: 57/164, Loss: 0.688369, Accuracy: 76.74%\n",
            "Epoch: 14, Step: 58/164, Loss: 0.687074, Accuracy: 76.74%\n",
            "Epoch: 14, Step: 59/164, Loss: 0.686422, Accuracy: 76.71%\n",
            "Epoch: 14, Step: 60/164, Loss: 0.685539, Accuracy: 76.74%\n",
            "Epoch: 14, Step: 61/164, Loss: 0.686356, Accuracy: 76.78%\n",
            "Epoch: 14, Step: 62/164, Loss: 0.687043, Accuracy: 76.83%\n",
            "Epoch: 14, Step: 63/164, Loss: 0.684997, Accuracy: 76.87%\n",
            "Epoch: 14, Step: 64/164, Loss: 0.683511, Accuracy: 76.89%\n",
            "Epoch: 14, Step: 65/164, Loss: 0.685035, Accuracy: 76.83%\n",
            "Epoch: 14, Step: 66/164, Loss: 0.684544, Accuracy: 76.83%\n",
            "Epoch: 14, Step: 67/164, Loss: 0.682289, Accuracy: 76.94%\n",
            "Epoch: 14, Step: 68/164, Loss: 0.680802, Accuracy: 77.01%\n",
            "Epoch: 14, Step: 69/164, Loss: 0.681354, Accuracy: 77.02%\n",
            "Epoch: 14, Step: 70/164, Loss: 0.681279, Accuracy: 77.09%\n",
            "Epoch: 14, Step: 71/164, Loss: 0.681153, Accuracy: 77.10%\n",
            "Epoch: 14, Step: 72/164, Loss: 0.681622, Accuracy: 77.07%\n",
            "Epoch: 14, Step: 73/164, Loss: 0.681448, Accuracy: 77.11%\n",
            "Epoch: 14, Step: 74/164, Loss: 0.680126, Accuracy: 77.17%\n",
            "Epoch: 14, Step: 75/164, Loss: 0.681883, Accuracy: 77.09%\n",
            "Epoch: 14, Step: 76/164, Loss: 0.678907, Accuracy: 77.19%\n",
            "Epoch: 14, Step: 77/164, Loss: 0.680218, Accuracy: 77.13%\n",
            "Epoch: 14, Step: 78/164, Loss: 0.678793, Accuracy: 77.19%\n",
            "Epoch: 14, Step: 79/164, Loss: 0.678224, Accuracy: 77.17%\n",
            "Epoch: 14, Step: 80/164, Loss: 0.679980, Accuracy: 77.10%\n",
            "Epoch: 14, Step: 81/164, Loss: 0.679366, Accuracy: 77.11%\n",
            "Epoch: 14, Step: 82/164, Loss: 0.679222, Accuracy: 77.11%\n",
            "Epoch: 14, Step: 83/164, Loss: 0.679091, Accuracy: 77.12%\n",
            "Epoch: 14, Step: 84/164, Loss: 0.677501, Accuracy: 77.19%\n",
            "Epoch: 14, Step: 85/164, Loss: 0.675854, Accuracy: 77.26%\n",
            "Epoch: 14, Step: 86/164, Loss: 0.677293, Accuracy: 77.21%\n",
            "Epoch: 14, Step: 87/164, Loss: 0.677064, Accuracy: 77.22%\n",
            "Epoch: 14, Step: 88/164, Loss: 0.678153, Accuracy: 77.15%\n",
            "Epoch: 14, Step: 89/164, Loss: 0.676680, Accuracy: 77.19%\n",
            "Epoch: 14, Step: 90/164, Loss: 0.676083, Accuracy: 77.16%\n",
            "Epoch: 14, Step: 91/164, Loss: 0.676706, Accuracy: 77.14%\n",
            "Epoch: 14, Step: 92/164, Loss: 0.677263, Accuracy: 77.11%\n",
            "Epoch: 14, Step: 93/164, Loss: 0.680567, Accuracy: 77.00%\n",
            "Epoch: 14, Step: 94/164, Loss: 0.677444, Accuracy: 77.10%\n",
            "Epoch: 14, Step: 95/164, Loss: 0.675699, Accuracy: 77.15%\n",
            "Epoch: 14, Step: 96/164, Loss: 0.675518, Accuracy: 77.16%\n",
            "Epoch: 14, Step: 97/164, Loss: 0.674352, Accuracy: 77.18%\n",
            "Epoch: 14, Step: 98/164, Loss: 0.673212, Accuracy: 77.20%\n",
            "Epoch: 14, Step: 99/164, Loss: 0.673540, Accuracy: 77.23%\n",
            "Epoch: 14, Step: 100/164, Loss: 0.673193, Accuracy: 77.24%\n",
            "Epoch: 14, Step: 101/164, Loss: 0.672703, Accuracy: 77.27%\n",
            "Epoch: 14, Step: 102/164, Loss: 0.673132, Accuracy: 77.24%\n",
            "Epoch: 14, Step: 103/164, Loss: 0.671720, Accuracy: 77.26%\n",
            "Epoch: 14, Step: 104/164, Loss: 0.671142, Accuracy: 77.28%\n",
            "Epoch: 14, Step: 105/164, Loss: 0.669612, Accuracy: 77.32%\n",
            "Epoch: 14, Step: 106/164, Loss: 0.670697, Accuracy: 77.26%\n",
            "Epoch: 14, Step: 107/164, Loss: 0.670475, Accuracy: 77.26%\n",
            "Epoch: 14, Step: 108/164, Loss: 0.669173, Accuracy: 77.32%\n",
            "Epoch: 14, Step: 109/164, Loss: 0.668402, Accuracy: 77.34%\n",
            "Epoch: 14, Step: 110/164, Loss: 0.668323, Accuracy: 77.35%\n",
            "Epoch: 14, Step: 111/164, Loss: 0.667862, Accuracy: 77.35%\n",
            "Epoch: 14, Step: 112/164, Loss: 0.667797, Accuracy: 77.36%\n",
            "Epoch: 14, Step: 113/164, Loss: 0.668274, Accuracy: 77.34%\n",
            "Epoch: 14, Step: 114/164, Loss: 0.667014, Accuracy: 77.37%\n",
            "Epoch: 14, Step: 115/164, Loss: 0.666971, Accuracy: 77.36%\n",
            "Epoch: 14, Step: 116/164, Loss: 0.668093, Accuracy: 77.30%\n",
            "Epoch: 14, Step: 117/164, Loss: 0.668036, Accuracy: 77.30%\n",
            "Epoch: 14, Step: 118/164, Loss: 0.667600, Accuracy: 77.31%\n",
            "Epoch: 14, Step: 119/164, Loss: 0.668762, Accuracy: 77.29%\n",
            "Epoch: 14, Step: 120/164, Loss: 0.667009, Accuracy: 77.36%\n",
            "Epoch: 14, Step: 121/164, Loss: 0.668108, Accuracy: 77.30%\n",
            "Epoch: 14, Step: 122/164, Loss: 0.668078, Accuracy: 77.27%\n",
            "Epoch: 14, Step: 123/164, Loss: 0.667464, Accuracy: 77.29%\n",
            "Epoch: 14, Step: 124/164, Loss: 0.666319, Accuracy: 77.31%\n",
            "Epoch: 14, Step: 125/164, Loss: 0.667243, Accuracy: 77.29%\n",
            "Epoch: 14, Step: 126/164, Loss: 0.666818, Accuracy: 77.31%\n",
            "Epoch: 14, Step: 127/164, Loss: 0.666902, Accuracy: 77.32%\n",
            "Epoch: 14, Step: 128/164, Loss: 0.667285, Accuracy: 77.31%\n",
            "Epoch: 14, Step: 129/164, Loss: 0.667623, Accuracy: 77.29%\n",
            "Epoch: 14, Step: 130/164, Loss: 0.666606, Accuracy: 77.33%\n",
            "Epoch: 14, Step: 131/164, Loss: 0.665445, Accuracy: 77.36%\n",
            "Epoch: 14, Step: 132/164, Loss: 0.666441, Accuracy: 77.33%\n",
            "Epoch: 14, Step: 133/164, Loss: 0.666799, Accuracy: 77.33%\n",
            "Epoch: 14, Step: 134/164, Loss: 0.666190, Accuracy: 77.36%\n",
            "Epoch: 14, Step: 135/164, Loss: 0.666232, Accuracy: 77.37%\n",
            "Epoch: 14, Step: 136/164, Loss: 0.665618, Accuracy: 77.40%\n",
            "Epoch: 14, Step: 137/164, Loss: 0.664952, Accuracy: 77.42%\n",
            "Epoch: 14, Step: 138/164, Loss: 0.664699, Accuracy: 77.43%\n",
            "Epoch: 14, Step: 139/164, Loss: 0.664840, Accuracy: 77.43%\n",
            "Epoch: 14, Step: 140/164, Loss: 0.664473, Accuracy: 77.47%\n",
            "Epoch: 14, Step: 141/164, Loss: 0.664963, Accuracy: 77.50%\n",
            "Epoch: 14, Step: 142/164, Loss: 0.665719, Accuracy: 77.49%\n",
            "Epoch: 14, Step: 143/164, Loss: 0.666807, Accuracy: 77.46%\n",
            "Epoch: 14, Step: 144/164, Loss: 0.667998, Accuracy: 77.42%\n",
            "Epoch: 14, Step: 145/164, Loss: 0.668266, Accuracy: 77.44%\n",
            "Epoch: 14, Step: 146/164, Loss: 0.667785, Accuracy: 77.46%\n",
            "Epoch: 14, Step: 147/164, Loss: 0.668192, Accuracy: 77.46%\n",
            "Epoch: 14, Step: 148/164, Loss: 0.666673, Accuracy: 77.50%\n",
            "Epoch: 14, Step: 149/164, Loss: 0.667105, Accuracy: 77.48%\n",
            "Epoch: 14, Step: 150/164, Loss: 0.666738, Accuracy: 77.48%\n",
            "Epoch: 14, Step: 151/164, Loss: 0.666437, Accuracy: 77.49%\n",
            "Epoch: 14, Step: 152/164, Loss: 0.666089, Accuracy: 77.49%\n",
            "Epoch: 14, Step: 153/164, Loss: 0.665268, Accuracy: 77.51%\n",
            "Epoch: 14, Step: 154/164, Loss: 0.665783, Accuracy: 77.51%\n",
            "Epoch: 14, Step: 155/164, Loss: 0.665598, Accuracy: 77.54%\n",
            "Epoch: 14, Step: 156/164, Loss: 0.665323, Accuracy: 77.56%\n",
            "Epoch: 14, Step: 157/164, Loss: 0.665768, Accuracy: 77.56%\n",
            "Epoch: 14, Step: 158/164, Loss: 0.664998, Accuracy: 77.59%\n",
            "Epoch: 14, Step: 159/164, Loss: 0.664692, Accuracy: 77.59%\n",
            "Epoch: 14, Step: 160/164, Loss: 0.664905, Accuracy: 77.59%\n",
            "Epoch: 14, Step: 161/164, Loss: 0.663711, Accuracy: 77.64%\n",
            "Epoch: 14, Step: 162/164, Loss: 0.662925, Accuracy: 77.67%\n",
            "Epoch: 14, Step: 163/164, Loss: 0.663200, Accuracy: 77.66%\n",
            "Epoch: 14, Step: 164/164, Loss: 0.662023, Accuracy: 77.69%\n",
            "Epoch: 15, Step: 1/164, Loss: 0.753468, Accuracy: 75.78%\n",
            "Epoch: 15, Step: 2/164, Loss: 0.628627, Accuracy: 80.47%\n",
            "Epoch: 15, Step: 3/164, Loss: 0.625603, Accuracy: 80.99%\n",
            "Epoch: 15, Step: 4/164, Loss: 0.627015, Accuracy: 80.27%\n",
            "Epoch: 15, Step: 5/164, Loss: 0.587542, Accuracy: 82.03%\n",
            "Epoch: 15, Step: 6/164, Loss: 0.587297, Accuracy: 81.25%\n",
            "Epoch: 15, Step: 7/164, Loss: 0.584345, Accuracy: 81.14%\n",
            "Epoch: 15, Step: 8/164, Loss: 0.592178, Accuracy: 80.47%\n",
            "Epoch: 15, Step: 9/164, Loss: 0.598456, Accuracy: 80.30%\n",
            "Epoch: 15, Step: 10/164, Loss: 0.601564, Accuracy: 80.00%\n",
            "Epoch: 15, Step: 11/164, Loss: 0.594208, Accuracy: 80.04%\n",
            "Epoch: 15, Step: 12/164, Loss: 0.595390, Accuracy: 80.08%\n",
            "Epoch: 15, Step: 13/164, Loss: 0.590033, Accuracy: 80.35%\n",
            "Epoch: 15, Step: 14/164, Loss: 0.595575, Accuracy: 80.30%\n",
            "Epoch: 15, Step: 15/164, Loss: 0.602026, Accuracy: 80.10%\n",
            "Epoch: 15, Step: 16/164, Loss: 0.598045, Accuracy: 80.13%\n",
            "Epoch: 15, Step: 17/164, Loss: 0.604155, Accuracy: 79.83%\n",
            "Epoch: 15, Step: 18/164, Loss: 0.603821, Accuracy: 79.47%\n",
            "Epoch: 15, Step: 19/164, Loss: 0.606801, Accuracy: 79.36%\n",
            "Epoch: 15, Step: 20/164, Loss: 0.610235, Accuracy: 79.30%\n",
            "Epoch: 15, Step: 21/164, Loss: 0.601556, Accuracy: 79.54%\n",
            "Epoch: 15, Step: 22/164, Loss: 0.603795, Accuracy: 79.62%\n",
            "Epoch: 15, Step: 23/164, Loss: 0.603497, Accuracy: 79.65%\n",
            "Epoch: 15, Step: 24/164, Loss: 0.604762, Accuracy: 79.52%\n",
            "Epoch: 15, Step: 25/164, Loss: 0.607016, Accuracy: 79.25%\n",
            "Epoch: 15, Step: 26/164, Loss: 0.603431, Accuracy: 79.30%\n",
            "Epoch: 15, Step: 27/164, Loss: 0.606036, Accuracy: 79.25%\n",
            "Epoch: 15, Step: 28/164, Loss: 0.604218, Accuracy: 79.32%\n",
            "Epoch: 15, Step: 29/164, Loss: 0.606106, Accuracy: 79.28%\n",
            "Epoch: 15, Step: 30/164, Loss: 0.607789, Accuracy: 79.32%\n",
            "Epoch: 15, Step: 31/164, Loss: 0.608469, Accuracy: 79.23%\n",
            "Epoch: 15, Step: 32/164, Loss: 0.608743, Accuracy: 79.30%\n",
            "Epoch: 15, Step: 33/164, Loss: 0.608089, Accuracy: 79.29%\n",
            "Epoch: 15, Step: 34/164, Loss: 0.609362, Accuracy: 79.20%\n",
            "Epoch: 15, Step: 35/164, Loss: 0.608844, Accuracy: 79.22%\n",
            "Epoch: 15, Step: 36/164, Loss: 0.610510, Accuracy: 79.30%\n",
            "Epoch: 15, Step: 37/164, Loss: 0.614799, Accuracy: 79.22%\n",
            "Epoch: 15, Step: 38/164, Loss: 0.616303, Accuracy: 79.07%\n",
            "Epoch: 15, Step: 39/164, Loss: 0.617267, Accuracy: 79.05%\n",
            "Epoch: 15, Step: 40/164, Loss: 0.618474, Accuracy: 79.02%\n",
            "Epoch: 15, Step: 41/164, Loss: 0.616467, Accuracy: 79.06%\n",
            "Epoch: 15, Step: 42/164, Loss: 0.618648, Accuracy: 79.02%\n",
            "Epoch: 15, Step: 43/164, Loss: 0.621337, Accuracy: 78.96%\n",
            "Epoch: 15, Step: 44/164, Loss: 0.620077, Accuracy: 79.00%\n",
            "Epoch: 15, Step: 45/164, Loss: 0.616306, Accuracy: 79.11%\n",
            "Epoch: 15, Step: 46/164, Loss: 0.617669, Accuracy: 79.08%\n",
            "Epoch: 15, Step: 47/164, Loss: 0.618396, Accuracy: 79.04%\n",
            "Epoch: 15, Step: 48/164, Loss: 0.619521, Accuracy: 78.97%\n",
            "Epoch: 15, Step: 49/164, Loss: 0.620605, Accuracy: 78.94%\n",
            "Epoch: 15, Step: 50/164, Loss: 0.620621, Accuracy: 78.97%\n",
            "Epoch: 15, Step: 51/164, Loss: 0.618690, Accuracy: 79.06%\n",
            "Epoch: 15, Step: 52/164, Loss: 0.622460, Accuracy: 78.92%\n",
            "Epoch: 15, Step: 53/164, Loss: 0.622984, Accuracy: 78.89%\n",
            "Epoch: 15, Step: 54/164, Loss: 0.622182, Accuracy: 78.88%\n",
            "Epoch: 15, Step: 55/164, Loss: 0.622236, Accuracy: 78.86%\n",
            "Epoch: 15, Step: 56/164, Loss: 0.624368, Accuracy: 78.78%\n",
            "Epoch: 15, Step: 57/164, Loss: 0.625548, Accuracy: 78.74%\n",
            "Epoch: 15, Step: 58/164, Loss: 0.627775, Accuracy: 78.68%\n",
            "Epoch: 15, Step: 59/164, Loss: 0.628904, Accuracy: 78.65%\n",
            "Epoch: 15, Step: 60/164, Loss: 0.628733, Accuracy: 78.66%\n",
            "Epoch: 15, Step: 61/164, Loss: 0.627997, Accuracy: 78.68%\n",
            "Epoch: 15, Step: 62/164, Loss: 0.629534, Accuracy: 78.54%\n",
            "Epoch: 15, Step: 63/164, Loss: 0.629797, Accuracy: 78.55%\n",
            "Epoch: 15, Step: 64/164, Loss: 0.628206, Accuracy: 78.55%\n",
            "Epoch: 15, Step: 65/164, Loss: 0.629161, Accuracy: 78.52%\n",
            "Epoch: 15, Step: 66/164, Loss: 0.629878, Accuracy: 78.54%\n",
            "Epoch: 15, Step: 67/164, Loss: 0.630288, Accuracy: 78.52%\n",
            "Epoch: 15, Step: 68/164, Loss: 0.629415, Accuracy: 78.53%\n",
            "Epoch: 15, Step: 69/164, Loss: 0.629247, Accuracy: 78.57%\n",
            "Epoch: 15, Step: 70/164, Loss: 0.628567, Accuracy: 78.60%\n",
            "Epoch: 15, Step: 71/164, Loss: 0.629766, Accuracy: 78.60%\n",
            "Epoch: 15, Step: 72/164, Loss: 0.629510, Accuracy: 78.59%\n",
            "Epoch: 15, Step: 73/164, Loss: 0.630108, Accuracy: 78.54%\n",
            "Epoch: 15, Step: 74/164, Loss: 0.631839, Accuracy: 78.51%\n",
            "Epoch: 15, Step: 75/164, Loss: 0.633971, Accuracy: 78.43%\n",
            "Epoch: 15, Step: 76/164, Loss: 0.634179, Accuracy: 78.40%\n",
            "Epoch: 15, Step: 77/164, Loss: 0.634449, Accuracy: 78.36%\n",
            "Epoch: 15, Step: 78/164, Loss: 0.633556, Accuracy: 78.45%\n",
            "Epoch: 15, Step: 79/164, Loss: 0.633575, Accuracy: 78.49%\n",
            "Epoch: 15, Step: 80/164, Loss: 0.633279, Accuracy: 78.46%\n",
            "Epoch: 15, Step: 81/164, Loss: 0.631730, Accuracy: 78.52%\n",
            "Epoch: 15, Step: 82/164, Loss: 0.631171, Accuracy: 78.48%\n",
            "Epoch: 15, Step: 83/164, Loss: 0.630269, Accuracy: 78.48%\n",
            "Epoch: 15, Step: 84/164, Loss: 0.629618, Accuracy: 78.49%\n",
            "Epoch: 15, Step: 85/164, Loss: 0.630333, Accuracy: 78.44%\n",
            "Epoch: 15, Step: 86/164, Loss: 0.628502, Accuracy: 78.48%\n",
            "Epoch: 15, Step: 87/164, Loss: 0.627562, Accuracy: 78.51%\n",
            "Epoch: 15, Step: 88/164, Loss: 0.627520, Accuracy: 78.53%\n",
            "Epoch: 15, Step: 89/164, Loss: 0.627985, Accuracy: 78.53%\n",
            "Epoch: 15, Step: 90/164, Loss: 0.628062, Accuracy: 78.54%\n",
            "Epoch: 15, Step: 91/164, Loss: 0.629058, Accuracy: 78.52%\n",
            "Epoch: 15, Step: 92/164, Loss: 0.629369, Accuracy: 78.49%\n",
            "Epoch: 15, Step: 93/164, Loss: 0.629776, Accuracy: 78.49%\n",
            "Epoch: 15, Step: 94/164, Loss: 0.629599, Accuracy: 78.52%\n",
            "Epoch: 15, Step: 95/164, Loss: 0.630630, Accuracy: 78.50%\n",
            "Epoch: 15, Step: 96/164, Loss: 0.629663, Accuracy: 78.55%\n",
            "Epoch: 15, Step: 97/164, Loss: 0.630447, Accuracy: 78.52%\n",
            "Epoch: 15, Step: 98/164, Loss: 0.630308, Accuracy: 78.56%\n",
            "Epoch: 15, Step: 99/164, Loss: 0.629497, Accuracy: 78.57%\n",
            "Epoch: 15, Step: 100/164, Loss: 0.629821, Accuracy: 78.61%\n",
            "Epoch: 15, Step: 101/164, Loss: 0.629451, Accuracy: 78.65%\n",
            "Epoch: 15, Step: 102/164, Loss: 0.629521, Accuracy: 78.68%\n",
            "Epoch: 15, Step: 103/164, Loss: 0.629620, Accuracy: 78.66%\n",
            "Epoch: 15, Step: 104/164, Loss: 0.629851, Accuracy: 78.65%\n",
            "Epoch: 15, Step: 105/164, Loss: 0.630196, Accuracy: 78.65%\n",
            "Epoch: 15, Step: 106/164, Loss: 0.629194, Accuracy: 78.69%\n",
            "Epoch: 15, Step: 107/164, Loss: 0.627795, Accuracy: 78.72%\n",
            "Epoch: 15, Step: 108/164, Loss: 0.629066, Accuracy: 78.65%\n",
            "Epoch: 15, Step: 109/164, Loss: 0.628195, Accuracy: 78.69%\n",
            "Epoch: 15, Step: 110/164, Loss: 0.628227, Accuracy: 78.68%\n",
            "Epoch: 15, Step: 111/164, Loss: 0.630161, Accuracy: 78.64%\n",
            "Epoch: 15, Step: 112/164, Loss: 0.630624, Accuracy: 78.63%\n",
            "Epoch: 15, Step: 113/164, Loss: 0.630914, Accuracy: 78.63%\n",
            "Epoch: 15, Step: 114/164, Loss: 0.629841, Accuracy: 78.65%\n",
            "Epoch: 15, Step: 115/164, Loss: 0.629437, Accuracy: 78.65%\n",
            "Epoch: 15, Step: 116/164, Loss: 0.629956, Accuracy: 78.64%\n",
            "Epoch: 15, Step: 117/164, Loss: 0.628522, Accuracy: 78.69%\n",
            "Epoch: 15, Step: 118/164, Loss: 0.629110, Accuracy: 78.68%\n",
            "Epoch: 15, Step: 119/164, Loss: 0.628643, Accuracy: 78.70%\n",
            "Epoch: 15, Step: 120/164, Loss: 0.627683, Accuracy: 78.72%\n",
            "Epoch: 15, Step: 121/164, Loss: 0.626748, Accuracy: 78.74%\n",
            "Epoch: 15, Step: 122/164, Loss: 0.626288, Accuracy: 78.74%\n",
            "Epoch: 15, Step: 123/164, Loss: 0.626436, Accuracy: 78.74%\n",
            "Epoch: 15, Step: 124/164, Loss: 0.625457, Accuracy: 78.76%\n",
            "Epoch: 15, Step: 125/164, Loss: 0.625292, Accuracy: 78.78%\n",
            "Epoch: 15, Step: 126/164, Loss: 0.625430, Accuracy: 78.77%\n",
            "Epoch: 15, Step: 127/164, Loss: 0.625661, Accuracy: 78.75%\n",
            "Epoch: 15, Step: 128/164, Loss: 0.626012, Accuracy: 78.74%\n",
            "Epoch: 15, Step: 129/164, Loss: 0.627677, Accuracy: 78.71%\n",
            "Epoch: 15, Step: 130/164, Loss: 0.627542, Accuracy: 78.72%\n",
            "Epoch: 15, Step: 131/164, Loss: 0.627068, Accuracy: 78.72%\n",
            "Epoch: 15, Step: 132/164, Loss: 0.626472, Accuracy: 78.75%\n",
            "Epoch: 15, Step: 133/164, Loss: 0.628777, Accuracy: 78.67%\n",
            "Epoch: 15, Step: 134/164, Loss: 0.630222, Accuracy: 78.65%\n",
            "Epoch: 15, Step: 135/164, Loss: 0.631372, Accuracy: 78.60%\n",
            "Epoch: 15, Step: 136/164, Loss: 0.630931, Accuracy: 78.61%\n",
            "Epoch: 15, Step: 137/164, Loss: 0.631035, Accuracy: 78.60%\n",
            "Epoch: 15, Step: 138/164, Loss: 0.631272, Accuracy: 78.59%\n",
            "Epoch: 15, Step: 139/164, Loss: 0.630817, Accuracy: 78.62%\n",
            "Epoch: 15, Step: 140/164, Loss: 0.630695, Accuracy: 78.62%\n",
            "Epoch: 15, Step: 141/164, Loss: 0.630535, Accuracy: 78.63%\n",
            "Epoch: 15, Step: 142/164, Loss: 0.631494, Accuracy: 78.60%\n",
            "Epoch: 15, Step: 143/164, Loss: 0.631139, Accuracy: 78.59%\n",
            "Epoch: 15, Step: 144/164, Loss: 0.630962, Accuracy: 78.60%\n",
            "Epoch: 15, Step: 145/164, Loss: 0.630338, Accuracy: 78.62%\n",
            "Epoch: 15, Step: 146/164, Loss: 0.630262, Accuracy: 78.64%\n",
            "Epoch: 15, Step: 147/164, Loss: 0.632298, Accuracy: 78.58%\n",
            "Epoch: 15, Step: 148/164, Loss: 0.632056, Accuracy: 78.59%\n",
            "Epoch: 15, Step: 149/164, Loss: 0.631249, Accuracy: 78.62%\n",
            "Epoch: 15, Step: 150/164, Loss: 0.632195, Accuracy: 78.61%\n",
            "Epoch: 15, Step: 151/164, Loss: 0.632245, Accuracy: 78.61%\n",
            "Epoch: 15, Step: 152/164, Loss: 0.632456, Accuracy: 78.58%\n",
            "Epoch: 15, Step: 153/164, Loss: 0.632496, Accuracy: 78.55%\n",
            "Epoch: 15, Step: 154/164, Loss: 0.633041, Accuracy: 78.54%\n",
            "Epoch: 15, Step: 155/164, Loss: 0.633226, Accuracy: 78.51%\n",
            "Epoch: 15, Step: 156/164, Loss: 0.634513, Accuracy: 78.47%\n",
            "Epoch: 15, Step: 157/164, Loss: 0.634046, Accuracy: 78.49%\n",
            "Epoch: 15, Step: 158/164, Loss: 0.634493, Accuracy: 78.49%\n",
            "Epoch: 15, Step: 159/164, Loss: 0.634883, Accuracy: 78.48%\n",
            "Epoch: 15, Step: 160/164, Loss: 0.634101, Accuracy: 78.51%\n",
            "Epoch: 15, Step: 161/164, Loss: 0.633842, Accuracy: 78.53%\n",
            "Epoch: 15, Step: 162/164, Loss: 0.633916, Accuracy: 78.55%\n",
            "Epoch: 15, Step: 163/164, Loss: 0.634222, Accuracy: 78.55%\n",
            "Epoch: 15, Step: 164/164, Loss: 0.634887, Accuracy: 78.53%\n",
            "Epoch: 16, Step: 1/164, Loss: 0.846480, Accuracy: 69.53%\n",
            "Epoch: 16, Step: 2/164, Loss: 0.843567, Accuracy: 70.70%\n",
            "Epoch: 16, Step: 3/164, Loss: 0.757778, Accuracy: 74.22%\n",
            "Epoch: 16, Step: 4/164, Loss: 0.693150, Accuracy: 76.95%\n",
            "Epoch: 16, Step: 5/164, Loss: 0.669343, Accuracy: 77.03%\n",
            "Epoch: 16, Step: 6/164, Loss: 0.649406, Accuracy: 77.99%\n",
            "Epoch: 16, Step: 7/164, Loss: 0.640260, Accuracy: 78.12%\n",
            "Epoch: 16, Step: 8/164, Loss: 0.624362, Accuracy: 78.91%\n",
            "Epoch: 16, Step: 9/164, Loss: 0.621484, Accuracy: 79.08%\n",
            "Epoch: 16, Step: 10/164, Loss: 0.615967, Accuracy: 79.30%\n",
            "Epoch: 16, Step: 11/164, Loss: 0.617196, Accuracy: 79.26%\n",
            "Epoch: 16, Step: 12/164, Loss: 0.616972, Accuracy: 79.43%\n",
            "Epoch: 16, Step: 13/164, Loss: 0.611057, Accuracy: 79.57%\n",
            "Epoch: 16, Step: 14/164, Loss: 0.604194, Accuracy: 79.69%\n",
            "Epoch: 16, Step: 15/164, Loss: 0.604446, Accuracy: 80.00%\n",
            "Epoch: 16, Step: 16/164, Loss: 0.600148, Accuracy: 79.88%\n",
            "Epoch: 16, Step: 17/164, Loss: 0.589452, Accuracy: 80.19%\n",
            "Epoch: 16, Step: 18/164, Loss: 0.590021, Accuracy: 80.34%\n",
            "Epoch: 16, Step: 19/164, Loss: 0.591857, Accuracy: 80.35%\n",
            "Epoch: 16, Step: 20/164, Loss: 0.595025, Accuracy: 80.31%\n",
            "Epoch: 16, Step: 21/164, Loss: 0.594361, Accuracy: 80.28%\n",
            "Epoch: 16, Step: 22/164, Loss: 0.590415, Accuracy: 80.36%\n",
            "Epoch: 16, Step: 23/164, Loss: 0.592391, Accuracy: 80.26%\n",
            "Epoch: 16, Step: 24/164, Loss: 0.595400, Accuracy: 80.27%\n",
            "Epoch: 16, Step: 25/164, Loss: 0.591931, Accuracy: 80.50%\n",
            "Epoch: 16, Step: 26/164, Loss: 0.586908, Accuracy: 80.65%\n",
            "Epoch: 16, Step: 27/164, Loss: 0.587841, Accuracy: 80.58%\n",
            "Epoch: 16, Step: 28/164, Loss: 0.583782, Accuracy: 80.66%\n",
            "Epoch: 16, Step: 29/164, Loss: 0.576019, Accuracy: 80.82%\n",
            "Epoch: 16, Step: 30/164, Loss: 0.577889, Accuracy: 80.73%\n",
            "Epoch: 16, Step: 31/164, Loss: 0.575847, Accuracy: 80.85%\n",
            "Epoch: 16, Step: 32/164, Loss: 0.580164, Accuracy: 80.69%\n",
            "Epoch: 16, Step: 33/164, Loss: 0.580924, Accuracy: 80.75%\n",
            "Epoch: 16, Step: 34/164, Loss: 0.583278, Accuracy: 80.81%\n",
            "Epoch: 16, Step: 35/164, Loss: 0.582305, Accuracy: 80.96%\n",
            "Epoch: 16, Step: 36/164, Loss: 0.586363, Accuracy: 80.75%\n",
            "Epoch: 16, Step: 37/164, Loss: 0.582082, Accuracy: 80.91%\n",
            "Epoch: 16, Step: 38/164, Loss: 0.582680, Accuracy: 80.96%\n",
            "Epoch: 16, Step: 39/164, Loss: 0.582003, Accuracy: 81.05%\n",
            "Epoch: 16, Step: 40/164, Loss: 0.585838, Accuracy: 81.04%\n",
            "Epoch: 16, Step: 41/164, Loss: 0.585269, Accuracy: 81.10%\n",
            "Epoch: 16, Step: 42/164, Loss: 0.585317, Accuracy: 81.06%\n",
            "Epoch: 16, Step: 43/164, Loss: 0.583042, Accuracy: 81.14%\n",
            "Epoch: 16, Step: 44/164, Loss: 0.582883, Accuracy: 81.16%\n",
            "Epoch: 16, Step: 45/164, Loss: 0.580990, Accuracy: 81.22%\n",
            "Epoch: 16, Step: 46/164, Loss: 0.579916, Accuracy: 81.22%\n",
            "Epoch: 16, Step: 47/164, Loss: 0.578265, Accuracy: 81.25%\n",
            "Epoch: 16, Step: 48/164, Loss: 0.579084, Accuracy: 81.15%\n",
            "Epoch: 16, Step: 49/164, Loss: 0.578674, Accuracy: 81.14%\n",
            "Epoch: 16, Step: 50/164, Loss: 0.577847, Accuracy: 81.16%\n",
            "Epoch: 16, Step: 51/164, Loss: 0.576481, Accuracy: 81.20%\n",
            "Epoch: 16, Step: 52/164, Loss: 0.577148, Accuracy: 81.11%\n",
            "Epoch: 16, Step: 53/164, Loss: 0.575466, Accuracy: 81.15%\n",
            "Epoch: 16, Step: 54/164, Loss: 0.576635, Accuracy: 81.09%\n",
            "Epoch: 16, Step: 55/164, Loss: 0.577517, Accuracy: 81.01%\n",
            "Epoch: 16, Step: 56/164, Loss: 0.578036, Accuracy: 80.97%\n",
            "Epoch: 16, Step: 57/164, Loss: 0.576898, Accuracy: 80.99%\n",
            "Epoch: 16, Step: 58/164, Loss: 0.576571, Accuracy: 80.97%\n",
            "Epoch: 16, Step: 59/164, Loss: 0.575441, Accuracy: 81.00%\n",
            "Epoch: 16, Step: 60/164, Loss: 0.575389, Accuracy: 80.99%\n",
            "Epoch: 16, Step: 61/164, Loss: 0.573662, Accuracy: 81.05%\n",
            "Epoch: 16, Step: 62/164, Loss: 0.574050, Accuracy: 81.00%\n",
            "Epoch: 16, Step: 63/164, Loss: 0.572411, Accuracy: 81.06%\n",
            "Epoch: 16, Step: 64/164, Loss: 0.572187, Accuracy: 81.07%\n",
            "Epoch: 16, Step: 65/164, Loss: 0.572792, Accuracy: 81.05%\n",
            "Epoch: 16, Step: 66/164, Loss: 0.573409, Accuracy: 81.01%\n",
            "Epoch: 16, Step: 67/164, Loss: 0.573786, Accuracy: 80.98%\n",
            "Epoch: 16, Step: 68/164, Loss: 0.575213, Accuracy: 80.96%\n",
            "Epoch: 16, Step: 69/164, Loss: 0.575219, Accuracy: 80.96%\n",
            "Epoch: 16, Step: 70/164, Loss: 0.574884, Accuracy: 80.93%\n",
            "Epoch: 16, Step: 71/164, Loss: 0.574534, Accuracy: 80.91%\n",
            "Epoch: 16, Step: 72/164, Loss: 0.572703, Accuracy: 80.99%\n",
            "Epoch: 16, Step: 73/164, Loss: 0.571291, Accuracy: 81.06%\n",
            "Epoch: 16, Step: 74/164, Loss: 0.568558, Accuracy: 81.14%\n",
            "Epoch: 16, Step: 75/164, Loss: 0.568338, Accuracy: 81.17%\n",
            "Epoch: 16, Step: 76/164, Loss: 0.567986, Accuracy: 81.14%\n",
            "Epoch: 16, Step: 77/164, Loss: 0.569099, Accuracy: 81.11%\n",
            "Epoch: 16, Step: 78/164, Loss: 0.568814, Accuracy: 81.11%\n",
            "Epoch: 16, Step: 79/164, Loss: 0.569531, Accuracy: 81.07%\n",
            "Epoch: 16, Step: 80/164, Loss: 0.568775, Accuracy: 81.09%\n",
            "Epoch: 16, Step: 81/164, Loss: 0.568627, Accuracy: 81.05%\n",
            "Epoch: 16, Step: 82/164, Loss: 0.567683, Accuracy: 81.06%\n",
            "Epoch: 16, Step: 83/164, Loss: 0.566141, Accuracy: 81.12%\n",
            "Epoch: 16, Step: 84/164, Loss: 0.565859, Accuracy: 81.14%\n",
            "Epoch: 16, Step: 85/164, Loss: 0.566484, Accuracy: 81.08%\n",
            "Epoch: 16, Step: 86/164, Loss: 0.568123, Accuracy: 81.03%\n",
            "Epoch: 16, Step: 87/164, Loss: 0.568829, Accuracy: 81.02%\n",
            "Epoch: 16, Step: 88/164, Loss: 0.570829, Accuracy: 81.00%\n",
            "Epoch: 16, Step: 89/164, Loss: 0.573025, Accuracy: 80.97%\n",
            "Epoch: 16, Step: 90/164, Loss: 0.573385, Accuracy: 80.96%\n",
            "Epoch: 16, Step: 91/164, Loss: 0.572920, Accuracy: 80.94%\n",
            "Epoch: 16, Step: 92/164, Loss: 0.573972, Accuracy: 80.89%\n",
            "Epoch: 16, Step: 93/164, Loss: 0.573581, Accuracy: 80.93%\n",
            "Epoch: 16, Step: 94/164, Loss: 0.572835, Accuracy: 80.97%\n",
            "Epoch: 16, Step: 95/164, Loss: 0.572820, Accuracy: 80.96%\n",
            "Epoch: 16, Step: 96/164, Loss: 0.573895, Accuracy: 80.92%\n",
            "Epoch: 16, Step: 97/164, Loss: 0.573890, Accuracy: 80.95%\n",
            "Epoch: 16, Step: 98/164, Loss: 0.574630, Accuracy: 80.92%\n",
            "Epoch: 16, Step: 99/164, Loss: 0.575616, Accuracy: 80.89%\n",
            "Epoch: 16, Step: 100/164, Loss: 0.576204, Accuracy: 80.84%\n",
            "Epoch: 16, Step: 101/164, Loss: 0.577418, Accuracy: 80.76%\n",
            "Epoch: 16, Step: 102/164, Loss: 0.577449, Accuracy: 80.78%\n",
            "Epoch: 16, Step: 103/164, Loss: 0.577219, Accuracy: 80.76%\n",
            "Epoch: 16, Step: 104/164, Loss: 0.576950, Accuracy: 80.75%\n",
            "Epoch: 16, Step: 105/164, Loss: 0.578630, Accuracy: 80.71%\n",
            "Epoch: 16, Step: 106/164, Loss: 0.578829, Accuracy: 80.70%\n",
            "Epoch: 16, Step: 107/164, Loss: 0.579132, Accuracy: 80.69%\n",
            "Epoch: 16, Step: 108/164, Loss: 0.579148, Accuracy: 80.69%\n",
            "Epoch: 16, Step: 109/164, Loss: 0.579010, Accuracy: 80.71%\n",
            "Epoch: 16, Step: 110/164, Loss: 0.579066, Accuracy: 80.72%\n",
            "Epoch: 16, Step: 111/164, Loss: 0.579519, Accuracy: 80.73%\n",
            "Epoch: 16, Step: 112/164, Loss: 0.580406, Accuracy: 80.70%\n",
            "Epoch: 16, Step: 113/164, Loss: 0.581785, Accuracy: 80.65%\n",
            "Epoch: 16, Step: 114/164, Loss: 0.581743, Accuracy: 80.67%\n",
            "Epoch: 16, Step: 115/164, Loss: 0.581827, Accuracy: 80.69%\n",
            "Epoch: 16, Step: 116/164, Loss: 0.582806, Accuracy: 80.65%\n",
            "Epoch: 16, Step: 117/164, Loss: 0.583386, Accuracy: 80.62%\n",
            "Epoch: 16, Step: 118/164, Loss: 0.582987, Accuracy: 80.63%\n",
            "Epoch: 16, Step: 119/164, Loss: 0.582392, Accuracy: 80.67%\n",
            "Epoch: 16, Step: 120/164, Loss: 0.581142, Accuracy: 80.74%\n",
            "Epoch: 16, Step: 121/164, Loss: 0.580257, Accuracy: 80.80%\n",
            "Epoch: 16, Step: 122/164, Loss: 0.581053, Accuracy: 80.76%\n",
            "Epoch: 16, Step: 123/164, Loss: 0.581422, Accuracy: 80.75%\n",
            "Epoch: 16, Step: 124/164, Loss: 0.579716, Accuracy: 80.82%\n",
            "Epoch: 16, Step: 125/164, Loss: 0.579030, Accuracy: 80.85%\n",
            "Epoch: 16, Step: 126/164, Loss: 0.578749, Accuracy: 80.86%\n",
            "Epoch: 16, Step: 127/164, Loss: 0.579917, Accuracy: 80.83%\n",
            "Epoch: 16, Step: 128/164, Loss: 0.580049, Accuracy: 80.83%\n",
            "Epoch: 16, Step: 129/164, Loss: 0.579876, Accuracy: 80.84%\n",
            "Epoch: 16, Step: 130/164, Loss: 0.580340, Accuracy: 80.82%\n",
            "Epoch: 16, Step: 131/164, Loss: 0.580367, Accuracy: 80.82%\n",
            "Epoch: 16, Step: 132/164, Loss: 0.580520, Accuracy: 80.81%\n",
            "Epoch: 16, Step: 133/164, Loss: 0.581968, Accuracy: 80.79%\n",
            "Epoch: 16, Step: 134/164, Loss: 0.582056, Accuracy: 80.78%\n",
            "Epoch: 16, Step: 135/164, Loss: 0.582028, Accuracy: 80.79%\n",
            "Epoch: 16, Step: 136/164, Loss: 0.581899, Accuracy: 80.77%\n",
            "Epoch: 16, Step: 137/164, Loss: 0.581872, Accuracy: 80.75%\n",
            "Epoch: 16, Step: 138/164, Loss: 0.582862, Accuracy: 80.70%\n",
            "Epoch: 16, Step: 139/164, Loss: 0.583560, Accuracy: 80.68%\n",
            "Epoch: 16, Step: 140/164, Loss: 0.583546, Accuracy: 80.66%\n",
            "Epoch: 16, Step: 141/164, Loss: 0.583357, Accuracy: 80.63%\n",
            "Epoch: 16, Step: 142/164, Loss: 0.584042, Accuracy: 80.60%\n",
            "Epoch: 16, Step: 143/164, Loss: 0.584682, Accuracy: 80.56%\n",
            "Epoch: 16, Step: 144/164, Loss: 0.584024, Accuracy: 80.58%\n",
            "Epoch: 16, Step: 145/164, Loss: 0.583185, Accuracy: 80.61%\n",
            "Epoch: 16, Step: 146/164, Loss: 0.582732, Accuracy: 80.60%\n",
            "Epoch: 16, Step: 147/164, Loss: 0.582676, Accuracy: 80.61%\n",
            "Epoch: 16, Step: 148/164, Loss: 0.582600, Accuracy: 80.60%\n",
            "Epoch: 16, Step: 149/164, Loss: 0.581656, Accuracy: 80.63%\n",
            "Epoch: 16, Step: 150/164, Loss: 0.580280, Accuracy: 80.66%\n",
            "Epoch: 16, Step: 151/164, Loss: 0.579935, Accuracy: 80.66%\n",
            "Epoch: 16, Step: 152/164, Loss: 0.578955, Accuracy: 80.71%\n",
            "Epoch: 16, Step: 153/164, Loss: 0.580105, Accuracy: 80.66%\n",
            "Epoch: 16, Step: 154/164, Loss: 0.580521, Accuracy: 80.64%\n",
            "Epoch: 16, Step: 155/164, Loss: 0.580053, Accuracy: 80.67%\n",
            "Epoch: 16, Step: 156/164, Loss: 0.579395, Accuracy: 80.71%\n",
            "Epoch: 16, Step: 157/164, Loss: 0.579460, Accuracy: 80.71%\n",
            "Epoch: 16, Step: 158/164, Loss: 0.579731, Accuracy: 80.72%\n",
            "Epoch: 16, Step: 159/164, Loss: 0.578388, Accuracy: 80.76%\n",
            "Epoch: 16, Step: 160/164, Loss: 0.577628, Accuracy: 80.79%\n",
            "Epoch: 16, Step: 161/164, Loss: 0.577417, Accuracy: 80.80%\n",
            "Epoch: 16, Step: 162/164, Loss: 0.577212, Accuracy: 80.78%\n",
            "Epoch: 16, Step: 163/164, Loss: 0.578662, Accuracy: 80.74%\n",
            "Epoch: 16, Step: 164/164, Loss: 0.578435, Accuracy: 80.74%\n",
            "Epoch: 17, Step: 1/164, Loss: 0.473153, Accuracy: 83.59%\n",
            "Epoch: 17, Step: 2/164, Loss: 0.570926, Accuracy: 82.03%\n",
            "Epoch: 17, Step: 3/164, Loss: 0.550198, Accuracy: 82.81%\n",
            "Epoch: 17, Step: 4/164, Loss: 0.547230, Accuracy: 82.03%\n",
            "Epoch: 17, Step: 5/164, Loss: 0.525601, Accuracy: 83.28%\n",
            "Epoch: 17, Step: 6/164, Loss: 0.528817, Accuracy: 82.68%\n",
            "Epoch: 17, Step: 7/164, Loss: 0.533416, Accuracy: 82.37%\n",
            "Epoch: 17, Step: 8/164, Loss: 0.539804, Accuracy: 81.74%\n",
            "Epoch: 17, Step: 9/164, Loss: 0.575217, Accuracy: 80.90%\n",
            "Epoch: 17, Step: 10/164, Loss: 0.576631, Accuracy: 81.17%\n",
            "Epoch: 17, Step: 11/164, Loss: 0.561400, Accuracy: 81.96%\n",
            "Epoch: 17, Step: 12/164, Loss: 0.570549, Accuracy: 81.84%\n",
            "Epoch: 17, Step: 13/164, Loss: 0.564745, Accuracy: 81.79%\n",
            "Epoch: 17, Step: 14/164, Loss: 0.577526, Accuracy: 81.36%\n",
            "Epoch: 17, Step: 15/164, Loss: 0.572706, Accuracy: 81.46%\n",
            "Epoch: 17, Step: 16/164, Loss: 0.573944, Accuracy: 81.35%\n",
            "Epoch: 17, Step: 17/164, Loss: 0.579515, Accuracy: 81.20%\n",
            "Epoch: 17, Step: 18/164, Loss: 0.576699, Accuracy: 81.34%\n",
            "Epoch: 17, Step: 19/164, Loss: 0.567116, Accuracy: 81.66%\n",
            "Epoch: 17, Step: 20/164, Loss: 0.566156, Accuracy: 81.68%\n",
            "Epoch: 17, Step: 21/164, Loss: 0.563979, Accuracy: 81.73%\n",
            "Epoch: 17, Step: 22/164, Loss: 0.566268, Accuracy: 81.64%\n",
            "Epoch: 17, Step: 23/164, Loss: 0.562352, Accuracy: 81.86%\n",
            "Epoch: 17, Step: 24/164, Loss: 0.561207, Accuracy: 81.90%\n",
            "Epoch: 17, Step: 25/164, Loss: 0.563012, Accuracy: 81.84%\n",
            "Epoch: 17, Step: 26/164, Loss: 0.564159, Accuracy: 81.64%\n",
            "Epoch: 17, Step: 27/164, Loss: 0.570660, Accuracy: 81.42%\n",
            "Epoch: 17, Step: 28/164, Loss: 0.569923, Accuracy: 81.47%\n",
            "Epoch: 17, Step: 29/164, Loss: 0.570824, Accuracy: 81.41%\n",
            "Epoch: 17, Step: 30/164, Loss: 0.567081, Accuracy: 81.48%\n",
            "Epoch: 17, Step: 31/164, Loss: 0.571238, Accuracy: 81.38%\n",
            "Epoch: 17, Step: 32/164, Loss: 0.572175, Accuracy: 81.25%\n",
            "Epoch: 17, Step: 33/164, Loss: 0.572661, Accuracy: 81.18%\n",
            "Epoch: 17, Step: 34/164, Loss: 0.573472, Accuracy: 81.14%\n",
            "Epoch: 17, Step: 35/164, Loss: 0.571967, Accuracy: 81.18%\n",
            "Epoch: 17, Step: 36/164, Loss: 0.572854, Accuracy: 81.10%\n",
            "Epoch: 17, Step: 37/164, Loss: 0.571132, Accuracy: 81.06%\n",
            "Epoch: 17, Step: 38/164, Loss: 0.569312, Accuracy: 81.11%\n",
            "Epoch: 17, Step: 39/164, Loss: 0.568327, Accuracy: 81.09%\n",
            "Epoch: 17, Step: 40/164, Loss: 0.569547, Accuracy: 81.09%\n",
            "Epoch: 17, Step: 41/164, Loss: 0.570673, Accuracy: 81.08%\n",
            "Epoch: 17, Step: 42/164, Loss: 0.574584, Accuracy: 80.93%\n",
            "Epoch: 17, Step: 43/164, Loss: 0.577192, Accuracy: 80.81%\n",
            "Epoch: 17, Step: 44/164, Loss: 0.574415, Accuracy: 80.97%\n",
            "Epoch: 17, Step: 45/164, Loss: 0.572792, Accuracy: 80.99%\n",
            "Epoch: 17, Step: 46/164, Loss: 0.566906, Accuracy: 81.23%\n",
            "Epoch: 17, Step: 47/164, Loss: 0.564688, Accuracy: 81.27%\n",
            "Epoch: 17, Step: 48/164, Loss: 0.562600, Accuracy: 81.30%\n",
            "Epoch: 17, Step: 49/164, Loss: 0.561012, Accuracy: 81.31%\n",
            "Epoch: 17, Step: 50/164, Loss: 0.560152, Accuracy: 81.33%\n",
            "Epoch: 17, Step: 51/164, Loss: 0.558832, Accuracy: 81.36%\n",
            "Epoch: 17, Step: 52/164, Loss: 0.556513, Accuracy: 81.34%\n",
            "Epoch: 17, Step: 53/164, Loss: 0.556204, Accuracy: 81.29%\n",
            "Epoch: 17, Step: 54/164, Loss: 0.555060, Accuracy: 81.39%\n",
            "Epoch: 17, Step: 55/164, Loss: 0.552916, Accuracy: 81.42%\n",
            "Epoch: 17, Step: 56/164, Loss: 0.551628, Accuracy: 81.46%\n",
            "Epoch: 17, Step: 57/164, Loss: 0.552920, Accuracy: 81.44%\n",
            "Epoch: 17, Step: 58/164, Loss: 0.555859, Accuracy: 81.36%\n",
            "Epoch: 17, Step: 59/164, Loss: 0.556841, Accuracy: 81.26%\n",
            "Epoch: 17, Step: 60/164, Loss: 0.557494, Accuracy: 81.21%\n",
            "Epoch: 17, Step: 61/164, Loss: 0.556732, Accuracy: 81.30%\n",
            "Epoch: 17, Step: 62/164, Loss: 0.553939, Accuracy: 81.43%\n",
            "Epoch: 17, Step: 63/164, Loss: 0.554692, Accuracy: 81.34%\n",
            "Epoch: 17, Step: 64/164, Loss: 0.553829, Accuracy: 81.34%\n",
            "Epoch: 17, Step: 65/164, Loss: 0.552091, Accuracy: 81.41%\n",
            "Epoch: 17, Step: 66/164, Loss: 0.550531, Accuracy: 81.46%\n",
            "Epoch: 17, Step: 67/164, Loss: 0.548018, Accuracy: 81.58%\n",
            "Epoch: 17, Step: 68/164, Loss: 0.550328, Accuracy: 81.48%\n",
            "Epoch: 17, Step: 69/164, Loss: 0.549180, Accuracy: 81.47%\n",
            "Epoch: 17, Step: 70/164, Loss: 0.546363, Accuracy: 81.57%\n",
            "Epoch: 17, Step: 71/164, Loss: 0.548062, Accuracy: 81.53%\n",
            "Epoch: 17, Step: 72/164, Loss: 0.546716, Accuracy: 81.55%\n",
            "Epoch: 17, Step: 73/164, Loss: 0.545726, Accuracy: 81.59%\n",
            "Epoch: 17, Step: 74/164, Loss: 0.545620, Accuracy: 81.58%\n",
            "Epoch: 17, Step: 75/164, Loss: 0.546387, Accuracy: 81.58%\n",
            "Epoch: 17, Step: 76/164, Loss: 0.546441, Accuracy: 81.56%\n",
            "Epoch: 17, Step: 77/164, Loss: 0.547987, Accuracy: 81.44%\n",
            "Epoch: 17, Step: 78/164, Loss: 0.547038, Accuracy: 81.45%\n",
            "Epoch: 17, Step: 79/164, Loss: 0.546650, Accuracy: 81.44%\n",
            "Epoch: 17, Step: 80/164, Loss: 0.547915, Accuracy: 81.41%\n",
            "Epoch: 17, Step: 81/164, Loss: 0.546479, Accuracy: 81.48%\n",
            "Epoch: 17, Step: 82/164, Loss: 0.545984, Accuracy: 81.48%\n",
            "Epoch: 17, Step: 83/164, Loss: 0.545411, Accuracy: 81.49%\n",
            "Epoch: 17, Step: 84/164, Loss: 0.545518, Accuracy: 81.44%\n",
            "Epoch: 17, Step: 85/164, Loss: 0.545699, Accuracy: 81.42%\n",
            "Epoch: 17, Step: 86/164, Loss: 0.545153, Accuracy: 81.44%\n",
            "Epoch: 17, Step: 87/164, Loss: 0.544873, Accuracy: 81.44%\n",
            "Epoch: 17, Step: 88/164, Loss: 0.547481, Accuracy: 81.40%\n",
            "Epoch: 17, Step: 89/164, Loss: 0.549144, Accuracy: 81.42%\n",
            "Epoch: 17, Step: 90/164, Loss: 0.548124, Accuracy: 81.46%\n",
            "Epoch: 17, Step: 91/164, Loss: 0.548239, Accuracy: 81.47%\n",
            "Epoch: 17, Step: 92/164, Loss: 0.550359, Accuracy: 81.40%\n",
            "Epoch: 17, Step: 93/164, Loss: 0.550512, Accuracy: 81.41%\n",
            "Epoch: 17, Step: 94/164, Loss: 0.550933, Accuracy: 81.37%\n",
            "Epoch: 17, Step: 95/164, Loss: 0.550008, Accuracy: 81.41%\n",
            "Epoch: 17, Step: 96/164, Loss: 0.552400, Accuracy: 81.32%\n",
            "Epoch: 17, Step: 97/164, Loss: 0.551043, Accuracy: 81.31%\n",
            "Epoch: 17, Step: 98/164, Loss: 0.552571, Accuracy: 81.27%\n",
            "Epoch: 17, Step: 99/164, Loss: 0.552282, Accuracy: 81.30%\n",
            "Epoch: 17, Step: 100/164, Loss: 0.554039, Accuracy: 81.21%\n",
            "Epoch: 17, Step: 101/164, Loss: 0.554077, Accuracy: 81.20%\n",
            "Epoch: 17, Step: 102/164, Loss: 0.554804, Accuracy: 81.20%\n",
            "Epoch: 17, Step: 103/164, Loss: 0.555121, Accuracy: 81.20%\n",
            "Epoch: 17, Step: 104/164, Loss: 0.554745, Accuracy: 81.21%\n",
            "Epoch: 17, Step: 105/164, Loss: 0.553014, Accuracy: 81.29%\n",
            "Epoch: 17, Step: 106/164, Loss: 0.552860, Accuracy: 81.29%\n",
            "Epoch: 17, Step: 107/164, Loss: 0.553331, Accuracy: 81.29%\n",
            "Epoch: 17, Step: 108/164, Loss: 0.552302, Accuracy: 81.32%\n",
            "Epoch: 17, Step: 109/164, Loss: 0.551649, Accuracy: 81.36%\n",
            "Epoch: 17, Step: 110/164, Loss: 0.550793, Accuracy: 81.36%\n",
            "Epoch: 17, Step: 111/164, Loss: 0.549869, Accuracy: 81.39%\n",
            "Epoch: 17, Step: 112/164, Loss: 0.549792, Accuracy: 81.40%\n",
            "Epoch: 17, Step: 113/164, Loss: 0.549793, Accuracy: 81.38%\n",
            "Epoch: 17, Step: 114/164, Loss: 0.548436, Accuracy: 81.44%\n",
            "Epoch: 17, Step: 115/164, Loss: 0.549619, Accuracy: 81.42%\n",
            "Epoch: 17, Step: 116/164, Loss: 0.549234, Accuracy: 81.41%\n",
            "Epoch: 17, Step: 117/164, Loss: 0.548053, Accuracy: 81.47%\n",
            "Epoch: 17, Step: 118/164, Loss: 0.549022, Accuracy: 81.45%\n",
            "Epoch: 17, Step: 119/164, Loss: 0.548608, Accuracy: 81.47%\n",
            "Epoch: 17, Step: 120/164, Loss: 0.549123, Accuracy: 81.48%\n",
            "Epoch: 17, Step: 121/164, Loss: 0.550011, Accuracy: 81.42%\n",
            "Epoch: 17, Step: 122/164, Loss: 0.550083, Accuracy: 81.42%\n",
            "Epoch: 17, Step: 123/164, Loss: 0.550870, Accuracy: 81.38%\n",
            "Epoch: 17, Step: 124/164, Loss: 0.550870, Accuracy: 81.39%\n",
            "Epoch: 17, Step: 125/164, Loss: 0.549949, Accuracy: 81.41%\n",
            "Epoch: 17, Step: 126/164, Loss: 0.551342, Accuracy: 81.37%\n",
            "Epoch: 17, Step: 127/164, Loss: 0.552355, Accuracy: 81.33%\n",
            "Epoch: 17, Step: 128/164, Loss: 0.551450, Accuracy: 81.37%\n",
            "Epoch: 17, Step: 129/164, Loss: 0.552101, Accuracy: 81.34%\n",
            "Epoch: 17, Step: 130/164, Loss: 0.552946, Accuracy: 81.30%\n",
            "Epoch: 17, Step: 131/164, Loss: 0.551843, Accuracy: 81.36%\n",
            "Epoch: 17, Step: 132/164, Loss: 0.551326, Accuracy: 81.36%\n",
            "Epoch: 17, Step: 133/164, Loss: 0.550889, Accuracy: 81.39%\n",
            "Epoch: 17, Step: 134/164, Loss: 0.550418, Accuracy: 81.40%\n",
            "Epoch: 17, Step: 135/164, Loss: 0.550524, Accuracy: 81.41%\n",
            "Epoch: 17, Step: 136/164, Loss: 0.550905, Accuracy: 81.41%\n",
            "Epoch: 17, Step: 137/164, Loss: 0.552130, Accuracy: 81.35%\n",
            "Epoch: 17, Step: 138/164, Loss: 0.552262, Accuracy: 81.35%\n",
            "Epoch: 17, Step: 139/164, Loss: 0.551747, Accuracy: 81.37%\n",
            "Epoch: 17, Step: 140/164, Loss: 0.551012, Accuracy: 81.40%\n",
            "Epoch: 17, Step: 141/164, Loss: 0.550941, Accuracy: 81.39%\n",
            "Epoch: 17, Step: 142/164, Loss: 0.550590, Accuracy: 81.39%\n",
            "Epoch: 17, Step: 143/164, Loss: 0.550197, Accuracy: 81.41%\n",
            "Epoch: 17, Step: 144/164, Loss: 0.550838, Accuracy: 81.41%\n",
            "Epoch: 17, Step: 145/164, Loss: 0.550846, Accuracy: 81.39%\n",
            "Epoch: 17, Step: 146/164, Loss: 0.552800, Accuracy: 81.35%\n",
            "Epoch: 17, Step: 147/164, Loss: 0.552255, Accuracy: 81.36%\n",
            "Epoch: 17, Step: 148/164, Loss: 0.552194, Accuracy: 81.38%\n",
            "Epoch: 17, Step: 149/164, Loss: 0.551698, Accuracy: 81.40%\n",
            "Epoch: 17, Step: 150/164, Loss: 0.551603, Accuracy: 81.39%\n",
            "Epoch: 17, Step: 151/164, Loss: 0.551954, Accuracy: 81.39%\n",
            "Epoch: 17, Step: 152/164, Loss: 0.552269, Accuracy: 81.40%\n",
            "Epoch: 17, Step: 153/164, Loss: 0.551737, Accuracy: 81.42%\n",
            "Epoch: 17, Step: 154/164, Loss: 0.551196, Accuracy: 81.43%\n",
            "Epoch: 17, Step: 155/164, Loss: 0.551017, Accuracy: 81.43%\n",
            "Epoch: 17, Step: 156/164, Loss: 0.551965, Accuracy: 81.40%\n",
            "Epoch: 17, Step: 157/164, Loss: 0.552648, Accuracy: 81.36%\n",
            "Epoch: 17, Step: 158/164, Loss: 0.553270, Accuracy: 81.34%\n",
            "Epoch: 17, Step: 159/164, Loss: 0.553187, Accuracy: 81.33%\n",
            "Epoch: 17, Step: 160/164, Loss: 0.553076, Accuracy: 81.34%\n",
            "Epoch: 17, Step: 161/164, Loss: 0.551876, Accuracy: 81.39%\n",
            "Epoch: 17, Step: 162/164, Loss: 0.552167, Accuracy: 81.38%\n",
            "Epoch: 17, Step: 163/164, Loss: 0.552856, Accuracy: 81.35%\n",
            "Epoch: 17, Step: 164/164, Loss: 0.553325, Accuracy: 81.34%\n",
            "Epoch: 18, Step: 1/164, Loss: 0.634704, Accuracy: 75.00%\n",
            "Epoch: 18, Step: 2/164, Loss: 0.665161, Accuracy: 75.00%\n",
            "Epoch: 18, Step: 3/164, Loss: 0.608032, Accuracy: 77.08%\n",
            "Epoch: 18, Step: 4/164, Loss: 0.582531, Accuracy: 79.49%\n",
            "Epoch: 18, Step: 5/164, Loss: 0.574648, Accuracy: 80.16%\n",
            "Epoch: 18, Step: 6/164, Loss: 0.569878, Accuracy: 80.34%\n",
            "Epoch: 18, Step: 7/164, Loss: 0.555340, Accuracy: 81.14%\n",
            "Epoch: 18, Step: 8/164, Loss: 0.573117, Accuracy: 80.47%\n",
            "Epoch: 18, Step: 9/164, Loss: 0.565187, Accuracy: 80.90%\n",
            "Epoch: 18, Step: 10/164, Loss: 0.564894, Accuracy: 80.94%\n",
            "Epoch: 18, Step: 11/164, Loss: 0.554410, Accuracy: 81.25%\n",
            "Epoch: 18, Step: 12/164, Loss: 0.548059, Accuracy: 81.38%\n",
            "Epoch: 18, Step: 13/164, Loss: 0.558270, Accuracy: 80.89%\n",
            "Epoch: 18, Step: 14/164, Loss: 0.550330, Accuracy: 81.14%\n",
            "Epoch: 18, Step: 15/164, Loss: 0.550307, Accuracy: 81.46%\n",
            "Epoch: 18, Step: 16/164, Loss: 0.555255, Accuracy: 81.30%\n",
            "Epoch: 18, Step: 17/164, Loss: 0.552439, Accuracy: 81.11%\n",
            "Epoch: 18, Step: 18/164, Loss: 0.554431, Accuracy: 81.08%\n",
            "Epoch: 18, Step: 19/164, Loss: 0.545735, Accuracy: 81.41%\n",
            "Epoch: 18, Step: 20/164, Loss: 0.542340, Accuracy: 81.45%\n",
            "Epoch: 18, Step: 21/164, Loss: 0.542945, Accuracy: 81.36%\n",
            "Epoch: 18, Step: 22/164, Loss: 0.543489, Accuracy: 81.46%\n",
            "Epoch: 18, Step: 23/164, Loss: 0.543605, Accuracy: 81.28%\n",
            "Epoch: 18, Step: 24/164, Loss: 0.548624, Accuracy: 81.18%\n",
            "Epoch: 18, Step: 25/164, Loss: 0.547761, Accuracy: 81.25%\n",
            "Epoch: 18, Step: 26/164, Loss: 0.546658, Accuracy: 81.40%\n",
            "Epoch: 18, Step: 27/164, Loss: 0.545923, Accuracy: 81.39%\n",
            "Epoch: 18, Step: 28/164, Loss: 0.546122, Accuracy: 81.33%\n",
            "Epoch: 18, Step: 29/164, Loss: 0.544973, Accuracy: 81.36%\n",
            "Epoch: 18, Step: 30/164, Loss: 0.550393, Accuracy: 81.07%\n",
            "Epoch: 18, Step: 31/164, Loss: 0.552884, Accuracy: 80.97%\n",
            "Epoch: 18, Step: 32/164, Loss: 0.546675, Accuracy: 81.10%\n",
            "Epoch: 18, Step: 33/164, Loss: 0.544882, Accuracy: 81.25%\n",
            "Epoch: 18, Step: 34/164, Loss: 0.546283, Accuracy: 81.20%\n",
            "Epoch: 18, Step: 35/164, Loss: 0.543504, Accuracy: 81.32%\n",
            "Epoch: 18, Step: 36/164, Loss: 0.544462, Accuracy: 81.25%\n",
            "Epoch: 18, Step: 37/164, Loss: 0.544619, Accuracy: 81.23%\n",
            "Epoch: 18, Step: 38/164, Loss: 0.546862, Accuracy: 81.19%\n",
            "Epoch: 18, Step: 39/164, Loss: 0.546460, Accuracy: 81.15%\n",
            "Epoch: 18, Step: 40/164, Loss: 0.544422, Accuracy: 81.21%\n",
            "Epoch: 18, Step: 41/164, Loss: 0.542964, Accuracy: 81.25%\n",
            "Epoch: 18, Step: 42/164, Loss: 0.541793, Accuracy: 81.21%\n",
            "Epoch: 18, Step: 43/164, Loss: 0.540536, Accuracy: 81.29%\n",
            "Epoch: 18, Step: 44/164, Loss: 0.539235, Accuracy: 81.32%\n",
            "Epoch: 18, Step: 45/164, Loss: 0.537523, Accuracy: 81.35%\n",
            "Epoch: 18, Step: 46/164, Loss: 0.535675, Accuracy: 81.35%\n",
            "Epoch: 18, Step: 47/164, Loss: 0.534521, Accuracy: 81.37%\n",
            "Epoch: 18, Step: 48/164, Loss: 0.532247, Accuracy: 81.45%\n",
            "Epoch: 18, Step: 49/164, Loss: 0.534605, Accuracy: 81.36%\n",
            "Epoch: 18, Step: 50/164, Loss: 0.535415, Accuracy: 81.31%\n",
            "Epoch: 18, Step: 51/164, Loss: 0.537124, Accuracy: 81.23%\n",
            "Epoch: 18, Step: 52/164, Loss: 0.537133, Accuracy: 81.22%\n",
            "Epoch: 18, Step: 53/164, Loss: 0.537504, Accuracy: 81.21%\n",
            "Epoch: 18, Step: 54/164, Loss: 0.537993, Accuracy: 81.19%\n",
            "Epoch: 18, Step: 55/164, Loss: 0.539831, Accuracy: 81.18%\n",
            "Epoch: 18, Step: 56/164, Loss: 0.540847, Accuracy: 81.21%\n",
            "Epoch: 18, Step: 57/164, Loss: 0.543581, Accuracy: 81.09%\n",
            "Epoch: 18, Step: 58/164, Loss: 0.542975, Accuracy: 81.14%\n",
            "Epoch: 18, Step: 59/164, Loss: 0.542983, Accuracy: 81.22%\n",
            "Epoch: 18, Step: 60/164, Loss: 0.544495, Accuracy: 81.25%\n",
            "Epoch: 18, Step: 61/164, Loss: 0.542308, Accuracy: 81.37%\n",
            "Epoch: 18, Step: 62/164, Loss: 0.540940, Accuracy: 81.39%\n",
            "Epoch: 18, Step: 63/164, Loss: 0.541638, Accuracy: 81.37%\n",
            "Epoch: 18, Step: 64/164, Loss: 0.539307, Accuracy: 81.47%\n",
            "Epoch: 18, Step: 65/164, Loss: 0.539770, Accuracy: 81.41%\n",
            "Epoch: 18, Step: 66/164, Loss: 0.539082, Accuracy: 81.45%\n",
            "Epoch: 18, Step: 67/164, Loss: 0.539124, Accuracy: 81.42%\n",
            "Epoch: 18, Step: 68/164, Loss: 0.538040, Accuracy: 81.45%\n",
            "Epoch: 18, Step: 69/164, Loss: 0.538255, Accuracy: 81.45%\n",
            "Epoch: 18, Step: 70/164, Loss: 0.537542, Accuracy: 81.51%\n",
            "Epoch: 18, Step: 71/164, Loss: 0.537389, Accuracy: 81.53%\n",
            "Epoch: 18, Step: 72/164, Loss: 0.537775, Accuracy: 81.54%\n",
            "Epoch: 18, Step: 73/164, Loss: 0.538529, Accuracy: 81.52%\n",
            "Epoch: 18, Step: 74/164, Loss: 0.539017, Accuracy: 81.45%\n",
            "Epoch: 18, Step: 75/164, Loss: 0.537315, Accuracy: 81.50%\n",
            "Epoch: 18, Step: 76/164, Loss: 0.535538, Accuracy: 81.57%\n",
            "Epoch: 18, Step: 77/164, Loss: 0.535007, Accuracy: 81.57%\n",
            "Epoch: 18, Step: 78/164, Loss: 0.534211, Accuracy: 81.63%\n",
            "Epoch: 18, Step: 79/164, Loss: 0.534567, Accuracy: 81.60%\n",
            "Epoch: 18, Step: 80/164, Loss: 0.533903, Accuracy: 81.62%\n",
            "Epoch: 18, Step: 81/164, Loss: 0.533032, Accuracy: 81.65%\n",
            "Epoch: 18, Step: 82/164, Loss: 0.531653, Accuracy: 81.74%\n",
            "Epoch: 18, Step: 83/164, Loss: 0.533126, Accuracy: 81.70%\n",
            "Epoch: 18, Step: 84/164, Loss: 0.532387, Accuracy: 81.72%\n",
            "Epoch: 18, Step: 85/164, Loss: 0.531265, Accuracy: 81.76%\n",
            "Epoch: 18, Step: 86/164, Loss: 0.531309, Accuracy: 81.74%\n",
            "Epoch: 18, Step: 87/164, Loss: 0.531787, Accuracy: 81.71%\n",
            "Epoch: 18, Step: 88/164, Loss: 0.530487, Accuracy: 81.79%\n",
            "Epoch: 18, Step: 89/164, Loss: 0.529772, Accuracy: 81.85%\n",
            "Epoch: 18, Step: 90/164, Loss: 0.530407, Accuracy: 81.85%\n",
            "Epoch: 18, Step: 91/164, Loss: 0.531627, Accuracy: 81.85%\n",
            "Epoch: 18, Step: 92/164, Loss: 0.532092, Accuracy: 81.88%\n",
            "Epoch: 18, Step: 93/164, Loss: 0.533814, Accuracy: 81.84%\n",
            "Epoch: 18, Step: 94/164, Loss: 0.534725, Accuracy: 81.82%\n",
            "Epoch: 18, Step: 95/164, Loss: 0.536423, Accuracy: 81.79%\n",
            "Epoch: 18, Step: 96/164, Loss: 0.535030, Accuracy: 81.85%\n",
            "Epoch: 18, Step: 97/164, Loss: 0.534728, Accuracy: 81.85%\n",
            "Epoch: 18, Step: 98/164, Loss: 0.534751, Accuracy: 81.86%\n",
            "Epoch: 18, Step: 99/164, Loss: 0.534449, Accuracy: 81.87%\n",
            "Epoch: 18, Step: 100/164, Loss: 0.534269, Accuracy: 81.89%\n",
            "Epoch: 18, Step: 101/164, Loss: 0.533276, Accuracy: 81.91%\n",
            "Epoch: 18, Step: 102/164, Loss: 0.533982, Accuracy: 81.87%\n",
            "Epoch: 18, Step: 103/164, Loss: 0.532722, Accuracy: 81.92%\n",
            "Epoch: 18, Step: 104/164, Loss: 0.532218, Accuracy: 81.94%\n",
            "Epoch: 18, Step: 105/164, Loss: 0.532279, Accuracy: 81.92%\n",
            "Epoch: 18, Step: 106/164, Loss: 0.532130, Accuracy: 81.94%\n",
            "Epoch: 18, Step: 107/164, Loss: 0.532678, Accuracy: 81.94%\n",
            "Epoch: 18, Step: 108/164, Loss: 0.532563, Accuracy: 81.94%\n",
            "Epoch: 18, Step: 109/164, Loss: 0.532698, Accuracy: 81.96%\n",
            "Epoch: 18, Step: 110/164, Loss: 0.531895, Accuracy: 82.00%\n",
            "Epoch: 18, Step: 111/164, Loss: 0.530864, Accuracy: 82.03%\n",
            "Epoch: 18, Step: 112/164, Loss: 0.531892, Accuracy: 82.00%\n",
            "Epoch: 18, Step: 113/164, Loss: 0.531900, Accuracy: 81.99%\n",
            "Epoch: 18, Step: 114/164, Loss: 0.530583, Accuracy: 82.04%\n",
            "Epoch: 18, Step: 115/164, Loss: 0.532245, Accuracy: 82.01%\n",
            "Epoch: 18, Step: 116/164, Loss: 0.532269, Accuracy: 82.02%\n",
            "Epoch: 18, Step: 117/164, Loss: 0.532886, Accuracy: 82.02%\n",
            "Epoch: 18, Step: 118/164, Loss: 0.532728, Accuracy: 82.02%\n",
            "Epoch: 18, Step: 119/164, Loss: 0.532982, Accuracy: 82.02%\n",
            "Epoch: 18, Step: 120/164, Loss: 0.534554, Accuracy: 81.97%\n",
            "Epoch: 18, Step: 121/164, Loss: 0.534594, Accuracy: 81.98%\n",
            "Epoch: 18, Step: 122/164, Loss: 0.535662, Accuracy: 81.94%\n",
            "Epoch: 18, Step: 123/164, Loss: 0.535444, Accuracy: 81.96%\n",
            "Epoch: 18, Step: 124/164, Loss: 0.535652, Accuracy: 81.97%\n",
            "Epoch: 18, Step: 125/164, Loss: 0.535981, Accuracy: 81.94%\n",
            "Epoch: 18, Step: 126/164, Loss: 0.536332, Accuracy: 81.94%\n",
            "Epoch: 18, Step: 127/164, Loss: 0.536519, Accuracy: 81.93%\n",
            "Epoch: 18, Step: 128/164, Loss: 0.535937, Accuracy: 81.95%\n",
            "Epoch: 18, Step: 129/164, Loss: 0.536346, Accuracy: 81.96%\n",
            "Epoch: 18, Step: 130/164, Loss: 0.535820, Accuracy: 81.98%\n",
            "Epoch: 18, Step: 131/164, Loss: 0.535600, Accuracy: 81.99%\n",
            "Epoch: 18, Step: 132/164, Loss: 0.535201, Accuracy: 82.01%\n",
            "Epoch: 18, Step: 133/164, Loss: 0.534657, Accuracy: 82.00%\n",
            "Epoch: 18, Step: 134/164, Loss: 0.534379, Accuracy: 82.00%\n",
            "Epoch: 18, Step: 135/164, Loss: 0.533990, Accuracy: 82.00%\n",
            "Epoch: 18, Step: 136/164, Loss: 0.532641, Accuracy: 82.05%\n",
            "Epoch: 18, Step: 137/164, Loss: 0.531890, Accuracy: 82.08%\n",
            "Epoch: 18, Step: 138/164, Loss: 0.533078, Accuracy: 82.01%\n",
            "Epoch: 18, Step: 139/164, Loss: 0.532538, Accuracy: 82.02%\n",
            "Epoch: 18, Step: 140/164, Loss: 0.533224, Accuracy: 82.01%\n",
            "Epoch: 18, Step: 141/164, Loss: 0.533003, Accuracy: 82.01%\n",
            "Epoch: 18, Step: 142/164, Loss: 0.532006, Accuracy: 82.04%\n",
            "Epoch: 18, Step: 143/164, Loss: 0.531953, Accuracy: 82.05%\n",
            "Epoch: 18, Step: 144/164, Loss: 0.532044, Accuracy: 82.04%\n",
            "Epoch: 18, Step: 145/164, Loss: 0.531341, Accuracy: 82.06%\n",
            "Epoch: 18, Step: 146/164, Loss: 0.531153, Accuracy: 82.07%\n",
            "Epoch: 18, Step: 147/164, Loss: 0.530610, Accuracy: 82.11%\n",
            "Epoch: 18, Step: 148/164, Loss: 0.530980, Accuracy: 82.09%\n",
            "Epoch: 18, Step: 149/164, Loss: 0.531686, Accuracy: 82.06%\n",
            "Epoch: 18, Step: 150/164, Loss: 0.531330, Accuracy: 82.09%\n",
            "Epoch: 18, Step: 151/164, Loss: 0.530824, Accuracy: 82.09%\n",
            "Epoch: 18, Step: 152/164, Loss: 0.530995, Accuracy: 82.08%\n",
            "Epoch: 18, Step: 153/164, Loss: 0.530719, Accuracy: 82.11%\n",
            "Epoch: 18, Step: 154/164, Loss: 0.530037, Accuracy: 82.13%\n",
            "Epoch: 18, Step: 155/164, Loss: 0.529894, Accuracy: 82.16%\n",
            "Epoch: 18, Step: 156/164, Loss: 0.530004, Accuracy: 82.17%\n",
            "Epoch: 18, Step: 157/164, Loss: 0.529824, Accuracy: 82.17%\n",
            "Epoch: 18, Step: 158/164, Loss: 0.531225, Accuracy: 82.11%\n",
            "Epoch: 18, Step: 159/164, Loss: 0.531898, Accuracy: 82.08%\n",
            "Epoch: 18, Step: 160/164, Loss: 0.531526, Accuracy: 82.10%\n",
            "Epoch: 18, Step: 161/164, Loss: 0.531708, Accuracy: 82.09%\n",
            "Epoch: 18, Step: 162/164, Loss: 0.531845, Accuracy: 82.10%\n",
            "Epoch: 18, Step: 163/164, Loss: 0.531863, Accuracy: 82.10%\n",
            "Epoch: 18, Step: 164/164, Loss: 0.532599, Accuracy: 82.07%\n",
            "Epoch: 19, Step: 1/164, Loss: 0.473558, Accuracy: 85.94%\n",
            "Epoch: 19, Step: 2/164, Loss: 0.484577, Accuracy: 85.55%\n",
            "Epoch: 19, Step: 3/164, Loss: 0.510363, Accuracy: 83.33%\n",
            "Epoch: 19, Step: 4/164, Loss: 0.496868, Accuracy: 83.20%\n",
            "Epoch: 19, Step: 5/164, Loss: 0.508781, Accuracy: 83.12%\n",
            "Epoch: 19, Step: 6/164, Loss: 0.523798, Accuracy: 82.68%\n",
            "Epoch: 19, Step: 7/164, Loss: 0.519912, Accuracy: 82.70%\n",
            "Epoch: 19, Step: 8/164, Loss: 0.534775, Accuracy: 82.32%\n",
            "Epoch: 19, Step: 9/164, Loss: 0.551963, Accuracy: 81.86%\n",
            "Epoch: 19, Step: 10/164, Loss: 0.544339, Accuracy: 82.03%\n",
            "Epoch: 19, Step: 11/164, Loss: 0.546252, Accuracy: 82.24%\n",
            "Epoch: 19, Step: 12/164, Loss: 0.543688, Accuracy: 82.36%\n",
            "Epoch: 19, Step: 13/164, Loss: 0.549621, Accuracy: 82.15%\n",
            "Epoch: 19, Step: 14/164, Loss: 0.543640, Accuracy: 82.37%\n",
            "Epoch: 19, Step: 15/164, Loss: 0.545828, Accuracy: 82.45%\n",
            "Epoch: 19, Step: 16/164, Loss: 0.545717, Accuracy: 82.18%\n",
            "Epoch: 19, Step: 17/164, Loss: 0.534630, Accuracy: 82.44%\n",
            "Epoch: 19, Step: 18/164, Loss: 0.524483, Accuracy: 82.64%\n",
            "Epoch: 19, Step: 19/164, Loss: 0.522170, Accuracy: 82.61%\n",
            "Epoch: 19, Step: 20/164, Loss: 0.523103, Accuracy: 82.46%\n",
            "Epoch: 19, Step: 21/164, Loss: 0.517623, Accuracy: 82.59%\n",
            "Epoch: 19, Step: 22/164, Loss: 0.512489, Accuracy: 82.63%\n",
            "Epoch: 19, Step: 23/164, Loss: 0.517506, Accuracy: 82.71%\n",
            "Epoch: 19, Step: 24/164, Loss: 0.514600, Accuracy: 82.68%\n",
            "Epoch: 19, Step: 25/164, Loss: 0.513068, Accuracy: 82.75%\n",
            "Epoch: 19, Step: 26/164, Loss: 0.510914, Accuracy: 82.99%\n",
            "Epoch: 19, Step: 27/164, Loss: 0.514755, Accuracy: 82.75%\n",
            "Epoch: 19, Step: 28/164, Loss: 0.519225, Accuracy: 82.48%\n",
            "Epoch: 19, Step: 29/164, Loss: 0.518001, Accuracy: 82.38%\n",
            "Epoch: 19, Step: 30/164, Loss: 0.521410, Accuracy: 82.21%\n",
            "Epoch: 19, Step: 31/164, Loss: 0.527680, Accuracy: 82.11%\n",
            "Epoch: 19, Step: 32/164, Loss: 0.523425, Accuracy: 82.30%\n",
            "Epoch: 19, Step: 33/164, Loss: 0.525018, Accuracy: 82.13%\n",
            "Epoch: 19, Step: 34/164, Loss: 0.525467, Accuracy: 82.08%\n",
            "Epoch: 19, Step: 35/164, Loss: 0.523037, Accuracy: 82.25%\n",
            "Epoch: 19, Step: 36/164, Loss: 0.528849, Accuracy: 82.05%\n",
            "Epoch: 19, Step: 37/164, Loss: 0.528518, Accuracy: 82.03%\n",
            "Epoch: 19, Step: 38/164, Loss: 0.530034, Accuracy: 81.99%\n",
            "Epoch: 19, Step: 39/164, Loss: 0.527927, Accuracy: 82.07%\n",
            "Epoch: 19, Step: 40/164, Loss: 0.524394, Accuracy: 82.21%\n",
            "Epoch: 19, Step: 41/164, Loss: 0.522378, Accuracy: 82.30%\n",
            "Epoch: 19, Step: 42/164, Loss: 0.521945, Accuracy: 82.27%\n",
            "Epoch: 19, Step: 43/164, Loss: 0.520165, Accuracy: 82.38%\n",
            "Epoch: 19, Step: 44/164, Loss: 0.518723, Accuracy: 82.42%\n",
            "Epoch: 19, Step: 45/164, Loss: 0.518740, Accuracy: 82.45%\n",
            "Epoch: 19, Step: 46/164, Loss: 0.520208, Accuracy: 82.35%\n",
            "Epoch: 19, Step: 47/164, Loss: 0.519814, Accuracy: 82.38%\n",
            "Epoch: 19, Step: 48/164, Loss: 0.517411, Accuracy: 82.45%\n",
            "Epoch: 19, Step: 49/164, Loss: 0.515367, Accuracy: 82.51%\n",
            "Epoch: 19, Step: 50/164, Loss: 0.516556, Accuracy: 82.48%\n",
            "Epoch: 19, Step: 51/164, Loss: 0.515579, Accuracy: 82.57%\n",
            "Epoch: 19, Step: 52/164, Loss: 0.516407, Accuracy: 82.50%\n",
            "Epoch: 19, Step: 53/164, Loss: 0.516371, Accuracy: 82.53%\n",
            "Epoch: 19, Step: 54/164, Loss: 0.516311, Accuracy: 82.48%\n",
            "Epoch: 19, Step: 55/164, Loss: 0.516590, Accuracy: 82.50%\n",
            "Epoch: 19, Step: 56/164, Loss: 0.518334, Accuracy: 82.52%\n",
            "Epoch: 19, Step: 57/164, Loss: 0.517271, Accuracy: 82.54%\n",
            "Epoch: 19, Step: 58/164, Loss: 0.520346, Accuracy: 82.39%\n",
            "Epoch: 19, Step: 59/164, Loss: 0.521752, Accuracy: 82.39%\n",
            "Epoch: 19, Step: 60/164, Loss: 0.521171, Accuracy: 82.38%\n",
            "Epoch: 19, Step: 61/164, Loss: 0.519937, Accuracy: 82.39%\n",
            "Epoch: 19, Step: 62/164, Loss: 0.519965, Accuracy: 82.40%\n",
            "Epoch: 19, Step: 63/164, Loss: 0.519258, Accuracy: 82.38%\n",
            "Epoch: 19, Step: 64/164, Loss: 0.518314, Accuracy: 82.45%\n",
            "Epoch: 19, Step: 65/164, Loss: 0.519345, Accuracy: 82.49%\n",
            "Epoch: 19, Step: 66/164, Loss: 0.519828, Accuracy: 82.50%\n",
            "Epoch: 19, Step: 67/164, Loss: 0.519881, Accuracy: 82.52%\n",
            "Epoch: 19, Step: 68/164, Loss: 0.518027, Accuracy: 82.59%\n",
            "Epoch: 19, Step: 69/164, Loss: 0.521043, Accuracy: 82.54%\n",
            "Epoch: 19, Step: 70/164, Loss: 0.519965, Accuracy: 82.56%\n",
            "Epoch: 19, Step: 71/164, Loss: 0.520192, Accuracy: 82.54%\n",
            "Epoch: 19, Step: 72/164, Loss: 0.521344, Accuracy: 82.56%\n",
            "Epoch: 19, Step: 73/164, Loss: 0.520980, Accuracy: 82.63%\n",
            "Epoch: 19, Step: 74/164, Loss: 0.519840, Accuracy: 82.66%\n",
            "Epoch: 19, Step: 75/164, Loss: 0.518639, Accuracy: 82.71%\n",
            "Epoch: 19, Step: 76/164, Loss: 0.518678, Accuracy: 82.71%\n",
            "Epoch: 19, Step: 77/164, Loss: 0.518908, Accuracy: 82.69%\n",
            "Epoch: 19, Step: 78/164, Loss: 0.516880, Accuracy: 82.80%\n",
            "Epoch: 19, Step: 79/164, Loss: 0.516939, Accuracy: 82.83%\n",
            "Epoch: 19, Step: 80/164, Loss: 0.516479, Accuracy: 82.83%\n",
            "Epoch: 19, Step: 81/164, Loss: 0.518404, Accuracy: 82.79%\n",
            "Epoch: 19, Step: 82/164, Loss: 0.517691, Accuracy: 82.80%\n",
            "Epoch: 19, Step: 83/164, Loss: 0.516629, Accuracy: 82.83%\n",
            "Epoch: 19, Step: 84/164, Loss: 0.517569, Accuracy: 82.85%\n",
            "Epoch: 19, Step: 85/164, Loss: 0.516552, Accuracy: 82.86%\n",
            "Epoch: 19, Step: 86/164, Loss: 0.516713, Accuracy: 82.84%\n",
            "Epoch: 19, Step: 87/164, Loss: 0.515428, Accuracy: 82.90%\n",
            "Epoch: 19, Step: 88/164, Loss: 0.515017, Accuracy: 82.95%\n",
            "Epoch: 19, Step: 89/164, Loss: 0.515176, Accuracy: 82.94%\n",
            "Epoch: 19, Step: 90/164, Loss: 0.514791, Accuracy: 82.97%\n",
            "Epoch: 19, Step: 91/164, Loss: 0.515437, Accuracy: 82.92%\n",
            "Epoch: 19, Step: 92/164, Loss: 0.516022, Accuracy: 82.91%\n",
            "Epoch: 19, Step: 93/164, Loss: 0.514785, Accuracy: 82.96%\n",
            "Epoch: 19, Step: 94/164, Loss: 0.514858, Accuracy: 82.95%\n",
            "Epoch: 19, Step: 95/164, Loss: 0.515355, Accuracy: 82.98%\n",
            "Epoch: 19, Step: 96/164, Loss: 0.514313, Accuracy: 83.00%\n",
            "Epoch: 19, Step: 97/164, Loss: 0.514879, Accuracy: 82.99%\n",
            "Epoch: 19, Step: 98/164, Loss: 0.515581, Accuracy: 82.96%\n",
            "Epoch: 19, Step: 99/164, Loss: 0.516662, Accuracy: 82.95%\n",
            "Epoch: 19, Step: 100/164, Loss: 0.516886, Accuracy: 82.95%\n",
            "Epoch: 19, Step: 101/164, Loss: 0.516734, Accuracy: 82.98%\n",
            "Epoch: 19, Step: 102/164, Loss: 0.517354, Accuracy: 82.94%\n",
            "Epoch: 19, Step: 103/164, Loss: 0.518471, Accuracy: 82.87%\n",
            "Epoch: 19, Step: 104/164, Loss: 0.519254, Accuracy: 82.80%\n",
            "Epoch: 19, Step: 105/164, Loss: 0.519078, Accuracy: 82.83%\n",
            "Epoch: 19, Step: 106/164, Loss: 0.519859, Accuracy: 82.81%\n",
            "Epoch: 19, Step: 107/164, Loss: 0.520363, Accuracy: 82.79%\n",
            "Epoch: 19, Step: 108/164, Loss: 0.521145, Accuracy: 82.78%\n",
            "Epoch: 19, Step: 109/164, Loss: 0.520438, Accuracy: 82.82%\n",
            "Epoch: 19, Step: 110/164, Loss: 0.519946, Accuracy: 82.84%\n",
            "Epoch: 19, Step: 111/164, Loss: 0.519683, Accuracy: 82.88%\n",
            "Epoch: 19, Step: 112/164, Loss: 0.519635, Accuracy: 82.88%\n",
            "Epoch: 19, Step: 113/164, Loss: 0.519535, Accuracy: 82.91%\n",
            "Epoch: 19, Step: 114/164, Loss: 0.520053, Accuracy: 82.88%\n",
            "Epoch: 19, Step: 115/164, Loss: 0.519871, Accuracy: 82.89%\n",
            "Epoch: 19, Step: 116/164, Loss: 0.519714, Accuracy: 82.87%\n",
            "Epoch: 19, Step: 117/164, Loss: 0.519997, Accuracy: 82.88%\n",
            "Epoch: 19, Step: 118/164, Loss: 0.521458, Accuracy: 82.85%\n",
            "Epoch: 19, Step: 119/164, Loss: 0.521689, Accuracy: 82.83%\n",
            "Epoch: 19, Step: 120/164, Loss: 0.521239, Accuracy: 82.83%\n",
            "Epoch: 19, Step: 121/164, Loss: 0.521857, Accuracy: 82.83%\n",
            "Epoch: 19, Step: 122/164, Loss: 0.522237, Accuracy: 82.83%\n",
            "Epoch: 19, Step: 123/164, Loss: 0.521586, Accuracy: 82.86%\n",
            "Epoch: 19, Step: 124/164, Loss: 0.522370, Accuracy: 82.83%\n",
            "Epoch: 19, Step: 125/164, Loss: 0.521498, Accuracy: 82.88%\n",
            "Epoch: 19, Step: 126/164, Loss: 0.522715, Accuracy: 82.82%\n",
            "Epoch: 19, Step: 127/164, Loss: 0.523739, Accuracy: 82.80%\n",
            "Epoch: 19, Step: 128/164, Loss: 0.523738, Accuracy: 82.79%\n",
            "Epoch: 19, Step: 129/164, Loss: 0.523241, Accuracy: 82.81%\n",
            "Epoch: 19, Step: 130/164, Loss: 0.522792, Accuracy: 82.80%\n",
            "Epoch: 19, Step: 131/164, Loss: 0.522287, Accuracy: 82.80%\n",
            "Epoch: 19, Step: 132/164, Loss: 0.523252, Accuracy: 82.75%\n",
            "Epoch: 19, Step: 133/164, Loss: 0.523399, Accuracy: 82.74%\n",
            "Epoch: 19, Step: 134/164, Loss: 0.522682, Accuracy: 82.77%\n",
            "Epoch: 19, Step: 135/164, Loss: 0.523046, Accuracy: 82.74%\n",
            "Epoch: 19, Step: 136/164, Loss: 0.522844, Accuracy: 82.75%\n",
            "Epoch: 19, Step: 137/164, Loss: 0.523476, Accuracy: 82.74%\n",
            "Epoch: 19, Step: 138/164, Loss: 0.524376, Accuracy: 82.71%\n",
            "Epoch: 19, Step: 139/164, Loss: 0.525066, Accuracy: 82.67%\n",
            "Epoch: 19, Step: 140/164, Loss: 0.524606, Accuracy: 82.68%\n",
            "Epoch: 19, Step: 141/164, Loss: 0.522902, Accuracy: 82.73%\n",
            "Epoch: 19, Step: 142/164, Loss: 0.522793, Accuracy: 82.72%\n",
            "Epoch: 19, Step: 143/164, Loss: 0.522023, Accuracy: 82.75%\n",
            "Epoch: 19, Step: 144/164, Loss: 0.521618, Accuracy: 82.76%\n",
            "Epoch: 19, Step: 145/164, Loss: 0.522584, Accuracy: 82.74%\n",
            "Epoch: 19, Step: 146/164, Loss: 0.522681, Accuracy: 82.73%\n",
            "Epoch: 19, Step: 147/164, Loss: 0.522539, Accuracy: 82.75%\n",
            "Epoch: 19, Step: 148/164, Loss: 0.523284, Accuracy: 82.75%\n",
            "Epoch: 19, Step: 149/164, Loss: 0.522390, Accuracy: 82.78%\n",
            "Epoch: 19, Step: 150/164, Loss: 0.522517, Accuracy: 82.77%\n",
            "Epoch: 19, Step: 151/164, Loss: 0.522571, Accuracy: 82.75%\n",
            "Epoch: 19, Step: 152/164, Loss: 0.523006, Accuracy: 82.72%\n",
            "Epoch: 19, Step: 153/164, Loss: 0.522804, Accuracy: 82.72%\n",
            "Epoch: 19, Step: 154/164, Loss: 0.522817, Accuracy: 82.71%\n",
            "Epoch: 19, Step: 155/164, Loss: 0.522858, Accuracy: 82.72%\n",
            "Epoch: 19, Step: 156/164, Loss: 0.523545, Accuracy: 82.71%\n",
            "Epoch: 19, Step: 157/164, Loss: 0.523058, Accuracy: 82.73%\n",
            "Epoch: 19, Step: 158/164, Loss: 0.523549, Accuracy: 82.70%\n",
            "Epoch: 19, Step: 159/164, Loss: 0.523529, Accuracy: 82.69%\n",
            "Epoch: 19, Step: 160/164, Loss: 0.523263, Accuracy: 82.70%\n",
            "Epoch: 19, Step: 161/164, Loss: 0.523540, Accuracy: 82.69%\n",
            "Epoch: 19, Step: 162/164, Loss: 0.523393, Accuracy: 82.69%\n",
            "Epoch: 19, Step: 163/164, Loss: 0.523345, Accuracy: 82.68%\n",
            "Epoch: 19, Step: 164/164, Loss: 0.524068, Accuracy: 82.64%\n",
            "Epoch: 20, Step: 1/164, Loss: 0.648789, Accuracy: 74.22%\n",
            "Epoch: 20, Step: 2/164, Loss: 0.552503, Accuracy: 79.69%\n",
            "Epoch: 20, Step: 3/164, Loss: 0.551183, Accuracy: 80.21%\n",
            "Epoch: 20, Step: 4/164, Loss: 0.561207, Accuracy: 79.88%\n",
            "Epoch: 20, Step: 5/164, Loss: 0.531801, Accuracy: 80.78%\n",
            "Epoch: 20, Step: 6/164, Loss: 0.544062, Accuracy: 79.82%\n",
            "Epoch: 20, Step: 7/164, Loss: 0.542461, Accuracy: 80.80%\n",
            "Epoch: 20, Step: 8/164, Loss: 0.523808, Accuracy: 81.35%\n",
            "Epoch: 20, Step: 9/164, Loss: 0.509176, Accuracy: 81.86%\n",
            "Epoch: 20, Step: 10/164, Loss: 0.503198, Accuracy: 82.50%\n",
            "Epoch: 20, Step: 11/164, Loss: 0.510542, Accuracy: 82.10%\n",
            "Epoch: 20, Step: 12/164, Loss: 0.517091, Accuracy: 81.77%\n",
            "Epoch: 20, Step: 13/164, Loss: 0.523009, Accuracy: 81.31%\n",
            "Epoch: 20, Step: 14/164, Loss: 0.514190, Accuracy: 81.86%\n",
            "Epoch: 20, Step: 15/164, Loss: 0.514796, Accuracy: 81.98%\n",
            "Epoch: 20, Step: 16/164, Loss: 0.516059, Accuracy: 81.93%\n",
            "Epoch: 20, Step: 17/164, Loss: 0.512918, Accuracy: 82.08%\n",
            "Epoch: 20, Step: 18/164, Loss: 0.516452, Accuracy: 81.99%\n",
            "Epoch: 20, Step: 19/164, Loss: 0.518598, Accuracy: 81.74%\n",
            "Epoch: 20, Step: 20/164, Loss: 0.516284, Accuracy: 81.72%\n",
            "Epoch: 20, Step: 21/164, Loss: 0.518116, Accuracy: 81.66%\n",
            "Epoch: 20, Step: 22/164, Loss: 0.513282, Accuracy: 81.85%\n",
            "Epoch: 20, Step: 23/164, Loss: 0.512630, Accuracy: 82.03%\n",
            "Epoch: 20, Step: 24/164, Loss: 0.508467, Accuracy: 82.19%\n",
            "Epoch: 20, Step: 25/164, Loss: 0.510376, Accuracy: 82.09%\n",
            "Epoch: 20, Step: 26/164, Loss: 0.509559, Accuracy: 82.15%\n",
            "Epoch: 20, Step: 27/164, Loss: 0.507999, Accuracy: 82.32%\n",
            "Epoch: 20, Step: 28/164, Loss: 0.508794, Accuracy: 82.31%\n",
            "Epoch: 20, Step: 29/164, Loss: 0.511046, Accuracy: 82.27%\n",
            "Epoch: 20, Step: 30/164, Loss: 0.509362, Accuracy: 82.34%\n",
            "Epoch: 20, Step: 31/164, Loss: 0.503621, Accuracy: 82.56%\n",
            "Epoch: 20, Step: 32/164, Loss: 0.503339, Accuracy: 82.59%\n",
            "Epoch: 20, Step: 33/164, Loss: 0.503084, Accuracy: 82.55%\n",
            "Epoch: 20, Step: 34/164, Loss: 0.499516, Accuracy: 82.63%\n",
            "Epoch: 20, Step: 35/164, Loss: 0.501125, Accuracy: 82.57%\n",
            "Epoch: 20, Step: 36/164, Loss: 0.499146, Accuracy: 82.68%\n",
            "Epoch: 20, Step: 37/164, Loss: 0.497892, Accuracy: 82.79%\n",
            "Epoch: 20, Step: 38/164, Loss: 0.494872, Accuracy: 82.96%\n",
            "Epoch: 20, Step: 39/164, Loss: 0.494370, Accuracy: 82.99%\n",
            "Epoch: 20, Step: 40/164, Loss: 0.488952, Accuracy: 83.16%\n",
            "Epoch: 20, Step: 41/164, Loss: 0.488390, Accuracy: 83.23%\n",
            "Epoch: 20, Step: 42/164, Loss: 0.490896, Accuracy: 83.11%\n",
            "Epoch: 20, Step: 43/164, Loss: 0.494944, Accuracy: 82.98%\n",
            "Epoch: 20, Step: 44/164, Loss: 0.497518, Accuracy: 82.94%\n",
            "Epoch: 20, Step: 45/164, Loss: 0.499426, Accuracy: 82.92%\n",
            "Epoch: 20, Step: 46/164, Loss: 0.503448, Accuracy: 82.80%\n",
            "Epoch: 20, Step: 47/164, Loss: 0.503506, Accuracy: 82.78%\n",
            "Epoch: 20, Step: 48/164, Loss: 0.499832, Accuracy: 82.91%\n",
            "Epoch: 20, Step: 49/164, Loss: 0.498988, Accuracy: 82.92%\n",
            "Epoch: 20, Step: 50/164, Loss: 0.500575, Accuracy: 82.94%\n",
            "Epoch: 20, Step: 51/164, Loss: 0.499428, Accuracy: 83.03%\n",
            "Epoch: 20, Step: 52/164, Loss: 0.500550, Accuracy: 83.04%\n",
            "Epoch: 20, Step: 53/164, Loss: 0.499234, Accuracy: 83.08%\n",
            "Epoch: 20, Step: 54/164, Loss: 0.500014, Accuracy: 83.02%\n",
            "Epoch: 20, Step: 55/164, Loss: 0.501416, Accuracy: 83.01%\n",
            "Epoch: 20, Step: 56/164, Loss: 0.498870, Accuracy: 83.12%\n",
            "Epoch: 20, Step: 57/164, Loss: 0.497586, Accuracy: 83.14%\n",
            "Epoch: 20, Step: 58/164, Loss: 0.497632, Accuracy: 83.15%\n",
            "Epoch: 20, Step: 59/164, Loss: 0.497663, Accuracy: 83.14%\n",
            "Epoch: 20, Step: 60/164, Loss: 0.499508, Accuracy: 83.11%\n",
            "Epoch: 20, Step: 61/164, Loss: 0.500876, Accuracy: 83.07%\n",
            "Epoch: 20, Step: 62/164, Loss: 0.502649, Accuracy: 82.99%\n",
            "Epoch: 20, Step: 63/164, Loss: 0.500504, Accuracy: 83.04%\n",
            "Epoch: 20, Step: 64/164, Loss: 0.500873, Accuracy: 83.02%\n",
            "Epoch: 20, Step: 65/164, Loss: 0.500480, Accuracy: 83.02%\n",
            "Epoch: 20, Step: 66/164, Loss: 0.502377, Accuracy: 82.94%\n",
            "Epoch: 20, Step: 67/164, Loss: 0.503664, Accuracy: 82.92%\n",
            "Epoch: 20, Step: 68/164, Loss: 0.503907, Accuracy: 82.96%\n",
            "Epoch: 20, Step: 69/164, Loss: 0.501818, Accuracy: 82.99%\n",
            "Epoch: 20, Step: 70/164, Loss: 0.503050, Accuracy: 82.92%\n",
            "Epoch: 20, Step: 71/164, Loss: 0.502805, Accuracy: 82.94%\n",
            "Epoch: 20, Step: 72/164, Loss: 0.502264, Accuracy: 82.94%\n",
            "Epoch: 20, Step: 73/164, Loss: 0.501901, Accuracy: 82.92%\n",
            "Epoch: 20, Step: 74/164, Loss: 0.501185, Accuracy: 82.91%\n",
            "Epoch: 20, Step: 75/164, Loss: 0.503033, Accuracy: 82.82%\n",
            "Epoch: 20, Step: 76/164, Loss: 0.503349, Accuracy: 82.83%\n",
            "Epoch: 20, Step: 77/164, Loss: 0.502831, Accuracy: 82.88%\n",
            "Epoch: 20, Step: 78/164, Loss: 0.503248, Accuracy: 82.86%\n",
            "Epoch: 20, Step: 79/164, Loss: 0.503817, Accuracy: 82.85%\n",
            "Epoch: 20, Step: 80/164, Loss: 0.502929, Accuracy: 82.88%\n",
            "Epoch: 20, Step: 81/164, Loss: 0.503548, Accuracy: 82.87%\n",
            "Epoch: 20, Step: 82/164, Loss: 0.502622, Accuracy: 82.91%\n",
            "Epoch: 20, Step: 83/164, Loss: 0.503326, Accuracy: 82.88%\n",
            "Epoch: 20, Step: 84/164, Loss: 0.503031, Accuracy: 82.89%\n",
            "Epoch: 20, Step: 85/164, Loss: 0.501886, Accuracy: 82.95%\n",
            "Epoch: 20, Step: 86/164, Loss: 0.501838, Accuracy: 82.96%\n",
            "Epoch: 20, Step: 87/164, Loss: 0.501680, Accuracy: 82.97%\n",
            "Epoch: 20, Step: 88/164, Loss: 0.502044, Accuracy: 82.95%\n",
            "Epoch: 20, Step: 89/164, Loss: 0.503212, Accuracy: 82.94%\n",
            "Epoch: 20, Step: 90/164, Loss: 0.503527, Accuracy: 82.91%\n",
            "Epoch: 20, Step: 91/164, Loss: 0.504468, Accuracy: 82.89%\n",
            "Epoch: 20, Step: 92/164, Loss: 0.504961, Accuracy: 82.89%\n",
            "Epoch: 20, Step: 93/164, Loss: 0.504354, Accuracy: 82.90%\n",
            "Epoch: 20, Step: 94/164, Loss: 0.504506, Accuracy: 82.93%\n",
            "Epoch: 20, Step: 95/164, Loss: 0.504950, Accuracy: 82.88%\n",
            "Epoch: 20, Step: 96/164, Loss: 0.504876, Accuracy: 82.89%\n",
            "Epoch: 20, Step: 97/164, Loss: 0.505157, Accuracy: 82.87%\n",
            "Epoch: 20, Step: 98/164, Loss: 0.503995, Accuracy: 82.88%\n",
            "Epoch: 20, Step: 99/164, Loss: 0.503870, Accuracy: 82.91%\n",
            "Epoch: 20, Step: 100/164, Loss: 0.504692, Accuracy: 82.88%\n",
            "Epoch: 20, Step: 101/164, Loss: 0.505469, Accuracy: 82.87%\n",
            "Epoch: 20, Step: 102/164, Loss: 0.506694, Accuracy: 82.83%\n",
            "Epoch: 20, Step: 103/164, Loss: 0.506488, Accuracy: 82.83%\n",
            "Epoch: 20, Step: 104/164, Loss: 0.505553, Accuracy: 82.84%\n",
            "Epoch: 20, Step: 105/164, Loss: 0.505668, Accuracy: 82.84%\n",
            "Epoch: 20, Step: 106/164, Loss: 0.505998, Accuracy: 82.82%\n",
            "Epoch: 20, Step: 107/164, Loss: 0.505507, Accuracy: 82.83%\n",
            "Epoch: 20, Step: 108/164, Loss: 0.504536, Accuracy: 82.85%\n",
            "Epoch: 20, Step: 109/164, Loss: 0.505037, Accuracy: 82.85%\n",
            "Epoch: 20, Step: 110/164, Loss: 0.504723, Accuracy: 82.88%\n",
            "Epoch: 20, Step: 111/164, Loss: 0.504099, Accuracy: 82.91%\n",
            "Epoch: 20, Step: 112/164, Loss: 0.503471, Accuracy: 82.92%\n",
            "Epoch: 20, Step: 113/164, Loss: 0.504097, Accuracy: 82.89%\n",
            "Epoch: 20, Step: 114/164, Loss: 0.503084, Accuracy: 82.89%\n",
            "Epoch: 20, Step: 115/164, Loss: 0.502230, Accuracy: 82.92%\n",
            "Epoch: 20, Step: 116/164, Loss: 0.501482, Accuracy: 82.94%\n",
            "Epoch: 20, Step: 117/164, Loss: 0.501266, Accuracy: 82.95%\n",
            "Epoch: 20, Step: 118/164, Loss: 0.501579, Accuracy: 82.94%\n",
            "Epoch: 20, Step: 119/164, Loss: 0.501334, Accuracy: 82.94%\n",
            "Epoch: 20, Step: 120/164, Loss: 0.501152, Accuracy: 82.90%\n",
            "Epoch: 20, Step: 121/164, Loss: 0.501113, Accuracy: 82.92%\n",
            "Epoch: 20, Step: 122/164, Loss: 0.502587, Accuracy: 82.88%\n",
            "Epoch: 20, Step: 123/164, Loss: 0.503546, Accuracy: 82.83%\n",
            "Epoch: 20, Step: 124/164, Loss: 0.502650, Accuracy: 82.86%\n",
            "Epoch: 20, Step: 125/164, Loss: 0.502566, Accuracy: 82.89%\n",
            "Epoch: 20, Step: 126/164, Loss: 0.502582, Accuracy: 82.89%\n",
            "Epoch: 20, Step: 127/164, Loss: 0.502048, Accuracy: 82.89%\n",
            "Epoch: 20, Step: 128/164, Loss: 0.502415, Accuracy: 82.88%\n",
            "Epoch: 20, Step: 129/164, Loss: 0.503611, Accuracy: 82.84%\n",
            "Epoch: 20, Step: 130/164, Loss: 0.502881, Accuracy: 82.87%\n",
            "Epoch: 20, Step: 131/164, Loss: 0.502670, Accuracy: 82.88%\n",
            "Epoch: 20, Step: 132/164, Loss: 0.502292, Accuracy: 82.92%\n",
            "Epoch: 20, Step: 133/164, Loss: 0.502617, Accuracy: 82.91%\n",
            "Epoch: 20, Step: 134/164, Loss: 0.503056, Accuracy: 82.92%\n",
            "Epoch: 20, Step: 135/164, Loss: 0.502207, Accuracy: 82.96%\n",
            "Epoch: 20, Step: 136/164, Loss: 0.501497, Accuracy: 83.00%\n",
            "Epoch: 20, Step: 137/164, Loss: 0.500806, Accuracy: 83.01%\n",
            "Epoch: 20, Step: 138/164, Loss: 0.500563, Accuracy: 83.02%\n",
            "Epoch: 20, Step: 139/164, Loss: 0.500250, Accuracy: 83.04%\n",
            "Epoch: 20, Step: 140/164, Loss: 0.500177, Accuracy: 83.02%\n",
            "Epoch: 20, Step: 141/164, Loss: 0.500870, Accuracy: 83.01%\n",
            "Epoch: 20, Step: 142/164, Loss: 0.501499, Accuracy: 83.01%\n",
            "Epoch: 20, Step: 143/164, Loss: 0.502190, Accuracy: 83.00%\n",
            "Epoch: 20, Step: 144/164, Loss: 0.502205, Accuracy: 82.96%\n",
            "Epoch: 20, Step: 145/164, Loss: 0.502587, Accuracy: 82.95%\n",
            "Epoch: 20, Step: 146/164, Loss: 0.501869, Accuracy: 82.98%\n",
            "Epoch: 20, Step: 147/164, Loss: 0.501495, Accuracy: 82.99%\n",
            "Epoch: 20, Step: 148/164, Loss: 0.500615, Accuracy: 83.03%\n",
            "Epoch: 20, Step: 149/164, Loss: 0.501924, Accuracy: 82.98%\n",
            "Epoch: 20, Step: 150/164, Loss: 0.501288, Accuracy: 82.99%\n",
            "Epoch: 20, Step: 151/164, Loss: 0.501297, Accuracy: 83.00%\n",
            "Epoch: 20, Step: 152/164, Loss: 0.501215, Accuracy: 83.01%\n",
            "Epoch: 20, Step: 153/164, Loss: 0.501350, Accuracy: 83.03%\n",
            "Epoch: 20, Step: 154/164, Loss: 0.503461, Accuracy: 82.98%\n",
            "Epoch: 20, Step: 155/164, Loss: 0.503134, Accuracy: 82.99%\n",
            "Epoch: 20, Step: 156/164, Loss: 0.502906, Accuracy: 82.98%\n",
            "Epoch: 20, Step: 157/164, Loss: 0.503178, Accuracy: 82.99%\n",
            "Epoch: 20, Step: 158/164, Loss: 0.502886, Accuracy: 83.01%\n",
            "Epoch: 20, Step: 159/164, Loss: 0.502590, Accuracy: 83.02%\n",
            "Epoch: 20, Step: 160/164, Loss: 0.502704, Accuracy: 83.02%\n",
            "Epoch: 20, Step: 161/164, Loss: 0.502951, Accuracy: 83.00%\n",
            "Epoch: 20, Step: 162/164, Loss: 0.504187, Accuracy: 82.98%\n",
            "Epoch: 20, Step: 163/164, Loss: 0.503461, Accuracy: 83.01%\n",
            "Epoch: 20, Step: 164/164, Loss: 0.503422, Accuracy: 83.01%\n",
            "Epoch: 21, Step: 1/164, Loss: 0.506916, Accuracy: 82.03%\n",
            "Epoch: 21, Step: 2/164, Loss: 0.516679, Accuracy: 83.59%\n",
            "Epoch: 21, Step: 3/164, Loss: 0.517508, Accuracy: 82.55%\n",
            "Epoch: 21, Step: 4/164, Loss: 0.518554, Accuracy: 81.64%\n",
            "Epoch: 21, Step: 5/164, Loss: 0.528139, Accuracy: 81.41%\n",
            "Epoch: 21, Step: 6/164, Loss: 0.519571, Accuracy: 81.77%\n",
            "Epoch: 21, Step: 7/164, Loss: 0.504513, Accuracy: 82.37%\n",
            "Epoch: 21, Step: 8/164, Loss: 0.505820, Accuracy: 82.42%\n",
            "Epoch: 21, Step: 9/164, Loss: 0.504956, Accuracy: 82.38%\n",
            "Epoch: 21, Step: 10/164, Loss: 0.516082, Accuracy: 82.50%\n",
            "Epoch: 21, Step: 11/164, Loss: 0.510400, Accuracy: 82.60%\n",
            "Epoch: 21, Step: 12/164, Loss: 0.496539, Accuracy: 83.01%\n",
            "Epoch: 21, Step: 13/164, Loss: 0.481877, Accuracy: 83.59%\n",
            "Epoch: 21, Step: 14/164, Loss: 0.477230, Accuracy: 83.87%\n",
            "Epoch: 21, Step: 15/164, Loss: 0.484999, Accuracy: 83.49%\n",
            "Epoch: 21, Step: 16/164, Loss: 0.475090, Accuracy: 83.84%\n",
            "Epoch: 21, Step: 17/164, Loss: 0.470715, Accuracy: 83.96%\n",
            "Epoch: 21, Step: 18/164, Loss: 0.463318, Accuracy: 84.16%\n",
            "Epoch: 21, Step: 19/164, Loss: 0.461820, Accuracy: 84.29%\n",
            "Epoch: 21, Step: 20/164, Loss: 0.461529, Accuracy: 84.41%\n",
            "Epoch: 21, Step: 21/164, Loss: 0.460623, Accuracy: 84.49%\n",
            "Epoch: 21, Step: 22/164, Loss: 0.465342, Accuracy: 84.45%\n",
            "Epoch: 21, Step: 23/164, Loss: 0.466107, Accuracy: 84.38%\n",
            "Epoch: 21, Step: 24/164, Loss: 0.467038, Accuracy: 84.24%\n",
            "Epoch: 21, Step: 25/164, Loss: 0.470012, Accuracy: 84.06%\n",
            "Epoch: 21, Step: 26/164, Loss: 0.466403, Accuracy: 84.19%\n",
            "Epoch: 21, Step: 27/164, Loss: 0.466418, Accuracy: 84.29%\n",
            "Epoch: 21, Step: 28/164, Loss: 0.464031, Accuracy: 84.43%\n",
            "Epoch: 21, Step: 29/164, Loss: 0.466862, Accuracy: 84.24%\n",
            "Epoch: 21, Step: 30/164, Loss: 0.467922, Accuracy: 84.22%\n",
            "Epoch: 21, Step: 31/164, Loss: 0.466870, Accuracy: 84.17%\n",
            "Epoch: 21, Step: 32/164, Loss: 0.467275, Accuracy: 84.30%\n",
            "Epoch: 21, Step: 33/164, Loss: 0.466874, Accuracy: 84.35%\n",
            "Epoch: 21, Step: 34/164, Loss: 0.468616, Accuracy: 84.26%\n",
            "Epoch: 21, Step: 35/164, Loss: 0.467967, Accuracy: 84.20%\n",
            "Epoch: 21, Step: 36/164, Loss: 0.467479, Accuracy: 84.11%\n",
            "Epoch: 21, Step: 37/164, Loss: 0.464414, Accuracy: 84.29%\n",
            "Epoch: 21, Step: 38/164, Loss: 0.463240, Accuracy: 84.33%\n",
            "Epoch: 21, Step: 39/164, Loss: 0.462453, Accuracy: 84.40%\n",
            "Epoch: 21, Step: 40/164, Loss: 0.467068, Accuracy: 84.20%\n",
            "Epoch: 21, Step: 41/164, Loss: 0.466462, Accuracy: 84.20%\n",
            "Epoch: 21, Step: 42/164, Loss: 0.466887, Accuracy: 84.13%\n",
            "Epoch: 21, Step: 43/164, Loss: 0.466500, Accuracy: 84.07%\n",
            "Epoch: 21, Step: 44/164, Loss: 0.467100, Accuracy: 83.97%\n",
            "Epoch: 21, Step: 45/164, Loss: 0.464467, Accuracy: 84.06%\n",
            "Epoch: 21, Step: 46/164, Loss: 0.463481, Accuracy: 84.17%\n",
            "Epoch: 21, Step: 47/164, Loss: 0.464588, Accuracy: 84.14%\n",
            "Epoch: 21, Step: 48/164, Loss: 0.463764, Accuracy: 84.13%\n",
            "Epoch: 21, Step: 49/164, Loss: 0.463512, Accuracy: 84.15%\n",
            "Epoch: 21, Step: 50/164, Loss: 0.463974, Accuracy: 84.09%\n",
            "Epoch: 21, Step: 51/164, Loss: 0.464766, Accuracy: 84.02%\n",
            "Epoch: 21, Step: 52/164, Loss: 0.462838, Accuracy: 84.09%\n",
            "Epoch: 21, Step: 53/164, Loss: 0.468748, Accuracy: 83.93%\n",
            "Epoch: 21, Step: 54/164, Loss: 0.468105, Accuracy: 83.96%\n",
            "Epoch: 21, Step: 55/164, Loss: 0.471002, Accuracy: 83.89%\n",
            "Epoch: 21, Step: 56/164, Loss: 0.469536, Accuracy: 83.93%\n",
            "Epoch: 21, Step: 57/164, Loss: 0.470305, Accuracy: 83.92%\n",
            "Epoch: 21, Step: 58/164, Loss: 0.471567, Accuracy: 83.88%\n",
            "Epoch: 21, Step: 59/164, Loss: 0.469676, Accuracy: 83.95%\n",
            "Epoch: 21, Step: 60/164, Loss: 0.470541, Accuracy: 83.95%\n",
            "Epoch: 21, Step: 61/164, Loss: 0.471271, Accuracy: 83.95%\n",
            "Epoch: 21, Step: 62/164, Loss: 0.472492, Accuracy: 83.83%\n",
            "Epoch: 21, Step: 63/164, Loss: 0.472930, Accuracy: 83.84%\n",
            "Epoch: 21, Step: 64/164, Loss: 0.474332, Accuracy: 83.75%\n",
            "Epoch: 21, Step: 65/164, Loss: 0.474488, Accuracy: 83.74%\n",
            "Epoch: 21, Step: 66/164, Loss: 0.473892, Accuracy: 83.79%\n",
            "Epoch: 21, Step: 67/164, Loss: 0.473297, Accuracy: 83.78%\n",
            "Epoch: 21, Step: 68/164, Loss: 0.472734, Accuracy: 83.80%\n",
            "Epoch: 21, Step: 69/164, Loss: 0.473768, Accuracy: 83.79%\n",
            "Epoch: 21, Step: 70/164, Loss: 0.471535, Accuracy: 83.87%\n",
            "Epoch: 21, Step: 71/164, Loss: 0.472614, Accuracy: 83.86%\n",
            "Epoch: 21, Step: 72/164, Loss: 0.471280, Accuracy: 83.87%\n",
            "Epoch: 21, Step: 73/164, Loss: 0.470929, Accuracy: 83.87%\n",
            "Epoch: 21, Step: 74/164, Loss: 0.471684, Accuracy: 83.82%\n",
            "Epoch: 21, Step: 75/164, Loss: 0.471832, Accuracy: 83.82%\n",
            "Epoch: 21, Step: 76/164, Loss: 0.472581, Accuracy: 83.79%\n",
            "Epoch: 21, Step: 77/164, Loss: 0.472258, Accuracy: 83.80%\n",
            "Epoch: 21, Step: 78/164, Loss: 0.472599, Accuracy: 83.75%\n",
            "Epoch: 21, Step: 79/164, Loss: 0.472436, Accuracy: 83.72%\n",
            "Epoch: 21, Step: 80/164, Loss: 0.472075, Accuracy: 83.72%\n",
            "Epoch: 21, Step: 81/164, Loss: 0.472188, Accuracy: 83.73%\n",
            "Epoch: 21, Step: 82/164, Loss: 0.473624, Accuracy: 83.71%\n",
            "Epoch: 21, Step: 83/164, Loss: 0.473280, Accuracy: 83.71%\n",
            "Epoch: 21, Step: 84/164, Loss: 0.474650, Accuracy: 83.64%\n",
            "Epoch: 21, Step: 85/164, Loss: 0.474256, Accuracy: 83.69%\n",
            "Epoch: 21, Step: 86/164, Loss: 0.474792, Accuracy: 83.68%\n",
            "Epoch: 21, Step: 87/164, Loss: 0.475146, Accuracy: 83.67%\n",
            "Epoch: 21, Step: 88/164, Loss: 0.474919, Accuracy: 83.66%\n",
            "Epoch: 21, Step: 89/164, Loss: 0.476613, Accuracy: 83.57%\n",
            "Epoch: 21, Step: 90/164, Loss: 0.476444, Accuracy: 83.57%\n",
            "Epoch: 21, Step: 91/164, Loss: 0.475792, Accuracy: 83.57%\n",
            "Epoch: 21, Step: 92/164, Loss: 0.475428, Accuracy: 83.58%\n",
            "Epoch: 21, Step: 93/164, Loss: 0.474984, Accuracy: 83.59%\n",
            "Epoch: 21, Step: 94/164, Loss: 0.474384, Accuracy: 83.62%\n",
            "Epoch: 21, Step: 95/164, Loss: 0.473415, Accuracy: 83.64%\n",
            "Epoch: 21, Step: 96/164, Loss: 0.472750, Accuracy: 83.68%\n",
            "Epoch: 21, Step: 97/164, Loss: 0.472662, Accuracy: 83.65%\n",
            "Epoch: 21, Step: 98/164, Loss: 0.472380, Accuracy: 83.66%\n",
            "Epoch: 21, Step: 99/164, Loss: 0.472657, Accuracy: 83.68%\n",
            "Epoch: 21, Step: 100/164, Loss: 0.472810, Accuracy: 83.69%\n",
            "Epoch: 21, Step: 101/164, Loss: 0.471299, Accuracy: 83.75%\n",
            "Epoch: 21, Step: 102/164, Loss: 0.471964, Accuracy: 83.77%\n",
            "Epoch: 21, Step: 103/164, Loss: 0.471848, Accuracy: 83.78%\n",
            "Epoch: 21, Step: 104/164, Loss: 0.471405, Accuracy: 83.79%\n",
            "Epoch: 21, Step: 105/164, Loss: 0.470671, Accuracy: 83.80%\n",
            "Epoch: 21, Step: 106/164, Loss: 0.471457, Accuracy: 83.78%\n",
            "Epoch: 21, Step: 107/164, Loss: 0.471345, Accuracy: 83.78%\n",
            "Epoch: 21, Step: 108/164, Loss: 0.471160, Accuracy: 83.77%\n",
            "Epoch: 21, Step: 109/164, Loss: 0.472210, Accuracy: 83.76%\n",
            "Epoch: 21, Step: 110/164, Loss: 0.472503, Accuracy: 83.75%\n",
            "Epoch: 21, Step: 111/164, Loss: 0.471347, Accuracy: 83.80%\n",
            "Epoch: 21, Step: 112/164, Loss: 0.471573, Accuracy: 83.79%\n",
            "Epoch: 21, Step: 113/164, Loss: 0.470625, Accuracy: 83.82%\n",
            "Epoch: 21, Step: 114/164, Loss: 0.470650, Accuracy: 83.80%\n",
            "Epoch: 21, Step: 115/164, Loss: 0.471245, Accuracy: 83.81%\n",
            "Epoch: 21, Step: 116/164, Loss: 0.472628, Accuracy: 83.76%\n",
            "Epoch: 21, Step: 117/164, Loss: 0.472048, Accuracy: 83.77%\n",
            "Epoch: 21, Step: 118/164, Loss: 0.472951, Accuracy: 83.77%\n",
            "Epoch: 21, Step: 119/164, Loss: 0.473457, Accuracy: 83.78%\n",
            "Epoch: 21, Step: 120/164, Loss: 0.473132, Accuracy: 83.77%\n",
            "Epoch: 21, Step: 121/164, Loss: 0.474333, Accuracy: 83.73%\n",
            "Epoch: 21, Step: 122/164, Loss: 0.474415, Accuracy: 83.72%\n",
            "Epoch: 21, Step: 123/164, Loss: 0.473388, Accuracy: 83.75%\n",
            "Epoch: 21, Step: 124/164, Loss: 0.473776, Accuracy: 83.73%\n",
            "Epoch: 21, Step: 125/164, Loss: 0.472755, Accuracy: 83.76%\n",
            "Epoch: 21, Step: 126/164, Loss: 0.472172, Accuracy: 83.78%\n",
            "Epoch: 21, Step: 127/164, Loss: 0.472005, Accuracy: 83.78%\n",
            "Epoch: 21, Step: 128/164, Loss: 0.472505, Accuracy: 83.78%\n",
            "Epoch: 21, Step: 129/164, Loss: 0.472324, Accuracy: 83.82%\n",
            "Epoch: 21, Step: 130/164, Loss: 0.471076, Accuracy: 83.87%\n",
            "Epoch: 21, Step: 131/164, Loss: 0.471903, Accuracy: 83.84%\n",
            "Epoch: 21, Step: 132/164, Loss: 0.471741, Accuracy: 83.86%\n",
            "Epoch: 21, Step: 133/164, Loss: 0.471560, Accuracy: 83.85%\n",
            "Epoch: 21, Step: 134/164, Loss: 0.470888, Accuracy: 83.89%\n",
            "Epoch: 21, Step: 135/164, Loss: 0.470630, Accuracy: 83.88%\n",
            "Epoch: 21, Step: 136/164, Loss: 0.471480, Accuracy: 83.86%\n",
            "Epoch: 21, Step: 137/164, Loss: 0.471801, Accuracy: 83.85%\n",
            "Epoch: 21, Step: 138/164, Loss: 0.471595, Accuracy: 83.85%\n",
            "Epoch: 21, Step: 139/164, Loss: 0.471537, Accuracy: 83.86%\n",
            "Epoch: 21, Step: 140/164, Loss: 0.471907, Accuracy: 83.85%\n",
            "Epoch: 21, Step: 141/164, Loss: 0.471598, Accuracy: 83.84%\n",
            "Epoch: 21, Step: 142/164, Loss: 0.470961, Accuracy: 83.86%\n",
            "Epoch: 21, Step: 143/164, Loss: 0.470388, Accuracy: 83.87%\n",
            "Epoch: 21, Step: 144/164, Loss: 0.469526, Accuracy: 83.91%\n",
            "Epoch: 21, Step: 145/164, Loss: 0.471460, Accuracy: 83.88%\n",
            "Epoch: 21, Step: 146/164, Loss: 0.471599, Accuracy: 83.87%\n",
            "Epoch: 21, Step: 147/164, Loss: 0.471238, Accuracy: 83.88%\n",
            "Epoch: 21, Step: 148/164, Loss: 0.471901, Accuracy: 83.87%\n",
            "Epoch: 21, Step: 149/164, Loss: 0.471741, Accuracy: 83.90%\n",
            "Epoch: 21, Step: 150/164, Loss: 0.470542, Accuracy: 83.93%\n",
            "Epoch: 21, Step: 151/164, Loss: 0.470001, Accuracy: 83.94%\n",
            "Epoch: 21, Step: 152/164, Loss: 0.470019, Accuracy: 83.96%\n",
            "Epoch: 21, Step: 153/164, Loss: 0.469987, Accuracy: 83.98%\n",
            "Epoch: 21, Step: 154/164, Loss: 0.469442, Accuracy: 83.99%\n",
            "Epoch: 21, Step: 155/164, Loss: 0.470127, Accuracy: 83.97%\n",
            "Epoch: 21, Step: 156/164, Loss: 0.470237, Accuracy: 83.96%\n",
            "Epoch: 21, Step: 157/164, Loss: 0.470043, Accuracy: 83.95%\n",
            "Epoch: 21, Step: 158/164, Loss: 0.470361, Accuracy: 83.93%\n",
            "Epoch: 21, Step: 159/164, Loss: 0.470459, Accuracy: 83.91%\n",
            "Epoch: 21, Step: 160/164, Loss: 0.470350, Accuracy: 83.93%\n",
            "Epoch: 21, Step: 161/164, Loss: 0.470661, Accuracy: 83.92%\n",
            "Epoch: 21, Step: 162/164, Loss: 0.470515, Accuracy: 83.91%\n",
            "Epoch: 21, Step: 163/164, Loss: 0.469506, Accuracy: 83.94%\n",
            "Epoch: 21, Step: 164/164, Loss: 0.470018, Accuracy: 83.95%\n",
            "Epoch: 22, Step: 1/164, Loss: 0.414420, Accuracy: 89.06%\n",
            "Epoch: 22, Step: 2/164, Loss: 0.468689, Accuracy: 87.11%\n",
            "Epoch: 22, Step: 3/164, Loss: 0.486877, Accuracy: 85.68%\n",
            "Epoch: 22, Step: 4/164, Loss: 0.465927, Accuracy: 85.16%\n",
            "Epoch: 22, Step: 5/164, Loss: 0.460126, Accuracy: 85.16%\n",
            "Epoch: 22, Step: 6/164, Loss: 0.448256, Accuracy: 85.03%\n",
            "Epoch: 22, Step: 7/164, Loss: 0.463237, Accuracy: 84.26%\n",
            "Epoch: 22, Step: 8/164, Loss: 0.470547, Accuracy: 83.89%\n",
            "Epoch: 22, Step: 9/164, Loss: 0.469686, Accuracy: 84.11%\n",
            "Epoch: 22, Step: 10/164, Loss: 0.468122, Accuracy: 84.30%\n",
            "Epoch: 22, Step: 11/164, Loss: 0.464913, Accuracy: 84.45%\n",
            "Epoch: 22, Step: 12/164, Loss: 0.461541, Accuracy: 84.57%\n",
            "Epoch: 22, Step: 13/164, Loss: 0.449177, Accuracy: 85.10%\n",
            "Epoch: 22, Step: 14/164, Loss: 0.445807, Accuracy: 85.49%\n",
            "Epoch: 22, Step: 15/164, Loss: 0.447043, Accuracy: 85.73%\n",
            "Epoch: 22, Step: 16/164, Loss: 0.447252, Accuracy: 85.55%\n",
            "Epoch: 22, Step: 17/164, Loss: 0.451996, Accuracy: 85.52%\n",
            "Epoch: 22, Step: 18/164, Loss: 0.454578, Accuracy: 85.29%\n",
            "Epoch: 22, Step: 19/164, Loss: 0.463141, Accuracy: 84.95%\n",
            "Epoch: 22, Step: 20/164, Loss: 0.464425, Accuracy: 84.80%\n",
            "Epoch: 22, Step: 21/164, Loss: 0.467415, Accuracy: 84.60%\n",
            "Epoch: 22, Step: 22/164, Loss: 0.465225, Accuracy: 84.73%\n",
            "Epoch: 22, Step: 23/164, Loss: 0.464113, Accuracy: 84.71%\n",
            "Epoch: 22, Step: 24/164, Loss: 0.463091, Accuracy: 84.80%\n",
            "Epoch: 22, Step: 25/164, Loss: 0.457304, Accuracy: 84.97%\n",
            "Epoch: 22, Step: 26/164, Loss: 0.457508, Accuracy: 85.04%\n",
            "Epoch: 22, Step: 27/164, Loss: 0.453503, Accuracy: 85.16%\n",
            "Epoch: 22, Step: 28/164, Loss: 0.450488, Accuracy: 85.18%\n",
            "Epoch: 22, Step: 29/164, Loss: 0.452518, Accuracy: 85.02%\n",
            "Epoch: 22, Step: 30/164, Loss: 0.449399, Accuracy: 85.10%\n",
            "Epoch: 22, Step: 31/164, Loss: 0.447519, Accuracy: 85.13%\n",
            "Epoch: 22, Step: 32/164, Loss: 0.446125, Accuracy: 85.18%\n",
            "Epoch: 22, Step: 33/164, Loss: 0.445287, Accuracy: 85.20%\n",
            "Epoch: 22, Step: 34/164, Loss: 0.444819, Accuracy: 85.16%\n",
            "Epoch: 22, Step: 35/164, Loss: 0.441581, Accuracy: 85.31%\n",
            "Epoch: 22, Step: 36/164, Loss: 0.442239, Accuracy: 85.24%\n",
            "Epoch: 22, Step: 37/164, Loss: 0.437895, Accuracy: 85.37%\n",
            "Epoch: 22, Step: 38/164, Loss: 0.439483, Accuracy: 85.34%\n",
            "Epoch: 22, Step: 39/164, Loss: 0.439819, Accuracy: 85.32%\n",
            "Epoch: 22, Step: 40/164, Loss: 0.440030, Accuracy: 85.29%\n",
            "Epoch: 22, Step: 41/164, Loss: 0.440510, Accuracy: 85.27%\n",
            "Epoch: 22, Step: 42/164, Loss: 0.440526, Accuracy: 85.19%\n",
            "Epoch: 22, Step: 43/164, Loss: 0.441972, Accuracy: 85.16%\n",
            "Epoch: 22, Step: 44/164, Loss: 0.439472, Accuracy: 85.16%\n",
            "Epoch: 22, Step: 45/164, Loss: 0.441972, Accuracy: 85.07%\n",
            "Epoch: 22, Step: 46/164, Loss: 0.443523, Accuracy: 85.07%\n",
            "Epoch: 22, Step: 47/164, Loss: 0.444831, Accuracy: 85.04%\n",
            "Epoch: 22, Step: 48/164, Loss: 0.444589, Accuracy: 85.03%\n",
            "Epoch: 22, Step: 49/164, Loss: 0.443457, Accuracy: 85.06%\n",
            "Epoch: 22, Step: 50/164, Loss: 0.443882, Accuracy: 85.06%\n",
            "Epoch: 22, Step: 51/164, Loss: 0.445449, Accuracy: 85.05%\n",
            "Epoch: 22, Step: 52/164, Loss: 0.445839, Accuracy: 85.01%\n",
            "Epoch: 22, Step: 53/164, Loss: 0.446030, Accuracy: 84.98%\n",
            "Epoch: 22, Step: 54/164, Loss: 0.443715, Accuracy: 85.08%\n",
            "Epoch: 22, Step: 55/164, Loss: 0.442768, Accuracy: 85.14%\n",
            "Epoch: 22, Step: 56/164, Loss: 0.442208, Accuracy: 85.17%\n",
            "Epoch: 22, Step: 57/164, Loss: 0.441908, Accuracy: 85.17%\n",
            "Epoch: 22, Step: 58/164, Loss: 0.442085, Accuracy: 85.13%\n",
            "Epoch: 22, Step: 59/164, Loss: 0.442226, Accuracy: 85.13%\n",
            "Epoch: 22, Step: 60/164, Loss: 0.443600, Accuracy: 85.12%\n",
            "Epoch: 22, Step: 61/164, Loss: 0.444031, Accuracy: 85.07%\n",
            "Epoch: 22, Step: 62/164, Loss: 0.444281, Accuracy: 85.04%\n",
            "Epoch: 22, Step: 63/164, Loss: 0.444032, Accuracy: 85.07%\n",
            "Epoch: 22, Step: 64/164, Loss: 0.444866, Accuracy: 85.10%\n",
            "Epoch: 22, Step: 65/164, Loss: 0.447160, Accuracy: 85.00%\n",
            "Epoch: 22, Step: 66/164, Loss: 0.447495, Accuracy: 85.01%\n",
            "Epoch: 22, Step: 67/164, Loss: 0.447350, Accuracy: 84.99%\n",
            "Epoch: 22, Step: 68/164, Loss: 0.447206, Accuracy: 85.03%\n",
            "Epoch: 22, Step: 69/164, Loss: 0.448447, Accuracy: 85.01%\n",
            "Epoch: 22, Step: 70/164, Loss: 0.448576, Accuracy: 85.03%\n",
            "Epoch: 22, Step: 71/164, Loss: 0.448550, Accuracy: 85.04%\n",
            "Epoch: 22, Step: 72/164, Loss: 0.447769, Accuracy: 85.00%\n",
            "Epoch: 22, Step: 73/164, Loss: 0.447928, Accuracy: 85.04%\n",
            "Epoch: 22, Step: 74/164, Loss: 0.449296, Accuracy: 85.03%\n",
            "Epoch: 22, Step: 75/164, Loss: 0.447383, Accuracy: 85.11%\n",
            "Epoch: 22, Step: 76/164, Loss: 0.446263, Accuracy: 85.18%\n",
            "Epoch: 22, Step: 77/164, Loss: 0.446204, Accuracy: 85.21%\n",
            "Epoch: 22, Step: 78/164, Loss: 0.448305, Accuracy: 85.14%\n",
            "Epoch: 22, Step: 79/164, Loss: 0.448674, Accuracy: 85.15%\n",
            "Epoch: 22, Step: 80/164, Loss: 0.448560, Accuracy: 85.15%\n",
            "Epoch: 22, Step: 81/164, Loss: 0.449374, Accuracy: 85.10%\n",
            "Epoch: 22, Step: 82/164, Loss: 0.449061, Accuracy: 85.13%\n",
            "Epoch: 22, Step: 83/164, Loss: 0.448243, Accuracy: 85.15%\n",
            "Epoch: 22, Step: 84/164, Loss: 0.449346, Accuracy: 85.11%\n",
            "Epoch: 22, Step: 85/164, Loss: 0.450401, Accuracy: 85.05%\n",
            "Epoch: 22, Step: 86/164, Loss: 0.449175, Accuracy: 85.09%\n",
            "Epoch: 22, Step: 87/164, Loss: 0.450787, Accuracy: 85.05%\n",
            "Epoch: 22, Step: 88/164, Loss: 0.451498, Accuracy: 85.03%\n",
            "Epoch: 22, Step: 89/164, Loss: 0.452374, Accuracy: 84.99%\n",
            "Epoch: 22, Step: 90/164, Loss: 0.453476, Accuracy: 84.96%\n",
            "Epoch: 22, Step: 91/164, Loss: 0.453874, Accuracy: 84.93%\n",
            "Epoch: 22, Step: 92/164, Loss: 0.454649, Accuracy: 84.91%\n",
            "Epoch: 22, Step: 93/164, Loss: 0.455314, Accuracy: 84.89%\n",
            "Epoch: 22, Step: 94/164, Loss: 0.455918, Accuracy: 84.86%\n",
            "Epoch: 22, Step: 95/164, Loss: 0.454639, Accuracy: 84.87%\n",
            "Epoch: 22, Step: 96/164, Loss: 0.454412, Accuracy: 84.86%\n",
            "Epoch: 22, Step: 97/164, Loss: 0.454114, Accuracy: 84.91%\n",
            "Epoch: 22, Step: 98/164, Loss: 0.454946, Accuracy: 84.86%\n",
            "Epoch: 22, Step: 99/164, Loss: 0.455809, Accuracy: 84.87%\n",
            "Epoch: 22, Step: 100/164, Loss: 0.456860, Accuracy: 84.84%\n",
            "Epoch: 22, Step: 101/164, Loss: 0.456921, Accuracy: 84.85%\n",
            "Epoch: 22, Step: 102/164, Loss: 0.455954, Accuracy: 84.88%\n",
            "Epoch: 22, Step: 103/164, Loss: 0.456396, Accuracy: 84.88%\n",
            "Epoch: 22, Step: 104/164, Loss: 0.456810, Accuracy: 84.84%\n",
            "Epoch: 22, Step: 105/164, Loss: 0.456586, Accuracy: 84.80%\n",
            "Epoch: 22, Step: 106/164, Loss: 0.457295, Accuracy: 84.77%\n",
            "Epoch: 22, Step: 107/164, Loss: 0.458420, Accuracy: 84.73%\n",
            "Epoch: 22, Step: 108/164, Loss: 0.458101, Accuracy: 84.74%\n",
            "Epoch: 22, Step: 109/164, Loss: 0.457594, Accuracy: 84.75%\n",
            "Epoch: 22, Step: 110/164, Loss: 0.457664, Accuracy: 84.75%\n",
            "Epoch: 22, Step: 111/164, Loss: 0.456629, Accuracy: 84.78%\n",
            "Epoch: 22, Step: 112/164, Loss: 0.457782, Accuracy: 84.74%\n",
            "Epoch: 22, Step: 113/164, Loss: 0.457639, Accuracy: 84.73%\n",
            "Epoch: 22, Step: 114/164, Loss: 0.458196, Accuracy: 84.71%\n",
            "Epoch: 22, Step: 115/164, Loss: 0.458870, Accuracy: 84.70%\n",
            "Epoch: 22, Step: 116/164, Loss: 0.459773, Accuracy: 84.67%\n",
            "Epoch: 22, Step: 117/164, Loss: 0.460782, Accuracy: 84.64%\n",
            "Epoch: 22, Step: 118/164, Loss: 0.461349, Accuracy: 84.62%\n",
            "Epoch: 22, Step: 119/164, Loss: 0.461505, Accuracy: 84.61%\n",
            "Epoch: 22, Step: 120/164, Loss: 0.462647, Accuracy: 84.58%\n",
            "Epoch: 22, Step: 121/164, Loss: 0.464870, Accuracy: 84.53%\n",
            "Epoch: 22, Step: 122/164, Loss: 0.464180, Accuracy: 84.55%\n",
            "Epoch: 22, Step: 123/164, Loss: 0.463362, Accuracy: 84.57%\n",
            "Epoch: 22, Step: 124/164, Loss: 0.463746, Accuracy: 84.56%\n",
            "Epoch: 22, Step: 125/164, Loss: 0.463021, Accuracy: 84.57%\n",
            "Epoch: 22, Step: 126/164, Loss: 0.462898, Accuracy: 84.57%\n",
            "Epoch: 22, Step: 127/164, Loss: 0.462779, Accuracy: 84.58%\n",
            "Epoch: 22, Step: 128/164, Loss: 0.462965, Accuracy: 84.58%\n",
            "Epoch: 22, Step: 129/164, Loss: 0.462004, Accuracy: 84.60%\n",
            "Epoch: 22, Step: 130/164, Loss: 0.461369, Accuracy: 84.62%\n",
            "Epoch: 22, Step: 131/164, Loss: 0.460940, Accuracy: 84.63%\n",
            "Epoch: 22, Step: 132/164, Loss: 0.460390, Accuracy: 84.64%\n",
            "Epoch: 22, Step: 133/164, Loss: 0.459512, Accuracy: 84.66%\n",
            "Epoch: 22, Step: 134/164, Loss: 0.459253, Accuracy: 84.68%\n",
            "Epoch: 22, Step: 135/164, Loss: 0.458617, Accuracy: 84.68%\n",
            "Epoch: 22, Step: 136/164, Loss: 0.458920, Accuracy: 84.65%\n",
            "Epoch: 22, Step: 137/164, Loss: 0.458990, Accuracy: 84.66%\n",
            "Epoch: 22, Step: 138/164, Loss: 0.459903, Accuracy: 84.66%\n",
            "Epoch: 22, Step: 139/164, Loss: 0.459692, Accuracy: 84.65%\n",
            "Epoch: 22, Step: 140/164, Loss: 0.460212, Accuracy: 84.64%\n",
            "Epoch: 22, Step: 141/164, Loss: 0.460763, Accuracy: 84.62%\n",
            "Epoch: 22, Step: 142/164, Loss: 0.461432, Accuracy: 84.62%\n",
            "Epoch: 22, Step: 143/164, Loss: 0.460629, Accuracy: 84.64%\n",
            "Epoch: 22, Step: 144/164, Loss: 0.460181, Accuracy: 84.63%\n",
            "Epoch: 22, Step: 145/164, Loss: 0.459627, Accuracy: 84.66%\n",
            "Epoch: 22, Step: 146/164, Loss: 0.459223, Accuracy: 84.66%\n",
            "Epoch: 22, Step: 147/164, Loss: 0.458748, Accuracy: 84.66%\n",
            "Epoch: 22, Step: 148/164, Loss: 0.458090, Accuracy: 84.68%\n",
            "Epoch: 22, Step: 149/164, Loss: 0.458780, Accuracy: 84.66%\n",
            "Epoch: 22, Step: 150/164, Loss: 0.459737, Accuracy: 84.62%\n",
            "Epoch: 22, Step: 151/164, Loss: 0.460045, Accuracy: 84.59%\n",
            "Epoch: 22, Step: 152/164, Loss: 0.459353, Accuracy: 84.60%\n",
            "Epoch: 22, Step: 153/164, Loss: 0.458724, Accuracy: 84.63%\n",
            "Epoch: 22, Step: 154/164, Loss: 0.458976, Accuracy: 84.63%\n",
            "Epoch: 22, Step: 155/164, Loss: 0.459724, Accuracy: 84.61%\n",
            "Epoch: 22, Step: 156/164, Loss: 0.459271, Accuracy: 84.63%\n",
            "Epoch: 22, Step: 157/164, Loss: 0.459313, Accuracy: 84.64%\n",
            "Epoch: 22, Step: 158/164, Loss: 0.459767, Accuracy: 84.64%\n",
            "Epoch: 22, Step: 159/164, Loss: 0.459309, Accuracy: 84.65%\n",
            "Epoch: 22, Step: 160/164, Loss: 0.458666, Accuracy: 84.67%\n",
            "Epoch: 22, Step: 161/164, Loss: 0.458418, Accuracy: 84.69%\n",
            "Epoch: 22, Step: 162/164, Loss: 0.458089, Accuracy: 84.69%\n",
            "Epoch: 22, Step: 163/164, Loss: 0.458078, Accuracy: 84.69%\n",
            "Epoch: 22, Step: 164/164, Loss: 0.457404, Accuracy: 84.71%\n",
            "Epoch: 23, Step: 1/164, Loss: 0.424365, Accuracy: 86.72%\n",
            "Epoch: 23, Step: 2/164, Loss: 0.403360, Accuracy: 85.55%\n",
            "Epoch: 23, Step: 3/164, Loss: 0.416076, Accuracy: 85.16%\n",
            "Epoch: 23, Step: 4/164, Loss: 0.409592, Accuracy: 85.74%\n",
            "Epoch: 23, Step: 5/164, Loss: 0.402476, Accuracy: 86.56%\n",
            "Epoch: 23, Step: 6/164, Loss: 0.425636, Accuracy: 85.94%\n",
            "Epoch: 23, Step: 7/164, Loss: 0.415226, Accuracy: 86.05%\n",
            "Epoch: 23, Step: 8/164, Loss: 0.419186, Accuracy: 85.74%\n",
            "Epoch: 23, Step: 9/164, Loss: 0.421192, Accuracy: 85.42%\n",
            "Epoch: 23, Step: 10/164, Loss: 0.429334, Accuracy: 84.92%\n",
            "Epoch: 23, Step: 11/164, Loss: 0.430818, Accuracy: 85.23%\n",
            "Epoch: 23, Step: 12/164, Loss: 0.426234, Accuracy: 85.61%\n",
            "Epoch: 23, Step: 13/164, Loss: 0.428443, Accuracy: 85.58%\n",
            "Epoch: 23, Step: 14/164, Loss: 0.431691, Accuracy: 85.38%\n",
            "Epoch: 23, Step: 15/164, Loss: 0.433950, Accuracy: 85.16%\n",
            "Epoch: 23, Step: 16/164, Loss: 0.431990, Accuracy: 85.25%\n",
            "Epoch: 23, Step: 17/164, Loss: 0.433618, Accuracy: 85.20%\n",
            "Epoch: 23, Step: 18/164, Loss: 0.436779, Accuracy: 85.07%\n",
            "Epoch: 23, Step: 19/164, Loss: 0.435714, Accuracy: 84.99%\n",
            "Epoch: 23, Step: 20/164, Loss: 0.444182, Accuracy: 84.77%\n",
            "Epoch: 23, Step: 21/164, Loss: 0.445284, Accuracy: 84.78%\n",
            "Epoch: 23, Step: 22/164, Loss: 0.445274, Accuracy: 84.91%\n",
            "Epoch: 23, Step: 23/164, Loss: 0.452763, Accuracy: 84.75%\n",
            "Epoch: 23, Step: 24/164, Loss: 0.455853, Accuracy: 84.60%\n",
            "Epoch: 23, Step: 25/164, Loss: 0.458164, Accuracy: 84.53%\n",
            "Epoch: 23, Step: 26/164, Loss: 0.453427, Accuracy: 84.68%\n",
            "Epoch: 23, Step: 27/164, Loss: 0.456597, Accuracy: 84.69%\n",
            "Epoch: 23, Step: 28/164, Loss: 0.456661, Accuracy: 84.71%\n",
            "Epoch: 23, Step: 29/164, Loss: 0.451259, Accuracy: 84.91%\n",
            "Epoch: 23, Step: 30/164, Loss: 0.451437, Accuracy: 84.79%\n",
            "Epoch: 23, Step: 31/164, Loss: 0.449834, Accuracy: 84.80%\n",
            "Epoch: 23, Step: 32/164, Loss: 0.449594, Accuracy: 84.84%\n",
            "Epoch: 23, Step: 33/164, Loss: 0.447374, Accuracy: 84.92%\n",
            "Epoch: 23, Step: 34/164, Loss: 0.444205, Accuracy: 84.95%\n",
            "Epoch: 23, Step: 35/164, Loss: 0.444206, Accuracy: 84.91%\n",
            "Epoch: 23, Step: 36/164, Loss: 0.445192, Accuracy: 84.87%\n",
            "Epoch: 23, Step: 37/164, Loss: 0.442872, Accuracy: 84.92%\n",
            "Epoch: 23, Step: 38/164, Loss: 0.444785, Accuracy: 84.87%\n",
            "Epoch: 23, Step: 39/164, Loss: 0.449192, Accuracy: 84.68%\n",
            "Epoch: 23, Step: 40/164, Loss: 0.451935, Accuracy: 84.49%\n",
            "Epoch: 23, Step: 41/164, Loss: 0.450811, Accuracy: 84.57%\n",
            "Epoch: 23, Step: 42/164, Loss: 0.450341, Accuracy: 84.60%\n",
            "Epoch: 23, Step: 43/164, Loss: 0.447163, Accuracy: 84.68%\n",
            "Epoch: 23, Step: 44/164, Loss: 0.448641, Accuracy: 84.61%\n",
            "Epoch: 23, Step: 45/164, Loss: 0.449159, Accuracy: 84.62%\n",
            "Epoch: 23, Step: 46/164, Loss: 0.445728, Accuracy: 84.68%\n",
            "Epoch: 23, Step: 47/164, Loss: 0.448341, Accuracy: 84.61%\n",
            "Epoch: 23, Step: 48/164, Loss: 0.450558, Accuracy: 84.55%\n",
            "Epoch: 23, Step: 49/164, Loss: 0.451569, Accuracy: 84.52%\n",
            "Epoch: 23, Step: 50/164, Loss: 0.451000, Accuracy: 84.53%\n",
            "Epoch: 23, Step: 51/164, Loss: 0.448725, Accuracy: 84.65%\n",
            "Epoch: 23, Step: 52/164, Loss: 0.448526, Accuracy: 84.68%\n",
            "Epoch: 23, Step: 53/164, Loss: 0.448402, Accuracy: 84.64%\n",
            "Epoch: 23, Step: 54/164, Loss: 0.448705, Accuracy: 84.61%\n",
            "Epoch: 23, Step: 55/164, Loss: 0.450085, Accuracy: 84.55%\n",
            "Epoch: 23, Step: 56/164, Loss: 0.453531, Accuracy: 84.43%\n",
            "Epoch: 23, Step: 57/164, Loss: 0.454554, Accuracy: 84.44%\n",
            "Epoch: 23, Step: 58/164, Loss: 0.453769, Accuracy: 84.52%\n",
            "Epoch: 23, Step: 59/164, Loss: 0.455782, Accuracy: 84.44%\n",
            "Epoch: 23, Step: 60/164, Loss: 0.455912, Accuracy: 84.38%\n",
            "Epoch: 23, Step: 61/164, Loss: 0.455290, Accuracy: 84.41%\n",
            "Epoch: 23, Step: 62/164, Loss: 0.454293, Accuracy: 84.46%\n",
            "Epoch: 23, Step: 63/164, Loss: 0.453919, Accuracy: 84.51%\n",
            "Epoch: 23, Step: 64/164, Loss: 0.453848, Accuracy: 84.53%\n",
            "Epoch: 23, Step: 65/164, Loss: 0.453785, Accuracy: 84.57%\n",
            "Epoch: 23, Step: 66/164, Loss: 0.452650, Accuracy: 84.61%\n",
            "Epoch: 23, Step: 67/164, Loss: 0.454580, Accuracy: 84.57%\n",
            "Epoch: 23, Step: 68/164, Loss: 0.453167, Accuracy: 84.60%\n",
            "Epoch: 23, Step: 69/164, Loss: 0.452747, Accuracy: 84.60%\n",
            "Epoch: 23, Step: 70/164, Loss: 0.451935, Accuracy: 84.61%\n",
            "Epoch: 23, Step: 71/164, Loss: 0.453023, Accuracy: 84.60%\n",
            "Epoch: 23, Step: 72/164, Loss: 0.452427, Accuracy: 84.59%\n",
            "Epoch: 23, Step: 73/164, Loss: 0.453175, Accuracy: 84.56%\n",
            "Epoch: 23, Step: 74/164, Loss: 0.452815, Accuracy: 84.57%\n",
            "Epoch: 23, Step: 75/164, Loss: 0.453196, Accuracy: 84.54%\n",
            "Epoch: 23, Step: 76/164, Loss: 0.452885, Accuracy: 84.53%\n",
            "Epoch: 23, Step: 77/164, Loss: 0.451664, Accuracy: 84.60%\n",
            "Epoch: 23, Step: 78/164, Loss: 0.450857, Accuracy: 84.65%\n",
            "Epoch: 23, Step: 79/164, Loss: 0.450164, Accuracy: 84.65%\n",
            "Epoch: 23, Step: 80/164, Loss: 0.450165, Accuracy: 84.66%\n",
            "Epoch: 23, Step: 81/164, Loss: 0.449012, Accuracy: 84.74%\n",
            "Epoch: 23, Step: 82/164, Loss: 0.447539, Accuracy: 84.77%\n",
            "Epoch: 23, Step: 83/164, Loss: 0.446526, Accuracy: 84.80%\n",
            "Epoch: 23, Step: 84/164, Loss: 0.448155, Accuracy: 84.71%\n",
            "Epoch: 23, Step: 85/164, Loss: 0.448144, Accuracy: 84.69%\n",
            "Epoch: 23, Step: 86/164, Loss: 0.449073, Accuracy: 84.66%\n",
            "Epoch: 23, Step: 87/164, Loss: 0.449074, Accuracy: 84.64%\n",
            "Epoch: 23, Step: 88/164, Loss: 0.449131, Accuracy: 84.61%\n",
            "Epoch: 23, Step: 89/164, Loss: 0.449288, Accuracy: 84.59%\n",
            "Epoch: 23, Step: 90/164, Loss: 0.448401, Accuracy: 84.61%\n",
            "Epoch: 23, Step: 91/164, Loss: 0.449092, Accuracy: 84.61%\n",
            "Epoch: 23, Step: 92/164, Loss: 0.449476, Accuracy: 84.60%\n",
            "Epoch: 23, Step: 93/164, Loss: 0.449643, Accuracy: 84.63%\n",
            "Epoch: 23, Step: 94/164, Loss: 0.450002, Accuracy: 84.66%\n",
            "Epoch: 23, Step: 95/164, Loss: 0.450250, Accuracy: 84.66%\n",
            "Epoch: 23, Step: 96/164, Loss: 0.449343, Accuracy: 84.68%\n",
            "Epoch: 23, Step: 97/164, Loss: 0.448993, Accuracy: 84.71%\n",
            "Epoch: 23, Step: 98/164, Loss: 0.448887, Accuracy: 84.70%\n",
            "Epoch: 23, Step: 99/164, Loss: 0.450176, Accuracy: 84.66%\n",
            "Epoch: 23, Step: 100/164, Loss: 0.451316, Accuracy: 84.62%\n",
            "Epoch: 23, Step: 101/164, Loss: 0.452018, Accuracy: 84.61%\n",
            "Epoch: 23, Step: 102/164, Loss: 0.452872, Accuracy: 84.56%\n",
            "Epoch: 23, Step: 103/164, Loss: 0.452787, Accuracy: 84.54%\n",
            "Epoch: 23, Step: 104/164, Loss: 0.452928, Accuracy: 84.56%\n",
            "Epoch: 23, Step: 105/164, Loss: 0.451645, Accuracy: 84.61%\n",
            "Epoch: 23, Step: 106/164, Loss: 0.450961, Accuracy: 84.63%\n",
            "Epoch: 23, Step: 107/164, Loss: 0.450392, Accuracy: 84.61%\n",
            "Epoch: 23, Step: 108/164, Loss: 0.449964, Accuracy: 84.64%\n",
            "Epoch: 23, Step: 109/164, Loss: 0.449939, Accuracy: 84.59%\n",
            "Epoch: 23, Step: 110/164, Loss: 0.449459, Accuracy: 84.60%\n",
            "Epoch: 23, Step: 111/164, Loss: 0.449674, Accuracy: 84.58%\n",
            "Epoch: 23, Step: 112/164, Loss: 0.449977, Accuracy: 84.56%\n",
            "Epoch: 23, Step: 113/164, Loss: 0.450871, Accuracy: 84.55%\n",
            "Epoch: 23, Step: 114/164, Loss: 0.450637, Accuracy: 84.55%\n",
            "Epoch: 23, Step: 115/164, Loss: 0.451347, Accuracy: 84.52%\n",
            "Epoch: 23, Step: 116/164, Loss: 0.450847, Accuracy: 84.54%\n",
            "Epoch: 23, Step: 117/164, Loss: 0.450688, Accuracy: 84.55%\n",
            "Epoch: 23, Step: 118/164, Loss: 0.451186, Accuracy: 84.50%\n",
            "Epoch: 23, Step: 119/164, Loss: 0.452084, Accuracy: 84.47%\n",
            "Epoch: 23, Step: 120/164, Loss: 0.451817, Accuracy: 84.50%\n",
            "Epoch: 23, Step: 121/164, Loss: 0.452945, Accuracy: 84.48%\n",
            "Epoch: 23, Step: 122/164, Loss: 0.452292, Accuracy: 84.50%\n",
            "Epoch: 23, Step: 123/164, Loss: 0.451026, Accuracy: 84.56%\n",
            "Epoch: 23, Step: 124/164, Loss: 0.450912, Accuracy: 84.55%\n",
            "Epoch: 23, Step: 125/164, Loss: 0.450613, Accuracy: 84.56%\n",
            "Epoch: 23, Step: 126/164, Loss: 0.450338, Accuracy: 84.57%\n",
            "Epoch: 23, Step: 127/164, Loss: 0.450061, Accuracy: 84.55%\n",
            "Epoch: 23, Step: 128/164, Loss: 0.449780, Accuracy: 84.55%\n",
            "Epoch: 23, Step: 129/164, Loss: 0.449747, Accuracy: 84.55%\n",
            "Epoch: 23, Step: 130/164, Loss: 0.450060, Accuracy: 84.56%\n",
            "Epoch: 23, Step: 131/164, Loss: 0.450089, Accuracy: 84.55%\n",
            "Epoch: 23, Step: 132/164, Loss: 0.450494, Accuracy: 84.56%\n",
            "Epoch: 23, Step: 133/164, Loss: 0.451219, Accuracy: 84.57%\n",
            "Epoch: 23, Step: 134/164, Loss: 0.451815, Accuracy: 84.56%\n",
            "Epoch: 23, Step: 135/164, Loss: 0.452359, Accuracy: 84.55%\n",
            "Epoch: 23, Step: 136/164, Loss: 0.453375, Accuracy: 84.52%\n",
            "Epoch: 23, Step: 137/164, Loss: 0.452952, Accuracy: 84.55%\n",
            "Epoch: 23, Step: 138/164, Loss: 0.453281, Accuracy: 84.54%\n",
            "Epoch: 23, Step: 139/164, Loss: 0.453846, Accuracy: 84.53%\n",
            "Epoch: 23, Step: 140/164, Loss: 0.454784, Accuracy: 84.50%\n",
            "Epoch: 23, Step: 141/164, Loss: 0.453980, Accuracy: 84.52%\n",
            "Epoch: 23, Step: 142/164, Loss: 0.453938, Accuracy: 84.53%\n",
            "Epoch: 23, Step: 143/164, Loss: 0.453941, Accuracy: 84.52%\n",
            "Epoch: 23, Step: 144/164, Loss: 0.453714, Accuracy: 84.54%\n",
            "Epoch: 23, Step: 145/164, Loss: 0.452544, Accuracy: 84.55%\n",
            "Epoch: 23, Step: 146/164, Loss: 0.453499, Accuracy: 84.50%\n",
            "Epoch: 23, Step: 147/164, Loss: 0.453474, Accuracy: 84.50%\n",
            "Epoch: 23, Step: 148/164, Loss: 0.453621, Accuracy: 84.52%\n",
            "Epoch: 23, Step: 149/164, Loss: 0.452935, Accuracy: 84.54%\n",
            "Epoch: 23, Step: 150/164, Loss: 0.453066, Accuracy: 84.56%\n",
            "Epoch: 23, Step: 151/164, Loss: 0.454012, Accuracy: 84.54%\n",
            "Epoch: 23, Step: 152/164, Loss: 0.454148, Accuracy: 84.54%\n",
            "Epoch: 23, Step: 153/164, Loss: 0.453568, Accuracy: 84.57%\n",
            "Epoch: 23, Step: 154/164, Loss: 0.452969, Accuracy: 84.60%\n",
            "Epoch: 23, Step: 155/164, Loss: 0.453516, Accuracy: 84.59%\n",
            "Epoch: 23, Step: 156/164, Loss: 0.453786, Accuracy: 84.58%\n",
            "Epoch: 23, Step: 157/164, Loss: 0.453433, Accuracy: 84.59%\n",
            "Epoch: 23, Step: 158/164, Loss: 0.453674, Accuracy: 84.56%\n",
            "Epoch: 23, Step: 159/164, Loss: 0.453281, Accuracy: 84.56%\n",
            "Epoch: 23, Step: 160/164, Loss: 0.453745, Accuracy: 84.55%\n",
            "Epoch: 23, Step: 161/164, Loss: 0.453576, Accuracy: 84.54%\n",
            "Epoch: 23, Step: 162/164, Loss: 0.452569, Accuracy: 84.58%\n",
            "Epoch: 23, Step: 163/164, Loss: 0.452650, Accuracy: 84.60%\n",
            "Epoch: 23, Step: 164/164, Loss: 0.453000, Accuracy: 84.60%\n",
            "Epoch: 24, Step: 1/164, Loss: 0.361739, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 2/164, Loss: 0.411613, Accuracy: 84.77%\n",
            "Epoch: 24, Step: 3/164, Loss: 0.406853, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 4/164, Loss: 0.410268, Accuracy: 85.94%\n",
            "Epoch: 24, Step: 5/164, Loss: 0.412600, Accuracy: 85.78%\n",
            "Epoch: 24, Step: 6/164, Loss: 0.389702, Accuracy: 86.46%\n",
            "Epoch: 24, Step: 7/164, Loss: 0.408645, Accuracy: 85.27%\n",
            "Epoch: 24, Step: 8/164, Loss: 0.418045, Accuracy: 85.55%\n",
            "Epoch: 24, Step: 9/164, Loss: 0.410749, Accuracy: 85.59%\n",
            "Epoch: 24, Step: 10/164, Loss: 0.418841, Accuracy: 85.70%\n",
            "Epoch: 24, Step: 11/164, Loss: 0.422390, Accuracy: 85.65%\n",
            "Epoch: 24, Step: 12/164, Loss: 0.439874, Accuracy: 84.90%\n",
            "Epoch: 24, Step: 13/164, Loss: 0.439199, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 14/164, Loss: 0.440131, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 15/164, Loss: 0.448754, Accuracy: 85.10%\n",
            "Epoch: 24, Step: 16/164, Loss: 0.449491, Accuracy: 84.96%\n",
            "Epoch: 24, Step: 17/164, Loss: 0.455784, Accuracy: 84.70%\n",
            "Epoch: 24, Step: 18/164, Loss: 0.453263, Accuracy: 84.81%\n",
            "Epoch: 24, Step: 19/164, Loss: 0.454762, Accuracy: 84.75%\n",
            "Epoch: 24, Step: 20/164, Loss: 0.454840, Accuracy: 84.92%\n",
            "Epoch: 24, Step: 21/164, Loss: 0.457777, Accuracy: 84.78%\n",
            "Epoch: 24, Step: 22/164, Loss: 0.459531, Accuracy: 84.73%\n",
            "Epoch: 24, Step: 23/164, Loss: 0.464094, Accuracy: 84.65%\n",
            "Epoch: 24, Step: 24/164, Loss: 0.465190, Accuracy: 84.67%\n",
            "Epoch: 24, Step: 25/164, Loss: 0.465072, Accuracy: 84.72%\n",
            "Epoch: 24, Step: 26/164, Loss: 0.463282, Accuracy: 84.80%\n",
            "Epoch: 24, Step: 27/164, Loss: 0.463961, Accuracy: 84.87%\n",
            "Epoch: 24, Step: 28/164, Loss: 0.465874, Accuracy: 84.77%\n",
            "Epoch: 24, Step: 29/164, Loss: 0.466513, Accuracy: 84.62%\n",
            "Epoch: 24, Step: 30/164, Loss: 0.464915, Accuracy: 84.61%\n",
            "Epoch: 24, Step: 31/164, Loss: 0.463382, Accuracy: 84.60%\n",
            "Epoch: 24, Step: 32/164, Loss: 0.459824, Accuracy: 84.86%\n",
            "Epoch: 24, Step: 33/164, Loss: 0.457757, Accuracy: 84.97%\n",
            "Epoch: 24, Step: 34/164, Loss: 0.459335, Accuracy: 84.97%\n",
            "Epoch: 24, Step: 35/164, Loss: 0.460757, Accuracy: 84.89%\n",
            "Epoch: 24, Step: 36/164, Loss: 0.459134, Accuracy: 84.94%\n",
            "Epoch: 24, Step: 37/164, Loss: 0.456000, Accuracy: 85.01%\n",
            "Epoch: 24, Step: 38/164, Loss: 0.455487, Accuracy: 85.03%\n",
            "Epoch: 24, Step: 39/164, Loss: 0.454639, Accuracy: 85.06%\n",
            "Epoch: 24, Step: 40/164, Loss: 0.456271, Accuracy: 84.96%\n",
            "Epoch: 24, Step: 41/164, Loss: 0.456780, Accuracy: 84.91%\n",
            "Epoch: 24, Step: 42/164, Loss: 0.457768, Accuracy: 84.91%\n",
            "Epoch: 24, Step: 43/164, Loss: 0.458770, Accuracy: 84.79%\n",
            "Epoch: 24, Step: 44/164, Loss: 0.456028, Accuracy: 84.84%\n",
            "Epoch: 24, Step: 45/164, Loss: 0.456766, Accuracy: 84.74%\n",
            "Epoch: 24, Step: 46/164, Loss: 0.455704, Accuracy: 84.71%\n",
            "Epoch: 24, Step: 47/164, Loss: 0.454914, Accuracy: 84.77%\n",
            "Epoch: 24, Step: 48/164, Loss: 0.453293, Accuracy: 84.83%\n",
            "Epoch: 24, Step: 49/164, Loss: 0.453070, Accuracy: 84.87%\n",
            "Epoch: 24, Step: 50/164, Loss: 0.453668, Accuracy: 84.86%\n",
            "Epoch: 24, Step: 51/164, Loss: 0.452447, Accuracy: 84.83%\n",
            "Epoch: 24, Step: 52/164, Loss: 0.450146, Accuracy: 84.92%\n",
            "Epoch: 24, Step: 53/164, Loss: 0.450223, Accuracy: 84.88%\n",
            "Epoch: 24, Step: 54/164, Loss: 0.448107, Accuracy: 84.95%\n",
            "Epoch: 24, Step: 55/164, Loss: 0.444529, Accuracy: 85.09%\n",
            "Epoch: 24, Step: 56/164, Loss: 0.443255, Accuracy: 85.13%\n",
            "Epoch: 24, Step: 57/164, Loss: 0.443378, Accuracy: 85.12%\n",
            "Epoch: 24, Step: 58/164, Loss: 0.443100, Accuracy: 85.13%\n",
            "Epoch: 24, Step: 59/164, Loss: 0.441879, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 60/164, Loss: 0.440980, Accuracy: 85.20%\n",
            "Epoch: 24, Step: 61/164, Loss: 0.441809, Accuracy: 85.12%\n",
            "Epoch: 24, Step: 62/164, Loss: 0.442356, Accuracy: 85.09%\n",
            "Epoch: 24, Step: 63/164, Loss: 0.440722, Accuracy: 85.14%\n",
            "Epoch: 24, Step: 64/164, Loss: 0.439623, Accuracy: 85.17%\n",
            "Epoch: 24, Step: 65/164, Loss: 0.440240, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 66/164, Loss: 0.437174, Accuracy: 85.27%\n",
            "Epoch: 24, Step: 67/164, Loss: 0.436164, Accuracy: 85.32%\n",
            "Epoch: 24, Step: 68/164, Loss: 0.436199, Accuracy: 85.33%\n",
            "Epoch: 24, Step: 69/164, Loss: 0.436122, Accuracy: 85.34%\n",
            "Epoch: 24, Step: 70/164, Loss: 0.436621, Accuracy: 85.29%\n",
            "Epoch: 24, Step: 71/164, Loss: 0.436805, Accuracy: 85.32%\n",
            "Epoch: 24, Step: 72/164, Loss: 0.434896, Accuracy: 85.38%\n",
            "Epoch: 24, Step: 73/164, Loss: 0.434508, Accuracy: 85.39%\n",
            "Epoch: 24, Step: 74/164, Loss: 0.433787, Accuracy: 85.42%\n",
            "Epoch: 24, Step: 75/164, Loss: 0.434258, Accuracy: 85.39%\n",
            "Epoch: 24, Step: 76/164, Loss: 0.433958, Accuracy: 85.35%\n",
            "Epoch: 24, Step: 77/164, Loss: 0.433808, Accuracy: 85.35%\n",
            "Epoch: 24, Step: 78/164, Loss: 0.435673, Accuracy: 85.28%\n",
            "Epoch: 24, Step: 79/164, Loss: 0.435662, Accuracy: 85.28%\n",
            "Epoch: 24, Step: 80/164, Loss: 0.435203, Accuracy: 85.33%\n",
            "Epoch: 24, Step: 81/164, Loss: 0.435391, Accuracy: 85.32%\n",
            "Epoch: 24, Step: 82/164, Loss: 0.434506, Accuracy: 85.36%\n",
            "Epoch: 24, Step: 83/164, Loss: 0.435741, Accuracy: 85.32%\n",
            "Epoch: 24, Step: 84/164, Loss: 0.435048, Accuracy: 85.35%\n",
            "Epoch: 24, Step: 85/164, Loss: 0.437550, Accuracy: 85.26%\n",
            "Epoch: 24, Step: 86/164, Loss: 0.436499, Accuracy: 85.27%\n",
            "Epoch: 24, Step: 87/164, Loss: 0.436146, Accuracy: 85.29%\n",
            "Epoch: 24, Step: 88/164, Loss: 0.436862, Accuracy: 85.29%\n",
            "Epoch: 24, Step: 89/164, Loss: 0.437330, Accuracy: 85.26%\n",
            "Epoch: 24, Step: 90/164, Loss: 0.435833, Accuracy: 85.31%\n",
            "Epoch: 24, Step: 91/164, Loss: 0.434799, Accuracy: 85.35%\n",
            "Epoch: 24, Step: 92/164, Loss: 0.435613, Accuracy: 85.31%\n",
            "Epoch: 24, Step: 93/164, Loss: 0.435702, Accuracy: 85.27%\n",
            "Epoch: 24, Step: 94/164, Loss: 0.435855, Accuracy: 85.26%\n",
            "Epoch: 24, Step: 95/164, Loss: 0.435698, Accuracy: 85.23%\n",
            "Epoch: 24, Step: 96/164, Loss: 0.436590, Accuracy: 85.21%\n",
            "Epoch: 24, Step: 97/164, Loss: 0.436719, Accuracy: 85.22%\n",
            "Epoch: 24, Step: 98/164, Loss: 0.437223, Accuracy: 85.19%\n",
            "Epoch: 24, Step: 99/164, Loss: 0.437782, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 100/164, Loss: 0.439140, Accuracy: 85.09%\n",
            "Epoch: 24, Step: 101/164, Loss: 0.439490, Accuracy: 85.09%\n",
            "Epoch: 24, Step: 102/164, Loss: 0.439613, Accuracy: 85.09%\n",
            "Epoch: 24, Step: 103/164, Loss: 0.439453, Accuracy: 85.13%\n",
            "Epoch: 24, Step: 104/164, Loss: 0.439433, Accuracy: 85.13%\n",
            "Epoch: 24, Step: 105/164, Loss: 0.438072, Accuracy: 85.19%\n",
            "Epoch: 24, Step: 106/164, Loss: 0.437425, Accuracy: 85.22%\n",
            "Epoch: 24, Step: 107/164, Loss: 0.437413, Accuracy: 85.24%\n",
            "Epoch: 24, Step: 108/164, Loss: 0.437063, Accuracy: 85.24%\n",
            "Epoch: 24, Step: 109/164, Loss: 0.437320, Accuracy: 85.24%\n",
            "Epoch: 24, Step: 110/164, Loss: 0.437351, Accuracy: 85.23%\n",
            "Epoch: 24, Step: 111/164, Loss: 0.438048, Accuracy: 85.21%\n",
            "Epoch: 24, Step: 112/164, Loss: 0.437376, Accuracy: 85.24%\n",
            "Epoch: 24, Step: 113/164, Loss: 0.437835, Accuracy: 85.20%\n",
            "Epoch: 24, Step: 114/164, Loss: 0.437950, Accuracy: 85.19%\n",
            "Epoch: 24, Step: 115/164, Loss: 0.438475, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 116/164, Loss: 0.438440, Accuracy: 85.15%\n",
            "Epoch: 24, Step: 117/164, Loss: 0.437706, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 118/164, Loss: 0.436391, Accuracy: 85.22%\n",
            "Epoch: 24, Step: 119/164, Loss: 0.437262, Accuracy: 85.18%\n",
            "Epoch: 24, Step: 120/164, Loss: 0.438079, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 121/164, Loss: 0.438008, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 122/164, Loss: 0.439183, Accuracy: 85.12%\n",
            "Epoch: 24, Step: 123/164, Loss: 0.439461, Accuracy: 85.13%\n",
            "Epoch: 24, Step: 124/164, Loss: 0.438696, Accuracy: 85.14%\n",
            "Epoch: 24, Step: 125/164, Loss: 0.438626, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 126/164, Loss: 0.438373, Accuracy: 85.17%\n",
            "Epoch: 24, Step: 127/164, Loss: 0.438753, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 128/164, Loss: 0.439052, Accuracy: 85.13%\n",
            "Epoch: 24, Step: 129/164, Loss: 0.438045, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 130/164, Loss: 0.437626, Accuracy: 85.17%\n",
            "Epoch: 24, Step: 131/164, Loss: 0.437111, Accuracy: 85.19%\n",
            "Epoch: 24, Step: 132/164, Loss: 0.436613, Accuracy: 85.21%\n",
            "Epoch: 24, Step: 133/164, Loss: 0.437295, Accuracy: 85.19%\n",
            "Epoch: 24, Step: 134/164, Loss: 0.438674, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 135/164, Loss: 0.438858, Accuracy: 85.14%\n",
            "Epoch: 24, Step: 136/164, Loss: 0.438064, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 137/164, Loss: 0.437978, Accuracy: 85.14%\n",
            "Epoch: 24, Step: 138/164, Loss: 0.438504, Accuracy: 85.13%\n",
            "Epoch: 24, Step: 139/164, Loss: 0.438004, Accuracy: 85.15%\n",
            "Epoch: 24, Step: 140/164, Loss: 0.437932, Accuracy: 85.16%\n",
            "Epoch: 24, Step: 141/164, Loss: 0.438341, Accuracy: 85.13%\n",
            "Epoch: 24, Step: 142/164, Loss: 0.437959, Accuracy: 85.15%\n",
            "Epoch: 24, Step: 143/164, Loss: 0.438461, Accuracy: 85.13%\n",
            "Epoch: 24, Step: 144/164, Loss: 0.438848, Accuracy: 85.15%\n",
            "Epoch: 24, Step: 145/164, Loss: 0.439434, Accuracy: 85.13%\n",
            "Epoch: 24, Step: 146/164, Loss: 0.439006, Accuracy: 85.13%\n",
            "Epoch: 24, Step: 147/164, Loss: 0.439046, Accuracy: 85.15%\n",
            "Epoch: 24, Step: 148/164, Loss: 0.437557, Accuracy: 85.19%\n",
            "Epoch: 24, Step: 149/164, Loss: 0.437176, Accuracy: 85.22%\n",
            "Epoch: 24, Step: 150/164, Loss: 0.437209, Accuracy: 85.20%\n",
            "Epoch: 24, Step: 151/164, Loss: 0.438048, Accuracy: 85.17%\n",
            "Epoch: 24, Step: 152/164, Loss: 0.437416, Accuracy: 85.19%\n",
            "Epoch: 24, Step: 153/164, Loss: 0.437074, Accuracy: 85.21%\n",
            "Epoch: 24, Step: 154/164, Loss: 0.437443, Accuracy: 85.19%\n",
            "Epoch: 24, Step: 155/164, Loss: 0.436893, Accuracy: 85.21%\n",
            "Epoch: 24, Step: 156/164, Loss: 0.436177, Accuracy: 85.25%\n",
            "Epoch: 24, Step: 157/164, Loss: 0.436072, Accuracy: 85.24%\n",
            "Epoch: 24, Step: 158/164, Loss: 0.435856, Accuracy: 85.22%\n",
            "Epoch: 24, Step: 159/164, Loss: 0.435248, Accuracy: 85.24%\n",
            "Epoch: 24, Step: 160/164, Loss: 0.434725, Accuracy: 85.26%\n",
            "Epoch: 24, Step: 161/164, Loss: 0.434523, Accuracy: 85.26%\n",
            "Epoch: 24, Step: 162/164, Loss: 0.434711, Accuracy: 85.26%\n",
            "Epoch: 24, Step: 163/164, Loss: 0.435261, Accuracy: 85.24%\n",
            "Epoch: 24, Step: 164/164, Loss: 0.435115, Accuracy: 85.25%\n",
            "Epoch: 25, Step: 1/164, Loss: 0.459888, Accuracy: 84.38%\n",
            "Epoch: 25, Step: 2/164, Loss: 0.372814, Accuracy: 87.89%\n",
            "Epoch: 25, Step: 3/164, Loss: 0.437221, Accuracy: 84.90%\n",
            "Epoch: 25, Step: 4/164, Loss: 0.437075, Accuracy: 84.96%\n",
            "Epoch: 25, Step: 5/164, Loss: 0.454658, Accuracy: 83.91%\n",
            "Epoch: 25, Step: 6/164, Loss: 0.457118, Accuracy: 83.85%\n",
            "Epoch: 25, Step: 7/164, Loss: 0.445638, Accuracy: 84.26%\n",
            "Epoch: 25, Step: 8/164, Loss: 0.470721, Accuracy: 83.79%\n",
            "Epoch: 25, Step: 9/164, Loss: 0.459888, Accuracy: 84.03%\n",
            "Epoch: 25, Step: 10/164, Loss: 0.445359, Accuracy: 84.61%\n",
            "Epoch: 25, Step: 11/164, Loss: 0.440497, Accuracy: 84.80%\n",
            "Epoch: 25, Step: 12/164, Loss: 0.444798, Accuracy: 84.64%\n",
            "Epoch: 25, Step: 13/164, Loss: 0.450618, Accuracy: 84.56%\n",
            "Epoch: 25, Step: 14/164, Loss: 0.451230, Accuracy: 84.65%\n",
            "Epoch: 25, Step: 15/164, Loss: 0.452524, Accuracy: 84.58%\n",
            "Epoch: 25, Step: 16/164, Loss: 0.447638, Accuracy: 84.72%\n",
            "Epoch: 25, Step: 17/164, Loss: 0.449399, Accuracy: 84.56%\n",
            "Epoch: 25, Step: 18/164, Loss: 0.451200, Accuracy: 84.59%\n",
            "Epoch: 25, Step: 19/164, Loss: 0.449680, Accuracy: 84.75%\n",
            "Epoch: 25, Step: 20/164, Loss: 0.448806, Accuracy: 84.77%\n",
            "Epoch: 25, Step: 21/164, Loss: 0.448933, Accuracy: 84.67%\n",
            "Epoch: 25, Step: 22/164, Loss: 0.450138, Accuracy: 84.69%\n",
            "Epoch: 25, Step: 23/164, Loss: 0.450052, Accuracy: 84.68%\n",
            "Epoch: 25, Step: 24/164, Loss: 0.446885, Accuracy: 84.80%\n",
            "Epoch: 25, Step: 25/164, Loss: 0.445304, Accuracy: 84.78%\n",
            "Epoch: 25, Step: 26/164, Loss: 0.445146, Accuracy: 84.77%\n",
            "Epoch: 25, Step: 27/164, Loss: 0.450181, Accuracy: 84.64%\n",
            "Epoch: 25, Step: 28/164, Loss: 0.449724, Accuracy: 84.71%\n",
            "Epoch: 25, Step: 29/164, Loss: 0.452110, Accuracy: 84.56%\n",
            "Epoch: 25, Step: 30/164, Loss: 0.447610, Accuracy: 84.77%\n",
            "Epoch: 25, Step: 31/164, Loss: 0.446939, Accuracy: 84.85%\n",
            "Epoch: 25, Step: 32/164, Loss: 0.450648, Accuracy: 84.74%\n",
            "Epoch: 25, Step: 33/164, Loss: 0.450767, Accuracy: 84.68%\n",
            "Epoch: 25, Step: 34/164, Loss: 0.448316, Accuracy: 84.74%\n",
            "Epoch: 25, Step: 35/164, Loss: 0.447085, Accuracy: 84.78%\n",
            "Epoch: 25, Step: 36/164, Loss: 0.444468, Accuracy: 84.90%\n",
            "Epoch: 25, Step: 37/164, Loss: 0.443897, Accuracy: 84.88%\n",
            "Epoch: 25, Step: 38/164, Loss: 0.445663, Accuracy: 84.81%\n",
            "Epoch: 25, Step: 39/164, Loss: 0.446593, Accuracy: 84.74%\n",
            "Epoch: 25, Step: 40/164, Loss: 0.445027, Accuracy: 84.80%\n",
            "Epoch: 25, Step: 41/164, Loss: 0.446320, Accuracy: 84.91%\n",
            "Epoch: 25, Step: 42/164, Loss: 0.445393, Accuracy: 84.95%\n",
            "Epoch: 25, Step: 43/164, Loss: 0.444724, Accuracy: 84.94%\n",
            "Epoch: 25, Step: 44/164, Loss: 0.444398, Accuracy: 84.93%\n",
            "Epoch: 25, Step: 45/164, Loss: 0.444250, Accuracy: 84.95%\n",
            "Epoch: 25, Step: 46/164, Loss: 0.443874, Accuracy: 84.99%\n",
            "Epoch: 25, Step: 47/164, Loss: 0.444781, Accuracy: 84.89%\n",
            "Epoch: 25, Step: 48/164, Loss: 0.443918, Accuracy: 84.96%\n",
            "Epoch: 25, Step: 49/164, Loss: 0.442174, Accuracy: 85.04%\n",
            "Epoch: 25, Step: 50/164, Loss: 0.443550, Accuracy: 84.97%\n",
            "Epoch: 25, Step: 51/164, Loss: 0.442931, Accuracy: 84.99%\n",
            "Epoch: 25, Step: 52/164, Loss: 0.441758, Accuracy: 84.99%\n",
            "Epoch: 25, Step: 53/164, Loss: 0.442157, Accuracy: 85.04%\n",
            "Epoch: 25, Step: 54/164, Loss: 0.440108, Accuracy: 85.16%\n",
            "Epoch: 25, Step: 55/164, Loss: 0.443631, Accuracy: 85.10%\n",
            "Epoch: 25, Step: 56/164, Loss: 0.442421, Accuracy: 85.11%\n",
            "Epoch: 25, Step: 57/164, Loss: 0.441499, Accuracy: 85.12%\n",
            "Epoch: 25, Step: 58/164, Loss: 0.445220, Accuracy: 85.04%\n",
            "Epoch: 25, Step: 59/164, Loss: 0.442542, Accuracy: 85.14%\n",
            "Epoch: 25, Step: 60/164, Loss: 0.440643, Accuracy: 85.22%\n",
            "Epoch: 25, Step: 61/164, Loss: 0.442813, Accuracy: 85.14%\n",
            "Epoch: 25, Step: 62/164, Loss: 0.443456, Accuracy: 85.14%\n",
            "Epoch: 25, Step: 63/164, Loss: 0.442343, Accuracy: 85.18%\n",
            "Epoch: 25, Step: 64/164, Loss: 0.441874, Accuracy: 85.19%\n",
            "Epoch: 25, Step: 65/164, Loss: 0.442368, Accuracy: 85.17%\n",
            "Epoch: 25, Step: 66/164, Loss: 0.442488, Accuracy: 85.19%\n",
            "Epoch: 25, Step: 67/164, Loss: 0.443207, Accuracy: 85.18%\n",
            "Epoch: 25, Step: 68/164, Loss: 0.441737, Accuracy: 85.25%\n",
            "Epoch: 25, Step: 69/164, Loss: 0.442985, Accuracy: 85.24%\n",
            "Epoch: 25, Step: 70/164, Loss: 0.442647, Accuracy: 85.26%\n",
            "Epoch: 25, Step: 71/164, Loss: 0.442652, Accuracy: 85.27%\n",
            "Epoch: 25, Step: 72/164, Loss: 0.442104, Accuracy: 85.32%\n",
            "Epoch: 25, Step: 73/164, Loss: 0.442945, Accuracy: 85.23%\n",
            "Epoch: 25, Step: 74/164, Loss: 0.443035, Accuracy: 85.25%\n",
            "Epoch: 25, Step: 75/164, Loss: 0.443400, Accuracy: 85.27%\n",
            "Epoch: 25, Step: 76/164, Loss: 0.445097, Accuracy: 85.28%\n",
            "Epoch: 25, Step: 77/164, Loss: 0.444998, Accuracy: 85.29%\n",
            "Epoch: 25, Step: 78/164, Loss: 0.445433, Accuracy: 85.25%\n",
            "Epoch: 25, Step: 79/164, Loss: 0.444579, Accuracy: 85.28%\n",
            "Epoch: 25, Step: 80/164, Loss: 0.444319, Accuracy: 85.30%\n",
            "Epoch: 25, Step: 81/164, Loss: 0.444243, Accuracy: 85.33%\n",
            "Epoch: 25, Step: 82/164, Loss: 0.445832, Accuracy: 85.28%\n",
            "Epoch: 25, Step: 83/164, Loss: 0.446874, Accuracy: 85.25%\n",
            "Epoch: 25, Step: 84/164, Loss: 0.445013, Accuracy: 85.31%\n",
            "Epoch: 25, Step: 85/164, Loss: 0.444614, Accuracy: 85.28%\n",
            "Epoch: 25, Step: 86/164, Loss: 0.444463, Accuracy: 85.27%\n",
            "Epoch: 25, Step: 87/164, Loss: 0.444840, Accuracy: 85.23%\n",
            "Epoch: 25, Step: 88/164, Loss: 0.446315, Accuracy: 85.17%\n",
            "Epoch: 25, Step: 89/164, Loss: 0.446335, Accuracy: 85.11%\n",
            "Epoch: 25, Step: 90/164, Loss: 0.446494, Accuracy: 85.11%\n",
            "Epoch: 25, Step: 91/164, Loss: 0.446261, Accuracy: 85.14%\n",
            "Epoch: 25, Step: 92/164, Loss: 0.447044, Accuracy: 85.10%\n",
            "Epoch: 25, Step: 93/164, Loss: 0.446669, Accuracy: 85.11%\n",
            "Epoch: 25, Step: 94/164, Loss: 0.448221, Accuracy: 85.02%\n",
            "Epoch: 25, Step: 95/164, Loss: 0.448481, Accuracy: 85.01%\n",
            "Epoch: 25, Step: 96/164, Loss: 0.446464, Accuracy: 85.07%\n",
            "Epoch: 25, Step: 97/164, Loss: 0.446948, Accuracy: 85.04%\n",
            "Epoch: 25, Step: 98/164, Loss: 0.446670, Accuracy: 85.05%\n",
            "Epoch: 25, Step: 99/164, Loss: 0.446017, Accuracy: 85.09%\n",
            "Epoch: 25, Step: 100/164, Loss: 0.447003, Accuracy: 85.06%\n",
            "Epoch: 25, Step: 101/164, Loss: 0.447385, Accuracy: 85.05%\n",
            "Epoch: 25, Step: 102/164, Loss: 0.445908, Accuracy: 85.10%\n",
            "Epoch: 25, Step: 103/164, Loss: 0.443794, Accuracy: 85.19%\n",
            "Epoch: 25, Step: 104/164, Loss: 0.443400, Accuracy: 85.19%\n",
            "Epoch: 25, Step: 105/164, Loss: 0.442666, Accuracy: 85.21%\n",
            "Epoch: 25, Step: 106/164, Loss: 0.443468, Accuracy: 85.17%\n",
            "Epoch: 25, Step: 107/164, Loss: 0.443058, Accuracy: 85.17%\n",
            "Epoch: 25, Step: 108/164, Loss: 0.441721, Accuracy: 85.20%\n",
            "Epoch: 25, Step: 109/164, Loss: 0.441335, Accuracy: 85.20%\n",
            "Epoch: 25, Step: 110/164, Loss: 0.441405, Accuracy: 85.21%\n",
            "Epoch: 25, Step: 111/164, Loss: 0.440713, Accuracy: 85.21%\n",
            "Epoch: 25, Step: 112/164, Loss: 0.440645, Accuracy: 85.19%\n",
            "Epoch: 25, Step: 113/164, Loss: 0.439373, Accuracy: 85.21%\n",
            "Epoch: 25, Step: 114/164, Loss: 0.438233, Accuracy: 85.26%\n",
            "Epoch: 25, Step: 115/164, Loss: 0.438330, Accuracy: 85.25%\n",
            "Epoch: 25, Step: 116/164, Loss: 0.439229, Accuracy: 85.20%\n",
            "Epoch: 25, Step: 117/164, Loss: 0.439789, Accuracy: 85.18%\n",
            "Epoch: 25, Step: 118/164, Loss: 0.440582, Accuracy: 85.12%\n",
            "Epoch: 25, Step: 119/164, Loss: 0.440018, Accuracy: 85.12%\n",
            "Epoch: 25, Step: 120/164, Loss: 0.440708, Accuracy: 85.11%\n",
            "Epoch: 25, Step: 121/164, Loss: 0.440543, Accuracy: 85.10%\n",
            "Epoch: 25, Step: 122/164, Loss: 0.440203, Accuracy: 85.13%\n",
            "Epoch: 25, Step: 123/164, Loss: 0.439324, Accuracy: 85.14%\n",
            "Epoch: 25, Step: 124/164, Loss: 0.440747, Accuracy: 85.09%\n",
            "Epoch: 25, Step: 125/164, Loss: 0.439868, Accuracy: 85.11%\n",
            "Epoch: 25, Step: 126/164, Loss: 0.440776, Accuracy: 85.09%\n",
            "Epoch: 25, Step: 127/164, Loss: 0.441055, Accuracy: 85.07%\n",
            "Epoch: 25, Step: 128/164, Loss: 0.441280, Accuracy: 85.05%\n",
            "Epoch: 25, Step: 129/164, Loss: 0.441375, Accuracy: 85.02%\n",
            "Epoch: 25, Step: 130/164, Loss: 0.441365, Accuracy: 84.99%\n",
            "Epoch: 25, Step: 131/164, Loss: 0.441004, Accuracy: 85.00%\n",
            "Epoch: 25, Step: 132/164, Loss: 0.440820, Accuracy: 85.01%\n",
            "Epoch: 25, Step: 133/164, Loss: 0.440769, Accuracy: 85.00%\n",
            "Epoch: 25, Step: 134/164, Loss: 0.439480, Accuracy: 85.05%\n",
            "Epoch: 25, Step: 135/164, Loss: 0.438995, Accuracy: 85.06%\n",
            "Epoch: 25, Step: 136/164, Loss: 0.439439, Accuracy: 85.04%\n",
            "Epoch: 25, Step: 137/164, Loss: 0.440016, Accuracy: 85.00%\n",
            "Epoch: 25, Step: 138/164, Loss: 0.439489, Accuracy: 85.05%\n",
            "Epoch: 25, Step: 139/164, Loss: 0.438878, Accuracy: 85.09%\n",
            "Epoch: 25, Step: 140/164, Loss: 0.439519, Accuracy: 85.06%\n",
            "Epoch: 25, Step: 141/164, Loss: 0.439246, Accuracy: 85.05%\n",
            "Epoch: 25, Step: 142/164, Loss: 0.439510, Accuracy: 85.03%\n",
            "Epoch: 25, Step: 143/164, Loss: 0.439298, Accuracy: 85.05%\n",
            "Epoch: 25, Step: 144/164, Loss: 0.438901, Accuracy: 85.07%\n",
            "Epoch: 25, Step: 145/164, Loss: 0.439022, Accuracy: 85.08%\n",
            "Epoch: 25, Step: 146/164, Loss: 0.440198, Accuracy: 85.04%\n",
            "Epoch: 25, Step: 147/164, Loss: 0.439802, Accuracy: 85.07%\n",
            "Epoch: 25, Step: 148/164, Loss: 0.441313, Accuracy: 85.03%\n",
            "Epoch: 25, Step: 149/164, Loss: 0.441015, Accuracy: 85.03%\n",
            "Epoch: 25, Step: 150/164, Loss: 0.440984, Accuracy: 85.03%\n",
            "Epoch: 25, Step: 151/164, Loss: 0.440248, Accuracy: 85.05%\n",
            "Epoch: 25, Step: 152/164, Loss: 0.440668, Accuracy: 85.03%\n",
            "Epoch: 25, Step: 153/164, Loss: 0.440356, Accuracy: 85.05%\n",
            "Epoch: 25, Step: 154/164, Loss: 0.439961, Accuracy: 85.04%\n",
            "Epoch: 25, Step: 155/164, Loss: 0.439515, Accuracy: 85.05%\n",
            "Epoch: 25, Step: 156/164, Loss: 0.439461, Accuracy: 85.06%\n",
            "Epoch: 25, Step: 157/164, Loss: 0.439224, Accuracy: 85.06%\n",
            "Epoch: 25, Step: 158/164, Loss: 0.438578, Accuracy: 85.10%\n",
            "Epoch: 25, Step: 159/164, Loss: 0.439385, Accuracy: 85.06%\n",
            "Epoch: 25, Step: 160/164, Loss: 0.439264, Accuracy: 85.06%\n",
            "Epoch: 25, Step: 161/164, Loss: 0.438751, Accuracy: 85.09%\n",
            "Epoch: 25, Step: 162/164, Loss: 0.438552, Accuracy: 85.09%\n",
            "Epoch: 25, Step: 163/164, Loss: 0.438922, Accuracy: 85.07%\n",
            "Epoch: 25, Step: 164/164, Loss: 0.440059, Accuracy: 85.06%\n",
            "Epoch: 26, Step: 1/164, Loss: 0.358894, Accuracy: 89.06%\n",
            "Epoch: 26, Step: 2/164, Loss: 0.345700, Accuracy: 89.84%\n",
            "Epoch: 26, Step: 3/164, Loss: 0.397726, Accuracy: 87.76%\n",
            "Epoch: 26, Step: 4/164, Loss: 0.430860, Accuracy: 85.74%\n",
            "Epoch: 26, Step: 5/164, Loss: 0.394341, Accuracy: 87.03%\n",
            "Epoch: 26, Step: 6/164, Loss: 0.423608, Accuracy: 85.94%\n",
            "Epoch: 26, Step: 7/164, Loss: 0.422642, Accuracy: 85.83%\n",
            "Epoch: 26, Step: 8/164, Loss: 0.438048, Accuracy: 85.25%\n",
            "Epoch: 26, Step: 9/164, Loss: 0.444826, Accuracy: 84.98%\n",
            "Epoch: 26, Step: 10/164, Loss: 0.432873, Accuracy: 85.23%\n",
            "Epoch: 26, Step: 11/164, Loss: 0.422342, Accuracy: 85.58%\n",
            "Epoch: 26, Step: 12/164, Loss: 0.429829, Accuracy: 85.35%\n",
            "Epoch: 26, Step: 13/164, Loss: 0.423264, Accuracy: 85.82%\n",
            "Epoch: 26, Step: 14/164, Loss: 0.425781, Accuracy: 85.60%\n",
            "Epoch: 26, Step: 15/164, Loss: 0.425913, Accuracy: 85.57%\n",
            "Epoch: 26, Step: 16/164, Loss: 0.424110, Accuracy: 85.64%\n",
            "Epoch: 26, Step: 17/164, Loss: 0.415163, Accuracy: 86.08%\n",
            "Epoch: 26, Step: 18/164, Loss: 0.418785, Accuracy: 85.98%\n",
            "Epoch: 26, Step: 19/164, Loss: 0.419366, Accuracy: 86.02%\n",
            "Epoch: 26, Step: 20/164, Loss: 0.413091, Accuracy: 86.13%\n",
            "Epoch: 26, Step: 21/164, Loss: 0.411308, Accuracy: 86.16%\n",
            "Epoch: 26, Step: 22/164, Loss: 0.406811, Accuracy: 86.33%\n",
            "Epoch: 26, Step: 23/164, Loss: 0.401849, Accuracy: 86.51%\n",
            "Epoch: 26, Step: 24/164, Loss: 0.399115, Accuracy: 86.65%\n",
            "Epoch: 26, Step: 25/164, Loss: 0.397847, Accuracy: 86.75%\n",
            "Epoch: 26, Step: 26/164, Loss: 0.403273, Accuracy: 86.66%\n",
            "Epoch: 26, Step: 27/164, Loss: 0.401288, Accuracy: 86.72%\n",
            "Epoch: 26, Step: 28/164, Loss: 0.403211, Accuracy: 86.64%\n",
            "Epoch: 26, Step: 29/164, Loss: 0.401706, Accuracy: 86.69%\n",
            "Epoch: 26, Step: 30/164, Loss: 0.404105, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 31/164, Loss: 0.405951, Accuracy: 86.49%\n",
            "Epoch: 26, Step: 32/164, Loss: 0.406324, Accuracy: 86.40%\n",
            "Epoch: 26, Step: 33/164, Loss: 0.405354, Accuracy: 86.39%\n",
            "Epoch: 26, Step: 34/164, Loss: 0.405942, Accuracy: 86.37%\n",
            "Epoch: 26, Step: 35/164, Loss: 0.402373, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 36/164, Loss: 0.402627, Accuracy: 86.50%\n",
            "Epoch: 26, Step: 37/164, Loss: 0.399923, Accuracy: 86.59%\n",
            "Epoch: 26, Step: 38/164, Loss: 0.398191, Accuracy: 86.57%\n",
            "Epoch: 26, Step: 39/164, Loss: 0.400617, Accuracy: 86.48%\n",
            "Epoch: 26, Step: 40/164, Loss: 0.400904, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 41/164, Loss: 0.399657, Accuracy: 86.53%\n",
            "Epoch: 26, Step: 42/164, Loss: 0.401924, Accuracy: 86.38%\n",
            "Epoch: 26, Step: 43/164, Loss: 0.401044, Accuracy: 86.41%\n",
            "Epoch: 26, Step: 44/164, Loss: 0.401890, Accuracy: 86.40%\n",
            "Epoch: 26, Step: 45/164, Loss: 0.399794, Accuracy: 86.48%\n",
            "Epoch: 26, Step: 46/164, Loss: 0.400120, Accuracy: 86.48%\n",
            "Epoch: 26, Step: 47/164, Loss: 0.399871, Accuracy: 86.50%\n",
            "Epoch: 26, Step: 48/164, Loss: 0.399722, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 49/164, Loss: 0.400048, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 50/164, Loss: 0.402594, Accuracy: 86.48%\n",
            "Epoch: 26, Step: 51/164, Loss: 0.402535, Accuracy: 86.46%\n",
            "Epoch: 26, Step: 52/164, Loss: 0.401621, Accuracy: 86.46%\n",
            "Epoch: 26, Step: 53/164, Loss: 0.404645, Accuracy: 86.39%\n",
            "Epoch: 26, Step: 54/164, Loss: 0.403408, Accuracy: 86.47%\n",
            "Epoch: 26, Step: 55/164, Loss: 0.404210, Accuracy: 86.46%\n",
            "Epoch: 26, Step: 56/164, Loss: 0.402341, Accuracy: 86.52%\n",
            "Epoch: 26, Step: 57/164, Loss: 0.403043, Accuracy: 86.49%\n",
            "Epoch: 26, Step: 58/164, Loss: 0.407216, Accuracy: 86.37%\n",
            "Epoch: 26, Step: 59/164, Loss: 0.406271, Accuracy: 86.45%\n",
            "Epoch: 26, Step: 60/164, Loss: 0.407326, Accuracy: 86.42%\n",
            "Epoch: 26, Step: 61/164, Loss: 0.407419, Accuracy: 86.40%\n",
            "Epoch: 26, Step: 62/164, Loss: 0.407432, Accuracy: 86.37%\n",
            "Epoch: 26, Step: 63/164, Loss: 0.409026, Accuracy: 86.33%\n",
            "Epoch: 26, Step: 64/164, Loss: 0.408316, Accuracy: 86.33%\n",
            "Epoch: 26, Step: 65/164, Loss: 0.406302, Accuracy: 86.41%\n",
            "Epoch: 26, Step: 66/164, Loss: 0.406790, Accuracy: 86.34%\n",
            "Epoch: 26, Step: 67/164, Loss: 0.405739, Accuracy: 86.39%\n",
            "Epoch: 26, Step: 68/164, Loss: 0.407096, Accuracy: 86.34%\n",
            "Epoch: 26, Step: 69/164, Loss: 0.407118, Accuracy: 86.32%\n",
            "Epoch: 26, Step: 70/164, Loss: 0.404734, Accuracy: 86.42%\n",
            "Epoch: 26, Step: 71/164, Loss: 0.405546, Accuracy: 86.37%\n",
            "Epoch: 26, Step: 72/164, Loss: 0.404275, Accuracy: 86.38%\n",
            "Epoch: 26, Step: 73/164, Loss: 0.404373, Accuracy: 86.42%\n",
            "Epoch: 26, Step: 74/164, Loss: 0.403016, Accuracy: 86.44%\n",
            "Epoch: 26, Step: 75/164, Loss: 0.403392, Accuracy: 86.44%\n",
            "Epoch: 26, Step: 76/164, Loss: 0.402176, Accuracy: 86.49%\n",
            "Epoch: 26, Step: 77/164, Loss: 0.405443, Accuracy: 86.40%\n",
            "Epoch: 26, Step: 78/164, Loss: 0.405127, Accuracy: 86.42%\n",
            "Epoch: 26, Step: 79/164, Loss: 0.406407, Accuracy: 86.35%\n",
            "Epoch: 26, Step: 80/164, Loss: 0.407454, Accuracy: 86.32%\n",
            "Epoch: 26, Step: 81/164, Loss: 0.407764, Accuracy: 86.31%\n",
            "Epoch: 26, Step: 82/164, Loss: 0.406533, Accuracy: 86.35%\n",
            "Epoch: 26, Step: 83/164, Loss: 0.406788, Accuracy: 86.32%\n",
            "Epoch: 26, Step: 84/164, Loss: 0.407865, Accuracy: 86.29%\n",
            "Epoch: 26, Step: 85/164, Loss: 0.408325, Accuracy: 86.25%\n",
            "Epoch: 26, Step: 86/164, Loss: 0.406904, Accuracy: 86.27%\n",
            "Epoch: 26, Step: 87/164, Loss: 0.407020, Accuracy: 86.29%\n",
            "Epoch: 26, Step: 88/164, Loss: 0.406312, Accuracy: 86.29%\n",
            "Epoch: 26, Step: 89/164, Loss: 0.405375, Accuracy: 86.31%\n",
            "Epoch: 26, Step: 90/164, Loss: 0.405598, Accuracy: 86.31%\n",
            "Epoch: 26, Step: 91/164, Loss: 0.405031, Accuracy: 86.32%\n",
            "Epoch: 26, Step: 92/164, Loss: 0.403599, Accuracy: 86.40%\n",
            "Epoch: 26, Step: 93/164, Loss: 0.401973, Accuracy: 86.44%\n",
            "Epoch: 26, Step: 94/164, Loss: 0.400754, Accuracy: 86.46%\n",
            "Epoch: 26, Step: 95/164, Loss: 0.401970, Accuracy: 86.41%\n",
            "Epoch: 26, Step: 96/164, Loss: 0.402430, Accuracy: 86.39%\n",
            "Epoch: 26, Step: 97/164, Loss: 0.400802, Accuracy: 86.44%\n",
            "Epoch: 26, Step: 98/164, Loss: 0.400134, Accuracy: 86.47%\n",
            "Epoch: 26, Step: 99/164, Loss: 0.398157, Accuracy: 86.55%\n",
            "Epoch: 26, Step: 100/164, Loss: 0.398409, Accuracy: 86.56%\n",
            "Epoch: 26, Step: 101/164, Loss: 0.398553, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 102/164, Loss: 0.398230, Accuracy: 86.55%\n",
            "Epoch: 26, Step: 103/164, Loss: 0.398504, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 104/164, Loss: 0.398612, Accuracy: 86.52%\n",
            "Epoch: 26, Step: 105/164, Loss: 0.397920, Accuracy: 86.55%\n",
            "Epoch: 26, Step: 106/164, Loss: 0.398463, Accuracy: 86.52%\n",
            "Epoch: 26, Step: 107/164, Loss: 0.398169, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 108/164, Loss: 0.397873, Accuracy: 86.55%\n",
            "Epoch: 26, Step: 109/164, Loss: 0.398014, Accuracy: 86.53%\n",
            "Epoch: 26, Step: 110/164, Loss: 0.396981, Accuracy: 86.55%\n",
            "Epoch: 26, Step: 111/164, Loss: 0.398097, Accuracy: 86.53%\n",
            "Epoch: 26, Step: 112/164, Loss: 0.398055, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 113/164, Loss: 0.398791, Accuracy: 86.50%\n",
            "Epoch: 26, Step: 114/164, Loss: 0.398406, Accuracy: 86.51%\n",
            "Epoch: 26, Step: 115/164, Loss: 0.398784, Accuracy: 86.48%\n",
            "Epoch: 26, Step: 116/164, Loss: 0.398028, Accuracy: 86.50%\n",
            "Epoch: 26, Step: 117/164, Loss: 0.398387, Accuracy: 86.48%\n",
            "Epoch: 26, Step: 118/164, Loss: 0.398567, Accuracy: 86.50%\n",
            "Epoch: 26, Step: 119/164, Loss: 0.398555, Accuracy: 86.50%\n",
            "Epoch: 26, Step: 120/164, Loss: 0.398472, Accuracy: 86.51%\n",
            "Epoch: 26, Step: 121/164, Loss: 0.398403, Accuracy: 86.51%\n",
            "Epoch: 26, Step: 122/164, Loss: 0.399531, Accuracy: 86.47%\n",
            "Epoch: 26, Step: 123/164, Loss: 0.398780, Accuracy: 86.49%\n",
            "Epoch: 26, Step: 124/164, Loss: 0.398868, Accuracy: 86.51%\n",
            "Epoch: 26, Step: 125/164, Loss: 0.399618, Accuracy: 86.48%\n",
            "Epoch: 26, Step: 126/164, Loss: 0.399306, Accuracy: 86.51%\n",
            "Epoch: 26, Step: 127/164, Loss: 0.400736, Accuracy: 86.45%\n",
            "Epoch: 26, Step: 128/164, Loss: 0.401029, Accuracy: 86.47%\n",
            "Epoch: 26, Step: 129/164, Loss: 0.401070, Accuracy: 86.48%\n",
            "Epoch: 26, Step: 130/164, Loss: 0.401536, Accuracy: 86.48%\n",
            "Epoch: 26, Step: 131/164, Loss: 0.402223, Accuracy: 86.43%\n",
            "Epoch: 26, Step: 132/164, Loss: 0.402373, Accuracy: 86.45%\n",
            "Epoch: 26, Step: 133/164, Loss: 0.402255, Accuracy: 86.44%\n",
            "Epoch: 26, Step: 134/164, Loss: 0.402824, Accuracy: 86.42%\n",
            "Epoch: 26, Step: 135/164, Loss: 0.402772, Accuracy: 86.42%\n",
            "Epoch: 26, Step: 136/164, Loss: 0.402834, Accuracy: 86.40%\n",
            "Epoch: 26, Step: 137/164, Loss: 0.401941, Accuracy: 86.45%\n",
            "Epoch: 26, Step: 138/164, Loss: 0.401121, Accuracy: 86.48%\n",
            "Epoch: 26, Step: 139/164, Loss: 0.401343, Accuracy: 86.48%\n",
            "Epoch: 26, Step: 140/164, Loss: 0.400653, Accuracy: 86.51%\n",
            "Epoch: 26, Step: 141/164, Loss: 0.400437, Accuracy: 86.51%\n",
            "Epoch: 26, Step: 142/164, Loss: 0.400285, Accuracy: 86.49%\n",
            "Epoch: 26, Step: 143/164, Loss: 0.399285, Accuracy: 86.53%\n",
            "Epoch: 26, Step: 144/164, Loss: 0.398949, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 145/164, Loss: 0.398413, Accuracy: 86.56%\n",
            "Epoch: 26, Step: 146/164, Loss: 0.398760, Accuracy: 86.55%\n",
            "Epoch: 26, Step: 147/164, Loss: 0.399132, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 148/164, Loss: 0.399464, Accuracy: 86.52%\n",
            "Epoch: 26, Step: 149/164, Loss: 0.399351, Accuracy: 86.52%\n",
            "Epoch: 26, Step: 150/164, Loss: 0.399958, Accuracy: 86.52%\n",
            "Epoch: 26, Step: 151/164, Loss: 0.399263, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 152/164, Loss: 0.399690, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 153/164, Loss: 0.399784, Accuracy: 86.57%\n",
            "Epoch: 26, Step: 154/164, Loss: 0.400046, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 155/164, Loss: 0.400058, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 156/164, Loss: 0.399934, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 157/164, Loss: 0.399823, Accuracy: 86.54%\n",
            "Epoch: 26, Step: 158/164, Loss: 0.400686, Accuracy: 86.53%\n",
            "Epoch: 26, Step: 159/164, Loss: 0.400877, Accuracy: 86.52%\n",
            "Epoch: 26, Step: 160/164, Loss: 0.401083, Accuracy: 86.51%\n",
            "Epoch: 26, Step: 161/164, Loss: 0.401828, Accuracy: 86.51%\n",
            "Epoch: 26, Step: 162/164, Loss: 0.401416, Accuracy: 86.53%\n",
            "Epoch: 26, Step: 163/164, Loss: 0.402472, Accuracy: 86.51%\n",
            "Epoch: 26, Step: 164/164, Loss: 0.402938, Accuracy: 86.52%\n",
            "Epoch: 27, Step: 1/164, Loss: 0.381333, Accuracy: 85.94%\n",
            "Epoch: 27, Step: 2/164, Loss: 0.452168, Accuracy: 83.59%\n",
            "Epoch: 27, Step: 3/164, Loss: 0.428748, Accuracy: 84.64%\n",
            "Epoch: 27, Step: 4/164, Loss: 0.417821, Accuracy: 84.96%\n",
            "Epoch: 27, Step: 5/164, Loss: 0.409094, Accuracy: 85.31%\n",
            "Epoch: 27, Step: 6/164, Loss: 0.387065, Accuracy: 86.46%\n",
            "Epoch: 27, Step: 7/164, Loss: 0.383790, Accuracy: 86.50%\n",
            "Epoch: 27, Step: 8/164, Loss: 0.369844, Accuracy: 87.50%\n",
            "Epoch: 27, Step: 9/164, Loss: 0.376564, Accuracy: 87.24%\n",
            "Epoch: 27, Step: 10/164, Loss: 0.379827, Accuracy: 87.11%\n",
            "Epoch: 27, Step: 11/164, Loss: 0.390017, Accuracy: 86.79%\n",
            "Epoch: 27, Step: 12/164, Loss: 0.383287, Accuracy: 86.98%\n",
            "Epoch: 27, Step: 13/164, Loss: 0.378952, Accuracy: 87.26%\n",
            "Epoch: 27, Step: 14/164, Loss: 0.395134, Accuracy: 86.89%\n",
            "Epoch: 27, Step: 15/164, Loss: 0.394498, Accuracy: 86.77%\n",
            "Epoch: 27, Step: 16/164, Loss: 0.397440, Accuracy: 86.62%\n",
            "Epoch: 27, Step: 17/164, Loss: 0.402221, Accuracy: 86.58%\n",
            "Epoch: 27, Step: 18/164, Loss: 0.403482, Accuracy: 86.41%\n",
            "Epoch: 27, Step: 19/164, Loss: 0.403981, Accuracy: 86.23%\n",
            "Epoch: 27, Step: 20/164, Loss: 0.401538, Accuracy: 86.29%\n",
            "Epoch: 27, Step: 21/164, Loss: 0.404156, Accuracy: 86.27%\n",
            "Epoch: 27, Step: 22/164, Loss: 0.399887, Accuracy: 86.33%\n",
            "Epoch: 27, Step: 23/164, Loss: 0.398844, Accuracy: 86.35%\n",
            "Epoch: 27, Step: 24/164, Loss: 0.397824, Accuracy: 86.23%\n",
            "Epoch: 27, Step: 25/164, Loss: 0.399203, Accuracy: 86.25%\n",
            "Epoch: 27, Step: 26/164, Loss: 0.399499, Accuracy: 86.30%\n",
            "Epoch: 27, Step: 27/164, Loss: 0.403206, Accuracy: 86.20%\n",
            "Epoch: 27, Step: 28/164, Loss: 0.400101, Accuracy: 86.30%\n",
            "Epoch: 27, Step: 29/164, Loss: 0.400946, Accuracy: 86.29%\n",
            "Epoch: 27, Step: 30/164, Loss: 0.397702, Accuracy: 86.33%\n",
            "Epoch: 27, Step: 31/164, Loss: 0.401261, Accuracy: 86.29%\n",
            "Epoch: 27, Step: 32/164, Loss: 0.404703, Accuracy: 86.23%\n",
            "Epoch: 27, Step: 33/164, Loss: 0.403923, Accuracy: 86.34%\n",
            "Epoch: 27, Step: 34/164, Loss: 0.404297, Accuracy: 86.37%\n",
            "Epoch: 27, Step: 35/164, Loss: 0.406294, Accuracy: 86.34%\n",
            "Epoch: 27, Step: 36/164, Loss: 0.406294, Accuracy: 86.33%\n",
            "Epoch: 27, Step: 37/164, Loss: 0.407935, Accuracy: 86.34%\n",
            "Epoch: 27, Step: 38/164, Loss: 0.406505, Accuracy: 86.33%\n",
            "Epoch: 27, Step: 39/164, Loss: 0.404337, Accuracy: 86.40%\n",
            "Epoch: 27, Step: 40/164, Loss: 0.404126, Accuracy: 86.46%\n",
            "Epoch: 27, Step: 41/164, Loss: 0.405474, Accuracy: 86.43%\n",
            "Epoch: 27, Step: 42/164, Loss: 0.406042, Accuracy: 86.38%\n",
            "Epoch: 27, Step: 43/164, Loss: 0.407192, Accuracy: 86.30%\n",
            "Epoch: 27, Step: 44/164, Loss: 0.407603, Accuracy: 86.20%\n",
            "Epoch: 27, Step: 45/164, Loss: 0.408756, Accuracy: 86.16%\n",
            "Epoch: 27, Step: 46/164, Loss: 0.407450, Accuracy: 86.12%\n",
            "Epoch: 27, Step: 47/164, Loss: 0.405267, Accuracy: 86.19%\n",
            "Epoch: 27, Step: 48/164, Loss: 0.405427, Accuracy: 86.20%\n",
            "Epoch: 27, Step: 49/164, Loss: 0.405591, Accuracy: 86.19%\n",
            "Epoch: 27, Step: 50/164, Loss: 0.407632, Accuracy: 86.17%\n",
            "Epoch: 27, Step: 51/164, Loss: 0.409078, Accuracy: 86.15%\n",
            "Epoch: 27, Step: 52/164, Loss: 0.407402, Accuracy: 86.25%\n",
            "Epoch: 27, Step: 53/164, Loss: 0.405708, Accuracy: 86.34%\n",
            "Epoch: 27, Step: 54/164, Loss: 0.404430, Accuracy: 86.37%\n",
            "Epoch: 27, Step: 55/164, Loss: 0.403909, Accuracy: 86.39%\n",
            "Epoch: 27, Step: 56/164, Loss: 0.406019, Accuracy: 86.41%\n",
            "Epoch: 27, Step: 57/164, Loss: 0.404070, Accuracy: 86.50%\n",
            "Epoch: 27, Step: 58/164, Loss: 0.404044, Accuracy: 86.45%\n",
            "Epoch: 27, Step: 59/164, Loss: 0.405467, Accuracy: 86.45%\n",
            "Epoch: 27, Step: 60/164, Loss: 0.406507, Accuracy: 86.42%\n",
            "Epoch: 27, Step: 61/164, Loss: 0.406268, Accuracy: 86.40%\n",
            "Epoch: 27, Step: 62/164, Loss: 0.406152, Accuracy: 86.39%\n",
            "Epoch: 27, Step: 63/164, Loss: 0.407859, Accuracy: 86.35%\n",
            "Epoch: 27, Step: 64/164, Loss: 0.407562, Accuracy: 86.34%\n",
            "Epoch: 27, Step: 65/164, Loss: 0.410080, Accuracy: 86.30%\n",
            "Epoch: 27, Step: 66/164, Loss: 0.411052, Accuracy: 86.29%\n",
            "Epoch: 27, Step: 67/164, Loss: 0.412419, Accuracy: 86.29%\n",
            "Epoch: 27, Step: 68/164, Loss: 0.410577, Accuracy: 86.33%\n",
            "Epoch: 27, Step: 69/164, Loss: 0.408356, Accuracy: 86.37%\n",
            "Epoch: 27, Step: 70/164, Loss: 0.408147, Accuracy: 86.36%\n",
            "Epoch: 27, Step: 71/164, Loss: 0.407562, Accuracy: 86.42%\n",
            "Epoch: 27, Step: 72/164, Loss: 0.407063, Accuracy: 86.41%\n",
            "Epoch: 27, Step: 73/164, Loss: 0.407701, Accuracy: 86.39%\n",
            "Epoch: 27, Step: 74/164, Loss: 0.409227, Accuracy: 86.37%\n",
            "Epoch: 27, Step: 75/164, Loss: 0.409100, Accuracy: 86.40%\n",
            "Epoch: 27, Step: 76/164, Loss: 0.408074, Accuracy: 86.45%\n",
            "Epoch: 27, Step: 77/164, Loss: 0.408227, Accuracy: 86.45%\n",
            "Epoch: 27, Step: 78/164, Loss: 0.407684, Accuracy: 86.47%\n",
            "Epoch: 27, Step: 79/164, Loss: 0.408691, Accuracy: 86.43%\n",
            "Epoch: 27, Step: 80/164, Loss: 0.407894, Accuracy: 86.48%\n",
            "Epoch: 27, Step: 81/164, Loss: 0.408844, Accuracy: 86.46%\n",
            "Epoch: 27, Step: 82/164, Loss: 0.410467, Accuracy: 86.41%\n",
            "Epoch: 27, Step: 83/164, Loss: 0.409337, Accuracy: 86.46%\n",
            "Epoch: 27, Step: 84/164, Loss: 0.409927, Accuracy: 86.46%\n",
            "Epoch: 27, Step: 85/164, Loss: 0.408838, Accuracy: 86.47%\n",
            "Epoch: 27, Step: 86/164, Loss: 0.408287, Accuracy: 86.48%\n",
            "Epoch: 27, Step: 87/164, Loss: 0.408096, Accuracy: 86.51%\n",
            "Epoch: 27, Step: 88/164, Loss: 0.408868, Accuracy: 86.51%\n",
            "Epoch: 27, Step: 89/164, Loss: 0.407999, Accuracy: 86.56%\n",
            "Epoch: 27, Step: 90/164, Loss: 0.408273, Accuracy: 86.52%\n",
            "Epoch: 27, Step: 91/164, Loss: 0.409086, Accuracy: 86.49%\n",
            "Epoch: 27, Step: 92/164, Loss: 0.410275, Accuracy: 86.43%\n",
            "Epoch: 27, Step: 93/164, Loss: 0.410268, Accuracy: 86.42%\n",
            "Epoch: 27, Step: 94/164, Loss: 0.410000, Accuracy: 86.43%\n",
            "Epoch: 27, Step: 95/164, Loss: 0.410154, Accuracy: 86.46%\n",
            "Epoch: 27, Step: 96/164, Loss: 0.408982, Accuracy: 86.49%\n",
            "Epoch: 27, Step: 97/164, Loss: 0.408591, Accuracy: 86.49%\n",
            "Epoch: 27, Step: 98/164, Loss: 0.408187, Accuracy: 86.51%\n",
            "Epoch: 27, Step: 99/164, Loss: 0.407886, Accuracy: 86.51%\n",
            "Epoch: 27, Step: 100/164, Loss: 0.407173, Accuracy: 86.55%\n",
            "Epoch: 27, Step: 101/164, Loss: 0.407892, Accuracy: 86.53%\n",
            "Epoch: 27, Step: 102/164, Loss: 0.407941, Accuracy: 86.50%\n",
            "Epoch: 27, Step: 103/164, Loss: 0.408241, Accuracy: 86.48%\n",
            "Epoch: 27, Step: 104/164, Loss: 0.407794, Accuracy: 86.50%\n",
            "Epoch: 27, Step: 105/164, Loss: 0.407139, Accuracy: 86.50%\n",
            "Epoch: 27, Step: 106/164, Loss: 0.407705, Accuracy: 86.48%\n",
            "Epoch: 27, Step: 107/164, Loss: 0.407934, Accuracy: 86.45%\n",
            "Epoch: 27, Step: 108/164, Loss: 0.408739, Accuracy: 86.41%\n",
            "Epoch: 27, Step: 109/164, Loss: 0.407257, Accuracy: 86.46%\n",
            "Epoch: 27, Step: 110/164, Loss: 0.406536, Accuracy: 86.47%\n",
            "Epoch: 27, Step: 111/164, Loss: 0.405536, Accuracy: 86.49%\n",
            "Epoch: 27, Step: 112/164, Loss: 0.405686, Accuracy: 86.47%\n",
            "Epoch: 27, Step: 113/164, Loss: 0.405403, Accuracy: 86.47%\n",
            "Epoch: 27, Step: 114/164, Loss: 0.405713, Accuracy: 86.46%\n",
            "Epoch: 27, Step: 115/164, Loss: 0.404862, Accuracy: 86.47%\n",
            "Epoch: 27, Step: 116/164, Loss: 0.405162, Accuracy: 86.44%\n",
            "Epoch: 27, Step: 117/164, Loss: 0.404265, Accuracy: 86.45%\n",
            "Epoch: 27, Step: 118/164, Loss: 0.404009, Accuracy: 86.44%\n",
            "Epoch: 27, Step: 119/164, Loss: 0.403421, Accuracy: 86.48%\n",
            "Epoch: 27, Step: 120/164, Loss: 0.403242, Accuracy: 86.50%\n",
            "Epoch: 27, Step: 121/164, Loss: 0.403232, Accuracy: 86.47%\n",
            "Epoch: 27, Step: 122/164, Loss: 0.403099, Accuracy: 86.46%\n",
            "Epoch: 27, Step: 123/164, Loss: 0.404029, Accuracy: 86.42%\n",
            "Epoch: 27, Step: 124/164, Loss: 0.403194, Accuracy: 86.43%\n",
            "Epoch: 27, Step: 125/164, Loss: 0.402985, Accuracy: 86.42%\n",
            "Epoch: 27, Step: 126/164, Loss: 0.403368, Accuracy: 86.40%\n",
            "Epoch: 27, Step: 127/164, Loss: 0.403614, Accuracy: 86.38%\n",
            "Epoch: 27, Step: 128/164, Loss: 0.402454, Accuracy: 86.43%\n",
            "Epoch: 27, Step: 129/164, Loss: 0.402969, Accuracy: 86.40%\n",
            "Epoch: 27, Step: 130/164, Loss: 0.402619, Accuracy: 86.42%\n",
            "Epoch: 27, Step: 131/164, Loss: 0.402845, Accuracy: 86.40%\n",
            "Epoch: 27, Step: 132/164, Loss: 0.403011, Accuracy: 86.39%\n",
            "Epoch: 27, Step: 133/164, Loss: 0.403353, Accuracy: 86.39%\n",
            "Epoch: 27, Step: 134/164, Loss: 0.402717, Accuracy: 86.41%\n",
            "Epoch: 27, Step: 135/164, Loss: 0.403536, Accuracy: 86.38%\n",
            "Epoch: 27, Step: 136/164, Loss: 0.403389, Accuracy: 86.35%\n",
            "Epoch: 27, Step: 137/164, Loss: 0.403650, Accuracy: 86.35%\n",
            "Epoch: 27, Step: 138/164, Loss: 0.403847, Accuracy: 86.35%\n",
            "Epoch: 27, Step: 139/164, Loss: 0.403973, Accuracy: 86.35%\n",
            "Epoch: 27, Step: 140/164, Loss: 0.404281, Accuracy: 86.36%\n",
            "Epoch: 27, Step: 141/164, Loss: 0.404528, Accuracy: 86.34%\n",
            "Epoch: 27, Step: 142/164, Loss: 0.404576, Accuracy: 86.34%\n",
            "Epoch: 27, Step: 143/164, Loss: 0.404849, Accuracy: 86.34%\n",
            "Epoch: 27, Step: 144/164, Loss: 0.404474, Accuracy: 86.34%\n",
            "Epoch: 27, Step: 145/164, Loss: 0.404355, Accuracy: 86.36%\n",
            "Epoch: 27, Step: 146/164, Loss: 0.404811, Accuracy: 86.33%\n",
            "Epoch: 27, Step: 147/164, Loss: 0.404413, Accuracy: 86.35%\n",
            "Epoch: 27, Step: 148/164, Loss: 0.404166, Accuracy: 86.35%\n",
            "Epoch: 27, Step: 149/164, Loss: 0.404046, Accuracy: 86.36%\n",
            "Epoch: 27, Step: 150/164, Loss: 0.404689, Accuracy: 86.34%\n",
            "Epoch: 27, Step: 151/164, Loss: 0.403919, Accuracy: 86.38%\n",
            "Epoch: 27, Step: 152/164, Loss: 0.403980, Accuracy: 86.36%\n",
            "Epoch: 27, Step: 153/164, Loss: 0.404024, Accuracy: 86.36%\n",
            "Epoch: 27, Step: 154/164, Loss: 0.404566, Accuracy: 86.35%\n",
            "Epoch: 27, Step: 155/164, Loss: 0.404660, Accuracy: 86.36%\n",
            "Epoch: 27, Step: 156/164, Loss: 0.403925, Accuracy: 86.39%\n",
            "Epoch: 27, Step: 157/164, Loss: 0.403810, Accuracy: 86.40%\n",
            "Epoch: 27, Step: 158/164, Loss: 0.404616, Accuracy: 86.39%\n",
            "Epoch: 27, Step: 159/164, Loss: 0.405060, Accuracy: 86.37%\n",
            "Epoch: 27, Step: 160/164, Loss: 0.404201, Accuracy: 86.39%\n",
            "Epoch: 27, Step: 161/164, Loss: 0.404276, Accuracy: 86.40%\n",
            "Epoch: 27, Step: 162/164, Loss: 0.403797, Accuracy: 86.40%\n",
            "Epoch: 27, Step: 163/164, Loss: 0.403575, Accuracy: 86.41%\n",
            "Epoch: 27, Step: 164/164, Loss: 0.404161, Accuracy: 86.39%\n",
            "Epoch: 28, Step: 1/164, Loss: 0.314569, Accuracy: 87.50%\n",
            "Epoch: 28, Step: 2/164, Loss: 0.338087, Accuracy: 86.72%\n",
            "Epoch: 28, Step: 3/164, Loss: 0.356981, Accuracy: 87.24%\n",
            "Epoch: 28, Step: 4/164, Loss: 0.353331, Accuracy: 88.28%\n",
            "Epoch: 28, Step: 5/164, Loss: 0.346764, Accuracy: 88.91%\n",
            "Epoch: 28, Step: 6/164, Loss: 0.347339, Accuracy: 88.28%\n",
            "Epoch: 28, Step: 7/164, Loss: 0.367347, Accuracy: 87.61%\n",
            "Epoch: 28, Step: 8/164, Loss: 0.356956, Accuracy: 87.79%\n",
            "Epoch: 28, Step: 9/164, Loss: 0.348996, Accuracy: 88.19%\n",
            "Epoch: 28, Step: 10/164, Loss: 0.342594, Accuracy: 88.75%\n",
            "Epoch: 28, Step: 11/164, Loss: 0.346431, Accuracy: 88.71%\n",
            "Epoch: 28, Step: 12/164, Loss: 0.358523, Accuracy: 88.15%\n",
            "Epoch: 28, Step: 13/164, Loss: 0.366424, Accuracy: 87.74%\n",
            "Epoch: 28, Step: 14/164, Loss: 0.367789, Accuracy: 87.78%\n",
            "Epoch: 28, Step: 15/164, Loss: 0.355391, Accuracy: 88.12%\n",
            "Epoch: 28, Step: 16/164, Loss: 0.353758, Accuracy: 88.23%\n",
            "Epoch: 28, Step: 17/164, Loss: 0.354213, Accuracy: 88.24%\n",
            "Epoch: 28, Step: 18/164, Loss: 0.358520, Accuracy: 88.02%\n",
            "Epoch: 28, Step: 19/164, Loss: 0.362153, Accuracy: 87.95%\n",
            "Epoch: 28, Step: 20/164, Loss: 0.369917, Accuracy: 87.85%\n",
            "Epoch: 28, Step: 21/164, Loss: 0.371591, Accuracy: 87.76%\n",
            "Epoch: 28, Step: 22/164, Loss: 0.368988, Accuracy: 87.82%\n",
            "Epoch: 28, Step: 23/164, Loss: 0.366659, Accuracy: 88.01%\n",
            "Epoch: 28, Step: 24/164, Loss: 0.368739, Accuracy: 87.83%\n",
            "Epoch: 28, Step: 25/164, Loss: 0.366806, Accuracy: 87.84%\n",
            "Epoch: 28, Step: 26/164, Loss: 0.370851, Accuracy: 87.83%\n",
            "Epoch: 28, Step: 27/164, Loss: 0.371868, Accuracy: 87.79%\n",
            "Epoch: 28, Step: 28/164, Loss: 0.368749, Accuracy: 88.00%\n",
            "Epoch: 28, Step: 29/164, Loss: 0.370710, Accuracy: 87.85%\n",
            "Epoch: 28, Step: 30/164, Loss: 0.369025, Accuracy: 87.92%\n",
            "Epoch: 28, Step: 31/164, Loss: 0.368420, Accuracy: 87.90%\n",
            "Epoch: 28, Step: 32/164, Loss: 0.371787, Accuracy: 87.77%\n",
            "Epoch: 28, Step: 33/164, Loss: 0.371025, Accuracy: 87.83%\n",
            "Epoch: 28, Step: 34/164, Loss: 0.372700, Accuracy: 87.84%\n",
            "Epoch: 28, Step: 35/164, Loss: 0.375509, Accuracy: 87.81%\n",
            "Epoch: 28, Step: 36/164, Loss: 0.377581, Accuracy: 87.65%\n",
            "Epoch: 28, Step: 37/164, Loss: 0.380126, Accuracy: 87.50%\n",
            "Epoch: 28, Step: 38/164, Loss: 0.379010, Accuracy: 87.58%\n",
            "Epoch: 28, Step: 39/164, Loss: 0.378814, Accuracy: 87.64%\n",
            "Epoch: 28, Step: 40/164, Loss: 0.376854, Accuracy: 87.70%\n",
            "Epoch: 28, Step: 41/164, Loss: 0.376386, Accuracy: 87.71%\n",
            "Epoch: 28, Step: 42/164, Loss: 0.379266, Accuracy: 87.52%\n",
            "Epoch: 28, Step: 43/164, Loss: 0.375394, Accuracy: 87.70%\n",
            "Epoch: 28, Step: 44/164, Loss: 0.374297, Accuracy: 87.73%\n",
            "Epoch: 28, Step: 45/164, Loss: 0.372020, Accuracy: 87.81%\n",
            "Epoch: 28, Step: 46/164, Loss: 0.372932, Accuracy: 87.77%\n",
            "Epoch: 28, Step: 47/164, Loss: 0.374615, Accuracy: 87.77%\n",
            "Epoch: 28, Step: 48/164, Loss: 0.373089, Accuracy: 87.84%\n",
            "Epoch: 28, Step: 49/164, Loss: 0.369888, Accuracy: 87.93%\n",
            "Epoch: 28, Step: 50/164, Loss: 0.370273, Accuracy: 87.88%\n",
            "Epoch: 28, Step: 51/164, Loss: 0.371438, Accuracy: 87.81%\n",
            "Epoch: 28, Step: 52/164, Loss: 0.371330, Accuracy: 87.76%\n",
            "Epoch: 28, Step: 53/164, Loss: 0.372261, Accuracy: 87.74%\n",
            "Epoch: 28, Step: 54/164, Loss: 0.373082, Accuracy: 87.69%\n",
            "Epoch: 28, Step: 55/164, Loss: 0.372468, Accuracy: 87.77%\n",
            "Epoch: 28, Step: 56/164, Loss: 0.371541, Accuracy: 87.77%\n",
            "Epoch: 28, Step: 57/164, Loss: 0.371427, Accuracy: 87.79%\n",
            "Epoch: 28, Step: 58/164, Loss: 0.372365, Accuracy: 87.77%\n",
            "Epoch: 28, Step: 59/164, Loss: 0.374190, Accuracy: 87.75%\n",
            "Epoch: 28, Step: 60/164, Loss: 0.373187, Accuracy: 87.75%\n",
            "Epoch: 28, Step: 61/164, Loss: 0.371537, Accuracy: 87.81%\n",
            "Epoch: 28, Step: 62/164, Loss: 0.371146, Accuracy: 87.78%\n",
            "Epoch: 28, Step: 63/164, Loss: 0.371349, Accuracy: 87.72%\n",
            "Epoch: 28, Step: 64/164, Loss: 0.369411, Accuracy: 87.78%\n",
            "Epoch: 28, Step: 65/164, Loss: 0.369950, Accuracy: 87.80%\n",
            "Epoch: 28, Step: 66/164, Loss: 0.369969, Accuracy: 87.78%\n",
            "Epoch: 28, Step: 67/164, Loss: 0.371565, Accuracy: 87.73%\n",
            "Epoch: 28, Step: 68/164, Loss: 0.371024, Accuracy: 87.79%\n",
            "Epoch: 28, Step: 69/164, Loss: 0.371265, Accuracy: 87.78%\n",
            "Epoch: 28, Step: 70/164, Loss: 0.370385, Accuracy: 87.83%\n",
            "Epoch: 28, Step: 71/164, Loss: 0.369904, Accuracy: 87.80%\n",
            "Epoch: 28, Step: 72/164, Loss: 0.371319, Accuracy: 87.76%\n",
            "Epoch: 28, Step: 73/164, Loss: 0.373348, Accuracy: 87.70%\n",
            "Epoch: 28, Step: 74/164, Loss: 0.373789, Accuracy: 87.69%\n",
            "Epoch: 28, Step: 75/164, Loss: 0.372935, Accuracy: 87.73%\n",
            "Epoch: 28, Step: 76/164, Loss: 0.372255, Accuracy: 87.76%\n",
            "Epoch: 28, Step: 77/164, Loss: 0.371471, Accuracy: 87.81%\n",
            "Epoch: 28, Step: 78/164, Loss: 0.370472, Accuracy: 87.86%\n",
            "Epoch: 28, Step: 79/164, Loss: 0.369658, Accuracy: 87.89%\n",
            "Epoch: 28, Step: 80/164, Loss: 0.370819, Accuracy: 87.86%\n",
            "Epoch: 28, Step: 81/164, Loss: 0.371044, Accuracy: 87.84%\n",
            "Epoch: 28, Step: 82/164, Loss: 0.371523, Accuracy: 87.83%\n",
            "Epoch: 28, Step: 83/164, Loss: 0.371703, Accuracy: 87.80%\n",
            "Epoch: 28, Step: 84/164, Loss: 0.373490, Accuracy: 87.78%\n",
            "Epoch: 28, Step: 85/164, Loss: 0.373522, Accuracy: 87.78%\n",
            "Epoch: 28, Step: 86/164, Loss: 0.374277, Accuracy: 87.75%\n",
            "Epoch: 28, Step: 87/164, Loss: 0.374783, Accuracy: 87.71%\n",
            "Epoch: 28, Step: 88/164, Loss: 0.375217, Accuracy: 87.69%\n",
            "Epoch: 28, Step: 89/164, Loss: 0.376004, Accuracy: 87.66%\n",
            "Epoch: 28, Step: 90/164, Loss: 0.377427, Accuracy: 87.59%\n",
            "Epoch: 28, Step: 91/164, Loss: 0.376913, Accuracy: 87.58%\n",
            "Epoch: 28, Step: 92/164, Loss: 0.377055, Accuracy: 87.56%\n",
            "Epoch: 28, Step: 93/164, Loss: 0.376859, Accuracy: 87.58%\n",
            "Epoch: 28, Step: 94/164, Loss: 0.376879, Accuracy: 87.56%\n",
            "Epoch: 28, Step: 95/164, Loss: 0.377437, Accuracy: 87.54%\n",
            "Epoch: 28, Step: 96/164, Loss: 0.378126, Accuracy: 87.52%\n",
            "Epoch: 28, Step: 97/164, Loss: 0.377505, Accuracy: 87.54%\n",
            "Epoch: 28, Step: 98/164, Loss: 0.379057, Accuracy: 87.51%\n",
            "Epoch: 28, Step: 99/164, Loss: 0.378963, Accuracy: 87.55%\n",
            "Epoch: 28, Step: 100/164, Loss: 0.380126, Accuracy: 87.50%\n",
            "Epoch: 28, Step: 101/164, Loss: 0.382040, Accuracy: 87.47%\n",
            "Epoch: 28, Step: 102/164, Loss: 0.382152, Accuracy: 87.46%\n",
            "Epoch: 28, Step: 103/164, Loss: 0.383134, Accuracy: 87.43%\n",
            "Epoch: 28, Step: 104/164, Loss: 0.382679, Accuracy: 87.45%\n",
            "Epoch: 28, Step: 105/164, Loss: 0.383112, Accuracy: 87.43%\n",
            "Epoch: 28, Step: 106/164, Loss: 0.382980, Accuracy: 87.40%\n",
            "Epoch: 28, Step: 107/164, Loss: 0.382897, Accuracy: 87.37%\n",
            "Epoch: 28, Step: 108/164, Loss: 0.383407, Accuracy: 87.35%\n",
            "Epoch: 28, Step: 109/164, Loss: 0.383059, Accuracy: 87.36%\n",
            "Epoch: 28, Step: 110/164, Loss: 0.383523, Accuracy: 87.35%\n",
            "Epoch: 28, Step: 111/164, Loss: 0.382892, Accuracy: 87.37%\n",
            "Epoch: 28, Step: 112/164, Loss: 0.382844, Accuracy: 87.39%\n",
            "Epoch: 28, Step: 113/164, Loss: 0.382900, Accuracy: 87.38%\n",
            "Epoch: 28, Step: 114/164, Loss: 0.383831, Accuracy: 87.36%\n",
            "Epoch: 28, Step: 115/164, Loss: 0.383903, Accuracy: 87.36%\n",
            "Epoch: 28, Step: 116/164, Loss: 0.383990, Accuracy: 87.37%\n",
            "Epoch: 28, Step: 117/164, Loss: 0.382166, Accuracy: 87.41%\n",
            "Epoch: 28, Step: 118/164, Loss: 0.381973, Accuracy: 87.41%\n",
            "Epoch: 28, Step: 119/164, Loss: 0.381906, Accuracy: 87.41%\n",
            "Epoch: 28, Step: 120/164, Loss: 0.381596, Accuracy: 87.43%\n",
            "Epoch: 28, Step: 121/164, Loss: 0.381404, Accuracy: 87.42%\n",
            "Epoch: 28, Step: 122/164, Loss: 0.381741, Accuracy: 87.42%\n",
            "Epoch: 28, Step: 123/164, Loss: 0.381778, Accuracy: 87.40%\n",
            "Epoch: 28, Step: 124/164, Loss: 0.382639, Accuracy: 87.37%\n",
            "Epoch: 28, Step: 125/164, Loss: 0.382093, Accuracy: 87.40%\n",
            "Epoch: 28, Step: 126/164, Loss: 0.382758, Accuracy: 87.36%\n",
            "Epoch: 28, Step: 127/164, Loss: 0.381360, Accuracy: 87.41%\n",
            "Epoch: 28, Step: 128/164, Loss: 0.381618, Accuracy: 87.40%\n",
            "Epoch: 28, Step: 129/164, Loss: 0.382829, Accuracy: 87.36%\n",
            "Epoch: 28, Step: 130/164, Loss: 0.383131, Accuracy: 87.35%\n",
            "Epoch: 28, Step: 131/164, Loss: 0.382398, Accuracy: 87.37%\n",
            "Epoch: 28, Step: 132/164, Loss: 0.381853, Accuracy: 87.40%\n",
            "Epoch: 28, Step: 133/164, Loss: 0.381757, Accuracy: 87.39%\n",
            "Epoch: 28, Step: 134/164, Loss: 0.381098, Accuracy: 87.40%\n",
            "Epoch: 28, Step: 135/164, Loss: 0.381298, Accuracy: 87.40%\n",
            "Epoch: 28, Step: 136/164, Loss: 0.381115, Accuracy: 87.40%\n",
            "Epoch: 28, Step: 137/164, Loss: 0.380939, Accuracy: 87.42%\n",
            "Epoch: 28, Step: 138/164, Loss: 0.382162, Accuracy: 87.38%\n",
            "Epoch: 28, Step: 139/164, Loss: 0.383314, Accuracy: 87.37%\n",
            "Epoch: 28, Step: 140/164, Loss: 0.383936, Accuracy: 87.34%\n",
            "Epoch: 28, Step: 141/164, Loss: 0.384551, Accuracy: 87.34%\n",
            "Epoch: 28, Step: 142/164, Loss: 0.384055, Accuracy: 87.34%\n",
            "Epoch: 28, Step: 143/164, Loss: 0.383927, Accuracy: 87.36%\n",
            "Epoch: 28, Step: 144/164, Loss: 0.384903, Accuracy: 87.32%\n",
            "Epoch: 28, Step: 145/164, Loss: 0.385543, Accuracy: 87.33%\n",
            "Epoch: 28, Step: 146/164, Loss: 0.385541, Accuracy: 87.32%\n",
            "Epoch: 28, Step: 147/164, Loss: 0.386934, Accuracy: 87.28%\n",
            "Epoch: 28, Step: 148/164, Loss: 0.387556, Accuracy: 87.24%\n",
            "Epoch: 28, Step: 149/164, Loss: 0.388048, Accuracy: 87.24%\n",
            "Epoch: 28, Step: 150/164, Loss: 0.386946, Accuracy: 87.29%\n",
            "Epoch: 28, Step: 151/164, Loss: 0.387072, Accuracy: 87.28%\n",
            "Epoch: 28, Step: 152/164, Loss: 0.386832, Accuracy: 87.28%\n",
            "Epoch: 28, Step: 153/164, Loss: 0.386357, Accuracy: 87.31%\n",
            "Epoch: 28, Step: 154/164, Loss: 0.386066, Accuracy: 87.30%\n",
            "Epoch: 28, Step: 155/164, Loss: 0.387235, Accuracy: 87.25%\n",
            "Epoch: 28, Step: 156/164, Loss: 0.388349, Accuracy: 87.21%\n",
            "Epoch: 28, Step: 157/164, Loss: 0.388070, Accuracy: 87.21%\n",
            "Epoch: 28, Step: 158/164, Loss: 0.388453, Accuracy: 87.18%\n",
            "Epoch: 28, Step: 159/164, Loss: 0.389174, Accuracy: 87.18%\n",
            "Epoch: 28, Step: 160/164, Loss: 0.390018, Accuracy: 87.14%\n",
            "Epoch: 28, Step: 161/164, Loss: 0.390963, Accuracy: 87.11%\n",
            "Epoch: 28, Step: 162/164, Loss: 0.391270, Accuracy: 87.09%\n",
            "Epoch: 28, Step: 163/164, Loss: 0.391183, Accuracy: 87.10%\n",
            "Epoch: 28, Step: 164/164, Loss: 0.392259, Accuracy: 87.09%\n",
            "Epoch: 29, Step: 1/164, Loss: 0.418634, Accuracy: 85.94%\n",
            "Epoch: 29, Step: 2/164, Loss: 0.386664, Accuracy: 87.11%\n",
            "Epoch: 29, Step: 3/164, Loss: 0.408676, Accuracy: 86.72%\n",
            "Epoch: 29, Step: 4/164, Loss: 0.393072, Accuracy: 86.72%\n",
            "Epoch: 29, Step: 5/164, Loss: 0.371935, Accuracy: 87.34%\n",
            "Epoch: 29, Step: 6/164, Loss: 0.369623, Accuracy: 87.50%\n",
            "Epoch: 29, Step: 7/164, Loss: 0.363420, Accuracy: 87.83%\n",
            "Epoch: 29, Step: 8/164, Loss: 0.363520, Accuracy: 87.89%\n",
            "Epoch: 29, Step: 9/164, Loss: 0.356148, Accuracy: 87.93%\n",
            "Epoch: 29, Step: 10/164, Loss: 0.367138, Accuracy: 87.73%\n",
            "Epoch: 29, Step: 11/164, Loss: 0.363698, Accuracy: 87.86%\n",
            "Epoch: 29, Step: 12/164, Loss: 0.366615, Accuracy: 87.63%\n",
            "Epoch: 29, Step: 13/164, Loss: 0.371750, Accuracy: 87.44%\n",
            "Epoch: 29, Step: 14/164, Loss: 0.369825, Accuracy: 87.33%\n",
            "Epoch: 29, Step: 15/164, Loss: 0.370230, Accuracy: 87.40%\n",
            "Epoch: 29, Step: 16/164, Loss: 0.362479, Accuracy: 87.74%\n",
            "Epoch: 29, Step: 17/164, Loss: 0.362516, Accuracy: 87.55%\n",
            "Epoch: 29, Step: 18/164, Loss: 0.359202, Accuracy: 87.59%\n",
            "Epoch: 29, Step: 19/164, Loss: 0.358486, Accuracy: 87.54%\n",
            "Epoch: 29, Step: 20/164, Loss: 0.359639, Accuracy: 87.42%\n",
            "Epoch: 29, Step: 21/164, Loss: 0.363819, Accuracy: 87.31%\n",
            "Epoch: 29, Step: 22/164, Loss: 0.363753, Accuracy: 87.25%\n",
            "Epoch: 29, Step: 23/164, Loss: 0.372099, Accuracy: 87.09%\n",
            "Epoch: 29, Step: 24/164, Loss: 0.375977, Accuracy: 87.01%\n",
            "Epoch: 29, Step: 25/164, Loss: 0.378551, Accuracy: 86.97%\n",
            "Epoch: 29, Step: 26/164, Loss: 0.377481, Accuracy: 86.99%\n",
            "Epoch: 29, Step: 27/164, Loss: 0.375397, Accuracy: 87.01%\n",
            "Epoch: 29, Step: 28/164, Loss: 0.375099, Accuracy: 86.97%\n",
            "Epoch: 29, Step: 29/164, Loss: 0.380563, Accuracy: 86.91%\n",
            "Epoch: 29, Step: 30/164, Loss: 0.381737, Accuracy: 86.80%\n",
            "Epoch: 29, Step: 31/164, Loss: 0.381983, Accuracy: 86.77%\n",
            "Epoch: 29, Step: 32/164, Loss: 0.377020, Accuracy: 86.99%\n",
            "Epoch: 29, Step: 33/164, Loss: 0.376579, Accuracy: 87.00%\n",
            "Epoch: 29, Step: 34/164, Loss: 0.378785, Accuracy: 86.95%\n",
            "Epoch: 29, Step: 35/164, Loss: 0.374535, Accuracy: 87.10%\n",
            "Epoch: 29, Step: 36/164, Loss: 0.376210, Accuracy: 87.00%\n",
            "Epoch: 29, Step: 37/164, Loss: 0.377955, Accuracy: 86.89%\n",
            "Epoch: 29, Step: 38/164, Loss: 0.376109, Accuracy: 86.94%\n",
            "Epoch: 29, Step: 39/164, Loss: 0.377685, Accuracy: 86.96%\n",
            "Epoch: 29, Step: 40/164, Loss: 0.375567, Accuracy: 87.01%\n",
            "Epoch: 29, Step: 41/164, Loss: 0.375365, Accuracy: 87.04%\n",
            "Epoch: 29, Step: 42/164, Loss: 0.377545, Accuracy: 86.98%\n",
            "Epoch: 29, Step: 43/164, Loss: 0.376665, Accuracy: 86.99%\n",
            "Epoch: 29, Step: 44/164, Loss: 0.377406, Accuracy: 87.02%\n",
            "Epoch: 29, Step: 45/164, Loss: 0.376577, Accuracy: 87.00%\n",
            "Epoch: 29, Step: 46/164, Loss: 0.377907, Accuracy: 86.97%\n",
            "Epoch: 29, Step: 47/164, Loss: 0.379594, Accuracy: 86.90%\n",
            "Epoch: 29, Step: 48/164, Loss: 0.379084, Accuracy: 86.91%\n",
            "Epoch: 29, Step: 49/164, Loss: 0.378471, Accuracy: 86.91%\n",
            "Epoch: 29, Step: 50/164, Loss: 0.380811, Accuracy: 86.84%\n",
            "Epoch: 29, Step: 51/164, Loss: 0.378195, Accuracy: 86.95%\n",
            "Epoch: 29, Step: 52/164, Loss: 0.375811, Accuracy: 87.05%\n",
            "Epoch: 29, Step: 53/164, Loss: 0.375689, Accuracy: 87.07%\n",
            "Epoch: 29, Step: 54/164, Loss: 0.378573, Accuracy: 87.07%\n",
            "Epoch: 29, Step: 55/164, Loss: 0.379525, Accuracy: 87.05%\n",
            "Epoch: 29, Step: 56/164, Loss: 0.379979, Accuracy: 87.04%\n",
            "Epoch: 29, Step: 57/164, Loss: 0.378225, Accuracy: 87.05%\n",
            "Epoch: 29, Step: 58/164, Loss: 0.378039, Accuracy: 87.06%\n",
            "Epoch: 29, Step: 59/164, Loss: 0.376811, Accuracy: 87.12%\n",
            "Epoch: 29, Step: 60/164, Loss: 0.376076, Accuracy: 87.15%\n",
            "Epoch: 29, Step: 61/164, Loss: 0.375304, Accuracy: 87.17%\n",
            "Epoch: 29, Step: 62/164, Loss: 0.375186, Accuracy: 87.16%\n",
            "Epoch: 29, Step: 63/164, Loss: 0.375857, Accuracy: 87.15%\n",
            "Epoch: 29, Step: 64/164, Loss: 0.374181, Accuracy: 87.18%\n",
            "Epoch: 29, Step: 65/164, Loss: 0.373276, Accuracy: 87.20%\n",
            "Epoch: 29, Step: 66/164, Loss: 0.375585, Accuracy: 87.16%\n",
            "Epoch: 29, Step: 67/164, Loss: 0.376361, Accuracy: 87.13%\n",
            "Epoch: 29, Step: 68/164, Loss: 0.376568, Accuracy: 87.13%\n",
            "Epoch: 29, Step: 69/164, Loss: 0.378852, Accuracy: 87.07%\n",
            "Epoch: 29, Step: 70/164, Loss: 0.380189, Accuracy: 87.00%\n",
            "Epoch: 29, Step: 71/164, Loss: 0.381517, Accuracy: 86.95%\n",
            "Epoch: 29, Step: 72/164, Loss: 0.383871, Accuracy: 86.89%\n",
            "Epoch: 29, Step: 73/164, Loss: 0.384185, Accuracy: 86.90%\n",
            "Epoch: 29, Step: 74/164, Loss: 0.382498, Accuracy: 86.97%\n",
            "Epoch: 29, Step: 75/164, Loss: 0.382091, Accuracy: 86.99%\n",
            "Epoch: 29, Step: 76/164, Loss: 0.382702, Accuracy: 86.96%\n",
            "Epoch: 29, Step: 77/164, Loss: 0.383223, Accuracy: 86.96%\n",
            "Epoch: 29, Step: 78/164, Loss: 0.384030, Accuracy: 86.92%\n",
            "Epoch: 29, Step: 79/164, Loss: 0.385250, Accuracy: 86.88%\n",
            "Epoch: 29, Step: 80/164, Loss: 0.385971, Accuracy: 86.84%\n",
            "Epoch: 29, Step: 81/164, Loss: 0.386392, Accuracy: 86.79%\n",
            "Epoch: 29, Step: 82/164, Loss: 0.387271, Accuracy: 86.74%\n",
            "Epoch: 29, Step: 83/164, Loss: 0.386886, Accuracy: 86.74%\n",
            "Epoch: 29, Step: 84/164, Loss: 0.386796, Accuracy: 86.72%\n",
            "Epoch: 29, Step: 85/164, Loss: 0.385305, Accuracy: 86.81%\n",
            "Epoch: 29, Step: 86/164, Loss: 0.386141, Accuracy: 86.78%\n",
            "Epoch: 29, Step: 87/164, Loss: 0.385419, Accuracy: 86.80%\n",
            "Epoch: 29, Step: 88/164, Loss: 0.384395, Accuracy: 86.85%\n",
            "Epoch: 29, Step: 89/164, Loss: 0.384082, Accuracy: 86.86%\n",
            "Epoch: 29, Step: 90/164, Loss: 0.382933, Accuracy: 86.86%\n",
            "Epoch: 29, Step: 91/164, Loss: 0.382876, Accuracy: 86.86%\n",
            "Epoch: 29, Step: 92/164, Loss: 0.382454, Accuracy: 86.87%\n",
            "Epoch: 29, Step: 93/164, Loss: 0.382275, Accuracy: 86.88%\n",
            "Epoch: 29, Step: 94/164, Loss: 0.381989, Accuracy: 86.89%\n",
            "Epoch: 29, Step: 95/164, Loss: 0.382733, Accuracy: 86.88%\n",
            "Epoch: 29, Step: 96/164, Loss: 0.381484, Accuracy: 86.91%\n",
            "Epoch: 29, Step: 97/164, Loss: 0.380685, Accuracy: 86.93%\n",
            "Epoch: 29, Step: 98/164, Loss: 0.380602, Accuracy: 86.93%\n",
            "Epoch: 29, Step: 99/164, Loss: 0.381478, Accuracy: 86.92%\n",
            "Epoch: 29, Step: 100/164, Loss: 0.382375, Accuracy: 86.92%\n",
            "Epoch: 29, Step: 101/164, Loss: 0.382348, Accuracy: 86.94%\n",
            "Epoch: 29, Step: 102/164, Loss: 0.381444, Accuracy: 86.97%\n",
            "Epoch: 29, Step: 103/164, Loss: 0.381669, Accuracy: 86.98%\n",
            "Epoch: 29, Step: 104/164, Loss: 0.382284, Accuracy: 87.00%\n",
            "Epoch: 29, Step: 105/164, Loss: 0.382073, Accuracy: 86.99%\n",
            "Epoch: 29, Step: 106/164, Loss: 0.380367, Accuracy: 87.08%\n",
            "Epoch: 29, Step: 107/164, Loss: 0.380678, Accuracy: 87.08%\n",
            "Epoch: 29, Step: 108/164, Loss: 0.380706, Accuracy: 87.09%\n",
            "Epoch: 29, Step: 109/164, Loss: 0.380962, Accuracy: 87.08%\n",
            "Epoch: 29, Step: 110/164, Loss: 0.380517, Accuracy: 87.07%\n",
            "Epoch: 29, Step: 111/164, Loss: 0.380501, Accuracy: 87.06%\n",
            "Epoch: 29, Step: 112/164, Loss: 0.379953, Accuracy: 87.06%\n",
            "Epoch: 29, Step: 113/164, Loss: 0.380788, Accuracy: 87.04%\n",
            "Epoch: 29, Step: 114/164, Loss: 0.381800, Accuracy: 87.01%\n",
            "Epoch: 29, Step: 115/164, Loss: 0.382559, Accuracy: 87.00%\n",
            "Epoch: 29, Step: 116/164, Loss: 0.381249, Accuracy: 87.04%\n",
            "Epoch: 29, Step: 117/164, Loss: 0.381978, Accuracy: 87.03%\n",
            "Epoch: 29, Step: 118/164, Loss: 0.381607, Accuracy: 87.04%\n",
            "Epoch: 29, Step: 119/164, Loss: 0.381440, Accuracy: 87.05%\n",
            "Epoch: 29, Step: 120/164, Loss: 0.380886, Accuracy: 87.06%\n",
            "Epoch: 29, Step: 121/164, Loss: 0.380450, Accuracy: 87.08%\n",
            "Epoch: 29, Step: 122/164, Loss: 0.381057, Accuracy: 87.08%\n",
            "Epoch: 29, Step: 123/164, Loss: 0.380623, Accuracy: 87.09%\n",
            "Epoch: 29, Step: 124/164, Loss: 0.380231, Accuracy: 87.08%\n",
            "Epoch: 29, Step: 125/164, Loss: 0.380756, Accuracy: 87.07%\n",
            "Epoch: 29, Step: 126/164, Loss: 0.381107, Accuracy: 87.05%\n",
            "Epoch: 29, Step: 127/164, Loss: 0.380675, Accuracy: 87.06%\n",
            "Epoch: 29, Step: 128/164, Loss: 0.381535, Accuracy: 87.06%\n",
            "Epoch: 29, Step: 129/164, Loss: 0.381115, Accuracy: 87.08%\n",
            "Epoch: 29, Step: 130/164, Loss: 0.380980, Accuracy: 87.08%\n",
            "Epoch: 29, Step: 131/164, Loss: 0.380153, Accuracy: 87.11%\n",
            "Epoch: 29, Step: 132/164, Loss: 0.380457, Accuracy: 87.10%\n",
            "Epoch: 29, Step: 133/164, Loss: 0.380698, Accuracy: 87.10%\n",
            "Epoch: 29, Step: 134/164, Loss: 0.381516, Accuracy: 87.07%\n",
            "Epoch: 29, Step: 135/164, Loss: 0.381935, Accuracy: 87.06%\n",
            "Epoch: 29, Step: 136/164, Loss: 0.381182, Accuracy: 87.09%\n",
            "Epoch: 29, Step: 137/164, Loss: 0.382737, Accuracy: 87.04%\n",
            "Epoch: 29, Step: 138/164, Loss: 0.382886, Accuracy: 87.04%\n",
            "Epoch: 29, Step: 139/164, Loss: 0.382641, Accuracy: 87.04%\n",
            "Epoch: 29, Step: 140/164, Loss: 0.383112, Accuracy: 87.03%\n",
            "Epoch: 29, Step: 141/164, Loss: 0.382288, Accuracy: 87.06%\n",
            "Epoch: 29, Step: 142/164, Loss: 0.381924, Accuracy: 87.06%\n",
            "Epoch: 29, Step: 143/164, Loss: 0.382332, Accuracy: 87.05%\n",
            "Epoch: 29, Step: 144/164, Loss: 0.382450, Accuracy: 87.04%\n",
            "Epoch: 29, Step: 145/164, Loss: 0.383007, Accuracy: 87.06%\n",
            "Epoch: 29, Step: 146/164, Loss: 0.382831, Accuracy: 87.08%\n",
            "Epoch: 29, Step: 147/164, Loss: 0.382557, Accuracy: 87.08%\n",
            "Epoch: 29, Step: 148/164, Loss: 0.382432, Accuracy: 87.09%\n",
            "Epoch: 29, Step: 149/164, Loss: 0.382257, Accuracy: 87.10%\n",
            "Epoch: 29, Step: 150/164, Loss: 0.383204, Accuracy: 87.07%\n",
            "Epoch: 29, Step: 151/164, Loss: 0.382736, Accuracy: 87.08%\n",
            "Epoch: 29, Step: 152/164, Loss: 0.382747, Accuracy: 87.07%\n",
            "Epoch: 29, Step: 153/164, Loss: 0.382442, Accuracy: 87.08%\n",
            "Epoch: 29, Step: 154/164, Loss: 0.382066, Accuracy: 87.08%\n",
            "Epoch: 29, Step: 155/164, Loss: 0.381977, Accuracy: 87.09%\n",
            "Epoch: 29, Step: 156/164, Loss: 0.381412, Accuracy: 87.11%\n",
            "Epoch: 29, Step: 157/164, Loss: 0.381290, Accuracy: 87.14%\n",
            "Epoch: 29, Step: 158/164, Loss: 0.381354, Accuracy: 87.13%\n",
            "Epoch: 29, Step: 159/164, Loss: 0.381102, Accuracy: 87.14%\n",
            "Epoch: 29, Step: 160/164, Loss: 0.381076, Accuracy: 87.15%\n",
            "Epoch: 29, Step: 161/164, Loss: 0.380810, Accuracy: 87.16%\n",
            "Epoch: 29, Step: 162/164, Loss: 0.381956, Accuracy: 87.12%\n",
            "Epoch: 29, Step: 163/164, Loss: 0.381486, Accuracy: 87.13%\n",
            "Epoch: 29, Step: 164/164, Loss: 0.380348, Accuracy: 87.14%\n",
            "Epoch: 30, Step: 1/164, Loss: 0.367638, Accuracy: 88.28%\n",
            "Epoch: 30, Step: 2/164, Loss: 0.317882, Accuracy: 89.84%\n",
            "Epoch: 30, Step: 3/164, Loss: 0.339806, Accuracy: 88.80%\n",
            "Epoch: 30, Step: 4/164, Loss: 0.368877, Accuracy: 87.89%\n",
            "Epoch: 30, Step: 5/164, Loss: 0.378443, Accuracy: 87.03%\n",
            "Epoch: 30, Step: 6/164, Loss: 0.372092, Accuracy: 86.98%\n",
            "Epoch: 30, Step: 7/164, Loss: 0.374990, Accuracy: 86.83%\n",
            "Epoch: 30, Step: 8/164, Loss: 0.368114, Accuracy: 87.01%\n",
            "Epoch: 30, Step: 9/164, Loss: 0.376973, Accuracy: 86.63%\n",
            "Epoch: 30, Step: 10/164, Loss: 0.368806, Accuracy: 86.95%\n",
            "Epoch: 30, Step: 11/164, Loss: 0.369594, Accuracy: 86.72%\n",
            "Epoch: 30, Step: 12/164, Loss: 0.367076, Accuracy: 86.85%\n",
            "Epoch: 30, Step: 13/164, Loss: 0.363655, Accuracy: 86.90%\n",
            "Epoch: 30, Step: 14/164, Loss: 0.362391, Accuracy: 86.94%\n",
            "Epoch: 30, Step: 15/164, Loss: 0.359702, Accuracy: 87.03%\n",
            "Epoch: 30, Step: 16/164, Loss: 0.358360, Accuracy: 87.21%\n",
            "Epoch: 30, Step: 17/164, Loss: 0.355518, Accuracy: 87.41%\n",
            "Epoch: 30, Step: 18/164, Loss: 0.358015, Accuracy: 87.37%\n",
            "Epoch: 30, Step: 19/164, Loss: 0.354054, Accuracy: 87.58%\n",
            "Epoch: 30, Step: 20/164, Loss: 0.357476, Accuracy: 87.50%\n",
            "Epoch: 30, Step: 21/164, Loss: 0.352930, Accuracy: 87.72%\n",
            "Epoch: 30, Step: 22/164, Loss: 0.355761, Accuracy: 87.64%\n",
            "Epoch: 30, Step: 23/164, Loss: 0.355215, Accuracy: 87.70%\n",
            "Epoch: 30, Step: 24/164, Loss: 0.354463, Accuracy: 87.76%\n",
            "Epoch: 30, Step: 25/164, Loss: 0.356705, Accuracy: 87.72%\n",
            "Epoch: 30, Step: 26/164, Loss: 0.364400, Accuracy: 87.44%\n",
            "Epoch: 30, Step: 27/164, Loss: 0.362064, Accuracy: 87.64%\n",
            "Epoch: 30, Step: 28/164, Loss: 0.363656, Accuracy: 87.58%\n",
            "Epoch: 30, Step: 29/164, Loss: 0.364900, Accuracy: 87.37%\n",
            "Epoch: 30, Step: 30/164, Loss: 0.361523, Accuracy: 87.50%\n",
            "Epoch: 30, Step: 31/164, Loss: 0.364575, Accuracy: 87.40%\n",
            "Epoch: 30, Step: 32/164, Loss: 0.367989, Accuracy: 87.33%\n",
            "Epoch: 30, Step: 33/164, Loss: 0.368848, Accuracy: 87.29%\n",
            "Epoch: 30, Step: 34/164, Loss: 0.367142, Accuracy: 87.36%\n",
            "Epoch: 30, Step: 35/164, Loss: 0.365452, Accuracy: 87.46%\n",
            "Epoch: 30, Step: 36/164, Loss: 0.367370, Accuracy: 87.46%\n",
            "Epoch: 30, Step: 37/164, Loss: 0.373104, Accuracy: 87.29%\n",
            "Epoch: 30, Step: 38/164, Loss: 0.375240, Accuracy: 87.17%\n",
            "Epoch: 30, Step: 39/164, Loss: 0.372975, Accuracy: 87.26%\n",
            "Epoch: 30, Step: 40/164, Loss: 0.373318, Accuracy: 87.27%\n",
            "Epoch: 30, Step: 41/164, Loss: 0.374804, Accuracy: 87.20%\n",
            "Epoch: 30, Step: 42/164, Loss: 0.376197, Accuracy: 87.13%\n",
            "Epoch: 30, Step: 43/164, Loss: 0.373686, Accuracy: 87.23%\n",
            "Epoch: 30, Step: 44/164, Loss: 0.372866, Accuracy: 87.29%\n",
            "Epoch: 30, Step: 45/164, Loss: 0.370575, Accuracy: 87.41%\n",
            "Epoch: 30, Step: 46/164, Loss: 0.370114, Accuracy: 87.45%\n",
            "Epoch: 30, Step: 47/164, Loss: 0.370111, Accuracy: 87.47%\n",
            "Epoch: 30, Step: 48/164, Loss: 0.369509, Accuracy: 87.45%\n",
            "Epoch: 30, Step: 49/164, Loss: 0.370514, Accuracy: 87.44%\n",
            "Epoch: 30, Step: 50/164, Loss: 0.369532, Accuracy: 87.47%\n",
            "Epoch: 30, Step: 51/164, Loss: 0.369443, Accuracy: 87.50%\n",
            "Epoch: 30, Step: 52/164, Loss: 0.370432, Accuracy: 87.52%\n",
            "Epoch: 30, Step: 53/164, Loss: 0.368619, Accuracy: 87.59%\n",
            "Epoch: 30, Step: 54/164, Loss: 0.365366, Accuracy: 87.70%\n",
            "Epoch: 30, Step: 55/164, Loss: 0.364883, Accuracy: 87.74%\n",
            "Epoch: 30, Step: 56/164, Loss: 0.366572, Accuracy: 87.72%\n",
            "Epoch: 30, Step: 57/164, Loss: 0.365326, Accuracy: 87.76%\n",
            "Epoch: 30, Step: 58/164, Loss: 0.365310, Accuracy: 87.72%\n",
            "Epoch: 30, Step: 59/164, Loss: 0.364520, Accuracy: 87.78%\n",
            "Epoch: 30, Step: 60/164, Loss: 0.365018, Accuracy: 87.70%\n",
            "Epoch: 30, Step: 61/164, Loss: 0.364324, Accuracy: 87.70%\n",
            "Epoch: 30, Step: 62/164, Loss: 0.365246, Accuracy: 87.70%\n",
            "Epoch: 30, Step: 63/164, Loss: 0.364964, Accuracy: 87.74%\n",
            "Epoch: 30, Step: 64/164, Loss: 0.365796, Accuracy: 87.73%\n",
            "Epoch: 30, Step: 65/164, Loss: 0.365780, Accuracy: 87.74%\n",
            "Epoch: 30, Step: 66/164, Loss: 0.364726, Accuracy: 87.80%\n",
            "Epoch: 30, Step: 67/164, Loss: 0.363998, Accuracy: 87.81%\n",
            "Epoch: 30, Step: 68/164, Loss: 0.362417, Accuracy: 87.88%\n",
            "Epoch: 30, Step: 69/164, Loss: 0.362760, Accuracy: 87.86%\n",
            "Epoch: 30, Step: 70/164, Loss: 0.362024, Accuracy: 87.87%\n",
            "Epoch: 30, Step: 71/164, Loss: 0.364552, Accuracy: 87.82%\n",
            "Epoch: 30, Step: 72/164, Loss: 0.363595, Accuracy: 87.86%\n",
            "Epoch: 30, Step: 73/164, Loss: 0.365598, Accuracy: 87.81%\n",
            "Epoch: 30, Step: 74/164, Loss: 0.366066, Accuracy: 87.79%\n",
            "Epoch: 30, Step: 75/164, Loss: 0.365293, Accuracy: 87.79%\n",
            "Epoch: 30, Step: 76/164, Loss: 0.365778, Accuracy: 87.76%\n",
            "Epoch: 30, Step: 77/164, Loss: 0.367542, Accuracy: 87.71%\n",
            "Epoch: 30, Step: 78/164, Loss: 0.367909, Accuracy: 87.71%\n",
            "Epoch: 30, Step: 79/164, Loss: 0.368011, Accuracy: 87.70%\n",
            "Epoch: 30, Step: 80/164, Loss: 0.366809, Accuracy: 87.72%\n",
            "Epoch: 30, Step: 81/164, Loss: 0.367377, Accuracy: 87.71%\n",
            "Epoch: 30, Step: 82/164, Loss: 0.368444, Accuracy: 87.68%\n",
            "Epoch: 30, Step: 83/164, Loss: 0.367480, Accuracy: 87.75%\n",
            "Epoch: 30, Step: 84/164, Loss: 0.368722, Accuracy: 87.72%\n",
            "Epoch: 30, Step: 85/164, Loss: 0.368772, Accuracy: 87.75%\n",
            "Epoch: 30, Step: 86/164, Loss: 0.368075, Accuracy: 87.75%\n",
            "Epoch: 30, Step: 87/164, Loss: 0.369166, Accuracy: 87.74%\n",
            "Epoch: 30, Step: 88/164, Loss: 0.370403, Accuracy: 87.70%\n",
            "Epoch: 30, Step: 89/164, Loss: 0.370068, Accuracy: 87.71%\n",
            "Epoch: 30, Step: 90/164, Loss: 0.368980, Accuracy: 87.74%\n",
            "Epoch: 30, Step: 91/164, Loss: 0.368275, Accuracy: 87.78%\n",
            "Epoch: 30, Step: 92/164, Loss: 0.368688, Accuracy: 87.79%\n",
            "Epoch: 30, Step: 93/164, Loss: 0.369756, Accuracy: 87.77%\n",
            "Epoch: 30, Step: 94/164, Loss: 0.369870, Accuracy: 87.77%\n",
            "Epoch: 30, Step: 95/164, Loss: 0.369477, Accuracy: 87.74%\n",
            "Epoch: 30, Step: 96/164, Loss: 0.368583, Accuracy: 87.77%\n",
            "Epoch: 30, Step: 97/164, Loss: 0.369307, Accuracy: 87.72%\n",
            "Epoch: 30, Step: 98/164, Loss: 0.369266, Accuracy: 87.72%\n",
            "Epoch: 30, Step: 99/164, Loss: 0.370187, Accuracy: 87.68%\n",
            "Epoch: 30, Step: 100/164, Loss: 0.371034, Accuracy: 87.66%\n",
            "Epoch: 30, Step: 101/164, Loss: 0.371817, Accuracy: 87.67%\n",
            "Epoch: 30, Step: 102/164, Loss: 0.371867, Accuracy: 87.65%\n",
            "Epoch: 30, Step: 103/164, Loss: 0.373091, Accuracy: 87.59%\n",
            "Epoch: 30, Step: 104/164, Loss: 0.371888, Accuracy: 87.65%\n",
            "Epoch: 30, Step: 105/164, Loss: 0.373219, Accuracy: 87.61%\n",
            "Epoch: 30, Step: 106/164, Loss: 0.372166, Accuracy: 87.63%\n",
            "Epoch: 30, Step: 107/164, Loss: 0.372659, Accuracy: 87.62%\n",
            "Epoch: 30, Step: 108/164, Loss: 0.373258, Accuracy: 87.60%\n",
            "Epoch: 30, Step: 109/164, Loss: 0.375131, Accuracy: 87.56%\n",
            "Epoch: 30, Step: 110/164, Loss: 0.375850, Accuracy: 87.54%\n",
            "Epoch: 30, Step: 111/164, Loss: 0.374128, Accuracy: 87.61%\n",
            "Epoch: 30, Step: 112/164, Loss: 0.374399, Accuracy: 87.60%\n",
            "Epoch: 30, Step: 113/164, Loss: 0.375413, Accuracy: 87.57%\n",
            "Epoch: 30, Step: 114/164, Loss: 0.375626, Accuracy: 87.55%\n",
            "Epoch: 30, Step: 115/164, Loss: 0.376476, Accuracy: 87.52%\n",
            "Epoch: 30, Step: 116/164, Loss: 0.376429, Accuracy: 87.51%\n",
            "Epoch: 30, Step: 117/164, Loss: 0.378164, Accuracy: 87.47%\n",
            "Epoch: 30, Step: 118/164, Loss: 0.378360, Accuracy: 87.45%\n",
            "Epoch: 30, Step: 119/164, Loss: 0.378428, Accuracy: 87.42%\n",
            "Epoch: 30, Step: 120/164, Loss: 0.379092, Accuracy: 87.38%\n",
            "Epoch: 30, Step: 121/164, Loss: 0.379445, Accuracy: 87.35%\n",
            "Epoch: 30, Step: 122/164, Loss: 0.380726, Accuracy: 87.31%\n",
            "Epoch: 30, Step: 123/164, Loss: 0.381109, Accuracy: 87.32%\n",
            "Epoch: 30, Step: 124/164, Loss: 0.380819, Accuracy: 87.34%\n",
            "Epoch: 30, Step: 125/164, Loss: 0.381410, Accuracy: 87.33%\n",
            "Epoch: 30, Step: 126/164, Loss: 0.381723, Accuracy: 87.33%\n",
            "Epoch: 30, Step: 127/164, Loss: 0.381249, Accuracy: 87.32%\n",
            "Epoch: 30, Step: 128/164, Loss: 0.381158, Accuracy: 87.33%\n",
            "Epoch: 30, Step: 129/164, Loss: 0.380747, Accuracy: 87.33%\n",
            "Epoch: 30, Step: 130/164, Loss: 0.380455, Accuracy: 87.34%\n",
            "Epoch: 30, Step: 131/164, Loss: 0.381804, Accuracy: 87.29%\n",
            "Epoch: 30, Step: 132/164, Loss: 0.382802, Accuracy: 87.26%\n",
            "Epoch: 30, Step: 133/164, Loss: 0.382438, Accuracy: 87.26%\n",
            "Epoch: 30, Step: 134/164, Loss: 0.382012, Accuracy: 87.24%\n",
            "Epoch: 30, Step: 135/164, Loss: 0.381630, Accuracy: 87.25%\n",
            "Epoch: 30, Step: 136/164, Loss: 0.381913, Accuracy: 87.23%\n",
            "Epoch: 30, Step: 137/164, Loss: 0.382805, Accuracy: 87.21%\n",
            "Epoch: 30, Step: 138/164, Loss: 0.383492, Accuracy: 87.18%\n",
            "Epoch: 30, Step: 139/164, Loss: 0.383900, Accuracy: 87.17%\n",
            "Epoch: 30, Step: 140/164, Loss: 0.384310, Accuracy: 87.15%\n",
            "Epoch: 30, Step: 141/164, Loss: 0.384818, Accuracy: 87.14%\n",
            "Epoch: 30, Step: 142/164, Loss: 0.385589, Accuracy: 87.11%\n",
            "Epoch: 30, Step: 143/164, Loss: 0.385722, Accuracy: 87.10%\n",
            "Epoch: 30, Step: 144/164, Loss: 0.386143, Accuracy: 87.09%\n",
            "Epoch: 30, Step: 145/164, Loss: 0.386298, Accuracy: 87.10%\n",
            "Epoch: 30, Step: 146/164, Loss: 0.386392, Accuracy: 87.09%\n",
            "Epoch: 30, Step: 147/164, Loss: 0.385461, Accuracy: 87.13%\n",
            "Epoch: 30, Step: 148/164, Loss: 0.385887, Accuracy: 87.13%\n",
            "Epoch: 30, Step: 149/164, Loss: 0.385475, Accuracy: 87.13%\n",
            "Epoch: 30, Step: 150/164, Loss: 0.385003, Accuracy: 87.14%\n",
            "Epoch: 30, Step: 151/164, Loss: 0.384622, Accuracy: 87.14%\n",
            "Epoch: 30, Step: 152/164, Loss: 0.383948, Accuracy: 87.17%\n",
            "Epoch: 30, Step: 153/164, Loss: 0.383558, Accuracy: 87.20%\n",
            "Epoch: 30, Step: 154/164, Loss: 0.383683, Accuracy: 87.20%\n",
            "Epoch: 30, Step: 155/164, Loss: 0.383709, Accuracy: 87.20%\n",
            "Epoch: 30, Step: 156/164, Loss: 0.383087, Accuracy: 87.21%\n",
            "Epoch: 30, Step: 157/164, Loss: 0.382376, Accuracy: 87.24%\n",
            "Epoch: 30, Step: 158/164, Loss: 0.382452, Accuracy: 87.24%\n",
            "Epoch: 30, Step: 159/164, Loss: 0.382558, Accuracy: 87.23%\n",
            "Epoch: 30, Step: 160/164, Loss: 0.382057, Accuracy: 87.25%\n",
            "Epoch: 30, Step: 161/164, Loss: 0.382129, Accuracy: 87.24%\n",
            "Epoch: 30, Step: 162/164, Loss: 0.382666, Accuracy: 87.22%\n",
            "Epoch: 30, Step: 163/164, Loss: 0.382082, Accuracy: 87.23%\n",
            "Epoch: 30, Step: 164/164, Loss: 0.382267, Accuracy: 87.21%\n",
            "Epoch: 31, Step: 1/164, Loss: 0.329350, Accuracy: 89.06%\n",
            "Epoch: 31, Step: 2/164, Loss: 0.277146, Accuracy: 90.62%\n",
            "Epoch: 31, Step: 3/164, Loss: 0.288878, Accuracy: 90.62%\n",
            "Epoch: 31, Step: 4/164, Loss: 0.290792, Accuracy: 90.23%\n",
            "Epoch: 31, Step: 5/164, Loss: 0.291470, Accuracy: 90.16%\n",
            "Epoch: 31, Step: 6/164, Loss: 0.311642, Accuracy: 89.58%\n",
            "Epoch: 31, Step: 7/164, Loss: 0.305971, Accuracy: 89.96%\n",
            "Epoch: 31, Step: 8/164, Loss: 0.316100, Accuracy: 89.84%\n",
            "Epoch: 31, Step: 9/164, Loss: 0.314164, Accuracy: 90.02%\n",
            "Epoch: 31, Step: 10/164, Loss: 0.317666, Accuracy: 90.00%\n",
            "Epoch: 31, Step: 11/164, Loss: 0.315462, Accuracy: 89.84%\n",
            "Epoch: 31, Step: 12/164, Loss: 0.322661, Accuracy: 89.45%\n",
            "Epoch: 31, Step: 13/164, Loss: 0.321969, Accuracy: 89.30%\n",
            "Epoch: 31, Step: 14/164, Loss: 0.328825, Accuracy: 89.01%\n",
            "Epoch: 31, Step: 15/164, Loss: 0.325053, Accuracy: 89.22%\n",
            "Epoch: 31, Step: 16/164, Loss: 0.331234, Accuracy: 89.11%\n",
            "Epoch: 31, Step: 17/164, Loss: 0.328549, Accuracy: 89.25%\n",
            "Epoch: 31, Step: 18/164, Loss: 0.323146, Accuracy: 89.50%\n",
            "Epoch: 31, Step: 19/164, Loss: 0.324380, Accuracy: 89.35%\n",
            "Epoch: 31, Step: 20/164, Loss: 0.326575, Accuracy: 89.30%\n",
            "Epoch: 31, Step: 21/164, Loss: 0.329073, Accuracy: 89.10%\n",
            "Epoch: 31, Step: 22/164, Loss: 0.330323, Accuracy: 89.10%\n",
            "Epoch: 31, Step: 23/164, Loss: 0.332036, Accuracy: 88.89%\n",
            "Epoch: 31, Step: 24/164, Loss: 0.328970, Accuracy: 89.06%\n",
            "Epoch: 31, Step: 25/164, Loss: 0.327781, Accuracy: 89.12%\n",
            "Epoch: 31, Step: 26/164, Loss: 0.331474, Accuracy: 89.06%\n",
            "Epoch: 31, Step: 27/164, Loss: 0.337162, Accuracy: 88.74%\n",
            "Epoch: 31, Step: 28/164, Loss: 0.337278, Accuracy: 88.70%\n",
            "Epoch: 31, Step: 29/164, Loss: 0.335774, Accuracy: 88.77%\n",
            "Epoch: 31, Step: 30/164, Loss: 0.336607, Accuracy: 88.75%\n",
            "Epoch: 31, Step: 31/164, Loss: 0.341914, Accuracy: 88.63%\n",
            "Epoch: 31, Step: 32/164, Loss: 0.342013, Accuracy: 88.50%\n",
            "Epoch: 31, Step: 33/164, Loss: 0.346506, Accuracy: 88.38%\n",
            "Epoch: 31, Step: 34/164, Loss: 0.352088, Accuracy: 88.03%\n",
            "Epoch: 31, Step: 35/164, Loss: 0.352522, Accuracy: 88.08%\n",
            "Epoch: 31, Step: 36/164, Loss: 0.353395, Accuracy: 88.00%\n",
            "Epoch: 31, Step: 37/164, Loss: 0.352081, Accuracy: 88.11%\n",
            "Epoch: 31, Step: 38/164, Loss: 0.349037, Accuracy: 88.26%\n",
            "Epoch: 31, Step: 39/164, Loss: 0.349183, Accuracy: 88.24%\n",
            "Epoch: 31, Step: 40/164, Loss: 0.351529, Accuracy: 88.14%\n",
            "Epoch: 31, Step: 41/164, Loss: 0.352080, Accuracy: 88.15%\n",
            "Epoch: 31, Step: 42/164, Loss: 0.354543, Accuracy: 88.11%\n",
            "Epoch: 31, Step: 43/164, Loss: 0.359409, Accuracy: 87.94%\n",
            "Epoch: 31, Step: 44/164, Loss: 0.358185, Accuracy: 88.01%\n",
            "Epoch: 31, Step: 45/164, Loss: 0.358199, Accuracy: 88.04%\n",
            "Epoch: 31, Step: 46/164, Loss: 0.357675, Accuracy: 88.08%\n",
            "Epoch: 31, Step: 47/164, Loss: 0.358510, Accuracy: 88.02%\n",
            "Epoch: 31, Step: 48/164, Loss: 0.358821, Accuracy: 87.97%\n",
            "Epoch: 31, Step: 49/164, Loss: 0.359741, Accuracy: 87.98%\n",
            "Epoch: 31, Step: 50/164, Loss: 0.360792, Accuracy: 87.89%\n",
            "Epoch: 31, Step: 51/164, Loss: 0.360287, Accuracy: 87.94%\n",
            "Epoch: 31, Step: 52/164, Loss: 0.361935, Accuracy: 87.94%\n",
            "Epoch: 31, Step: 53/164, Loss: 0.363527, Accuracy: 87.91%\n",
            "Epoch: 31, Step: 54/164, Loss: 0.364358, Accuracy: 87.88%\n",
            "Epoch: 31, Step: 55/164, Loss: 0.368409, Accuracy: 87.74%\n",
            "Epoch: 31, Step: 56/164, Loss: 0.368726, Accuracy: 87.72%\n",
            "Epoch: 31, Step: 57/164, Loss: 0.369171, Accuracy: 87.72%\n",
            "Epoch: 31, Step: 58/164, Loss: 0.369245, Accuracy: 87.74%\n",
            "Epoch: 31, Step: 59/164, Loss: 0.370648, Accuracy: 87.63%\n",
            "Epoch: 31, Step: 60/164, Loss: 0.368182, Accuracy: 87.71%\n",
            "Epoch: 31, Step: 61/164, Loss: 0.366548, Accuracy: 87.72%\n",
            "Epoch: 31, Step: 62/164, Loss: 0.365286, Accuracy: 87.74%\n",
            "Epoch: 31, Step: 63/164, Loss: 0.366705, Accuracy: 87.75%\n",
            "Epoch: 31, Step: 64/164, Loss: 0.368409, Accuracy: 87.65%\n",
            "Epoch: 31, Step: 65/164, Loss: 0.369186, Accuracy: 87.62%\n",
            "Epoch: 31, Step: 66/164, Loss: 0.368117, Accuracy: 87.63%\n",
            "Epoch: 31, Step: 67/164, Loss: 0.367824, Accuracy: 87.60%\n",
            "Epoch: 31, Step: 68/164, Loss: 0.368365, Accuracy: 87.57%\n",
            "Epoch: 31, Step: 69/164, Loss: 0.370523, Accuracy: 87.50%\n",
            "Epoch: 31, Step: 70/164, Loss: 0.370994, Accuracy: 87.49%\n",
            "Epoch: 31, Step: 71/164, Loss: 0.370494, Accuracy: 87.51%\n",
            "Epoch: 31, Step: 72/164, Loss: 0.369525, Accuracy: 87.54%\n",
            "Epoch: 31, Step: 73/164, Loss: 0.368363, Accuracy: 87.61%\n",
            "Epoch: 31, Step: 74/164, Loss: 0.371042, Accuracy: 87.56%\n",
            "Epoch: 31, Step: 75/164, Loss: 0.370853, Accuracy: 87.56%\n",
            "Epoch: 31, Step: 76/164, Loss: 0.369315, Accuracy: 87.58%\n",
            "Epoch: 31, Step: 77/164, Loss: 0.369473, Accuracy: 87.56%\n",
            "Epoch: 31, Step: 78/164, Loss: 0.369437, Accuracy: 87.56%\n",
            "Epoch: 31, Step: 79/164, Loss: 0.368278, Accuracy: 87.58%\n",
            "Epoch: 31, Step: 80/164, Loss: 0.368358, Accuracy: 87.56%\n",
            "Epoch: 31, Step: 81/164, Loss: 0.369761, Accuracy: 87.46%\n",
            "Epoch: 31, Step: 82/164, Loss: 0.370131, Accuracy: 87.45%\n",
            "Epoch: 31, Step: 83/164, Loss: 0.369858, Accuracy: 87.46%\n",
            "Epoch: 31, Step: 84/164, Loss: 0.368379, Accuracy: 87.53%\n",
            "Epoch: 31, Step: 85/164, Loss: 0.368568, Accuracy: 87.54%\n",
            "Epoch: 31, Step: 86/164, Loss: 0.369121, Accuracy: 87.54%\n",
            "Epoch: 31, Step: 87/164, Loss: 0.368221, Accuracy: 87.57%\n",
            "Epoch: 31, Step: 88/164, Loss: 0.367831, Accuracy: 87.59%\n",
            "Epoch: 31, Step: 89/164, Loss: 0.368928, Accuracy: 87.58%\n",
            "Epoch: 31, Step: 90/164, Loss: 0.369342, Accuracy: 87.62%\n",
            "Epoch: 31, Step: 91/164, Loss: 0.369535, Accuracy: 87.59%\n",
            "Epoch: 31, Step: 92/164, Loss: 0.369719, Accuracy: 87.59%\n",
            "Epoch: 31, Step: 93/164, Loss: 0.368795, Accuracy: 87.63%\n",
            "Epoch: 31, Step: 94/164, Loss: 0.368274, Accuracy: 87.64%\n",
            "Epoch: 31, Step: 95/164, Loss: 0.367959, Accuracy: 87.67%\n",
            "Epoch: 31, Step: 96/164, Loss: 0.367467, Accuracy: 87.70%\n",
            "Epoch: 31, Step: 97/164, Loss: 0.368295, Accuracy: 87.65%\n",
            "Epoch: 31, Step: 98/164, Loss: 0.367348, Accuracy: 87.69%\n",
            "Epoch: 31, Step: 99/164, Loss: 0.367002, Accuracy: 87.70%\n",
            "Epoch: 31, Step: 100/164, Loss: 0.367792, Accuracy: 87.68%\n",
            "Epoch: 31, Step: 101/164, Loss: 0.367375, Accuracy: 87.71%\n",
            "Epoch: 31, Step: 102/164, Loss: 0.366720, Accuracy: 87.75%\n",
            "Epoch: 31, Step: 103/164, Loss: 0.367573, Accuracy: 87.74%\n",
            "Epoch: 31, Step: 104/164, Loss: 0.367057, Accuracy: 87.76%\n",
            "Epoch: 31, Step: 105/164, Loss: 0.367175, Accuracy: 87.73%\n",
            "Epoch: 31, Step: 106/164, Loss: 0.366330, Accuracy: 87.76%\n",
            "Epoch: 31, Step: 107/164, Loss: 0.366017, Accuracy: 87.77%\n",
            "Epoch: 31, Step: 108/164, Loss: 0.366335, Accuracy: 87.75%\n",
            "Epoch: 31, Step: 109/164, Loss: 0.367252, Accuracy: 87.72%\n",
            "Epoch: 31, Step: 110/164, Loss: 0.367822, Accuracy: 87.71%\n",
            "Epoch: 31, Step: 111/164, Loss: 0.368054, Accuracy: 87.73%\n",
            "Epoch: 31, Step: 112/164, Loss: 0.368370, Accuracy: 87.71%\n",
            "Epoch: 31, Step: 113/164, Loss: 0.367593, Accuracy: 87.76%\n",
            "Epoch: 31, Step: 114/164, Loss: 0.368406, Accuracy: 87.75%\n",
            "Epoch: 31, Step: 115/164, Loss: 0.367964, Accuracy: 87.76%\n",
            "Epoch: 31, Step: 116/164, Loss: 0.367139, Accuracy: 87.79%\n",
            "Epoch: 31, Step: 117/164, Loss: 0.367539, Accuracy: 87.78%\n",
            "Epoch: 31, Step: 118/164, Loss: 0.367193, Accuracy: 87.79%\n",
            "Epoch: 31, Step: 119/164, Loss: 0.368642, Accuracy: 87.76%\n",
            "Epoch: 31, Step: 120/164, Loss: 0.369394, Accuracy: 87.77%\n",
            "Epoch: 31, Step: 121/164, Loss: 0.369224, Accuracy: 87.78%\n",
            "Epoch: 31, Step: 122/164, Loss: 0.369234, Accuracy: 87.76%\n",
            "Epoch: 31, Step: 123/164, Loss: 0.369032, Accuracy: 87.78%\n",
            "Epoch: 31, Step: 124/164, Loss: 0.368583, Accuracy: 87.81%\n",
            "Epoch: 31, Step: 125/164, Loss: 0.369644, Accuracy: 87.81%\n",
            "Epoch: 31, Step: 126/164, Loss: 0.369377, Accuracy: 87.82%\n",
            "Epoch: 31, Step: 127/164, Loss: 0.368718, Accuracy: 87.85%\n",
            "Epoch: 31, Step: 128/164, Loss: 0.368648, Accuracy: 87.85%\n",
            "Epoch: 31, Step: 129/164, Loss: 0.367663, Accuracy: 87.88%\n",
            "Epoch: 31, Step: 130/164, Loss: 0.366841, Accuracy: 87.88%\n",
            "Epoch: 31, Step: 131/164, Loss: 0.367113, Accuracy: 87.88%\n",
            "Epoch: 31, Step: 132/164, Loss: 0.367858, Accuracy: 87.87%\n",
            "Epoch: 31, Step: 133/164, Loss: 0.366827, Accuracy: 87.91%\n",
            "Epoch: 31, Step: 134/164, Loss: 0.367271, Accuracy: 87.89%\n",
            "Epoch: 31, Step: 135/164, Loss: 0.367944, Accuracy: 87.85%\n",
            "Epoch: 31, Step: 136/164, Loss: 0.368331, Accuracy: 87.84%\n",
            "Epoch: 31, Step: 137/164, Loss: 0.369436, Accuracy: 87.78%\n",
            "Epoch: 31, Step: 138/164, Loss: 0.368683, Accuracy: 87.80%\n",
            "Epoch: 31, Step: 139/164, Loss: 0.368901, Accuracy: 87.79%\n",
            "Epoch: 31, Step: 140/164, Loss: 0.368835, Accuracy: 87.79%\n",
            "Epoch: 31, Step: 141/164, Loss: 0.368211, Accuracy: 87.80%\n",
            "Epoch: 31, Step: 142/164, Loss: 0.368008, Accuracy: 87.81%\n",
            "Epoch: 31, Step: 143/164, Loss: 0.367323, Accuracy: 87.82%\n",
            "Epoch: 31, Step: 144/164, Loss: 0.367644, Accuracy: 87.81%\n",
            "Epoch: 31, Step: 145/164, Loss: 0.367734, Accuracy: 87.82%\n",
            "Epoch: 31, Step: 146/164, Loss: 0.367357, Accuracy: 87.83%\n",
            "Epoch: 31, Step: 147/164, Loss: 0.366499, Accuracy: 87.86%\n",
            "Epoch: 31, Step: 148/164, Loss: 0.366075, Accuracy: 87.88%\n",
            "Epoch: 31, Step: 149/164, Loss: 0.366426, Accuracy: 87.87%\n",
            "Epoch: 31, Step: 150/164, Loss: 0.366023, Accuracy: 87.89%\n",
            "Epoch: 31, Step: 151/164, Loss: 0.365529, Accuracy: 87.90%\n",
            "Epoch: 31, Step: 152/164, Loss: 0.364783, Accuracy: 87.93%\n",
            "Epoch: 31, Step: 153/164, Loss: 0.364282, Accuracy: 87.95%\n",
            "Epoch: 31, Step: 154/164, Loss: 0.363323, Accuracy: 87.98%\n",
            "Epoch: 31, Step: 155/164, Loss: 0.362786, Accuracy: 87.99%\n",
            "Epoch: 31, Step: 156/164, Loss: 0.362148, Accuracy: 88.01%\n",
            "Epoch: 31, Step: 157/164, Loss: 0.361790, Accuracy: 88.01%\n",
            "Epoch: 31, Step: 158/164, Loss: 0.360656, Accuracy: 88.06%\n",
            "Epoch: 31, Step: 159/164, Loss: 0.360920, Accuracy: 88.06%\n",
            "Epoch: 31, Step: 160/164, Loss: 0.361306, Accuracy: 88.03%\n",
            "Epoch: 31, Step: 161/164, Loss: 0.361679, Accuracy: 88.01%\n",
            "Epoch: 31, Step: 162/164, Loss: 0.361336, Accuracy: 88.03%\n",
            "Epoch: 31, Step: 163/164, Loss: 0.362389, Accuracy: 88.00%\n",
            "Epoch: 31, Step: 164/164, Loss: 0.362140, Accuracy: 88.02%\n",
            "Epoch: 32, Step: 1/164, Loss: 0.307783, Accuracy: 89.84%\n",
            "Epoch: 32, Step: 2/164, Loss: 0.337162, Accuracy: 89.06%\n",
            "Epoch: 32, Step: 3/164, Loss: 0.340427, Accuracy: 89.32%\n",
            "Epoch: 32, Step: 4/164, Loss: 0.338465, Accuracy: 88.87%\n",
            "Epoch: 32, Step: 5/164, Loss: 0.330467, Accuracy: 88.28%\n",
            "Epoch: 32, Step: 6/164, Loss: 0.351173, Accuracy: 87.89%\n",
            "Epoch: 32, Step: 7/164, Loss: 0.334722, Accuracy: 88.28%\n",
            "Epoch: 32, Step: 8/164, Loss: 0.332504, Accuracy: 88.77%\n",
            "Epoch: 32, Step: 9/164, Loss: 0.326381, Accuracy: 88.89%\n",
            "Epoch: 32, Step: 10/164, Loss: 0.323472, Accuracy: 89.06%\n",
            "Epoch: 32, Step: 11/164, Loss: 0.317479, Accuracy: 89.42%\n",
            "Epoch: 32, Step: 12/164, Loss: 0.323878, Accuracy: 89.26%\n",
            "Epoch: 32, Step: 13/164, Loss: 0.324875, Accuracy: 89.18%\n",
            "Epoch: 32, Step: 14/164, Loss: 0.319856, Accuracy: 89.40%\n",
            "Epoch: 32, Step: 15/164, Loss: 0.316635, Accuracy: 89.32%\n",
            "Epoch: 32, Step: 16/164, Loss: 0.316188, Accuracy: 89.36%\n",
            "Epoch: 32, Step: 17/164, Loss: 0.325715, Accuracy: 88.88%\n",
            "Epoch: 32, Step: 18/164, Loss: 0.323445, Accuracy: 88.93%\n",
            "Epoch: 32, Step: 19/164, Loss: 0.326629, Accuracy: 88.90%\n",
            "Epoch: 32, Step: 20/164, Loss: 0.331207, Accuracy: 88.71%\n",
            "Epoch: 32, Step: 21/164, Loss: 0.332019, Accuracy: 88.65%\n",
            "Epoch: 32, Step: 22/164, Loss: 0.335593, Accuracy: 88.60%\n",
            "Epoch: 32, Step: 23/164, Loss: 0.343610, Accuracy: 88.28%\n",
            "Epoch: 32, Step: 24/164, Loss: 0.344421, Accuracy: 88.22%\n",
            "Epoch: 32, Step: 25/164, Loss: 0.341009, Accuracy: 88.31%\n",
            "Epoch: 32, Step: 26/164, Loss: 0.340515, Accuracy: 88.28%\n",
            "Epoch: 32, Step: 27/164, Loss: 0.341615, Accuracy: 88.22%\n",
            "Epoch: 32, Step: 28/164, Loss: 0.339396, Accuracy: 88.36%\n",
            "Epoch: 32, Step: 29/164, Loss: 0.337925, Accuracy: 88.44%\n",
            "Epoch: 32, Step: 30/164, Loss: 0.334682, Accuracy: 88.62%\n",
            "Epoch: 32, Step: 31/164, Loss: 0.338828, Accuracy: 88.53%\n",
            "Epoch: 32, Step: 32/164, Loss: 0.338209, Accuracy: 88.55%\n",
            "Epoch: 32, Step: 33/164, Loss: 0.340862, Accuracy: 88.45%\n",
            "Epoch: 32, Step: 34/164, Loss: 0.343021, Accuracy: 88.37%\n",
            "Epoch: 32, Step: 35/164, Loss: 0.342729, Accuracy: 88.39%\n",
            "Epoch: 32, Step: 36/164, Loss: 0.343836, Accuracy: 88.28%\n",
            "Epoch: 32, Step: 37/164, Loss: 0.343534, Accuracy: 88.32%\n",
            "Epoch: 32, Step: 38/164, Loss: 0.343050, Accuracy: 88.34%\n",
            "Epoch: 32, Step: 39/164, Loss: 0.344645, Accuracy: 88.28%\n",
            "Epoch: 32, Step: 40/164, Loss: 0.344011, Accuracy: 88.36%\n",
            "Epoch: 32, Step: 41/164, Loss: 0.342610, Accuracy: 88.36%\n",
            "Epoch: 32, Step: 42/164, Loss: 0.341230, Accuracy: 88.43%\n",
            "Epoch: 32, Step: 43/164, Loss: 0.344161, Accuracy: 88.34%\n",
            "Epoch: 32, Step: 44/164, Loss: 0.343413, Accuracy: 88.41%\n",
            "Epoch: 32, Step: 45/164, Loss: 0.341796, Accuracy: 88.44%\n",
            "Epoch: 32, Step: 46/164, Loss: 0.341197, Accuracy: 88.43%\n",
            "Epoch: 32, Step: 47/164, Loss: 0.343248, Accuracy: 88.41%\n",
            "Epoch: 32, Step: 48/164, Loss: 0.342306, Accuracy: 88.44%\n",
            "Epoch: 32, Step: 49/164, Loss: 0.342704, Accuracy: 88.46%\n",
            "Epoch: 32, Step: 50/164, Loss: 0.342234, Accuracy: 88.47%\n",
            "Epoch: 32, Step: 51/164, Loss: 0.343029, Accuracy: 88.50%\n",
            "Epoch: 32, Step: 52/164, Loss: 0.341983, Accuracy: 88.51%\n",
            "Epoch: 32, Step: 53/164, Loss: 0.341021, Accuracy: 88.56%\n",
            "Epoch: 32, Step: 54/164, Loss: 0.341956, Accuracy: 88.54%\n",
            "Epoch: 32, Step: 55/164, Loss: 0.345401, Accuracy: 88.45%\n",
            "Epoch: 32, Step: 56/164, Loss: 0.345840, Accuracy: 88.46%\n",
            "Epoch: 32, Step: 57/164, Loss: 0.347342, Accuracy: 88.40%\n",
            "Epoch: 32, Step: 58/164, Loss: 0.346260, Accuracy: 88.42%\n",
            "Epoch: 32, Step: 59/164, Loss: 0.347262, Accuracy: 88.36%\n",
            "Epoch: 32, Step: 60/164, Loss: 0.351295, Accuracy: 88.27%\n",
            "Epoch: 32, Step: 61/164, Loss: 0.352198, Accuracy: 88.23%\n",
            "Epoch: 32, Step: 62/164, Loss: 0.351652, Accuracy: 88.29%\n",
            "Epoch: 32, Step: 63/164, Loss: 0.351590, Accuracy: 88.26%\n",
            "Epoch: 32, Step: 64/164, Loss: 0.350139, Accuracy: 88.32%\n",
            "Epoch: 32, Step: 65/164, Loss: 0.351841, Accuracy: 88.25%\n",
            "Epoch: 32, Step: 66/164, Loss: 0.352307, Accuracy: 88.20%\n",
            "Epoch: 32, Step: 67/164, Loss: 0.354714, Accuracy: 88.15%\n",
            "Epoch: 32, Step: 68/164, Loss: 0.354682, Accuracy: 88.19%\n",
            "Epoch: 32, Step: 69/164, Loss: 0.354299, Accuracy: 88.20%\n",
            "Epoch: 32, Step: 70/164, Loss: 0.355353, Accuracy: 88.16%\n",
            "Epoch: 32, Step: 71/164, Loss: 0.355865, Accuracy: 88.18%\n",
            "Epoch: 32, Step: 72/164, Loss: 0.355950, Accuracy: 88.16%\n",
            "Epoch: 32, Step: 73/164, Loss: 0.357369, Accuracy: 88.13%\n",
            "Epoch: 32, Step: 74/164, Loss: 0.358382, Accuracy: 88.10%\n",
            "Epoch: 32, Step: 75/164, Loss: 0.358963, Accuracy: 88.10%\n",
            "Epoch: 32, Step: 76/164, Loss: 0.358393, Accuracy: 88.15%\n",
            "Epoch: 32, Step: 77/164, Loss: 0.359465, Accuracy: 88.11%\n",
            "Epoch: 32, Step: 78/164, Loss: 0.358721, Accuracy: 88.11%\n",
            "Epoch: 32, Step: 79/164, Loss: 0.357819, Accuracy: 88.11%\n",
            "Epoch: 32, Step: 80/164, Loss: 0.357403, Accuracy: 88.12%\n",
            "Epoch: 32, Step: 81/164, Loss: 0.358220, Accuracy: 88.08%\n",
            "Epoch: 32, Step: 82/164, Loss: 0.357736, Accuracy: 88.13%\n",
            "Epoch: 32, Step: 83/164, Loss: 0.357648, Accuracy: 88.12%\n",
            "Epoch: 32, Step: 84/164, Loss: 0.357468, Accuracy: 88.12%\n",
            "Epoch: 32, Step: 85/164, Loss: 0.358698, Accuracy: 88.09%\n",
            "Epoch: 32, Step: 86/164, Loss: 0.358889, Accuracy: 88.06%\n",
            "Epoch: 32, Step: 87/164, Loss: 0.359475, Accuracy: 88.06%\n",
            "Epoch: 32, Step: 88/164, Loss: 0.359417, Accuracy: 88.03%\n",
            "Epoch: 32, Step: 89/164, Loss: 0.358606, Accuracy: 88.03%\n",
            "Epoch: 32, Step: 90/164, Loss: 0.358515, Accuracy: 88.01%\n",
            "Epoch: 32, Step: 91/164, Loss: 0.358799, Accuracy: 88.03%\n",
            "Epoch: 32, Step: 92/164, Loss: 0.359059, Accuracy: 88.00%\n",
            "Epoch: 32, Step: 93/164, Loss: 0.359519, Accuracy: 87.97%\n",
            "Epoch: 32, Step: 94/164, Loss: 0.359286, Accuracy: 87.96%\n",
            "Epoch: 32, Step: 95/164, Loss: 0.360175, Accuracy: 87.91%\n",
            "Epoch: 32, Step: 96/164, Loss: 0.360600, Accuracy: 87.90%\n",
            "Epoch: 32, Step: 97/164, Loss: 0.360236, Accuracy: 87.91%\n",
            "Epoch: 32, Step: 98/164, Loss: 0.360375, Accuracy: 87.92%\n",
            "Epoch: 32, Step: 99/164, Loss: 0.360761, Accuracy: 87.90%\n",
            "Epoch: 32, Step: 100/164, Loss: 0.360483, Accuracy: 87.91%\n",
            "Epoch: 32, Step: 101/164, Loss: 0.359246, Accuracy: 87.96%\n",
            "Epoch: 32, Step: 102/164, Loss: 0.359770, Accuracy: 87.97%\n",
            "Epoch: 32, Step: 103/164, Loss: 0.360332, Accuracy: 87.93%\n",
            "Epoch: 32, Step: 104/164, Loss: 0.359318, Accuracy: 87.94%\n",
            "Epoch: 32, Step: 105/164, Loss: 0.358918, Accuracy: 87.95%\n",
            "Epoch: 32, Step: 106/164, Loss: 0.359445, Accuracy: 87.95%\n",
            "Epoch: 32, Step: 107/164, Loss: 0.359468, Accuracy: 87.94%\n",
            "Epoch: 32, Step: 108/164, Loss: 0.358900, Accuracy: 87.95%\n",
            "Epoch: 32, Step: 109/164, Loss: 0.358722, Accuracy: 87.98%\n",
            "Epoch: 32, Step: 110/164, Loss: 0.358905, Accuracy: 87.96%\n",
            "Epoch: 32, Step: 111/164, Loss: 0.358436, Accuracy: 87.99%\n",
            "Epoch: 32, Step: 112/164, Loss: 0.359129, Accuracy: 87.95%\n",
            "Epoch: 32, Step: 113/164, Loss: 0.359424, Accuracy: 87.96%\n",
            "Epoch: 32, Step: 114/164, Loss: 0.359633, Accuracy: 87.97%\n",
            "Epoch: 32, Step: 115/164, Loss: 0.359029, Accuracy: 87.98%\n",
            "Epoch: 32, Step: 116/164, Loss: 0.358330, Accuracy: 87.99%\n",
            "Epoch: 32, Step: 117/164, Loss: 0.357911, Accuracy: 88.01%\n",
            "Epoch: 32, Step: 118/164, Loss: 0.358686, Accuracy: 88.01%\n",
            "Epoch: 32, Step: 119/164, Loss: 0.359037, Accuracy: 88.00%\n",
            "Epoch: 32, Step: 120/164, Loss: 0.359177, Accuracy: 87.97%\n",
            "Epoch: 32, Step: 121/164, Loss: 0.359018, Accuracy: 87.96%\n",
            "Epoch: 32, Step: 122/164, Loss: 0.358835, Accuracy: 87.97%\n",
            "Epoch: 32, Step: 123/164, Loss: 0.359816, Accuracy: 87.95%\n",
            "Epoch: 32, Step: 124/164, Loss: 0.359059, Accuracy: 87.96%\n",
            "Epoch: 32, Step: 125/164, Loss: 0.359374, Accuracy: 87.97%\n",
            "Epoch: 32, Step: 126/164, Loss: 0.360377, Accuracy: 87.95%\n",
            "Epoch: 32, Step: 127/164, Loss: 0.360979, Accuracy: 87.92%\n",
            "Epoch: 32, Step: 128/164, Loss: 0.361237, Accuracy: 87.92%\n",
            "Epoch: 32, Step: 129/164, Loss: 0.360851, Accuracy: 87.95%\n",
            "Epoch: 32, Step: 130/164, Loss: 0.360943, Accuracy: 87.95%\n",
            "Epoch: 32, Step: 131/164, Loss: 0.361949, Accuracy: 87.92%\n",
            "Epoch: 32, Step: 132/164, Loss: 0.361275, Accuracy: 87.93%\n",
            "Epoch: 32, Step: 133/164, Loss: 0.361814, Accuracy: 87.90%\n",
            "Epoch: 32, Step: 134/164, Loss: 0.361423, Accuracy: 87.92%\n",
            "Epoch: 32, Step: 135/164, Loss: 0.360881, Accuracy: 87.94%\n",
            "Epoch: 32, Step: 136/164, Loss: 0.360604, Accuracy: 87.96%\n",
            "Epoch: 32, Step: 137/164, Loss: 0.360742, Accuracy: 87.95%\n",
            "Epoch: 32, Step: 138/164, Loss: 0.360574, Accuracy: 87.97%\n",
            "Epoch: 32, Step: 139/164, Loss: 0.359942, Accuracy: 87.98%\n",
            "Epoch: 32, Step: 140/164, Loss: 0.359980, Accuracy: 87.99%\n",
            "Epoch: 32, Step: 141/164, Loss: 0.360385, Accuracy: 87.97%\n",
            "Epoch: 32, Step: 142/164, Loss: 0.359339, Accuracy: 88.01%\n",
            "Epoch: 32, Step: 143/164, Loss: 0.359362, Accuracy: 88.00%\n",
            "Epoch: 32, Step: 144/164, Loss: 0.358905, Accuracy: 88.00%\n",
            "Epoch: 32, Step: 145/164, Loss: 0.358795, Accuracy: 88.01%\n",
            "Epoch: 32, Step: 146/164, Loss: 0.357895, Accuracy: 88.04%\n",
            "Epoch: 32, Step: 147/164, Loss: 0.357411, Accuracy: 88.05%\n",
            "Epoch: 32, Step: 148/164, Loss: 0.356967, Accuracy: 88.09%\n",
            "Epoch: 32, Step: 149/164, Loss: 0.357525, Accuracy: 88.07%\n",
            "Epoch: 32, Step: 150/164, Loss: 0.357260, Accuracy: 88.08%\n",
            "Epoch: 32, Step: 151/164, Loss: 0.356422, Accuracy: 88.12%\n",
            "Epoch: 32, Step: 152/164, Loss: 0.356217, Accuracy: 88.13%\n",
            "Epoch: 32, Step: 153/164, Loss: 0.355435, Accuracy: 88.15%\n",
            "Epoch: 32, Step: 154/164, Loss: 0.356273, Accuracy: 88.11%\n",
            "Epoch: 32, Step: 155/164, Loss: 0.356478, Accuracy: 88.10%\n",
            "Epoch: 32, Step: 156/164, Loss: 0.357444, Accuracy: 88.08%\n",
            "Epoch: 32, Step: 157/164, Loss: 0.356609, Accuracy: 88.12%\n",
            "Epoch: 32, Step: 158/164, Loss: 0.357194, Accuracy: 88.12%\n",
            "Epoch: 32, Step: 159/164, Loss: 0.357341, Accuracy: 88.14%\n",
            "Epoch: 32, Step: 160/164, Loss: 0.357316, Accuracy: 88.14%\n",
            "Epoch: 32, Step: 161/164, Loss: 0.357712, Accuracy: 88.12%\n",
            "Epoch: 32, Step: 162/164, Loss: 0.358038, Accuracy: 88.13%\n",
            "Epoch: 32, Step: 163/164, Loss: 0.358578, Accuracy: 88.07%\n",
            "Epoch: 32, Step: 164/164, Loss: 0.357874, Accuracy: 88.07%\n",
            "Epoch: 33, Step: 1/164, Loss: 0.206401, Accuracy: 94.53%\n",
            "Epoch: 33, Step: 2/164, Loss: 0.273693, Accuracy: 92.19%\n",
            "Epoch: 33, Step: 3/164, Loss: 0.305318, Accuracy: 90.36%\n",
            "Epoch: 33, Step: 4/164, Loss: 0.299789, Accuracy: 90.04%\n",
            "Epoch: 33, Step: 5/164, Loss: 0.311786, Accuracy: 89.38%\n",
            "Epoch: 33, Step: 6/164, Loss: 0.319663, Accuracy: 88.93%\n",
            "Epoch: 33, Step: 7/164, Loss: 0.325407, Accuracy: 88.50%\n",
            "Epoch: 33, Step: 8/164, Loss: 0.307411, Accuracy: 89.36%\n",
            "Epoch: 33, Step: 9/164, Loss: 0.303872, Accuracy: 89.58%\n",
            "Epoch: 33, Step: 10/164, Loss: 0.309311, Accuracy: 88.98%\n",
            "Epoch: 33, Step: 11/164, Loss: 0.305691, Accuracy: 89.06%\n",
            "Epoch: 33, Step: 12/164, Loss: 0.300340, Accuracy: 89.52%\n",
            "Epoch: 33, Step: 13/164, Loss: 0.305654, Accuracy: 89.30%\n",
            "Epoch: 33, Step: 14/164, Loss: 0.314053, Accuracy: 89.01%\n",
            "Epoch: 33, Step: 15/164, Loss: 0.308457, Accuracy: 89.27%\n",
            "Epoch: 33, Step: 16/164, Loss: 0.310493, Accuracy: 89.26%\n",
            "Epoch: 33, Step: 17/164, Loss: 0.312882, Accuracy: 89.34%\n",
            "Epoch: 33, Step: 18/164, Loss: 0.307866, Accuracy: 89.58%\n",
            "Epoch: 33, Step: 19/164, Loss: 0.306253, Accuracy: 89.56%\n",
            "Epoch: 33, Step: 20/164, Loss: 0.306365, Accuracy: 89.49%\n",
            "Epoch: 33, Step: 21/164, Loss: 0.307347, Accuracy: 89.51%\n",
            "Epoch: 33, Step: 22/164, Loss: 0.308798, Accuracy: 89.49%\n",
            "Epoch: 33, Step: 23/164, Loss: 0.309039, Accuracy: 89.54%\n",
            "Epoch: 33, Step: 24/164, Loss: 0.311126, Accuracy: 89.39%\n",
            "Epoch: 33, Step: 25/164, Loss: 0.311606, Accuracy: 89.41%\n",
            "Epoch: 33, Step: 26/164, Loss: 0.318045, Accuracy: 89.27%\n",
            "Epoch: 33, Step: 27/164, Loss: 0.315833, Accuracy: 89.38%\n",
            "Epoch: 33, Step: 28/164, Loss: 0.315718, Accuracy: 89.31%\n",
            "Epoch: 33, Step: 29/164, Loss: 0.317355, Accuracy: 89.28%\n",
            "Epoch: 33, Step: 30/164, Loss: 0.316004, Accuracy: 89.24%\n",
            "Epoch: 33, Step: 31/164, Loss: 0.316820, Accuracy: 89.16%\n",
            "Epoch: 33, Step: 32/164, Loss: 0.317048, Accuracy: 89.11%\n",
            "Epoch: 33, Step: 33/164, Loss: 0.316701, Accuracy: 89.18%\n",
            "Epoch: 33, Step: 34/164, Loss: 0.319118, Accuracy: 89.15%\n",
            "Epoch: 33, Step: 35/164, Loss: 0.320438, Accuracy: 89.11%\n",
            "Epoch: 33, Step: 36/164, Loss: 0.322820, Accuracy: 88.95%\n",
            "Epoch: 33, Step: 37/164, Loss: 0.321843, Accuracy: 88.96%\n",
            "Epoch: 33, Step: 38/164, Loss: 0.320056, Accuracy: 89.00%\n",
            "Epoch: 33, Step: 39/164, Loss: 0.318969, Accuracy: 89.08%\n",
            "Epoch: 33, Step: 40/164, Loss: 0.317829, Accuracy: 89.14%\n",
            "Epoch: 33, Step: 41/164, Loss: 0.315379, Accuracy: 89.29%\n",
            "Epoch: 33, Step: 42/164, Loss: 0.315547, Accuracy: 89.30%\n",
            "Epoch: 33, Step: 43/164, Loss: 0.314753, Accuracy: 89.32%\n",
            "Epoch: 33, Step: 44/164, Loss: 0.316698, Accuracy: 89.33%\n",
            "Epoch: 33, Step: 45/164, Loss: 0.317646, Accuracy: 89.36%\n",
            "Epoch: 33, Step: 46/164, Loss: 0.320147, Accuracy: 89.25%\n",
            "Epoch: 33, Step: 47/164, Loss: 0.321869, Accuracy: 89.21%\n",
            "Epoch: 33, Step: 48/164, Loss: 0.323910, Accuracy: 89.06%\n",
            "Epoch: 33, Step: 49/164, Loss: 0.323796, Accuracy: 89.06%\n",
            "Epoch: 33, Step: 50/164, Loss: 0.323606, Accuracy: 89.09%\n",
            "Epoch: 33, Step: 51/164, Loss: 0.323490, Accuracy: 89.06%\n",
            "Epoch: 33, Step: 52/164, Loss: 0.324630, Accuracy: 89.06%\n",
            "Epoch: 33, Step: 53/164, Loss: 0.325919, Accuracy: 89.03%\n",
            "Epoch: 33, Step: 54/164, Loss: 0.324607, Accuracy: 89.06%\n",
            "Epoch: 33, Step: 55/164, Loss: 0.325522, Accuracy: 89.06%\n",
            "Epoch: 33, Step: 56/164, Loss: 0.327511, Accuracy: 89.01%\n",
            "Epoch: 33, Step: 57/164, Loss: 0.329199, Accuracy: 88.97%\n",
            "Epoch: 33, Step: 58/164, Loss: 0.328922, Accuracy: 89.00%\n",
            "Epoch: 33, Step: 59/164, Loss: 0.330712, Accuracy: 88.90%\n",
            "Epoch: 33, Step: 60/164, Loss: 0.332907, Accuracy: 88.83%\n",
            "Epoch: 33, Step: 61/164, Loss: 0.332527, Accuracy: 88.86%\n",
            "Epoch: 33, Step: 62/164, Loss: 0.332628, Accuracy: 88.85%\n",
            "Epoch: 33, Step: 63/164, Loss: 0.332900, Accuracy: 88.85%\n",
            "Epoch: 33, Step: 64/164, Loss: 0.332893, Accuracy: 88.89%\n",
            "Epoch: 33, Step: 65/164, Loss: 0.335602, Accuracy: 88.80%\n",
            "Epoch: 33, Step: 66/164, Loss: 0.336264, Accuracy: 88.80%\n",
            "Epoch: 33, Step: 67/164, Loss: 0.334889, Accuracy: 88.85%\n",
            "Epoch: 33, Step: 68/164, Loss: 0.334191, Accuracy: 88.88%\n",
            "Epoch: 33, Step: 69/164, Loss: 0.334639, Accuracy: 88.88%\n",
            "Epoch: 33, Step: 70/164, Loss: 0.334553, Accuracy: 88.90%\n",
            "Epoch: 33, Step: 71/164, Loss: 0.336125, Accuracy: 88.84%\n",
            "Epoch: 33, Step: 72/164, Loss: 0.335707, Accuracy: 88.81%\n",
            "Epoch: 33, Step: 73/164, Loss: 0.337491, Accuracy: 88.74%\n",
            "Epoch: 33, Step: 74/164, Loss: 0.338090, Accuracy: 88.70%\n",
            "Epoch: 33, Step: 75/164, Loss: 0.339558, Accuracy: 88.61%\n",
            "Epoch: 33, Step: 76/164, Loss: 0.339539, Accuracy: 88.58%\n",
            "Epoch: 33, Step: 77/164, Loss: 0.338157, Accuracy: 88.59%\n",
            "Epoch: 33, Step: 78/164, Loss: 0.337264, Accuracy: 88.60%\n",
            "Epoch: 33, Step: 79/164, Loss: 0.336977, Accuracy: 88.61%\n",
            "Epoch: 33, Step: 80/164, Loss: 0.336239, Accuracy: 88.63%\n",
            "Epoch: 33, Step: 81/164, Loss: 0.335757, Accuracy: 88.65%\n",
            "Epoch: 33, Step: 82/164, Loss: 0.334471, Accuracy: 88.68%\n",
            "Epoch: 33, Step: 83/164, Loss: 0.335205, Accuracy: 88.68%\n",
            "Epoch: 33, Step: 84/164, Loss: 0.336218, Accuracy: 88.63%\n",
            "Epoch: 33, Step: 85/164, Loss: 0.336226, Accuracy: 88.64%\n",
            "Epoch: 33, Step: 86/164, Loss: 0.336281, Accuracy: 88.68%\n",
            "Epoch: 33, Step: 87/164, Loss: 0.335720, Accuracy: 88.69%\n",
            "Epoch: 33, Step: 88/164, Loss: 0.337121, Accuracy: 88.64%\n",
            "Epoch: 33, Step: 89/164, Loss: 0.336932, Accuracy: 88.65%\n",
            "Epoch: 33, Step: 90/164, Loss: 0.337692, Accuracy: 88.62%\n",
            "Epoch: 33, Step: 91/164, Loss: 0.337577, Accuracy: 88.64%\n",
            "Epoch: 33, Step: 92/164, Loss: 0.338604, Accuracy: 88.62%\n",
            "Epoch: 33, Step: 93/164, Loss: 0.338851, Accuracy: 88.59%\n",
            "Epoch: 33, Step: 94/164, Loss: 0.339135, Accuracy: 88.60%\n",
            "Epoch: 33, Step: 95/164, Loss: 0.339535, Accuracy: 88.58%\n",
            "Epoch: 33, Step: 96/164, Loss: 0.339617, Accuracy: 88.55%\n",
            "Epoch: 33, Step: 97/164, Loss: 0.339565, Accuracy: 88.57%\n",
            "Epoch: 33, Step: 98/164, Loss: 0.338179, Accuracy: 88.62%\n",
            "Epoch: 33, Step: 99/164, Loss: 0.338264, Accuracy: 88.64%\n",
            "Epoch: 33, Step: 100/164, Loss: 0.337956, Accuracy: 88.64%\n",
            "Epoch: 33, Step: 101/164, Loss: 0.337837, Accuracy: 88.62%\n",
            "Epoch: 33, Step: 102/164, Loss: 0.338602, Accuracy: 88.58%\n",
            "Epoch: 33, Step: 103/164, Loss: 0.337325, Accuracy: 88.61%\n",
            "Epoch: 33, Step: 104/164, Loss: 0.337596, Accuracy: 88.59%\n",
            "Epoch: 33, Step: 105/164, Loss: 0.337397, Accuracy: 88.58%\n",
            "Epoch: 33, Step: 106/164, Loss: 0.337400, Accuracy: 88.60%\n",
            "Epoch: 33, Step: 107/164, Loss: 0.337225, Accuracy: 88.60%\n",
            "Epoch: 33, Step: 108/164, Loss: 0.338984, Accuracy: 88.52%\n",
            "Epoch: 33, Step: 109/164, Loss: 0.338392, Accuracy: 88.55%\n",
            "Epoch: 33, Step: 110/164, Loss: 0.337427, Accuracy: 88.59%\n",
            "Epoch: 33, Step: 111/164, Loss: 0.337840, Accuracy: 88.56%\n",
            "Epoch: 33, Step: 112/164, Loss: 0.337576, Accuracy: 88.57%\n",
            "Epoch: 33, Step: 113/164, Loss: 0.337506, Accuracy: 88.58%\n",
            "Epoch: 33, Step: 114/164, Loss: 0.338200, Accuracy: 88.54%\n",
            "Epoch: 33, Step: 115/164, Loss: 0.338037, Accuracy: 88.55%\n",
            "Epoch: 33, Step: 116/164, Loss: 0.338528, Accuracy: 88.53%\n",
            "Epoch: 33, Step: 117/164, Loss: 0.339522, Accuracy: 88.49%\n",
            "Epoch: 33, Step: 118/164, Loss: 0.338821, Accuracy: 88.51%\n",
            "Epoch: 33, Step: 119/164, Loss: 0.339167, Accuracy: 88.49%\n",
            "Epoch: 33, Step: 120/164, Loss: 0.339175, Accuracy: 88.50%\n",
            "Epoch: 33, Step: 121/164, Loss: 0.339338, Accuracy: 88.47%\n",
            "Epoch: 33, Step: 122/164, Loss: 0.339624, Accuracy: 88.45%\n",
            "Epoch: 33, Step: 123/164, Loss: 0.338782, Accuracy: 88.48%\n",
            "Epoch: 33, Step: 124/164, Loss: 0.339336, Accuracy: 88.46%\n",
            "Epoch: 33, Step: 125/164, Loss: 0.339681, Accuracy: 88.46%\n",
            "Epoch: 33, Step: 126/164, Loss: 0.339287, Accuracy: 88.46%\n",
            "Epoch: 33, Step: 127/164, Loss: 0.339310, Accuracy: 88.47%\n",
            "Epoch: 33, Step: 128/164, Loss: 0.338825, Accuracy: 88.48%\n",
            "Epoch: 33, Step: 129/164, Loss: 0.338747, Accuracy: 88.48%\n",
            "Epoch: 33, Step: 130/164, Loss: 0.338181, Accuracy: 88.50%\n",
            "Epoch: 33, Step: 131/164, Loss: 0.339488, Accuracy: 88.47%\n",
            "Epoch: 33, Step: 132/164, Loss: 0.340212, Accuracy: 88.44%\n",
            "Epoch: 33, Step: 133/164, Loss: 0.340544, Accuracy: 88.42%\n",
            "Epoch: 33, Step: 134/164, Loss: 0.340571, Accuracy: 88.43%\n",
            "Epoch: 33, Step: 135/164, Loss: 0.340777, Accuracy: 88.43%\n",
            "Epoch: 33, Step: 136/164, Loss: 0.340815, Accuracy: 88.42%\n",
            "Epoch: 33, Step: 137/164, Loss: 0.340015, Accuracy: 88.45%\n",
            "Epoch: 33, Step: 138/164, Loss: 0.339485, Accuracy: 88.47%\n",
            "Epoch: 33, Step: 139/164, Loss: 0.340571, Accuracy: 88.45%\n",
            "Epoch: 33, Step: 140/164, Loss: 0.340844, Accuracy: 88.45%\n",
            "Epoch: 33, Step: 141/164, Loss: 0.341095, Accuracy: 88.45%\n",
            "Epoch: 33, Step: 142/164, Loss: 0.341091, Accuracy: 88.44%\n",
            "Epoch: 33, Step: 143/164, Loss: 0.341556, Accuracy: 88.43%\n",
            "Epoch: 33, Step: 144/164, Loss: 0.341845, Accuracy: 88.42%\n",
            "Epoch: 33, Step: 145/164, Loss: 0.342470, Accuracy: 88.39%\n",
            "Epoch: 33, Step: 146/164, Loss: 0.341605, Accuracy: 88.43%\n",
            "Epoch: 33, Step: 147/164, Loss: 0.341622, Accuracy: 88.45%\n",
            "Epoch: 33, Step: 148/164, Loss: 0.342261, Accuracy: 88.43%\n",
            "Epoch: 33, Step: 149/164, Loss: 0.342003, Accuracy: 88.44%\n",
            "Epoch: 33, Step: 150/164, Loss: 0.342019, Accuracy: 88.45%\n",
            "Epoch: 33, Step: 151/164, Loss: 0.342198, Accuracy: 88.43%\n",
            "Epoch: 33, Step: 152/164, Loss: 0.342115, Accuracy: 88.43%\n",
            "Epoch: 33, Step: 153/164, Loss: 0.341529, Accuracy: 88.44%\n",
            "Epoch: 33, Step: 154/164, Loss: 0.341574, Accuracy: 88.45%\n",
            "Epoch: 33, Step: 155/164, Loss: 0.341166, Accuracy: 88.47%\n",
            "Epoch: 33, Step: 156/164, Loss: 0.341304, Accuracy: 88.46%\n",
            "Epoch: 33, Step: 157/164, Loss: 0.341302, Accuracy: 88.48%\n",
            "Epoch: 33, Step: 158/164, Loss: 0.341334, Accuracy: 88.47%\n",
            "Epoch: 33, Step: 159/164, Loss: 0.341697, Accuracy: 88.46%\n",
            "Epoch: 33, Step: 160/164, Loss: 0.341757, Accuracy: 88.43%\n",
            "Epoch: 33, Step: 161/164, Loss: 0.342284, Accuracy: 88.42%\n",
            "Epoch: 33, Step: 162/164, Loss: 0.343007, Accuracy: 88.41%\n",
            "Epoch: 33, Step: 163/164, Loss: 0.343362, Accuracy: 88.39%\n",
            "Epoch: 33, Step: 164/164, Loss: 0.342493, Accuracy: 88.41%\n",
            "Epoch: 34, Step: 1/164, Loss: 0.374002, Accuracy: 87.50%\n",
            "Epoch: 34, Step: 2/164, Loss: 0.392730, Accuracy: 85.55%\n",
            "Epoch: 34, Step: 3/164, Loss: 0.410090, Accuracy: 85.42%\n",
            "Epoch: 34, Step: 4/164, Loss: 0.398093, Accuracy: 86.13%\n",
            "Epoch: 34, Step: 5/164, Loss: 0.395147, Accuracy: 86.41%\n",
            "Epoch: 34, Step: 6/164, Loss: 0.386520, Accuracy: 86.46%\n",
            "Epoch: 34, Step: 7/164, Loss: 0.386235, Accuracy: 86.50%\n",
            "Epoch: 34, Step: 8/164, Loss: 0.368941, Accuracy: 87.11%\n",
            "Epoch: 34, Step: 9/164, Loss: 0.359802, Accuracy: 87.67%\n",
            "Epoch: 34, Step: 10/164, Loss: 0.354755, Accuracy: 88.28%\n",
            "Epoch: 34, Step: 11/164, Loss: 0.354783, Accuracy: 88.35%\n",
            "Epoch: 34, Step: 12/164, Loss: 0.346871, Accuracy: 88.54%\n",
            "Epoch: 34, Step: 13/164, Loss: 0.344441, Accuracy: 88.52%\n",
            "Epoch: 34, Step: 14/164, Loss: 0.352077, Accuracy: 88.39%\n",
            "Epoch: 34, Step: 15/164, Loss: 0.351252, Accuracy: 88.33%\n",
            "Epoch: 34, Step: 16/164, Loss: 0.353768, Accuracy: 87.99%\n",
            "Epoch: 34, Step: 17/164, Loss: 0.354933, Accuracy: 88.05%\n",
            "Epoch: 34, Step: 18/164, Loss: 0.360084, Accuracy: 87.89%\n",
            "Epoch: 34, Step: 19/164, Loss: 0.364020, Accuracy: 87.75%\n",
            "Epoch: 34, Step: 20/164, Loss: 0.370392, Accuracy: 87.54%\n",
            "Epoch: 34, Step: 21/164, Loss: 0.370787, Accuracy: 87.43%\n",
            "Epoch: 34, Step: 22/164, Loss: 0.369098, Accuracy: 87.50%\n",
            "Epoch: 34, Step: 23/164, Loss: 0.367823, Accuracy: 87.43%\n",
            "Epoch: 34, Step: 24/164, Loss: 0.371405, Accuracy: 87.27%\n",
            "Epoch: 34, Step: 25/164, Loss: 0.372324, Accuracy: 87.28%\n",
            "Epoch: 34, Step: 26/164, Loss: 0.373900, Accuracy: 87.11%\n",
            "Epoch: 34, Step: 27/164, Loss: 0.376207, Accuracy: 86.98%\n",
            "Epoch: 34, Step: 28/164, Loss: 0.371689, Accuracy: 87.14%\n",
            "Epoch: 34, Step: 29/164, Loss: 0.370373, Accuracy: 87.23%\n",
            "Epoch: 34, Step: 30/164, Loss: 0.367587, Accuracy: 87.34%\n",
            "Epoch: 34, Step: 31/164, Loss: 0.367843, Accuracy: 87.35%\n",
            "Epoch: 34, Step: 32/164, Loss: 0.364800, Accuracy: 87.40%\n",
            "Epoch: 34, Step: 33/164, Loss: 0.360119, Accuracy: 87.45%\n",
            "Epoch: 34, Step: 34/164, Loss: 0.357519, Accuracy: 87.55%\n",
            "Epoch: 34, Step: 35/164, Loss: 0.358912, Accuracy: 87.50%\n",
            "Epoch: 34, Step: 36/164, Loss: 0.355590, Accuracy: 87.63%\n",
            "Epoch: 34, Step: 37/164, Loss: 0.354288, Accuracy: 87.65%\n",
            "Epoch: 34, Step: 38/164, Loss: 0.355776, Accuracy: 87.66%\n",
            "Epoch: 34, Step: 39/164, Loss: 0.355277, Accuracy: 87.70%\n",
            "Epoch: 34, Step: 40/164, Loss: 0.357085, Accuracy: 87.56%\n",
            "Epoch: 34, Step: 41/164, Loss: 0.356140, Accuracy: 87.58%\n",
            "Epoch: 34, Step: 42/164, Loss: 0.356800, Accuracy: 87.61%\n",
            "Epoch: 34, Step: 43/164, Loss: 0.356605, Accuracy: 87.65%\n",
            "Epoch: 34, Step: 44/164, Loss: 0.359015, Accuracy: 87.52%\n",
            "Epoch: 34, Step: 45/164, Loss: 0.358685, Accuracy: 87.50%\n",
            "Epoch: 34, Step: 46/164, Loss: 0.357796, Accuracy: 87.57%\n",
            "Epoch: 34, Step: 47/164, Loss: 0.360099, Accuracy: 87.55%\n",
            "Epoch: 34, Step: 48/164, Loss: 0.360484, Accuracy: 87.53%\n",
            "Epoch: 34, Step: 49/164, Loss: 0.363028, Accuracy: 87.48%\n",
            "Epoch: 34, Step: 50/164, Loss: 0.364349, Accuracy: 87.41%\n",
            "Epoch: 34, Step: 51/164, Loss: 0.364742, Accuracy: 87.39%\n",
            "Epoch: 34, Step: 52/164, Loss: 0.363433, Accuracy: 87.42%\n",
            "Epoch: 34, Step: 53/164, Loss: 0.361768, Accuracy: 87.44%\n",
            "Epoch: 34, Step: 54/164, Loss: 0.360518, Accuracy: 87.47%\n",
            "Epoch: 34, Step: 55/164, Loss: 0.360900, Accuracy: 87.39%\n",
            "Epoch: 34, Step: 56/164, Loss: 0.359147, Accuracy: 87.44%\n",
            "Epoch: 34, Step: 57/164, Loss: 0.359511, Accuracy: 87.43%\n",
            "Epoch: 34, Step: 58/164, Loss: 0.359539, Accuracy: 87.46%\n",
            "Epoch: 34, Step: 59/164, Loss: 0.357866, Accuracy: 87.53%\n",
            "Epoch: 34, Step: 60/164, Loss: 0.358773, Accuracy: 87.47%\n",
            "Epoch: 34, Step: 61/164, Loss: 0.358840, Accuracy: 87.49%\n",
            "Epoch: 34, Step: 62/164, Loss: 0.357771, Accuracy: 87.49%\n",
            "Epoch: 34, Step: 63/164, Loss: 0.355612, Accuracy: 87.56%\n",
            "Epoch: 34, Step: 64/164, Loss: 0.357185, Accuracy: 87.50%\n",
            "Epoch: 34, Step: 65/164, Loss: 0.356045, Accuracy: 87.54%\n",
            "Epoch: 34, Step: 66/164, Loss: 0.355336, Accuracy: 87.54%\n",
            "Epoch: 34, Step: 67/164, Loss: 0.355983, Accuracy: 87.59%\n",
            "Epoch: 34, Step: 68/164, Loss: 0.355098, Accuracy: 87.65%\n",
            "Epoch: 34, Step: 69/164, Loss: 0.356347, Accuracy: 87.62%\n",
            "Epoch: 34, Step: 70/164, Loss: 0.356729, Accuracy: 87.62%\n",
            "Epoch: 34, Step: 71/164, Loss: 0.356550, Accuracy: 87.62%\n",
            "Epoch: 34, Step: 72/164, Loss: 0.356558, Accuracy: 87.57%\n",
            "Epoch: 34, Step: 73/164, Loss: 0.358388, Accuracy: 87.52%\n",
            "Epoch: 34, Step: 74/164, Loss: 0.357571, Accuracy: 87.55%\n",
            "Epoch: 34, Step: 75/164, Loss: 0.356916, Accuracy: 87.59%\n",
            "Epoch: 34, Step: 76/164, Loss: 0.357614, Accuracy: 87.56%\n",
            "Epoch: 34, Step: 77/164, Loss: 0.356029, Accuracy: 87.62%\n",
            "Epoch: 34, Step: 78/164, Loss: 0.354770, Accuracy: 87.68%\n",
            "Epoch: 34, Step: 79/164, Loss: 0.355184, Accuracy: 87.71%\n",
            "Epoch: 34, Step: 80/164, Loss: 0.354335, Accuracy: 87.75%\n",
            "Epoch: 34, Step: 81/164, Loss: 0.356333, Accuracy: 87.67%\n",
            "Epoch: 34, Step: 82/164, Loss: 0.356783, Accuracy: 87.66%\n",
            "Epoch: 34, Step: 83/164, Loss: 0.356908, Accuracy: 87.66%\n",
            "Epoch: 34, Step: 84/164, Loss: 0.357224, Accuracy: 87.63%\n",
            "Epoch: 34, Step: 85/164, Loss: 0.357105, Accuracy: 87.66%\n",
            "Epoch: 34, Step: 86/164, Loss: 0.355653, Accuracy: 87.70%\n",
            "Epoch: 34, Step: 87/164, Loss: 0.355895, Accuracy: 87.71%\n",
            "Epoch: 34, Step: 88/164, Loss: 0.357024, Accuracy: 87.69%\n",
            "Epoch: 34, Step: 89/164, Loss: 0.357612, Accuracy: 87.65%\n",
            "Epoch: 34, Step: 90/164, Loss: 0.357407, Accuracy: 87.67%\n",
            "Epoch: 34, Step: 91/164, Loss: 0.358449, Accuracy: 87.66%\n",
            "Epoch: 34, Step: 92/164, Loss: 0.359143, Accuracy: 87.64%\n",
            "Epoch: 34, Step: 93/164, Loss: 0.359353, Accuracy: 87.65%\n",
            "Epoch: 34, Step: 94/164, Loss: 0.359832, Accuracy: 87.65%\n",
            "Epoch: 34, Step: 95/164, Loss: 0.359309, Accuracy: 87.68%\n",
            "Epoch: 34, Step: 96/164, Loss: 0.360622, Accuracy: 87.62%\n",
            "Epoch: 34, Step: 97/164, Loss: 0.360458, Accuracy: 87.64%\n",
            "Epoch: 34, Step: 98/164, Loss: 0.359962, Accuracy: 87.68%\n",
            "Epoch: 34, Step: 99/164, Loss: 0.359921, Accuracy: 87.71%\n",
            "Epoch: 34, Step: 100/164, Loss: 0.358796, Accuracy: 87.74%\n",
            "Epoch: 34, Step: 101/164, Loss: 0.358795, Accuracy: 87.75%\n",
            "Epoch: 34, Step: 102/164, Loss: 0.358661, Accuracy: 87.76%\n",
            "Epoch: 34, Step: 103/164, Loss: 0.359076, Accuracy: 87.75%\n",
            "Epoch: 34, Step: 104/164, Loss: 0.359359, Accuracy: 87.73%\n",
            "Epoch: 34, Step: 105/164, Loss: 0.358980, Accuracy: 87.76%\n",
            "Epoch: 34, Step: 106/164, Loss: 0.358687, Accuracy: 87.78%\n",
            "Epoch: 34, Step: 107/164, Loss: 0.357987, Accuracy: 87.81%\n",
            "Epoch: 34, Step: 108/164, Loss: 0.358003, Accuracy: 87.80%\n",
            "Epoch: 34, Step: 109/164, Loss: 0.358375, Accuracy: 87.77%\n",
            "Epoch: 34, Step: 110/164, Loss: 0.357346, Accuracy: 87.81%\n",
            "Epoch: 34, Step: 111/164, Loss: 0.356583, Accuracy: 87.84%\n",
            "Epoch: 34, Step: 112/164, Loss: 0.356972, Accuracy: 87.81%\n",
            "Epoch: 34, Step: 113/164, Loss: 0.356069, Accuracy: 87.87%\n",
            "Epoch: 34, Step: 114/164, Loss: 0.355345, Accuracy: 87.88%\n",
            "Epoch: 34, Step: 115/164, Loss: 0.354935, Accuracy: 87.89%\n",
            "Epoch: 34, Step: 116/164, Loss: 0.354123, Accuracy: 87.92%\n",
            "Epoch: 34, Step: 117/164, Loss: 0.352929, Accuracy: 87.95%\n",
            "Epoch: 34, Step: 118/164, Loss: 0.352813, Accuracy: 87.94%\n",
            "Epoch: 34, Step: 119/164, Loss: 0.352305, Accuracy: 87.97%\n",
            "Epoch: 34, Step: 120/164, Loss: 0.352493, Accuracy: 87.98%\n",
            "Epoch: 34, Step: 121/164, Loss: 0.353559, Accuracy: 87.96%\n",
            "Epoch: 34, Step: 122/164, Loss: 0.353270, Accuracy: 87.97%\n",
            "Epoch: 34, Step: 123/164, Loss: 0.353441, Accuracy: 87.95%\n",
            "Epoch: 34, Step: 124/164, Loss: 0.353312, Accuracy: 87.95%\n",
            "Epoch: 34, Step: 125/164, Loss: 0.353416, Accuracy: 87.96%\n",
            "Epoch: 34, Step: 126/164, Loss: 0.354881, Accuracy: 87.92%\n",
            "Epoch: 34, Step: 127/164, Loss: 0.354070, Accuracy: 87.94%\n",
            "Epoch: 34, Step: 128/164, Loss: 0.353591, Accuracy: 87.96%\n",
            "Epoch: 34, Step: 129/164, Loss: 0.354208, Accuracy: 87.92%\n",
            "Epoch: 34, Step: 130/164, Loss: 0.353796, Accuracy: 87.94%\n",
            "Epoch: 34, Step: 131/164, Loss: 0.353878, Accuracy: 87.94%\n",
            "Epoch: 34, Step: 132/164, Loss: 0.353668, Accuracy: 87.95%\n",
            "Epoch: 34, Step: 133/164, Loss: 0.353652, Accuracy: 87.93%\n",
            "Epoch: 34, Step: 134/164, Loss: 0.353658, Accuracy: 87.95%\n",
            "Epoch: 34, Step: 135/164, Loss: 0.353458, Accuracy: 87.95%\n",
            "Epoch: 34, Step: 136/164, Loss: 0.354098, Accuracy: 87.93%\n",
            "Epoch: 34, Step: 137/164, Loss: 0.353955, Accuracy: 87.94%\n",
            "Epoch: 34, Step: 138/164, Loss: 0.353181, Accuracy: 87.97%\n",
            "Epoch: 34, Step: 139/164, Loss: 0.353277, Accuracy: 87.96%\n",
            "Epoch: 34, Step: 140/164, Loss: 0.354370, Accuracy: 87.91%\n",
            "Epoch: 34, Step: 141/164, Loss: 0.355365, Accuracy: 87.90%\n",
            "Epoch: 34, Step: 142/164, Loss: 0.356504, Accuracy: 87.88%\n",
            "Epoch: 34, Step: 143/164, Loss: 0.355881, Accuracy: 87.89%\n",
            "Epoch: 34, Step: 144/164, Loss: 0.355160, Accuracy: 87.92%\n",
            "Epoch: 34, Step: 145/164, Loss: 0.355727, Accuracy: 87.89%\n",
            "Epoch: 34, Step: 146/164, Loss: 0.355586, Accuracy: 87.90%\n",
            "Epoch: 34, Step: 147/164, Loss: 0.355413, Accuracy: 87.91%\n",
            "Epoch: 34, Step: 148/164, Loss: 0.355408, Accuracy: 87.90%\n",
            "Epoch: 34, Step: 149/164, Loss: 0.355307, Accuracy: 87.90%\n",
            "Epoch: 34, Step: 150/164, Loss: 0.354758, Accuracy: 87.93%\n",
            "Epoch: 34, Step: 151/164, Loss: 0.353801, Accuracy: 87.98%\n",
            "Epoch: 34, Step: 152/164, Loss: 0.353562, Accuracy: 87.98%\n",
            "Epoch: 34, Step: 153/164, Loss: 0.353415, Accuracy: 87.97%\n",
            "Epoch: 34, Step: 154/164, Loss: 0.353364, Accuracy: 87.97%\n",
            "Epoch: 34, Step: 155/164, Loss: 0.352568, Accuracy: 88.02%\n",
            "Epoch: 34, Step: 156/164, Loss: 0.352410, Accuracy: 88.05%\n",
            "Epoch: 34, Step: 157/164, Loss: 0.352174, Accuracy: 88.05%\n",
            "Epoch: 34, Step: 158/164, Loss: 0.352281, Accuracy: 88.04%\n",
            "Epoch: 34, Step: 159/164, Loss: 0.351670, Accuracy: 88.07%\n",
            "Epoch: 34, Step: 160/164, Loss: 0.351128, Accuracy: 88.07%\n",
            "Epoch: 34, Step: 161/164, Loss: 0.351191, Accuracy: 88.07%\n",
            "Epoch: 34, Step: 162/164, Loss: 0.350684, Accuracy: 88.10%\n",
            "Epoch: 34, Step: 163/164, Loss: 0.350787, Accuracy: 88.07%\n",
            "Epoch: 34, Step: 164/164, Loss: 0.350584, Accuracy: 88.07%\n",
            "Epoch: 35, Step: 1/164, Loss: 0.296749, Accuracy: 88.28%\n",
            "Epoch: 35, Step: 2/164, Loss: 0.314147, Accuracy: 89.84%\n",
            "Epoch: 35, Step: 3/164, Loss: 0.316998, Accuracy: 88.54%\n",
            "Epoch: 35, Step: 4/164, Loss: 0.294797, Accuracy: 89.45%\n",
            "Epoch: 35, Step: 5/164, Loss: 0.303384, Accuracy: 89.22%\n",
            "Epoch: 35, Step: 6/164, Loss: 0.332356, Accuracy: 88.67%\n",
            "Epoch: 35, Step: 7/164, Loss: 0.345641, Accuracy: 88.50%\n",
            "Epoch: 35, Step: 8/164, Loss: 0.337962, Accuracy: 88.38%\n",
            "Epoch: 35, Step: 9/164, Loss: 0.331625, Accuracy: 88.54%\n",
            "Epoch: 35, Step: 10/164, Loss: 0.331880, Accuracy: 88.75%\n",
            "Epoch: 35, Step: 11/164, Loss: 0.345104, Accuracy: 88.21%\n",
            "Epoch: 35, Step: 12/164, Loss: 0.349377, Accuracy: 88.09%\n",
            "Epoch: 35, Step: 13/164, Loss: 0.354031, Accuracy: 87.98%\n",
            "Epoch: 35, Step: 14/164, Loss: 0.360139, Accuracy: 87.72%\n",
            "Epoch: 35, Step: 15/164, Loss: 0.355884, Accuracy: 87.92%\n",
            "Epoch: 35, Step: 16/164, Loss: 0.352657, Accuracy: 88.04%\n",
            "Epoch: 35, Step: 17/164, Loss: 0.352637, Accuracy: 88.01%\n",
            "Epoch: 35, Step: 18/164, Loss: 0.354452, Accuracy: 88.06%\n",
            "Epoch: 35, Step: 19/164, Loss: 0.348653, Accuracy: 88.28%\n",
            "Epoch: 35, Step: 20/164, Loss: 0.347253, Accuracy: 88.40%\n",
            "Epoch: 35, Step: 21/164, Loss: 0.352340, Accuracy: 88.32%\n",
            "Epoch: 35, Step: 22/164, Loss: 0.356549, Accuracy: 88.21%\n",
            "Epoch: 35, Step: 23/164, Loss: 0.355490, Accuracy: 88.25%\n",
            "Epoch: 35, Step: 24/164, Loss: 0.351218, Accuracy: 88.44%\n",
            "Epoch: 35, Step: 25/164, Loss: 0.357170, Accuracy: 88.28%\n",
            "Epoch: 35, Step: 26/164, Loss: 0.356950, Accuracy: 88.19%\n",
            "Epoch: 35, Step: 27/164, Loss: 0.354596, Accuracy: 88.25%\n",
            "Epoch: 35, Step: 28/164, Loss: 0.356635, Accuracy: 88.11%\n",
            "Epoch: 35, Step: 29/164, Loss: 0.357508, Accuracy: 88.09%\n",
            "Epoch: 35, Step: 30/164, Loss: 0.355299, Accuracy: 88.18%\n",
            "Epoch: 35, Step: 31/164, Loss: 0.359618, Accuracy: 88.05%\n",
            "Epoch: 35, Step: 32/164, Loss: 0.358870, Accuracy: 87.99%\n",
            "Epoch: 35, Step: 33/164, Loss: 0.360611, Accuracy: 87.88%\n",
            "Epoch: 35, Step: 34/164, Loss: 0.359235, Accuracy: 87.96%\n",
            "Epoch: 35, Step: 35/164, Loss: 0.361061, Accuracy: 87.90%\n",
            "Epoch: 35, Step: 36/164, Loss: 0.362279, Accuracy: 87.83%\n",
            "Epoch: 35, Step: 37/164, Loss: 0.361952, Accuracy: 87.80%\n",
            "Epoch: 35, Step: 38/164, Loss: 0.360126, Accuracy: 87.93%\n",
            "Epoch: 35, Step: 39/164, Loss: 0.360141, Accuracy: 87.90%\n",
            "Epoch: 35, Step: 40/164, Loss: 0.361283, Accuracy: 87.91%\n",
            "Epoch: 35, Step: 41/164, Loss: 0.362473, Accuracy: 87.92%\n",
            "Epoch: 35, Step: 42/164, Loss: 0.360724, Accuracy: 87.98%\n",
            "Epoch: 35, Step: 43/164, Loss: 0.361472, Accuracy: 87.99%\n",
            "Epoch: 35, Step: 44/164, Loss: 0.362376, Accuracy: 87.98%\n",
            "Epoch: 35, Step: 45/164, Loss: 0.360381, Accuracy: 88.00%\n",
            "Epoch: 35, Step: 46/164, Loss: 0.360424, Accuracy: 88.06%\n",
            "Epoch: 35, Step: 47/164, Loss: 0.359108, Accuracy: 88.13%\n",
            "Epoch: 35, Step: 48/164, Loss: 0.362282, Accuracy: 88.05%\n",
            "Epoch: 35, Step: 49/164, Loss: 0.361254, Accuracy: 88.09%\n",
            "Epoch: 35, Step: 50/164, Loss: 0.360637, Accuracy: 88.09%\n",
            "Epoch: 35, Step: 51/164, Loss: 0.359744, Accuracy: 88.10%\n",
            "Epoch: 35, Step: 52/164, Loss: 0.358615, Accuracy: 88.13%\n",
            "Epoch: 35, Step: 53/164, Loss: 0.355910, Accuracy: 88.22%\n",
            "Epoch: 35, Step: 54/164, Loss: 0.352902, Accuracy: 88.35%\n",
            "Epoch: 35, Step: 55/164, Loss: 0.351731, Accuracy: 88.35%\n",
            "Epoch: 35, Step: 56/164, Loss: 0.351284, Accuracy: 88.36%\n",
            "Epoch: 35, Step: 57/164, Loss: 0.351954, Accuracy: 88.31%\n",
            "Epoch: 35, Step: 58/164, Loss: 0.351773, Accuracy: 88.32%\n",
            "Epoch: 35, Step: 59/164, Loss: 0.351575, Accuracy: 88.27%\n",
            "Epoch: 35, Step: 60/164, Loss: 0.349742, Accuracy: 88.33%\n",
            "Epoch: 35, Step: 61/164, Loss: 0.348846, Accuracy: 88.35%\n",
            "Epoch: 35, Step: 62/164, Loss: 0.348196, Accuracy: 88.41%\n",
            "Epoch: 35, Step: 63/164, Loss: 0.348305, Accuracy: 88.44%\n",
            "Epoch: 35, Step: 64/164, Loss: 0.348862, Accuracy: 88.42%\n",
            "Epoch: 35, Step: 65/164, Loss: 0.349253, Accuracy: 88.41%\n",
            "Epoch: 35, Step: 66/164, Loss: 0.350435, Accuracy: 88.34%\n",
            "Epoch: 35, Step: 67/164, Loss: 0.352063, Accuracy: 88.26%\n",
            "Epoch: 35, Step: 68/164, Loss: 0.352545, Accuracy: 88.27%\n",
            "Epoch: 35, Step: 69/164, Loss: 0.352014, Accuracy: 88.26%\n",
            "Epoch: 35, Step: 70/164, Loss: 0.353692, Accuracy: 88.17%\n",
            "Epoch: 35, Step: 71/164, Loss: 0.353646, Accuracy: 88.15%\n",
            "Epoch: 35, Step: 72/164, Loss: 0.353244, Accuracy: 88.15%\n",
            "Epoch: 35, Step: 73/164, Loss: 0.351996, Accuracy: 88.23%\n",
            "Epoch: 35, Step: 74/164, Loss: 0.353285, Accuracy: 88.20%\n",
            "Epoch: 35, Step: 75/164, Loss: 0.353474, Accuracy: 88.19%\n",
            "Epoch: 35, Step: 76/164, Loss: 0.353550, Accuracy: 88.17%\n",
            "Epoch: 35, Step: 77/164, Loss: 0.354267, Accuracy: 88.14%\n",
            "Epoch: 35, Step: 78/164, Loss: 0.353700, Accuracy: 88.17%\n",
            "Epoch: 35, Step: 79/164, Loss: 0.354000, Accuracy: 88.17%\n",
            "Epoch: 35, Step: 80/164, Loss: 0.355225, Accuracy: 88.14%\n",
            "Epoch: 35, Step: 81/164, Loss: 0.354504, Accuracy: 88.18%\n",
            "Epoch: 35, Step: 82/164, Loss: 0.354812, Accuracy: 88.14%\n",
            "Epoch: 35, Step: 83/164, Loss: 0.355257, Accuracy: 88.12%\n",
            "Epoch: 35, Step: 84/164, Loss: 0.356151, Accuracy: 88.06%\n",
            "Epoch: 35, Step: 85/164, Loss: 0.355132, Accuracy: 88.08%\n",
            "Epoch: 35, Step: 86/164, Loss: 0.353964, Accuracy: 88.11%\n",
            "Epoch: 35, Step: 87/164, Loss: 0.354621, Accuracy: 88.13%\n",
            "Epoch: 35, Step: 88/164, Loss: 0.354051, Accuracy: 88.17%\n",
            "Epoch: 35, Step: 89/164, Loss: 0.354522, Accuracy: 88.12%\n",
            "Epoch: 35, Step: 90/164, Loss: 0.354194, Accuracy: 88.10%\n",
            "Epoch: 35, Step: 91/164, Loss: 0.354500, Accuracy: 88.11%\n",
            "Epoch: 35, Step: 92/164, Loss: 0.353252, Accuracy: 88.14%\n",
            "Epoch: 35, Step: 93/164, Loss: 0.353641, Accuracy: 88.12%\n",
            "Epoch: 35, Step: 94/164, Loss: 0.353932, Accuracy: 88.11%\n",
            "Epoch: 35, Step: 95/164, Loss: 0.352978, Accuracy: 88.12%\n",
            "Epoch: 35, Step: 96/164, Loss: 0.352925, Accuracy: 88.13%\n",
            "Epoch: 35, Step: 97/164, Loss: 0.352556, Accuracy: 88.14%\n",
            "Epoch: 35, Step: 98/164, Loss: 0.353910, Accuracy: 88.08%\n",
            "Epoch: 35, Step: 99/164, Loss: 0.353292, Accuracy: 88.06%\n",
            "Epoch: 35, Step: 100/164, Loss: 0.353621, Accuracy: 88.05%\n",
            "Epoch: 35, Step: 101/164, Loss: 0.354521, Accuracy: 87.99%\n",
            "Epoch: 35, Step: 102/164, Loss: 0.353243, Accuracy: 88.01%\n",
            "Epoch: 35, Step: 103/164, Loss: 0.354343, Accuracy: 87.97%\n",
            "Epoch: 35, Step: 104/164, Loss: 0.354731, Accuracy: 87.93%\n",
            "Epoch: 35, Step: 105/164, Loss: 0.355052, Accuracy: 87.93%\n",
            "Epoch: 35, Step: 106/164, Loss: 0.357005, Accuracy: 87.86%\n",
            "Epoch: 35, Step: 107/164, Loss: 0.356819, Accuracy: 87.87%\n",
            "Epoch: 35, Step: 108/164, Loss: 0.357667, Accuracy: 87.83%\n",
            "Epoch: 35, Step: 109/164, Loss: 0.357637, Accuracy: 87.86%\n",
            "Epoch: 35, Step: 110/164, Loss: 0.356620, Accuracy: 87.89%\n",
            "Epoch: 35, Step: 111/164, Loss: 0.357142, Accuracy: 87.89%\n",
            "Epoch: 35, Step: 112/164, Loss: 0.356491, Accuracy: 87.92%\n",
            "Epoch: 35, Step: 113/164, Loss: 0.356352, Accuracy: 87.93%\n",
            "Epoch: 35, Step: 114/164, Loss: 0.356178, Accuracy: 87.92%\n",
            "Epoch: 35, Step: 115/164, Loss: 0.355143, Accuracy: 87.97%\n",
            "Epoch: 35, Step: 116/164, Loss: 0.354580, Accuracy: 87.98%\n",
            "Epoch: 35, Step: 117/164, Loss: 0.355149, Accuracy: 87.97%\n",
            "Epoch: 35, Step: 118/164, Loss: 0.355054, Accuracy: 87.96%\n",
            "Epoch: 35, Step: 119/164, Loss: 0.354484, Accuracy: 87.97%\n",
            "Epoch: 35, Step: 120/164, Loss: 0.355033, Accuracy: 87.98%\n",
            "Epoch: 35, Step: 121/164, Loss: 0.355323, Accuracy: 87.96%\n",
            "Epoch: 35, Step: 122/164, Loss: 0.354815, Accuracy: 87.99%\n",
            "Epoch: 35, Step: 123/164, Loss: 0.355297, Accuracy: 88.00%\n",
            "Epoch: 35, Step: 124/164, Loss: 0.355423, Accuracy: 88.00%\n",
            "Epoch: 35, Step: 125/164, Loss: 0.355292, Accuracy: 87.97%\n",
            "Epoch: 35, Step: 126/164, Loss: 0.355675, Accuracy: 87.95%\n",
            "Epoch: 35, Step: 127/164, Loss: 0.355742, Accuracy: 87.97%\n",
            "Epoch: 35, Step: 128/164, Loss: 0.354601, Accuracy: 88.02%\n",
            "Epoch: 35, Step: 129/164, Loss: 0.354621, Accuracy: 88.01%\n",
            "Epoch: 35, Step: 130/164, Loss: 0.354161, Accuracy: 88.02%\n",
            "Epoch: 35, Step: 131/164, Loss: 0.354453, Accuracy: 88.02%\n",
            "Epoch: 35, Step: 132/164, Loss: 0.354761, Accuracy: 87.99%\n",
            "Epoch: 35, Step: 133/164, Loss: 0.354625, Accuracy: 88.00%\n",
            "Epoch: 35, Step: 134/164, Loss: 0.354265, Accuracy: 88.00%\n",
            "Epoch: 35, Step: 135/164, Loss: 0.353528, Accuracy: 88.02%\n",
            "Epoch: 35, Step: 136/164, Loss: 0.354523, Accuracy: 88.00%\n",
            "Epoch: 35, Step: 137/164, Loss: 0.354165, Accuracy: 88.01%\n",
            "Epoch: 35, Step: 138/164, Loss: 0.354117, Accuracy: 87.99%\n",
            "Epoch: 35, Step: 139/164, Loss: 0.353661, Accuracy: 88.02%\n",
            "Epoch: 35, Step: 140/164, Loss: 0.353795, Accuracy: 88.02%\n",
            "Epoch: 35, Step: 141/164, Loss: 0.353198, Accuracy: 88.03%\n",
            "Epoch: 35, Step: 142/164, Loss: 0.352840, Accuracy: 88.05%\n",
            "Epoch: 35, Step: 143/164, Loss: 0.352060, Accuracy: 88.08%\n",
            "Epoch: 35, Step: 144/164, Loss: 0.351906, Accuracy: 88.09%\n",
            "Epoch: 35, Step: 145/164, Loss: 0.352738, Accuracy: 88.07%\n",
            "Epoch: 35, Step: 146/164, Loss: 0.352801, Accuracy: 88.07%\n",
            "Epoch: 35, Step: 147/164, Loss: 0.352099, Accuracy: 88.11%\n",
            "Epoch: 35, Step: 148/164, Loss: 0.351558, Accuracy: 88.12%\n",
            "Epoch: 35, Step: 149/164, Loss: 0.351080, Accuracy: 88.16%\n",
            "Epoch: 35, Step: 150/164, Loss: 0.350949, Accuracy: 88.17%\n",
            "Epoch: 35, Step: 151/164, Loss: 0.350438, Accuracy: 88.19%\n",
            "Epoch: 35, Step: 152/164, Loss: 0.349516, Accuracy: 88.22%\n",
            "Epoch: 35, Step: 153/164, Loss: 0.349845, Accuracy: 88.21%\n",
            "Epoch: 35, Step: 154/164, Loss: 0.349784, Accuracy: 88.23%\n",
            "Epoch: 35, Step: 155/164, Loss: 0.349456, Accuracy: 88.24%\n",
            "Epoch: 35, Step: 156/164, Loss: 0.349707, Accuracy: 88.23%\n",
            "Epoch: 35, Step: 157/164, Loss: 0.349765, Accuracy: 88.22%\n",
            "Epoch: 35, Step: 158/164, Loss: 0.349739, Accuracy: 88.21%\n",
            "Epoch: 35, Step: 159/164, Loss: 0.349762, Accuracy: 88.24%\n",
            "Epoch: 35, Step: 160/164, Loss: 0.349361, Accuracy: 88.26%\n",
            "Epoch: 35, Step: 161/164, Loss: 0.349000, Accuracy: 88.26%\n",
            "Epoch: 35, Step: 162/164, Loss: 0.349495, Accuracy: 88.23%\n",
            "Epoch: 35, Step: 163/164, Loss: 0.349915, Accuracy: 88.21%\n",
            "Epoch: 35, Step: 164/164, Loss: 0.350082, Accuracy: 88.21%\n",
            "Epoch: 36, Step: 1/164, Loss: 0.354529, Accuracy: 89.06%\n",
            "Epoch: 36, Step: 2/164, Loss: 0.355786, Accuracy: 89.06%\n",
            "Epoch: 36, Step: 3/164, Loss: 0.386527, Accuracy: 87.50%\n",
            "Epoch: 36, Step: 4/164, Loss: 0.370907, Accuracy: 88.09%\n",
            "Epoch: 36, Step: 5/164, Loss: 0.344346, Accuracy: 89.06%\n",
            "Epoch: 36, Step: 6/164, Loss: 0.330564, Accuracy: 89.32%\n",
            "Epoch: 36, Step: 7/164, Loss: 0.337420, Accuracy: 88.95%\n",
            "Epoch: 36, Step: 8/164, Loss: 0.331251, Accuracy: 89.26%\n",
            "Epoch: 36, Step: 9/164, Loss: 0.331022, Accuracy: 89.15%\n",
            "Epoch: 36, Step: 10/164, Loss: 0.351759, Accuracy: 88.83%\n",
            "Epoch: 36, Step: 11/164, Loss: 0.349203, Accuracy: 88.99%\n",
            "Epoch: 36, Step: 12/164, Loss: 0.341876, Accuracy: 89.19%\n",
            "Epoch: 36, Step: 13/164, Loss: 0.352598, Accuracy: 88.76%\n",
            "Epoch: 36, Step: 14/164, Loss: 0.344721, Accuracy: 88.95%\n",
            "Epoch: 36, Step: 15/164, Loss: 0.342472, Accuracy: 88.91%\n",
            "Epoch: 36, Step: 16/164, Loss: 0.335167, Accuracy: 88.92%\n",
            "Epoch: 36, Step: 17/164, Loss: 0.330944, Accuracy: 89.02%\n",
            "Epoch: 36, Step: 18/164, Loss: 0.328473, Accuracy: 89.02%\n",
            "Epoch: 36, Step: 19/164, Loss: 0.332318, Accuracy: 88.61%\n",
            "Epoch: 36, Step: 20/164, Loss: 0.330098, Accuracy: 88.63%\n",
            "Epoch: 36, Step: 21/164, Loss: 0.328106, Accuracy: 88.69%\n",
            "Epoch: 36, Step: 22/164, Loss: 0.326067, Accuracy: 88.67%\n",
            "Epoch: 36, Step: 23/164, Loss: 0.332810, Accuracy: 88.35%\n",
            "Epoch: 36, Step: 24/164, Loss: 0.335761, Accuracy: 88.25%\n",
            "Epoch: 36, Step: 25/164, Loss: 0.336535, Accuracy: 88.22%\n",
            "Epoch: 36, Step: 26/164, Loss: 0.334714, Accuracy: 88.34%\n",
            "Epoch: 36, Step: 27/164, Loss: 0.332335, Accuracy: 88.43%\n",
            "Epoch: 36, Step: 28/164, Loss: 0.331380, Accuracy: 88.53%\n",
            "Epoch: 36, Step: 29/164, Loss: 0.337262, Accuracy: 88.25%\n",
            "Epoch: 36, Step: 30/164, Loss: 0.333432, Accuracy: 88.39%\n",
            "Epoch: 36, Step: 31/164, Loss: 0.337770, Accuracy: 88.31%\n",
            "Epoch: 36, Step: 32/164, Loss: 0.340214, Accuracy: 88.26%\n",
            "Epoch: 36, Step: 33/164, Loss: 0.339260, Accuracy: 88.35%\n",
            "Epoch: 36, Step: 34/164, Loss: 0.338995, Accuracy: 88.42%\n",
            "Epoch: 36, Step: 35/164, Loss: 0.340309, Accuracy: 88.39%\n",
            "Epoch: 36, Step: 36/164, Loss: 0.339578, Accuracy: 88.41%\n",
            "Epoch: 36, Step: 37/164, Loss: 0.339947, Accuracy: 88.34%\n",
            "Epoch: 36, Step: 38/164, Loss: 0.341383, Accuracy: 88.28%\n",
            "Epoch: 36, Step: 39/164, Loss: 0.342384, Accuracy: 88.24%\n",
            "Epoch: 36, Step: 40/164, Loss: 0.342600, Accuracy: 88.18%\n",
            "Epoch: 36, Step: 41/164, Loss: 0.343586, Accuracy: 88.09%\n",
            "Epoch: 36, Step: 42/164, Loss: 0.347168, Accuracy: 88.06%\n",
            "Epoch: 36, Step: 43/164, Loss: 0.345124, Accuracy: 88.08%\n",
            "Epoch: 36, Step: 44/164, Loss: 0.347061, Accuracy: 87.98%\n",
            "Epoch: 36, Step: 45/164, Loss: 0.345672, Accuracy: 88.07%\n",
            "Epoch: 36, Step: 46/164, Loss: 0.344223, Accuracy: 88.13%\n",
            "Epoch: 36, Step: 47/164, Loss: 0.345748, Accuracy: 88.10%\n",
            "Epoch: 36, Step: 48/164, Loss: 0.343871, Accuracy: 88.18%\n",
            "Epoch: 36, Step: 49/164, Loss: 0.343132, Accuracy: 88.17%\n",
            "Epoch: 36, Step: 50/164, Loss: 0.340996, Accuracy: 88.27%\n",
            "Epoch: 36, Step: 51/164, Loss: 0.340529, Accuracy: 88.28%\n",
            "Epoch: 36, Step: 52/164, Loss: 0.340682, Accuracy: 88.33%\n",
            "Epoch: 36, Step: 53/164, Loss: 0.340611, Accuracy: 88.27%\n",
            "Epoch: 36, Step: 54/164, Loss: 0.339643, Accuracy: 88.32%\n",
            "Epoch: 36, Step: 55/164, Loss: 0.337224, Accuracy: 88.41%\n",
            "Epoch: 36, Step: 56/164, Loss: 0.339755, Accuracy: 88.34%\n",
            "Epoch: 36, Step: 57/164, Loss: 0.341674, Accuracy: 88.31%\n",
            "Epoch: 36, Step: 58/164, Loss: 0.340047, Accuracy: 88.39%\n",
            "Epoch: 36, Step: 59/164, Loss: 0.339039, Accuracy: 88.44%\n",
            "Epoch: 36, Step: 60/164, Loss: 0.340254, Accuracy: 88.40%\n",
            "Epoch: 36, Step: 61/164, Loss: 0.340959, Accuracy: 88.32%\n",
            "Epoch: 36, Step: 62/164, Loss: 0.341563, Accuracy: 88.31%\n",
            "Epoch: 36, Step: 63/164, Loss: 0.341399, Accuracy: 88.32%\n",
            "Epoch: 36, Step: 64/164, Loss: 0.338687, Accuracy: 88.43%\n",
            "Epoch: 36, Step: 65/164, Loss: 0.339422, Accuracy: 88.41%\n",
            "Epoch: 36, Step: 66/164, Loss: 0.344265, Accuracy: 88.29%\n",
            "Epoch: 36, Step: 67/164, Loss: 0.344160, Accuracy: 88.32%\n",
            "Epoch: 36, Step: 68/164, Loss: 0.345376, Accuracy: 88.30%\n",
            "Epoch: 36, Step: 69/164, Loss: 0.343665, Accuracy: 88.34%\n",
            "Epoch: 36, Step: 70/164, Loss: 0.344877, Accuracy: 88.29%\n",
            "Epoch: 36, Step: 71/164, Loss: 0.343992, Accuracy: 88.34%\n",
            "Epoch: 36, Step: 72/164, Loss: 0.344910, Accuracy: 88.29%\n",
            "Epoch: 36, Step: 73/164, Loss: 0.345859, Accuracy: 88.29%\n",
            "Epoch: 36, Step: 74/164, Loss: 0.343708, Accuracy: 88.38%\n",
            "Epoch: 36, Step: 75/164, Loss: 0.344340, Accuracy: 88.38%\n",
            "Epoch: 36, Step: 76/164, Loss: 0.343391, Accuracy: 88.39%\n",
            "Epoch: 36, Step: 77/164, Loss: 0.342537, Accuracy: 88.44%\n",
            "Epoch: 36, Step: 78/164, Loss: 0.343376, Accuracy: 88.40%\n",
            "Epoch: 36, Step: 79/164, Loss: 0.343094, Accuracy: 88.40%\n",
            "Epoch: 36, Step: 80/164, Loss: 0.341448, Accuracy: 88.45%\n",
            "Epoch: 36, Step: 81/164, Loss: 0.341119, Accuracy: 88.47%\n",
            "Epoch: 36, Step: 82/164, Loss: 0.341432, Accuracy: 88.47%\n",
            "Epoch: 36, Step: 83/164, Loss: 0.341076, Accuracy: 88.47%\n",
            "Epoch: 36, Step: 84/164, Loss: 0.341381, Accuracy: 88.49%\n",
            "Epoch: 36, Step: 85/164, Loss: 0.341131, Accuracy: 88.55%\n",
            "Epoch: 36, Step: 86/164, Loss: 0.340824, Accuracy: 88.55%\n",
            "Epoch: 36, Step: 87/164, Loss: 0.340906, Accuracy: 88.56%\n",
            "Epoch: 36, Step: 88/164, Loss: 0.339305, Accuracy: 88.61%\n",
            "Epoch: 36, Step: 89/164, Loss: 0.338862, Accuracy: 88.63%\n",
            "Epoch: 36, Step: 90/164, Loss: 0.339076, Accuracy: 88.63%\n",
            "Epoch: 36, Step: 91/164, Loss: 0.339455, Accuracy: 88.61%\n",
            "Epoch: 36, Step: 92/164, Loss: 0.340561, Accuracy: 88.54%\n",
            "Epoch: 36, Step: 93/164, Loss: 0.339627, Accuracy: 88.58%\n",
            "Epoch: 36, Step: 94/164, Loss: 0.341973, Accuracy: 88.49%\n",
            "Epoch: 36, Step: 95/164, Loss: 0.341673, Accuracy: 88.49%\n",
            "Epoch: 36, Step: 96/164, Loss: 0.340662, Accuracy: 88.53%\n",
            "Epoch: 36, Step: 97/164, Loss: 0.342349, Accuracy: 88.50%\n",
            "Epoch: 36, Step: 98/164, Loss: 0.342403, Accuracy: 88.52%\n",
            "Epoch: 36, Step: 99/164, Loss: 0.342395, Accuracy: 88.53%\n",
            "Epoch: 36, Step: 100/164, Loss: 0.342096, Accuracy: 88.52%\n",
            "Epoch: 36, Step: 101/164, Loss: 0.342087, Accuracy: 88.52%\n",
            "Epoch: 36, Step: 102/164, Loss: 0.342631, Accuracy: 88.52%\n",
            "Epoch: 36, Step: 103/164, Loss: 0.342641, Accuracy: 88.52%\n",
            "Epoch: 36, Step: 104/164, Loss: 0.341777, Accuracy: 88.55%\n",
            "Epoch: 36, Step: 105/164, Loss: 0.340941, Accuracy: 88.59%\n",
            "Epoch: 36, Step: 106/164, Loss: 0.340641, Accuracy: 88.61%\n",
            "Epoch: 36, Step: 107/164, Loss: 0.340615, Accuracy: 88.62%\n",
            "Epoch: 36, Step: 108/164, Loss: 0.341616, Accuracy: 88.60%\n",
            "Epoch: 36, Step: 109/164, Loss: 0.341010, Accuracy: 88.62%\n",
            "Epoch: 36, Step: 110/164, Loss: 0.341592, Accuracy: 88.59%\n",
            "Epoch: 36, Step: 111/164, Loss: 0.341065, Accuracy: 88.63%\n",
            "Epoch: 36, Step: 112/164, Loss: 0.340295, Accuracy: 88.61%\n",
            "Epoch: 36, Step: 113/164, Loss: 0.339751, Accuracy: 88.63%\n",
            "Epoch: 36, Step: 114/164, Loss: 0.339659, Accuracy: 88.62%\n",
            "Epoch: 36, Step: 115/164, Loss: 0.339474, Accuracy: 88.61%\n",
            "Epoch: 36, Step: 116/164, Loss: 0.338512, Accuracy: 88.66%\n",
            "Epoch: 36, Step: 117/164, Loss: 0.338837, Accuracy: 88.65%\n",
            "Epoch: 36, Step: 118/164, Loss: 0.338835, Accuracy: 88.64%\n",
            "Epoch: 36, Step: 119/164, Loss: 0.338532, Accuracy: 88.64%\n",
            "Epoch: 36, Step: 120/164, Loss: 0.338810, Accuracy: 88.64%\n",
            "Epoch: 36, Step: 121/164, Loss: 0.338338, Accuracy: 88.63%\n",
            "Epoch: 36, Step: 122/164, Loss: 0.339658, Accuracy: 88.60%\n",
            "Epoch: 36, Step: 123/164, Loss: 0.339568, Accuracy: 88.62%\n",
            "Epoch: 36, Step: 124/164, Loss: 0.339333, Accuracy: 88.62%\n",
            "Epoch: 36, Step: 125/164, Loss: 0.339615, Accuracy: 88.60%\n",
            "Epoch: 36, Step: 126/164, Loss: 0.339102, Accuracy: 88.60%\n",
            "Epoch: 36, Step: 127/164, Loss: 0.338695, Accuracy: 88.58%\n",
            "Epoch: 36, Step: 128/164, Loss: 0.338524, Accuracy: 88.58%\n",
            "Epoch: 36, Step: 129/164, Loss: 0.338526, Accuracy: 88.57%\n",
            "Epoch: 36, Step: 130/164, Loss: 0.338772, Accuracy: 88.56%\n",
            "Epoch: 36, Step: 131/164, Loss: 0.338568, Accuracy: 88.58%\n",
            "Epoch: 36, Step: 132/164, Loss: 0.338873, Accuracy: 88.57%\n",
            "Epoch: 36, Step: 133/164, Loss: 0.338207, Accuracy: 88.57%\n",
            "Epoch: 36, Step: 134/164, Loss: 0.337715, Accuracy: 88.58%\n",
            "Epoch: 36, Step: 135/164, Loss: 0.336909, Accuracy: 88.61%\n",
            "Epoch: 36, Step: 136/164, Loss: 0.336951, Accuracy: 88.63%\n",
            "Epoch: 36, Step: 137/164, Loss: 0.336758, Accuracy: 88.64%\n",
            "Epoch: 36, Step: 138/164, Loss: 0.336324, Accuracy: 88.64%\n",
            "Epoch: 36, Step: 139/164, Loss: 0.336983, Accuracy: 88.63%\n",
            "Epoch: 36, Step: 140/164, Loss: 0.337058, Accuracy: 88.63%\n",
            "Epoch: 36, Step: 141/164, Loss: 0.336825, Accuracy: 88.65%\n",
            "Epoch: 36, Step: 142/164, Loss: 0.337988, Accuracy: 88.62%\n",
            "Epoch: 36, Step: 143/164, Loss: 0.338185, Accuracy: 88.63%\n",
            "Epoch: 36, Step: 144/164, Loss: 0.337649, Accuracy: 88.62%\n",
            "Epoch: 36, Step: 145/164, Loss: 0.338778, Accuracy: 88.59%\n",
            "Epoch: 36, Step: 146/164, Loss: 0.338822, Accuracy: 88.55%\n",
            "Epoch: 36, Step: 147/164, Loss: 0.339400, Accuracy: 88.55%\n",
            "Epoch: 36, Step: 148/164, Loss: 0.340527, Accuracy: 88.50%\n",
            "Epoch: 36, Step: 149/164, Loss: 0.340751, Accuracy: 88.49%\n",
            "Epoch: 36, Step: 150/164, Loss: 0.340143, Accuracy: 88.49%\n",
            "Epoch: 36, Step: 151/164, Loss: 0.339881, Accuracy: 88.50%\n",
            "Epoch: 36, Step: 152/164, Loss: 0.339254, Accuracy: 88.52%\n",
            "Epoch: 36, Step: 153/164, Loss: 0.338597, Accuracy: 88.54%\n",
            "Epoch: 36, Step: 154/164, Loss: 0.337704, Accuracy: 88.57%\n",
            "Epoch: 36, Step: 155/164, Loss: 0.337657, Accuracy: 88.55%\n",
            "Epoch: 36, Step: 156/164, Loss: 0.338268, Accuracy: 88.54%\n",
            "Epoch: 36, Step: 157/164, Loss: 0.337556, Accuracy: 88.57%\n",
            "Epoch: 36, Step: 158/164, Loss: 0.338413, Accuracy: 88.54%\n",
            "Epoch: 36, Step: 159/164, Loss: 0.338527, Accuracy: 88.52%\n",
            "Epoch: 36, Step: 160/164, Loss: 0.338785, Accuracy: 88.51%\n",
            "Epoch: 36, Step: 161/164, Loss: 0.338935, Accuracy: 88.49%\n",
            "Epoch: 36, Step: 162/164, Loss: 0.339496, Accuracy: 88.48%\n",
            "Epoch: 36, Step: 163/164, Loss: 0.339658, Accuracy: 88.47%\n",
            "Epoch: 36, Step: 164/164, Loss: 0.339011, Accuracy: 88.48%\n",
            "Epoch: 37, Step: 1/164, Loss: 0.287536, Accuracy: 92.97%\n",
            "Epoch: 37, Step: 2/164, Loss: 0.332866, Accuracy: 91.02%\n",
            "Epoch: 37, Step: 3/164, Loss: 0.282014, Accuracy: 92.19%\n",
            "Epoch: 37, Step: 4/164, Loss: 0.304828, Accuracy: 90.62%\n",
            "Epoch: 37, Step: 5/164, Loss: 0.296018, Accuracy: 90.47%\n",
            "Epoch: 37, Step: 6/164, Loss: 0.285745, Accuracy: 90.76%\n",
            "Epoch: 37, Step: 7/164, Loss: 0.273917, Accuracy: 91.18%\n",
            "Epoch: 37, Step: 8/164, Loss: 0.282244, Accuracy: 90.43%\n",
            "Epoch: 37, Step: 9/164, Loss: 0.290324, Accuracy: 90.10%\n",
            "Epoch: 37, Step: 10/164, Loss: 0.290878, Accuracy: 90.08%\n",
            "Epoch: 37, Step: 11/164, Loss: 0.293690, Accuracy: 89.91%\n",
            "Epoch: 37, Step: 12/164, Loss: 0.304001, Accuracy: 89.45%\n",
            "Epoch: 37, Step: 13/164, Loss: 0.303202, Accuracy: 89.36%\n",
            "Epoch: 37, Step: 14/164, Loss: 0.302310, Accuracy: 89.62%\n",
            "Epoch: 37, Step: 15/164, Loss: 0.299979, Accuracy: 89.69%\n",
            "Epoch: 37, Step: 16/164, Loss: 0.300669, Accuracy: 89.70%\n",
            "Epoch: 37, Step: 17/164, Loss: 0.300496, Accuracy: 89.71%\n",
            "Epoch: 37, Step: 18/164, Loss: 0.303304, Accuracy: 89.58%\n",
            "Epoch: 37, Step: 19/164, Loss: 0.305136, Accuracy: 89.64%\n",
            "Epoch: 37, Step: 20/164, Loss: 0.313462, Accuracy: 89.49%\n",
            "Epoch: 37, Step: 21/164, Loss: 0.314539, Accuracy: 89.36%\n",
            "Epoch: 37, Step: 22/164, Loss: 0.315628, Accuracy: 89.38%\n",
            "Epoch: 37, Step: 23/164, Loss: 0.318336, Accuracy: 89.30%\n",
            "Epoch: 37, Step: 24/164, Loss: 0.319181, Accuracy: 89.23%\n",
            "Epoch: 37, Step: 25/164, Loss: 0.316394, Accuracy: 89.28%\n",
            "Epoch: 37, Step: 26/164, Loss: 0.315484, Accuracy: 89.27%\n",
            "Epoch: 37, Step: 27/164, Loss: 0.312072, Accuracy: 89.38%\n",
            "Epoch: 37, Step: 28/164, Loss: 0.312344, Accuracy: 89.37%\n",
            "Epoch: 37, Step: 29/164, Loss: 0.309589, Accuracy: 89.49%\n",
            "Epoch: 37, Step: 30/164, Loss: 0.313031, Accuracy: 89.38%\n",
            "Epoch: 37, Step: 31/164, Loss: 0.316208, Accuracy: 89.31%\n",
            "Epoch: 37, Step: 32/164, Loss: 0.313729, Accuracy: 89.48%\n",
            "Epoch: 37, Step: 33/164, Loss: 0.314153, Accuracy: 89.49%\n",
            "Epoch: 37, Step: 34/164, Loss: 0.316210, Accuracy: 89.43%\n",
            "Epoch: 37, Step: 35/164, Loss: 0.319029, Accuracy: 89.33%\n",
            "Epoch: 37, Step: 36/164, Loss: 0.319332, Accuracy: 89.30%\n",
            "Epoch: 37, Step: 37/164, Loss: 0.319230, Accuracy: 89.34%\n",
            "Epoch: 37, Step: 38/164, Loss: 0.318866, Accuracy: 89.35%\n",
            "Epoch: 37, Step: 39/164, Loss: 0.319085, Accuracy: 89.32%\n",
            "Epoch: 37, Step: 40/164, Loss: 0.316343, Accuracy: 89.38%\n",
            "Epoch: 37, Step: 41/164, Loss: 0.319327, Accuracy: 89.33%\n",
            "Epoch: 37, Step: 42/164, Loss: 0.317104, Accuracy: 89.34%\n",
            "Epoch: 37, Step: 43/164, Loss: 0.316660, Accuracy: 89.37%\n",
            "Epoch: 37, Step: 44/164, Loss: 0.315447, Accuracy: 89.40%\n",
            "Epoch: 37, Step: 45/164, Loss: 0.318484, Accuracy: 89.32%\n",
            "Epoch: 37, Step: 46/164, Loss: 0.320030, Accuracy: 89.28%\n",
            "Epoch: 37, Step: 47/164, Loss: 0.318096, Accuracy: 89.33%\n",
            "Epoch: 37, Step: 48/164, Loss: 0.316638, Accuracy: 89.39%\n",
            "Epoch: 37, Step: 49/164, Loss: 0.320618, Accuracy: 89.30%\n",
            "Epoch: 37, Step: 50/164, Loss: 0.320380, Accuracy: 89.30%\n",
            "Epoch: 37, Step: 51/164, Loss: 0.321907, Accuracy: 89.29%\n",
            "Epoch: 37, Step: 52/164, Loss: 0.321773, Accuracy: 89.29%\n",
            "Epoch: 37, Step: 53/164, Loss: 0.326118, Accuracy: 89.11%\n",
            "Epoch: 37, Step: 54/164, Loss: 0.328327, Accuracy: 88.98%\n",
            "Epoch: 37, Step: 55/164, Loss: 0.326732, Accuracy: 89.02%\n",
            "Epoch: 37, Step: 56/164, Loss: 0.327788, Accuracy: 88.96%\n",
            "Epoch: 37, Step: 57/164, Loss: 0.328278, Accuracy: 88.99%\n",
            "Epoch: 37, Step: 58/164, Loss: 0.327309, Accuracy: 89.05%\n",
            "Epoch: 37, Step: 59/164, Loss: 0.327536, Accuracy: 89.09%\n",
            "Epoch: 37, Step: 60/164, Loss: 0.328872, Accuracy: 89.04%\n",
            "Epoch: 37, Step: 61/164, Loss: 0.328001, Accuracy: 89.06%\n",
            "Epoch: 37, Step: 62/164, Loss: 0.327765, Accuracy: 89.11%\n",
            "Epoch: 37, Step: 63/164, Loss: 0.326539, Accuracy: 89.15%\n",
            "Epoch: 37, Step: 64/164, Loss: 0.327309, Accuracy: 89.14%\n",
            "Epoch: 37, Step: 65/164, Loss: 0.326117, Accuracy: 89.17%\n",
            "Epoch: 37, Step: 66/164, Loss: 0.325710, Accuracy: 89.15%\n",
            "Epoch: 37, Step: 67/164, Loss: 0.325634, Accuracy: 89.13%\n",
            "Epoch: 37, Step: 68/164, Loss: 0.325901, Accuracy: 89.13%\n",
            "Epoch: 37, Step: 69/164, Loss: 0.325264, Accuracy: 89.15%\n",
            "Epoch: 37, Step: 70/164, Loss: 0.326737, Accuracy: 89.10%\n",
            "Epoch: 37, Step: 71/164, Loss: 0.327722, Accuracy: 89.05%\n",
            "Epoch: 37, Step: 72/164, Loss: 0.327421, Accuracy: 89.04%\n",
            "Epoch: 37, Step: 73/164, Loss: 0.328519, Accuracy: 89.02%\n",
            "Epoch: 37, Step: 74/164, Loss: 0.329807, Accuracy: 89.01%\n",
            "Epoch: 37, Step: 75/164, Loss: 0.331009, Accuracy: 88.91%\n",
            "Epoch: 37, Step: 76/164, Loss: 0.331028, Accuracy: 88.89%\n",
            "Epoch: 37, Step: 77/164, Loss: 0.330710, Accuracy: 88.89%\n",
            "Epoch: 37, Step: 78/164, Loss: 0.330240, Accuracy: 88.89%\n",
            "Epoch: 37, Step: 79/164, Loss: 0.329214, Accuracy: 88.92%\n",
            "Epoch: 37, Step: 80/164, Loss: 0.329806, Accuracy: 88.88%\n",
            "Epoch: 37, Step: 81/164, Loss: 0.330671, Accuracy: 88.85%\n",
            "Epoch: 37, Step: 82/164, Loss: 0.330655, Accuracy: 88.84%\n",
            "Epoch: 37, Step: 83/164, Loss: 0.331389, Accuracy: 88.83%\n",
            "Epoch: 37, Step: 84/164, Loss: 0.331226, Accuracy: 88.87%\n",
            "Epoch: 37, Step: 85/164, Loss: 0.330681, Accuracy: 88.91%\n",
            "Epoch: 37, Step: 86/164, Loss: 0.331169, Accuracy: 88.92%\n",
            "Epoch: 37, Step: 87/164, Loss: 0.331044, Accuracy: 88.90%\n",
            "Epoch: 37, Step: 88/164, Loss: 0.330189, Accuracy: 88.92%\n",
            "Epoch: 37, Step: 89/164, Loss: 0.330556, Accuracy: 88.91%\n",
            "Epoch: 37, Step: 90/164, Loss: 0.329296, Accuracy: 88.97%\n",
            "Epoch: 37, Step: 91/164, Loss: 0.328874, Accuracy: 88.97%\n",
            "Epoch: 37, Step: 92/164, Loss: 0.328659, Accuracy: 89.03%\n",
            "Epoch: 37, Step: 93/164, Loss: 0.329519, Accuracy: 89.01%\n",
            "Epoch: 37, Step: 94/164, Loss: 0.328985, Accuracy: 89.02%\n",
            "Epoch: 37, Step: 95/164, Loss: 0.328824, Accuracy: 89.03%\n",
            "Epoch: 37, Step: 96/164, Loss: 0.329170, Accuracy: 89.01%\n",
            "Epoch: 37, Step: 97/164, Loss: 0.329166, Accuracy: 88.98%\n",
            "Epoch: 37, Step: 98/164, Loss: 0.330575, Accuracy: 88.90%\n",
            "Epoch: 37, Step: 99/164, Loss: 0.330992, Accuracy: 88.90%\n",
            "Epoch: 37, Step: 100/164, Loss: 0.330948, Accuracy: 88.91%\n",
            "Epoch: 37, Step: 101/164, Loss: 0.330784, Accuracy: 88.93%\n",
            "Epoch: 37, Step: 102/164, Loss: 0.331390, Accuracy: 88.90%\n",
            "Epoch: 37, Step: 103/164, Loss: 0.332785, Accuracy: 88.85%\n",
            "Epoch: 37, Step: 104/164, Loss: 0.333542, Accuracy: 88.82%\n",
            "Epoch: 37, Step: 105/164, Loss: 0.333936, Accuracy: 88.81%\n",
            "Epoch: 37, Step: 106/164, Loss: 0.335411, Accuracy: 88.78%\n",
            "Epoch: 37, Step: 107/164, Loss: 0.336119, Accuracy: 88.79%\n",
            "Epoch: 37, Step: 108/164, Loss: 0.337365, Accuracy: 88.75%\n",
            "Epoch: 37, Step: 109/164, Loss: 0.338910, Accuracy: 88.71%\n",
            "Epoch: 37, Step: 110/164, Loss: 0.338912, Accuracy: 88.71%\n",
            "Epoch: 37, Step: 111/164, Loss: 0.337988, Accuracy: 88.75%\n",
            "Epoch: 37, Step: 112/164, Loss: 0.338349, Accuracy: 88.74%\n",
            "Epoch: 37, Step: 113/164, Loss: 0.337354, Accuracy: 88.77%\n",
            "Epoch: 37, Step: 114/164, Loss: 0.337779, Accuracy: 88.75%\n",
            "Epoch: 37, Step: 115/164, Loss: 0.336742, Accuracy: 88.77%\n",
            "Epoch: 37, Step: 116/164, Loss: 0.337450, Accuracy: 88.73%\n",
            "Epoch: 37, Step: 117/164, Loss: 0.337762, Accuracy: 88.74%\n",
            "Epoch: 37, Step: 118/164, Loss: 0.337471, Accuracy: 88.74%\n",
            "Epoch: 37, Step: 119/164, Loss: 0.337152, Accuracy: 88.75%\n",
            "Epoch: 37, Step: 120/164, Loss: 0.337399, Accuracy: 88.77%\n",
            "Epoch: 37, Step: 121/164, Loss: 0.337705, Accuracy: 88.76%\n",
            "Epoch: 37, Step: 122/164, Loss: 0.337173, Accuracy: 88.81%\n",
            "Epoch: 37, Step: 123/164, Loss: 0.337425, Accuracy: 88.79%\n",
            "Epoch: 37, Step: 124/164, Loss: 0.336983, Accuracy: 88.81%\n",
            "Epoch: 37, Step: 125/164, Loss: 0.336462, Accuracy: 88.82%\n",
            "Epoch: 37, Step: 126/164, Loss: 0.336019, Accuracy: 88.83%\n",
            "Epoch: 37, Step: 127/164, Loss: 0.335333, Accuracy: 88.84%\n",
            "Epoch: 37, Step: 128/164, Loss: 0.335792, Accuracy: 88.84%\n",
            "Epoch: 37, Step: 129/164, Loss: 0.335563, Accuracy: 88.84%\n",
            "Epoch: 37, Step: 130/164, Loss: 0.335152, Accuracy: 88.86%\n",
            "Epoch: 37, Step: 131/164, Loss: 0.334950, Accuracy: 88.87%\n",
            "Epoch: 37, Step: 132/164, Loss: 0.334443, Accuracy: 88.90%\n",
            "Epoch: 37, Step: 133/164, Loss: 0.335091, Accuracy: 88.89%\n",
            "Epoch: 37, Step: 134/164, Loss: 0.334430, Accuracy: 88.92%\n",
            "Epoch: 37, Step: 135/164, Loss: 0.334426, Accuracy: 88.93%\n",
            "Epoch: 37, Step: 136/164, Loss: 0.334078, Accuracy: 88.94%\n",
            "Epoch: 37, Step: 137/164, Loss: 0.334128, Accuracy: 88.93%\n",
            "Epoch: 37, Step: 138/164, Loss: 0.333621, Accuracy: 88.92%\n",
            "Epoch: 37, Step: 139/164, Loss: 0.333340, Accuracy: 88.92%\n",
            "Epoch: 37, Step: 140/164, Loss: 0.332941, Accuracy: 88.93%\n",
            "Epoch: 37, Step: 141/164, Loss: 0.333557, Accuracy: 88.91%\n",
            "Epoch: 37, Step: 142/164, Loss: 0.333445, Accuracy: 88.91%\n",
            "Epoch: 37, Step: 143/164, Loss: 0.332385, Accuracy: 88.96%\n",
            "Epoch: 37, Step: 144/164, Loss: 0.331164, Accuracy: 88.99%\n",
            "Epoch: 37, Step: 145/164, Loss: 0.330783, Accuracy: 89.00%\n",
            "Epoch: 37, Step: 146/164, Loss: 0.330849, Accuracy: 88.99%\n",
            "Epoch: 37, Step: 147/164, Loss: 0.331073, Accuracy: 88.97%\n",
            "Epoch: 37, Step: 148/164, Loss: 0.331936, Accuracy: 88.95%\n",
            "Epoch: 37, Step: 149/164, Loss: 0.333492, Accuracy: 88.91%\n",
            "Epoch: 37, Step: 150/164, Loss: 0.333994, Accuracy: 88.91%\n",
            "Epoch: 37, Step: 151/164, Loss: 0.334139, Accuracy: 88.91%\n",
            "Epoch: 37, Step: 152/164, Loss: 0.333013, Accuracy: 88.96%\n",
            "Epoch: 37, Step: 153/164, Loss: 0.332919, Accuracy: 88.96%\n",
            "Epoch: 37, Step: 154/164, Loss: 0.332947, Accuracy: 88.94%\n",
            "Epoch: 37, Step: 155/164, Loss: 0.334098, Accuracy: 88.90%\n",
            "Epoch: 37, Step: 156/164, Loss: 0.333970, Accuracy: 88.89%\n",
            "Epoch: 37, Step: 157/164, Loss: 0.333717, Accuracy: 88.90%\n",
            "Epoch: 37, Step: 158/164, Loss: 0.333896, Accuracy: 88.89%\n",
            "Epoch: 37, Step: 159/164, Loss: 0.334234, Accuracy: 88.88%\n",
            "Epoch: 37, Step: 160/164, Loss: 0.333367, Accuracy: 88.89%\n",
            "Epoch: 37, Step: 161/164, Loss: 0.333353, Accuracy: 88.90%\n",
            "Epoch: 37, Step: 162/164, Loss: 0.333027, Accuracy: 88.93%\n",
            "Epoch: 37, Step: 163/164, Loss: 0.332318, Accuracy: 88.95%\n",
            "Epoch: 37, Step: 164/164, Loss: 0.333756, Accuracy: 88.93%\n",
            "Epoch: 38, Step: 1/164, Loss: 0.387427, Accuracy: 89.06%\n",
            "Epoch: 38, Step: 2/164, Loss: 0.353000, Accuracy: 89.45%\n",
            "Epoch: 38, Step: 3/164, Loss: 0.363194, Accuracy: 88.80%\n",
            "Epoch: 38, Step: 4/164, Loss: 0.345733, Accuracy: 89.45%\n",
            "Epoch: 38, Step: 5/164, Loss: 0.341621, Accuracy: 89.22%\n",
            "Epoch: 38, Step: 6/164, Loss: 0.334846, Accuracy: 89.45%\n",
            "Epoch: 38, Step: 7/164, Loss: 0.319828, Accuracy: 89.62%\n",
            "Epoch: 38, Step: 8/164, Loss: 0.308535, Accuracy: 89.65%\n",
            "Epoch: 38, Step: 9/164, Loss: 0.315749, Accuracy: 89.50%\n",
            "Epoch: 38, Step: 10/164, Loss: 0.316970, Accuracy: 89.22%\n",
            "Epoch: 38, Step: 11/164, Loss: 0.315315, Accuracy: 89.35%\n",
            "Epoch: 38, Step: 12/164, Loss: 0.326134, Accuracy: 89.13%\n",
            "Epoch: 38, Step: 13/164, Loss: 0.333705, Accuracy: 88.88%\n",
            "Epoch: 38, Step: 14/164, Loss: 0.328236, Accuracy: 89.06%\n",
            "Epoch: 38, Step: 15/164, Loss: 0.321131, Accuracy: 89.53%\n",
            "Epoch: 38, Step: 16/164, Loss: 0.324592, Accuracy: 89.31%\n",
            "Epoch: 38, Step: 17/164, Loss: 0.329880, Accuracy: 89.20%\n",
            "Epoch: 38, Step: 18/164, Loss: 0.333355, Accuracy: 89.11%\n",
            "Epoch: 38, Step: 19/164, Loss: 0.331772, Accuracy: 89.10%\n",
            "Epoch: 38, Step: 20/164, Loss: 0.328296, Accuracy: 89.18%\n",
            "Epoch: 38, Step: 21/164, Loss: 0.324140, Accuracy: 89.25%\n",
            "Epoch: 38, Step: 22/164, Loss: 0.323468, Accuracy: 89.10%\n",
            "Epoch: 38, Step: 23/164, Loss: 0.324461, Accuracy: 89.03%\n",
            "Epoch: 38, Step: 24/164, Loss: 0.328446, Accuracy: 88.93%\n",
            "Epoch: 38, Step: 25/164, Loss: 0.328016, Accuracy: 88.84%\n",
            "Epoch: 38, Step: 26/164, Loss: 0.327752, Accuracy: 88.85%\n",
            "Epoch: 38, Step: 27/164, Loss: 0.330139, Accuracy: 88.80%\n",
            "Epoch: 38, Step: 28/164, Loss: 0.331869, Accuracy: 88.92%\n",
            "Epoch: 38, Step: 29/164, Loss: 0.332638, Accuracy: 88.82%\n",
            "Epoch: 38, Step: 30/164, Loss: 0.330248, Accuracy: 88.91%\n",
            "Epoch: 38, Step: 31/164, Loss: 0.325715, Accuracy: 89.11%\n",
            "Epoch: 38, Step: 32/164, Loss: 0.327577, Accuracy: 89.06%\n",
            "Epoch: 38, Step: 33/164, Loss: 0.325047, Accuracy: 89.16%\n",
            "Epoch: 38, Step: 34/164, Loss: 0.328601, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 35/164, Loss: 0.328872, Accuracy: 89.08%\n",
            "Epoch: 38, Step: 36/164, Loss: 0.326580, Accuracy: 89.15%\n",
            "Epoch: 38, Step: 37/164, Loss: 0.328918, Accuracy: 89.08%\n",
            "Epoch: 38, Step: 38/164, Loss: 0.327776, Accuracy: 89.10%\n",
            "Epoch: 38, Step: 39/164, Loss: 0.330516, Accuracy: 89.04%\n",
            "Epoch: 38, Step: 40/164, Loss: 0.330305, Accuracy: 89.10%\n",
            "Epoch: 38, Step: 41/164, Loss: 0.329916, Accuracy: 89.12%\n",
            "Epoch: 38, Step: 42/164, Loss: 0.328253, Accuracy: 89.19%\n",
            "Epoch: 38, Step: 43/164, Loss: 0.328865, Accuracy: 89.10%\n",
            "Epoch: 38, Step: 44/164, Loss: 0.329783, Accuracy: 89.08%\n",
            "Epoch: 38, Step: 45/164, Loss: 0.330777, Accuracy: 89.06%\n",
            "Epoch: 38, Step: 46/164, Loss: 0.330383, Accuracy: 89.08%\n",
            "Epoch: 38, Step: 47/164, Loss: 0.330956, Accuracy: 89.10%\n",
            "Epoch: 38, Step: 48/164, Loss: 0.329496, Accuracy: 89.16%\n",
            "Epoch: 38, Step: 49/164, Loss: 0.330907, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 50/164, Loss: 0.331189, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 51/164, Loss: 0.332761, Accuracy: 89.02%\n",
            "Epoch: 38, Step: 52/164, Loss: 0.333641, Accuracy: 88.96%\n",
            "Epoch: 38, Step: 53/164, Loss: 0.334249, Accuracy: 88.94%\n",
            "Epoch: 38, Step: 54/164, Loss: 0.333084, Accuracy: 88.99%\n",
            "Epoch: 38, Step: 55/164, Loss: 0.332001, Accuracy: 89.01%\n",
            "Epoch: 38, Step: 56/164, Loss: 0.329307, Accuracy: 89.10%\n",
            "Epoch: 38, Step: 57/164, Loss: 0.326622, Accuracy: 89.20%\n",
            "Epoch: 38, Step: 58/164, Loss: 0.325019, Accuracy: 89.26%\n",
            "Epoch: 38, Step: 59/164, Loss: 0.323582, Accuracy: 89.31%\n",
            "Epoch: 38, Step: 60/164, Loss: 0.323475, Accuracy: 89.26%\n",
            "Epoch: 38, Step: 61/164, Loss: 0.325071, Accuracy: 89.19%\n",
            "Epoch: 38, Step: 62/164, Loss: 0.325561, Accuracy: 89.23%\n",
            "Epoch: 38, Step: 63/164, Loss: 0.323865, Accuracy: 89.29%\n",
            "Epoch: 38, Step: 64/164, Loss: 0.322923, Accuracy: 89.32%\n",
            "Epoch: 38, Step: 65/164, Loss: 0.323962, Accuracy: 89.24%\n",
            "Epoch: 38, Step: 66/164, Loss: 0.325099, Accuracy: 89.24%\n",
            "Epoch: 38, Step: 67/164, Loss: 0.324965, Accuracy: 89.30%\n",
            "Epoch: 38, Step: 68/164, Loss: 0.325010, Accuracy: 89.29%\n",
            "Epoch: 38, Step: 69/164, Loss: 0.324983, Accuracy: 89.28%\n",
            "Epoch: 38, Step: 70/164, Loss: 0.325895, Accuracy: 89.20%\n",
            "Epoch: 38, Step: 71/164, Loss: 0.324777, Accuracy: 89.24%\n",
            "Epoch: 38, Step: 72/164, Loss: 0.324822, Accuracy: 89.24%\n",
            "Epoch: 38, Step: 73/164, Loss: 0.324427, Accuracy: 89.26%\n",
            "Epoch: 38, Step: 74/164, Loss: 0.326224, Accuracy: 89.23%\n",
            "Epoch: 38, Step: 75/164, Loss: 0.326998, Accuracy: 89.25%\n",
            "Epoch: 38, Step: 76/164, Loss: 0.327650, Accuracy: 89.21%\n",
            "Epoch: 38, Step: 77/164, Loss: 0.327199, Accuracy: 89.20%\n",
            "Epoch: 38, Step: 78/164, Loss: 0.327375, Accuracy: 89.20%\n",
            "Epoch: 38, Step: 79/164, Loss: 0.328394, Accuracy: 89.13%\n",
            "Epoch: 38, Step: 80/164, Loss: 0.330185, Accuracy: 89.11%\n",
            "Epoch: 38, Step: 81/164, Loss: 0.330109, Accuracy: 89.10%\n",
            "Epoch: 38, Step: 82/164, Loss: 0.328577, Accuracy: 89.15%\n",
            "Epoch: 38, Step: 83/164, Loss: 0.329636, Accuracy: 89.12%\n",
            "Epoch: 38, Step: 84/164, Loss: 0.328657, Accuracy: 89.16%\n",
            "Epoch: 38, Step: 85/164, Loss: 0.328233, Accuracy: 89.15%\n",
            "Epoch: 38, Step: 86/164, Loss: 0.327337, Accuracy: 89.15%\n",
            "Epoch: 38, Step: 87/164, Loss: 0.326562, Accuracy: 89.18%\n",
            "Epoch: 38, Step: 88/164, Loss: 0.326408, Accuracy: 89.15%\n",
            "Epoch: 38, Step: 89/164, Loss: 0.326636, Accuracy: 89.13%\n",
            "Epoch: 38, Step: 90/164, Loss: 0.325761, Accuracy: 89.16%\n",
            "Epoch: 38, Step: 91/164, Loss: 0.326426, Accuracy: 89.13%\n",
            "Epoch: 38, Step: 92/164, Loss: 0.326243, Accuracy: 89.14%\n",
            "Epoch: 38, Step: 93/164, Loss: 0.327449, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 94/164, Loss: 0.328319, Accuracy: 89.05%\n",
            "Epoch: 38, Step: 95/164, Loss: 0.327804, Accuracy: 89.07%\n",
            "Epoch: 38, Step: 96/164, Loss: 0.328607, Accuracy: 89.05%\n",
            "Epoch: 38, Step: 97/164, Loss: 0.327227, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 98/164, Loss: 0.327476, Accuracy: 89.05%\n",
            "Epoch: 38, Step: 99/164, Loss: 0.327528, Accuracy: 89.05%\n",
            "Epoch: 38, Step: 100/164, Loss: 0.327389, Accuracy: 89.05%\n",
            "Epoch: 38, Step: 101/164, Loss: 0.327313, Accuracy: 89.08%\n",
            "Epoch: 38, Step: 102/164, Loss: 0.327120, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 103/164, Loss: 0.326881, Accuracy: 89.08%\n",
            "Epoch: 38, Step: 104/164, Loss: 0.326853, Accuracy: 89.07%\n",
            "Epoch: 38, Step: 105/164, Loss: 0.326486, Accuracy: 89.05%\n",
            "Epoch: 38, Step: 106/164, Loss: 0.327565, Accuracy: 88.99%\n",
            "Epoch: 38, Step: 107/164, Loss: 0.328155, Accuracy: 89.00%\n",
            "Epoch: 38, Step: 108/164, Loss: 0.328262, Accuracy: 88.98%\n",
            "Epoch: 38, Step: 109/164, Loss: 0.327336, Accuracy: 89.01%\n",
            "Epoch: 38, Step: 110/164, Loss: 0.327430, Accuracy: 89.01%\n",
            "Epoch: 38, Step: 111/164, Loss: 0.328072, Accuracy: 89.00%\n",
            "Epoch: 38, Step: 112/164, Loss: 0.326717, Accuracy: 89.07%\n",
            "Epoch: 38, Step: 113/164, Loss: 0.326816, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 114/164, Loss: 0.326613, Accuracy: 89.11%\n",
            "Epoch: 38, Step: 115/164, Loss: 0.326977, Accuracy: 89.10%\n",
            "Epoch: 38, Step: 116/164, Loss: 0.328203, Accuracy: 89.06%\n",
            "Epoch: 38, Step: 117/164, Loss: 0.329253, Accuracy: 89.03%\n",
            "Epoch: 38, Step: 118/164, Loss: 0.328439, Accuracy: 89.06%\n",
            "Epoch: 38, Step: 119/164, Loss: 0.328909, Accuracy: 89.04%\n",
            "Epoch: 38, Step: 120/164, Loss: 0.328225, Accuracy: 89.06%\n",
            "Epoch: 38, Step: 121/164, Loss: 0.328026, Accuracy: 89.06%\n",
            "Epoch: 38, Step: 122/164, Loss: 0.327766, Accuracy: 89.07%\n",
            "Epoch: 38, Step: 123/164, Loss: 0.327590, Accuracy: 89.06%\n",
            "Epoch: 38, Step: 124/164, Loss: 0.327226, Accuracy: 89.06%\n",
            "Epoch: 38, Step: 125/164, Loss: 0.326371, Accuracy: 89.08%\n",
            "Epoch: 38, Step: 126/164, Loss: 0.326760, Accuracy: 89.06%\n",
            "Epoch: 38, Step: 127/164, Loss: 0.326285, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 128/164, Loss: 0.325740, Accuracy: 89.12%\n",
            "Epoch: 38, Step: 129/164, Loss: 0.325187, Accuracy: 89.12%\n",
            "Epoch: 38, Step: 130/164, Loss: 0.325700, Accuracy: 89.10%\n",
            "Epoch: 38, Step: 131/164, Loss: 0.325847, Accuracy: 89.12%\n",
            "Epoch: 38, Step: 132/164, Loss: 0.326559, Accuracy: 89.10%\n",
            "Epoch: 38, Step: 133/164, Loss: 0.326628, Accuracy: 89.10%\n",
            "Epoch: 38, Step: 134/164, Loss: 0.326588, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 135/164, Loss: 0.327049, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 136/164, Loss: 0.326833, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 137/164, Loss: 0.327323, Accuracy: 89.10%\n",
            "Epoch: 38, Step: 138/164, Loss: 0.326953, Accuracy: 89.11%\n",
            "Epoch: 38, Step: 139/164, Loss: 0.326411, Accuracy: 89.12%\n",
            "Epoch: 38, Step: 140/164, Loss: 0.326840, Accuracy: 89.12%\n",
            "Epoch: 38, Step: 141/164, Loss: 0.326440, Accuracy: 89.12%\n",
            "Epoch: 38, Step: 142/164, Loss: 0.327378, Accuracy: 89.08%\n",
            "Epoch: 38, Step: 143/164, Loss: 0.327404, Accuracy: 89.08%\n",
            "Epoch: 38, Step: 144/164, Loss: 0.327753, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 145/164, Loss: 0.327473, Accuracy: 89.11%\n",
            "Epoch: 38, Step: 146/164, Loss: 0.327724, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 147/164, Loss: 0.327075, Accuracy: 89.12%\n",
            "Epoch: 38, Step: 148/164, Loss: 0.327959, Accuracy: 89.11%\n",
            "Epoch: 38, Step: 149/164, Loss: 0.327915, Accuracy: 89.10%\n",
            "Epoch: 38, Step: 150/164, Loss: 0.327478, Accuracy: 89.11%\n",
            "Epoch: 38, Step: 151/164, Loss: 0.328467, Accuracy: 89.08%\n",
            "Epoch: 38, Step: 152/164, Loss: 0.328326, Accuracy: 89.08%\n",
            "Epoch: 38, Step: 153/164, Loss: 0.328157, Accuracy: 89.08%\n",
            "Epoch: 38, Step: 154/164, Loss: 0.328119, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 155/164, Loss: 0.328089, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 156/164, Loss: 0.329099, Accuracy: 89.06%\n",
            "Epoch: 38, Step: 157/164, Loss: 0.328673, Accuracy: 89.07%\n",
            "Epoch: 38, Step: 158/164, Loss: 0.328063, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 159/164, Loss: 0.328069, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 160/164, Loss: 0.328146, Accuracy: 89.09%\n",
            "Epoch: 38, Step: 161/164, Loss: 0.328866, Accuracy: 89.06%\n",
            "Epoch: 38, Step: 162/164, Loss: 0.328851, Accuracy: 89.06%\n",
            "Epoch: 38, Step: 163/164, Loss: 0.329065, Accuracy: 89.06%\n",
            "Epoch: 38, Step: 164/164, Loss: 0.328156, Accuracy: 89.08%\n",
            "Epoch: 39, Step: 1/164, Loss: 0.304421, Accuracy: 88.28%\n",
            "Epoch: 39, Step: 2/164, Loss: 0.293633, Accuracy: 91.02%\n",
            "Epoch: 39, Step: 3/164, Loss: 0.323233, Accuracy: 88.80%\n",
            "Epoch: 39, Step: 4/164, Loss: 0.307237, Accuracy: 89.45%\n",
            "Epoch: 39, Step: 5/164, Loss: 0.301038, Accuracy: 90.00%\n",
            "Epoch: 39, Step: 6/164, Loss: 0.292010, Accuracy: 90.23%\n",
            "Epoch: 39, Step: 7/164, Loss: 0.294477, Accuracy: 90.07%\n",
            "Epoch: 39, Step: 8/164, Loss: 0.298297, Accuracy: 90.14%\n",
            "Epoch: 39, Step: 9/164, Loss: 0.287654, Accuracy: 90.36%\n",
            "Epoch: 39, Step: 10/164, Loss: 0.287764, Accuracy: 90.39%\n",
            "Epoch: 39, Step: 11/164, Loss: 0.284823, Accuracy: 90.41%\n",
            "Epoch: 39, Step: 12/164, Loss: 0.289807, Accuracy: 90.10%\n",
            "Epoch: 39, Step: 13/164, Loss: 0.289587, Accuracy: 90.20%\n",
            "Epoch: 39, Step: 14/164, Loss: 0.295150, Accuracy: 90.07%\n",
            "Epoch: 39, Step: 15/164, Loss: 0.296074, Accuracy: 89.95%\n",
            "Epoch: 39, Step: 16/164, Loss: 0.296912, Accuracy: 89.94%\n",
            "Epoch: 39, Step: 17/164, Loss: 0.300321, Accuracy: 89.80%\n",
            "Epoch: 39, Step: 18/164, Loss: 0.299585, Accuracy: 89.80%\n",
            "Epoch: 39, Step: 19/164, Loss: 0.302200, Accuracy: 89.56%\n",
            "Epoch: 39, Step: 20/164, Loss: 0.304080, Accuracy: 89.57%\n",
            "Epoch: 39, Step: 21/164, Loss: 0.307515, Accuracy: 89.51%\n",
            "Epoch: 39, Step: 22/164, Loss: 0.308328, Accuracy: 89.45%\n",
            "Epoch: 39, Step: 23/164, Loss: 0.313984, Accuracy: 89.37%\n",
            "Epoch: 39, Step: 24/164, Loss: 0.312497, Accuracy: 89.42%\n",
            "Epoch: 39, Step: 25/164, Loss: 0.312400, Accuracy: 89.38%\n",
            "Epoch: 39, Step: 26/164, Loss: 0.314390, Accuracy: 89.30%\n",
            "Epoch: 39, Step: 27/164, Loss: 0.317034, Accuracy: 89.29%\n",
            "Epoch: 39, Step: 28/164, Loss: 0.313150, Accuracy: 89.43%\n",
            "Epoch: 39, Step: 29/164, Loss: 0.313573, Accuracy: 89.44%\n",
            "Epoch: 39, Step: 30/164, Loss: 0.310852, Accuracy: 89.53%\n",
            "Epoch: 39, Step: 31/164, Loss: 0.311855, Accuracy: 89.47%\n",
            "Epoch: 39, Step: 32/164, Loss: 0.316358, Accuracy: 89.36%\n",
            "Epoch: 39, Step: 33/164, Loss: 0.318071, Accuracy: 89.32%\n",
            "Epoch: 39, Step: 34/164, Loss: 0.323894, Accuracy: 89.15%\n",
            "Epoch: 39, Step: 35/164, Loss: 0.326293, Accuracy: 89.02%\n",
            "Epoch: 39, Step: 36/164, Loss: 0.325828, Accuracy: 89.08%\n",
            "Epoch: 39, Step: 37/164, Loss: 0.326455, Accuracy: 89.06%\n",
            "Epoch: 39, Step: 38/164, Loss: 0.325083, Accuracy: 89.12%\n",
            "Epoch: 39, Step: 39/164, Loss: 0.324661, Accuracy: 89.16%\n",
            "Epoch: 39, Step: 40/164, Loss: 0.324539, Accuracy: 89.20%\n",
            "Epoch: 39, Step: 41/164, Loss: 0.322874, Accuracy: 89.21%\n",
            "Epoch: 39, Step: 42/164, Loss: 0.322185, Accuracy: 89.27%\n",
            "Epoch: 39, Step: 43/164, Loss: 0.322304, Accuracy: 89.28%\n",
            "Epoch: 39, Step: 44/164, Loss: 0.322470, Accuracy: 89.20%\n",
            "Epoch: 39, Step: 45/164, Loss: 0.323018, Accuracy: 89.20%\n",
            "Epoch: 39, Step: 46/164, Loss: 0.320334, Accuracy: 89.30%\n",
            "Epoch: 39, Step: 47/164, Loss: 0.319362, Accuracy: 89.35%\n",
            "Epoch: 39, Step: 48/164, Loss: 0.318780, Accuracy: 89.36%\n",
            "Epoch: 39, Step: 49/164, Loss: 0.317269, Accuracy: 89.45%\n",
            "Epoch: 39, Step: 50/164, Loss: 0.317246, Accuracy: 89.36%\n",
            "Epoch: 39, Step: 51/164, Loss: 0.319021, Accuracy: 89.34%\n",
            "Epoch: 39, Step: 52/164, Loss: 0.319297, Accuracy: 89.33%\n",
            "Epoch: 39, Step: 53/164, Loss: 0.319487, Accuracy: 89.28%\n",
            "Epoch: 39, Step: 54/164, Loss: 0.320653, Accuracy: 89.21%\n",
            "Epoch: 39, Step: 55/164, Loss: 0.318813, Accuracy: 89.23%\n",
            "Epoch: 39, Step: 56/164, Loss: 0.319595, Accuracy: 89.17%\n",
            "Epoch: 39, Step: 57/164, Loss: 0.321783, Accuracy: 89.09%\n",
            "Epoch: 39, Step: 58/164, Loss: 0.322147, Accuracy: 89.06%\n",
            "Epoch: 39, Step: 59/164, Loss: 0.322691, Accuracy: 89.09%\n",
            "Epoch: 39, Step: 60/164, Loss: 0.322997, Accuracy: 89.08%\n",
            "Epoch: 39, Step: 61/164, Loss: 0.322441, Accuracy: 89.09%\n",
            "Epoch: 39, Step: 62/164, Loss: 0.323315, Accuracy: 89.05%\n",
            "Epoch: 39, Step: 63/164, Loss: 0.322172, Accuracy: 89.06%\n",
            "Epoch: 39, Step: 64/164, Loss: 0.321342, Accuracy: 89.09%\n",
            "Epoch: 39, Step: 65/164, Loss: 0.320430, Accuracy: 89.15%\n",
            "Epoch: 39, Step: 66/164, Loss: 0.320373, Accuracy: 89.09%\n",
            "Epoch: 39, Step: 67/164, Loss: 0.321926, Accuracy: 89.00%\n",
            "Epoch: 39, Step: 68/164, Loss: 0.321544, Accuracy: 89.03%\n",
            "Epoch: 39, Step: 69/164, Loss: 0.322575, Accuracy: 89.01%\n",
            "Epoch: 39, Step: 70/164, Loss: 0.323319, Accuracy: 89.01%\n",
            "Epoch: 39, Step: 71/164, Loss: 0.323449, Accuracy: 88.99%\n",
            "Epoch: 39, Step: 72/164, Loss: 0.324412, Accuracy: 88.95%\n",
            "Epoch: 39, Step: 73/164, Loss: 0.324036, Accuracy: 88.99%\n",
            "Epoch: 39, Step: 74/164, Loss: 0.324127, Accuracy: 89.00%\n",
            "Epoch: 39, Step: 75/164, Loss: 0.323482, Accuracy: 89.03%\n",
            "Epoch: 39, Step: 76/164, Loss: 0.323822, Accuracy: 89.00%\n",
            "Epoch: 39, Step: 77/164, Loss: 0.323772, Accuracy: 89.02%\n",
            "Epoch: 39, Step: 78/164, Loss: 0.323133, Accuracy: 89.05%\n",
            "Epoch: 39, Step: 79/164, Loss: 0.321851, Accuracy: 89.06%\n",
            "Epoch: 39, Step: 80/164, Loss: 0.320959, Accuracy: 89.11%\n",
            "Epoch: 39, Step: 81/164, Loss: 0.321096, Accuracy: 89.11%\n",
            "Epoch: 39, Step: 82/164, Loss: 0.320634, Accuracy: 89.14%\n",
            "Epoch: 39, Step: 83/164, Loss: 0.320456, Accuracy: 89.18%\n",
            "Epoch: 39, Step: 84/164, Loss: 0.320427, Accuracy: 89.18%\n",
            "Epoch: 39, Step: 85/164, Loss: 0.321215, Accuracy: 89.19%\n",
            "Epoch: 39, Step: 86/164, Loss: 0.321917, Accuracy: 89.14%\n",
            "Epoch: 39, Step: 87/164, Loss: 0.322379, Accuracy: 89.12%\n",
            "Epoch: 39, Step: 88/164, Loss: 0.321890, Accuracy: 89.17%\n",
            "Epoch: 39, Step: 89/164, Loss: 0.322416, Accuracy: 89.16%\n",
            "Epoch: 39, Step: 90/164, Loss: 0.322659, Accuracy: 89.17%\n",
            "Epoch: 39, Step: 91/164, Loss: 0.323119, Accuracy: 89.13%\n",
            "Epoch: 39, Step: 92/164, Loss: 0.323934, Accuracy: 89.10%\n",
            "Epoch: 39, Step: 93/164, Loss: 0.322579, Accuracy: 89.15%\n",
            "Epoch: 39, Step: 94/164, Loss: 0.322389, Accuracy: 89.14%\n",
            "Epoch: 39, Step: 95/164, Loss: 0.323235, Accuracy: 89.11%\n",
            "Epoch: 39, Step: 96/164, Loss: 0.322968, Accuracy: 89.14%\n",
            "Epoch: 39, Step: 97/164, Loss: 0.323870, Accuracy: 89.11%\n",
            "Epoch: 39, Step: 98/164, Loss: 0.323408, Accuracy: 89.13%\n",
            "Epoch: 39, Step: 99/164, Loss: 0.322663, Accuracy: 89.15%\n",
            "Epoch: 39, Step: 100/164, Loss: 0.324884, Accuracy: 89.07%\n",
            "Epoch: 39, Step: 101/164, Loss: 0.325061, Accuracy: 89.07%\n",
            "Epoch: 39, Step: 102/164, Loss: 0.324791, Accuracy: 89.07%\n",
            "Epoch: 39, Step: 103/164, Loss: 0.324160, Accuracy: 89.10%\n",
            "Epoch: 39, Step: 104/164, Loss: 0.324873, Accuracy: 89.11%\n",
            "Epoch: 39, Step: 105/164, Loss: 0.325097, Accuracy: 89.08%\n",
            "Epoch: 39, Step: 106/164, Loss: 0.324830, Accuracy: 89.11%\n",
            "Epoch: 39, Step: 107/164, Loss: 0.325101, Accuracy: 89.10%\n",
            "Epoch: 39, Step: 108/164, Loss: 0.325743, Accuracy: 89.09%\n",
            "Epoch: 39, Step: 109/164, Loss: 0.325795, Accuracy: 89.06%\n",
            "Epoch: 39, Step: 110/164, Loss: 0.324904, Accuracy: 89.11%\n",
            "Epoch: 39, Step: 111/164, Loss: 0.324559, Accuracy: 89.11%\n",
            "Epoch: 39, Step: 112/164, Loss: 0.325097, Accuracy: 89.06%\n",
            "Epoch: 39, Step: 113/164, Loss: 0.325221, Accuracy: 89.04%\n",
            "Epoch: 39, Step: 114/164, Loss: 0.326066, Accuracy: 89.05%\n",
            "Epoch: 39, Step: 115/164, Loss: 0.326760, Accuracy: 89.03%\n",
            "Epoch: 39, Step: 116/164, Loss: 0.326730, Accuracy: 89.03%\n",
            "Epoch: 39, Step: 117/164, Loss: 0.326596, Accuracy: 89.07%\n",
            "Epoch: 39, Step: 118/164, Loss: 0.326215, Accuracy: 89.07%\n",
            "Epoch: 39, Step: 119/164, Loss: 0.325725, Accuracy: 89.11%\n",
            "Epoch: 39, Step: 120/164, Loss: 0.325205, Accuracy: 89.11%\n",
            "Epoch: 39, Step: 121/164, Loss: 0.325343, Accuracy: 89.11%\n",
            "Epoch: 39, Step: 122/164, Loss: 0.325372, Accuracy: 89.11%\n",
            "Epoch: 39, Step: 123/164, Loss: 0.324980, Accuracy: 89.13%\n",
            "Epoch: 39, Step: 124/164, Loss: 0.323574, Accuracy: 89.19%\n",
            "Epoch: 39, Step: 125/164, Loss: 0.324053, Accuracy: 89.17%\n",
            "Epoch: 39, Step: 126/164, Loss: 0.323811, Accuracy: 89.19%\n",
            "Epoch: 39, Step: 127/164, Loss: 0.323763, Accuracy: 89.19%\n",
            "Epoch: 39, Step: 128/164, Loss: 0.323999, Accuracy: 89.21%\n",
            "Epoch: 39, Step: 129/164, Loss: 0.323181, Accuracy: 89.24%\n",
            "Epoch: 39, Step: 130/164, Loss: 0.323082, Accuracy: 89.24%\n",
            "Epoch: 39, Step: 131/164, Loss: 0.323744, Accuracy: 89.21%\n",
            "Epoch: 39, Step: 132/164, Loss: 0.323248, Accuracy: 89.20%\n",
            "Epoch: 39, Step: 133/164, Loss: 0.323443, Accuracy: 89.18%\n",
            "Epoch: 39, Step: 134/164, Loss: 0.323304, Accuracy: 89.17%\n",
            "Epoch: 39, Step: 135/164, Loss: 0.323661, Accuracy: 89.17%\n",
            "Epoch: 39, Step: 136/164, Loss: 0.323280, Accuracy: 89.19%\n",
            "Epoch: 39, Step: 137/164, Loss: 0.323228, Accuracy: 89.19%\n",
            "Epoch: 39, Step: 138/164, Loss: 0.322958, Accuracy: 89.22%\n",
            "Epoch: 39, Step: 139/164, Loss: 0.323407, Accuracy: 89.20%\n",
            "Epoch: 39, Step: 140/164, Loss: 0.323677, Accuracy: 89.19%\n",
            "Epoch: 39, Step: 141/164, Loss: 0.324108, Accuracy: 89.21%\n",
            "Epoch: 39, Step: 142/164, Loss: 0.323927, Accuracy: 89.21%\n",
            "Epoch: 39, Step: 143/164, Loss: 0.323302, Accuracy: 89.21%\n",
            "Epoch: 39, Step: 144/164, Loss: 0.322778, Accuracy: 89.21%\n",
            "Epoch: 39, Step: 145/164, Loss: 0.324008, Accuracy: 89.18%\n",
            "Epoch: 39, Step: 146/164, Loss: 0.324800, Accuracy: 89.16%\n",
            "Epoch: 39, Step: 147/164, Loss: 0.324484, Accuracy: 89.17%\n",
            "Epoch: 39, Step: 148/164, Loss: 0.324553, Accuracy: 89.17%\n",
            "Epoch: 39, Step: 149/164, Loss: 0.324563, Accuracy: 89.17%\n",
            "Epoch: 39, Step: 150/164, Loss: 0.324057, Accuracy: 89.18%\n",
            "Epoch: 39, Step: 151/164, Loss: 0.324641, Accuracy: 89.16%\n",
            "Epoch: 39, Step: 152/164, Loss: 0.324828, Accuracy: 89.13%\n",
            "Epoch: 39, Step: 153/164, Loss: 0.324694, Accuracy: 89.15%\n",
            "Epoch: 39, Step: 154/164, Loss: 0.326036, Accuracy: 89.11%\n",
            "Epoch: 39, Step: 155/164, Loss: 0.326684, Accuracy: 89.09%\n",
            "Epoch: 39, Step: 156/164, Loss: 0.327835, Accuracy: 89.06%\n",
            "Epoch: 39, Step: 157/164, Loss: 0.327520, Accuracy: 89.08%\n",
            "Epoch: 39, Step: 158/164, Loss: 0.327020, Accuracy: 89.10%\n",
            "Epoch: 39, Step: 159/164, Loss: 0.327634, Accuracy: 89.08%\n",
            "Epoch: 39, Step: 160/164, Loss: 0.328182, Accuracy: 89.06%\n",
            "Epoch: 39, Step: 161/164, Loss: 0.327804, Accuracy: 89.06%\n",
            "Epoch: 39, Step: 162/164, Loss: 0.328613, Accuracy: 89.04%\n",
            "Epoch: 39, Step: 163/164, Loss: 0.328553, Accuracy: 89.05%\n",
            "Epoch: 39, Step: 164/164, Loss: 0.328609, Accuracy: 89.05%\n",
            "Epoch: 40, Step: 1/164, Loss: 0.280503, Accuracy: 89.84%\n",
            "Epoch: 40, Step: 2/164, Loss: 0.284528, Accuracy: 91.41%\n",
            "Epoch: 40, Step: 3/164, Loss: 0.292883, Accuracy: 90.62%\n",
            "Epoch: 40, Step: 4/164, Loss: 0.286747, Accuracy: 90.82%\n",
            "Epoch: 40, Step: 5/164, Loss: 0.342138, Accuracy: 88.75%\n",
            "Epoch: 40, Step: 6/164, Loss: 0.345056, Accuracy: 88.54%\n",
            "Epoch: 40, Step: 7/164, Loss: 0.327393, Accuracy: 89.17%\n",
            "Epoch: 40, Step: 8/164, Loss: 0.316549, Accuracy: 89.36%\n",
            "Epoch: 40, Step: 9/164, Loss: 0.318950, Accuracy: 89.24%\n",
            "Epoch: 40, Step: 10/164, Loss: 0.313754, Accuracy: 89.45%\n",
            "Epoch: 40, Step: 11/164, Loss: 0.313798, Accuracy: 89.56%\n",
            "Epoch: 40, Step: 12/164, Loss: 0.311450, Accuracy: 89.32%\n",
            "Epoch: 40, Step: 13/164, Loss: 0.309826, Accuracy: 89.36%\n",
            "Epoch: 40, Step: 14/164, Loss: 0.312174, Accuracy: 89.45%\n",
            "Epoch: 40, Step: 15/164, Loss: 0.308187, Accuracy: 89.43%\n",
            "Epoch: 40, Step: 16/164, Loss: 0.320415, Accuracy: 89.16%\n",
            "Epoch: 40, Step: 17/164, Loss: 0.316964, Accuracy: 89.38%\n",
            "Epoch: 40, Step: 18/164, Loss: 0.313470, Accuracy: 89.45%\n",
            "Epoch: 40, Step: 19/164, Loss: 0.307964, Accuracy: 89.68%\n",
            "Epoch: 40, Step: 20/164, Loss: 0.308788, Accuracy: 89.61%\n",
            "Epoch: 40, Step: 21/164, Loss: 0.306019, Accuracy: 89.73%\n",
            "Epoch: 40, Step: 22/164, Loss: 0.303111, Accuracy: 89.70%\n",
            "Epoch: 40, Step: 23/164, Loss: 0.301005, Accuracy: 89.91%\n",
            "Epoch: 40, Step: 24/164, Loss: 0.298401, Accuracy: 89.91%\n",
            "Epoch: 40, Step: 25/164, Loss: 0.302174, Accuracy: 89.88%\n",
            "Epoch: 40, Step: 26/164, Loss: 0.304218, Accuracy: 89.84%\n",
            "Epoch: 40, Step: 27/164, Loss: 0.304228, Accuracy: 89.79%\n",
            "Epoch: 40, Step: 28/164, Loss: 0.304308, Accuracy: 89.84%\n",
            "Epoch: 40, Step: 29/164, Loss: 0.304188, Accuracy: 89.87%\n",
            "Epoch: 40, Step: 30/164, Loss: 0.301305, Accuracy: 89.95%\n",
            "Epoch: 40, Step: 31/164, Loss: 0.300677, Accuracy: 89.97%\n",
            "Epoch: 40, Step: 32/164, Loss: 0.303980, Accuracy: 89.87%\n",
            "Epoch: 40, Step: 33/164, Loss: 0.302154, Accuracy: 89.91%\n",
            "Epoch: 40, Step: 34/164, Loss: 0.299801, Accuracy: 89.96%\n",
            "Epoch: 40, Step: 35/164, Loss: 0.300565, Accuracy: 89.98%\n",
            "Epoch: 40, Step: 36/164, Loss: 0.303814, Accuracy: 89.89%\n",
            "Epoch: 40, Step: 37/164, Loss: 0.301334, Accuracy: 89.97%\n",
            "Epoch: 40, Step: 38/164, Loss: 0.302618, Accuracy: 89.91%\n",
            "Epoch: 40, Step: 39/164, Loss: 0.303735, Accuracy: 89.82%\n",
            "Epoch: 40, Step: 40/164, Loss: 0.302584, Accuracy: 89.90%\n",
            "Epoch: 40, Step: 41/164, Loss: 0.306712, Accuracy: 89.71%\n",
            "Epoch: 40, Step: 42/164, Loss: 0.305638, Accuracy: 89.75%\n",
            "Epoch: 40, Step: 43/164, Loss: 0.304472, Accuracy: 89.75%\n",
            "Epoch: 40, Step: 44/164, Loss: 0.303390, Accuracy: 89.77%\n",
            "Epoch: 40, Step: 45/164, Loss: 0.302705, Accuracy: 89.77%\n",
            "Epoch: 40, Step: 46/164, Loss: 0.304941, Accuracy: 89.69%\n",
            "Epoch: 40, Step: 47/164, Loss: 0.306617, Accuracy: 89.66%\n",
            "Epoch: 40, Step: 48/164, Loss: 0.307748, Accuracy: 89.68%\n",
            "Epoch: 40, Step: 49/164, Loss: 0.308303, Accuracy: 89.64%\n",
            "Epoch: 40, Step: 50/164, Loss: 0.308337, Accuracy: 89.73%\n",
            "Epoch: 40, Step: 51/164, Loss: 0.307784, Accuracy: 89.72%\n",
            "Epoch: 40, Step: 52/164, Loss: 0.309543, Accuracy: 89.66%\n",
            "Epoch: 40, Step: 53/164, Loss: 0.312001, Accuracy: 89.55%\n",
            "Epoch: 40, Step: 54/164, Loss: 0.312195, Accuracy: 89.58%\n",
            "Epoch: 40, Step: 55/164, Loss: 0.313421, Accuracy: 89.55%\n",
            "Epoch: 40, Step: 56/164, Loss: 0.313793, Accuracy: 89.54%\n",
            "Epoch: 40, Step: 57/164, Loss: 0.312233, Accuracy: 89.64%\n",
            "Epoch: 40, Step: 58/164, Loss: 0.312716, Accuracy: 89.61%\n",
            "Epoch: 40, Step: 59/164, Loss: 0.312207, Accuracy: 89.59%\n",
            "Epoch: 40, Step: 60/164, Loss: 0.315266, Accuracy: 89.51%\n",
            "Epoch: 40, Step: 61/164, Loss: 0.316004, Accuracy: 89.47%\n",
            "Epoch: 40, Step: 62/164, Loss: 0.314509, Accuracy: 89.53%\n",
            "Epoch: 40, Step: 63/164, Loss: 0.314089, Accuracy: 89.57%\n",
            "Epoch: 40, Step: 64/164, Loss: 0.316225, Accuracy: 89.55%\n",
            "Epoch: 40, Step: 65/164, Loss: 0.317381, Accuracy: 89.51%\n",
            "Epoch: 40, Step: 66/164, Loss: 0.318846, Accuracy: 89.45%\n",
            "Epoch: 40, Step: 67/164, Loss: 0.318027, Accuracy: 89.45%\n",
            "Epoch: 40, Step: 68/164, Loss: 0.319004, Accuracy: 89.41%\n",
            "Epoch: 40, Step: 69/164, Loss: 0.320302, Accuracy: 89.33%\n",
            "Epoch: 40, Step: 70/164, Loss: 0.320278, Accuracy: 89.34%\n",
            "Epoch: 40, Step: 71/164, Loss: 0.319150, Accuracy: 89.38%\n",
            "Epoch: 40, Step: 72/164, Loss: 0.319774, Accuracy: 89.36%\n",
            "Epoch: 40, Step: 73/164, Loss: 0.319101, Accuracy: 89.36%\n",
            "Epoch: 40, Step: 74/164, Loss: 0.320686, Accuracy: 89.29%\n",
            "Epoch: 40, Step: 75/164, Loss: 0.319701, Accuracy: 89.31%\n",
            "Epoch: 40, Step: 76/164, Loss: 0.318646, Accuracy: 89.33%\n",
            "Epoch: 40, Step: 77/164, Loss: 0.319021, Accuracy: 89.33%\n",
            "Epoch: 40, Step: 78/164, Loss: 0.320749, Accuracy: 89.28%\n",
            "Epoch: 40, Step: 79/164, Loss: 0.320372, Accuracy: 89.27%\n",
            "Epoch: 40, Step: 80/164, Loss: 0.320355, Accuracy: 89.28%\n",
            "Epoch: 40, Step: 81/164, Loss: 0.320085, Accuracy: 89.26%\n",
            "Epoch: 40, Step: 82/164, Loss: 0.319907, Accuracy: 89.24%\n",
            "Epoch: 40, Step: 83/164, Loss: 0.321217, Accuracy: 89.20%\n",
            "Epoch: 40, Step: 84/164, Loss: 0.320591, Accuracy: 89.24%\n",
            "Epoch: 40, Step: 85/164, Loss: 0.319982, Accuracy: 89.24%\n",
            "Epoch: 40, Step: 86/164, Loss: 0.319218, Accuracy: 89.27%\n",
            "Epoch: 40, Step: 87/164, Loss: 0.319550, Accuracy: 89.27%\n",
            "Epoch: 40, Step: 88/164, Loss: 0.320478, Accuracy: 89.22%\n",
            "Epoch: 40, Step: 89/164, Loss: 0.321876, Accuracy: 89.19%\n",
            "Epoch: 40, Step: 90/164, Loss: 0.322259, Accuracy: 89.18%\n",
            "Epoch: 40, Step: 91/164, Loss: 0.324031, Accuracy: 89.14%\n",
            "Epoch: 40, Step: 92/164, Loss: 0.325154, Accuracy: 89.11%\n",
            "Epoch: 40, Step: 93/164, Loss: 0.325282, Accuracy: 89.14%\n",
            "Epoch: 40, Step: 94/164, Loss: 0.326063, Accuracy: 89.13%\n",
            "Epoch: 40, Step: 95/164, Loss: 0.327820, Accuracy: 89.06%\n",
            "Epoch: 40, Step: 96/164, Loss: 0.330347, Accuracy: 89.00%\n",
            "Epoch: 40, Step: 97/164, Loss: 0.329617, Accuracy: 89.02%\n",
            "Epoch: 40, Step: 98/164, Loss: 0.328550, Accuracy: 89.05%\n",
            "Epoch: 40, Step: 99/164, Loss: 0.328317, Accuracy: 89.06%\n",
            "Epoch: 40, Step: 100/164, Loss: 0.329222, Accuracy: 89.05%\n",
            "Epoch: 40, Step: 101/164, Loss: 0.329266, Accuracy: 89.02%\n",
            "Epoch: 40, Step: 102/164, Loss: 0.329044, Accuracy: 89.01%\n",
            "Epoch: 40, Step: 103/164, Loss: 0.329157, Accuracy: 88.99%\n",
            "Epoch: 40, Step: 104/164, Loss: 0.329829, Accuracy: 88.95%\n",
            "Epoch: 40, Step: 105/164, Loss: 0.331299, Accuracy: 88.91%\n",
            "Epoch: 40, Step: 106/164, Loss: 0.331004, Accuracy: 88.94%\n",
            "Epoch: 40, Step: 107/164, Loss: 0.331184, Accuracy: 88.92%\n",
            "Epoch: 40, Step: 108/164, Loss: 0.331218, Accuracy: 88.90%\n",
            "Epoch: 40, Step: 109/164, Loss: 0.331370, Accuracy: 88.91%\n",
            "Epoch: 40, Step: 110/164, Loss: 0.331101, Accuracy: 88.91%\n",
            "Epoch: 40, Step: 111/164, Loss: 0.330523, Accuracy: 88.94%\n",
            "Epoch: 40, Step: 112/164, Loss: 0.329361, Accuracy: 88.99%\n",
            "Epoch: 40, Step: 113/164, Loss: 0.329279, Accuracy: 88.99%\n",
            "Epoch: 40, Step: 114/164, Loss: 0.328819, Accuracy: 88.99%\n",
            "Epoch: 40, Step: 115/164, Loss: 0.328685, Accuracy: 89.00%\n",
            "Epoch: 40, Step: 116/164, Loss: 0.327849, Accuracy: 89.04%\n",
            "Epoch: 40, Step: 117/164, Loss: 0.327065, Accuracy: 89.06%\n",
            "Epoch: 40, Step: 118/164, Loss: 0.326656, Accuracy: 89.06%\n",
            "Epoch: 40, Step: 119/164, Loss: 0.326632, Accuracy: 89.06%\n",
            "Epoch: 40, Step: 120/164, Loss: 0.326536, Accuracy: 89.06%\n",
            "Epoch: 40, Step: 121/164, Loss: 0.327049, Accuracy: 89.04%\n",
            "Epoch: 40, Step: 122/164, Loss: 0.327442, Accuracy: 89.01%\n",
            "Epoch: 40, Step: 123/164, Loss: 0.327800, Accuracy: 89.02%\n",
            "Epoch: 40, Step: 124/164, Loss: 0.328532, Accuracy: 88.99%\n",
            "Epoch: 40, Step: 125/164, Loss: 0.328242, Accuracy: 89.00%\n",
            "Epoch: 40, Step: 126/164, Loss: 0.327720, Accuracy: 89.02%\n",
            "Epoch: 40, Step: 127/164, Loss: 0.327339, Accuracy: 89.03%\n",
            "Epoch: 40, Step: 128/164, Loss: 0.326140, Accuracy: 89.06%\n",
            "Epoch: 40, Step: 129/164, Loss: 0.326092, Accuracy: 89.05%\n",
            "Epoch: 40, Step: 130/164, Loss: 0.325933, Accuracy: 89.06%\n",
            "Epoch: 40, Step: 131/164, Loss: 0.325967, Accuracy: 89.07%\n",
            "Epoch: 40, Step: 132/164, Loss: 0.325913, Accuracy: 89.07%\n",
            "Epoch: 40, Step: 133/164, Loss: 0.327006, Accuracy: 89.04%\n",
            "Epoch: 40, Step: 134/164, Loss: 0.326541, Accuracy: 89.08%\n",
            "Epoch: 40, Step: 135/164, Loss: 0.326609, Accuracy: 89.09%\n",
            "Epoch: 40, Step: 136/164, Loss: 0.326544, Accuracy: 89.10%\n",
            "Epoch: 40, Step: 137/164, Loss: 0.326622, Accuracy: 89.10%\n",
            "Epoch: 40, Step: 138/164, Loss: 0.326397, Accuracy: 89.11%\n",
            "Epoch: 40, Step: 139/164, Loss: 0.326526, Accuracy: 89.09%\n",
            "Epoch: 40, Step: 140/164, Loss: 0.326981, Accuracy: 89.07%\n",
            "Epoch: 40, Step: 141/164, Loss: 0.326361, Accuracy: 89.10%\n",
            "Epoch: 40, Step: 142/164, Loss: 0.326689, Accuracy: 89.07%\n",
            "Epoch: 40, Step: 143/164, Loss: 0.326287, Accuracy: 89.09%\n",
            "Epoch: 40, Step: 144/164, Loss: 0.326385, Accuracy: 89.11%\n",
            "Epoch: 40, Step: 145/164, Loss: 0.326185, Accuracy: 89.11%\n",
            "Epoch: 40, Step: 146/164, Loss: 0.326060, Accuracy: 89.11%\n",
            "Epoch: 40, Step: 147/164, Loss: 0.326003, Accuracy: 89.12%\n",
            "Epoch: 40, Step: 148/164, Loss: 0.325393, Accuracy: 89.12%\n",
            "Epoch: 40, Step: 149/164, Loss: 0.325211, Accuracy: 89.13%\n",
            "Epoch: 40, Step: 150/164, Loss: 0.325590, Accuracy: 89.12%\n",
            "Epoch: 40, Step: 151/164, Loss: 0.326324, Accuracy: 89.09%\n",
            "Epoch: 40, Step: 152/164, Loss: 0.326783, Accuracy: 89.08%\n",
            "Epoch: 40, Step: 153/164, Loss: 0.327890, Accuracy: 89.04%\n",
            "Epoch: 40, Step: 154/164, Loss: 0.328442, Accuracy: 89.04%\n",
            "Epoch: 40, Step: 155/164, Loss: 0.328446, Accuracy: 89.04%\n",
            "Epoch: 40, Step: 156/164, Loss: 0.328203, Accuracy: 89.05%\n",
            "Epoch: 40, Step: 157/164, Loss: 0.327982, Accuracy: 89.05%\n",
            "Epoch: 40, Step: 158/164, Loss: 0.327598, Accuracy: 89.07%\n",
            "Epoch: 40, Step: 159/164, Loss: 0.327568, Accuracy: 89.05%\n",
            "Epoch: 40, Step: 160/164, Loss: 0.326950, Accuracy: 89.09%\n",
            "Epoch: 40, Step: 161/164, Loss: 0.327214, Accuracy: 89.09%\n",
            "Epoch: 40, Step: 162/164, Loss: 0.327111, Accuracy: 89.08%\n",
            "Epoch: 40, Step: 163/164, Loss: 0.327588, Accuracy: 89.06%\n",
            "Epoch: 40, Step: 164/164, Loss: 0.327251, Accuracy: 89.07%\n",
            "Epoch: 41, Step: 1/164, Loss: 0.241165, Accuracy: 92.19%\n",
            "Epoch: 41, Step: 2/164, Loss: 0.266213, Accuracy: 91.02%\n",
            "Epoch: 41, Step: 3/164, Loss: 0.297642, Accuracy: 89.84%\n",
            "Epoch: 41, Step: 4/164, Loss: 0.271449, Accuracy: 91.21%\n",
            "Epoch: 41, Step: 5/164, Loss: 0.275024, Accuracy: 91.09%\n",
            "Epoch: 41, Step: 6/164, Loss: 0.288996, Accuracy: 90.36%\n",
            "Epoch: 41, Step: 7/164, Loss: 0.287685, Accuracy: 90.40%\n",
            "Epoch: 41, Step: 8/164, Loss: 0.294354, Accuracy: 89.55%\n",
            "Epoch: 41, Step: 9/164, Loss: 0.279912, Accuracy: 90.02%\n",
            "Epoch: 41, Step: 10/164, Loss: 0.283892, Accuracy: 89.77%\n",
            "Epoch: 41, Step: 11/164, Loss: 0.290950, Accuracy: 89.56%\n",
            "Epoch: 41, Step: 12/164, Loss: 0.302118, Accuracy: 89.06%\n",
            "Epoch: 41, Step: 13/164, Loss: 0.299093, Accuracy: 89.12%\n",
            "Epoch: 41, Step: 14/164, Loss: 0.296807, Accuracy: 89.17%\n",
            "Epoch: 41, Step: 15/164, Loss: 0.298671, Accuracy: 89.01%\n",
            "Epoch: 41, Step: 16/164, Loss: 0.301751, Accuracy: 88.77%\n",
            "Epoch: 41, Step: 17/164, Loss: 0.303734, Accuracy: 88.65%\n",
            "Epoch: 41, Step: 18/164, Loss: 0.304270, Accuracy: 88.59%\n",
            "Epoch: 41, Step: 19/164, Loss: 0.300303, Accuracy: 88.82%\n",
            "Epoch: 41, Step: 20/164, Loss: 0.303346, Accuracy: 88.63%\n",
            "Epoch: 41, Step: 21/164, Loss: 0.300289, Accuracy: 88.80%\n",
            "Epoch: 41, Step: 22/164, Loss: 0.300368, Accuracy: 88.74%\n",
            "Epoch: 41, Step: 23/164, Loss: 0.301047, Accuracy: 88.76%\n",
            "Epoch: 41, Step: 24/164, Loss: 0.304357, Accuracy: 88.74%\n",
            "Epoch: 41, Step: 25/164, Loss: 0.304003, Accuracy: 88.84%\n",
            "Epoch: 41, Step: 26/164, Loss: 0.307386, Accuracy: 88.73%\n",
            "Epoch: 41, Step: 27/164, Loss: 0.307326, Accuracy: 88.63%\n",
            "Epoch: 41, Step: 28/164, Loss: 0.308307, Accuracy: 88.64%\n",
            "Epoch: 41, Step: 29/164, Loss: 0.310734, Accuracy: 88.55%\n",
            "Epoch: 41, Step: 30/164, Loss: 0.310236, Accuracy: 88.59%\n",
            "Epoch: 41, Step: 31/164, Loss: 0.309878, Accuracy: 88.71%\n",
            "Epoch: 41, Step: 32/164, Loss: 0.312310, Accuracy: 88.67%\n",
            "Epoch: 41, Step: 33/164, Loss: 0.307782, Accuracy: 88.83%\n",
            "Epoch: 41, Step: 34/164, Loss: 0.310320, Accuracy: 88.81%\n",
            "Epoch: 41, Step: 35/164, Loss: 0.310828, Accuracy: 88.84%\n",
            "Epoch: 41, Step: 36/164, Loss: 0.310419, Accuracy: 88.89%\n",
            "Epoch: 41, Step: 37/164, Loss: 0.309675, Accuracy: 89.00%\n",
            "Epoch: 41, Step: 38/164, Loss: 0.312644, Accuracy: 88.88%\n",
            "Epoch: 41, Step: 39/164, Loss: 0.314088, Accuracy: 88.74%\n",
            "Epoch: 41, Step: 40/164, Loss: 0.314987, Accuracy: 88.73%\n",
            "Epoch: 41, Step: 41/164, Loss: 0.316007, Accuracy: 88.72%\n",
            "Epoch: 41, Step: 42/164, Loss: 0.314933, Accuracy: 88.75%\n",
            "Epoch: 41, Step: 43/164, Loss: 0.315621, Accuracy: 88.79%\n",
            "Epoch: 41, Step: 44/164, Loss: 0.313656, Accuracy: 88.87%\n",
            "Epoch: 41, Step: 45/164, Loss: 0.314621, Accuracy: 88.84%\n",
            "Epoch: 41, Step: 46/164, Loss: 0.314094, Accuracy: 88.88%\n",
            "Epoch: 41, Step: 47/164, Loss: 0.313919, Accuracy: 88.91%\n",
            "Epoch: 41, Step: 48/164, Loss: 0.315107, Accuracy: 88.88%\n",
            "Epoch: 41, Step: 49/164, Loss: 0.313748, Accuracy: 88.95%\n",
            "Epoch: 41, Step: 50/164, Loss: 0.314022, Accuracy: 88.95%\n",
            "Epoch: 41, Step: 51/164, Loss: 0.314908, Accuracy: 88.86%\n",
            "Epoch: 41, Step: 52/164, Loss: 0.314212, Accuracy: 88.91%\n",
            "Epoch: 41, Step: 53/164, Loss: 0.314164, Accuracy: 88.94%\n",
            "Epoch: 41, Step: 54/164, Loss: 0.315091, Accuracy: 88.95%\n",
            "Epoch: 41, Step: 55/164, Loss: 0.314580, Accuracy: 88.99%\n",
            "Epoch: 41, Step: 56/164, Loss: 0.316457, Accuracy: 88.92%\n",
            "Epoch: 41, Step: 57/164, Loss: 0.314223, Accuracy: 88.98%\n",
            "Epoch: 41, Step: 58/164, Loss: 0.314479, Accuracy: 88.98%\n",
            "Epoch: 41, Step: 59/164, Loss: 0.314050, Accuracy: 89.02%\n",
            "Epoch: 41, Step: 60/164, Loss: 0.312803, Accuracy: 89.11%\n",
            "Epoch: 41, Step: 61/164, Loss: 0.313039, Accuracy: 89.13%\n",
            "Epoch: 41, Step: 62/164, Loss: 0.313527, Accuracy: 89.13%\n",
            "Epoch: 41, Step: 63/164, Loss: 0.314030, Accuracy: 89.11%\n",
            "Epoch: 41, Step: 64/164, Loss: 0.315981, Accuracy: 89.06%\n",
            "Epoch: 41, Step: 65/164, Loss: 0.315109, Accuracy: 89.12%\n",
            "Epoch: 41, Step: 66/164, Loss: 0.313560, Accuracy: 89.17%\n",
            "Epoch: 41, Step: 67/164, Loss: 0.314214, Accuracy: 89.16%\n",
            "Epoch: 41, Step: 68/164, Loss: 0.312932, Accuracy: 89.23%\n",
            "Epoch: 41, Step: 69/164, Loss: 0.311560, Accuracy: 89.31%\n",
            "Epoch: 41, Step: 70/164, Loss: 0.312697, Accuracy: 89.29%\n",
            "Epoch: 41, Step: 71/164, Loss: 0.311624, Accuracy: 89.30%\n",
            "Epoch: 41, Step: 72/164, Loss: 0.313720, Accuracy: 89.28%\n",
            "Epoch: 41, Step: 73/164, Loss: 0.314833, Accuracy: 89.24%\n",
            "Epoch: 41, Step: 74/164, Loss: 0.316400, Accuracy: 89.19%\n",
            "Epoch: 41, Step: 75/164, Loss: 0.316591, Accuracy: 89.21%\n",
            "Epoch: 41, Step: 76/164, Loss: 0.316245, Accuracy: 89.24%\n",
            "Epoch: 41, Step: 77/164, Loss: 0.315382, Accuracy: 89.28%\n",
            "Epoch: 41, Step: 78/164, Loss: 0.315310, Accuracy: 89.29%\n",
            "Epoch: 41, Step: 79/164, Loss: 0.315353, Accuracy: 89.30%\n",
            "Epoch: 41, Step: 80/164, Loss: 0.313959, Accuracy: 89.38%\n",
            "Epoch: 41, Step: 81/164, Loss: 0.312930, Accuracy: 89.44%\n",
            "Epoch: 41, Step: 82/164, Loss: 0.313853, Accuracy: 89.42%\n",
            "Epoch: 41, Step: 83/164, Loss: 0.314394, Accuracy: 89.38%\n",
            "Epoch: 41, Step: 84/164, Loss: 0.314356, Accuracy: 89.40%\n",
            "Epoch: 41, Step: 85/164, Loss: 0.314025, Accuracy: 89.37%\n",
            "Epoch: 41, Step: 86/164, Loss: 0.314172, Accuracy: 89.34%\n",
            "Epoch: 41, Step: 87/164, Loss: 0.315358, Accuracy: 89.30%\n",
            "Epoch: 41, Step: 88/164, Loss: 0.314458, Accuracy: 89.34%\n",
            "Epoch: 41, Step: 89/164, Loss: 0.312694, Accuracy: 89.41%\n",
            "Epoch: 41, Step: 90/164, Loss: 0.312973, Accuracy: 89.39%\n",
            "Epoch: 41, Step: 91/164, Loss: 0.312989, Accuracy: 89.38%\n",
            "Epoch: 41, Step: 92/164, Loss: 0.313318, Accuracy: 89.39%\n",
            "Epoch: 41, Step: 93/164, Loss: 0.313423, Accuracy: 89.35%\n",
            "Epoch: 41, Step: 94/164, Loss: 0.313397, Accuracy: 89.36%\n",
            "Epoch: 41, Step: 95/164, Loss: 0.313028, Accuracy: 89.38%\n",
            "Epoch: 41, Step: 96/164, Loss: 0.312891, Accuracy: 89.36%\n",
            "Epoch: 41, Step: 97/164, Loss: 0.313654, Accuracy: 89.31%\n",
            "Epoch: 41, Step: 98/164, Loss: 0.314163, Accuracy: 89.29%\n",
            "Epoch: 41, Step: 99/164, Loss: 0.314374, Accuracy: 89.28%\n",
            "Epoch: 41, Step: 100/164, Loss: 0.314042, Accuracy: 89.30%\n",
            "Epoch: 41, Step: 101/164, Loss: 0.313782, Accuracy: 89.29%\n",
            "Epoch: 41, Step: 102/164, Loss: 0.313400, Accuracy: 89.32%\n",
            "Epoch: 41, Step: 103/164, Loss: 0.313573, Accuracy: 89.31%\n",
            "Epoch: 41, Step: 104/164, Loss: 0.313140, Accuracy: 89.32%\n",
            "Epoch: 41, Step: 105/164, Loss: 0.313734, Accuracy: 89.30%\n",
            "Epoch: 41, Step: 106/164, Loss: 0.314329, Accuracy: 89.29%\n",
            "Epoch: 41, Step: 107/164, Loss: 0.314055, Accuracy: 89.30%\n",
            "Epoch: 41, Step: 108/164, Loss: 0.314898, Accuracy: 89.27%\n",
            "Epoch: 41, Step: 109/164, Loss: 0.315186, Accuracy: 89.23%\n",
            "Epoch: 41, Step: 110/164, Loss: 0.314720, Accuracy: 89.26%\n",
            "Epoch: 41, Step: 111/164, Loss: 0.315116, Accuracy: 89.26%\n",
            "Epoch: 41, Step: 112/164, Loss: 0.315926, Accuracy: 89.22%\n",
            "Epoch: 41, Step: 113/164, Loss: 0.316655, Accuracy: 89.19%\n",
            "Epoch: 41, Step: 114/164, Loss: 0.316474, Accuracy: 89.19%\n",
            "Epoch: 41, Step: 115/164, Loss: 0.317765, Accuracy: 89.13%\n",
            "Epoch: 41, Step: 116/164, Loss: 0.317928, Accuracy: 89.11%\n",
            "Epoch: 41, Step: 117/164, Loss: 0.317083, Accuracy: 89.16%\n",
            "Epoch: 41, Step: 118/164, Loss: 0.316884, Accuracy: 89.18%\n",
            "Epoch: 41, Step: 119/164, Loss: 0.317430, Accuracy: 89.15%\n",
            "Epoch: 41, Step: 120/164, Loss: 0.317870, Accuracy: 89.12%\n",
            "Epoch: 41, Step: 121/164, Loss: 0.318481, Accuracy: 89.10%\n",
            "Epoch: 41, Step: 122/164, Loss: 0.317850, Accuracy: 89.13%\n",
            "Epoch: 41, Step: 123/164, Loss: 0.318823, Accuracy: 89.10%\n",
            "Epoch: 41, Step: 124/164, Loss: 0.319131, Accuracy: 89.09%\n",
            "Epoch: 41, Step: 125/164, Loss: 0.319563, Accuracy: 89.09%\n",
            "Epoch: 41, Step: 126/164, Loss: 0.319971, Accuracy: 89.08%\n",
            "Epoch: 41, Step: 127/164, Loss: 0.319248, Accuracy: 89.09%\n",
            "Epoch: 41, Step: 128/164, Loss: 0.320109, Accuracy: 89.07%\n",
            "Epoch: 41, Step: 129/164, Loss: 0.320170, Accuracy: 89.08%\n",
            "Epoch: 41, Step: 130/164, Loss: 0.319880, Accuracy: 89.11%\n",
            "Epoch: 41, Step: 131/164, Loss: 0.319776, Accuracy: 89.11%\n",
            "Epoch: 41, Step: 132/164, Loss: 0.319477, Accuracy: 89.11%\n",
            "Epoch: 41, Step: 133/164, Loss: 0.319734, Accuracy: 89.12%\n",
            "Epoch: 41, Step: 134/164, Loss: 0.319887, Accuracy: 89.10%\n",
            "Epoch: 41, Step: 135/164, Loss: 0.319446, Accuracy: 89.11%\n",
            "Epoch: 41, Step: 136/164, Loss: 0.319236, Accuracy: 89.11%\n",
            "Epoch: 41, Step: 137/164, Loss: 0.318562, Accuracy: 89.14%\n",
            "Epoch: 41, Step: 138/164, Loss: 0.318691, Accuracy: 89.15%\n",
            "Epoch: 41, Step: 139/164, Loss: 0.319226, Accuracy: 89.14%\n",
            "Epoch: 41, Step: 140/164, Loss: 0.319852, Accuracy: 89.13%\n",
            "Epoch: 41, Step: 141/164, Loss: 0.320302, Accuracy: 89.12%\n",
            "Epoch: 41, Step: 142/164, Loss: 0.320446, Accuracy: 89.08%\n",
            "Epoch: 41, Step: 143/164, Loss: 0.320346, Accuracy: 89.09%\n",
            "Epoch: 41, Step: 144/164, Loss: 0.320033, Accuracy: 89.09%\n",
            "Epoch: 41, Step: 145/164, Loss: 0.319859, Accuracy: 89.10%\n",
            "Epoch: 41, Step: 146/164, Loss: 0.319637, Accuracy: 89.11%\n",
            "Epoch: 41, Step: 147/164, Loss: 0.319800, Accuracy: 89.12%\n",
            "Epoch: 41, Step: 148/164, Loss: 0.319797, Accuracy: 89.11%\n",
            "Epoch: 41, Step: 149/164, Loss: 0.319708, Accuracy: 89.10%\n",
            "Epoch: 41, Step: 150/164, Loss: 0.318821, Accuracy: 89.14%\n",
            "Epoch: 41, Step: 151/164, Loss: 0.319560, Accuracy: 89.11%\n",
            "Epoch: 41, Step: 152/164, Loss: 0.319584, Accuracy: 89.11%\n",
            "Epoch: 41, Step: 153/164, Loss: 0.320001, Accuracy: 89.12%\n",
            "Epoch: 41, Step: 154/164, Loss: 0.320286, Accuracy: 89.11%\n",
            "Epoch: 41, Step: 155/164, Loss: 0.319782, Accuracy: 89.12%\n",
            "Epoch: 41, Step: 156/164, Loss: 0.319242, Accuracy: 89.14%\n",
            "Epoch: 41, Step: 157/164, Loss: 0.319740, Accuracy: 89.11%\n",
            "Epoch: 41, Step: 158/164, Loss: 0.319748, Accuracy: 89.12%\n",
            "Epoch: 41, Step: 159/164, Loss: 0.320780, Accuracy: 89.09%\n",
            "Epoch: 41, Step: 160/164, Loss: 0.321795, Accuracy: 89.07%\n",
            "Epoch: 41, Step: 161/164, Loss: 0.321787, Accuracy: 89.04%\n",
            "Epoch: 41, Step: 162/164, Loss: 0.322625, Accuracy: 89.00%\n",
            "Epoch: 41, Step: 163/164, Loss: 0.322413, Accuracy: 89.00%\n",
            "Epoch: 41, Step: 164/164, Loss: 0.325009, Accuracy: 88.95%\n",
            "Epoch: 42, Step: 1/164, Loss: 0.248874, Accuracy: 92.19%\n",
            "Epoch: 42, Step: 2/164, Loss: 0.313558, Accuracy: 90.62%\n",
            "Epoch: 42, Step: 3/164, Loss: 0.303662, Accuracy: 90.62%\n",
            "Epoch: 42, Step: 4/164, Loss: 0.354100, Accuracy: 88.48%\n",
            "Epoch: 42, Step: 5/164, Loss: 0.318839, Accuracy: 89.84%\n",
            "Epoch: 42, Step: 6/164, Loss: 0.306340, Accuracy: 90.36%\n",
            "Epoch: 42, Step: 7/164, Loss: 0.333917, Accuracy: 89.51%\n",
            "Epoch: 42, Step: 8/164, Loss: 0.344557, Accuracy: 89.26%\n",
            "Epoch: 42, Step: 9/164, Loss: 0.346870, Accuracy: 89.15%\n",
            "Epoch: 42, Step: 10/164, Loss: 0.346877, Accuracy: 88.98%\n",
            "Epoch: 42, Step: 11/164, Loss: 0.354897, Accuracy: 88.78%\n",
            "Epoch: 42, Step: 12/164, Loss: 0.348449, Accuracy: 89.13%\n",
            "Epoch: 42, Step: 13/164, Loss: 0.350389, Accuracy: 88.88%\n",
            "Epoch: 42, Step: 14/164, Loss: 0.351991, Accuracy: 88.73%\n",
            "Epoch: 42, Step: 15/164, Loss: 0.346316, Accuracy: 89.11%\n",
            "Epoch: 42, Step: 16/164, Loss: 0.351242, Accuracy: 88.96%\n",
            "Epoch: 42, Step: 17/164, Loss: 0.345101, Accuracy: 89.02%\n",
            "Epoch: 42, Step: 18/164, Loss: 0.343721, Accuracy: 89.11%\n",
            "Epoch: 42, Step: 19/164, Loss: 0.342089, Accuracy: 89.06%\n",
            "Epoch: 42, Step: 20/164, Loss: 0.347095, Accuracy: 88.79%\n",
            "Epoch: 42, Step: 21/164, Loss: 0.350243, Accuracy: 88.65%\n",
            "Epoch: 42, Step: 22/164, Loss: 0.350088, Accuracy: 88.57%\n",
            "Epoch: 42, Step: 23/164, Loss: 0.350269, Accuracy: 88.55%\n",
            "Epoch: 42, Step: 24/164, Loss: 0.351740, Accuracy: 88.48%\n",
            "Epoch: 42, Step: 25/164, Loss: 0.351609, Accuracy: 88.44%\n",
            "Epoch: 42, Step: 26/164, Loss: 0.349111, Accuracy: 88.46%\n",
            "Epoch: 42, Step: 27/164, Loss: 0.345882, Accuracy: 88.60%\n",
            "Epoch: 42, Step: 28/164, Loss: 0.343105, Accuracy: 88.67%\n",
            "Epoch: 42, Step: 29/164, Loss: 0.340080, Accuracy: 88.71%\n",
            "Epoch: 42, Step: 30/164, Loss: 0.340151, Accuracy: 88.62%\n",
            "Epoch: 42, Step: 31/164, Loss: 0.343087, Accuracy: 88.51%\n",
            "Epoch: 42, Step: 32/164, Loss: 0.345157, Accuracy: 88.40%\n",
            "Epoch: 42, Step: 33/164, Loss: 0.347305, Accuracy: 88.40%\n",
            "Epoch: 42, Step: 34/164, Loss: 0.346671, Accuracy: 88.51%\n",
            "Epoch: 42, Step: 35/164, Loss: 0.342413, Accuracy: 88.64%\n",
            "Epoch: 42, Step: 36/164, Loss: 0.344199, Accuracy: 88.52%\n",
            "Epoch: 42, Step: 37/164, Loss: 0.342564, Accuracy: 88.53%\n",
            "Epoch: 42, Step: 38/164, Loss: 0.341260, Accuracy: 88.55%\n",
            "Epoch: 42, Step: 39/164, Loss: 0.342902, Accuracy: 88.46%\n",
            "Epoch: 42, Step: 40/164, Loss: 0.341174, Accuracy: 88.55%\n",
            "Epoch: 42, Step: 41/164, Loss: 0.341094, Accuracy: 88.59%\n",
            "Epoch: 42, Step: 42/164, Loss: 0.342767, Accuracy: 88.56%\n",
            "Epoch: 42, Step: 43/164, Loss: 0.339871, Accuracy: 88.63%\n",
            "Epoch: 42, Step: 44/164, Loss: 0.342258, Accuracy: 88.49%\n",
            "Epoch: 42, Step: 45/164, Loss: 0.342141, Accuracy: 88.49%\n",
            "Epoch: 42, Step: 46/164, Loss: 0.340449, Accuracy: 88.49%\n",
            "Epoch: 42, Step: 47/164, Loss: 0.338262, Accuracy: 88.56%\n",
            "Epoch: 42, Step: 48/164, Loss: 0.337424, Accuracy: 88.57%\n",
            "Epoch: 42, Step: 49/164, Loss: 0.340995, Accuracy: 88.44%\n",
            "Epoch: 42, Step: 50/164, Loss: 0.340115, Accuracy: 88.47%\n",
            "Epoch: 42, Step: 51/164, Loss: 0.341796, Accuracy: 88.45%\n",
            "Epoch: 42, Step: 52/164, Loss: 0.342198, Accuracy: 88.46%\n",
            "Epoch: 42, Step: 53/164, Loss: 0.340896, Accuracy: 88.53%\n",
            "Epoch: 42, Step: 54/164, Loss: 0.342185, Accuracy: 88.50%\n",
            "Epoch: 42, Step: 55/164, Loss: 0.344325, Accuracy: 88.47%\n",
            "Epoch: 42, Step: 56/164, Loss: 0.343779, Accuracy: 88.52%\n",
            "Epoch: 42, Step: 57/164, Loss: 0.346637, Accuracy: 88.40%\n",
            "Epoch: 42, Step: 58/164, Loss: 0.346931, Accuracy: 88.40%\n",
            "Epoch: 42, Step: 59/164, Loss: 0.345124, Accuracy: 88.44%\n",
            "Epoch: 42, Step: 60/164, Loss: 0.344666, Accuracy: 88.44%\n",
            "Epoch: 42, Step: 61/164, Loss: 0.345405, Accuracy: 88.43%\n",
            "Epoch: 42, Step: 62/164, Loss: 0.345743, Accuracy: 88.43%\n",
            "Epoch: 42, Step: 63/164, Loss: 0.344352, Accuracy: 88.48%\n",
            "Epoch: 42, Step: 64/164, Loss: 0.344527, Accuracy: 88.54%\n",
            "Epoch: 42, Step: 65/164, Loss: 0.343924, Accuracy: 88.61%\n",
            "Epoch: 42, Step: 66/164, Loss: 0.344056, Accuracy: 88.66%\n",
            "Epoch: 42, Step: 67/164, Loss: 0.346243, Accuracy: 88.58%\n",
            "Epoch: 42, Step: 68/164, Loss: 0.345143, Accuracy: 88.64%\n",
            "Epoch: 42, Step: 69/164, Loss: 0.345192, Accuracy: 88.62%\n",
            "Epoch: 42, Step: 70/164, Loss: 0.345005, Accuracy: 88.60%\n",
            "Epoch: 42, Step: 71/164, Loss: 0.344898, Accuracy: 88.61%\n",
            "Epoch: 42, Step: 72/164, Loss: 0.344379, Accuracy: 88.63%\n",
            "Epoch: 42, Step: 73/164, Loss: 0.346375, Accuracy: 88.57%\n",
            "Epoch: 42, Step: 74/164, Loss: 0.345837, Accuracy: 88.60%\n",
            "Epoch: 42, Step: 75/164, Loss: 0.343828, Accuracy: 88.67%\n",
            "Epoch: 42, Step: 76/164, Loss: 0.343890, Accuracy: 88.65%\n",
            "Epoch: 42, Step: 77/164, Loss: 0.343507, Accuracy: 88.65%\n",
            "Epoch: 42, Step: 78/164, Loss: 0.342739, Accuracy: 88.66%\n",
            "Epoch: 42, Step: 79/164, Loss: 0.343027, Accuracy: 88.65%\n",
            "Epoch: 42, Step: 80/164, Loss: 0.341097, Accuracy: 88.72%\n",
            "Epoch: 42, Step: 81/164, Loss: 0.340238, Accuracy: 88.74%\n",
            "Epoch: 42, Step: 82/164, Loss: 0.340749, Accuracy: 88.71%\n",
            "Epoch: 42, Step: 83/164, Loss: 0.339957, Accuracy: 88.71%\n",
            "Epoch: 42, Step: 84/164, Loss: 0.340346, Accuracy: 88.70%\n",
            "Epoch: 42, Step: 85/164, Loss: 0.340295, Accuracy: 88.69%\n",
            "Epoch: 42, Step: 86/164, Loss: 0.340071, Accuracy: 88.72%\n",
            "Epoch: 42, Step: 87/164, Loss: 0.339361, Accuracy: 88.74%\n",
            "Epoch: 42, Step: 88/164, Loss: 0.340062, Accuracy: 88.71%\n",
            "Epoch: 42, Step: 89/164, Loss: 0.339079, Accuracy: 88.74%\n",
            "Epoch: 42, Step: 90/164, Loss: 0.339113, Accuracy: 88.74%\n",
            "Epoch: 42, Step: 91/164, Loss: 0.339359, Accuracy: 88.73%\n",
            "Epoch: 42, Step: 92/164, Loss: 0.338839, Accuracy: 88.75%\n",
            "Epoch: 42, Step: 93/164, Loss: 0.338681, Accuracy: 88.74%\n",
            "Epoch: 42, Step: 94/164, Loss: 0.339497, Accuracy: 88.72%\n",
            "Epoch: 42, Step: 95/164, Loss: 0.338549, Accuracy: 88.75%\n",
            "Epoch: 42, Step: 96/164, Loss: 0.339363, Accuracy: 88.70%\n",
            "Epoch: 42, Step: 97/164, Loss: 0.337688, Accuracy: 88.77%\n",
            "Epoch: 42, Step: 98/164, Loss: 0.336910, Accuracy: 88.80%\n",
            "Epoch: 42, Step: 99/164, Loss: 0.336837, Accuracy: 88.79%\n",
            "Epoch: 42, Step: 100/164, Loss: 0.335728, Accuracy: 88.83%\n",
            "Epoch: 42, Step: 101/164, Loss: 0.335352, Accuracy: 88.81%\n",
            "Epoch: 42, Step: 102/164, Loss: 0.335202, Accuracy: 88.81%\n",
            "Epoch: 42, Step: 103/164, Loss: 0.335053, Accuracy: 88.80%\n",
            "Epoch: 42, Step: 104/164, Loss: 0.336239, Accuracy: 88.78%\n",
            "Epoch: 42, Step: 105/164, Loss: 0.336644, Accuracy: 88.76%\n",
            "Epoch: 42, Step: 106/164, Loss: 0.335870, Accuracy: 88.79%\n",
            "Epoch: 42, Step: 107/164, Loss: 0.335380, Accuracy: 88.79%\n",
            "Epoch: 42, Step: 108/164, Loss: 0.335572, Accuracy: 88.79%\n",
            "Epoch: 42, Step: 109/164, Loss: 0.335577, Accuracy: 88.77%\n",
            "Epoch: 42, Step: 110/164, Loss: 0.335795, Accuracy: 88.76%\n",
            "Epoch: 42, Step: 111/164, Loss: 0.335985, Accuracy: 88.75%\n",
            "Epoch: 42, Step: 112/164, Loss: 0.336045, Accuracy: 88.76%\n",
            "Epoch: 42, Step: 113/164, Loss: 0.335753, Accuracy: 88.77%\n",
            "Epoch: 42, Step: 114/164, Loss: 0.335245, Accuracy: 88.76%\n",
            "Epoch: 42, Step: 115/164, Loss: 0.335887, Accuracy: 88.74%\n",
            "Epoch: 42, Step: 116/164, Loss: 0.336590, Accuracy: 88.72%\n",
            "Epoch: 42, Step: 117/164, Loss: 0.337127, Accuracy: 88.70%\n",
            "Epoch: 42, Step: 118/164, Loss: 0.336881, Accuracy: 88.69%\n",
            "Epoch: 42, Step: 119/164, Loss: 0.337635, Accuracy: 88.68%\n",
            "Epoch: 42, Step: 120/164, Loss: 0.337734, Accuracy: 88.67%\n",
            "Epoch: 42, Step: 121/164, Loss: 0.336965, Accuracy: 88.68%\n",
            "Epoch: 42, Step: 122/164, Loss: 0.337136, Accuracy: 88.67%\n",
            "Epoch: 42, Step: 123/164, Loss: 0.337492, Accuracy: 88.66%\n",
            "Epoch: 42, Step: 124/164, Loss: 0.337242, Accuracy: 88.66%\n",
            "Epoch: 42, Step: 125/164, Loss: 0.338553, Accuracy: 88.61%\n",
            "Epoch: 42, Step: 126/164, Loss: 0.338357, Accuracy: 88.61%\n",
            "Epoch: 42, Step: 127/164, Loss: 0.338465, Accuracy: 88.61%\n",
            "Epoch: 42, Step: 128/164, Loss: 0.337240, Accuracy: 88.65%\n",
            "Epoch: 42, Step: 129/164, Loss: 0.337601, Accuracy: 88.62%\n",
            "Epoch: 42, Step: 130/164, Loss: 0.337146, Accuracy: 88.64%\n",
            "Epoch: 42, Step: 131/164, Loss: 0.336578, Accuracy: 88.65%\n",
            "Epoch: 42, Step: 132/164, Loss: 0.336949, Accuracy: 88.63%\n",
            "Epoch: 42, Step: 133/164, Loss: 0.336532, Accuracy: 88.62%\n",
            "Epoch: 42, Step: 134/164, Loss: 0.337050, Accuracy: 88.61%\n",
            "Epoch: 42, Step: 135/164, Loss: 0.336644, Accuracy: 88.65%\n",
            "Epoch: 42, Step: 136/164, Loss: 0.336007, Accuracy: 88.67%\n",
            "Epoch: 42, Step: 137/164, Loss: 0.335727, Accuracy: 88.67%\n",
            "Epoch: 42, Step: 138/164, Loss: 0.335927, Accuracy: 88.65%\n",
            "Epoch: 42, Step: 139/164, Loss: 0.335267, Accuracy: 88.69%\n",
            "Epoch: 42, Step: 140/164, Loss: 0.335037, Accuracy: 88.70%\n",
            "Epoch: 42, Step: 141/164, Loss: 0.334962, Accuracy: 88.72%\n",
            "Epoch: 42, Step: 142/164, Loss: 0.335256, Accuracy: 88.71%\n",
            "Epoch: 42, Step: 143/164, Loss: 0.334824, Accuracy: 88.72%\n",
            "Epoch: 42, Step: 144/164, Loss: 0.334487, Accuracy: 88.74%\n",
            "Epoch: 42, Step: 145/164, Loss: 0.333699, Accuracy: 88.77%\n",
            "Epoch: 42, Step: 146/164, Loss: 0.333725, Accuracy: 88.77%\n",
            "Epoch: 42, Step: 147/164, Loss: 0.333459, Accuracy: 88.78%\n",
            "Epoch: 42, Step: 148/164, Loss: 0.333516, Accuracy: 88.76%\n",
            "Epoch: 42, Step: 149/164, Loss: 0.333242, Accuracy: 88.76%\n",
            "Epoch: 42, Step: 150/164, Loss: 0.333031, Accuracy: 88.76%\n",
            "Epoch: 42, Step: 151/164, Loss: 0.332797, Accuracy: 88.76%\n",
            "Epoch: 42, Step: 152/164, Loss: 0.332178, Accuracy: 88.78%\n",
            "Epoch: 42, Step: 153/164, Loss: 0.332177, Accuracy: 88.78%\n",
            "Epoch: 42, Step: 154/164, Loss: 0.331556, Accuracy: 88.79%\n",
            "Epoch: 42, Step: 155/164, Loss: 0.331674, Accuracy: 88.77%\n",
            "Epoch: 42, Step: 156/164, Loss: 0.332346, Accuracy: 88.75%\n",
            "Epoch: 42, Step: 157/164, Loss: 0.332096, Accuracy: 88.75%\n",
            "Epoch: 42, Step: 158/164, Loss: 0.331982, Accuracy: 88.76%\n",
            "Epoch: 42, Step: 159/164, Loss: 0.331702, Accuracy: 88.77%\n",
            "Epoch: 42, Step: 160/164, Loss: 0.331462, Accuracy: 88.77%\n",
            "Epoch: 42, Step: 161/164, Loss: 0.331912, Accuracy: 88.75%\n",
            "Epoch: 42, Step: 162/164, Loss: 0.330866, Accuracy: 88.79%\n",
            "Epoch: 42, Step: 163/164, Loss: 0.330590, Accuracy: 88.80%\n",
            "Epoch: 42, Step: 164/164, Loss: 0.330775, Accuracy: 88.80%\n",
            "Epoch: 43, Step: 1/164, Loss: 0.320898, Accuracy: 85.94%\n",
            "Epoch: 43, Step: 2/164, Loss: 0.297710, Accuracy: 88.28%\n",
            "Epoch: 43, Step: 3/164, Loss: 0.286325, Accuracy: 89.06%\n",
            "Epoch: 43, Step: 4/164, Loss: 0.311407, Accuracy: 88.67%\n",
            "Epoch: 43, Step: 5/164, Loss: 0.322400, Accuracy: 88.59%\n",
            "Epoch: 43, Step: 6/164, Loss: 0.346423, Accuracy: 87.76%\n",
            "Epoch: 43, Step: 7/164, Loss: 0.351780, Accuracy: 88.17%\n",
            "Epoch: 43, Step: 8/164, Loss: 0.332661, Accuracy: 88.77%\n",
            "Epoch: 43, Step: 9/164, Loss: 0.339009, Accuracy: 88.63%\n",
            "Epoch: 43, Step: 10/164, Loss: 0.331840, Accuracy: 88.91%\n",
            "Epoch: 43, Step: 11/164, Loss: 0.334111, Accuracy: 88.57%\n",
            "Epoch: 43, Step: 12/164, Loss: 0.335712, Accuracy: 88.54%\n",
            "Epoch: 43, Step: 13/164, Loss: 0.325735, Accuracy: 88.88%\n",
            "Epoch: 43, Step: 14/164, Loss: 0.332249, Accuracy: 88.67%\n",
            "Epoch: 43, Step: 15/164, Loss: 0.321064, Accuracy: 89.01%\n",
            "Epoch: 43, Step: 16/164, Loss: 0.326617, Accuracy: 88.82%\n",
            "Epoch: 43, Step: 17/164, Loss: 0.324464, Accuracy: 88.92%\n",
            "Epoch: 43, Step: 18/164, Loss: 0.325032, Accuracy: 88.80%\n",
            "Epoch: 43, Step: 19/164, Loss: 0.319324, Accuracy: 89.06%\n",
            "Epoch: 43, Step: 20/164, Loss: 0.318008, Accuracy: 89.10%\n",
            "Epoch: 43, Step: 21/164, Loss: 0.316649, Accuracy: 89.29%\n",
            "Epoch: 43, Step: 22/164, Loss: 0.316013, Accuracy: 89.28%\n",
            "Epoch: 43, Step: 23/164, Loss: 0.313705, Accuracy: 89.37%\n",
            "Epoch: 43, Step: 24/164, Loss: 0.315231, Accuracy: 89.39%\n",
            "Epoch: 43, Step: 25/164, Loss: 0.318654, Accuracy: 89.28%\n",
            "Epoch: 43, Step: 26/164, Loss: 0.321484, Accuracy: 89.15%\n",
            "Epoch: 43, Step: 27/164, Loss: 0.325328, Accuracy: 88.98%\n",
            "Epoch: 43, Step: 28/164, Loss: 0.327659, Accuracy: 88.95%\n",
            "Epoch: 43, Step: 29/164, Loss: 0.326097, Accuracy: 89.01%\n",
            "Epoch: 43, Step: 30/164, Loss: 0.328896, Accuracy: 88.91%\n",
            "Epoch: 43, Step: 31/164, Loss: 0.325704, Accuracy: 88.96%\n",
            "Epoch: 43, Step: 32/164, Loss: 0.320417, Accuracy: 89.18%\n",
            "Epoch: 43, Step: 33/164, Loss: 0.321356, Accuracy: 89.20%\n",
            "Epoch: 43, Step: 34/164, Loss: 0.322242, Accuracy: 89.13%\n",
            "Epoch: 43, Step: 35/164, Loss: 0.319701, Accuracy: 89.22%\n",
            "Epoch: 43, Step: 36/164, Loss: 0.322750, Accuracy: 89.21%\n",
            "Epoch: 43, Step: 37/164, Loss: 0.324328, Accuracy: 89.15%\n",
            "Epoch: 43, Step: 38/164, Loss: 0.322036, Accuracy: 89.17%\n",
            "Epoch: 43, Step: 39/164, Loss: 0.323125, Accuracy: 89.10%\n",
            "Epoch: 43, Step: 40/164, Loss: 0.321931, Accuracy: 89.18%\n",
            "Epoch: 43, Step: 41/164, Loss: 0.322089, Accuracy: 89.18%\n",
            "Epoch: 43, Step: 42/164, Loss: 0.320815, Accuracy: 89.17%\n",
            "Epoch: 43, Step: 43/164, Loss: 0.321262, Accuracy: 89.14%\n",
            "Epoch: 43, Step: 44/164, Loss: 0.318754, Accuracy: 89.20%\n",
            "Epoch: 43, Step: 45/164, Loss: 0.317130, Accuracy: 89.22%\n",
            "Epoch: 43, Step: 46/164, Loss: 0.316368, Accuracy: 89.32%\n",
            "Epoch: 43, Step: 47/164, Loss: 0.315414, Accuracy: 89.33%\n",
            "Epoch: 43, Step: 48/164, Loss: 0.313978, Accuracy: 89.37%\n",
            "Epoch: 43, Step: 49/164, Loss: 0.312494, Accuracy: 89.41%\n",
            "Epoch: 43, Step: 50/164, Loss: 0.312515, Accuracy: 89.47%\n",
            "Epoch: 43, Step: 51/164, Loss: 0.310372, Accuracy: 89.54%\n",
            "Epoch: 43, Step: 52/164, Loss: 0.310811, Accuracy: 89.53%\n",
            "Epoch: 43, Step: 53/164, Loss: 0.311045, Accuracy: 89.53%\n",
            "Epoch: 43, Step: 54/164, Loss: 0.309926, Accuracy: 89.66%\n",
            "Epoch: 43, Step: 55/164, Loss: 0.310266, Accuracy: 89.67%\n",
            "Epoch: 43, Step: 56/164, Loss: 0.311567, Accuracy: 89.61%\n",
            "Epoch: 43, Step: 57/164, Loss: 0.313009, Accuracy: 89.58%\n",
            "Epoch: 43, Step: 58/164, Loss: 0.312118, Accuracy: 89.56%\n",
            "Epoch: 43, Step: 59/164, Loss: 0.311018, Accuracy: 89.59%\n",
            "Epoch: 43, Step: 60/164, Loss: 0.311014, Accuracy: 89.61%\n",
            "Epoch: 43, Step: 61/164, Loss: 0.313474, Accuracy: 89.51%\n",
            "Epoch: 43, Step: 62/164, Loss: 0.313365, Accuracy: 89.50%\n",
            "Epoch: 43, Step: 63/164, Loss: 0.314099, Accuracy: 89.51%\n",
            "Epoch: 43, Step: 64/164, Loss: 0.312894, Accuracy: 89.55%\n",
            "Epoch: 43, Step: 65/164, Loss: 0.313342, Accuracy: 89.57%\n",
            "Epoch: 43, Step: 66/164, Loss: 0.313105, Accuracy: 89.58%\n",
            "Epoch: 43, Step: 67/164, Loss: 0.314856, Accuracy: 89.55%\n",
            "Epoch: 43, Step: 68/164, Loss: 0.315090, Accuracy: 89.52%\n",
            "Epoch: 43, Step: 69/164, Loss: 0.315636, Accuracy: 89.48%\n",
            "Epoch: 43, Step: 70/164, Loss: 0.316285, Accuracy: 89.45%\n",
            "Epoch: 43, Step: 71/164, Loss: 0.316316, Accuracy: 89.48%\n",
            "Epoch: 43, Step: 72/164, Loss: 0.318326, Accuracy: 89.44%\n",
            "Epoch: 43, Step: 73/164, Loss: 0.318237, Accuracy: 89.46%\n",
            "Epoch: 43, Step: 74/164, Loss: 0.316177, Accuracy: 89.55%\n",
            "Epoch: 43, Step: 75/164, Loss: 0.316311, Accuracy: 89.54%\n",
            "Epoch: 43, Step: 76/164, Loss: 0.315310, Accuracy: 89.59%\n",
            "Epoch: 43, Step: 77/164, Loss: 0.314204, Accuracy: 89.60%\n",
            "Epoch: 43, Step: 78/164, Loss: 0.313185, Accuracy: 89.65%\n",
            "Epoch: 43, Step: 79/164, Loss: 0.312410, Accuracy: 89.70%\n",
            "Epoch: 43, Step: 80/164, Loss: 0.313472, Accuracy: 89.62%\n",
            "Epoch: 43, Step: 81/164, Loss: 0.313116, Accuracy: 89.64%\n",
            "Epoch: 43, Step: 82/164, Loss: 0.313004, Accuracy: 89.62%\n",
            "Epoch: 43, Step: 83/164, Loss: 0.313420, Accuracy: 89.61%\n",
            "Epoch: 43, Step: 84/164, Loss: 0.313459, Accuracy: 89.61%\n",
            "Epoch: 43, Step: 85/164, Loss: 0.312496, Accuracy: 89.64%\n",
            "Epoch: 43, Step: 86/164, Loss: 0.312679, Accuracy: 89.66%\n",
            "Epoch: 43, Step: 87/164, Loss: 0.312557, Accuracy: 89.66%\n",
            "Epoch: 43, Step: 88/164, Loss: 0.311992, Accuracy: 89.70%\n",
            "Epoch: 43, Step: 89/164, Loss: 0.310828, Accuracy: 89.75%\n",
            "Epoch: 43, Step: 90/164, Loss: 0.310186, Accuracy: 89.76%\n",
            "Epoch: 43, Step: 91/164, Loss: 0.310289, Accuracy: 89.70%\n",
            "Epoch: 43, Step: 92/164, Loss: 0.311720, Accuracy: 89.70%\n",
            "Epoch: 43, Step: 93/164, Loss: 0.312283, Accuracy: 89.68%\n",
            "Epoch: 43, Step: 94/164, Loss: 0.311274, Accuracy: 89.69%\n",
            "Epoch: 43, Step: 95/164, Loss: 0.312408, Accuracy: 89.64%\n",
            "Epoch: 43, Step: 96/164, Loss: 0.313434, Accuracy: 89.62%\n",
            "Epoch: 43, Step: 97/164, Loss: 0.313565, Accuracy: 89.59%\n",
            "Epoch: 43, Step: 98/164, Loss: 0.313979, Accuracy: 89.56%\n",
            "Epoch: 43, Step: 99/164, Loss: 0.314530, Accuracy: 89.54%\n",
            "Epoch: 43, Step: 100/164, Loss: 0.314887, Accuracy: 89.53%\n",
            "Epoch: 43, Step: 101/164, Loss: 0.314190, Accuracy: 89.55%\n",
            "Epoch: 43, Step: 102/164, Loss: 0.315192, Accuracy: 89.53%\n",
            "Epoch: 43, Step: 103/164, Loss: 0.315872, Accuracy: 89.50%\n",
            "Epoch: 43, Step: 104/164, Loss: 0.315249, Accuracy: 89.53%\n",
            "Epoch: 43, Step: 105/164, Loss: 0.314283, Accuracy: 89.57%\n",
            "Epoch: 43, Step: 106/164, Loss: 0.313926, Accuracy: 89.60%\n",
            "Epoch: 43, Step: 107/164, Loss: 0.313133, Accuracy: 89.63%\n",
            "Epoch: 43, Step: 108/164, Loss: 0.313411, Accuracy: 89.62%\n",
            "Epoch: 43, Step: 109/164, Loss: 0.314803, Accuracy: 89.59%\n",
            "Epoch: 43, Step: 110/164, Loss: 0.313506, Accuracy: 89.62%\n",
            "Epoch: 43, Step: 111/164, Loss: 0.312607, Accuracy: 89.65%\n",
            "Epoch: 43, Step: 112/164, Loss: 0.312525, Accuracy: 89.63%\n",
            "Epoch: 43, Step: 113/164, Loss: 0.311650, Accuracy: 89.66%\n",
            "Epoch: 43, Step: 114/164, Loss: 0.310942, Accuracy: 89.68%\n",
            "Epoch: 43, Step: 115/164, Loss: 0.310384, Accuracy: 89.69%\n",
            "Epoch: 43, Step: 116/164, Loss: 0.310772, Accuracy: 89.69%\n",
            "Epoch: 43, Step: 117/164, Loss: 0.311329, Accuracy: 89.68%\n",
            "Epoch: 43, Step: 118/164, Loss: 0.310753, Accuracy: 89.70%\n",
            "Epoch: 43, Step: 119/164, Loss: 0.310304, Accuracy: 89.71%\n",
            "Epoch: 43, Step: 120/164, Loss: 0.310788, Accuracy: 89.69%\n",
            "Epoch: 43, Step: 121/164, Loss: 0.310313, Accuracy: 89.70%\n",
            "Epoch: 43, Step: 122/164, Loss: 0.310373, Accuracy: 89.68%\n",
            "Epoch: 43, Step: 123/164, Loss: 0.310817, Accuracy: 89.65%\n",
            "Epoch: 43, Step: 124/164, Loss: 0.310648, Accuracy: 89.66%\n",
            "Epoch: 43, Step: 125/164, Loss: 0.311615, Accuracy: 89.63%\n",
            "Epoch: 43, Step: 126/164, Loss: 0.311884, Accuracy: 89.61%\n",
            "Epoch: 43, Step: 127/164, Loss: 0.311323, Accuracy: 89.64%\n",
            "Epoch: 43, Step: 128/164, Loss: 0.311590, Accuracy: 89.64%\n",
            "Epoch: 43, Step: 129/164, Loss: 0.311527, Accuracy: 89.63%\n",
            "Epoch: 43, Step: 130/164, Loss: 0.312269, Accuracy: 89.62%\n",
            "Epoch: 43, Step: 131/164, Loss: 0.312097, Accuracy: 89.63%\n",
            "Epoch: 43, Step: 132/164, Loss: 0.312069, Accuracy: 89.62%\n",
            "Epoch: 43, Step: 133/164, Loss: 0.311838, Accuracy: 89.61%\n",
            "Epoch: 43, Step: 134/164, Loss: 0.311791, Accuracy: 89.62%\n",
            "Epoch: 43, Step: 135/164, Loss: 0.312990, Accuracy: 89.58%\n",
            "Epoch: 43, Step: 136/164, Loss: 0.313360, Accuracy: 89.56%\n",
            "Epoch: 43, Step: 137/164, Loss: 0.313441, Accuracy: 89.56%\n",
            "Epoch: 43, Step: 138/164, Loss: 0.312750, Accuracy: 89.59%\n",
            "Epoch: 43, Step: 139/164, Loss: 0.312507, Accuracy: 89.59%\n",
            "Epoch: 43, Step: 140/164, Loss: 0.312051, Accuracy: 89.58%\n",
            "Epoch: 43, Step: 141/164, Loss: 0.312606, Accuracy: 89.56%\n",
            "Epoch: 43, Step: 142/164, Loss: 0.311828, Accuracy: 89.58%\n",
            "Epoch: 43, Step: 143/164, Loss: 0.311205, Accuracy: 89.60%\n",
            "Epoch: 43, Step: 144/164, Loss: 0.311443, Accuracy: 89.60%\n",
            "Epoch: 43, Step: 145/164, Loss: 0.310908, Accuracy: 89.62%\n",
            "Epoch: 43, Step: 146/164, Loss: 0.310732, Accuracy: 89.61%\n",
            "Epoch: 43, Step: 147/164, Loss: 0.310521, Accuracy: 89.62%\n",
            "Epoch: 43, Step: 148/164, Loss: 0.310220, Accuracy: 89.64%\n",
            "Epoch: 43, Step: 149/164, Loss: 0.309878, Accuracy: 89.64%\n",
            "Epoch: 43, Step: 150/164, Loss: 0.309642, Accuracy: 89.65%\n",
            "Epoch: 43, Step: 151/164, Loss: 0.309827, Accuracy: 89.65%\n",
            "Epoch: 43, Step: 152/164, Loss: 0.310393, Accuracy: 89.63%\n",
            "Epoch: 43, Step: 153/164, Loss: 0.310276, Accuracy: 89.63%\n",
            "Epoch: 43, Step: 154/164, Loss: 0.309719, Accuracy: 89.66%\n",
            "Epoch: 43, Step: 155/164, Loss: 0.309828, Accuracy: 89.65%\n",
            "Epoch: 43, Step: 156/164, Loss: 0.310073, Accuracy: 89.66%\n",
            "Epoch: 43, Step: 157/164, Loss: 0.310678, Accuracy: 89.64%\n",
            "Epoch: 43, Step: 158/164, Loss: 0.311098, Accuracy: 89.63%\n",
            "Epoch: 43, Step: 159/164, Loss: 0.311082, Accuracy: 89.61%\n",
            "Epoch: 43, Step: 160/164, Loss: 0.310856, Accuracy: 89.63%\n",
            "Epoch: 43, Step: 161/164, Loss: 0.311358, Accuracy: 89.60%\n",
            "Epoch: 43, Step: 162/164, Loss: 0.310801, Accuracy: 89.62%\n",
            "Epoch: 43, Step: 163/164, Loss: 0.311374, Accuracy: 89.61%\n",
            "Epoch: 43, Step: 164/164, Loss: 0.312298, Accuracy: 89.58%\n",
            "Epoch: 44, Step: 1/164, Loss: 0.377123, Accuracy: 85.94%\n",
            "Epoch: 44, Step: 2/164, Loss: 0.359310, Accuracy: 87.50%\n",
            "Epoch: 44, Step: 3/164, Loss: 0.350953, Accuracy: 87.50%\n",
            "Epoch: 44, Step: 4/164, Loss: 0.360006, Accuracy: 87.70%\n",
            "Epoch: 44, Step: 5/164, Loss: 0.348372, Accuracy: 88.12%\n",
            "Epoch: 44, Step: 6/164, Loss: 0.349452, Accuracy: 88.41%\n",
            "Epoch: 44, Step: 7/164, Loss: 0.352563, Accuracy: 87.50%\n",
            "Epoch: 44, Step: 8/164, Loss: 0.342733, Accuracy: 87.99%\n",
            "Epoch: 44, Step: 9/164, Loss: 0.338168, Accuracy: 88.28%\n",
            "Epoch: 44, Step: 10/164, Loss: 0.346001, Accuracy: 88.20%\n",
            "Epoch: 44, Step: 11/164, Loss: 0.340526, Accuracy: 88.28%\n",
            "Epoch: 44, Step: 12/164, Loss: 0.339028, Accuracy: 88.48%\n",
            "Epoch: 44, Step: 13/164, Loss: 0.338453, Accuracy: 88.46%\n",
            "Epoch: 44, Step: 14/164, Loss: 0.340110, Accuracy: 88.56%\n",
            "Epoch: 44, Step: 15/164, Loss: 0.336239, Accuracy: 88.65%\n",
            "Epoch: 44, Step: 16/164, Loss: 0.336708, Accuracy: 88.67%\n",
            "Epoch: 44, Step: 17/164, Loss: 0.330011, Accuracy: 89.02%\n",
            "Epoch: 44, Step: 18/164, Loss: 0.323768, Accuracy: 89.24%\n",
            "Epoch: 44, Step: 19/164, Loss: 0.324401, Accuracy: 89.23%\n",
            "Epoch: 44, Step: 20/164, Loss: 0.325829, Accuracy: 89.10%\n",
            "Epoch: 44, Step: 21/164, Loss: 0.322766, Accuracy: 89.25%\n",
            "Epoch: 44, Step: 22/164, Loss: 0.321282, Accuracy: 89.31%\n",
            "Epoch: 44, Step: 23/164, Loss: 0.326797, Accuracy: 89.13%\n",
            "Epoch: 44, Step: 24/164, Loss: 0.326350, Accuracy: 89.26%\n",
            "Epoch: 44, Step: 25/164, Loss: 0.336487, Accuracy: 88.88%\n",
            "Epoch: 44, Step: 26/164, Loss: 0.335341, Accuracy: 88.85%\n",
            "Epoch: 44, Step: 27/164, Loss: 0.334543, Accuracy: 88.77%\n",
            "Epoch: 44, Step: 28/164, Loss: 0.331188, Accuracy: 88.90%\n",
            "Epoch: 44, Step: 29/164, Loss: 0.330901, Accuracy: 88.93%\n",
            "Epoch: 44, Step: 30/164, Loss: 0.333046, Accuracy: 88.91%\n",
            "Epoch: 44, Step: 31/164, Loss: 0.335128, Accuracy: 88.89%\n",
            "Epoch: 44, Step: 32/164, Loss: 0.337281, Accuracy: 88.70%\n",
            "Epoch: 44, Step: 33/164, Loss: 0.335153, Accuracy: 88.80%\n",
            "Epoch: 44, Step: 34/164, Loss: 0.333957, Accuracy: 88.83%\n",
            "Epoch: 44, Step: 35/164, Loss: 0.332352, Accuracy: 88.88%\n",
            "Epoch: 44, Step: 36/164, Loss: 0.329671, Accuracy: 88.98%\n",
            "Epoch: 44, Step: 37/164, Loss: 0.327442, Accuracy: 89.08%\n",
            "Epoch: 44, Step: 38/164, Loss: 0.329339, Accuracy: 88.92%\n",
            "Epoch: 44, Step: 39/164, Loss: 0.330445, Accuracy: 88.86%\n",
            "Epoch: 44, Step: 40/164, Loss: 0.331080, Accuracy: 88.83%\n",
            "Epoch: 44, Step: 41/164, Loss: 0.331487, Accuracy: 88.81%\n",
            "Epoch: 44, Step: 42/164, Loss: 0.328713, Accuracy: 88.91%\n",
            "Epoch: 44, Step: 43/164, Loss: 0.326763, Accuracy: 88.97%\n",
            "Epoch: 44, Step: 44/164, Loss: 0.325464, Accuracy: 88.97%\n",
            "Epoch: 44, Step: 45/164, Loss: 0.324689, Accuracy: 88.98%\n",
            "Epoch: 44, Step: 46/164, Loss: 0.325194, Accuracy: 88.96%\n",
            "Epoch: 44, Step: 47/164, Loss: 0.325947, Accuracy: 88.90%\n",
            "Epoch: 44, Step: 48/164, Loss: 0.325641, Accuracy: 88.92%\n",
            "Epoch: 44, Step: 49/164, Loss: 0.325117, Accuracy: 88.92%\n",
            "Epoch: 44, Step: 50/164, Loss: 0.325146, Accuracy: 88.94%\n",
            "Epoch: 44, Step: 51/164, Loss: 0.326027, Accuracy: 88.88%\n",
            "Epoch: 44, Step: 52/164, Loss: 0.326508, Accuracy: 88.85%\n",
            "Epoch: 44, Step: 53/164, Loss: 0.327680, Accuracy: 88.84%\n",
            "Epoch: 44, Step: 54/164, Loss: 0.326982, Accuracy: 88.85%\n",
            "Epoch: 44, Step: 55/164, Loss: 0.326777, Accuracy: 88.84%\n",
            "Epoch: 44, Step: 56/164, Loss: 0.326335, Accuracy: 88.83%\n",
            "Epoch: 44, Step: 57/164, Loss: 0.325685, Accuracy: 88.84%\n",
            "Epoch: 44, Step: 58/164, Loss: 0.325730, Accuracy: 88.86%\n",
            "Epoch: 44, Step: 59/164, Loss: 0.324340, Accuracy: 88.94%\n",
            "Epoch: 44, Step: 60/164, Loss: 0.323311, Accuracy: 88.97%\n",
            "Epoch: 44, Step: 61/164, Loss: 0.323443, Accuracy: 89.00%\n",
            "Epoch: 44, Step: 62/164, Loss: 0.323218, Accuracy: 88.99%\n",
            "Epoch: 44, Step: 63/164, Loss: 0.321782, Accuracy: 89.04%\n",
            "Epoch: 44, Step: 64/164, Loss: 0.321276, Accuracy: 89.07%\n",
            "Epoch: 44, Step: 65/164, Loss: 0.319192, Accuracy: 89.17%\n",
            "Epoch: 44, Step: 66/164, Loss: 0.317921, Accuracy: 89.20%\n",
            "Epoch: 44, Step: 67/164, Loss: 0.317822, Accuracy: 89.23%\n",
            "Epoch: 44, Step: 68/164, Loss: 0.316661, Accuracy: 89.23%\n",
            "Epoch: 44, Step: 69/164, Loss: 0.315731, Accuracy: 89.24%\n",
            "Epoch: 44, Step: 70/164, Loss: 0.313822, Accuracy: 89.31%\n",
            "Epoch: 44, Step: 71/164, Loss: 0.312583, Accuracy: 89.35%\n",
            "Epoch: 44, Step: 72/164, Loss: 0.311715, Accuracy: 89.38%\n",
            "Epoch: 44, Step: 73/164, Loss: 0.313584, Accuracy: 89.34%\n",
            "Epoch: 44, Step: 74/164, Loss: 0.313012, Accuracy: 89.40%\n",
            "Epoch: 44, Step: 75/164, Loss: 0.315230, Accuracy: 89.29%\n",
            "Epoch: 44, Step: 76/164, Loss: 0.314305, Accuracy: 89.33%\n",
            "Epoch: 44, Step: 77/164, Loss: 0.315115, Accuracy: 89.29%\n",
            "Epoch: 44, Step: 78/164, Loss: 0.317394, Accuracy: 89.22%\n",
            "Epoch: 44, Step: 79/164, Loss: 0.317090, Accuracy: 89.25%\n",
            "Epoch: 44, Step: 80/164, Loss: 0.317003, Accuracy: 89.26%\n",
            "Epoch: 44, Step: 81/164, Loss: 0.317314, Accuracy: 89.27%\n",
            "Epoch: 44, Step: 82/164, Loss: 0.317133, Accuracy: 89.23%\n",
            "Epoch: 44, Step: 83/164, Loss: 0.317532, Accuracy: 89.20%\n",
            "Epoch: 44, Step: 84/164, Loss: 0.317737, Accuracy: 89.21%\n",
            "Epoch: 44, Step: 85/164, Loss: 0.317269, Accuracy: 89.24%\n",
            "Epoch: 44, Step: 86/164, Loss: 0.317145, Accuracy: 89.25%\n",
            "Epoch: 44, Step: 87/164, Loss: 0.316701, Accuracy: 89.25%\n",
            "Epoch: 44, Step: 88/164, Loss: 0.317281, Accuracy: 89.26%\n",
            "Epoch: 44, Step: 89/164, Loss: 0.316784, Accuracy: 89.26%\n",
            "Epoch: 44, Step: 90/164, Loss: 0.316821, Accuracy: 89.25%\n",
            "Epoch: 44, Step: 91/164, Loss: 0.316584, Accuracy: 89.26%\n",
            "Epoch: 44, Step: 92/164, Loss: 0.317243, Accuracy: 89.26%\n",
            "Epoch: 44, Step: 93/164, Loss: 0.316969, Accuracy: 89.26%\n",
            "Epoch: 44, Step: 94/164, Loss: 0.316381, Accuracy: 89.27%\n",
            "Epoch: 44, Step: 95/164, Loss: 0.315780, Accuracy: 89.28%\n",
            "Epoch: 44, Step: 96/164, Loss: 0.315874, Accuracy: 89.31%\n",
            "Epoch: 44, Step: 97/164, Loss: 0.316633, Accuracy: 89.30%\n",
            "Epoch: 44, Step: 98/164, Loss: 0.315396, Accuracy: 89.35%\n",
            "Epoch: 44, Step: 99/164, Loss: 0.315459, Accuracy: 89.33%\n",
            "Epoch: 44, Step: 100/164, Loss: 0.315129, Accuracy: 89.36%\n",
            "Epoch: 44, Step: 101/164, Loss: 0.315694, Accuracy: 89.36%\n",
            "Epoch: 44, Step: 102/164, Loss: 0.314949, Accuracy: 89.36%\n",
            "Epoch: 44, Step: 103/164, Loss: 0.315594, Accuracy: 89.34%\n",
            "Epoch: 44, Step: 104/164, Loss: 0.314887, Accuracy: 89.36%\n",
            "Epoch: 44, Step: 105/164, Loss: 0.314030, Accuracy: 89.38%\n",
            "Epoch: 44, Step: 106/164, Loss: 0.313770, Accuracy: 89.40%\n",
            "Epoch: 44, Step: 107/164, Loss: 0.313757, Accuracy: 89.38%\n",
            "Epoch: 44, Step: 108/164, Loss: 0.313347, Accuracy: 89.42%\n",
            "Epoch: 44, Step: 109/164, Loss: 0.312659, Accuracy: 89.44%\n",
            "Epoch: 44, Step: 110/164, Loss: 0.312424, Accuracy: 89.44%\n",
            "Epoch: 44, Step: 111/164, Loss: 0.312186, Accuracy: 89.47%\n",
            "Epoch: 44, Step: 112/164, Loss: 0.313420, Accuracy: 89.44%\n",
            "Epoch: 44, Step: 113/164, Loss: 0.312458, Accuracy: 89.46%\n",
            "Epoch: 44, Step: 114/164, Loss: 0.312402, Accuracy: 89.46%\n",
            "Epoch: 44, Step: 115/164, Loss: 0.312309, Accuracy: 89.44%\n",
            "Epoch: 44, Step: 116/164, Loss: 0.312638, Accuracy: 89.44%\n",
            "Epoch: 44, Step: 117/164, Loss: 0.312147, Accuracy: 89.46%\n",
            "Epoch: 44, Step: 118/164, Loss: 0.312187, Accuracy: 89.46%\n",
            "Epoch: 44, Step: 119/164, Loss: 0.314427, Accuracy: 89.39%\n",
            "Epoch: 44, Step: 120/164, Loss: 0.313736, Accuracy: 89.41%\n",
            "Epoch: 44, Step: 121/164, Loss: 0.313471, Accuracy: 89.44%\n",
            "Epoch: 44, Step: 122/164, Loss: 0.313805, Accuracy: 89.41%\n",
            "Epoch: 44, Step: 123/164, Loss: 0.313944, Accuracy: 89.42%\n",
            "Epoch: 44, Step: 124/164, Loss: 0.315207, Accuracy: 89.37%\n",
            "Epoch: 44, Step: 125/164, Loss: 0.315827, Accuracy: 89.35%\n",
            "Epoch: 44, Step: 126/164, Loss: 0.315352, Accuracy: 89.39%\n",
            "Epoch: 44, Step: 127/164, Loss: 0.314620, Accuracy: 89.41%\n",
            "Epoch: 44, Step: 128/164, Loss: 0.313833, Accuracy: 89.42%\n",
            "Epoch: 44, Step: 129/164, Loss: 0.313386, Accuracy: 89.43%\n",
            "Epoch: 44, Step: 130/164, Loss: 0.313218, Accuracy: 89.44%\n",
            "Epoch: 44, Step: 131/164, Loss: 0.313138, Accuracy: 89.42%\n",
            "Epoch: 44, Step: 132/164, Loss: 0.314350, Accuracy: 89.41%\n",
            "Epoch: 44, Step: 133/164, Loss: 0.314497, Accuracy: 89.40%\n",
            "Epoch: 44, Step: 134/164, Loss: 0.314016, Accuracy: 89.41%\n",
            "Epoch: 44, Step: 135/164, Loss: 0.313928, Accuracy: 89.42%\n",
            "Epoch: 44, Step: 136/164, Loss: 0.314135, Accuracy: 89.42%\n",
            "Epoch: 44, Step: 137/164, Loss: 0.314544, Accuracy: 89.41%\n",
            "Epoch: 44, Step: 138/164, Loss: 0.314605, Accuracy: 89.41%\n",
            "Epoch: 44, Step: 139/164, Loss: 0.314332, Accuracy: 89.41%\n",
            "Epoch: 44, Step: 140/164, Loss: 0.314025, Accuracy: 89.41%\n",
            "Epoch: 44, Step: 141/164, Loss: 0.313041, Accuracy: 89.46%\n",
            "Epoch: 44, Step: 142/164, Loss: 0.313589, Accuracy: 89.45%\n",
            "Epoch: 44, Step: 143/164, Loss: 0.312781, Accuracy: 89.48%\n",
            "Epoch: 44, Step: 144/164, Loss: 0.312835, Accuracy: 89.45%\n",
            "Epoch: 44, Step: 145/164, Loss: 0.314122, Accuracy: 89.41%\n",
            "Epoch: 44, Step: 146/164, Loss: 0.313753, Accuracy: 89.43%\n",
            "Epoch: 44, Step: 147/164, Loss: 0.313690, Accuracy: 89.44%\n",
            "Epoch: 44, Step: 148/164, Loss: 0.313653, Accuracy: 89.44%\n",
            "Epoch: 44, Step: 149/164, Loss: 0.314174, Accuracy: 89.43%\n",
            "Epoch: 44, Step: 150/164, Loss: 0.314556, Accuracy: 89.42%\n",
            "Epoch: 44, Step: 151/164, Loss: 0.314524, Accuracy: 89.42%\n",
            "Epoch: 44, Step: 152/164, Loss: 0.314192, Accuracy: 89.43%\n",
            "Epoch: 44, Step: 153/164, Loss: 0.314027, Accuracy: 89.44%\n",
            "Epoch: 44, Step: 154/164, Loss: 0.313715, Accuracy: 89.45%\n",
            "Epoch: 44, Step: 155/164, Loss: 0.313793, Accuracy: 89.46%\n",
            "Epoch: 44, Step: 156/164, Loss: 0.313938, Accuracy: 89.46%\n",
            "Epoch: 44, Step: 157/164, Loss: 0.313506, Accuracy: 89.47%\n",
            "Epoch: 44, Step: 158/164, Loss: 0.313569, Accuracy: 89.46%\n",
            "Epoch: 44, Step: 159/164, Loss: 0.313013, Accuracy: 89.49%\n",
            "Epoch: 44, Step: 160/164, Loss: 0.312795, Accuracy: 89.49%\n",
            "Epoch: 44, Step: 161/164, Loss: 0.313394, Accuracy: 89.47%\n",
            "Epoch: 44, Step: 162/164, Loss: 0.313115, Accuracy: 89.49%\n",
            "Epoch: 44, Step: 163/164, Loss: 0.313385, Accuracy: 89.49%\n",
            "Epoch: 44, Step: 164/164, Loss: 0.313497, Accuracy: 89.49%\n",
            "Epoch: 45, Step: 1/164, Loss: 0.293840, Accuracy: 89.84%\n",
            "Epoch: 45, Step: 2/164, Loss: 0.278959, Accuracy: 90.62%\n",
            "Epoch: 45, Step: 3/164, Loss: 0.310893, Accuracy: 89.84%\n",
            "Epoch: 45, Step: 4/164, Loss: 0.318158, Accuracy: 89.65%\n",
            "Epoch: 45, Step: 5/164, Loss: 0.297969, Accuracy: 89.84%\n",
            "Epoch: 45, Step: 6/164, Loss: 0.292713, Accuracy: 89.97%\n",
            "Epoch: 45, Step: 7/164, Loss: 0.301337, Accuracy: 89.29%\n",
            "Epoch: 45, Step: 8/164, Loss: 0.313851, Accuracy: 88.87%\n",
            "Epoch: 45, Step: 9/164, Loss: 0.314820, Accuracy: 88.54%\n",
            "Epoch: 45, Step: 10/164, Loss: 0.306875, Accuracy: 88.83%\n",
            "Epoch: 45, Step: 11/164, Loss: 0.306405, Accuracy: 88.78%\n",
            "Epoch: 45, Step: 12/164, Loss: 0.311887, Accuracy: 88.74%\n",
            "Epoch: 45, Step: 13/164, Loss: 0.306548, Accuracy: 89.12%\n",
            "Epoch: 45, Step: 14/164, Loss: 0.308305, Accuracy: 89.12%\n",
            "Epoch: 45, Step: 15/164, Loss: 0.304338, Accuracy: 89.32%\n",
            "Epoch: 45, Step: 16/164, Loss: 0.303730, Accuracy: 89.31%\n",
            "Epoch: 45, Step: 17/164, Loss: 0.305135, Accuracy: 89.29%\n",
            "Epoch: 45, Step: 18/164, Loss: 0.308508, Accuracy: 89.19%\n",
            "Epoch: 45, Step: 19/164, Loss: 0.303969, Accuracy: 89.39%\n",
            "Epoch: 45, Step: 20/164, Loss: 0.297145, Accuracy: 89.65%\n",
            "Epoch: 45, Step: 21/164, Loss: 0.299088, Accuracy: 89.81%\n",
            "Epoch: 45, Step: 22/164, Loss: 0.307824, Accuracy: 89.67%\n",
            "Epoch: 45, Step: 23/164, Loss: 0.311395, Accuracy: 89.50%\n",
            "Epoch: 45, Step: 24/164, Loss: 0.310268, Accuracy: 89.49%\n",
            "Epoch: 45, Step: 25/164, Loss: 0.315024, Accuracy: 89.34%\n",
            "Epoch: 45, Step: 26/164, Loss: 0.316496, Accuracy: 89.36%\n",
            "Epoch: 45, Step: 27/164, Loss: 0.319346, Accuracy: 89.44%\n",
            "Epoch: 45, Step: 28/164, Loss: 0.319158, Accuracy: 89.54%\n",
            "Epoch: 45, Step: 29/164, Loss: 0.316847, Accuracy: 89.60%\n",
            "Epoch: 45, Step: 30/164, Loss: 0.313918, Accuracy: 89.71%\n",
            "Epoch: 45, Step: 31/164, Loss: 0.314995, Accuracy: 89.74%\n",
            "Epoch: 45, Step: 32/164, Loss: 0.313504, Accuracy: 89.79%\n",
            "Epoch: 45, Step: 33/164, Loss: 0.314099, Accuracy: 89.80%\n",
            "Epoch: 45, Step: 34/164, Loss: 0.317996, Accuracy: 89.61%\n",
            "Epoch: 45, Step: 35/164, Loss: 0.318265, Accuracy: 89.62%\n",
            "Epoch: 45, Step: 36/164, Loss: 0.319260, Accuracy: 89.54%\n",
            "Epoch: 45, Step: 37/164, Loss: 0.319819, Accuracy: 89.57%\n",
            "Epoch: 45, Step: 38/164, Loss: 0.319331, Accuracy: 89.60%\n",
            "Epoch: 45, Step: 39/164, Loss: 0.315732, Accuracy: 89.74%\n",
            "Epoch: 45, Step: 40/164, Loss: 0.313742, Accuracy: 89.82%\n",
            "Epoch: 45, Step: 41/164, Loss: 0.312036, Accuracy: 89.88%\n",
            "Epoch: 45, Step: 42/164, Loss: 0.309947, Accuracy: 89.96%\n",
            "Epoch: 45, Step: 43/164, Loss: 0.310905, Accuracy: 89.99%\n",
            "Epoch: 45, Step: 44/164, Loss: 0.311546, Accuracy: 89.88%\n",
            "Epoch: 45, Step: 45/164, Loss: 0.311312, Accuracy: 89.91%\n",
            "Epoch: 45, Step: 46/164, Loss: 0.309193, Accuracy: 90.01%\n",
            "Epoch: 45, Step: 47/164, Loss: 0.309208, Accuracy: 90.03%\n",
            "Epoch: 45, Step: 48/164, Loss: 0.308467, Accuracy: 90.06%\n",
            "Epoch: 45, Step: 49/164, Loss: 0.308313, Accuracy: 90.04%\n",
            "Epoch: 45, Step: 50/164, Loss: 0.308356, Accuracy: 90.00%\n",
            "Epoch: 45, Step: 51/164, Loss: 0.308179, Accuracy: 90.00%\n",
            "Epoch: 45, Step: 52/164, Loss: 0.307766, Accuracy: 89.99%\n",
            "Epoch: 45, Step: 53/164, Loss: 0.309188, Accuracy: 89.90%\n",
            "Epoch: 45, Step: 54/164, Loss: 0.309997, Accuracy: 89.84%\n",
            "Epoch: 45, Step: 55/164, Loss: 0.308485, Accuracy: 89.91%\n",
            "Epoch: 45, Step: 56/164, Loss: 0.310826, Accuracy: 89.84%\n",
            "Epoch: 45, Step: 57/164, Loss: 0.311311, Accuracy: 89.84%\n",
            "Epoch: 45, Step: 58/164, Loss: 0.312475, Accuracy: 89.78%\n",
            "Epoch: 45, Step: 59/164, Loss: 0.311203, Accuracy: 89.82%\n",
            "Epoch: 45, Step: 60/164, Loss: 0.310293, Accuracy: 89.84%\n",
            "Epoch: 45, Step: 61/164, Loss: 0.309571, Accuracy: 89.86%\n",
            "Epoch: 45, Step: 62/164, Loss: 0.312226, Accuracy: 89.79%\n",
            "Epoch: 45, Step: 63/164, Loss: 0.310463, Accuracy: 89.86%\n",
            "Epoch: 45, Step: 64/164, Loss: 0.310313, Accuracy: 89.84%\n",
            "Epoch: 45, Step: 65/164, Loss: 0.309915, Accuracy: 89.87%\n",
            "Epoch: 45, Step: 66/164, Loss: 0.311023, Accuracy: 89.84%\n",
            "Epoch: 45, Step: 67/164, Loss: 0.310868, Accuracy: 89.84%\n",
            "Epoch: 45, Step: 68/164, Loss: 0.311329, Accuracy: 89.81%\n",
            "Epoch: 45, Step: 69/164, Loss: 0.312201, Accuracy: 89.76%\n",
            "Epoch: 45, Step: 70/164, Loss: 0.314253, Accuracy: 89.70%\n",
            "Epoch: 45, Step: 71/164, Loss: 0.313320, Accuracy: 89.73%\n",
            "Epoch: 45, Step: 72/164, Loss: 0.312913, Accuracy: 89.75%\n",
            "Epoch: 45, Step: 73/164, Loss: 0.313314, Accuracy: 89.69%\n",
            "Epoch: 45, Step: 74/164, Loss: 0.313623, Accuracy: 89.71%\n",
            "Epoch: 45, Step: 75/164, Loss: 0.314421, Accuracy: 89.71%\n",
            "Epoch: 45, Step: 76/164, Loss: 0.313638, Accuracy: 89.74%\n",
            "Epoch: 45, Step: 77/164, Loss: 0.315044, Accuracy: 89.67%\n",
            "Epoch: 45, Step: 78/164, Loss: 0.315170, Accuracy: 89.68%\n",
            "Epoch: 45, Step: 79/164, Loss: 0.315163, Accuracy: 89.67%\n",
            "Epoch: 45, Step: 80/164, Loss: 0.314781, Accuracy: 89.69%\n",
            "Epoch: 45, Step: 81/164, Loss: 0.313322, Accuracy: 89.78%\n",
            "Epoch: 45, Step: 82/164, Loss: 0.312260, Accuracy: 89.82%\n",
            "Epoch: 45, Step: 83/164, Loss: 0.312062, Accuracy: 89.81%\n",
            "Epoch: 45, Step: 84/164, Loss: 0.313089, Accuracy: 89.76%\n",
            "Epoch: 45, Step: 85/164, Loss: 0.313836, Accuracy: 89.75%\n",
            "Epoch: 45, Step: 86/164, Loss: 0.312170, Accuracy: 89.82%\n",
            "Epoch: 45, Step: 87/164, Loss: 0.312136, Accuracy: 89.81%\n",
            "Epoch: 45, Step: 88/164, Loss: 0.312043, Accuracy: 89.81%\n",
            "Epoch: 45, Step: 89/164, Loss: 0.312154, Accuracy: 89.81%\n",
            "Epoch: 45, Step: 90/164, Loss: 0.312917, Accuracy: 89.75%\n",
            "Epoch: 45, Step: 91/164, Loss: 0.313650, Accuracy: 89.71%\n",
            "Epoch: 45, Step: 92/164, Loss: 0.313699, Accuracy: 89.72%\n",
            "Epoch: 45, Step: 93/164, Loss: 0.313936, Accuracy: 89.70%\n",
            "Epoch: 45, Step: 94/164, Loss: 0.314073, Accuracy: 89.68%\n",
            "Epoch: 45, Step: 95/164, Loss: 0.313509, Accuracy: 89.71%\n",
            "Epoch: 45, Step: 96/164, Loss: 0.312599, Accuracy: 89.75%\n",
            "Epoch: 45, Step: 97/164, Loss: 0.312771, Accuracy: 89.72%\n",
            "Epoch: 45, Step: 98/164, Loss: 0.312498, Accuracy: 89.71%\n",
            "Epoch: 45, Step: 99/164, Loss: 0.313502, Accuracy: 89.68%\n",
            "Epoch: 45, Step: 100/164, Loss: 0.312972, Accuracy: 89.69%\n",
            "Epoch: 45, Step: 101/164, Loss: 0.314289, Accuracy: 89.61%\n",
            "Epoch: 45, Step: 102/164, Loss: 0.313962, Accuracy: 89.63%\n",
            "Epoch: 45, Step: 103/164, Loss: 0.312773, Accuracy: 89.66%\n",
            "Epoch: 45, Step: 104/164, Loss: 0.314545, Accuracy: 89.61%\n",
            "Epoch: 45, Step: 105/164, Loss: 0.313924, Accuracy: 89.62%\n",
            "Epoch: 45, Step: 106/164, Loss: 0.314832, Accuracy: 89.57%\n",
            "Epoch: 45, Step: 107/164, Loss: 0.313955, Accuracy: 89.60%\n",
            "Epoch: 45, Step: 108/164, Loss: 0.314526, Accuracy: 89.58%\n",
            "Epoch: 45, Step: 109/164, Loss: 0.316539, Accuracy: 89.52%\n",
            "Epoch: 45, Step: 110/164, Loss: 0.316405, Accuracy: 89.53%\n",
            "Epoch: 45, Step: 111/164, Loss: 0.315691, Accuracy: 89.56%\n",
            "Epoch: 45, Step: 112/164, Loss: 0.315150, Accuracy: 89.56%\n",
            "Epoch: 45, Step: 113/164, Loss: 0.314851, Accuracy: 89.57%\n",
            "Epoch: 45, Step: 114/164, Loss: 0.315864, Accuracy: 89.54%\n",
            "Epoch: 45, Step: 115/164, Loss: 0.316187, Accuracy: 89.51%\n",
            "Epoch: 45, Step: 116/164, Loss: 0.316481, Accuracy: 89.50%\n",
            "Epoch: 45, Step: 117/164, Loss: 0.316817, Accuracy: 89.48%\n",
            "Epoch: 45, Step: 118/164, Loss: 0.316837, Accuracy: 89.46%\n",
            "Epoch: 45, Step: 119/164, Loss: 0.316243, Accuracy: 89.47%\n",
            "Epoch: 45, Step: 120/164, Loss: 0.316129, Accuracy: 89.49%\n",
            "Epoch: 45, Step: 121/164, Loss: 0.316551, Accuracy: 89.46%\n",
            "Epoch: 45, Step: 122/164, Loss: 0.317152, Accuracy: 89.43%\n",
            "Epoch: 45, Step: 123/164, Loss: 0.317040, Accuracy: 89.42%\n",
            "Epoch: 45, Step: 124/164, Loss: 0.318147, Accuracy: 89.40%\n",
            "Epoch: 45, Step: 125/164, Loss: 0.317952, Accuracy: 89.38%\n",
            "Epoch: 45, Step: 126/164, Loss: 0.317343, Accuracy: 89.40%\n",
            "Epoch: 45, Step: 127/164, Loss: 0.317274, Accuracy: 89.40%\n",
            "Epoch: 45, Step: 128/164, Loss: 0.317008, Accuracy: 89.42%\n",
            "Epoch: 45, Step: 129/164, Loss: 0.317058, Accuracy: 89.41%\n",
            "Epoch: 45, Step: 130/164, Loss: 0.316592, Accuracy: 89.44%\n",
            "Epoch: 45, Step: 131/164, Loss: 0.317483, Accuracy: 89.38%\n",
            "Epoch: 45, Step: 132/164, Loss: 0.317731, Accuracy: 89.39%\n",
            "Epoch: 45, Step: 133/164, Loss: 0.317552, Accuracy: 89.38%\n",
            "Epoch: 45, Step: 134/164, Loss: 0.316651, Accuracy: 89.39%\n",
            "Epoch: 45, Step: 135/164, Loss: 0.316808, Accuracy: 89.39%\n",
            "Epoch: 45, Step: 136/164, Loss: 0.316330, Accuracy: 89.40%\n",
            "Epoch: 45, Step: 137/164, Loss: 0.317043, Accuracy: 89.38%\n",
            "Epoch: 45, Step: 138/164, Loss: 0.317520, Accuracy: 89.36%\n",
            "Epoch: 45, Step: 139/164, Loss: 0.316863, Accuracy: 89.38%\n",
            "Epoch: 45, Step: 140/164, Loss: 0.316430, Accuracy: 89.40%\n",
            "Epoch: 45, Step: 141/164, Loss: 0.315831, Accuracy: 89.41%\n",
            "Epoch: 45, Step: 142/164, Loss: 0.315364, Accuracy: 89.43%\n",
            "Epoch: 45, Step: 143/164, Loss: 0.315513, Accuracy: 89.43%\n",
            "Epoch: 45, Step: 144/164, Loss: 0.315160, Accuracy: 89.44%\n",
            "Epoch: 45, Step: 145/164, Loss: 0.315150, Accuracy: 89.45%\n",
            "Epoch: 45, Step: 146/164, Loss: 0.315049, Accuracy: 89.46%\n",
            "Epoch: 45, Step: 147/164, Loss: 0.315095, Accuracy: 89.47%\n",
            "Epoch: 45, Step: 148/164, Loss: 0.314919, Accuracy: 89.46%\n",
            "Epoch: 45, Step: 149/164, Loss: 0.314165, Accuracy: 89.49%\n",
            "Epoch: 45, Step: 150/164, Loss: 0.314252, Accuracy: 89.48%\n",
            "Epoch: 45, Step: 151/164, Loss: 0.314500, Accuracy: 89.47%\n",
            "Epoch: 45, Step: 152/164, Loss: 0.314705, Accuracy: 89.45%\n",
            "Epoch: 45, Step: 153/164, Loss: 0.314487, Accuracy: 89.46%\n",
            "Epoch: 45, Step: 154/164, Loss: 0.313937, Accuracy: 89.48%\n",
            "Epoch: 45, Step: 155/164, Loss: 0.315328, Accuracy: 89.43%\n",
            "Epoch: 45, Step: 156/164, Loss: 0.314634, Accuracy: 89.46%\n",
            "Epoch: 45, Step: 157/164, Loss: 0.314550, Accuracy: 89.47%\n",
            "Epoch: 45, Step: 158/164, Loss: 0.314504, Accuracy: 89.45%\n",
            "Epoch: 45, Step: 159/164, Loss: 0.314666, Accuracy: 89.45%\n",
            "Epoch: 45, Step: 160/164, Loss: 0.314411, Accuracy: 89.45%\n",
            "Epoch: 45, Step: 161/164, Loss: 0.314062, Accuracy: 89.46%\n",
            "Epoch: 45, Step: 162/164, Loss: 0.314342, Accuracy: 89.43%\n",
            "Epoch: 45, Step: 163/164, Loss: 0.313949, Accuracy: 89.45%\n",
            "Epoch: 45, Step: 164/164, Loss: 0.314750, Accuracy: 89.44%\n",
            "Epoch: 46, Step: 1/164, Loss: 0.242713, Accuracy: 92.19%\n",
            "Epoch: 46, Step: 2/164, Loss: 0.275025, Accuracy: 89.84%\n",
            "Epoch: 46, Step: 3/164, Loss: 0.275421, Accuracy: 90.10%\n",
            "Epoch: 46, Step: 4/164, Loss: 0.273823, Accuracy: 90.04%\n",
            "Epoch: 46, Step: 5/164, Loss: 0.298942, Accuracy: 89.53%\n",
            "Epoch: 46, Step: 6/164, Loss: 0.293659, Accuracy: 89.58%\n",
            "Epoch: 46, Step: 7/164, Loss: 0.294131, Accuracy: 89.73%\n",
            "Epoch: 46, Step: 8/164, Loss: 0.285239, Accuracy: 90.14%\n",
            "Epoch: 46, Step: 9/164, Loss: 0.296130, Accuracy: 89.93%\n",
            "Epoch: 46, Step: 10/164, Loss: 0.301688, Accuracy: 89.45%\n",
            "Epoch: 46, Step: 11/164, Loss: 0.300121, Accuracy: 89.56%\n",
            "Epoch: 46, Step: 12/164, Loss: 0.296714, Accuracy: 89.78%\n",
            "Epoch: 46, Step: 13/164, Loss: 0.297896, Accuracy: 89.96%\n",
            "Epoch: 46, Step: 14/164, Loss: 0.306315, Accuracy: 89.51%\n",
            "Epoch: 46, Step: 15/164, Loss: 0.299839, Accuracy: 89.69%\n",
            "Epoch: 46, Step: 16/164, Loss: 0.303622, Accuracy: 89.60%\n",
            "Epoch: 46, Step: 17/164, Loss: 0.303356, Accuracy: 89.57%\n",
            "Epoch: 46, Step: 18/164, Loss: 0.304005, Accuracy: 89.67%\n",
            "Epoch: 46, Step: 19/164, Loss: 0.296012, Accuracy: 90.01%\n",
            "Epoch: 46, Step: 20/164, Loss: 0.300615, Accuracy: 89.84%\n",
            "Epoch: 46, Step: 21/164, Loss: 0.296835, Accuracy: 89.88%\n",
            "Epoch: 46, Step: 22/164, Loss: 0.291718, Accuracy: 90.06%\n",
            "Epoch: 46, Step: 23/164, Loss: 0.291205, Accuracy: 89.98%\n",
            "Epoch: 46, Step: 24/164, Loss: 0.292363, Accuracy: 89.94%\n",
            "Epoch: 46, Step: 25/164, Loss: 0.292846, Accuracy: 89.94%\n",
            "Epoch: 46, Step: 26/164, Loss: 0.292564, Accuracy: 89.99%\n",
            "Epoch: 46, Step: 27/164, Loss: 0.292366, Accuracy: 90.08%\n",
            "Epoch: 46, Step: 28/164, Loss: 0.292439, Accuracy: 90.12%\n",
            "Epoch: 46, Step: 29/164, Loss: 0.295639, Accuracy: 90.09%\n",
            "Epoch: 46, Step: 30/164, Loss: 0.295055, Accuracy: 90.08%\n",
            "Epoch: 46, Step: 31/164, Loss: 0.297040, Accuracy: 90.05%\n",
            "Epoch: 46, Step: 32/164, Loss: 0.299217, Accuracy: 89.94%\n",
            "Epoch: 46, Step: 33/164, Loss: 0.301192, Accuracy: 89.87%\n",
            "Epoch: 46, Step: 34/164, Loss: 0.300314, Accuracy: 89.84%\n",
            "Epoch: 46, Step: 35/164, Loss: 0.303881, Accuracy: 89.75%\n",
            "Epoch: 46, Step: 36/164, Loss: 0.302944, Accuracy: 89.76%\n",
            "Epoch: 46, Step: 37/164, Loss: 0.300992, Accuracy: 89.82%\n",
            "Epoch: 46, Step: 38/164, Loss: 0.300606, Accuracy: 89.84%\n",
            "Epoch: 46, Step: 39/164, Loss: 0.298859, Accuracy: 90.02%\n",
            "Epoch: 46, Step: 40/164, Loss: 0.300964, Accuracy: 90.08%\n",
            "Epoch: 46, Step: 41/164, Loss: 0.303768, Accuracy: 89.94%\n",
            "Epoch: 46, Step: 42/164, Loss: 0.302525, Accuracy: 89.97%\n",
            "Epoch: 46, Step: 43/164, Loss: 0.301227, Accuracy: 89.99%\n",
            "Epoch: 46, Step: 44/164, Loss: 0.304008, Accuracy: 89.86%\n",
            "Epoch: 46, Step: 45/164, Loss: 0.303497, Accuracy: 89.84%\n",
            "Epoch: 46, Step: 46/164, Loss: 0.305714, Accuracy: 89.72%\n",
            "Epoch: 46, Step: 47/164, Loss: 0.306504, Accuracy: 89.66%\n",
            "Epoch: 46, Step: 48/164, Loss: 0.310288, Accuracy: 89.57%\n",
            "Epoch: 46, Step: 49/164, Loss: 0.310448, Accuracy: 89.54%\n",
            "Epoch: 46, Step: 50/164, Loss: 0.309551, Accuracy: 89.53%\n",
            "Epoch: 46, Step: 51/164, Loss: 0.309216, Accuracy: 89.49%\n",
            "Epoch: 46, Step: 52/164, Loss: 0.313777, Accuracy: 89.39%\n",
            "Epoch: 46, Step: 53/164, Loss: 0.312671, Accuracy: 89.43%\n",
            "Epoch: 46, Step: 54/164, Loss: 0.312331, Accuracy: 89.45%\n",
            "Epoch: 46, Step: 55/164, Loss: 0.311674, Accuracy: 89.46%\n",
            "Epoch: 46, Step: 56/164, Loss: 0.309703, Accuracy: 89.54%\n",
            "Epoch: 46, Step: 57/164, Loss: 0.309942, Accuracy: 89.54%\n",
            "Epoch: 46, Step: 58/164, Loss: 0.308537, Accuracy: 89.59%\n",
            "Epoch: 46, Step: 59/164, Loss: 0.308294, Accuracy: 89.63%\n",
            "Epoch: 46, Step: 60/164, Loss: 0.309176, Accuracy: 89.60%\n",
            "Epoch: 46, Step: 61/164, Loss: 0.307753, Accuracy: 89.61%\n",
            "Epoch: 46, Step: 62/164, Loss: 0.307118, Accuracy: 89.62%\n",
            "Epoch: 46, Step: 63/164, Loss: 0.304647, Accuracy: 89.68%\n",
            "Epoch: 46, Step: 64/164, Loss: 0.306159, Accuracy: 89.62%\n",
            "Epoch: 46, Step: 65/164, Loss: 0.305131, Accuracy: 89.68%\n",
            "Epoch: 46, Step: 66/164, Loss: 0.304380, Accuracy: 89.74%\n",
            "Epoch: 46, Step: 67/164, Loss: 0.303740, Accuracy: 89.79%\n",
            "Epoch: 46, Step: 68/164, Loss: 0.303153, Accuracy: 89.79%\n",
            "Epoch: 46, Step: 69/164, Loss: 0.305775, Accuracy: 89.73%\n",
            "Epoch: 46, Step: 70/164, Loss: 0.304813, Accuracy: 89.74%\n",
            "Epoch: 46, Step: 71/164, Loss: 0.308376, Accuracy: 89.65%\n",
            "Epoch: 46, Step: 72/164, Loss: 0.308305, Accuracy: 89.59%\n",
            "Epoch: 46, Step: 73/164, Loss: 0.307820, Accuracy: 89.60%\n",
            "Epoch: 46, Step: 74/164, Loss: 0.306760, Accuracy: 89.63%\n",
            "Epoch: 46, Step: 75/164, Loss: 0.308352, Accuracy: 89.57%\n",
            "Epoch: 46, Step: 76/164, Loss: 0.308048, Accuracy: 89.61%\n",
            "Epoch: 46, Step: 77/164, Loss: 0.306937, Accuracy: 89.66%\n",
            "Epoch: 46, Step: 78/164, Loss: 0.306336, Accuracy: 89.67%\n",
            "Epoch: 46, Step: 79/164, Loss: 0.306179, Accuracy: 89.69%\n",
            "Epoch: 46, Step: 80/164, Loss: 0.305409, Accuracy: 89.74%\n",
            "Epoch: 46, Step: 81/164, Loss: 0.305845, Accuracy: 89.70%\n",
            "Epoch: 46, Step: 82/164, Loss: 0.306237, Accuracy: 89.67%\n",
            "Epoch: 46, Step: 83/164, Loss: 0.308514, Accuracy: 89.56%\n",
            "Epoch: 46, Step: 84/164, Loss: 0.308720, Accuracy: 89.56%\n",
            "Epoch: 46, Step: 85/164, Loss: 0.308398, Accuracy: 89.59%\n",
            "Epoch: 46, Step: 86/164, Loss: 0.308634, Accuracy: 89.57%\n",
            "Epoch: 46, Step: 87/164, Loss: 0.308212, Accuracy: 89.60%\n",
            "Epoch: 46, Step: 88/164, Loss: 0.308710, Accuracy: 89.58%\n",
            "Epoch: 46, Step: 89/164, Loss: 0.308805, Accuracy: 89.60%\n",
            "Epoch: 46, Step: 90/164, Loss: 0.309290, Accuracy: 89.57%\n",
            "Epoch: 46, Step: 91/164, Loss: 0.311074, Accuracy: 89.52%\n",
            "Epoch: 46, Step: 92/164, Loss: 0.311941, Accuracy: 89.52%\n",
            "Epoch: 46, Step: 93/164, Loss: 0.312064, Accuracy: 89.48%\n",
            "Epoch: 46, Step: 94/164, Loss: 0.312091, Accuracy: 89.50%\n",
            "Epoch: 46, Step: 95/164, Loss: 0.311408, Accuracy: 89.53%\n",
            "Epoch: 46, Step: 96/164, Loss: 0.311253, Accuracy: 89.53%\n",
            "Epoch: 46, Step: 97/164, Loss: 0.311034, Accuracy: 89.51%\n",
            "Epoch: 46, Step: 98/164, Loss: 0.311194, Accuracy: 89.52%\n",
            "Epoch: 46, Step: 99/164, Loss: 0.310516, Accuracy: 89.56%\n",
            "Epoch: 46, Step: 100/164, Loss: 0.309785, Accuracy: 89.55%\n",
            "Epoch: 46, Step: 101/164, Loss: 0.310194, Accuracy: 89.56%\n",
            "Epoch: 46, Step: 102/164, Loss: 0.309759, Accuracy: 89.57%\n",
            "Epoch: 46, Step: 103/164, Loss: 0.310715, Accuracy: 89.56%\n",
            "Epoch: 46, Step: 104/164, Loss: 0.310612, Accuracy: 89.57%\n",
            "Epoch: 46, Step: 105/164, Loss: 0.309563, Accuracy: 89.60%\n",
            "Epoch: 46, Step: 106/164, Loss: 0.310816, Accuracy: 89.56%\n",
            "Epoch: 46, Step: 107/164, Loss: 0.310014, Accuracy: 89.56%\n",
            "Epoch: 46, Step: 108/164, Loss: 0.309495, Accuracy: 89.57%\n",
            "Epoch: 46, Step: 109/164, Loss: 0.308713, Accuracy: 89.60%\n",
            "Epoch: 46, Step: 110/164, Loss: 0.307878, Accuracy: 89.62%\n",
            "Epoch: 46, Step: 111/164, Loss: 0.307370, Accuracy: 89.63%\n",
            "Epoch: 46, Step: 112/164, Loss: 0.307478, Accuracy: 89.61%\n",
            "Epoch: 46, Step: 113/164, Loss: 0.307676, Accuracy: 89.62%\n",
            "Epoch: 46, Step: 114/164, Loss: 0.309583, Accuracy: 89.58%\n",
            "Epoch: 46, Step: 115/164, Loss: 0.309218, Accuracy: 89.59%\n",
            "Epoch: 46, Step: 116/164, Loss: 0.308773, Accuracy: 89.59%\n",
            "Epoch: 46, Step: 117/164, Loss: 0.308010, Accuracy: 89.63%\n",
            "Epoch: 46, Step: 118/164, Loss: 0.307630, Accuracy: 89.65%\n",
            "Epoch: 46, Step: 119/164, Loss: 0.307429, Accuracy: 89.64%\n",
            "Epoch: 46, Step: 120/164, Loss: 0.307335, Accuracy: 89.64%\n",
            "Epoch: 46, Step: 121/164, Loss: 0.307118, Accuracy: 89.64%\n",
            "Epoch: 46, Step: 122/164, Loss: 0.306509, Accuracy: 89.68%\n",
            "Epoch: 46, Step: 123/164, Loss: 0.306636, Accuracy: 89.66%\n",
            "Epoch: 46, Step: 124/164, Loss: 0.305816, Accuracy: 89.69%\n",
            "Epoch: 46, Step: 125/164, Loss: 0.305628, Accuracy: 89.70%\n",
            "Epoch: 46, Step: 126/164, Loss: 0.305820, Accuracy: 89.69%\n",
            "Epoch: 46, Step: 127/164, Loss: 0.305531, Accuracy: 89.70%\n",
            "Epoch: 46, Step: 128/164, Loss: 0.305240, Accuracy: 89.70%\n",
            "Epoch: 46, Step: 129/164, Loss: 0.305058, Accuracy: 89.69%\n",
            "Epoch: 46, Step: 130/164, Loss: 0.304673, Accuracy: 89.69%\n",
            "Epoch: 46, Step: 131/164, Loss: 0.303988, Accuracy: 89.72%\n",
            "Epoch: 46, Step: 132/164, Loss: 0.304694, Accuracy: 89.71%\n",
            "Epoch: 46, Step: 133/164, Loss: 0.305839, Accuracy: 89.69%\n",
            "Epoch: 46, Step: 134/164, Loss: 0.305887, Accuracy: 89.69%\n",
            "Epoch: 46, Step: 135/164, Loss: 0.305178, Accuracy: 89.70%\n",
            "Epoch: 46, Step: 136/164, Loss: 0.305814, Accuracy: 89.69%\n",
            "Epoch: 46, Step: 137/164, Loss: 0.306030, Accuracy: 89.67%\n",
            "Epoch: 46, Step: 138/164, Loss: 0.305938, Accuracy: 89.67%\n",
            "Epoch: 46, Step: 139/164, Loss: 0.306035, Accuracy: 89.66%\n",
            "Epoch: 46, Step: 140/164, Loss: 0.306489, Accuracy: 89.63%\n",
            "Epoch: 46, Step: 141/164, Loss: 0.306294, Accuracy: 89.66%\n",
            "Epoch: 46, Step: 142/164, Loss: 0.306078, Accuracy: 89.67%\n",
            "Epoch: 46, Step: 143/164, Loss: 0.306039, Accuracy: 89.69%\n",
            "Epoch: 46, Step: 144/164, Loss: 0.305349, Accuracy: 89.71%\n",
            "Epoch: 46, Step: 145/164, Loss: 0.305622, Accuracy: 89.70%\n",
            "Epoch: 46, Step: 146/164, Loss: 0.304754, Accuracy: 89.74%\n",
            "Epoch: 46, Step: 147/164, Loss: 0.304144, Accuracy: 89.75%\n",
            "Epoch: 46, Step: 148/164, Loss: 0.304429, Accuracy: 89.76%\n",
            "Epoch: 46, Step: 149/164, Loss: 0.304090, Accuracy: 89.77%\n",
            "Epoch: 46, Step: 150/164, Loss: 0.304222, Accuracy: 89.75%\n",
            "Epoch: 46, Step: 151/164, Loss: 0.304030, Accuracy: 89.77%\n",
            "Epoch: 46, Step: 152/164, Loss: 0.302877, Accuracy: 89.81%\n",
            "Epoch: 46, Step: 153/164, Loss: 0.303392, Accuracy: 89.80%\n",
            "Epoch: 46, Step: 154/164, Loss: 0.303411, Accuracy: 89.79%\n",
            "Epoch: 46, Step: 155/164, Loss: 0.304615, Accuracy: 89.74%\n",
            "Epoch: 46, Step: 156/164, Loss: 0.305206, Accuracy: 89.71%\n",
            "Epoch: 46, Step: 157/164, Loss: 0.305357, Accuracy: 89.71%\n",
            "Epoch: 46, Step: 158/164, Loss: 0.305557, Accuracy: 89.70%\n",
            "Epoch: 46, Step: 159/164, Loss: 0.305692, Accuracy: 89.69%\n",
            "Epoch: 46, Step: 160/164, Loss: 0.304904, Accuracy: 89.73%\n",
            "Epoch: 46, Step: 161/164, Loss: 0.304873, Accuracy: 89.74%\n",
            "Epoch: 46, Step: 162/164, Loss: 0.305396, Accuracy: 89.74%\n",
            "Epoch: 46, Step: 163/164, Loss: 0.305569, Accuracy: 89.72%\n",
            "Epoch: 46, Step: 164/164, Loss: 0.305552, Accuracy: 89.72%\n",
            "Epoch: 47, Step: 1/164, Loss: 0.242729, Accuracy: 89.84%\n",
            "Epoch: 47, Step: 2/164, Loss: 0.317741, Accuracy: 87.11%\n",
            "Epoch: 47, Step: 3/164, Loss: 0.329450, Accuracy: 86.98%\n",
            "Epoch: 47, Step: 4/164, Loss: 0.318175, Accuracy: 88.28%\n",
            "Epoch: 47, Step: 5/164, Loss: 0.295055, Accuracy: 89.53%\n",
            "Epoch: 47, Step: 6/164, Loss: 0.280791, Accuracy: 90.10%\n",
            "Epoch: 47, Step: 7/164, Loss: 0.308550, Accuracy: 89.29%\n",
            "Epoch: 47, Step: 8/164, Loss: 0.298933, Accuracy: 89.75%\n",
            "Epoch: 47, Step: 9/164, Loss: 0.300916, Accuracy: 89.84%\n",
            "Epoch: 47, Step: 10/164, Loss: 0.301419, Accuracy: 89.69%\n",
            "Epoch: 47, Step: 11/164, Loss: 0.297246, Accuracy: 89.91%\n",
            "Epoch: 47, Step: 12/164, Loss: 0.290948, Accuracy: 90.23%\n",
            "Epoch: 47, Step: 13/164, Loss: 0.292635, Accuracy: 90.14%\n",
            "Epoch: 47, Step: 14/164, Loss: 0.299932, Accuracy: 89.96%\n",
            "Epoch: 47, Step: 15/164, Loss: 0.296447, Accuracy: 89.95%\n",
            "Epoch: 47, Step: 16/164, Loss: 0.296493, Accuracy: 89.84%\n",
            "Epoch: 47, Step: 17/164, Loss: 0.296982, Accuracy: 89.84%\n",
            "Epoch: 47, Step: 18/164, Loss: 0.302864, Accuracy: 89.93%\n",
            "Epoch: 47, Step: 19/164, Loss: 0.304521, Accuracy: 89.84%\n",
            "Epoch: 47, Step: 20/164, Loss: 0.305174, Accuracy: 89.84%\n",
            "Epoch: 47, Step: 21/164, Loss: 0.301348, Accuracy: 89.99%\n",
            "Epoch: 47, Step: 22/164, Loss: 0.297951, Accuracy: 90.13%\n",
            "Epoch: 47, Step: 23/164, Loss: 0.296346, Accuracy: 90.12%\n",
            "Epoch: 47, Step: 24/164, Loss: 0.294742, Accuracy: 90.14%\n",
            "Epoch: 47, Step: 25/164, Loss: 0.300326, Accuracy: 90.03%\n",
            "Epoch: 47, Step: 26/164, Loss: 0.298640, Accuracy: 90.20%\n",
            "Epoch: 47, Step: 27/164, Loss: 0.299302, Accuracy: 90.22%\n",
            "Epoch: 47, Step: 28/164, Loss: 0.296093, Accuracy: 90.35%\n",
            "Epoch: 47, Step: 29/164, Loss: 0.299543, Accuracy: 90.19%\n",
            "Epoch: 47, Step: 30/164, Loss: 0.298147, Accuracy: 90.26%\n",
            "Epoch: 47, Step: 31/164, Loss: 0.300362, Accuracy: 90.22%\n",
            "Epoch: 47, Step: 32/164, Loss: 0.299033, Accuracy: 90.23%\n",
            "Epoch: 47, Step: 33/164, Loss: 0.304494, Accuracy: 90.20%\n",
            "Epoch: 47, Step: 34/164, Loss: 0.307544, Accuracy: 90.12%\n",
            "Epoch: 47, Step: 35/164, Loss: 0.309227, Accuracy: 90.09%\n",
            "Epoch: 47, Step: 36/164, Loss: 0.307016, Accuracy: 90.08%\n",
            "Epoch: 47, Step: 37/164, Loss: 0.303985, Accuracy: 90.24%\n",
            "Epoch: 47, Step: 38/164, Loss: 0.304226, Accuracy: 90.23%\n",
            "Epoch: 47, Step: 39/164, Loss: 0.305003, Accuracy: 90.24%\n",
            "Epoch: 47, Step: 40/164, Loss: 0.302292, Accuracy: 90.33%\n",
            "Epoch: 47, Step: 41/164, Loss: 0.298858, Accuracy: 90.40%\n",
            "Epoch: 47, Step: 42/164, Loss: 0.298679, Accuracy: 90.42%\n",
            "Epoch: 47, Step: 43/164, Loss: 0.299028, Accuracy: 90.41%\n",
            "Epoch: 47, Step: 44/164, Loss: 0.299776, Accuracy: 90.36%\n",
            "Epoch: 47, Step: 45/164, Loss: 0.300742, Accuracy: 90.31%\n",
            "Epoch: 47, Step: 46/164, Loss: 0.298015, Accuracy: 90.42%\n",
            "Epoch: 47, Step: 47/164, Loss: 0.297779, Accuracy: 90.44%\n",
            "Epoch: 47, Step: 48/164, Loss: 0.298000, Accuracy: 90.43%\n",
            "Epoch: 47, Step: 49/164, Loss: 0.298078, Accuracy: 90.42%\n",
            "Epoch: 47, Step: 50/164, Loss: 0.298193, Accuracy: 90.39%\n",
            "Epoch: 47, Step: 51/164, Loss: 0.298960, Accuracy: 90.36%\n",
            "Epoch: 47, Step: 52/164, Loss: 0.300254, Accuracy: 90.31%\n",
            "Epoch: 47, Step: 53/164, Loss: 0.302607, Accuracy: 90.21%\n",
            "Epoch: 47, Step: 54/164, Loss: 0.304196, Accuracy: 90.18%\n",
            "Epoch: 47, Step: 55/164, Loss: 0.302780, Accuracy: 90.20%\n",
            "Epoch: 47, Step: 56/164, Loss: 0.302759, Accuracy: 90.21%\n",
            "Epoch: 47, Step: 57/164, Loss: 0.301593, Accuracy: 90.23%\n",
            "Epoch: 47, Step: 58/164, Loss: 0.299187, Accuracy: 90.32%\n",
            "Epoch: 47, Step: 59/164, Loss: 0.299088, Accuracy: 90.29%\n",
            "Epoch: 47, Step: 60/164, Loss: 0.300578, Accuracy: 90.21%\n",
            "Epoch: 47, Step: 61/164, Loss: 0.300914, Accuracy: 90.18%\n",
            "Epoch: 47, Step: 62/164, Loss: 0.300874, Accuracy: 90.18%\n",
            "Epoch: 47, Step: 63/164, Loss: 0.300536, Accuracy: 90.22%\n",
            "Epoch: 47, Step: 64/164, Loss: 0.303132, Accuracy: 90.19%\n",
            "Epoch: 47, Step: 65/164, Loss: 0.302164, Accuracy: 90.24%\n",
            "Epoch: 47, Step: 66/164, Loss: 0.300650, Accuracy: 90.27%\n",
            "Epoch: 47, Step: 67/164, Loss: 0.300723, Accuracy: 90.22%\n",
            "Epoch: 47, Step: 68/164, Loss: 0.301571, Accuracy: 90.15%\n",
            "Epoch: 47, Step: 69/164, Loss: 0.301596, Accuracy: 90.16%\n",
            "Epoch: 47, Step: 70/164, Loss: 0.301815, Accuracy: 90.12%\n",
            "Epoch: 47, Step: 71/164, Loss: 0.301187, Accuracy: 90.14%\n",
            "Epoch: 47, Step: 72/164, Loss: 0.301462, Accuracy: 90.13%\n",
            "Epoch: 47, Step: 73/164, Loss: 0.301680, Accuracy: 90.11%\n",
            "Epoch: 47, Step: 74/164, Loss: 0.303101, Accuracy: 90.05%\n",
            "Epoch: 47, Step: 75/164, Loss: 0.302812, Accuracy: 90.07%\n",
            "Epoch: 47, Step: 76/164, Loss: 0.301412, Accuracy: 90.12%\n",
            "Epoch: 47, Step: 77/164, Loss: 0.301996, Accuracy: 90.14%\n",
            "Epoch: 47, Step: 78/164, Loss: 0.301640, Accuracy: 90.12%\n",
            "Epoch: 47, Step: 79/164, Loss: 0.301930, Accuracy: 90.13%\n",
            "Epoch: 47, Step: 80/164, Loss: 0.301255, Accuracy: 90.14%\n",
            "Epoch: 47, Step: 81/164, Loss: 0.301836, Accuracy: 90.09%\n",
            "Epoch: 47, Step: 82/164, Loss: 0.301700, Accuracy: 90.11%\n",
            "Epoch: 47, Step: 83/164, Loss: 0.302507, Accuracy: 90.09%\n",
            "Epoch: 47, Step: 84/164, Loss: 0.302610, Accuracy: 90.04%\n",
            "Epoch: 47, Step: 85/164, Loss: 0.302825, Accuracy: 90.04%\n",
            "Epoch: 47, Step: 86/164, Loss: 0.302818, Accuracy: 90.06%\n",
            "Epoch: 47, Step: 87/164, Loss: 0.302775, Accuracy: 90.09%\n",
            "Epoch: 47, Step: 88/164, Loss: 0.302954, Accuracy: 90.07%\n",
            "Epoch: 47, Step: 89/164, Loss: 0.303215, Accuracy: 90.05%\n",
            "Epoch: 47, Step: 90/164, Loss: 0.303307, Accuracy: 90.04%\n",
            "Epoch: 47, Step: 91/164, Loss: 0.302923, Accuracy: 90.05%\n",
            "Epoch: 47, Step: 92/164, Loss: 0.303539, Accuracy: 90.00%\n",
            "Epoch: 47, Step: 93/164, Loss: 0.304255, Accuracy: 89.96%\n",
            "Epoch: 47, Step: 94/164, Loss: 0.304212, Accuracy: 89.99%\n",
            "Epoch: 47, Step: 95/164, Loss: 0.303571, Accuracy: 90.00%\n",
            "Epoch: 47, Step: 96/164, Loss: 0.303014, Accuracy: 90.02%\n",
            "Epoch: 47, Step: 97/164, Loss: 0.302835, Accuracy: 90.02%\n",
            "Epoch: 47, Step: 98/164, Loss: 0.302140, Accuracy: 90.03%\n",
            "Epoch: 47, Step: 99/164, Loss: 0.302457, Accuracy: 89.99%\n",
            "Epoch: 47, Step: 100/164, Loss: 0.303207, Accuracy: 89.98%\n",
            "Epoch: 47, Step: 101/164, Loss: 0.303684, Accuracy: 89.96%\n",
            "Epoch: 47, Step: 102/164, Loss: 0.305184, Accuracy: 89.91%\n",
            "Epoch: 47, Step: 103/164, Loss: 0.304360, Accuracy: 89.97%\n",
            "Epoch: 47, Step: 104/164, Loss: 0.303424, Accuracy: 89.99%\n",
            "Epoch: 47, Step: 105/164, Loss: 0.304684, Accuracy: 89.93%\n",
            "Epoch: 47, Step: 106/164, Loss: 0.305200, Accuracy: 89.92%\n",
            "Epoch: 47, Step: 107/164, Loss: 0.305734, Accuracy: 89.90%\n",
            "Epoch: 47, Step: 108/164, Loss: 0.306304, Accuracy: 89.88%\n",
            "Epoch: 47, Step: 109/164, Loss: 0.305864, Accuracy: 89.90%\n",
            "Epoch: 47, Step: 110/164, Loss: 0.305948, Accuracy: 89.90%\n",
            "Epoch: 47, Step: 111/164, Loss: 0.307170, Accuracy: 89.86%\n",
            "Epoch: 47, Step: 112/164, Loss: 0.306465, Accuracy: 89.89%\n",
            "Epoch: 47, Step: 113/164, Loss: 0.306546, Accuracy: 89.88%\n",
            "Epoch: 47, Step: 114/164, Loss: 0.306589, Accuracy: 89.87%\n",
            "Epoch: 47, Step: 115/164, Loss: 0.306506, Accuracy: 89.86%\n",
            "Epoch: 47, Step: 116/164, Loss: 0.306493, Accuracy: 89.89%\n",
            "Epoch: 47, Step: 117/164, Loss: 0.306302, Accuracy: 89.91%\n",
            "Epoch: 47, Step: 118/164, Loss: 0.306307, Accuracy: 89.92%\n",
            "Epoch: 47, Step: 119/164, Loss: 0.307058, Accuracy: 89.90%\n",
            "Epoch: 47, Step: 120/164, Loss: 0.306837, Accuracy: 89.92%\n",
            "Epoch: 47, Step: 121/164, Loss: 0.307196, Accuracy: 89.90%\n",
            "Epoch: 47, Step: 122/164, Loss: 0.307015, Accuracy: 89.89%\n",
            "Epoch: 47, Step: 123/164, Loss: 0.306332, Accuracy: 89.91%\n",
            "Epoch: 47, Step: 124/164, Loss: 0.306004, Accuracy: 89.89%\n",
            "Epoch: 47, Step: 125/164, Loss: 0.305505, Accuracy: 89.89%\n",
            "Epoch: 47, Step: 126/164, Loss: 0.305813, Accuracy: 89.89%\n",
            "Epoch: 47, Step: 127/164, Loss: 0.306192, Accuracy: 89.87%\n",
            "Epoch: 47, Step: 128/164, Loss: 0.307607, Accuracy: 89.83%\n",
            "Epoch: 47, Step: 129/164, Loss: 0.306689, Accuracy: 89.87%\n",
            "Epoch: 47, Step: 130/164, Loss: 0.306807, Accuracy: 89.86%\n",
            "Epoch: 47, Step: 131/164, Loss: 0.306624, Accuracy: 89.85%\n",
            "Epoch: 47, Step: 132/164, Loss: 0.305849, Accuracy: 89.86%\n",
            "Epoch: 47, Step: 133/164, Loss: 0.306642, Accuracy: 89.82%\n",
            "Epoch: 47, Step: 134/164, Loss: 0.306177, Accuracy: 89.83%\n",
            "Epoch: 47, Step: 135/164, Loss: 0.305896, Accuracy: 89.82%\n",
            "Epoch: 47, Step: 136/164, Loss: 0.306792, Accuracy: 89.79%\n",
            "Epoch: 47, Step: 137/164, Loss: 0.306449, Accuracy: 89.79%\n",
            "Epoch: 47, Step: 138/164, Loss: 0.306143, Accuracy: 89.80%\n",
            "Epoch: 47, Step: 139/164, Loss: 0.306434, Accuracy: 89.77%\n",
            "Epoch: 47, Step: 140/164, Loss: 0.306388, Accuracy: 89.77%\n",
            "Epoch: 47, Step: 141/164, Loss: 0.306752, Accuracy: 89.75%\n",
            "Epoch: 47, Step: 142/164, Loss: 0.306542, Accuracy: 89.74%\n",
            "Epoch: 47, Step: 143/164, Loss: 0.306644, Accuracy: 89.74%\n",
            "Epoch: 47, Step: 144/164, Loss: 0.306527, Accuracy: 89.74%\n",
            "Epoch: 47, Step: 145/164, Loss: 0.306908, Accuracy: 89.73%\n",
            "Epoch: 47, Step: 146/164, Loss: 0.306879, Accuracy: 89.73%\n",
            "Epoch: 47, Step: 147/164, Loss: 0.307379, Accuracy: 89.71%\n",
            "Epoch: 47, Step: 148/164, Loss: 0.306888, Accuracy: 89.73%\n",
            "Epoch: 47, Step: 149/164, Loss: 0.306829, Accuracy: 89.73%\n",
            "Epoch: 47, Step: 150/164, Loss: 0.306206, Accuracy: 89.75%\n",
            "Epoch: 47, Step: 151/164, Loss: 0.306981, Accuracy: 89.72%\n",
            "Epoch: 47, Step: 152/164, Loss: 0.306601, Accuracy: 89.72%\n",
            "Epoch: 47, Step: 153/164, Loss: 0.306476, Accuracy: 89.71%\n",
            "Epoch: 47, Step: 154/164, Loss: 0.305999, Accuracy: 89.73%\n",
            "Epoch: 47, Step: 155/164, Loss: 0.305848, Accuracy: 89.73%\n",
            "Epoch: 47, Step: 156/164, Loss: 0.306671, Accuracy: 89.71%\n",
            "Epoch: 47, Step: 157/164, Loss: 0.307131, Accuracy: 89.70%\n",
            "Epoch: 47, Step: 158/164, Loss: 0.306826, Accuracy: 89.71%\n",
            "Epoch: 47, Step: 159/164, Loss: 0.306883, Accuracy: 89.70%\n",
            "Epoch: 47, Step: 160/164, Loss: 0.307244, Accuracy: 89.68%\n",
            "Epoch: 47, Step: 161/164, Loss: 0.307388, Accuracy: 89.69%\n",
            "Epoch: 47, Step: 162/164, Loss: 0.306695, Accuracy: 89.71%\n",
            "Epoch: 47, Step: 163/164, Loss: 0.306864, Accuracy: 89.69%\n",
            "Epoch: 47, Step: 164/164, Loss: 0.306345, Accuracy: 89.70%\n",
            "Epoch: 48, Step: 1/164, Loss: 0.315650, Accuracy: 89.84%\n",
            "Epoch: 48, Step: 2/164, Loss: 0.270282, Accuracy: 92.19%\n",
            "Epoch: 48, Step: 3/164, Loss: 0.316019, Accuracy: 90.89%\n",
            "Epoch: 48, Step: 4/164, Loss: 0.314672, Accuracy: 89.84%\n",
            "Epoch: 48, Step: 5/164, Loss: 0.326996, Accuracy: 89.22%\n",
            "Epoch: 48, Step: 6/164, Loss: 0.317997, Accuracy: 89.19%\n",
            "Epoch: 48, Step: 7/164, Loss: 0.318232, Accuracy: 89.29%\n",
            "Epoch: 48, Step: 8/164, Loss: 0.330016, Accuracy: 88.96%\n",
            "Epoch: 48, Step: 9/164, Loss: 0.322395, Accuracy: 89.24%\n",
            "Epoch: 48, Step: 10/164, Loss: 0.334121, Accuracy: 88.52%\n",
            "Epoch: 48, Step: 11/164, Loss: 0.329660, Accuracy: 88.64%\n",
            "Epoch: 48, Step: 12/164, Loss: 0.329327, Accuracy: 88.61%\n",
            "Epoch: 48, Step: 13/164, Loss: 0.329519, Accuracy: 88.46%\n",
            "Epoch: 48, Step: 14/164, Loss: 0.328090, Accuracy: 88.62%\n",
            "Epoch: 48, Step: 15/164, Loss: 0.324960, Accuracy: 88.65%\n",
            "Epoch: 48, Step: 16/164, Loss: 0.323502, Accuracy: 88.67%\n",
            "Epoch: 48, Step: 17/164, Loss: 0.321308, Accuracy: 88.79%\n",
            "Epoch: 48, Step: 18/164, Loss: 0.317603, Accuracy: 88.93%\n",
            "Epoch: 48, Step: 19/164, Loss: 0.315242, Accuracy: 89.02%\n",
            "Epoch: 48, Step: 20/164, Loss: 0.313154, Accuracy: 89.18%\n",
            "Epoch: 48, Step: 21/164, Loss: 0.311849, Accuracy: 89.29%\n",
            "Epoch: 48, Step: 22/164, Loss: 0.318588, Accuracy: 89.24%\n",
            "Epoch: 48, Step: 23/164, Loss: 0.317753, Accuracy: 89.30%\n",
            "Epoch: 48, Step: 24/164, Loss: 0.313668, Accuracy: 89.45%\n",
            "Epoch: 48, Step: 25/164, Loss: 0.310790, Accuracy: 89.59%\n",
            "Epoch: 48, Step: 26/164, Loss: 0.312159, Accuracy: 89.57%\n",
            "Epoch: 48, Step: 27/164, Loss: 0.314790, Accuracy: 89.50%\n",
            "Epoch: 48, Step: 28/164, Loss: 0.315631, Accuracy: 89.51%\n",
            "Epoch: 48, Step: 29/164, Loss: 0.313401, Accuracy: 89.66%\n",
            "Epoch: 48, Step: 30/164, Loss: 0.311083, Accuracy: 89.61%\n",
            "Epoch: 48, Step: 31/164, Loss: 0.309908, Accuracy: 89.59%\n",
            "Epoch: 48, Step: 32/164, Loss: 0.307948, Accuracy: 89.60%\n",
            "Epoch: 48, Step: 33/164, Loss: 0.307110, Accuracy: 89.63%\n",
            "Epoch: 48, Step: 34/164, Loss: 0.307354, Accuracy: 89.68%\n",
            "Epoch: 48, Step: 35/164, Loss: 0.309720, Accuracy: 89.55%\n",
            "Epoch: 48, Step: 36/164, Loss: 0.309783, Accuracy: 89.52%\n",
            "Epoch: 48, Step: 37/164, Loss: 0.312122, Accuracy: 89.44%\n",
            "Epoch: 48, Step: 38/164, Loss: 0.310977, Accuracy: 89.49%\n",
            "Epoch: 48, Step: 39/164, Loss: 0.309474, Accuracy: 89.56%\n",
            "Epoch: 48, Step: 40/164, Loss: 0.307133, Accuracy: 89.67%\n",
            "Epoch: 48, Step: 41/164, Loss: 0.305158, Accuracy: 89.71%\n",
            "Epoch: 48, Step: 42/164, Loss: 0.304538, Accuracy: 89.77%\n",
            "Epoch: 48, Step: 43/164, Loss: 0.302041, Accuracy: 89.86%\n",
            "Epoch: 48, Step: 44/164, Loss: 0.302093, Accuracy: 89.84%\n",
            "Epoch: 48, Step: 45/164, Loss: 0.301028, Accuracy: 89.90%\n",
            "Epoch: 48, Step: 46/164, Loss: 0.298692, Accuracy: 89.98%\n",
            "Epoch: 48, Step: 47/164, Loss: 0.299725, Accuracy: 89.91%\n",
            "Epoch: 48, Step: 48/164, Loss: 0.301651, Accuracy: 89.79%\n",
            "Epoch: 48, Step: 49/164, Loss: 0.301864, Accuracy: 89.80%\n",
            "Epoch: 48, Step: 50/164, Loss: 0.299528, Accuracy: 89.89%\n",
            "Epoch: 48, Step: 51/164, Loss: 0.299823, Accuracy: 89.92%\n",
            "Epoch: 48, Step: 52/164, Loss: 0.300675, Accuracy: 89.90%\n",
            "Epoch: 48, Step: 53/164, Loss: 0.303867, Accuracy: 89.78%\n",
            "Epoch: 48, Step: 54/164, Loss: 0.301467, Accuracy: 89.87%\n",
            "Epoch: 48, Step: 55/164, Loss: 0.301156, Accuracy: 89.90%\n",
            "Epoch: 48, Step: 56/164, Loss: 0.304170, Accuracy: 89.86%\n",
            "Epoch: 48, Step: 57/164, Loss: 0.303143, Accuracy: 89.88%\n",
            "Epoch: 48, Step: 58/164, Loss: 0.302072, Accuracy: 89.91%\n",
            "Epoch: 48, Step: 59/164, Loss: 0.302999, Accuracy: 89.91%\n",
            "Epoch: 48, Step: 60/164, Loss: 0.302141, Accuracy: 89.92%\n",
            "Epoch: 48, Step: 61/164, Loss: 0.303388, Accuracy: 89.88%\n",
            "Epoch: 48, Step: 62/164, Loss: 0.302211, Accuracy: 89.92%\n",
            "Epoch: 48, Step: 63/164, Loss: 0.302158, Accuracy: 89.91%\n",
            "Epoch: 48, Step: 64/164, Loss: 0.302541, Accuracy: 89.88%\n",
            "Epoch: 48, Step: 65/164, Loss: 0.301857, Accuracy: 89.88%\n",
            "Epoch: 48, Step: 66/164, Loss: 0.303148, Accuracy: 89.86%\n",
            "Epoch: 48, Step: 67/164, Loss: 0.303752, Accuracy: 89.86%\n",
            "Epoch: 48, Step: 68/164, Loss: 0.304305, Accuracy: 89.81%\n",
            "Epoch: 48, Step: 69/164, Loss: 0.304321, Accuracy: 89.82%\n",
            "Epoch: 48, Step: 70/164, Loss: 0.304230, Accuracy: 89.82%\n",
            "Epoch: 48, Step: 71/164, Loss: 0.304440, Accuracy: 89.79%\n",
            "Epoch: 48, Step: 72/164, Loss: 0.304346, Accuracy: 89.75%\n",
            "Epoch: 48, Step: 73/164, Loss: 0.305652, Accuracy: 89.72%\n",
            "Epoch: 48, Step: 74/164, Loss: 0.306496, Accuracy: 89.64%\n",
            "Epoch: 48, Step: 75/164, Loss: 0.307341, Accuracy: 89.64%\n",
            "Epoch: 48, Step: 76/164, Loss: 0.308614, Accuracy: 89.55%\n",
            "Epoch: 48, Step: 77/164, Loss: 0.307911, Accuracy: 89.54%\n",
            "Epoch: 48, Step: 78/164, Loss: 0.307016, Accuracy: 89.55%\n",
            "Epoch: 48, Step: 79/164, Loss: 0.306495, Accuracy: 89.56%\n",
            "Epoch: 48, Step: 80/164, Loss: 0.306328, Accuracy: 89.59%\n",
            "Epoch: 48, Step: 81/164, Loss: 0.306807, Accuracy: 89.54%\n",
            "Epoch: 48, Step: 82/164, Loss: 0.306991, Accuracy: 89.49%\n",
            "Epoch: 48, Step: 83/164, Loss: 0.308361, Accuracy: 89.46%\n",
            "Epoch: 48, Step: 84/164, Loss: 0.308646, Accuracy: 89.48%\n",
            "Epoch: 48, Step: 85/164, Loss: 0.308084, Accuracy: 89.52%\n",
            "Epoch: 48, Step: 86/164, Loss: 0.308571, Accuracy: 89.53%\n",
            "Epoch: 48, Step: 87/164, Loss: 0.308186, Accuracy: 89.55%\n",
            "Epoch: 48, Step: 88/164, Loss: 0.309509, Accuracy: 89.51%\n",
            "Epoch: 48, Step: 89/164, Loss: 0.309863, Accuracy: 89.48%\n",
            "Epoch: 48, Step: 90/164, Loss: 0.310182, Accuracy: 89.48%\n",
            "Epoch: 48, Step: 91/164, Loss: 0.309850, Accuracy: 89.47%\n",
            "Epoch: 48, Step: 92/164, Loss: 0.310376, Accuracy: 89.43%\n",
            "Epoch: 48, Step: 93/164, Loss: 0.310024, Accuracy: 89.40%\n",
            "Epoch: 48, Step: 94/164, Loss: 0.309566, Accuracy: 89.40%\n",
            "Epoch: 48, Step: 95/164, Loss: 0.309593, Accuracy: 89.42%\n",
            "Epoch: 48, Step: 96/164, Loss: 0.310216, Accuracy: 89.40%\n",
            "Epoch: 48, Step: 97/164, Loss: 0.310392, Accuracy: 89.38%\n",
            "Epoch: 48, Step: 98/164, Loss: 0.310236, Accuracy: 89.39%\n",
            "Epoch: 48, Step: 99/164, Loss: 0.310360, Accuracy: 89.39%\n",
            "Epoch: 48, Step: 100/164, Loss: 0.310006, Accuracy: 89.39%\n",
            "Epoch: 48, Step: 101/164, Loss: 0.309094, Accuracy: 89.44%\n",
            "Epoch: 48, Step: 102/164, Loss: 0.308555, Accuracy: 89.44%\n",
            "Epoch: 48, Step: 103/164, Loss: 0.308562, Accuracy: 89.45%\n",
            "Epoch: 48, Step: 104/164, Loss: 0.309690, Accuracy: 89.44%\n",
            "Epoch: 48, Step: 105/164, Loss: 0.309885, Accuracy: 89.43%\n",
            "Epoch: 48, Step: 106/164, Loss: 0.310262, Accuracy: 89.42%\n",
            "Epoch: 48, Step: 107/164, Loss: 0.310679, Accuracy: 89.41%\n",
            "Epoch: 48, Step: 108/164, Loss: 0.310913, Accuracy: 89.40%\n",
            "Epoch: 48, Step: 109/164, Loss: 0.310474, Accuracy: 89.41%\n",
            "Epoch: 48, Step: 110/164, Loss: 0.310295, Accuracy: 89.43%\n",
            "Epoch: 48, Step: 111/164, Loss: 0.311152, Accuracy: 89.38%\n",
            "Epoch: 48, Step: 112/164, Loss: 0.311591, Accuracy: 89.38%\n",
            "Epoch: 48, Step: 113/164, Loss: 0.310874, Accuracy: 89.41%\n",
            "Epoch: 48, Step: 114/164, Loss: 0.310213, Accuracy: 89.43%\n",
            "Epoch: 48, Step: 115/164, Loss: 0.310190, Accuracy: 89.44%\n",
            "Epoch: 48, Step: 116/164, Loss: 0.310895, Accuracy: 89.42%\n",
            "Epoch: 48, Step: 117/164, Loss: 0.311147, Accuracy: 89.42%\n",
            "Epoch: 48, Step: 118/164, Loss: 0.310673, Accuracy: 89.45%\n",
            "Epoch: 48, Step: 119/164, Loss: 0.310150, Accuracy: 89.46%\n",
            "Epoch: 48, Step: 120/164, Loss: 0.309740, Accuracy: 89.48%\n",
            "Epoch: 48, Step: 121/164, Loss: 0.310122, Accuracy: 89.46%\n",
            "Epoch: 48, Step: 122/164, Loss: 0.309764, Accuracy: 89.47%\n",
            "Epoch: 48, Step: 123/164, Loss: 0.309932, Accuracy: 89.47%\n",
            "Epoch: 48, Step: 124/164, Loss: 0.310218, Accuracy: 89.46%\n",
            "Epoch: 48, Step: 125/164, Loss: 0.309720, Accuracy: 89.46%\n",
            "Epoch: 48, Step: 126/164, Loss: 0.310191, Accuracy: 89.46%\n",
            "Epoch: 48, Step: 127/164, Loss: 0.311165, Accuracy: 89.42%\n",
            "Epoch: 48, Step: 128/164, Loss: 0.311228, Accuracy: 89.41%\n",
            "Epoch: 48, Step: 129/164, Loss: 0.311981, Accuracy: 89.38%\n",
            "Epoch: 48, Step: 130/164, Loss: 0.312582, Accuracy: 89.34%\n",
            "Epoch: 48, Step: 131/164, Loss: 0.312677, Accuracy: 89.33%\n",
            "Epoch: 48, Step: 132/164, Loss: 0.312779, Accuracy: 89.32%\n",
            "Epoch: 48, Step: 133/164, Loss: 0.313181, Accuracy: 89.30%\n",
            "Epoch: 48, Step: 134/164, Loss: 0.313614, Accuracy: 89.28%\n",
            "Epoch: 48, Step: 135/164, Loss: 0.314319, Accuracy: 89.26%\n",
            "Epoch: 48, Step: 136/164, Loss: 0.314383, Accuracy: 89.27%\n",
            "Epoch: 48, Step: 137/164, Loss: 0.314941, Accuracy: 89.24%\n",
            "Epoch: 48, Step: 138/164, Loss: 0.314779, Accuracy: 89.23%\n",
            "Epoch: 48, Step: 139/164, Loss: 0.314692, Accuracy: 89.24%\n",
            "Epoch: 48, Step: 140/164, Loss: 0.314263, Accuracy: 89.25%\n",
            "Epoch: 48, Step: 141/164, Loss: 0.313851, Accuracy: 89.27%\n",
            "Epoch: 48, Step: 142/164, Loss: 0.312903, Accuracy: 89.32%\n",
            "Epoch: 48, Step: 143/164, Loss: 0.312759, Accuracy: 89.34%\n",
            "Epoch: 48, Step: 144/164, Loss: 0.312863, Accuracy: 89.34%\n",
            "Epoch: 48, Step: 145/164, Loss: 0.312750, Accuracy: 89.35%\n",
            "Epoch: 48, Step: 146/164, Loss: 0.312268, Accuracy: 89.37%\n",
            "Epoch: 48, Step: 147/164, Loss: 0.312493, Accuracy: 89.36%\n",
            "Epoch: 48, Step: 148/164, Loss: 0.311865, Accuracy: 89.38%\n",
            "Epoch: 48, Step: 149/164, Loss: 0.311289, Accuracy: 89.41%\n",
            "Epoch: 48, Step: 150/164, Loss: 0.310556, Accuracy: 89.43%\n",
            "Epoch: 48, Step: 151/164, Loss: 0.310546, Accuracy: 89.42%\n",
            "Epoch: 48, Step: 152/164, Loss: 0.311354, Accuracy: 89.40%\n",
            "Epoch: 48, Step: 153/164, Loss: 0.311242, Accuracy: 89.41%\n",
            "Epoch: 48, Step: 154/164, Loss: 0.311315, Accuracy: 89.41%\n",
            "Epoch: 48, Step: 155/164, Loss: 0.311040, Accuracy: 89.42%\n",
            "Epoch: 48, Step: 156/164, Loss: 0.311185, Accuracy: 89.44%\n",
            "Epoch: 48, Step: 157/164, Loss: 0.311826, Accuracy: 89.43%\n",
            "Epoch: 48, Step: 158/164, Loss: 0.311323, Accuracy: 89.42%\n",
            "Epoch: 48, Step: 159/164, Loss: 0.310747, Accuracy: 89.44%\n",
            "Epoch: 48, Step: 160/164, Loss: 0.310787, Accuracy: 89.44%\n",
            "Epoch: 48, Step: 161/164, Loss: 0.310780, Accuracy: 89.44%\n",
            "Epoch: 48, Step: 162/164, Loss: 0.310005, Accuracy: 89.46%\n",
            "Epoch: 48, Step: 163/164, Loss: 0.310293, Accuracy: 89.44%\n",
            "Epoch: 48, Step: 164/164, Loss: 0.309288, Accuracy: 89.46%\n",
            "Epoch: 49, Step: 1/164, Loss: 0.306710, Accuracy: 89.84%\n",
            "Epoch: 49, Step: 2/164, Loss: 0.270204, Accuracy: 92.19%\n",
            "Epoch: 49, Step: 3/164, Loss: 0.239301, Accuracy: 92.71%\n",
            "Epoch: 49, Step: 4/164, Loss: 0.257865, Accuracy: 92.19%\n",
            "Epoch: 49, Step: 5/164, Loss: 0.251343, Accuracy: 92.19%\n",
            "Epoch: 49, Step: 6/164, Loss: 0.275215, Accuracy: 91.67%\n",
            "Epoch: 49, Step: 7/164, Loss: 0.278845, Accuracy: 91.18%\n",
            "Epoch: 49, Step: 8/164, Loss: 0.286387, Accuracy: 90.72%\n",
            "Epoch: 49, Step: 9/164, Loss: 0.283111, Accuracy: 90.62%\n",
            "Epoch: 49, Step: 10/164, Loss: 0.281810, Accuracy: 90.70%\n",
            "Epoch: 49, Step: 11/164, Loss: 0.281242, Accuracy: 90.77%\n",
            "Epoch: 49, Step: 12/164, Loss: 0.281323, Accuracy: 90.76%\n",
            "Epoch: 49, Step: 13/164, Loss: 0.273980, Accuracy: 91.05%\n",
            "Epoch: 49, Step: 14/164, Loss: 0.278790, Accuracy: 90.79%\n",
            "Epoch: 49, Step: 15/164, Loss: 0.283141, Accuracy: 90.68%\n",
            "Epoch: 49, Step: 16/164, Loss: 0.283176, Accuracy: 90.77%\n",
            "Epoch: 49, Step: 17/164, Loss: 0.287665, Accuracy: 90.67%\n",
            "Epoch: 49, Step: 18/164, Loss: 0.286504, Accuracy: 90.76%\n",
            "Epoch: 49, Step: 19/164, Loss: 0.284916, Accuracy: 90.75%\n",
            "Epoch: 49, Step: 20/164, Loss: 0.282871, Accuracy: 90.74%\n",
            "Epoch: 49, Step: 21/164, Loss: 0.280363, Accuracy: 90.77%\n",
            "Epoch: 49, Step: 22/164, Loss: 0.291778, Accuracy: 90.52%\n",
            "Epoch: 49, Step: 23/164, Loss: 0.291442, Accuracy: 90.56%\n",
            "Epoch: 49, Step: 24/164, Loss: 0.295694, Accuracy: 90.46%\n",
            "Epoch: 49, Step: 25/164, Loss: 0.295547, Accuracy: 90.47%\n",
            "Epoch: 49, Step: 26/164, Loss: 0.296821, Accuracy: 90.47%\n",
            "Epoch: 49, Step: 27/164, Loss: 0.293147, Accuracy: 90.62%\n",
            "Epoch: 49, Step: 28/164, Loss: 0.294426, Accuracy: 90.60%\n",
            "Epoch: 49, Step: 29/164, Loss: 0.294905, Accuracy: 90.38%\n",
            "Epoch: 49, Step: 30/164, Loss: 0.290593, Accuracy: 90.60%\n",
            "Epoch: 49, Step: 31/164, Loss: 0.289654, Accuracy: 90.68%\n",
            "Epoch: 49, Step: 32/164, Loss: 0.288611, Accuracy: 90.70%\n",
            "Epoch: 49, Step: 33/164, Loss: 0.287549, Accuracy: 90.81%\n",
            "Epoch: 49, Step: 34/164, Loss: 0.287216, Accuracy: 90.81%\n",
            "Epoch: 49, Step: 35/164, Loss: 0.288835, Accuracy: 90.83%\n",
            "Epoch: 49, Step: 36/164, Loss: 0.292002, Accuracy: 90.71%\n",
            "Epoch: 49, Step: 37/164, Loss: 0.294888, Accuracy: 90.58%\n",
            "Epoch: 49, Step: 38/164, Loss: 0.293430, Accuracy: 90.58%\n",
            "Epoch: 49, Step: 39/164, Loss: 0.293798, Accuracy: 90.60%\n",
            "Epoch: 49, Step: 40/164, Loss: 0.293481, Accuracy: 90.59%\n",
            "Epoch: 49, Step: 41/164, Loss: 0.292712, Accuracy: 90.62%\n",
            "Epoch: 49, Step: 42/164, Loss: 0.290121, Accuracy: 90.72%\n",
            "Epoch: 49, Step: 43/164, Loss: 0.291115, Accuracy: 90.70%\n",
            "Epoch: 49, Step: 44/164, Loss: 0.291827, Accuracy: 90.61%\n",
            "Epoch: 49, Step: 45/164, Loss: 0.292275, Accuracy: 90.64%\n",
            "Epoch: 49, Step: 46/164, Loss: 0.291305, Accuracy: 90.71%\n",
            "Epoch: 49, Step: 47/164, Loss: 0.290365, Accuracy: 90.79%\n",
            "Epoch: 49, Step: 48/164, Loss: 0.292880, Accuracy: 90.64%\n",
            "Epoch: 49, Step: 49/164, Loss: 0.293718, Accuracy: 90.58%\n",
            "Epoch: 49, Step: 50/164, Loss: 0.294551, Accuracy: 90.55%\n",
            "Epoch: 49, Step: 51/164, Loss: 0.293124, Accuracy: 90.62%\n",
            "Epoch: 49, Step: 52/164, Loss: 0.292049, Accuracy: 90.66%\n",
            "Epoch: 49, Step: 53/164, Loss: 0.294512, Accuracy: 90.61%\n",
            "Epoch: 49, Step: 54/164, Loss: 0.294772, Accuracy: 90.55%\n",
            "Epoch: 49, Step: 55/164, Loss: 0.293492, Accuracy: 90.58%\n",
            "Epoch: 49, Step: 56/164, Loss: 0.295356, Accuracy: 90.50%\n",
            "Epoch: 49, Step: 57/164, Loss: 0.297511, Accuracy: 90.42%\n",
            "Epoch: 49, Step: 58/164, Loss: 0.296947, Accuracy: 90.45%\n",
            "Epoch: 49, Step: 59/164, Loss: 0.298753, Accuracy: 90.37%\n",
            "Epoch: 49, Step: 60/164, Loss: 0.299262, Accuracy: 90.34%\n",
            "Epoch: 49, Step: 61/164, Loss: 0.298960, Accuracy: 90.33%\n",
            "Epoch: 49, Step: 62/164, Loss: 0.298028, Accuracy: 90.39%\n",
            "Epoch: 49, Step: 63/164, Loss: 0.297387, Accuracy: 90.44%\n",
            "Epoch: 49, Step: 64/164, Loss: 0.297760, Accuracy: 90.39%\n",
            "Epoch: 49, Step: 65/164, Loss: 0.299683, Accuracy: 90.29%\n",
            "Epoch: 49, Step: 66/164, Loss: 0.299980, Accuracy: 90.28%\n",
            "Epoch: 49, Step: 67/164, Loss: 0.300358, Accuracy: 90.23%\n",
            "Epoch: 49, Step: 68/164, Loss: 0.301045, Accuracy: 90.23%\n",
            "Epoch: 49, Step: 69/164, Loss: 0.300195, Accuracy: 90.31%\n",
            "Epoch: 49, Step: 70/164, Loss: 0.299360, Accuracy: 90.33%\n",
            "Epoch: 49, Step: 71/164, Loss: 0.298835, Accuracy: 90.35%\n",
            "Epoch: 49, Step: 72/164, Loss: 0.299231, Accuracy: 90.30%\n",
            "Epoch: 49, Step: 73/164, Loss: 0.299130, Accuracy: 90.31%\n",
            "Epoch: 49, Step: 74/164, Loss: 0.300341, Accuracy: 90.29%\n",
            "Epoch: 49, Step: 75/164, Loss: 0.301846, Accuracy: 90.24%\n",
            "Epoch: 49, Step: 76/164, Loss: 0.302335, Accuracy: 90.23%\n",
            "Epoch: 49, Step: 77/164, Loss: 0.303236, Accuracy: 90.22%\n",
            "Epoch: 49, Step: 78/164, Loss: 0.303898, Accuracy: 90.18%\n",
            "Epoch: 49, Step: 79/164, Loss: 0.303566, Accuracy: 90.22%\n",
            "Epoch: 49, Step: 80/164, Loss: 0.303238, Accuracy: 90.26%\n",
            "Epoch: 49, Step: 81/164, Loss: 0.302308, Accuracy: 90.28%\n",
            "Epoch: 49, Step: 82/164, Loss: 0.303001, Accuracy: 90.25%\n",
            "Epoch: 49, Step: 83/164, Loss: 0.303369, Accuracy: 90.26%\n",
            "Epoch: 49, Step: 84/164, Loss: 0.303424, Accuracy: 90.27%\n",
            "Epoch: 49, Step: 85/164, Loss: 0.303604, Accuracy: 90.22%\n",
            "Epoch: 49, Step: 86/164, Loss: 0.303839, Accuracy: 90.20%\n",
            "Epoch: 49, Step: 87/164, Loss: 0.304083, Accuracy: 90.19%\n",
            "Epoch: 49, Step: 88/164, Loss: 0.304190, Accuracy: 90.19%\n",
            "Epoch: 49, Step: 89/164, Loss: 0.304336, Accuracy: 90.19%\n",
            "Epoch: 49, Step: 90/164, Loss: 0.304519, Accuracy: 90.18%\n",
            "Epoch: 49, Step: 91/164, Loss: 0.304499, Accuracy: 90.18%\n",
            "Epoch: 49, Step: 92/164, Loss: 0.305176, Accuracy: 90.16%\n",
            "Epoch: 49, Step: 93/164, Loss: 0.304920, Accuracy: 90.17%\n",
            "Epoch: 49, Step: 94/164, Loss: 0.305163, Accuracy: 90.17%\n",
            "Epoch: 49, Step: 95/164, Loss: 0.306262, Accuracy: 90.13%\n",
            "Epoch: 49, Step: 96/164, Loss: 0.306835, Accuracy: 90.11%\n",
            "Epoch: 49, Step: 97/164, Loss: 0.305566, Accuracy: 90.14%\n",
            "Epoch: 49, Step: 98/164, Loss: 0.306534, Accuracy: 90.10%\n",
            "Epoch: 49, Step: 99/164, Loss: 0.308678, Accuracy: 90.03%\n",
            "Epoch: 49, Step: 100/164, Loss: 0.308906, Accuracy: 89.99%\n",
            "Epoch: 49, Step: 101/164, Loss: 0.308962, Accuracy: 90.01%\n",
            "Epoch: 49, Step: 102/164, Loss: 0.308744, Accuracy: 89.98%\n",
            "Epoch: 49, Step: 103/164, Loss: 0.307850, Accuracy: 90.00%\n",
            "Epoch: 49, Step: 104/164, Loss: 0.308271, Accuracy: 89.97%\n",
            "Epoch: 49, Step: 105/164, Loss: 0.307119, Accuracy: 90.01%\n",
            "Epoch: 49, Step: 106/164, Loss: 0.308511, Accuracy: 89.98%\n",
            "Epoch: 49, Step: 107/164, Loss: 0.308311, Accuracy: 89.99%\n",
            "Epoch: 49, Step: 108/164, Loss: 0.307792, Accuracy: 90.00%\n",
            "Epoch: 49, Step: 109/164, Loss: 0.308672, Accuracy: 89.99%\n",
            "Epoch: 49, Step: 110/164, Loss: 0.308878, Accuracy: 89.99%\n",
            "Epoch: 49, Step: 111/164, Loss: 0.309707, Accuracy: 89.96%\n",
            "Epoch: 49, Step: 112/164, Loss: 0.309557, Accuracy: 89.96%\n",
            "Epoch: 49, Step: 113/164, Loss: 0.310141, Accuracy: 89.93%\n",
            "Epoch: 49, Step: 114/164, Loss: 0.310334, Accuracy: 89.93%\n",
            "Epoch: 49, Step: 115/164, Loss: 0.310299, Accuracy: 89.95%\n",
            "Epoch: 49, Step: 116/164, Loss: 0.309529, Accuracy: 89.96%\n",
            "Epoch: 49, Step: 117/164, Loss: 0.308895, Accuracy: 89.99%\n",
            "Epoch: 49, Step: 118/164, Loss: 0.308814, Accuracy: 89.98%\n",
            "Epoch: 49, Step: 119/164, Loss: 0.309948, Accuracy: 89.94%\n",
            "Epoch: 49, Step: 120/164, Loss: 0.309651, Accuracy: 89.95%\n",
            "Epoch: 49, Step: 121/164, Loss: 0.311108, Accuracy: 89.91%\n",
            "Epoch: 49, Step: 122/164, Loss: 0.311016, Accuracy: 89.91%\n",
            "Epoch: 49, Step: 123/164, Loss: 0.311290, Accuracy: 89.89%\n",
            "Epoch: 49, Step: 124/164, Loss: 0.311786, Accuracy: 89.89%\n",
            "Epoch: 49, Step: 125/164, Loss: 0.311424, Accuracy: 89.89%\n",
            "Epoch: 49, Step: 126/164, Loss: 0.311428, Accuracy: 89.87%\n",
            "Epoch: 49, Step: 127/164, Loss: 0.311801, Accuracy: 89.86%\n",
            "Epoch: 49, Step: 128/164, Loss: 0.310503, Accuracy: 89.89%\n",
            "Epoch: 49, Step: 129/164, Loss: 0.310660, Accuracy: 89.86%\n",
            "Epoch: 49, Step: 130/164, Loss: 0.310064, Accuracy: 89.89%\n",
            "Epoch: 49, Step: 131/164, Loss: 0.309610, Accuracy: 89.92%\n",
            "Epoch: 49, Step: 132/164, Loss: 0.310498, Accuracy: 89.87%\n",
            "Epoch: 49, Step: 133/164, Loss: 0.310559, Accuracy: 89.87%\n",
            "Epoch: 49, Step: 134/164, Loss: 0.309698, Accuracy: 89.90%\n",
            "Epoch: 49, Step: 135/164, Loss: 0.308890, Accuracy: 89.92%\n",
            "Epoch: 49, Step: 136/164, Loss: 0.309258, Accuracy: 89.90%\n",
            "Epoch: 49, Step: 137/164, Loss: 0.309905, Accuracy: 89.88%\n",
            "Epoch: 49, Step: 138/164, Loss: 0.309193, Accuracy: 89.89%\n",
            "Epoch: 49, Step: 139/164, Loss: 0.309390, Accuracy: 89.85%\n",
            "Epoch: 49, Step: 140/164, Loss: 0.309319, Accuracy: 89.85%\n",
            "Epoch: 49, Step: 141/164, Loss: 0.309802, Accuracy: 89.84%\n",
            "Epoch: 49, Step: 142/164, Loss: 0.309898, Accuracy: 89.83%\n",
            "Epoch: 49, Step: 143/164, Loss: 0.309768, Accuracy: 89.82%\n",
            "Epoch: 49, Step: 144/164, Loss: 0.309596, Accuracy: 89.82%\n",
            "Epoch: 49, Step: 145/164, Loss: 0.309400, Accuracy: 89.80%\n",
            "Epoch: 49, Step: 146/164, Loss: 0.309775, Accuracy: 89.79%\n",
            "Epoch: 49, Step: 147/164, Loss: 0.309455, Accuracy: 89.81%\n",
            "Epoch: 49, Step: 148/164, Loss: 0.309639, Accuracy: 89.81%\n",
            "Epoch: 49, Step: 149/164, Loss: 0.309030, Accuracy: 89.81%\n",
            "Epoch: 49, Step: 150/164, Loss: 0.309109, Accuracy: 89.82%\n",
            "Epoch: 49, Step: 151/164, Loss: 0.308631, Accuracy: 89.85%\n",
            "Epoch: 49, Step: 152/164, Loss: 0.308585, Accuracy: 89.84%\n",
            "Epoch: 49, Step: 153/164, Loss: 0.308511, Accuracy: 89.85%\n",
            "Epoch: 49, Step: 154/164, Loss: 0.309278, Accuracy: 89.85%\n",
            "Epoch: 49, Step: 155/164, Loss: 0.309770, Accuracy: 89.82%\n",
            "Epoch: 49, Step: 156/164, Loss: 0.310102, Accuracy: 89.81%\n",
            "Epoch: 49, Step: 157/164, Loss: 0.309923, Accuracy: 89.83%\n",
            "Epoch: 49, Step: 158/164, Loss: 0.309686, Accuracy: 89.84%\n",
            "Epoch: 49, Step: 159/164, Loss: 0.309772, Accuracy: 89.83%\n",
            "Epoch: 49, Step: 160/164, Loss: 0.310501, Accuracy: 89.79%\n",
            "Epoch: 49, Step: 161/164, Loss: 0.309814, Accuracy: 89.83%\n",
            "Epoch: 49, Step: 162/164, Loss: 0.309970, Accuracy: 89.81%\n",
            "Epoch: 49, Step: 163/164, Loss: 0.309827, Accuracy: 89.81%\n",
            "Epoch: 49, Step: 164/164, Loss: 0.310688, Accuracy: 89.78%\n",
            "Epoch: 50, Step: 1/164, Loss: 0.177818, Accuracy: 94.53%\n",
            "Epoch: 50, Step: 2/164, Loss: 0.343246, Accuracy: 88.28%\n",
            "Epoch: 50, Step: 3/164, Loss: 0.305293, Accuracy: 89.58%\n",
            "Epoch: 50, Step: 4/164, Loss: 0.322799, Accuracy: 88.87%\n",
            "Epoch: 50, Step: 5/164, Loss: 0.341791, Accuracy: 88.44%\n",
            "Epoch: 50, Step: 6/164, Loss: 0.327806, Accuracy: 89.06%\n",
            "Epoch: 50, Step: 7/164, Loss: 0.318404, Accuracy: 89.40%\n",
            "Epoch: 50, Step: 8/164, Loss: 0.319255, Accuracy: 89.06%\n",
            "Epoch: 50, Step: 9/164, Loss: 0.312300, Accuracy: 88.89%\n",
            "Epoch: 50, Step: 10/164, Loss: 0.329114, Accuracy: 88.36%\n",
            "Epoch: 50, Step: 11/164, Loss: 0.319973, Accuracy: 88.64%\n",
            "Epoch: 50, Step: 12/164, Loss: 0.313651, Accuracy: 88.80%\n",
            "Epoch: 50, Step: 13/164, Loss: 0.307322, Accuracy: 89.18%\n",
            "Epoch: 50, Step: 14/164, Loss: 0.298596, Accuracy: 89.51%\n",
            "Epoch: 50, Step: 15/164, Loss: 0.293864, Accuracy: 89.79%\n",
            "Epoch: 50, Step: 16/164, Loss: 0.297266, Accuracy: 89.70%\n",
            "Epoch: 50, Step: 17/164, Loss: 0.297303, Accuracy: 89.75%\n",
            "Epoch: 50, Step: 18/164, Loss: 0.294988, Accuracy: 89.76%\n",
            "Epoch: 50, Step: 19/164, Loss: 0.293621, Accuracy: 89.88%\n",
            "Epoch: 50, Step: 20/164, Loss: 0.299027, Accuracy: 89.84%\n",
            "Epoch: 50, Step: 21/164, Loss: 0.294326, Accuracy: 89.99%\n",
            "Epoch: 50, Step: 22/164, Loss: 0.295337, Accuracy: 89.91%\n",
            "Epoch: 50, Step: 23/164, Loss: 0.294019, Accuracy: 89.91%\n",
            "Epoch: 50, Step: 24/164, Loss: 0.295145, Accuracy: 89.91%\n",
            "Epoch: 50, Step: 25/164, Loss: 0.304845, Accuracy: 89.84%\n",
            "Epoch: 50, Step: 26/164, Loss: 0.305474, Accuracy: 89.81%\n",
            "Epoch: 50, Step: 27/164, Loss: 0.307047, Accuracy: 89.61%\n",
            "Epoch: 50, Step: 28/164, Loss: 0.305340, Accuracy: 89.68%\n",
            "Epoch: 50, Step: 29/164, Loss: 0.301921, Accuracy: 89.82%\n",
            "Epoch: 50, Step: 30/164, Loss: 0.304339, Accuracy: 89.79%\n",
            "Epoch: 50, Step: 31/164, Loss: 0.301912, Accuracy: 89.84%\n",
            "Epoch: 50, Step: 32/164, Loss: 0.299818, Accuracy: 90.01%\n",
            "Epoch: 50, Step: 33/164, Loss: 0.305640, Accuracy: 89.87%\n",
            "Epoch: 50, Step: 34/164, Loss: 0.305257, Accuracy: 89.84%\n",
            "Epoch: 50, Step: 35/164, Loss: 0.303352, Accuracy: 89.93%\n",
            "Epoch: 50, Step: 36/164, Loss: 0.304745, Accuracy: 89.89%\n",
            "Epoch: 50, Step: 37/164, Loss: 0.304559, Accuracy: 89.93%\n",
            "Epoch: 50, Step: 38/164, Loss: 0.303466, Accuracy: 89.95%\n",
            "Epoch: 50, Step: 39/164, Loss: 0.308044, Accuracy: 89.86%\n",
            "Epoch: 50, Step: 40/164, Loss: 0.306549, Accuracy: 89.92%\n",
            "Epoch: 50, Step: 41/164, Loss: 0.308720, Accuracy: 89.81%\n",
            "Epoch: 50, Step: 42/164, Loss: 0.307212, Accuracy: 89.81%\n",
            "Epoch: 50, Step: 43/164, Loss: 0.307718, Accuracy: 89.77%\n",
            "Epoch: 50, Step: 44/164, Loss: 0.308547, Accuracy: 89.75%\n",
            "Epoch: 50, Step: 45/164, Loss: 0.313850, Accuracy: 89.57%\n",
            "Epoch: 50, Step: 46/164, Loss: 0.317810, Accuracy: 89.47%\n",
            "Epoch: 50, Step: 47/164, Loss: 0.316903, Accuracy: 89.53%\n",
            "Epoch: 50, Step: 48/164, Loss: 0.315118, Accuracy: 89.57%\n",
            "Epoch: 50, Step: 49/164, Loss: 0.314615, Accuracy: 89.59%\n",
            "Epoch: 50, Step: 50/164, Loss: 0.314740, Accuracy: 89.59%\n",
            "Epoch: 50, Step: 51/164, Loss: 0.313861, Accuracy: 89.63%\n",
            "Epoch: 50, Step: 52/164, Loss: 0.312209, Accuracy: 89.68%\n",
            "Epoch: 50, Step: 53/164, Loss: 0.313349, Accuracy: 89.67%\n",
            "Epoch: 50, Step: 54/164, Loss: 0.312295, Accuracy: 89.76%\n",
            "Epoch: 50, Step: 55/164, Loss: 0.311460, Accuracy: 89.79%\n",
            "Epoch: 50, Step: 56/164, Loss: 0.310751, Accuracy: 89.82%\n",
            "Epoch: 50, Step: 57/164, Loss: 0.308620, Accuracy: 89.90%\n",
            "Epoch: 50, Step: 58/164, Loss: 0.310605, Accuracy: 89.84%\n",
            "Epoch: 50, Step: 59/164, Loss: 0.309800, Accuracy: 89.91%\n",
            "Epoch: 50, Step: 60/164, Loss: 0.309193, Accuracy: 89.93%\n",
            "Epoch: 50, Step: 61/164, Loss: 0.309306, Accuracy: 89.96%\n",
            "Epoch: 50, Step: 62/164, Loss: 0.310393, Accuracy: 89.87%\n",
            "Epoch: 50, Step: 63/164, Loss: 0.309509, Accuracy: 89.92%\n",
            "Epoch: 50, Step: 64/164, Loss: 0.308394, Accuracy: 89.97%\n",
            "Epoch: 50, Step: 65/164, Loss: 0.307518, Accuracy: 89.99%\n",
            "Epoch: 50, Step: 66/164, Loss: 0.306962, Accuracy: 90.03%\n",
            "Epoch: 50, Step: 67/164, Loss: 0.307569, Accuracy: 89.98%\n",
            "Epoch: 50, Step: 68/164, Loss: 0.306448, Accuracy: 90.00%\n",
            "Epoch: 50, Step: 69/164, Loss: 0.306990, Accuracy: 89.99%\n",
            "Epoch: 50, Step: 70/164, Loss: 0.306789, Accuracy: 90.00%\n",
            "Epoch: 50, Step: 71/164, Loss: 0.305671, Accuracy: 90.03%\n",
            "Epoch: 50, Step: 72/164, Loss: 0.305143, Accuracy: 90.01%\n",
            "Epoch: 50, Step: 73/164, Loss: 0.304833, Accuracy: 90.00%\n",
            "Epoch: 50, Step: 74/164, Loss: 0.306724, Accuracy: 89.93%\n",
            "Epoch: 50, Step: 75/164, Loss: 0.306943, Accuracy: 89.92%\n",
            "Epoch: 50, Step: 76/164, Loss: 0.307231, Accuracy: 89.91%\n",
            "Epoch: 50, Step: 77/164, Loss: 0.305598, Accuracy: 89.99%\n",
            "Epoch: 50, Step: 78/164, Loss: 0.304847, Accuracy: 90.00%\n",
            "Epoch: 50, Step: 79/164, Loss: 0.305007, Accuracy: 90.00%\n",
            "Epoch: 50, Step: 80/164, Loss: 0.305067, Accuracy: 90.00%\n",
            "Epoch: 50, Step: 81/164, Loss: 0.305001, Accuracy: 90.03%\n",
            "Epoch: 50, Step: 82/164, Loss: 0.303753, Accuracy: 90.09%\n",
            "Epoch: 50, Step: 83/164, Loss: 0.303346, Accuracy: 90.10%\n",
            "Epoch: 50, Step: 84/164, Loss: 0.302401, Accuracy: 90.14%\n",
            "Epoch: 50, Step: 85/164, Loss: 0.304001, Accuracy: 90.10%\n",
            "Epoch: 50, Step: 86/164, Loss: 0.302332, Accuracy: 90.16%\n",
            "Epoch: 50, Step: 87/164, Loss: 0.303438, Accuracy: 90.11%\n",
            "Epoch: 50, Step: 88/164, Loss: 0.302646, Accuracy: 90.14%\n",
            "Epoch: 50, Step: 89/164, Loss: 0.302413, Accuracy: 90.14%\n",
            "Epoch: 50, Step: 90/164, Loss: 0.302077, Accuracy: 90.16%\n",
            "Epoch: 50, Step: 91/164, Loss: 0.301873, Accuracy: 90.18%\n",
            "Epoch: 50, Step: 92/164, Loss: 0.300512, Accuracy: 90.23%\n",
            "Epoch: 50, Step: 93/164, Loss: 0.301003, Accuracy: 90.21%\n",
            "Epoch: 50, Step: 94/164, Loss: 0.302060, Accuracy: 90.18%\n",
            "Epoch: 50, Step: 95/164, Loss: 0.301980, Accuracy: 90.18%\n",
            "Epoch: 50, Step: 96/164, Loss: 0.303587, Accuracy: 90.17%\n",
            "Epoch: 50, Step: 97/164, Loss: 0.303819, Accuracy: 90.16%\n",
            "Epoch: 50, Step: 98/164, Loss: 0.304045, Accuracy: 90.12%\n",
            "Epoch: 50, Step: 99/164, Loss: 0.305271, Accuracy: 90.09%\n",
            "Epoch: 50, Step: 100/164, Loss: 0.304722, Accuracy: 90.11%\n",
            "Epoch: 50, Step: 101/164, Loss: 0.304321, Accuracy: 90.11%\n",
            "Epoch: 50, Step: 102/164, Loss: 0.304274, Accuracy: 90.10%\n",
            "Epoch: 50, Step: 103/164, Loss: 0.305468, Accuracy: 90.06%\n",
            "Epoch: 50, Step: 104/164, Loss: 0.304663, Accuracy: 90.10%\n",
            "Epoch: 50, Step: 105/164, Loss: 0.304402, Accuracy: 90.08%\n",
            "Epoch: 50, Step: 106/164, Loss: 0.304331, Accuracy: 90.08%\n",
            "Epoch: 50, Step: 107/164, Loss: 0.304894, Accuracy: 90.06%\n",
            "Epoch: 50, Step: 108/164, Loss: 0.304250, Accuracy: 90.08%\n",
            "Epoch: 50, Step: 109/164, Loss: 0.304613, Accuracy: 90.07%\n",
            "Epoch: 50, Step: 110/164, Loss: 0.306186, Accuracy: 89.99%\n",
            "Epoch: 50, Step: 111/164, Loss: 0.306165, Accuracy: 89.97%\n",
            "Epoch: 50, Step: 112/164, Loss: 0.305921, Accuracy: 89.96%\n",
            "Epoch: 50, Step: 113/164, Loss: 0.305596, Accuracy: 89.97%\n",
            "Epoch: 50, Step: 114/164, Loss: 0.305249, Accuracy: 90.00%\n",
            "Epoch: 50, Step: 115/164, Loss: 0.305345, Accuracy: 89.99%\n",
            "Epoch: 50, Step: 116/164, Loss: 0.304487, Accuracy: 90.02%\n",
            "Epoch: 50, Step: 117/164, Loss: 0.305463, Accuracy: 89.98%\n",
            "Epoch: 50, Step: 118/164, Loss: 0.305459, Accuracy: 89.97%\n",
            "Epoch: 50, Step: 119/164, Loss: 0.305900, Accuracy: 89.96%\n",
            "Epoch: 50, Step: 120/164, Loss: 0.306436, Accuracy: 89.95%\n",
            "Epoch: 50, Step: 121/164, Loss: 0.305798, Accuracy: 89.97%\n",
            "Epoch: 50, Step: 122/164, Loss: 0.306356, Accuracy: 89.95%\n",
            "Epoch: 50, Step: 123/164, Loss: 0.305843, Accuracy: 89.96%\n",
            "Epoch: 50, Step: 124/164, Loss: 0.306000, Accuracy: 89.96%\n",
            "Epoch: 50, Step: 125/164, Loss: 0.305317, Accuracy: 89.99%\n",
            "Epoch: 50, Step: 126/164, Loss: 0.305139, Accuracy: 90.00%\n",
            "Epoch: 50, Step: 127/164, Loss: 0.305747, Accuracy: 89.99%\n",
            "Epoch: 50, Step: 128/164, Loss: 0.306693, Accuracy: 89.96%\n",
            "Epoch: 50, Step: 129/164, Loss: 0.306119, Accuracy: 89.98%\n",
            "Epoch: 50, Step: 130/164, Loss: 0.305488, Accuracy: 90.02%\n",
            "Epoch: 50, Step: 131/164, Loss: 0.305819, Accuracy: 90.00%\n",
            "Epoch: 50, Step: 132/164, Loss: 0.306258, Accuracy: 89.97%\n",
            "Epoch: 50, Step: 133/164, Loss: 0.306719, Accuracy: 89.96%\n",
            "Epoch: 50, Step: 134/164, Loss: 0.306169, Accuracy: 89.98%\n",
            "Epoch: 50, Step: 135/164, Loss: 0.306610, Accuracy: 89.97%\n",
            "Epoch: 50, Step: 136/164, Loss: 0.307047, Accuracy: 89.95%\n",
            "Epoch: 50, Step: 137/164, Loss: 0.307839, Accuracy: 89.92%\n",
            "Epoch: 50, Step: 138/164, Loss: 0.307167, Accuracy: 89.96%\n",
            "Epoch: 50, Step: 139/164, Loss: 0.306532, Accuracy: 89.97%\n",
            "Epoch: 50, Step: 140/164, Loss: 0.306583, Accuracy: 89.98%\n",
            "Epoch: 50, Step: 141/164, Loss: 0.306080, Accuracy: 90.02%\n",
            "Epoch: 50, Step: 142/164, Loss: 0.305800, Accuracy: 90.03%\n",
            "Epoch: 50, Step: 143/164, Loss: 0.305999, Accuracy: 90.03%\n",
            "Epoch: 50, Step: 144/164, Loss: 0.305605, Accuracy: 90.03%\n",
            "Epoch: 50, Step: 145/164, Loss: 0.305155, Accuracy: 90.05%\n",
            "Epoch: 50, Step: 146/164, Loss: 0.305231, Accuracy: 90.03%\n",
            "Epoch: 50, Step: 147/164, Loss: 0.306122, Accuracy: 90.01%\n",
            "Epoch: 50, Step: 148/164, Loss: 0.306653, Accuracy: 90.00%\n",
            "Epoch: 50, Step: 149/164, Loss: 0.306231, Accuracy: 90.00%\n",
            "Epoch: 50, Step: 150/164, Loss: 0.306269, Accuracy: 90.00%\n",
            "Epoch: 50, Step: 151/164, Loss: 0.306203, Accuracy: 89.98%\n",
            "Epoch: 50, Step: 152/164, Loss: 0.306410, Accuracy: 89.94%\n",
            "Epoch: 50, Step: 153/164, Loss: 0.305970, Accuracy: 89.96%\n",
            "Epoch: 50, Step: 154/164, Loss: 0.306155, Accuracy: 89.94%\n",
            "Epoch: 50, Step: 155/164, Loss: 0.305833, Accuracy: 89.93%\n",
            "Epoch: 50, Step: 156/164, Loss: 0.305916, Accuracy: 89.94%\n",
            "Epoch: 50, Step: 157/164, Loss: 0.305969, Accuracy: 89.93%\n",
            "Epoch: 50, Step: 158/164, Loss: 0.306056, Accuracy: 89.94%\n",
            "Epoch: 50, Step: 159/164, Loss: 0.305425, Accuracy: 89.95%\n",
            "Epoch: 50, Step: 160/164, Loss: 0.305394, Accuracy: 89.96%\n",
            "Epoch: 50, Step: 161/164, Loss: 0.305471, Accuracy: 89.97%\n",
            "Epoch: 50, Step: 162/164, Loss: 0.305504, Accuracy: 89.96%\n",
            "Epoch: 50, Step: 163/164, Loss: 0.305886, Accuracy: 89.95%\n",
            "Epoch: 50, Step: 164/164, Loss: 0.305928, Accuracy: 89.95%\n"
          ]
        }
      ],
      "source": [
        "train(model, train_loader, criterion, optimizer, scheduler, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "Loss: 0.568953, Accuracy: 82.73%\n"
          ]
        }
      ],
      "source": [
        "test(model, test_loader, criterion)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
