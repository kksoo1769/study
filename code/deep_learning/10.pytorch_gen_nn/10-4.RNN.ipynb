{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7dUbyNVXcEf"
      },
      "source": [
        "# 파이토치 RNN 분류 모델\n",
        "- 코드 출처: https://tutorials.pytorch.kr/intermediate/char_rnn_classification_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dB-d43kLYEAi"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import os\n",
        "\n",
        "URL = 'https://download.pytorch.org/tutorial/data.zip'\n",
        "res = requests.get(URL)\n",
        "res.raise_for_status()\n",
        "\n",
        "z = zipfile.ZipFile(io.BytesIO(res.content))\n",
        "z.extractall(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vukqoa09LSZw"
      },
      "source": [
        "이름: Ślusàrski"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "2d1pQ-JeYKzw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\Arabic.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\Chinese.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\Czech.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\Dutch.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\English.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\French.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\German.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\Greek.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\Irish.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\Italian.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\Japanese.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\Korean.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\Polish.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\Portuguese.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\Russian.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\Scottish.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\Spanish.txt', 'c:\\\\Users\\\\kksoo\\\\Desktop\\\\work\\\\study\\\\code\\\\deep_learning\\\\10.pytorch_gen_nn\\\\data\\\\names\\\\Vietnamese.txt']\n",
            "Slusarski\n"
          ]
        }
      ],
      "source": [
        "from io import open\n",
        "import glob\n",
        "\n",
        "path = os.path.join(os.getcwd(), 'data', 'names')\n",
        "\n",
        "def find_files(path):\n",
        "    \"\"\"특정 패턴에 맞는 파일들을 찾는 함수\"\"\"\n",
        "    return glob.glob(path)\n",
        "\n",
        "print(find_files(os.path.join(path, '*.txt')))\n",
        "\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn' and c in all_letters # 악센트 제거\n",
        "    )\n",
        "\n",
        "print(unicode_to_ascii('Ślusàrski'))\n",
        "\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "\n",
        "def read_lines(file_name):\n",
        "    lines = open(file_name, encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    return [unicode_to_ascii(line) for line in lines]\n",
        "\n",
        "for file_name in find_files(os.path.join(path, '*.txt')):\n",
        "    category = os.path.splitext(os.path.basename(file_name))[0]\n",
        "    all_categories.append(category)\n",
        "    lines = read_lines(file_name)\n",
        "    category_lines[category] = lines\n",
        "    \n",
        "n_categories = len(all_categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "o39feEPmYRdv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Ahn', 'Baik', 'Bang', 'Byon', 'Cha']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "category_lines[\"Korean\"][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Mkjk05rwYUyx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0.]])\n",
            "torch.Size([5, 1, 57])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def letter_to_idx(letter):\n",
        "    return all_letters.find(letter)\n",
        "\n",
        "def letter_to_tensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters)\n",
        "    tensor[0][letter_to_idx(letter)] = 1\n",
        "    \n",
        "    return tensor\n",
        "\n",
        "def line_to_tensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "\n",
        "    for i, letter in enumerate(line):\n",
        "        tensor[i][0][letter_to_idx(letter)] = 1\n",
        "    \n",
        "    return tensor\n",
        "\n",
        "print(letter_to_tensor('J'))\n",
        "print(line_to_tensor('Jones').size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPVvWrMHYelv"
      },
      "source": [
        "## 신경망 생성\n",
        "\n",
        "- 모델 생성 방법 참고 : https://pytorch.org/tutorials/beginner/former_torchies/nnft_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "t6gKYokQYYZW"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = self.i2h(combined)\n",
        "        output = self.i2o(combined)\n",
        "        output = self.softmax(output)\n",
        "\n",
        "        return output, hidden\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "n_hidden = 128\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "wuFpzGrHYgBY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-2.8524, -2.9110, -2.8458, -2.8373, -2.9441, -2.8148, -2.9210, -2.9318,\n",
            "         -2.9164, -3.0367, -2.8514, -2.9803, -2.8800, -2.9007, -2.9146, -2.7858,\n",
            "         -2.8292, -2.9059]], grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "input = letter_to_tensor('A')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "output, next_hidden = rnn(input, hidden)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "wpGGzL2NYku2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-2.8524, -2.9110, -2.8458, -2.8373, -2.9441, -2.8148, -2.9210, -2.9318,\n",
            "         -2.9164, -3.0367, -2.8514, -2.9803, -2.8800, -2.9007, -2.9146, -2.7858,\n",
            "         -2.8292, -2.9059]], grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "input = line_to_tensor('Albert')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "output, next_hidden = rnn(input[0], hidden)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3qAoF6BYrPW"
      },
      "source": [
        "## 모델 학습\n",
        "- 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "WNTCbv4aYoP2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Scottish', 15)\n"
          ]
        }
      ],
      "source": [
        "def category_from_output(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item()\n",
        "    \n",
        "    return all_categories[category_i], category_i\n",
        "\n",
        "print(category_from_output(output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "aanvL45oYs00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Category: Vietnamese, Line: An\n",
            "Category: Vietnamese, Line: Schneijder\n",
            "Category: Vietnamese, Line: Koury\n",
            "Category: Vietnamese, Line: Sarkis\n",
            "Category: Vietnamese, Line: Tanaka\n",
            "Category: Vietnamese, Line: Deguchi\n",
            "Category: Vietnamese, Line: Thai\n",
            "Category: Vietnamese, Line: Freund\n",
            "Category: Vietnamese, Line: De santigo\n",
            "Category: Vietnamese, Line: Buchta\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def random_choice(l):\n",
        "    return l[random.randint(0, len(l) - 1)]\n",
        "\n",
        "def random_training_example():\n",
        "    category = random_choice(all_categories)\n",
        "    line = random_choice(category_lines[category])\n",
        "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "    line_tensor = line_to_tensor(line)\n",
        "\n",
        "    return category, line, category_tensor, line_tensor\n",
        "\n",
        "for i in range(10):\n",
        "    cateogory, line, category_tensor, line_tensor = random_training_example()\n",
        "    print(f\"Category: {category}, Line: {line}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVA-IZP3Yzz2"
      },
      "source": [
        "## 손실함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y98Uy0YPYwjY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDyQIe8lY_Vl"
      },
      "source": [
        "## 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vIcTqP8Y9lo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRDcSbrsZAK9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSwAjR6QZDRf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0_2HyE3ZPZk"
      },
      "source": [
        "## 모델 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBVWJNmoZO8a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfjRYlioZV3o"
      },
      "source": [
        "## 사용자 입력으로부터의 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uteG1Je5ZQWg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
