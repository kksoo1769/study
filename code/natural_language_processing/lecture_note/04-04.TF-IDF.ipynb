{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF(Term Frequency-Inverse Document Frequency)\n",
    "\n",
    "단어의 빈도와 문서의 빈도에 특정 식을 취한 역 문서 빈도를 사용하여 DTM 내의 각 단어들마다 중요한 정도를 가중치로 주는 방법이다. 주로 문서의 유사도를 구하거나, 검색 시스템에서 검색 결과의 중요도를 정하는 작업, 문서 내에서 특정 단어의 중요도를 구하는 작업 등에 사용할 수 있다. `TF-IDF`는 `TF`와 `IDF`를 곱한 값을 의미한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`d`: 문서, `t`: 단어, `n`: 문서의 총 개수\n",
    "\n",
    "# tf(d, t)\n",
    "특정 문서 `d`에서 특정 단어 `t`의 등장 횟수이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df(t)\n",
    "특정 단어 `t`가 등장한 문서의 수이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## idf(d, t)\n",
    "`df(t)`에 반비례하는 수로, $ idf(d, t) = log(\\frac{n}{1 + df(t)}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM\n",
      "[[0 1 0 1 0 1 1 1 0]\n",
      " [1 0 1 0 1 0 0 0 1]]\n",
      "\n",
      "Word to Index\n",
      "{'you': 6, 'know': 1, 'want': 5, 'your': 7, 'love': 3, 'like': 2, 'youwhat': 8, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"you know I want your love\",\n",
    "    \"I like you\"\n",
    "    \"what should I do\"\n",
    "]\n",
    "vector = CountVectorizer()\n",
    "\n",
    "print(\"DTM\")\n",
    "print(vector.fit_transform(corpus).toarray(), end=\"\\n\" * 2)\n",
    "print(\"Word to Index\")\n",
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tf-Idf\n",
      "[[0.        0.4472136 0.        0.4472136 0.        0.4472136 0.4472136\n",
      "  0.4472136 0.       ]\n",
      " [0.5       0.        0.5       0.        0.5       0.        0.\n",
      "  0.        0.5      ]]\n",
      "\n",
      "Word to Index\n",
      "{'you': 6, 'know': 1, 'want': 5, 'your': 7, 'love': 3, 'like': 2, 'youwhat': 8, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vector = TfidfVectorizer()\n",
    "\n",
    "print(\"Tf-Idf\")\n",
    "print(tfidf_vector.fit_transform(corpus).toarray(), end=\"\\n\" * 2)\n",
    "print(\"Word to Index\")\n",
    "print(tfidf_vector.vocabulary_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
